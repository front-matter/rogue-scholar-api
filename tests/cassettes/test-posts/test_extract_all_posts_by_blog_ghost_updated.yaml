interactions:
- request:
    body: '{}'
    headers:
      accept:
      - application/vnd.pgrst.object+json
      accept-encoding:
      - gzip, deflate
      accept-profile:
      - public
      connection:
      - keep-alive
      content-length:
      - '2'
      content-profile:
      - public
      content-type:
      - application/json
      host:
      - db.rogue-scholar.org
      user-agent:
      - python-httpx/0.24.1
      x-client-info:
      - supabase-py/1.2.0
    method: GET
    uri: https://db.rogue-scholar.org/rest/v1/blogs?select=id%2C%20slug%2C%20feed_url%2C%20current_feed_url%2C%20home_page_url%2C%20archive_prefix%2C%20feed_format%2C%20created_at%2C%20modified_at%2C%20use_mastodon%2C%20generator%2C%20favicon%2C%20title%2C%20description%2C%20category%2C%20status%2C%20user_id%2C%20authors%2C%20plan%2C%20use_api%2C%20relative_url%2C%20filter&slug=eq.front_matter
  response:
    content: '{"id":"f0m0e38","slug":"front_matter","feed_url":"https://blog.front-matter.io/atom-complete/","current_feed_url":"https://blog.front-matter.io/atom/","home_page_url":"https://blog.front-matter.io","archive_prefix":null,"feed_format":"application/atom+xml","created_at":"2023-01-02","modified_at":"2023-10-11T16:42:07+00:00","use_mastodon":true,"generator":"Ghost
      5.52","favicon":"https://blog.front-matter.io/favicon.png","title":"Front Matter","description":"The
      Front Matter Blog covers the intersection of science and technology since 2007.","category":"computerAndInformationSciences","status":"active","user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","authors":null,"plan":"Team","use_api":true,"relative_url":null,"filter":null}'
    headers:
      Access-Control-Allow-Origin:
      - '*'
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 81804d25ebd9caf9-DUS
      Connection:
      - keep-alive
      Content-Location:
      - /blogs?select=id%2C%20slug%2C%20feed_url%2C%20current_feed_url%2C%20home_page_url%2C%20archive_prefix%2C%20feed_format%2C%20created_at%2C%20modified_at%2C%20use_mastodon%2C%20generator%2C%20favicon%2C%20title%2C%20description%2C%20category%2C%20status%2C%20user_id%2C%20authors%2C%20plan%2C%20use_api%2C%20relative_url%2C%20filter&slug=eq.front_matter
      Content-Profile:
      - public
      Content-Range:
      - 0-0/*
      Content-Type:
      - application/vnd.pgrst.object+json; charset=utf-8
      Date:
      - Wed, 18 Oct 2023 11:04:35 GMT
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      Via:
      - kong/2.8.1
      X-Kong-Proxy-Latency:
      - '1'
      X-Kong-Upstream-Latency:
      - '5'
      alt-svc:
      - h3=":443"; ma=86400
      sb-gateway-version:
      - '1'
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: null
    headers:
      A-Im:
      - feed
      Accept:
      - application/atom+xml,application/rdf+xml,application/rss+xml,application/x-netcdf,application/xml;q=0.9,text/xml;q=0.2,*/*;q=0.1
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - close
      Host:
      - blog.front-matter.io
      User-Agent:
      - feedparser/6.0.10 +https://github.com/kurtmckee/feedparser/
    method: GET
    uri: https://blog.front-matter.io/atom-complete/
  response:
    body:
      string: "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<feed xmlns=\"http://www.w3.org/2005/Atom\">\n
        \   <title><![CDATA[ Front Matter ]]></title>\n    <subtitle><![CDATA[  The
        Front Matter Blog covers the intersection of science and technology since
        2007. ]]></subtitle>\n    <link rel=\"self\" type=\"application/atom+xml\"
        href=\"https://blog.front-matter.io/atom/?page=\" />    \n    <link rel=\"alternate\"
        type=\"text/html\" href=\"https://blog.front-matter.io\" />\n    <link rel=\"license\"
        type=\"text/html\" href=\"https://creativecommons.org/licenses/by/4.0/legalcode\"
        />\n    <id>https://blog.front-matter.io/atom/</id>\n    <language>en</language>\n
        \   <generator uri=\"https://ghost.org\" version=\"5.52\">Ghost</generator>\n
        \   <updated>2023-10-17T09:09:46+00:00</updated>\n    \n    <entry>\n\t\t<title><![CDATA[
        Generating Overlay blog posts ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/generating-overlay-blog-posts/\"
        />\n\t\t<id>https://doi.org/10.53731/gzrse-p5d35</id>\n        <published>2023-10-11T16:40:31.000+00:00</published>\n\t\t<updated>2023-10-12T08:27:25.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://images.unsplash.com/flagged/photo-1552425083-0117136f7d67?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDIxfHxjYW5vcHl8ZW58MHx8fHwxNjk3MDQwMDk1fDA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://images.unsplash.com/flagged/photo-1552425083-0117136f7d67?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDIxfHxjYW5vcHl8ZW58MHx8fHwxNjk3MDQwMDk1fDA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"></p><p>On
        Monday the Rogue Scholar science blog archive <a href=\"https://doi.org/10.53731/ar11b-5ea39\"
        rel=\"noreferrer\">launched a dedicated API</a>. Today I am reporting on the
        first Jupyter notebook using that API to generate an overlay blog post.</p><blockquote>An&nbsp;<strong>overlay
        journal</strong>&nbsp;or&nbsp;<strong>overlay ejournal</strong>&nbsp;is a
        type of&nbsp;open access&nbsp;academic journal, almost always an online&nbsp;electronic
        journal&nbsp;(ejournal), that does not produce its own content, but selects
        from texts that are already freely available online.&nbsp;From <a href=\"https://en.wikipedia.org/wiki/Overlay_journal\"
        rel=\"noreferrer\">Wikipedia</a></blockquote><p>An <strong>overlay blog post</strong>
        applies the idea of an <strong>overlay journal</strong> to science blog posts,
        and the Rogue Scholar API \u2013 in combination with content that has an open
        license (<a href=\"https://creativecommons.org/licenses/by/4.0/legalcode\"
        rel=\"noreferrer\">CC-BY</a>) \u2013 makes that easy.</p><p>The Jupyter notebook
        that I started and <a href=\"https://github.com/front-matter/rogue-scholar-notebooks\">made
        available via GitHub</a> and <a href=\"https://doi.org/10.5281/zenodo.8433675\"
        rel=\"noreferrer\">Zenodo</a> fetches all blog posts using a search term and
        some other conditions (here written in English and published after 2010).
        I thought a good search term to try out the concept would be <strong>Retraction
        Watch</strong>, after the <a href=\"https://doi.org/10.13003/c23rw1d9\" rel=\"noreferrer\">announcement
        in September</a> that <em>Crossref has acquired the Retraction Watch database
        of expressions of concerns and retractions and has made it openly accessible
        to anyone who wants to use it.</em></p><p>The notebook includes this note:</p><div
        class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">\U0001F4A1</div><div
        class=\"kg-callout-text\">We use the query&nbsp;retraction watch. We limit
        results to posts published since&nbsp;2010&nbsp;(the year Retraction Watch
        launched) and&nbsp;en&nbsp;as language. We retrieve the&nbsp;title,&nbsp;authors,&nbsp;publication
        date,&nbsp;abstract,&nbsp;blog name,&nbsp;doi&nbsp;and&nbsp;url.We sort the
        results in reverse chronological order (newest first).</div></div><p>The query
        for that search term returned 17 blog posts included in Rogue Scholar (out
        of about 9,000 posts), and manual curation narrowed that list further down
        to 12 posts (visualized with <a href=\"https://mermaid.js.org/\" rel=\"noreferrer\">Mermaid</a>):</p><figure
        class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2023/10/mermaid-figure-1.png\"
        class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"190\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2023/10/mermaid-figure-1.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/10/mermaid-figure-1.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/10/mermaid-figure-1.png
        1600w, https://blog.front-matter.io/content/images/size/w2400/2023/10/mermaid-figure-1.png
        2400w\" sizes=\"(min-width: 720px) 720px\"></figure><p>The notebook then generates
        a bibtex file of all 12 blog posts (easy as they all have DOIs) and generates
        a summary written in markdown using the title, author, blog name, publication
        date, and abstract.</p><h2 id=\"conclusions\">Conclusions</h2><p>The notebook
        needs some more fine-tuning, and I plan to publish the first overlay blog
        post next week. But notebooks are an interesting approach to automate the
        generating of overlay blog posts, open to everyone as the content of the Rogue
        Scholar API is freely available for reuse. I particularly like using both
        automation and manual curation using open source tools, which is a powerful
        combination</p><h2 id=\"references\">References</h2><p>Fenner, M. (2023).
        <em>Rogue Scholar has an API</em>. <a href=\"https://doi.org/10.53731/ar11b-5ea39\">https://doi.org/10.53731/ar11b-5ea39</a></p><p>Fenner,
        M. (2023). <em>front-matter/rogue-scholar-notebooks: Initial public release</em>
        (0.8) [Computer software]. Zenodo. <a href=\"https://doi.org/10.5281/ZENODO.8433675\">https://doi.org/10.5281/ZENODO.8433675</a></p><p>Crossref,
        Hendricks, G., Center for Scientific Integrity, &amp; Lammey, R. (2023). <em>Crossref
        acquires Retraction Watch data and opens it for the scientific community</em>.
        <a href=\"https://doi.org/10.13003/c23rw1d9\">https://doi.org/10.13003/c23rw1d9</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Rogue Scholar has an API ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/rogue-scholar-has-an-api/\" />\n\t\t<id></id>\n
        \       <published>2023-10-09T15:19:57.000+00:00</published>\n\t\t<updated>2023-10-12T08:11:37.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://images.unsplash.com/photo-1555952494-efd681c7e3f9?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDM0fHxweXRob258ZW58MHx8fHwxNjk2ODU4Nzc5fDA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://images.unsplash.com/photo-1555952494-efd681c7e3f9?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDM0fHxweXRob258ZW58MHx8fHwxNjk2ODU4Nzc5fDA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"></p><p>The
        Rogue Scholar science blog archive has launched a dedicated API today, publicly
        available at <code>https://api.rogue-scholar.org</code> and complementing
        the <a href=\"https://rogue-scholar.org\" rel=\"noreferrer\">website</a>.</p><p>Rogue
        Scholar had an API before but with two important limitations. </p><ul><li><strong>Serverless</strong>.
        The API at https://rogue-scholar.org/api uses <a href=\"https://www.serverless.com/\"
        rel=\"noreferrer\">serverless</a> technology, which isn't a good fit for long-running
        resource-intense processes.</li><li><strong>GitHub Actions</strong>. GitHub
        Actions are used for DOI registrations. They can be triggered at specific
        times, but <a href=\"https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows\"
        rel=\"noreferrer\">not more than once every 5 min</a>.</li></ul><p>The new
        API overcomes these limitations once it is fully implemented by the end of
        the year. The version released today implements HTTP <code>get</code>requests,
        supports anonymous users, and provides the same information that is also available
        via the Rogue Scholar <a href=\"https://rogue-scholar.org\" rel=\"noreferrer\">website</a>.
        The API is implemented as a Python <a href=\"https://quart.palletsprojects.com/en/latest/index.html\"
        rel=\"noreferrer\">Quart application</a> (an async Python web micro-framework
        heavily inspired by Flask), hosted on the <a href=\"https://fly.io\" rel=\"noreferrer\">fly.io</a>
        platform, and available as Open Source software via <a href=\"https://github.com/front-matter/rogue-scholar-api\"
        rel=\"noreferrer\">GitHub</a> , <a href=\"https://pypi.org/project/rogue-scholar-api/\"
        rel=\"noreferrer\">PyPi</a>, and <a href=\"https://doi.org/10.5281/ZENODO.8433679\"
        rel=\"noreferrer\">Zenodo</a>. More work is needed to allow users to run the
        API locally, as the API requires data from the database (Postgres) and search
        index (Typesense), which both also use Open Source software but need authentication
        for access. The simplest way to get started with the Rogue Scholar API is
        to use the <a href=\"https://api.rogue-scholar.org/openapi.json\" rel=\"noreferrer\">OpenAPI
        endpoint</a> with the <a href=\"https://api.rogue-scholar.org/docs\" rel=\"noreferrer\">Swagger
        UI</a>:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2023/10/Bildschirmfoto-2023-10-09-um-16.24.07.png\"
        class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1340\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2023/10/Bildschirmfoto-2023-10-09-um-16.24.07.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/10/Bildschirmfoto-2023-10-09-um-16.24.07.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/10/Bildschirmfoto-2023-10-09-um-16.24.07.png
        1600w, https://blog.front-matter.io/content/images/2023/10/Bildschirmfoto-2023-10-09-um-16.24.07.png
        2086w\" sizes=\"(min-width: 720px) 720px\"><figcaption><a href=\"https://api.rogue-scholar.org/docs\"
        rel=\"noreferrer\"><span style=\"white-space: pre-wrap;\">Rogue Scholar API
        Swagger UI</span></a></figcaption></figure><p>In the coming weeks, I will
        work on improving the Rogue Scholar API in the following important areas:</p><h2
        id=\"integration-of-doi-registration\">Integration of DOI registration</h2><p>This
        is currently done via GitHub Actions and a <a href=\"https://rubygems.org/gems/commonmeta-ruby\"
        rel=\"noreferrer\">Ruby gem</a> automatically converts the blog post metadata
        into Crossref XML needed for DOI registration. This works fine but doesn't
        easily scale to 100s or more DOI registrations or updates per day, and is
        more difficult to integrate with other workflows compared to an internal API.
        The goal is to switch to the DOI registrations via a background task triggered
        by the API and using the Python <a href=\"https://pypi.org/project/commonmeta-py/\"
        rel=\"noreferrer\">metadata conversion library</a> that I wrote at the beginning
        of the year.</p><h2 id=\"conversion-of-blog-posts-to-epub-or-pdf\">Conversion
        of blog posts to ePub or PDF</h2><p>Converting the science blog posts archived
        in Rogue Scholar into ePub, PDF, or other formats using the <a href=\"https://pandoc.org/\"
        rel=\"noreferrer\">Pandoc</a> universal document converter would enable several
        interesting use cases, for example storing blog posts locally with a reference
        manager or generating collections by blog, author, or topic.</p><h2 id=\"metadata-conversion\">Metadata
        conversion</h2><p>The API released today continues the Rogue Scholar integration
        with DOI content negotiation to convert blog post metadata into different
        formats such as BibTeX or formatted citations. We could offer <a href=\"https://github.com/front-matter/commonmeta-py\"
        rel=\"noreferrer\">additional metadata conversions</a> not currently implemented
        by DOI content negotiation such as <a href=\"https://schema.org/\" rel=\"noreferrer\">Schema.org</a>
        JSON-LD.</p><h2 id=\"data-science-using-science-blogs\">Data Science using
        science blogs</h2><p>Finally, the new API enables data scientists to explore
        science blogs in more detail. With close to 10,000 science blog posts from
        60 different blogs going as far back as 2005 and available as full-text with
        an open license (<a href=\"https://creativecommons.org/licenses/by/4.0/legalcode\"
        rel=\"noreferrer\">CC-BY</a>), many interesting questions can be explored.
        I will start with a Jupyter notebook that provides a more detailed analysis
        than the <a href=\"https://rogue-scholar.org/#stats\" rel=\"noreferrer\">Rogue
        Scholar stats page</a>, taking as inspiration the work of the <a href=\"https://doi.org/10.59349/zh4g1-q7e26\"
        rel=\"noreferrer\">Journal of Open Source Software</a>. I am particularly
        interested in the more than <a href=\"https://api.crossref.org/members/31795/works?filter=has-references:true\"
        rel=\"noreferrer\">750 blog posts that include references</a> in their metadata,
        as to the best of my knowledge that kind of bibliometric analysis has never
        been done.</p><h2 id=\"references\">References</h2><p>Fenner, M. (2023). <em>front-matter/rogue-scholar-api:
        Initial public release</em> (v0.6,2) [Computer software]. Zenodo. <a href=\"https://doi.org/10.5281/ZENODO.8433679\">https://doi.org/10.5281/ZENODO.8433679</a></p><p>Smith,
        A. M. (2023). <em>JOSS publishes 2000th paper</em>. Journal of Open Source
        Software Blog. <a href=\"https://doi.org/10.59349/zh4g1-q7e26\">https://doi.org/10.59349/zh4g1-q7e26</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ The rise of the (science) newsletter ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/the-rise-of-the-science-newsletter/\"
        />\n\t\t<id></id>\n        <published>2023-10-04T10:36:32.000+00:00</published>\n\t\t<updated>2023-10-04T17:40:14.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://images.unsplash.com/photo-1518546488314-6ed28acc48e3?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDI1fHxyaXNlfGVufDB8fHx8MTY5NjQwNTMyNnww&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://images.unsplash.com/photo-1518546488314-6ed28acc48e3?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDI1fHxyaXNlfGVufDB8fHx8MTY5NjQwNTMyNnww&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"></p><p>Newsletters
        have been around forever, but their popularity has significantly increased
        in the past few years, also thanks to platforms such as <a href=\"https://ghost.org/\"
        rel=\"noreferrer\">Ghost</a>, <a href=\"https://medium.com/\" rel=\"noreferrer\">Medium</a>,
        and <a href=\"https://substack.com/\" rel=\"noreferrer\">Substack</a>.  Which
        of course also includes science newsletters.</p><h2 id=\"failure-of-advertising-as-a-revenue-model\">Failure
        of advertising as a revenue model</h2><p>The most important driver of this
        trend is probably the realization that advertising is a poor revenue model
        for content published on the web, including blogs. Even more so for science
        content, which seldom draws a lot of traffic but rather typically caters to
        small, fragmented communities. This trend is only aggravated by the development
        of targeted advertising platforms and technologies, which don't respect the
        users' privacy and in turn led to legislation such as GDPR (<a href=\"https://en.wikipedia.org/wiki/General_Data_Protection_Regulation\"
        rel=\"noreferrer\">General Data Protection Regulation</a>), implemented in
        the European Union in May 2018. </p><h2 id=\"failure-of-twitter-and-social-media\">Failure
        of Twitter and social media</h2><p>A direct consequence of this <em>rat race
        </em>around advertising revenue and user privacy, made worse by a pandemic
        that dramatically changed how we interact online, is that social media are
        seeing the biggest changes in more than 10 years. Twitter changed ownership
        12 months ago and is no longer <em>the</em> place to communicate science,
        including finding out about new publications, science events, or science blog
        posts. One side effect of this development is that <a href=\"https://altmetrics.org/manifesto/\"
        rel=\"noreferrer\">altmetrics</a> have stopped being useful. Scientists have
        dramatically <a href=\"https://doi.org/10.1038/d41586-023-02554-0\" rel=\"noreferrer\">reduced
        their use of Twitter</a> or have moved to other social media platforms. And
        the visibility of posts on the platform formerly known as Twitter is now determined
        mainly by <a href=\"https://indieweb.org/algorithmic_feed\" rel=\"noreferrer\">algorithmic
        feeds</a> rather than their users. Facebook/Meta and Reddit have similar issues,
        and this is related to private organizations owning and controlling most popular
        social media platforms.</p><h2 id=\"newsletters-as-an-alternative\">Newsletters
        as an alternative</h2><p>Newsletters provide an <a href=\"https://ghost.org/resources/how-to-make-money-blogging/\"
        rel=\"noreferrer\">interesting alternative</a> to advertising and \"traditional\"
        social media. They are particularly promising for science blogs, as they can
        be easily combined with blogging platforms. Either as a single platform as
        with Ghost (used by this blog), Substack, or Medium, or integrated with the
        blogging platform, as several science blogs participating in Rogue Scholar
        are doing.</p><p>Newsletters can provide a revenue source that is more sustainable
        than advertising, and they reach users directly rather than depending on social
        media which currently are undergoing major changes.</p><h2 id=\"the-problems-with-newsletters\">The
        problems with newsletters</h2><p>Newsletters are not without problems. The
        biggest challenge I see is that they make it very easy to lock content behind
        a paywall. Which does not align well with the overall trend toward Open Access
        and scholarly content that is free to read and reuse.</p><p>Another challenge
        is that email is not always the best medium for scholarly communication. Email
        is fine for occasional newsletters, but doesn't really scale well. There are
        good reasons we have RSS readers and social media, and depending on newsletters
        only feels like a regression to how we communicated in the early 1990s.</p><h2
        id=\"conclusions\">Conclusions</h2><p>Newsletters are an evolving format that
        can nicely integrate with science blogs. For science blogs, it is important
        that the content remains free to read and reuse (ideally using a CC-BC license),
        and that the content remains also available via RSS feed and web page. This
        approach aligns with the <a href=\"https://doi.org/10.24343/C34W2H\" rel=\"noreferrer\">Principles
        of Open Scholarly Infrastructure</a>:</p><blockquote><strong>Revenue based
        on services, not data</strong>&nbsp;\u2013 data related to the running of
        the research enterprise should be a community property. Appropriate revenue
        sources might include value-added services, consulting, API Service Level
        Agreements or membership fees.</blockquote><p>Front Matter is offering two
        newsletters:</p><ul><li>The <strong>Front Matter newsletter</strong> distributes
        the blog posts of this blog, which currently focus on the Rogue Scholar science
        blog service and related topics. Recommended for all bloggers participating
        in the Rogue Scholar service. You can subscribe <a href=\"https://blog.front-matter.io/\"
        rel=\"noreferrer\">here</a>.</li><li>The <strong>Syldavia Gazette newsletter</strong>
        publishes summaries of interesting science blog posts found on the web, including
        an automated weekly digest of new blog posts archived in the Rogue Scholar
        science blog archive over the past seven days. You can subscribe <a href=\"https://syldavia-gazette.org/\"
        rel=\"noreferrer\">here</a>.</li></ul><p>Over the last two days I have reorganized
        the Front Matter newsletters into one technical newsletter (Front Matter)
        and one journalistic newsletter (Syldavia Gazette). In the process, I had
        to move the existing subscriptions around. Please unsubscribe if you now receive
        a Front Matter newsletter you no longer wish to receive.</p><p>The new format
        of the Syldavia Gazette newsletter (including the weekly Rogue Scholar digest)
        poses an interesting problem best described in the movie <em>Ghostbusters</em>:</p><figure
        class=\"kg-card kg-image-card\"><img src=\"https://media.tenor.com/2YAgdU9Ifo8AAAAC/dont-cross-the-streams-ghostbusters.gif\"
        class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"498\" height=\"206\"></figure><p>Rogue
        Scholar automatically archives all blog posts of participating science blogs.
        If the Syldavia Gazette publishes digests of Rogue Scholar blog posts, this
        could lead to an interesting loop. The solution was to implement a new feature
        in Rogue Scholar to only archive some blog posts using a filter. This of course
        is also useful for other use cases discussed several times where only some
        posts should be included in Rogue Scholar, archived, and assigned a DOI.</p><h2
        id=\"references\">References</h2><p>Vidal Valero, M. (2023). Thousands of
        scientists are cutting back on Twitter, seeding angst and uncertainty. <em>Nature</em>,
        <em>620</em>(7974), 482\u2013484. <a href=\"https://doi.org/10.1038/d41586-023-02554-0\">https://doi.org/10.1038/d41586-023-02554-0</a></p><p>Bilder,
        G., Lin, J., &amp; Neylon, C. (2020). <em>The Principles of Open Scholarly
        Infrastructure</em>. <a href=\"https://doi.org/10.24343/C34W2H\">https://doi.org/10.24343/C34W2H</a></p><p>Fenner,
        M. (2023). <em>The Rogue Scholar weekly newsletter launches on Wednesday</em>.
        <a href=\"https://doi.org/10.53731/9cdnt-2k006\">https://doi.org/10.53731/9cdnt-2k006</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Collecting metadata for science blog posts
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/collecting-metadata/\"
        />\n\t\t<id></id>\n        <published>2023-10-02T20:02:56.000+00:00</published>\n\t\t<updated>2023-10-02T20:02:56.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2023/10/8071729256_19fe2e444c.jpg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2023/10/8071729256_19fe2e444c.jpg\"></p><p>Metadata
        are an important feature of every scholarly resource. For science blog posts
        \u2013 which are published with far fewer resources than for example journal
        articles or books \u2013 there is an additional requirement: make the metadata
        collection as painless as possible. In this post, I describe the lessons learned
        over the years, including recent work on the <a href=\"https://rogue-scholar.org\"
        rel=\"noreferrer\">Rogue Scholar science blog archive</a>.</p><h2 id=\"google-scholar-and-html-meta-tags\">Google
        Scholar and HTML meta tags</h2><p>Scholarly resources published on the web
        want to expose their metadata to make it easier to find them. One important
        driver is <a href=\"https://scholar.google.com/\" rel=\"noreferrer\">Google
        Scholar</a> and their <a href=\"https://scholar.google.com/intl/en/scholar/inclusion.html\"
        rel=\"noreferrer\">Inclusion Guidelines for Webmasters</a> are followed by
        most scholarly publishers and repositories. The guidelines rely heavily on
        <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTML/Element/meta\"
        rel=\"noreferrer\">HTML meta tags</a>, in particular the <a href=\"https://div.div1.com.au/div-thoughts/div-commentaries/66-div-commentary-metadata\"
        rel=\"noreferrer\">Highwire Press and Dublin Core</a> subsets. One problem
        with HTML meta tags is that they can't easily describe structured content,
        such as multiple authors, each with a name and ORCID ID. The bigger problem
        for science blogs is that generating these tags is a lot of work, and not
        really supported by standard blogging platforms.</p><h2 id=\"schemaorg-and-google-dataset-search\">Schema.org
        and Google Dataset Search</h2><p><a href=\"https://schema.org/\" rel=\"noreferrer\">Schema.org</a>
        describes structured content on the internet. It overcomes the limitations
        of HTML meta tags and can easily describe structured content such as multiple
        authors, each having a given name, family name, identifier, and affiliation.
        And schema.org is heavily used by Google and other search engines. But while
        schema.org is essential for <a href=\"https://datasetsearch.research.google.com/\"
        rel=\"noreferrer\">Google Dataset Search</a> and <a href=\"https://doi.org/10.1038/s41597-019-0031-8\"
        rel=\"noreferrer\">discovery of datasets published on the internet</a>, it
        has seen little adoption to describe textual scholarly publications such as
        journal articles, conference proceedings, or books. One reason is that schema.org
        uses a very different approach from Google Scholar, another reason is that
        it is more difficult to implement.</p><p>I have used schema.org for many years
        to register DOIs with metadata for the <a href=\"https://datacite.org/blog/\"
        rel=\"noreferrer\">DataCite blog</a>. This approach worked well but was probably
        too complex to be adopted by a larger number of science blogs. One improvement
        was the combination of schema.org with HTML meta tags, but still required
        a lot of customization of each blog.</p><h2 id=\"rss-and-atom-feeds\">RSS
        and Atom Feeds</h2><p>Blogs provide a unique mechanism to distribute metadata
        and content: <a href=\"https://en.wikipedia.org/wiki/RSS\" rel=\"noreferrer\">RSS
        feeds</a>, and the related <a href=\"https://datatracker.ietf.org/doc/html/rfc4287\"
        rel=\"noreferrer\">Atom</a> and <a href=\"https://www.jsonfeed.org/\" rel=\"noreferrer\">JSON
        Feed</a> formats. These formats provide all the required and some of the recommended
        metadata needed for scholarly content, including title, authors, publication
        date, abstract, location (URL), and language. RSS and Atom have been around
        for more than 15 years (JSON Feed was <a href=\"https://www.jsonfeed.org/2017/05/17/announcing-json-feed.html\"
        rel=\"noreferrer\">announced</a> in 2017) and all blogging platforms support
        at least one of these formats.</p><p>RSS and related formats basically solved
        the challenge of metadata collection for science blogs, and therefore the
        Rogue Scholar science blog archive relies heavily on them. The experience
        collecting metadata and content from more than 50 different science blogs
        (using <a href=\"https://rogue-scholar.org/#stats\" rel=\"noreferrer\">11
        different blogging platforms</a>) over the past several months has been very
        positive.</p><p>One major challenge with RSS and related formats is that they
        are not very good at providing archival content as they focus on the most
        recent blog posts. Several popular blogging platforms (e.g. WordPress and
        Blogger) provide pagination to access older content, but other platforms (e.g.
        the static site generators Hugo and Jekyll) provide no built-in pagination
        of RSS feeds.</p><h2 id=\"blogging-platform-apis\">Blogging platform APIs</h2><p>RSS
        feeds are \"poor man's APIs\", e.g. they use the older XML serialization (RSS
        and Atom) instead of JSON serialization that dominates APIs today, have trouble
        accessing older content, and are read-only. </p><p>The next step in the evolution
        of metadata and content collection for science blogs is therefore to use existing
        JSON APIs, and in the last few weeks, the Rogue Scholar backend has been refactored
        to use these APIs if available. Ghost, WordPress (both self-hosted and WordPress.com),
        and Substack all provide nice JSON APIs so that the majority of Rogue Scholar
        blogs and blog posts are now retrieved via REST API calls. The early experience
        using these JSON APIs has been very encouraging and follows the fundamental
        principle of Rogue Scholar to not put a burden (technical, financial, or otherwise)
        on participating science blogs.</p><p>The use of blog APIs addresses another
        important problem: how are the DOIs registered by the Rogue Scholar service
        automatically added to the blogging platform? This issue is solved for several
        participating blogs using the Ghost platform and I am currently working on
        implementing this for blogs using WordPress, the most popular blogging platform
        on Rogue Scholar.</p><h2 id=\"extracting-metadata-from-full-text-content\">Extracting
        metadata from full-text content</h2><p>One important limitation of using RSS
        feeds or blogging platform APIs is that they will only provide standard metadata,
        which sometimes might not be enough for scholarly content. I am currently
        exploring with one science blog extending the JSON Feed format with <a href=\"https://www.jsonfeed.org/version/1.1/\"
        rel=\"noreferrer\">extensions</a>, but that requires technical work by participating
        blogs and will probably scale poorly</p><p>A different approach that Rogue
        Scholar has followed for a few months takes advantage of the fact that all
        Rogue Scholar blog posts are available as full-text content with an open license
        (<a href=\"https://creativecommons.org/licenses/by/4.0/legalcode.en\" rel=\"noreferrer\">CC-BY</a>)
        that allows reuse. A good example of important metadata that are not part
        of RSS or REST API metadata but included in the full-text content is references.
        As they typically follow a well-known pattern (a <em>References</em> or <em>Bibliography</em>
        section followed by a list of references formatted with various citation styles
        and including a link), it is not too difficult to extract them and include
        them in the metadata registered with a DOI. </p><figure class=\"kg-card kg-image-card\"><img
        src=\"https://blog.front-matter.io/content/images/2023/10/article2-1-1-1.png\"
        class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"500\" height=\"722\"></figure><p>Rogue
        Scholar implemented this approach in <a href=\"https://doi.org/10.53731/6mkrk-dzh02\"
        rel=\"noreferrer\">June</a>. About <a href=\"ref.org/members/31795/works?filter=has-references:true\"
        rel=\"noreferrer\">10%</a> of Rogue Scholar blog posts now have their references
        registered with Crossref.</p><p>Other metadata that can be extracted from
        the full-text content describe funding information and <a href=\"https://www.crossref.org/documentation/schema-library/markup-guide-metadata-segments/relationships/\">relationships</a>,
        for example, these common use cases for science blogs:</p><ul><li><strong>IsIdenticalTo</strong>:
        The same content is cross-posted elsewhere, either on another blog or as a
        PDF in a repository,</li><li><strong>IsTranslationOf</strong>: The same content
        has been posted translated into another language,</li><li><strong>IsPreprintOf</strong>:
        The content has been published as a peer-reviewed paper in a journal,</li><li><strong>HasAward</strong>:
        The content has been funded as part of work on a research grant.</li></ul><p>I
        recently started piloting this approach with two other blogs, including relationship
        links in an <em>Acknowledgments</em> section, and converting them to Crossref
        DOI metadata. About <a href=\"https://www.crossref.org/members/prep/31795\"
        rel=\"noreferrer\">1%</a> of Rogue Scholar blog posts now include funding
        \ information and/or relationships.</p><figure class=\"kg-card kg-image-card
        kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2023/10/Bildschirmfoto-2023-10-02-um-21.23.04.png\"
        class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1550\" height=\"660\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2023/10/Bildschirmfoto-2023-10-02-um-21.23.04.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/10/Bildschirmfoto-2023-10-02-um-21.23.04.png
        1000w, https://blog.front-matter.io/content/images/2023/10/Bildschirmfoto-2023-10-02-um-21.23.04.png
        1550w\" sizes=\"(min-width: 720px) 720px\"><figcaption><a href=\"https://doi.org/10.53731/r79v4e1-97aq74v-ag578\"
        rel=\"noreferrer\"><span style=\"white-space: pre-wrap;\">Acknowledgments
        and References sections</span></a><span style=\"white-space: pre-wrap;\">
        used to extract metadata.</span></figcaption></figure><h2 id=\"conclusions\">Conclusions</h2><p>Collecting
        metadata for science blogs can be challenging, and this blog post summarizes
        some of the important lessons learned. However, the experience is also encouraging,
        as collecting metadata does not have to be a frustrating and time-consuming
        experience. We have a number of complementary approaches at our disposal.
        Rogue Scholar is currently mostly processing RSS feeds and blog platform APIs,
        but we can also complement this approach with metadata from HTML meta tags
        and/or schema.org.</p><p>I am sure the last chapter of this story hasn't been
        written yet. At least two challenges remain: collecting metadata from blogs
        that are no longer active and only persist in archived form, and updating
        blog posts with registered DOIs that are written using static site generators
        hosted on platforms such as GitHub and GitLab. Twenty-five percent of Rogue
        Scholar blogs fall into the latter category and the solution probably involves
        some form of GitHub Action (or Gitlab CI/CD) that triggers a pull request.</p><h2
        id=\"references\">References</h2><p>Fenner, M., Crosas, M., Grethe, J. S.,
        Kennedy, D., Hermjakob, H., Rocca-Serra, P., Durand, G., Berjon, R., Karcher,
        S., Martone, M., &amp; Clark, T. (2019). A data citation roadmap for scholarly
        data repositories. <em>Scientific Data</em>, <em>6</em>(1), Article 1. <a
        href=\"https://doi.org/10.1038/s41597-019-0031-8\">https://doi.org/10.1038/s41597-019-0031-8</a></p><p>Fenner,
        M. (2023). <em>Starting to include references in DOI metadata for blog posts</em>.
        <a href=\"https://doi.org/10.53731/6mkrk-dzh02\">https://doi.org/10.53731/6mkrk-dzh02</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Use cases for science blogs: grant-funded
        projects ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/use-cases-for-science-blogs-grant-funded-projects/\"
        />\n\t\t<id>https://doi.org/10.53731/mh9a1-dw902</id>\n        <published>2023-09-25T13:23:07.000+00:00</published>\n\t\t<updated>2023-09-25T13:42:56.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://images.unsplash.com/photo-1517048676732-d65bc937f952?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDI3fHxwcm9qZWN0fGVufDB8fHx8MTY5NTY0MjU4MHww&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://images.unsplash.com/photo-1517048676732-d65bc937f952?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDI3fHxwcm9qZWN0fGVufDB8fHx8MTY5NTY0MjU4MHww&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"></p><p>The
        <a href=\"https://rogue-scholar.org\" rel=\"noreferrer\">Rogue Scholar science
        blog archive</a> is open to science blogs that want to be enhanced by adding
        long-term archiving, DOI registration, and full-text search. The currently
        56 participating blogs represent a broad spectrum of topics, people, and communities.
        Today I want to go into more detail into one particular Rogue Scholar use
        case: science blogs for grant-funded projects.</p>\n<p>Science blogs for grant-funded
        projects typically have the following features:</p>\n<ul><li>Science blogs
        are part of the outreach activities of many grant-funded projects.</li><li>They
        complement other project outputs that include publications, presentations,
        datasets, and software.</li><li>Funders want to see the impact these outputs,
        including the blog, have on relevant communities.</li><li>Grant-funded projects
        are a time-limited activity of typically 24-36 months, but the impact ideally
        continues to grow past the funding period.</li></ul>\n<p>From the above it
        becomes clear that grant-funded research that includes a blog as part of its
        outreach activities, has to think about two major issues:</p>\n<ul><li>How
        to track the impact of the science blog in ways that can inform the project
        team and the funder? </li><li>How do we maintain the content of the science
        blog beyond the funding period?</li></ul>\n<p>Rogue Scholar can help with
        this use case, and I have implemented this for Project THOR.</p>\n<h2 id=\"project-thor\">Project
        THOR</h2>\n<p>Project THOR \u2013 Technical and Human Infrastructure for Open
        Research is a research project funded by the the European Union\u2019s Horizon
        2020 research and innovation programme under&nbsp;<a href=\"https://doi.org/10.3030/654039\">grant
        agreement No 654039</a> that was carried out between June 2015 and November
        2019. It had nine participating organizations and was coordinated by the British
        Library. I joined DataCite in August 2015 as Technical Director and was deeply
        involved in THOR. The <a href=\"https://doi.org/10.59350/e346f-2jg53\" rel=\"noreferrer\">goals
        of the project </a>were</p>\n<blockquote>THOR will build on the services provided
        by ORCID and DataCite to ensure that every researcher, at any phase of their
        career, or at any institution, will have seamless and free access to Persistent
        Identifiers (PIDs) for their research artefacts and their work will be uniquely
        attributed to them.</blockquote>\n<p>The project started a <a href=\"https://project-thor.eu/\"
        rel=\"noreferrer\">blog</a> to report on project activities and project outputs
        and published 66 blog posts during the 30-month project duration. The public
        project outputs are available via <a href=\"https://zenodo.org\" rel=\"noreferrer\">Zenodo</a>
        and in various publications.</p>\n<p>Almost four years after the project ended,
        the blog is unfortunately no longer publicly accessible, and several key people
        involved in THOR have moved on to other projects, and organizations, or have
        retired. This is a typical story for grant-funded projects, but painful as
        THOR is about persistent identifiers and services. </p>\n<p>Fast-forward to
        September 2023 and the launch of Rogue Scholar, and we can now make these
        changes:</p>\n<ul><li><a href=\"https://rogue-scholar.org/blogs/thor\" rel=\"noreferrer\">Register
        the THOR blog with Rogue Scholar </a>and archive the full-text of all blog
        posts, available via search. A search for <a href=\"https://rogue-scholar.org/posts?page=1&amp;query=content+drift\"
        rel=\"noreferrer\">content drift</a> finds the blog post about the THOR final
        event where Herbert van de Sompel gave a keynote.</li><li>Register DOIs for
        all blog posts, with metadata that includes the abstract, authors (with ORCID
        ID), and funding information \u2013 the <a href=\"https://doi.org/10.3030/654039\"
        rel=\"noreferrer\">THOR grant</a>. This enables searching for outputs funded
        by THOR via Crossref or other services using Crossref and/or ORCID metadata</li><li>Have
        the DOIs point to archived versions of blog posts at the <a href=\"https://archive.org/\"
        rel=\"noreferrer\">Internet Archive</a>, enabling reading of the full text
        of all blog posts despite the blog no longer being publicly available.</li></ul>\n<figure
        class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2023/09/Bildschirmfoto-2023-09-25-um-14.52.11.png\"
        class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1920\" height=\"1262\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2023/09/Bildschirmfoto-2023-09-25-um-14.52.11.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/09/Bildschirmfoto-2023-09-25-um-14.52.11.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/09/Bildschirmfoto-2023-09-25-um-14.52.11.png
        1600w, https://blog.front-matter.io/content/images/2023/09/Bildschirmfoto-2023-09-25-um-14.52.11.png
        1920w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space:
        pre-wrap;\">Project THOR in </span><a href=\"https://rogue-scholar.org/blogs/thor\"
        rel=\"noreferrer\"><span style=\"white-space: pre-wrap;\">Rogue Scholar</span></a></figcaption></figure>\n<p>The
        ideal time to think about including the blog of a grant-funded science project
        in Rogue Scholar is of course at the start of the project and not four years
        after the project has ended. Please <a href=\"mailto:info@front-matter.io\"
        rel=\"noreferrer\">reach out to Rogue Scholar</a> if you manage a blog for
        a grant-funded science project. The costs for automatically archiving all
        posts, indexing them for full-text search, and registering DOIs are very reasonable
        (a $1 per blog post one-time fee), with additional optional fees if you want
        training and/or reporting.</p>\n<h2 id=\"references\">References</h2>\n<p>Brown,
        J. (2015). <em>The next step for open science: A state-of-the-art identifier
        network</em>. <a href=\"https://doi.org/10.59350/e346f-2jg53\">https://doi.org/10.59350/e346f-2jg53</a></p>\n<p>Fenner,
        M. (2015). <em>Thank you PLOS</em>. <a href=\"https://doi.org/10.53731/r294649-6f79289-8cvzn\">https://doi.org/10.53731/r294649-6f79289-8cvzn</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ DOI registration workflow for a science
        blog ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/doi-registration-workflow-science-blog/\"
        />\n\t\t<id>https://doi.org/10.53731/w6nzs-jta75</id>\n        <published>2023-09-22T13:15:45.000+00:00</published>\n\t\t<updated>2023-09-22T13:41:17.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://images.unsplash.com/photo-1595126731003-755959b6baf8?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDEyfHxyZWdpc3RyYXRpb258ZW58MHx8fHwxNjk1MzczNDkzfDA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://images.unsplash.com/photo-1595126731003-755959b6baf8?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDEyfHxyZWdpc3RyYXRpb258ZW58MHx8fHwxNjk1MzczNDkzfDA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"></p><p>In
        previous blog posts such as the one <a href=\"https://doi.org/10.53731/gvb08-7kc16\"
        rel=\"noreferrer\">published earlier this week</a>, I discussed the various
        elements involved in registering a DOI for a science blog post. Briefly, the
        <a href=\"https://rogue-scholar.org\" rel=\"noreferrer\">Rogue Scholar</a>
        service takes advantage of the fact that blogs </p>\n<ul><li>use RSS feeds
        (or the Atom or JSON Feed format) to distribute content and metadata at the
        time of publication, </li><li>these feeds contain the most important metadata
        needed for publication \u2013 such as title, authors, publication date, and
        </li><li>addition metadata (such as abstract and references) can be automatically
        extracted from the full-text content included in the feed.</li></ul>\n<p>This
        basic workflow can be optimized in many ways, for example including funding
        information (watch out for a blog post next week), but one fundamental issue
        remains to be solved: how does the blog learn about the DOI registered for
        a new post, and automatically adds it to the blog?</p>\n<h2 id=\"canonical-url\">Canonical
        URL</h2>\n<p>As much as possible Rogue Scholar takes advantage of technologies
        that have existed for a long time and are not specific to scholarly content.
        That's why the service works with existing blogs that use standard blogging
        software - currently <a href=\"https://rogue-scholar.org/#stats\" rel=\"noreferrer\">eleven
        different platforms</a>, the most popular being Wordpress, Ghost, and Hugo.</p>\n<p>These
        platforms don't know about DOIs without extra work, but they all know about
        a similar concept: <a href=\"https://developers.google.com/search/docs/crawling-indexing/canonicalization\"
        rel=\"noreferrer\">canonical URLs</a>. Wikipedia <a href=\"https://en.wikipedia.org/wiki/Canonical_link_element\"
        rel=\"noreferrer\">explains</a>:</p>\n<blockquote>A&nbsp;<strong>canonical
        link element</strong>&nbsp;is an&nbsp;HTML element&nbsp;that helps&nbsp;webmasters&nbsp;prevent&nbsp;duplicate
        content&nbsp;issues in&nbsp;search engine optimization&nbsp;by specifying
        the \"canonical\" or \"preferred\" version of a web page. It is described
        in RFC 6596, which went live in April 2012.</blockquote>\n<p>The problem canonical
        URLs are addressing is duplicate content at different locations that can confuse
        search engines such as Google or Bing. This is related to the problem persistent
        identifiers such as DOIs are addressing for the scholarly community: accessing
        content over long periods of time that may change its location on the web
        (its URL), with two inter-related strategies:</p>\n<ul><li><strong>URL redirection</strong>.
        DOIs <a href=\"https://doi.org/10.5281/zenodo.1324300\" rel=\"noreferrer\">redirect
        to a target URL</a> that can be changed by the publisher,</li><li><strong>Persistence</strong>.
        The publisher of scholarly content makes an extra effort to make sure content
        doesn't disappear (<a href=\"https://doi.org/10.1371/journal.pone.0115253\"
        rel=\"noreferrer\">link rot</a>), or significantly change (<a href=\"Deane-Pratt,
        A. (2017). THhttps://doi.org/10.59350/p000s-pth40\" rel=\"noreferrer\">content
        drift</a>).</li></ul>\n<p>Obviously, canonical URLs are not DOIs, but they
        provide a standard way for a science blog to add a DOI to a post.</p>\n<h2
        id=\"backends\">Backends</h2>\n<p>Science blogs provide a backend to store
        content and metadata, including the canonical URL. This can either be a database
        (as in the case of Wordpress or Ghost) or a file (as in the case of Hugo and
        many other <a href=\"https://jamstack.org/generators/\" rel=\"noreferrer\">static
        site generators</a>).</p>\n<h3 id=\"wordpress\">Wordpress</h3>\n<p>Wordpress
        doesn't know about canonical URLs out of the box, but they can be added via
        a plugin, the most popular for this being <a href=\"https://yoast.com/help/canonical-urls-in-yoast-seo/\"
        rel=\"noreferrer\">Yoast SEO</a> (which comes in free and paid versions).
        After installing and activating the plugin you can add a canonical URL in
        a new Yoast SEO section of the post editor:</p>\n<figure class=\"kg-card kg-image-card\"><img
        src=\"https://blog.front-matter.io/content/images/2023/09/Bildschirmfoto-2023-09-22-um-13.25.21.png\"
        class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1276\" height=\"444\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2023/09/Bildschirmfoto-2023-09-22-um-13.25.21.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/09/Bildschirmfoto-2023-09-22-um-13.25.21.png
        1000w, https://blog.front-matter.io/content/images/2023/09/Bildschirmfoto-2023-09-22-um-13.25.21.png
        1276w\" sizes=\"(min-width: 720px) 720px\"></figure>\n<p>Alternatively, you
        can <a href=\"https://redpishi.com/wordpress-tutorials/canonical-urls-in-wordpress/\"
        rel=\"noreferrer\">fiddle with your Wordpress configuration</a> to add a custom
        field for the canonical URL.</p>\n<h3 id=\"ghost\">Ghost</h3>\n<p>The Ghost
        blogging platform has a canonical URL field for every post, which you can
        access from the post settings sidebar:</p>\n<figure class=\"kg-card kg-image-card\"><img
        src=\"https://blog.front-matter.io/content/images/2023/09/Bildschirmfoto-2023-09-22-um-13.33.03.png\"
        class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1014\" height=\"544\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2023/09/Bildschirmfoto-2023-09-22-um-13.33.03.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/09/Bildschirmfoto-2023-09-22-um-13.33.03.png
        1000w, https://blog.front-matter.io/content/images/2023/09/Bildschirmfoto-2023-09-22-um-13.33.03.png
        1014w\" sizes=\"(min-width: 720px) 720px\"></figure>\n<h3 id=\"hugo\">Hugo</h3>\n<p>Hugo
        and other Open Source static site generators give you a lot of flexibility
        with metadata. If you add a <code>canonicalUrl</code> field to the blog post
        Front Matter, you can reuse it for the canonical URL (with some <a href=\"https://blog.concannon.tech/tech-talk/hugo-canonical-url/\"
        rel=\"noreferrer\">additional work</a>).</p>\n<p>The canonical URL or DOI
        is now stored with the blog post, but also exposed to web crawlers. The format
        is <code>&lt;link rel=\"canonical\" href=\"<a href=\"https://doi.org/10.53731/gvb08-7kc16\"
        rel=\"noreferrer noopener\"><code>https://doi.org/10.53731/gvb08-7kc16</code></a>\"&gt;</code>.</p>\n<h2
        id=\"frontends\">Frontends</h2>\n<p>To display the canonical URL aka DOI on
        your blog frontend, you have to modify your blog theme, the popular themes
        for Wordpress, Ghost, and Hugo don't really support displaying the canonical
        URL out of the box, as they are primarily intended for web crawlers and not
        humans.</p>\n<p>You should follow the <a href=\"https://doi.org/10.13003/5jchdy\"
        rel=\"noreferrer\">Crossref DOI display guidelines</a>, when thinking about
        how to display the DOI for your blog post, i.e. always be displayed as a clickable
        full URL link. Rogue Scholar displays DOIs like this: </p>\n<figure class=\"kg-card
        kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2023/09/Bildschirmfoto-2023-09-22-um-13.57.23.png\"
        class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1104\" height=\"228\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2023/09/Bildschirmfoto-2023-09-22-um-13.57.23.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/09/Bildschirmfoto-2023-09-22-um-13.57.23.png
        1000w, https://blog.front-matter.io/content/images/2023/09/Bildschirmfoto-2023-09-22-um-13.57.23.png
        1104w\" sizes=\"(min-width: 720px) 720px\"></figure>\n<p>This blog (using
        the Ghost platform) displays DOIs like this in a sidebar: </p>\n<figure class=\"kg-card
        kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2023/09/Bildschirmfoto-2023-09-22-um-13.59.54-1.png\"
        class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"460\" height=\"169\"></figure>\n<h2
        id=\"doi-registration-workflow\">DOI registration workflow</h2>\n<p>The changes
        to the backend and frontend explained above are good enough for occasional
        blog posts or to get started with Rogue Scholar. After a blog post is published,
        Rogue Scholar will register a DOI <a href=\"https://doi.org/10.53731/gvb08-7kc16\"
        rel=\"noreferrer\">within 30 minutes</a> and show that DOI on the <a href=\"https://rogue-scholar.org/blogs/andrewheiss\"
        rel=\"noreferrer\">website</a> or via <a href=\"https://rogue-scholar.org/api/blogs/tcw6w29\"
        rel=\"noreferrer\">API</a>. You can then copy/paste that DOI into your new
        canonical URL field. A simple improvement would be notifications of new DOI
        registrations by email, similar to what Crossref is sending to Front Matter
        as the Crossref member:</p>\n<pre><code class=\"language-xml\">&lt;?xml version=\"1.0\"
        encoding=\"UTF-8\"?&gt;\n&lt;doi_batch_diagnostic status=\"completed\" sp=\"ds5\"&gt;\n
        \  &lt;submission_id&gt;1590342900&lt;/submission_id&gt;\n   &lt;batch_id&gt;8a637b09-fda6-4980-baa1-147497683bd9&lt;/batch_id&gt;\n
        \  &lt;record_diagnostic status=\"Success\"&gt;\n      &lt;doi&gt;10.53731/w6nzs-jta75&lt;/doi&gt;\n
        \     &lt;msg&gt;Successfully added&lt;/msg&gt;\n      &lt;citations_diagnostic&gt;\n
        \        &lt;citation key=\"ref1\" status=\"resolved_reference\"&gt;10.53731/gvb08-7kc16&lt;/citation&gt;\n
        \        &lt;citation key=\"ref2\" status=\"resolved_reference\"&gt;Cite to
        nonCR doi: 10.5281/zenodo.1324300&lt;/citation&gt;\n         &lt;citation
        key=\"ref3\" status=\"resolved_reference\"&gt;10.1371/journal.pone.0115253&lt;/citation&gt;\n
        \        &lt;citation key=\"ref4\" status=\"resolved_reference\"&gt;10.59350/p000s-pth40&lt;/citation&gt;\n
        \        &lt;citation key=\"ref5\" status=\"resolved_reference\"&gt;10.53731/r79x921-97aq74v-ag5a2&lt;/citation&gt;\n
        \     &lt;/citations_diagnostic&gt;\n   &lt;/record_diagnostic&gt;\n   &lt;batch_data&gt;\n
        \     &lt;record_count&gt;1&lt;/record_count&gt;\n      &lt;success_count&gt;1&lt;/success_count&gt;\n
        \     &lt;warning_count&gt;0&lt;/warning_count&gt;\n      &lt;failure_count&gt;0&lt;/failure_count&gt;\n
        \  &lt;/batch_data&gt;\n&lt;/doi_batch_diagnostic&gt;</code></pre>\n<p>But
        maybe including a clickable link to the DOI just registered and some basic
        metadata that were registered (as it takes a few hours until the metadata
        show up in the Crossref REST API).</p>\n<p>For blogs with a more frequent
        publication frequency (e.g. weekly or daily) this workflow should be automated.
        One important consideration is whether the blog should know the DOI that will
        be registered in advance, avoiding the round trip with Rogue Scholar and Crossref,
        and allowing customizations of the DOI name, such as <code>10.53731/front-matter.2023-09-19</code>.
        The biggest advantage would be that the DOI name can be shared in advance
        of publication, e.g. for press releases, or to reference in other content.</p>\n<p>While
        these considerations are reasonable and not new for DOIs in general, for the
        science blog use case the workflow should be simple and I want to follow these
        principles:</p>\n<ul><li>Rogue Scholar DOIs will be generated as a short random
        10-character string upon DOI registration. Rogue Scholar users or staff can't
        modify the DOI names that will be generated. Rogue Scholar DOIs are <a href=\"10.53731/r79x921-97aq74v-ag5a2\"
        rel=\"noreferrer\">cool DOIs</a>.</li><li>If you see a Rogue Scholar DOI,
        it can be used (immediately as a link, accessing the metadata after a few
        hours). Rogue Scholar is not offering DOIs that are not or not fully registered,
        i.e. DOIs for <a href=\"https://www.crossref.org/documentation/research-nexus/pending-publication\"
        rel=\"noreferrer\">pending publications</a> (Crossref) or <a href=\"https://support.datacite.org/docs/doi-states\"
        rel=\"noreferrer\">draft DOIs</a> (DataCite).</li><li>DOI registration happens
        with the Rogue Scholar service talking to the Crossref API, participating
        blogs don't need to install or develop functionality to generate Crossref
        metadata and/or interact with the Crossref API.</li></ul>\n<p>The easiest
        architecture for automatically sending the registered DOI names back to the
        blog is using the blog API. I have this implemented for the blogs where Rogue
        Scholar has admin access to the blog API (this blog and two other blogs using
        the Ghost platform), and this updates the blog post immediately after DOI
        registration as part of the same GitHub Action. Most Rogue Scholar blogs have
        a write API, and in the case of static site generators, the underlying repository
        platform (typically GitHub or GitLab) has an API. If your blog is updated
        more than once a month and is hosted by Wordpress, Ghost, Hugo, or Jekyll,
        reach out to me if you want to participate in the DOI registration beta workflow.
        </p>\n<h2 id=\"references\">References</h2>\n<p>Fenner, M. (2023). <em>Streamlining
        the archiving of science blog posts</em>. <a href=\"https://doi.org/10.53731/gvb08-7kc16\">https://doi.org/10.53731/gvb08-7kc16</a></p>\n<p>Wimalaratne,
        S., &amp; Fenner, M. (2018). <em>D2.1 Pid Resolution Services Best Practices</em>.
        <a href=\"https://doi.org/10.5281/ZENODO.1324300\">https://doi.org/10.5281/ZENODO.1324300</a></p>\n<p>Klein,
        M., Sompel, H. V. de, Sanderson, R., Shankar, H., Balakireva, L., Zhou, K.,
        &amp; Tobin, R. (2014). Scholarly Context Not Found: One in Five Articles
        Suffers from Reference Rot. <em>PLOS ONE</em>, <em>9</em>(12), e115253. <a
        href=\"https://doi.org/10.1371/journal.pone.0115253\">https://doi.org/10.1371/journal.pone.0115253</a></p>\n<p>Deane-Pratt,
        A. (2017). <em>THOR\u2019s last hurrah</em>. <a href=\"https://doi.org/10.59350/p000s-pth40\">https://doi.org/10.59350/p000s-pth40</a></p>\n<p>Fenner,
        M. (2016). <em>Cool DOIs</em>. <a href=\"https://doi.org/10.53731/r79x921-97aq74v-ag5a2\">https://doi.org/10.53731/r79x921-97aq74v-ag5a2</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Streamlining the archiving of science blog
        posts ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/streamlining/\"
        />\n\t\t<id>https://doi.org/10.53731/gvb08-7kc16</id>\n        <published>2023-09-19T08:26:31.000+00:00</published>\n\t\t<updated>2023-09-19T08:35:56.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://images.unsplash.com/photo-1476725994324-6f6833ea0631?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDM1fHxmYXN0fGVufDB8fHx8MTY5NTEwNjkzN3ww&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://images.unsplash.com/photo-1476725994324-6f6833ea0631?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDM1fHxmYXN0fGVufDB8fHx8MTY5NTEwNjkzN3ww&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"></p><p>The
        <a href=\"https://rogue-scholar.org\" rel=\"noreferrer\">Rogue Scholar science
        blog</a> archive is adding important functionality to existing science blogs.
        The first step after a blog has signed up with Rogue Scholar is archiving
        the content. This is not only needed for long-term preservation but also enables
        full-text search and DOI registration with meaningful metadata. Rogue Scholar
        uses the blog feed (in RSS, Atom, or JSON Feed format) for this, which is
        updated the moment a blog post is published or updated. </p>\n<p>The elegant
        approach would be to notify Rogue Scholar when this happens so that Rogue
        Scholar can fetch the updated content, using a technology called <a href=\"https://en.wikipedia.org/wiki/Webhook\"
        rel=\"noreferrer\">webhooks</a>. But one important principle of Rogue Scholar
        is simplicity, not requiring any additional technical work for the participating
        blogs unless absolutely necessary. This means that at least for the time being
        regular checks of the blog feed are more appropriate for Rogue Scholar, and
        with a small update yesterday this workflow has been greatly improved. </p>\n<p>Rogue
        Scholar now checks all participating blogs for new or updated content every
        10 minutes. When new or updated content is found, it is processed and stored
        in the Rogue Scholar Postgres database within a minute. This in turn triggers
        an update of full-text search index running in <a href=\"https://typesense.org/\"
        rel=\"noreferrer\">Typesense</a> which takes another minute. Rogue Scholar
        checks every 10 minutes whether a blog post is new or the metadata used for
        DOI registration have changed and triggers a DOI update. DOI registration
        consists of two parts:</p>\n<ul><li>Registration of the DOI and URL in the
        DOI resolution service, so that <a href=\"https://doi.org/10.53731/xszpd-6z265\">https://doi.org/10.53731/xszpd-6z265</a>
        redirects to <a href=\"https://blog.front-matter.io/posts/releasing-commonmeta-py-v0-8/\">https://blog.front-matter.io/posts/releasing-commonmeta-py-v0-8/</a>.
        This happens within a few minutes.</li><li>Registration of DOI metadata, so
        that blog post metadata can be found via Crossref services. This happens within
        a few hours.</li></ul>\n<p>While writing this blog post, I got two emails
        from Crossref telling me about new content registered with Crossref. There
        were two blog posts by Rogue Scholar blogs this morning published 4 and 11
        minutes before the DOIs were successfully registered, compared to the delay
        of several hours (and in a few cases even longer) before this update.</p>\n<p>With
        this new workflow in place, another bottleneck now becomes more visible. Rogue
        Scholar and Crossref (and all the services that use Crossref metadata) now
        know about the DOIs registered for blog posts, but how do the participating
        blogs learn about this? For the special case where the blog has an API and
        Rogue Scholar is allowed to write to it (currently this blog and the <a href=\"https://upstream.force11.org\"
        rel=\"noreferrer\">Upstream</a> blog, which both use the Ghost blogging platform),
        this happens automatically as part of the DOI registration GitHub Action.
        </p>\n<p>For all other blogs participating in Rogue Scholar that is still
        something I have to figure out, and the main challenge is again to come up
        with a workflow that doesn't require major technical work for the participating
        blogs. One strategy would be to come up with solutions for the individual
        blogging platforms, starting with Wordpress which is used by <a href=\"https://rogue-scholar.org/#stats\"
        rel=\"noreferrer\">42% of Rogue Scholar blogs</a>. Obviously, a solution for
        this issue is more important for blogs that are updated frequently than blogs
        that are updated only a few times per month. Stay tuned.</p>\n<h2 id=\"references\">References</h2>\n<p>Fenner,
        M. (2023). <em>Releasing commonmeta-py v0.8</em>. <a href=\"https://doi.org/10.53731/xszpd-6z265\">https://doi.org/10.53731/xszpd-6z265</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Releasing commonmeta-py v0.8 ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/releasing-commonmeta-py-v0-8/\"
        />\n\t\t<id>https://doi.org/10.53731/xszpd-6z265</id>\n        <published>2023-09-12T17:31:18.000+00:00</published>\n\t\t<updated>2023-09-12T17:43:03.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://images.unsplash.com/photo-1589794094880-be5a4daf3e11?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDN8fGNvbW1vbnxlbnwwfHx8fDE2OTQ1MzMxNDB8MA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://images.unsplash.com/photo-1589794094880-be5a4daf3e11?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDN8fGNvbW1vbnxlbnwwfHx8fDE2OTQ1MzMxNDB8MA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"></p><p>Today
        I am happy to announce the release of <a href=\"https://pypi.org/project/commonmeta-py/\">commonmeta-py
        v0.8</a>, the next major release of the Python scholarly metadata conversion
        library. There are numerous changes in this release compared to v0.7.1 released
        in March, in particular:</p>\n<ul><li>Added support for metadata conversions
        from the <a href=\"https://www.jsonfeed.org/\" rel=\"noreferrer\">JSON Feed</a>
        and <a href=\"https://inveniordm.docs.cern.ch/reference/metadata/\" rel=\"noreferrer\">InvenioRDM</a>
        formats.</li><li>Updated commonmeta JSON schema to v.10.1. The biggest changes
        are added support for file metadata and contributor roles.</li><li>Many bug
        fixes and small improvements.</li></ul>\n<h2 id=\"json-feed\">JSON Feed</h2>\n<p><a
        href=\"https://www.jsonfeed.org/\" rel=\"noreferrer\">JSON Feed</a> is a syndication
        format for blogs and other periodical content and uses JSON instead of XML
        serialization used by the RSS and Atom formats. The <a href=\"https://rogue-scholar.org\"
        rel=\"noreferrer\">Rogue Scholar blog archive</a> that I started earlier this
        year makes heavy use of JSON Feed and uses it to convert blog post metadata
        to Crossref XML and then register DOIs for them. For the about 5,000 DOIs
        for blog posts that I have registered so far, I used <a href=\"https://github.com/features/actions\"
        rel=\"noreferrer\">GitHub Actions</a> and the <a href=\"https://doi.org/10.5281/ZENODO.7752775\"
        rel=\"noreferrer\">commonmeta-ruby</a> library. As the number of blog posts
        registered every day is constantly increasing, I need to refactor the Rogue
        Scholar backend to properly handle that, and I decided to build a dedicated
        Python API to replace the GitHub Actions workflow. This work will start in
        October, and adding JSON Feed support to commonmeta-py is an important step.</p>\n<h2
        id=\"files-metadata\">Files metadata</h2>\n<p>One big addition in commonmeta
        v0.10, and supported in the new release of commonmeta-py, is metadata for
        content associated with a scholarly resource. In the simplest case, this is
        a direct download link to a publication or software, but it can also mean
        download links to multiple files each with file size, file type, and checksum.
        The best implementation is currently the new InvenioRDM commonmeta-py format,
        but files metadata are also supported in the schema.org format, and partially
        in DataCite and Crossref formats. Files metadata are particularly important
        for automated machine access to content, whereas human users are typically
        first directed to a landing page with links to download content. To properly
        use this functionality, the content should be available with an open license
        such as <a href=\"mmons.org/licenses/by/4.0/\" rel=\"noreferrer\">CC-BY</a>,
        <a href=\"https://opensource.org/license/mit/\" rel=\"noreferrer\">MIT</a>,
        or <a href=\"https://creativecommons.org/share-your-work/public-domain/cc0/\"
        rel=\"noreferrer\">CC Zero</a> \u2013 licenses have been supported in commonmeta
        since the first release.</p>\n<h2 id=\"contributor-roles\">Contributor roles</h2>\n<p>Authorship
        of scholarly content has become more complex over the years, with many publications
        typically requiring multiple authors, often with dedicated roles. The Contributor
        Roles Taxonomy (CRediT), now <a href=\"https://credit.niso.org/\" rel=\"noreferrer\">hosted
        by NISO</a>, was started 10 years ago to address this complexity and has been
        adopted by an increasing number of publishers. One remaining problem is that
        CRediT was developed for text publications and has limited support for other
        publication types, e.g. datasets or software. Another problem is the different
        terminologies used. ORCID use <strong>contributor</strong> and has <a href=\"https://info.orcid.org/credit-for-research-contribution/\"
        rel=\"noreferrer\">added support for CRediT</a> in 2021. Crossref uses <strong>contributor</strong>
        and has <a href=\"https://www.crossref.org/documentation/schema-library/markup-guide-metadata-segments/contributors/\"
        rel=\"noreferrer\">defined different contributor roles</a> that are different
        from CRediT. DataCite (based on work in <a href=\"https://www.dublincore.org/specifications/dublin-core/dcmi-terms/elements11/contributor/\"
        rel=\"noreferrer\">Dublin Core</a>) uses the <a href=\"https://doi.org/10.14454/3W3Z-SA82\"
        rel=\"noreferrer\">concepts of <strong>creator</strong> and <strong>contributor</strong></a>,
        where creators are <em>the main researchers involved in producing the data,
        or the authors of the publication</em> whereas a contributor is <em>the institution
        or person responsible for collecting, managing, distributing, or otherwise
        contributing to the development of the resource. </em></p>\n<p>A complex problem,
        but one important step forward would be to align these different taxonomies
        in commonmeta. Commonmeta v0.10 has therefore dropped the <strong>creator</strong>
        property in favor of <strong>contributor</strong>, added support for contributor
        roles from CRediT, Crossref, and DataCite, and added support for multiple
        contributor roles. The various metadata formats supported in commonmeta implementations
        such as <em>commonmeta-py</em> can then use a subset of these contributor
        roles. An example would be the <strong>editor</strong> role which is used
        in Crossref, DataCite, BibTeX, schema.org, and citation style language (CSL)
        metadata. Going forward commonmeta can consolidate these roles and add new
        roles needed for particular use cases and metadata formats, e.g. the <strong>maintainer</strong>
        role for software used by codemeta.</p>\n<h2 id=\"references\">References</h2>\n<p>Fenner,
        Martin. (2023). <em>Commonmeta-ruby</em> (v3.0.1) [Computer software]. Zenodo.
        <a href=\"https://doi.org/10.5281/ZENODO.7752775\">https://doi.org/10.5281/ZENODO.7752775</a></p>\n<p>Fenner,
        M. (2021). <em>First InvenioRDM Long-Term Support (LTS) version released today\u202F
        and Front Matter is joining as a participating partner</em>. <a href=\"https://doi.org/10.53731/r8c26t1-97aq74v-ag66m\">https://doi.org/10.53731/r8c26t1-97aq74v-ag66m</a></p>\n<p>Allen,
        L., Scott, J., Brand, A., Hlava, M., &amp; Altman, M. (2014). Publishing:
        Credit where credit is due. <em>Nature</em>, <em>508</em>(7496), 312\u2013313.
        <a href=\"https://doi.org/10.1038/508312a\">https://doi.org/10.1038/508312a</a></p>\n<p>Hosseini,
        M., Kerridge, S., Allen, L., Kiermer, V., &amp; Holmes, K. L. (2023). <em>Enhancing
        Understanding and Adoption of the Contributor Roles Taxonomy (CRediT)</em>.
        <a href=\"https://doi.org/10.31222/osf.io/n6249\">https://doi.org/10.31222/osf.io/n6249</a></p>\n<p>DataCite
        Metadata Working Group. (2021). <em>DataCite Metadata Schema Documentation
        for the Publication and Citation of Research Data and Other Research Outputs
        v4.4</em>. 82 pages. <a href=\"https://doi.org/10.14454/3W3Z-SA82\">https://doi.org/10.14454/3W3Z-SA82</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ New in Rogue Scholar: filter posts by language
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/filter-posts-by-language/\"
        />\n\t\t<id>https://doi.org/10.53731/ggtnh-1as93</id>\n        <published>2023-09-04T13:42:47.000+00:00</published>\n\t\t<updated>2023-09-04T13:48:20.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://images.unsplash.com/photo-1601520525445-1039c1fa232b?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDh8fGxhbmd1YWdlfGVufDB8fHx8MTY5MzgzMjMwOXww&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://images.unsplash.com/photo-1601520525445-1039c1fa232b?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDh8fGxhbmd1YWdlfGVufDB8fHx8MTY5MzgzMjMwOXww&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"></p><p>The
        <a href=\"https://rogue-scholar.org\" rel=\"noreferrer\">Rogue Scholar science
        blog archive</a> received a small update today with the following changes:
        optionally filter blog posts by language, added support for all OECD fields
        of science and technology, and searching by DOI. And it passed another big
        milestone: more than 5,000 (<a href=\"https://rogue-scholar.org/de/posts\"
        rel=\"noreferrer\">5,483</a> today) blog posts are now archived.</p>\n<h3
        id=\"filter-blog-posts-by-language\">Filter blog posts by language</h3>\n<p>Rogue
        Scholar supports science blog posts in any language and the user interface
        supports English, Spanish, German, French, Portuguese, and Italian. Ninety
        percent of the archived blog posts are in English, the rest in German or Spanish.
        With the new filter you can limit search results to your preferred language,
        e.g. German:</p>\n<figure class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2023/09/Bildschirmfoto-2023-09-04-um-15.10.17.png\"
        class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1904\" height=\"914\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2023/09/Bildschirmfoto-2023-09-04-um-15.10.17.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/09/Bildschirmfoto-2023-09-04-um-15.10.17.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/09/Bildschirmfoto-2023-09-04-um-15.10.17.png
        1600w, https://blog.front-matter.io/content/images/2023/09/Bildschirmfoto-2023-09-04-um-15.10.17.png
        1904w\" sizes=\"(min-width: 720px) 720px\"></figure>\n<p>This new feature
        hopefully makes it easier to find content in languages other than English
        and encourages more non-English science blogs to join Rogue Scholar.</p>\n<h3
        id=\"support-for-all-oecd-fields\">Support for all OECD fields</h3>\n<p>Subject
        area classification is one important way to find interesting blogs and blog
        posts. Rogue Scholar started out with the six top-level categories of the
        widely used <a href=\"https://www.oecd.org/science/inno/38235147.pdf\" rel=\"noreferrer\">OECD
        Fields of Science and Technology</a>. This week I am adding all 43 second-level
        categories for a little bit more fine-grained detail. This makes it possible
        to identify two blogs included in the Rogue Scholar as chemistry blogs and
        two other blogs as writing about languages and literature.</p>\n<figure class=\"kg-card
        kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2023/09/Bildschirmfoto-2023-09-04-um-15.28.10.png\"
        class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"557\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2023/09/Bildschirmfoto-2023-09-04-um-15.28.10.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/09/Bildschirmfoto-2023-09-04-um-15.28.10.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/09/Bildschirmfoto-2023-09-04-um-15.28.10.png
        1600w, https://blog.front-matter.io/content/images/size/w2400/2023/09/Bildschirmfoto-2023-09-04-um-15.28.10.png
        2400w\" sizes=\"(min-width: 720px) 720px\"></figure>\n<p>This is the first
        iteration of improved OECD fields of science support. Not all categories are
        already translated into all six supported languages, and the classification
        into a specific category is sometimes not easy. If you are responsible for
        a blog on Rogue Scholar, you can change the subject category in your admin
        dashboard. Future versions of this functionality will support multiple fields
        of science per blog, and support the (automated) classification of individual
        posts using machine learning.</p>\n<h3 id=\"searching-by-doi\">Searching by
        DOI</h3>\n<p>The full-text index was updated to support searching by DOI,
        either as identifier for a blog post or in the references. Searching for the
        Force11 Software Citation Principles (<a href=\"https://doi.org/10.7717/peerj-cs.86\"
        rel=\"noreferrer\">10.7717/peerj-cs.86</a>) for example returns 14 results
        from six different blogs:</p>\n<figure class=\"kg-card kg-image-card\"><img
        src=\"https://blog.front-matter.io/content/images/2023/09/Bildschirmfoto-2023-09-04-um-15.30.49.png\"
        class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1936\" height=\"1344\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2023/09/Bildschirmfoto-2023-09-04-um-15.30.49.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/09/Bildschirmfoto-2023-09-04-um-15.30.49.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/09/Bildschirmfoto-2023-09-04-um-15.30.49.png
        1600w, https://blog.front-matter.io/content/images/2023/09/Bildschirmfoto-2023-09-04-um-15.30.49.png
        1936w\" sizes=\"(min-width: 720px) 720px\"></figure>\n<p>This functionality
        will be further enhanced in the future by integrating with the Crossref <a
        href=\"https://www.crossref.org/services/cited-by/\" rel=\"noreferrer\">Cited-By</a>
        service to find citations of Rogue Scholar blog posts elsewhere.</p>\n<h3
        id=\"references\">References</h3>\n<p>Smith, A. M., Katz, D. S., Niemeyer,
        K. E., &amp; FORCE11 Software Citation Working Group. (2016). Software citation
        principles. <em>PeerJ Computer Science</em>, <em>2</em>, e86. <a href=\"https://doi.org/10.7717/peerj-cs.86\">https://doi.org/10.7717/peerj-cs.86</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Rogue Scholar is growing ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/rogue-scholar-is-growing/\" />\n\t\t<id>https://doi.org/10.53731/hv15p-dx796</id>\n
        \       <published>2023-08-28T11:05:16.000+00:00</published>\n\t\t<updated>2023-08-28T15:53:06.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://images.unsplash.com/photo-1590415024718-798cdaab96dd?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDJ8fGdyb3d8ZW58MHx8fHwxNjkzMjExNzkwfDA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://images.unsplash.com/photo-1590415024718-798cdaab96dd?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDJ8fGdyb3d8ZW58MHx8fHwxNjkzMjExNzkwfDA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"></p><p>The
        <a href=\"https://rogue-scholar.org/\">Rogue Scholar science blog archive</a>
        continues to grow. It is closing in on 50 science blogs (currently <a href=\"https://rogue-scholar.org/blogs\">45</a>),
        3,000 blog posts (currently <a href=\"https://rogue-scholar.org/posts\">2,944</a>,
        of which <a href=\"https://api.crossref.org/members/31795/works\">2,775</a>
        have a DOI), and 250 (currently <a href=\"https://api.crossref.org/members/31795/works?filter=has-references:true\">212</a>)
        blog posts with references registered with Crossref. I have set up eleven
        Mastodon bots for Rogue Scholar blogs after <a href=\"https://doi.org/10.53731/f1mhr-wps22\">announcing
        the feature</a> last week. We have achieved 32% of our funding goal to pay
        for the archiving of all current Rogue Scholar blog posts.</p>\n<figure class=\"kg-card
        kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-28-um-10.49.56.png\"
        class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"423\" height=\"290\"></figure>\n<p>Also
        last week, Rogue Scholar added the first <a href=\"https://rogue-scholar.org/blogs/norbisley\">Spanish-language
        blog</a> and the first two blogs covering Chemistry (<a href=\"https://rogue-scholar.org/blogs/cwagen\">here</a>
        and <a href=\"https://rogue-scholar.org/blogs/rzepa\">here</a>). </p>\n<h3
        id=\"whats-next\">What's next?</h3>\n<p>We have done some preliminary work
        to explore the feasibility of storing blog posts as <a href=\"https://en.wikipedia.org/wiki/EPUB\">ePub</a>
        files. This is particularly interesting since <a href=\"https://forums.zotero.org/discussion/106716/available-for-beta-testing-updated-reader-with-epub-snapshot-support-and-new-annotation-types\">version
        7 of the Zotero reference manager</a> will support storing ePub files next
        to metadata, and already integrates nicely with Rogue Scholar: </p>\n<figure
        class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-28-um-12.28.10.png\"
        class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1910\" height=\"1050\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2023/08/Bildschirmfoto-2023-08-28-um-12.28.10.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/08/Bildschirmfoto-2023-08-28-um-12.28.10.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/08/Bildschirmfoto-2023-08-28-um-12.28.10.png
        1600w, https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-28-um-12.28.10.png
        1910w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span>Zotero picks
        up references from a </span><a href=\"https://rogue-scholar.org/posts?page=1&amp;query=open+access\"
        rel=\"noreferrer\"><span>Rogue Scholar search</span></a><span>.</span></figcaption></figure>\n<p>The
        preliminary work on ePub looks good but requires a major architectural change
        in the backend, which is planned for October.</p>\n<p>Last week Rogue Scholar
        started launching Mastodon bots for the participating science blogs. This
        service is opt-in, i.e. the blog has to give Rogue Scholar permission to launch
        the bot and announce new blog posts (<a href=\"mailto:info@front-matter.io\">via
        email</a> is the easiest way). The information about the blog provided in
        Mastodon is exactly the same as on the <a href=\"https://rogue-scholar.org/blogs\">Rogue
        Scholar blogs</a> page.</p>\n<figure class=\"kg-card kg-image-card\"><img
        src=\"https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-28-um-12.33.18.png\"
        class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"980\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2023/08/Bildschirmfoto-2023-08-28-um-12.33.18.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/08/Bildschirmfoto-2023-08-28-um-12.33.18.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/08/Bildschirmfoto-2023-08-28-um-12.33.18.png
        1600w, https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-28-um-12.33.18.png
        2344w\" sizes=\"(min-width: 720px) 720px\"></figure>\n<p>The information posted
        to the Fediverse by the bot when a new blog post is published is again very
        similar to what you see on the <a href=\"https://rogue-scholar.org/posts\">Rogue
        Scholar posts</a> page but allows direct interactions, e.g. like, boost, bookmark,
        or comment.</p>\n<figure class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-28-um-12.44.08.png\"
        class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1182\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2023/08/Bildschirmfoto-2023-08-28-um-12.44.08.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/08/Bildschirmfoto-2023-08-28-um-12.44.08.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/08/Bildschirmfoto-2023-08-28-um-12.44.08.png
        1600w, https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-28-um-12.44.08.png
        2006w\" sizes=\"(min-width: 720px) 720px\"></figure>\n<p>The Mastodon version
        4.2.0 release planned for September enables searching of all public posts,
        and I will work on proper support for searching for the DOI of the blog post.</p>\n<h3
        id=\"what-you-can-do-with-the-rogue-scholar\">What you can do with the Rogue
        Scholar</h3>\n<ul><li>If you write for a blog that you want to be included
        in the Rogue Scholar, sign up <a href=\"https://rogue-scholar.org/auth/signin\">here</a>.</li><li>If
        you like to read content via the Rogue Scholar, search for posts <a href=\"https://rogue-scholar.org/posts\">here</a>,
        follow one or more of the blogs via Mastodon <a href=\"https://rogue-scholar.social/directory\">here</a>,
        or follow the RSS/Atom feeds of participating blogs <a href=\"https://rogue-scholar.org/blogs\">here</a></li><li>If
        you want to support Rogue Scholar financially, donate <a href=\"https://ko-fi.com/rogue_scholar\">here</a>.</li><li>If
        you want to learn more about the Rogue Scholar, reach out to me via <a href=\"mailto:info@front-matter.io\">email</a>,
        <a href=\"https://hachyderm.io/@mfenner\">Mastodon</a>, or <a href=\"https://discord.gg/HvbD4dNPFh\">Discord</a>.</li></ul>\n<h3
        id=\"references\">References</h3>\n<p>Fenner, M. (2023). <em>Rogue Scholar
        joins the Fediverse</em>. <a href=\"https://doi.org/10.53731/f1mhr-wps22\">https://doi.org/10.53731/f1mhr-wps22</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Rogue Scholar joins the Fediverse ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/rogue-scholar-joins-fediverse/\"
        />\n\t\t<id>https://doi.org/10.53731/f1mhr-wps22</id>\n        <published>2023-08-21T10:05:02.000+00:00</published>\n\t\t<updated>2023-08-21T11:21:06.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://images.unsplash.com/photo-1582213782179-e0d53f98f2ca?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDF8fGpvaW58ZW58MHx8fHwxNjkyNjAxNTA1fDA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://images.unsplash.com/photo-1582213782179-e0d53f98f2ca?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDF8fGpvaW58ZW58MHx8fHwxNjkyNjAxNTA1fDA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"></p><p>Today
        I am happy to announce that the Rogue Scholar science blog archive has joined
        the <a href=\"https://en.wikipedia.org/wiki/Fediverse\">Fediverse</a>, the
        federated social network that communicates using the&nbsp;<a href=\"https://en.wikipedia.org/wiki/ActivityPub\">ActivityPub</a>&nbsp;protocol.
        I have launched a Mastodon instance at <a href=\" https://rogue-scholar.social\">Rogue
        Scholar Social</a> that accepts Science Blog bots as accounts, publishing
        summaries of blog posts.</p>\n<figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-21-um-09.25.37.png\"
        class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1289\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2023/08/Bildschirmfoto-2023-08-21-um-09.25.37.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/08/Bildschirmfoto-2023-08-21-um-09.25.37.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/08/Bildschirmfoto-2023-08-21-um-09.25.37.png
        1600w, https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-21-um-09.25.37.png
        2392w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span>Local live feed
        at </span><a href=\"https://rogue-scholar.social/public/local\" rel=\"noreferrer\"><span>https://rogue-scholar.social/public/local</span></a></figcaption></figure>\n<p>Science
        blogs are typically read by going to the blog homepage with a web browser
        or using an RSS reader. More recently, newsletters have also become popular.
        These three approaches (web, feed reader, and email) combine discovery and
        reading of content in different ways. The discovery part can be augmented
        by social media, and Twitter has played a central role in this for more than
        10 years. Unfortunately, Twitter (as we knew it) no longer exists, and we
        have to use other social media channels to discover interesting scholarly
        content.</p>\n<p>In the past nine months, <a href=\"https://mastodon.social\">Mastodon</a>,
        has emerged as <a href=\"https://doi.org/10.1038/d41586-023-02554-0\">the
        most popular alternative to Twitter for scientists</a>. It is fundamentally
        different from Twitter, and other popular social media providers. It is based
        on a federated architecture (using the <a href=\"https://en.wikipedia.org/wiki/ActivityPub\">ActivityPub</a>
        protocol) and uses Open Source software (<a href=\"https://github.com/mastodon/mastodon\">available
        on GitHub</a>) so that everybody can install their own instance of Mastodon
        (<a href=\"https://github.com/BasixKOR/awesome-activitypub\">or other software
        using the ActivityPub protocol</a>). This flexibility and openness make using
        Mastodon harder to use but easier to customize to the needs of a science blog
        reader.</p>\n<p>The Rogue Scholar Mastodon instance is different from most
        other Mastodon instances in that it is not open for new users to join. It
        doesn't have personal accounts, only bots for blogs that participate in the
        Rogue Scholar science blog archive. To create a Mastodon account for your
        blog, open your blog configuration in the Rogue Scholar dashboard (login via
        the sign in link on the <a href=\"https://rogue-scholar.org/\">Rogue Scholar
        homepage</a>) and enter a unique name (only lowercase letters and underscore
        are allowed). Account creation and posting messages for new blog posts are
        not automated yet, but there is nothing else for blog authors to do. </p>\n<figure
        class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-21-um-09.59.49.png\"
        class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1230\" height=\"1438\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2023/08/Bildschirmfoto-2023-08-21-um-09.59.49.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/08/Bildschirmfoto-2023-08-21-um-09.59.49.png
        1000w, https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-21-um-09.59.49.png
        1230w\" sizes=\"(min-width: 720px) 720px\"></figure>\n<p>As a science blog
        reader, go to the Rogue Scholar Mastodon instance profiles directory and subscribe
        to one or more science blogs participating in the Rogue Scholar Mastodon service.</p>\n<figure
        class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-21-um-11.30.16.png\"
        class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"925\" height=\"839\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2023/08/Bildschirmfoto-2023-08-21-um-11.30.16.png
        600w, https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-21-um-11.30.16.png
        925w\" sizes=\"(min-width: 720px) 720px\"></figure>\n<p>Depending on your
        Mastodon client (here I use <a href=\"https://tapbots.com/ivory/mac/\">Ivory</a>
        for Mac) you see a summary of the latest blog post in your feed. Clicking
        on the link (the DOI) leads you to the full-text post, but you can also like,
        share or boost the blog post, or post a comment.</p>\n<figure class=\"kg-card
        kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-21-um-11.36.39-1.png\"
        class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1048\" height=\"531\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2023/08/Bildschirmfoto-2023-08-21-um-11.36.39-1.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/08/Bildschirmfoto-2023-08-21-um-11.36.39-1.png
        1000w, https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-21-um-11.36.39-1.png
        1048w\" sizes=\"(min-width: 720px) 720px\"></figure>\n<p>If you have problems
        configuring Mastodon for your blog in Rogue Scholar, or following a Rogue
        Scholar blog via Mastodon, <a href=\"mailto:info@front-matter.io\">send an
        email</a> or <a href=\"https://hachyderm.io/@mfenner\">ping me on Mastodon</a>.</p>\n<p>The
        next steps in the next few weeks are:</p>\n<ul><li>Refine the Rogue Scholar
        / Mastodon integration, including automation</li><li>Look into features currently
        missing but important for science blogs such as integration with full-text
        search and support for more metadata. The Rogue Scholar Mastodon instance
        is running the latest beta version of Mastodon (<a href=\"https://github.com/mastodon/mastodon/releases/tag/v4.2.0-beta1\">v4.2.0-beta1</a>),
        which displays more information in the preview card (blog name, publication
        date, and beginning of description):</li></ul>\n<figure class=\"kg-card kg-image-card\"><img
        src=\"https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-21-um-12.01.34.png\"
        class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"573\" height=\"631\"></figure>\n<h3
        id=\"references\">References</h3>\n<p>Vidal Valero, M. (2023). Thousands of
        scientists are cutting back on Twitter, seeding angst and uncertainty. <em>Nature</em>,
        <em>620</em>(7974), 482\u2013484. <a href=\"https://doi.org/10.1038/d41586-023-02554-0\">https://doi.org/10.1038/d41586-023-02554-0</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ New Rogue Scholar milestone and funding
        drive ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/new-rogue-scholar-milestone-and/\"
        />\n\t\t<id>https://doi.org/10.53731/gqvhe-je521</id>\n        <published>2023-08-15T12:20:29.000+00:00</published>\n\t\t<updated>2023-08-15T17:24:37.000+00:00</updated>\n
        \       <media:content url=\"https://images.unsplash.com/photo-1571334374861-5e51ddfc58ce?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDJ8fG1pbGVzdG9uZXxlbnwwfHx8fDE2OTIxMDA2ODB8MA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://images.unsplash.com/photo-1571334374861-5e51ddfc58ce?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDJ8fG1pbGVzdG9uZXxlbnwwfHx8fDE2OTIxMDA2ODB8MA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"></p><p>This
        week the Rogue Scholar science blog archive reached another big milestone:
        2,000 blog posts archived (2,242 as of today). This was achieved by adding
        new blogs (now 39) but, more importantly, by archiving older posts from the
        participating blogs. Twenty-one of the 39 science blogs now have all their
        posts archived at the Rogue Scholar, are included in the full-text search,
        and have (with two exceptions) DOIs and metadata registered for them. This
        was only possible via the financial contributions that Rogue Scholar received
        last week when I launched the new <a href=\"https://doi.org/10.53731/c09py-3we11\">financial
        support options</a>. Thank you Rogue Scholar supporters!</p>\n<p>Reaching
        one milestone of course means setting up a new goal for the Rogue Scholar:
        5,000 posts from 50 science blogs. A big part of that is archiving all (about
        1,500) posts from the participating blogs not yet included in Rogue Scholar.
        This costs money (paying for database and file hosting, DOI registration,
        and development work needed), and many blogs included in Rogue Scholar are
        personal blogs and can't pay the $1 per post one-time fee that Rogue Scholar
        is charging (beyond 50 free posts per year) to support the Rogue Scholar infrastructure.
        I am therefore asking everyone who wants to support Rogue Scholar (as a blog
        author as well as a reader) for as little as $3 (the price of a coffee), to
        use the <a href=\"https://ko-fi.com/rogue_scholar\">Buy me a coffee</a> link
        in the Rogue Scholar menu bar, and contribute. All donations count towards
        a goal of $1500 and progress can be tracked on the <a href=\"https://ko-fi.com/rogue_scholar\">KO-fi
        Buy me a coffee page</a>:</p>\n<figure class=\"kg-card kg-image-card\"><img
        src=\"https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-15-um-14.12.57.png\"
        class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"872\" height=\"594\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2023/08/Bildschirmfoto-2023-08-15-um-14.12.57.png
        600w, https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-15-um-14.12.57.png
        872w\" sizes=\"(min-width: 720px) 720px\"></figure>\n<h3 id=\"references\">References</h3>\n<p>Fenner,
        M. (2023). <em>How to support Rogue Scholar?</em> <a href=\"https://doi.org/10.53731/c09py-3we11\">https://doi.org/10.53731/c09py-3we11</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ How to support Rogue Scholar? ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/how-to-support-rogue-scholar/\"
        />\n\t\t<id>https://doi.org/10.53731/c09py-3we11</id>\n        <published>2023-08-07T11:40:36.000+00:00</published>\n\t\t<updated>2023-08-07T13:34:57.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://images.unsplash.com/photo-1579621970588-a35d0e7ab9b6?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDU5fHxmaW5hbmNpYWwlMjBzdXBwb3J0fGVufDB8fHx8MTY5MTQwNzI5NHww&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://images.unsplash.com/photo-1579621970588-a35d0e7ab9b6?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDU5fHxmaW5hbmNpYWwlMjBzdXBwb3J0fGVufDB8fHx8MTY5MTQwNzI5NHww&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"></p><p>The
        <a href=\"https://rogue-scholar.org\">Rogue Scholar science blog archive</a>
        adds important functionality to existing science blogs, namely archiving,
        full-text search, and DOI registration. While a lot of effort has gone into
        making Rogue Scholar as affordable as possible by using Open Source software,
        automation, and involving the community, it still costs money to build and
        run scholarly infrastructure, including scholarly infrastructure for science
        blogs.</p>\n<p>We made a few fundamental decisions even before starting Rogue
        Scholar:</p>\n<ul><li>Time-limited funds are used only for time-limited activities</li><li>Mission-consistent
        revenue generation</li><li>Revenue based on services, not data</li><li>Open
        source</li><li>Open data (within constraints of privacy laws)</li></ul>\n<p>These
        principles of course come from the <a href=\"https://doi.org/10.24343/C34W2H\">Principles
        of Open Scholarly Infrastructure</a> (POSI). It is too early for Rogue Scholar
        for a<a href=\"https://openscholarlyinfrastructure.org/posse/\"> formal commitment
        to POSI</a>, because it only launched a few months ago, and has no formal
        governance structure in place. Rogue Scholar is run by Front Matter, a German
        organization <a href=\"https://doi.org/10.53731/r87krmh-97aq74v-ag5x0\">started
        by me in 2021</a>. Front Matter is not (yet) a non-profit under German law
        because the overhead of starting and running a non-profit in Germany is considerable.
        The topic of Rogue Scholar governance is important, but in this blog post
        I want to focus on one aspect of POSI.</p>\n<h3 id=\"mission-consistent-revenue-generation\">Mission-consistent
        revenue generation</h3>\n<p>Rogue Scholar helps blogs that publish their content
        under an open license. Creative Commons Attribution (<a href=\"https://creativecommons.org/licenses/by/4.0/legalcode\">CC-BY
        4.0</a>) is the appropriate license for scholarly publications, <a href=\"https://oaspa.org/why-cc-by/\">as
        explained by the Open Access Publishers Association</a> (OASPA). Therefore
        content is always free to read, share and adapt for users of Rogue Scholar,
        and I hope to see interesting services and other implementations evolve over
        time.</p>\n<p>Consistent with the POSI principle <em>revenue based on services,
        not data</em>, I could see newsletters as a possible revenue source in the
        future, as long as content always remains accessible free of charge via webpage
        or RSS feed. Newsletters are a service that <a href=\"https://www.listenupih.com/ghost-post/\">has
        become popular with blogs in the past few years</a>, either to complement
        existent access models (good), unfortunately sometimes to restrict access
        (bad). Last <a href=\"https://doi.org/10.53731/9cdnt-2k006\">week I started</a>
        the <em>Rogue Scholar Digest</em> newsletter which sends weekly summaries
        of the Rogue Scholar posts the last seven days on Wednesdays. The newsletter
        is generated automatically without any manual curation of either the most
        interesting posts or posts about a particular topic, so it would not be appropriate
        to charge for it.</p>\n<p>Advertising on science blogs is a revenue model
        that has been tried for many years but overall has failed to deliver. Maybe
        science content isn't popular enough unless published by a few very popular
        bloggers. In addition, it is a very annoying business model that goes with
        tracking users and clicks, hopefully something that you will never see with
        the Rogue Scholar.</p>\n<p>Article Processing Charges (APC) as a cost model
        for journal articles are receiving a lot of criticism, for example in <a href=\"https://doi.org/10.59350/d1zfz-8cs77\">this
        blog post by Brembs</a>. It is critical to keep the costs for publishing scholarly
        content down and to be transparent about it. A good example is the Journal
        of Open Source Software (JOSS) which <a href=\"https://doi.org/10.59349/g4fz2-1cr36\">in
        2019 reported</a> a cost of about $100 per paper, paid for by grant funding.
        Rogue Scholar is looking at a cost of $1 per blog post in direct costs (compared
        to $2.71 for JOSS), but that does not include the costs of running a blogging
        platform or staff costs of editing papers (both paid by participating blogs)
        and developing the software platform (paid by Front Matter). </p>\n<p>Many
        science blogs are written by individuals in their \"free\" time as academics
        or science journalists. It wouldn't be appropriate to charge them for participating
        in Rogue Scholar, which is why Rogue Scholar is free for up to 50 blog posts
        published a year. If you publish more than 50 posts (or once per week) as
        an individual or organization, I hope you have a revenue source for the time
        spent writing and editing those posts and are willing to pay Rogue Scholar
        a one-time fee of $1 per post.</p>\n<p>What I am seeing with the about 40
        blogs participating in Rogue Scholar so far is that most of them will not
        publish more than 50 posts in 2023, but some blogs have been running for five,
        10, or more years, and have published 100s of posts before 2023. Archiving
        these older posts in Rogue Scholar is particularly important, as the risk
        of scholarly content disappearing <a href=\"https://doi.org/10.1371/journal.pone.0115253\">increases
        with time</a>. Based on the experience of archiving my own blog posts in Rogue
        Scholar going back until 2007, I am convinced that science blog posts older
        than two or three years are absolutely worth archiving.</p>\n<h3 id=\"new-payment-options\">New
        payment options</h3>\n<p>To align the Rogue Scholar with the <em>mission-consistent
        revenue generation </em>discussed in the previous paragraph, Rogue Scholar
        is launching two payment options today:</p>\n<ul><li>Donations (one-time or
        monthly) of $3 or more if you want to support the Rogue Scholar as a reader.
        Follow the new <a href=\"https://ko-fi.com/rogue_scholar\">buy me a coffee</a>
        link in the navigation bar on top of all Rogue Scholar pages.</li></ul>\n<figure
        class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-07-um-13.38.35.png\"
        class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"502\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2023/08/Bildschirmfoto-2023-08-07-um-13.38.35.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/08/Bildschirmfoto-2023-08-07-um-13.38.35.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/08/Bildschirmfoto-2023-08-07-um-13.38.35.png
        1600w, https://blog.front-matter.io/content/images/size/w2400/2023/08/Bildschirmfoto-2023-08-07-um-13.38.35.png
        2400w\" sizes=\"(min-width: 720px) 720px\"></figure>\n<ul><li>Follow the <a
        href=\"https://ko-fi.com/rogue_scholar/shop\">pay for more blog posts</a>
        link in the <a href=\"https://rogue-scholar.org/#pricing\">Rogue Scholar pricing
        section</a> to pay for archiving additional blog posts. Pay a one-time fee
        of $25 to archive 25 blog posts (including full-text search and DOI registration).
        This can be for your own blog or any other blog included in the Rogue Scholar,
        and can of course be multiples of 25 to archive more blog posts.</li></ul>\n<figure
        class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-07-um-13.37.05.png\"
        class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1101\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2023/08/Bildschirmfoto-2023-08-07-um-13.37.05.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/08/Bildschirmfoto-2023-08-07-um-13.37.05.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/08/Bildschirmfoto-2023-08-07-um-13.37.05.png
        1600w, https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-07-um-13.37.05.png
        2376w\" sizes=\"(min-width: 720px) 720px\"></figure>\n<p>The payments are
        handled by the <a href=\"https://ko-fi.com/\">Ko-fi</a> service (using Stripe
        and Paypal for payment processing). These new payment options make two important
        assumptions:</p>\n<ul><li>Users are willing to donate money for something
        they feel is important, even if it adds no direct value. I hope that some
        individuals are willing to donate to Rogue Scholar, but realistically organizations
        involved in scholarly communication are more likely to give one-time or regular
        donations.</li><li>Separating the payment for archiving blog posts from blog
        owners allows more flexible funding sources, e.g. crowdfunding campaigns to
        preserve the content of a blog important in a particular community, or funders
        willing to support scholar infrastructure for science blogs.</li></ul>\n<p>Please
        reach out in the comments or <a href=\"mailto:info@front-matter.io\">via email</a>
        if you have questions or feedback, or if you want to discuss funding the Rogue
        Scholar in other ways.</p>\n<h3 id=\"references\">References</h3>\n<p>Bilder
        G, Lin J, Neylon C. The Principles of Open Scholarly Infrastructure. Published
        online 2020. doi:<a href=\"https://doi.org/10.24343/C34W2H\">10.24343/C34W2H</a></p>\n<p>Fenner
        M. Front Matter officially launches today. Published online August 2, 2021.
        doi:<a href=\"https://doi.org/10.53731/r87krmh-97aq74v-ag5x0\">10.53731/r87krmh-97aq74v-ag5x0</a></p>\n<p>Redhead
        C. Why CC-BY? <em>OASPA</em>. Published online October 23, 2012. Accessed
        August 7, 2023. <a href=\"https://oaspa.org/why-cc-by/\">https://oaspa.org/why-cc-by/</a></p>\n<p>Fenner
        M. The Rogue Scholar weekly newsletter launches on Wednesday. Published online
        July 31, 2023. doi:<a href=\"https://doi.org/10.53731/9cdnt-2k006\">10.53731/9cdnt-2k006</a></p>\n<p>How
        to reach $4.2M ARR while pursuing a mission | Ghost\U0001F47B. <em>Listen
        Up IH</em>. Published online February 4, 2022. Accessed August 7, 2023. <a
        href=\"https://www.listenupih.com/ghost-post/\">https://www.listenupih.com/ghost-post/</a></p>\n<p>Brembs
        B. Is Open Access headed for a cost explosion? Published online October 2,
        2019. doi:<a href=\"https://doi.org/10.59350/d1zfz-8cs77\">10.59350/d1zfz-8cs77</a></p>\n<p>Katz
        DS, Barba LA, Niemeyer K, Smith AM. Cost models for running an online open
        journal. Published online June 4, 2019. doi:<a href=\"https://doi.org/10.59349/g4fz2-1cr36\">10.59349/g4fz2-1cr36</a></p>\n<p>Klein
        M, Sompel HV de, Sanderson R, et al. Scholarly Context Not Found: One in Five
        Articles Suffers from Reference Rot. <em>PLOS ONE</em>. 2014;9(12):e115253.
        doi:<a href=\"https://doi.org/10.1371/journal.pone.0115253\">10.1371/journal.pone.0115253</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Improvements in Rogue Scholar: tags and
        images ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/improvements-in-rogue-scholar-tags-and-images/\"
        />\n\t\t<id>https://doi.org/10.53731/7pqhx-z0y63</id>\n        <published>2023-08-02T16:10:51.000+00:00</published>\n\t\t<updated>2023-08-02T23:53:09.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-02-um-17.21.33.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-02-um-17.21.33.png\"></p><p>The
        Rogue Scholar science blog archive adds <a href=\"https://doi.org/10.53731/z9v2s-bh329\">important
        functionality</a> to existing blogs, namely long-term archiving, full-text
        search, and DOI registration. In this week's update, I focussed on improving
        functionality that is specific for blogs and not really found regularly with
        other formats for scholarly content.</p>\n<h3 id=\"tags\">Tags</h3>\n<p>Tags
        are a common way to categorize blog posts and help find content of interest.
        They are either used fairly flexibly, or with a predefined list, and posts
        can have zero, one, or multiple tags. The main reason tags exist is that most
        blogging platforms don't have good search functionality. As Rogue Scholar
        has a <a href=\"https://doi.org/10.53731/6r1dx-wdp04\">full-text search powered
        by Typesense</a>, tags are less important. They are still helpful, and this
        week they have been improved in the following ways:</p>\n<ul><li>Tags have
        been normalized, removing any hashes, hyphens, and lowercase first letters,
        so that searching for <code>#Covid-19</code> will also find <code>COVID 19,</code>and
        searching for <code>Pre-Print</code>will also find <code>preprint</code>.</li><li>Tags
        for blog posts are now clickable, triggering a search with that tag (either
        for a given blog or all posts)</li><li>Pagination now supports tags, so that
        a search for the tag <code>Open Access</code> lets you paginate through the
        68 results on five pages.</li></ul>\n<h3 id=\"feature-images\">Feature Images</h3>\n<p>Optional
        <a href=\"https://wordpress.com/support/featured-images/\">Feature images</a>
        can highlight visual information in a blog post. Some blogging platforms,
        e.g. Ghost or Medium, use them prominently, but there is more than one way
        to implement them in RSS or Atom feeds. As Rogue Scholar has access to the
        full-text HTML, it is easy to pick a feature image if none exists already.
        Starting this week Rogue Scholar automatically displays the first image that
        is at least 100px wide found in the full-text.</p>\n<figure class=\"kg-card
        kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-02-um-18.02.21.png\"
        class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1948\" height=\"1270\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2023/08/Bildschirmfoto-2023-08-02-um-18.02.21.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/08/Bildschirmfoto-2023-08-02-um-18.02.21.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/08/Bildschirmfoto-2023-08-02-um-18.02.21.png
        1600w, https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-02-um-18.02.21.png
        1948w\" sizes=\"(min-width: 720px) 720px\"></figure>\n<p>Both new features
        are available now. Feedback via comments, Discourse, or email is always welcomed,
        as this is the first version of this functionality. Some images for example
        don't display properly because they were moved or because the browser complains
        about mixed (HTTPS and HTTP) content. </p>\n<h3 id=\"references\">References</h3>\n<p>Fenner
        M. The Rogue Scholar is now open for business. Published online April 4, 2023.
        doi:<a href=\"https://doi.org/10.53731/z9v2s-bh329\">10.53731/z9v2s-bh329</a></p>\n<p>Fenner
        M. Rogue Scholar full-text search improvements. Published online July 10,
        2023. doi:<a href=\"https://doi.org/10.53731/6r1dx-wdp04\">10.53731/6r1dx-wdp04</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ The Rogue Scholar weekly newsletter launches
        on Wednesday ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/rogue-scholar-weekly-newsletter/\"
        />\n\t\t<id>https://doi.org/10.53731/9cdnt-2k006</id>\n        <published>2023-07-31T15:53:42.000+00:00</published>\n\t\t<updated>2023-07-31T17:24:48.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2023/07/Bildschirmfoto-2023-07-31-um-17.25.00.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2023/07/Bildschirmfoto-2023-07-31-um-17.25.00.png\"></p><p>The
        <a href=\"https://rogue-scholar.org\">Rogue Scholar</a> science blog archive
        is growing nicely, reaching more than 1,500 blog posts this week, and 5-10
        new posts every week. You can subscribe to all the blogs you are interested
        in via an RSS Reader and use various strategies to find and read interesting
        content, but some people prefer to receive regular email updates instead.
        That is why the Rogue Scholar is launching the Rogue Scholar Digest newsletter
        this week, publishing every Wednesday and containing summaries (title, publication
        date, blog name, author, and summary) with a link to the full-text post on
        the hosting blog.</p>\n<p>These weekly emails are generated automatically
        using the Rogue Scholar API and the newsletter functionality of this blog.
        To subscribe to the Rogue Scholar weekly digest, click the subscribe link
        on this <a href=\"https://blog.front-matter.io/\">blog's homepage</a> and
        add your name and email. Signing up for the newsletter is free and you can
        cancel anytime.</p>\n<figure class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2023/07/Bildschirmfoto-2023-07-31-um-17.39.25.png\"
        class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1104\" height=\"1428\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2023/07/Bildschirmfoto-2023-07-31-um-17.39.25.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/07/Bildschirmfoto-2023-07-31-um-17.39.25.png
        1000w, https://blog.front-matter.io/content/images/2023/07/Bildschirmfoto-2023-07-31-um-17.39.25.png
        1104w\" sizes=\"(min-width: 720px) 720px\"></figure>\n<p>Once you have confirmed
        the account via email, sign in and change your email preferences to receive
        the weekly Rogue Scholar Digest (there are a few other newsletters you can
        subscribe to):</p>\n<figure class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2023/07/Bildschirmfoto-2023-07-31-um-17.41.17.png\"
        class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1026\" height=\"1222\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2023/07/Bildschirmfoto-2023-07-31-um-17.41.17.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/07/Bildschirmfoto-2023-07-31-um-17.41.17.png
        1000w, https://blog.front-matter.io/content/images/2023/07/Bildschirmfoto-2023-07-31-um-17.41.17.png
        1026w\" sizes=\"(min-width: 720px) 720px\"></figure>\n<p>A newsletter summarizing
        5-10 posts is quickly scanned and interesting posts bookmarked for later reading,
        or stored in a reference manager for referencing later. When the Rogue Scholar
        archive grows further and the number of weekly new posts gets too large, I
        can start more specialized newsletters, e.g. by subject category (e.g. social
        sciences) or language.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Launching blog administration self-service
        in Rogue Scholar ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/blog-administration-self-service/\"
        />\n\t\t<id>https://doi.org/10.53731/vhw34-xxf63</id>\n        <published>2023-07-19T08:00:38.000+00:00</published>\n\t\t<updated>2023-07-19T08:31:55.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2023/07/Bildschirmfoto-2023-07-19-um-09.04.55-1.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2023/07/Bildschirmfoto-2023-07-19-um-09.04.55-1.png\"></p><p>This
        week I added blog administration self-service to the Rogue Scholar blog archive.
        This makes adding a blog to Rogue Scholar easier, faster, and cheaper.</p>\n<p>To
        start blog administration please create an account with Rogue Scholar. Use
        the \"Sign In\" Link in the upper right corner to sign in or create an account
        with username and password, or sign in via Google or GitHub.</p>\n<p>Once
        signed in, you can add your blog via the Dashboard page. You have to agree
        to the Rogue Scholar terms of service (which haven't changed since Rogue Scholar
        launched in April 2023):</p>\n<ul><li>The blog is about science or scholarship.</li><li>The
        full text of blog posts is made available via an Atom (preferred), RSS, or
        JSON feed.</li><li>The full text of blog posts is made available under the
        Creative Commons Attribution 4.0 International License.</li></ul>\n<p>The
        only required information is the URL of the Atom, RSS, or JSON Feed. The Atom
        format is preferred, as Atom supports multiple authors and author URLs, used
        for the ORCID ID in DOI registration.</p>\n<p>A blog image (favicon) is optional
        and can be added if not included in the Blog feed. About half of the included
        blogs currently have a favicon:</p>\n<figure class=\"kg-card kg-image-card\"><img
        src=\"https://blog.front-matter.io/content/images/2023/07/Bildschirmfoto-2023-07-19-um-09.27.07.png\"
        class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"764\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2023/07/Bildschirmfoto-2023-07-19-um-09.27.07.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/07/Bildschirmfoto-2023-07-19-um-09.27.07.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/07/Bildschirmfoto-2023-07-19-um-09.27.07.png
        1600w, https://blog.front-matter.io/content/images/2023/07/Bildschirmfoto-2023-07-19-um-09.27.07.png
        2240w\" sizes=\"(min-width: 720px) 720px\"></figure>\n<p>The category helps
        classify the blog and becomes more important as the number of blogs and blog
        posts included in Rogue Scholar increases. Currently, we use the six top-level
        categories of the <a href=\"https://www.oecd.org/science/inno/38235147.pdf\">OECD
        Fields of Science and Technology</a>.</p>\n<p>Once submitted, Rogue Scholar
        automatically fetches additional information from the blog feed, e.g. blog
        home page, title, description, and language. There is a final manual approval
        step before the blog can go live on Rogue Scholar, and we might contact you
        with additional questions. The main issue that we found is incomplete author
        information in the feed. Once approved, Rogue Scholar starts archiving the
        full text of blog posts, adds them to the full-text search, and starts DOI
        registration of blog posts, all fully automated.</p>\n<figure class=\"kg-card
        kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2023/07/Bildschirmfoto-2023-07-19-um-09.40.05.png\"
        class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1930\" height=\"1392\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2023/07/Bildschirmfoto-2023-07-19-um-09.40.05.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/07/Bildschirmfoto-2023-07-19-um-09.40.05.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/07/Bildschirmfoto-2023-07-19-um-09.40.05.png
        1600w, https://blog.front-matter.io/content/images/2023/07/Bildschirmfoto-2023-07-19-um-09.40.05.png
        1930w\" sizes=\"(min-width: 720px) 720px\"></figure>\n<p>Of course, it is
        possible to register more than one blog, and three users have done so. Blogs
        already included in the Rogue Scholar have to be manually added, so please
        first create an account with Rogue Scholar.</p>\n<p>In the past weeks, I have
        worked on translating the Rogue Scholar user interface. The currently supported
        languages are English and German, and I am particularly interested in including
        science blogs written in other languages. It is of course also possible to
        write individual posts in other languages, Rogue Scholar will automatically
        detect the language and display it if different from the preset language:</p>\n<figure
        class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2023/07/Bildschirmfoto-2023-07-19-um-09.48.45.png\"
        class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1652\" height=\"1260\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2023/07/Bildschirmfoto-2023-07-19-um-09.48.45.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/07/Bildschirmfoto-2023-07-19-um-09.48.45.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/07/Bildschirmfoto-2023-07-19-um-09.48.45.png
        1600w, https://blog.front-matter.io/content/images/2023/07/Bildschirmfoto-2023-07-19-um-09.48.45.png
        1652w\" sizes=\"(min-width: 720px) 720px\"></figure>\n<p>Once non-English
        language content in the Rogue Scholar becomes more common, we will also add
        a language option to the search interface.</p>\n<p>Please <a href=\"mailto:info@front-matter.io\">reach
        to me</a> if you have feedback or questions, or if you need help adding your
        blog to the Rogue Scholar. The next feature I will be working on is a streamlined
        payment process for blogs with more than 50 posts per year (which are always
        free).</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Rogue Scholar full-text search improvements
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/rogue-scholar-full-text-search-improvements/\"
        />\n\t\t<id>https://doi.org/10.53731/6r1dx-wdp04</id>\n        <published>2023-07-10T13:10:53.000+00:00</published>\n\t\t<updated>2023-07-11T06:28:04.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://images.unsplash.com/photo-1472512946974-cc09a294e210?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDI3fHxzZWFyY2h8ZW58MHx8fHwxNjg4OTkyNDk1fDA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://images.unsplash.com/photo-1472512946974-cc09a294e210?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDI3fHxzZWFyY2h8ZW58MHx8fHwxNjg4OTkyNDk1fDA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"></p><p>Two
        weeks ago I <a href=\"https://doi.org/10.53731/80awr-zcc48\">added a first
        version of full-text search to the Rogue Scholar blog</a> archive. This was
        a good start, as blogs typically only have the timeline, tags, and metadata
        like titles and authors to help readers find relevant content. Today I launched
        an improved version of full-text search with these improvements:</p>\n<ul><li>Sorting
        of search results by relevance</li><li>Support for fuzzy search or <a href=\"https://en.wikipedia.org/wiki/Approximate_string_matching\">approximate
        string matching</a></li><li>Added the backend for an updated search interface
        supporting faceted search and/or <a href=\"https://github.com/typesense/typesense-instantsearch-adapter\">InstantSearch</a></li></ul>\n<p>Sorting
        by relevance helps with search terms that produce many hits, e.g. <a href=\"https://rogue-scholar.org/de/posts?page=1&amp;query=RDA\">RDA</a>
        (for Research Data Alliance). Fuzzy search helps with typos and synonyms,
        e.g. <a href=\"https://rogue-scholar.org/de/posts?page=1&amp;query=proprint\">Proprint</a>
        (for preprint), <a href=\"https://rogue-scholar.org/de/posts?page=1&amp;query=open+scholarship\">Open
        Scholarship</a> (which also finds blog posts about Open Science), or <a href=\"https://rogue-scholar.org/de/posts?page=1&amp;query=Iain+Hry\">Iain
        Hry</a>, which finds blog posts from or about Iain Hrynaszkiewicz (who works
        at the Public Library of Science).</p>\n<p>These and further improvements
        in the future are of course only meaningful because the Rogue Scholar is a
        central archive of scholarly blogs, so users don't have to go to a long list
        of different places. And because the Rogue Scholar has archived the full text
        of these science blogs, rather than only metadata or abstracts.</p>\n<p>While
        the initial implementation of the <a href=\"https://www.crunchydata.com/blog/postgres-full-text-search-a-search-engine-in-a-database\">full-text
        search built into the Postgres</a> database that powers the Rogue Scholar
        backend, this new version uses <a href=\"https://typesense.org/\">Typesense</a>,
        a dedicated open source search engine. Adding another layer of technology
        complicates the Rogue Scholar technology stack, but full-text search using
        the functionality built into Postgres also can be challenging for more complex
        use cases. Sorting search results by relevance for example is possible, but
        more difficult compared to a dedicated search engine such as Typesense.</p>\n<p>Faceted
        search will become more important as the Rogue Scholar archive continues to
        grow, for example to allow filtering by language or subject area. <a href=\"https://www.algolia.com/doc/guides/building-search-ui/what-is-instantsearch/js/\">Instantsearch</a>
        \ is a popular open source library that supports search interfaces built directly
        into blogs, and that can take advantage of the Rogue Scholar full-text search.</p>\n<h3
        id=\"references\">References</h3>\n<p>Fenner M. Full-text search added to
        the Rogue Scholar science blog archive. Published online June 27, 2023. doi:<a
        href=\"https://doi.org/10.53731/80awr-zcc48\">10.53731/80awr-zcc48</a></p>\n<p>Hrynaszkiewicz
        I, Norton ML, Vickers AJ, Altman DG. Preparing raw clinical data for publication:
        guidance for journal editors, authors, and peer reviewers. <em>BMJ</em>. 2010;340(jan28
        1):c181-c181. doi:<a href=\"https://doi.org/10.1136/bmj.c181\">10.1136/bmj.c181</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ The Rogue Scholar archive reaches a milestone:
        1000 searchable full-text science blog posts with DOIs ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/the-rogue-scholar-milestone/\" />\n\t\t<id>https://doi.org/10.53731/89zgc-ptr93</id>\n
        \       <published>2023-07-03T07:32:37.000+00:00</published>\n\t\t<updated>2023-07-04T15:36:44.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2023/07/Bildschirmfoto-2023-07-03-um-09.31.14.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2023/07/Bildschirmfoto-2023-07-03-um-09.31.14.png\"></p><p>The
        Rogue Scholar science blog archive <a href=\"https://doi.org/10.53731/z9v2s-bh329\">launched
        in April</a> and I have been busy building out the core features of archiving
        the full-text of blog posts, establishing a full-text search, and registering
        DOIs and metadata for all posts. My announced goal was to complete this work
        by the end of the second quarter.</p>\n<p>We now have July and I am happy
        to report that the core features are working and that the Rogue Scholar includes
        1,000 blog posts that are available via full-text search, with DOIs linking
        to the original post on one of 35 science blogs, marking an important milestone
        worth celebrating.</p>\n<figure class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2023/07/Bildschirmfoto-2023-07-03-um-09.31.14-1.png\"
        class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"382\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2023/07/Bildschirmfoto-2023-07-03-um-09.31.14-1.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/07/Bildschirmfoto-2023-07-03-um-09.31.14-1.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/07/Bildschirmfoto-2023-07-03-um-09.31.14-1.png
        1600w, https://blog.front-matter.io/content/images/2023/07/Bildschirmfoto-2023-07-03-um-09.31.14-1.png
        2396w\" sizes=\"(min-width: 720px) 720px\"><figcaption><a href=\"https://rogue-scholar.org/posts\"
        rel=\"noopener\"><span>Rogue Scholar blog posts</span></a></figcaption></figure>\n<p>What
        is equally important is that this milestone has been reached without major
        technical work for the involved blogs. Rogue Scholar works with all blogging
        platforms that publish scholarly content and have an RSS or Atom feed with
        full-text content distributed under a Creative Commons Attribution (<a href=\"https://creativecommons.org/licenses/by/4.0/legalcode\">CC-BY
        4.0</a>) license \u2013 currently <a href=\"https://rogue-scholar.org/#stats\">nine
        different blogging platforms</a> from Wordpress, Blogger, and Ghost to several
        static site generators. The major issue was author names, usually resolved
        by configuration changes, e.g. in the Wordpress author profile.</p>\n<p>And
        the implementation doesn't take any shortcuts, the DOI metadata include abstract,
        language, license, and (OECD Fields of Science) subject category for all posts,
        and author ORCID ID and references for some posts.</p>\n<figure class=\"kg-card
        kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2023/07/Bildschirmfoto-2023-07-03-um-08.29.15.png\"
        class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1876\" height=\"1226\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2023/07/Bildschirmfoto-2023-07-03-um-08.29.15.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/07/Bildschirmfoto-2023-07-03-um-08.29.15.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/07/Bildschirmfoto-2023-07-03-um-08.29.15.png
        1600w, https://blog.front-matter.io/content/images/2023/07/Bildschirmfoto-2023-07-03-um-08.29.15.png
        1876w\" sizes=\"(min-width: 720px) 720px\"><figcaption><a href=\"https://www.crossref.org/members/prep/31795\"
        rel=\"noopener\"><span>Crossref Participation Reports</span></a><span> for
        blog posts registered by Front Matter</span></figcaption></figure>\n<p>And
        that Rogue Scholar does this without major costs for the participating blogs
        (free for up to 50 posts per year, and a one-time fee of $1 per post thereafter),
        or for Front Matter hosting the blog archive (with monthly costs under $200
        plus $.25 per DOI registration). This is possible because Rogue Scholar follows
        three principles: using open source software (more details in another post),
        automation as much as possible, and community participation.</p>\n<p>Reaching
        this milestone demonstrates that a central archive of science blogs with full-text
        content, and DOIs for all blog posts with relevant metadata is feasible, making
        an important contribution to <a href=\"https://doi.org/10.6084/M9.FIGSHARE.1314859\">Open
        Scholarly infrastructure</a>.</p>\n<p>What comes next? Besides a lot of detailed
        work (e.g. working with six blogs registered with the Rogue Scholar that have
        RSS/Atom feeds with incomplete author metadata or no full-text RSS feed),
        the main goals for the next three months are:</p>\n<ul><li>Improve the payment
        workflow, including automated payment processing and a sponsorship option
        for organizations wanting to support Rogue Scholar and/or specific blogs</li><li>Include
        more science blogs, more blog posts (so far I have included all posts from
        12 blogs), and improve the metadata (e.g. ORCID identifiers and references).
        In particular, I want to include blogs that publish posts in languages other
        than English (currently only <a href=\"https://rogue-scholar.org/#stats\">three
        of the 35 blogs</a>).</li><li>Build a community of Rogue Scholar bloggers
        and users. I have gotten a lot of feedback in the last few months but would
        like to better understand how people are currently using the Rogue Scholar
        or what can be improved. The starting point is the <a href=\"https://discord.gg/HvbD4dNPFh\">Rogue
        Scholar Discord</a> community, but there are also other feedback channels,
        including email, Mastodon, Zoom, and of course personal communications (you
        find me at the <a href=\"https://www.zbmed.de/en/networking/events/open-science-festival\">Open
        Science Festival Cologne</a> this week).</li></ul>\n<h3 id=\"references\">References</h3>\n<p>Fenner
        M. The Rogue Scholar: An Archive for Scholarly blogs. Published online January
        31, 2023. doi:<a href=\"https://doi.org/10.54900/bj4g7p2-2f0fn9b\">10.54900/bj4g7p2-2f0fn9b</a></p>\n<p>Fenner
        M. The Rogue Scholar is now open for business. Published online April 4, 2023.
        doi:<a href=\"https://doi.org/10.53731/z9v2s-bh329\">10.53731/z9v2s-bh329</a></p>\n<p>Fenner
        M. Starting to register DOIs for all blog posts included in the Rogue Scholar.
        Published online June 5, 2023. doi:<a href=\"https://doi.org/10.53731/m9fs5-nap05\">10.53731/m9fs5-nap05</a></p>\n<p>Bilder
        G, Lin J, Neylon C. Principles for Open Scholarly Infrastructures-v1. Published
        online 2015:35186 Bytes. doi:<a href=\"https://doi.org/10.6084/M9.FIGSHARE.1314859\">10.6084/M9.FIGSHARE.1314859</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Full-text search added to the Rogue Scholar
        science blog archive ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/full-text-search-added-to-the-rogue-scholar-science-blog-archive/\"
        />\n\t\t<id>https://doi.org/10.53731/80awr-zcc48</id>\n        <published>2023-06-27T13:04:24.000+00:00</published>\n\t\t<updated>2023-06-27T20:14:32.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2023/06/Bildschirmfoto-2023-06-27-um-14.23.30.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2023/06/Bildschirmfoto-2023-06-27-um-14.23.30.png\"></p><p>In
        January I started the <a href=\"https://rogue-scholar.org\">Rogue Scholar</a>
        blog archive with the slogan \"science blogging on steroids\", promising to
        enhance science blogs in important ways. Earlier this month I began <a href=\"https://doi.org/10.53731/m9fs5-nap05\">DOI
        registrations for blog posts</a>, and I am well on track to complete this
        for the included 35 blogs with more than 1,000 blog posts in the next few
        weeks. Another promise was the full-text search of blog posts, a functionality
        that is not typically part of blogging platforms, or that is implemented with
        only limited functionality.</p>\n<p>Today, I am happy to announce the first
        version of full-text search for all Rogue Scholar content. Full-text search
        works either for specific blogs and does a much better job of finding relevant
        content compared to blogging platforms or generic web searches, e.g. this
        blog post describing the work of a group of researchers from the University
        of Geneva.</p>\n<figure class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2023/06/Bildschirmfoto-2023-06-27-um-14.27.30.png\"
        class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"930\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2023/06/Bildschirmfoto-2023-06-27-um-14.27.30.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/06/Bildschirmfoto-2023-06-27-um-14.27.30.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/06/Bildschirmfoto-2023-06-27-um-14.27.30.png
        1600w, https://blog.front-matter.io/content/images/size/w2400/2023/06/Bildschirmfoto-2023-06-27-um-14.27.30.png
        2400w\" sizes=\"(min-width: 720px) 720px\"></figure>\n<p>Full-text search
        also works across all blogs included in the Rogue Scholar, something that
        would be much harder to accomplish otherwise. A good example are topics widely
        discussed in the blogosphere such as <a href=\"https://rogue-scholar.org/posts?query=covid\">COVID</a>,
        <a href=\"https://rogue-scholar.org/posts?query=climate+change\">climate change</a>,
        or <a href=\"https://rogue-scholar.org/posts?query=chatgpt\">ChatGPT</a>,
        but also more obscure content where we don't remember the source, for example,
        a blog post about the <a href=\"https://en.wikipedia.org/wiki/Tasmanian_devil\">Tasmanian
        Devil</a> (a carnivorous marsupial from Tasmania that is severely affected
        by a transmissible facial tumor that threatens the survival of the species).</p>\n<figure
        class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2023/06/Bildschirmfoto-2023-06-27-um-14.39.04.png\"
        class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"926\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2023/06/Bildschirmfoto-2023-06-27-um-14.39.04.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/06/Bildschirmfoto-2023-06-27-um-14.39.04.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/06/Bildschirmfoto-2023-06-27-um-14.39.04.png
        1600w, https://blog.front-matter.io/content/images/size/w2400/2023/06/Bildschirmfoto-2023-06-27-um-14.39.04.png
        2400w\" sizes=\"(min-width: 720px) 720px\"></figure>\n<p>The first implementation
        of full-text search of course has some limitations, mainly:</p>\n<ul><li>Author
        names not yet included (unless they also appear in the full-text)</li><li>No
        relevance sorting of results (they are always sorted by reverse publication
        date)</li><li>Improvements in the search user interface, either a faceted
        search interface powered by <a href=\"https://www.elastic.co/\">Elasticsearch</a>,
        or the floating modal search window made popular by Algolia and the <a href=\"https://github.com/algolia/instantsearch\">Instantsearch</a>
        open source library</li></ul>\n<p>The Rogue Scholar full-text search is implemented
        with the <a href=\"https://supabase.com/blog/postgres-full-text-search-vs-the-rest\">Postgres
        database full-text search</a>, which is a nice alternative to a dedicated
        search index particularly if you don't need to search millions of documents.
        And the full-text search was only possible because all blogs participating
        in the Rogue Scholar agreed to a Creative Commons Attribution (<a href=\"https://creativecommons.org/licenses/by/4.0/legalcode\">CC-BY
        4.0</a>) license for all their posts.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Starting to include references in DOI metadata
        for blog posts ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/starting-to-include-references-in-doi-metadata-for-blog-posts/\"
        />\n\t\t<id>https://doi.org/10.53731/6mkrk-dzh02</id>\n        <published>2023-06-16T09:11:18.000+00:00</published>\n\t\t<updated>2023-06-16T09:11:18.000+00:00</updated>\n
        \       <media:content url=\"https://blog.front-matter.io/content/images/2023/06/article2-1-1.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2023/06/article2-1-1.png\"></p><p>Two
        weeks ago I <a href=\"https://doi.org/10.53731/m9fs5-nap05\">started registering
        DOIs</a> for blog posts included in the Rogue Scholar blog archive. It is
        an automated process but involves a lot of manual checks. So far I have registered
        <a href=\"https://api.crossref.org/prefixes/10.59350/works\">231 blog posts</a>
        from 20 different science blogs, and I hope to finish the DOI registrations
        by the end of the month. Going forward these DOI registrations will happen
        automatically whenever one of the science blogs included in the Rogue Scholar
        publishes a new post. I do this by monitoring the RSS feeds of these blogs,
        which I also use to generate the DOI metadata.</p>\n<p>The DOI registrations
        include required and recommended metadata, including</p>\n<ul><li>Author ORCID
        ID if provided by the blog</li><li>Abstract</li><li>Language of the post</li><li>License
        (all Rogue Scholar blogs use the <a href=\"https://creativecommons.org/licenses/by/4.0/legalcode\">Creative
        Commons Attribution 4.0 license</a>)</li></ul>\n<p>Because all Rogue Scholar
        blog posts are archived as full-text, we can extract additional metadata and
        register them with Crossref. The obvious first candidate is references, and
        today the Rogue Scholar has started to add them to the DOI metadata it registers
        with Crossref. The workflow for adding references follows the same principles
        I also use elsewhere for the Rogue Scholar:</p>\n<ul><li>No particular technical
        effort is required for blog authors</li><li>Using open source software and
        open access content</li><li>The process should be simple and cheap</li></ul>\n<p>The
        initial implementation uses the standard formatting for references: a section
        at the end of the text, starting with an HTML &lt;h2&gt;, &lt;h3&gt; or &lt;h4&gt;
        header and the word <strong>References</strong>, followed by a list of links
        that are either DOIs or generic URLs. This <a href=\"https://doi.org/10.53731/r795v41-97aq74v-ag4cd\">pattern
        is so common</a> that Crossref colleague Geoff Bilder uses it in presentations,
        and it is immediately recognized by most audiences:</p>\n<figure class=\"kg-card
        kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2023/06/article2-1-1-1.png\"
        alt=\"\" loading=\"lazy\" width=\"500\" height=\"722\"></figure>\n<p>Because
        some blogs have additional text after their references, I strip any text (and
        the included links) after an additional &lt;h2&gt;, &lt;h3&gt;, &lt;h4&gt;,
        or &lt;hr&gt; HTML tag. </p>\n<p>You can use the Crossref API to find Rogue
        Scholar DOIs with references (four blog posts as I write this) using the query
        <a href=\"https://api.crossref.org/prefixes/10.59350/works?filter=has-references:true\">https://api.crossref.org/prefixes/10.59350/works?filter=has-references:true</a></p>\n<p>When
        registering references I automatically check whether they resolve (using an
        HTTP HEAD request), to at least prevent typos or otherwise wrong DOIs/other
        URLs. I am not registering additional metadata for the references (e.g. the
        title), as this would dramatically increase the effort for blog authors, and
        that information is available in the original blog post.</p>\n<p>About 5%
        of the so far about 450 Rogue Scholar blog posts have references (the registration
        of the references with Crossref is ongoing). I hope that including the references
        in the DOI metadata will encourage blog authors to include more references,
        and I am of course open to feedback regarding the best workflows. The references
        in Rogue Scholar posts are of course not limited to journal articles, preprints,
        or conference proceedings, but can also include datasets, software (such as
        the <a href=\"https://doi.org/10.5281/ZENODO.7752775\">software used to generate
        the Crossref metadata</a>), or anything with a URL that needs referencing.
        \ </p>\n<p>Of course I am fully aware that including references is only part
        of the story. I assume that Rogue Scholar blog authors are also interested
        in citations of their blog posts, and thanks to the work by many organizations
        including Crossref and <a href=\"https://opencitations.net/\">OpenCitations</a>
        <a href=\"https://doi.org/10.53731/rc3j5sn-tzg61kj-7ztra\">Open Citation data
        has reached a critical milestone</a>. I will update the Rogue Scholar to display
        these citations in the coming months.</p>\n<h2 id=\"references\">References</h2>\n<p>Fenner
        M. <em>Starting to Register DOIs for All Blog Posts Included in the Rogue
        Scholar</em>. Feature; 2023. doi:<a href=\"https://doi.org/10.53731/m9fs5-nap05\">10.53731/m9fs5-nap05</a></p>\n<p>Fenner
        M. <em>Reference Lists and Tables of Content</em>. Feature; 2016. doi:<a href=\"https://doi.org/10.53731/r795v41-97aq74v-ag4cd\">10.53731/r795v41-97aq74v-ag4cd</a></p>\n<p>Fenner,
        Martin. commonmeta-ruby. Published online March 20, 2023. doi:<a href=\"https://doi.org/10.5281/ZENODO.7752775\">10.5281/ZENODO.7752775</a></p>\n<p>Fenner
        M. <em>Open Citation Data Reach Critical Milestone</em>. Perspective; 2021.
        doi:<a href=\"https://doi.org/10.53731/rc3j5sn-tzg61kj-7ztra\">10.53731/rc3j5sn-tzg61kj-7ztra</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Starting to register DOIs for all blog posts
        included in the Rogue Scholar ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/starting-to-register-dois-for-all-blog-posts-included-in-the-rogue-scholar/\"
        />\n\t\t<id>https://doi.org/10.53731/m9fs5-nap05</id>\n        <published>2023-06-05T13:18:24.000+00:00</published>\n\t\t<updated>2023-06-05T13:18:24.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2023/06/Bildschirmfoto-2023-06-05-um-14.58.49-1.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2023/06/Bildschirmfoto-2023-06-05-um-14.58.49-1.png\"></p><p>The
        <a href=\"https://rogue-scholar.org/\">Rogue Scholar</a> archive of scholarly
        blogs has grown to 34 blogs with about 420 blog posts. In order to implement
        DOI registration for these blog posts, I needed two things:</p><ul><li>Content
        and metadata, ideally without requiring blogs to implement anything special.</li><li>A
        way to track the DOIs that have been registered</li></ul><p>Initial work on
        DOI registration for blog posts focussed on exposing the relevant metadata
        on the blog landing page, using schema.org and/or HTML meta tags. While this
        approach worked well for this and similar blogs, it was too complicated and
        didn't scale well for the large and diverse number of blogs the Rogue Scholar
        aims to cover. </p><p>Therefore I implemented a different workflow taking
        advantage of the fact that all blogs come with RSS feeds that include content
        and metadata. More work was needed because there are different formats for
        these feeds (multiple flavors of RSS, as well as <a href=\"https://en.wikipedia.org/wiki/Atom_(web_standard)\">Atom</a>,
        and the newer <a href=\"https://www.jsonfeed.org/\">JSON Feed</a>). Luckily,
        \_libraries in multiple programming languages exist to simplify the parsing
        of the various RSS Feed formats (I use the Javascript library <a href=\"https://www.npmjs.com/package/@extractus/feed-extractor\">feed-extractor</a>).</p><p>The
        main challenge with metadata for blog posts \u2013 and with DOI metadata more
        general \u2013 is author names. They might not be natural names (for example
        <strong>mfenner</strong> instead of <strong>Martin Fenner</strong>), might
        be names for organizations and not people, the blogging platform might not
        support multiple authors, and some work is required to include the ORCID author
        identifier (or ROR institutional. identifier). The Atom format supports an
        <strong>author URL</strong>, which can hold the ORCID ID (or ROR ID), and
        Wordpress can be enhanced with the popular <a href=\"https://wordpress.org/plugins/co-authors-plus/\">Co-Authors
        Plus</a> plugin to support multiple authors. </p><p>The other challenge with
        DOI registration is keeping track of the content that has already been registered,
        and for this I launched a database, with one record for each post. I need
        the database also to enable full-text search across all blog posts, something
        I will implement in the coming weeks. </p><p>Will all the required pieces
        coming together, I was finally able to start DOI registrations yesterday.
        You will easily detect blog posts with a DOI on the Rogue Scholar website
        (there is a DOI icon next to the title, and the underlying link to the blog
        post is a DOI):</p><figure class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2023/06/Bildschirmfoto-2023-06-05-um-14.58.49.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"1046\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2023/06/Bildschirmfoto-2023-06-05-um-14.58.49.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/06/Bildschirmfoto-2023-06-05-um-14.58.49.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/06/Bildschirmfoto-2023-06-05-um-14.58.49.png
        1600w, https://blog.front-matter.io/content/images/size/w2400/2023/06/Bildschirmfoto-2023-06-05-um-14.58.49.png
        2400w\" sizes=\"(min-width: 720px) 720px\"></figure><p>The process of DOI
        registration for all included blog posts should be concluded by the end of
        the month. There is more work needed to resolve issues with some author names,
        and DOI registration can be further automated (I am currently using GitHub
        Actions and a cronjob). </p><p>What also needs more work is getting the DOIs
        displayed on the blogs (the DOIs resolve to the blog post and not the Rogue
        Scholar archive). This is probably straightforward when using a static site
        generator, but requires more work when a database is involved (e.g. Wordpress).
        For Ghost blogs like this one, I found the <strong>canonical_url</strong>
        field to be a good place to store the DOI.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Does it compose? ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/does-it-compose/\" />\n\t\t<id>https://doi.org/10.53731/4nwxn-frt36</id>\n
        \       <published>2023-05-16T11:36:56.000+00:00</published>\n\t\t<updated>2023-06-18T10:27:46.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://images.unsplash.com/photo-1523351964962-1ee5847816c3?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDUzfHxjb250YWluZXJ8ZW58MHx8fHwxNjg0MjMyMTQ0fDA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://images.unsplash.com/photo-1523351964962-1ee5847816c3?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDUzfHxjb250YWluZXJ8ZW58MHx8fHwxNjg0MjMyMTQ0fDA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"></p><p>One
        question I have increasingly asked myself in the past few years. Meaning </p><blockquote>Can
        I run this open source software \_using Docker containers and a Docker Compose
        file?</blockquote><p>As the Docker project <a href=\"https://snyk.io/blog/the-docker-project-turns-10/\">turned
        ten this spring</a>, it has become standard practice to distribute open source
        software via Docker images and to provide a <a href=\"https://docs.docker.com/compose/\">Docker
        Compose</a> file to run the software together with other dependencies. The
        <a href=\"https://github.com/docker/awesome-compose\">Awesome Compose</a>
        project has collected many examples, and all you need is a <code>docker-compose.yml</code>file
        and a recent installation of Docker, e.g. <a href=\"https://www.docker.com/products/docker-desktop/\">Docker
        Desktop</a>. Be aware that Docker Compose has evolved over the years. It started
        out as a dedicated Python application but was later integrated into the Docker
        application (written in Go) as Compose V2.</p><p>Docker and Docker Compose
        allow you to run pretty complex applications without first addressing a long
        list of requirements (which might conflict with other software you have installed),
        or needing a long and complex build step where many things can go wrong. For
        example a self-hosted instance of Supabase (a hosted Postgres database with
        additional features) that I installed last week following <a href=\"https://supabase.com/docs/guides/self-hosting/docker\">these
        instructions</a>.</p><p>An important open source project that I am involved
        in is <a href=\"https://inveniordm.docs.cern.ch/\">InvenioRDM</a>, the turn-key
        research data management repository. InvenioRDM started in 2019, with a first
        production-suitable version in August 2021, and the <a href=\"https://inveniosoftware.org/products/rdm/#status\">next
        major goal </a>is to have the large and popular <a href=\"https://zenodo.org/\">Zenodo</a>
        repository running on top of InvenioRDM. Zenodo <a href=\"https://blog.zenodo.org/2023/05/08/2023-05-08-10years/\">turned
        ten last week</a>, a few weeks after Docker. Interestingly, my personal tenth
        anniversary was last year in May as I became a full-time software developer
        and left academic medicine as a medical doctor treating cancer patients in
        <a href=\"https://doi.org/10.53731/r294649-6f79289-8cw2j\">May 2012</a>.</p><p>Unfortunately,
        InvenioRDM \"doesn't compose\" yet. It is very close, but there are no ready-made
        Docker images to download, and the <a href=\"https://inveniordm.docs.cern.ch/install/\">installation
        instructions</a> start with installing a Python command-line tool (invenio-cli).
        So if you have 1-2 hours to play with InvenioRDM and get a first impression,
        there is no official solution from the InvenioRDM project yet. For this reason,
        I started the <a href=\"https://github.com/front-matter/docker-invenio-rdm\">docker-invenio-rdm</a>
        repository on Github. It contains a Docker Compose file that uses pre-built
        Docker images, and using that file with a <code>docker compose up</code>command
        on your local computer should give you a running InvenioRDM within 15 minutes:</p><figure
        class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2023/05/Bildschirmfoto-2023-05-11-um-10.37.55.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"1210\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2023/05/Bildschirmfoto-2023-05-11-um-10.37.55.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/05/Bildschirmfoto-2023-05-11-um-10.37.55.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/05/Bildschirmfoto-2023-05-11-um-10.37.55.png
        1600w, https://blog.front-matter.io/content/images/2023/05/Bildschirmfoto-2023-05-11-um-10.37.55.png
        2193w\" sizes=\"(min-width: 720px) 720px\"></figure><p>I started this recently
        and obviously want to move forward in two directions:</p><ul><li>fine-tune
        the initial configuration to provide a great initial experience with InvenioRDM,
        e.g. making it easy to <a href=\"https://inveniordm.docs.cern.ch/develop/topics/theming/\">theme</a>
        the InvenioRDM instance</li><li>make this an official part of the InvenioRDM
        project, extending the <a href=\"https://github.com/inveniosoftware/docker-invenio\">docker-invenio</a>
        GitHub repository that provides Docker base images for InvenioRDM and other
        projects using the Invenio software.</li></ul><p>But of course, Docker Compose
        is not the answer to all questions regarding running Docker-based infrastructure.
        For production environments, most people shy away from using Docker Compose.
        The reasons for that and the alternatives will be the topic of a future blog
        post (spoiler: there is exciting news).</p><p>Docker Compose also needs more
        work to be set up correctly for development environments. It is a common practice
        and a workflow I used while working at DataCite (where we launched Docker-based
        infrastructure in 2016), but for now, the easiest way to set up InvenioRDM
        development environments is using the <a href=\"https://inveniordm.docs.cern.ch/install/\">invenio-cli
        tool with a local development environment</a>.</p><p>Please reach out to me
        with feedback on running Docker Compose for InvenioRDM (use the <a href=\"https://github.com/front-matter/docker-invenio-rdm/discussions\">discussions</a>
        feature in the GitHub repo), or if you have questions about running InvenioRDM
        in production.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Dog food, persistent identifiers, and metadata
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/dog-food-persistent-identifiers-and-metadata/\"
        />\n\t\t<id>https://doi.org/10.53731/nfa3v-h9q90</id>\n        <published>2023-04-17T17:08:26.000+00:00</published>\n\t\t<updated>2023-04-17T17:20:25.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://images.unsplash.com/photo-1608408891486-f5cade977d19?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDR8fGRvZyUyMGZvb2R8ZW58MHx8fHwxNjgxNzQyOTYy&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://images.unsplash.com/photo-1608408891486-f5cade977d19?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDR8fGRvZyUyMGZvb2R8ZW58MHx8fHwxNjgxNzQyOTYy&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"></p><p>I
        am a big fan of dog food, and I <a href=\"https://doi.org/10.53731/r79vxn1-97aq74v-ag58n\">wrote
        about this topic</a> already seven years ago:</p><blockquote><a href=\"https://newrepublic.com/article/115349/dogfooding-tech-slang-working-out-glitches\">Eating
        your own dog food</a> is a slang term to describe that an organization should
        itself use the products and services it provides. </blockquote><p>One of the
        major projects I am working on right now is the <a href=\"https://rogue-scholar.org\">Rogue
        Scholar</a> science blog archive <a href=\"https://doi.org/10.53731/z9v2s-bh329\">that
        launched</a> at the beginning of the month. As part of this work \u2013 but
        also because I am very interested in this \u2013 I read a lot of science blogs.
        And today I released an update of the Rogue Scholar that makes this easier.</p><h3
        id=\"persistent-identifiers-for-science-blogs\">Persistent identifiers for
        science blogs</h3><p>People who know me know that I care about persistent
        identifiers for scholarly resources. I have worked for seven years for <a
        href=\"https://datacite.org\">DataCite</a>, a DOI registration to register
        datasets, software, and other non-textual resources. I was involved in the
        launch of <a href=\"https://orcid.org\">ORCID</a> (identifiers for researchers)
        in 2012 and <a href=\"https://ror.org\">ROR</a> (identifiers for research
        organizations) in 2019. So it shouldn't surprise anyone that I am officially
        announcing the Rogue Scholar identifier for science blogs today. Each blog
        that has registered with the Rogue Scholar is uniquely identified, e.g. </p><ul><li>Upstream
        <a href=\"https://rogue-scholar.org/pm0p222\">https://rogue-scholar.org/pm0p222</a>,</li><li>GigaBlog
        <a href=\"https://rogue-scholar.org/3ffcd46\">https://rogue-scholar.org/3ffcd46</a>,
        and of course</li><li>Front Matter <a href=\"https://rogue-scholar.org/f0m0e38\">https://rogue-scholar.org/f0m0e38</a></li></ul><p>Persistent
        identifiers should not have any semantic meaning (e.g. the blog name) in them,
        as names can change over time. And they should not be linked to a domain name,
        (e.g. upstream.force11.org) as those might also change. The Rogue Scholar
        identifier uses a 7-digit random string generated by the <a href=\"https://github.com/front-matter/base32-url\">base32
        algorithm</a> and a two-digit checksum (the Front Matter identifier for example
        was generated with the random number 16127113320). DataCite, ROR, and the
        repository <a href=\"https://zenodo.org\">Zenodo</a> use similarly constructed
        unique identifiers. Their main advantage over <a href=\"https://en.wikipedia.org/wiki/Universally_unique_identifier\">UUIDs</a>
        is that they are easier to handle because of their compact size \u2013 there
        are still more than three billion unique strings for the Rogue Scholar identifier.
        Finally, persistent identifiers should be actionable, which means expressed
        as URLs that a human or machine can follow.</p><p>Why did I not use International
        Standard Serial Numbers (<a href=\"https://www.issn.org/\">ISSNs</a>), well-established
        identifiers that also work for blogs (the Front Matter blog has ISSN <a href=\"https://portal.issn.org/resource/ISSN/2749-9952\">2749-9952</a>)?
        Why ISSN registration can be easy and cheap, registration can become an issue,
        especially for new blogs that are just beginning to publish. And ISSNs have
        only the most basic metadata (e.g. title, country). And why not use digital
        object identifiers (<a href=\"https://www.doi.org/\">DOIs</a>)? They have
        traditionally been used for scholarly outputs such as journal articles, datasets,
        and <a href=\"https://doi.org/10.53731/fezg09h-hgn1gzm\">blog posts</a>. While
        you can register DOIs for serials such as journals, conference proceedings,
        or blogs, there is currently no standard practice to do so.</p><h3 id=\"metadata-for-science-blogs\">Metadata
        for science blogs</h3><p>Persistent identifiers are not really useful without
        meaningful metadata. For science blogs, this means at least the following:</p><ul><li>Blog
        name</li><li>Blog short description</li><li>Blog URL</li><li>Alternate identifiers,
        e.g ISSN and/or DOI</li><li>Blog editor(s)</li><li>License for the content,
        e.g Creative Commons Attribution (<a href=\"https://creativecommons.org/licenses/by/4.0/\">CC-BY</a>)</li><li>Subject
        area(s) for the content, e.g. aligned with the <a href=\"https://en.wikipedia.org/wiki/Fields_of_Science_and_Technology\">OECD
        Fields of Science and Technology</a></li></ul><p>For the blogs participating
        in the Rogue Scholar, I am collecting this information and will make it available
        in the Rogue Scholar search. To not start from scratch, I am using the metadata
        available from most blogs via <a href=\"https://doi.org/10.53731/d6vdvbt-tffmezj\">RSS
        or Atom feed</a>. For some information, e.g. license or subject area, I need
        to ask additional questions to the blog editor.</p><p>RSS and Atom both use
        XML, rather than JSON, which is much more pleasant to work with. Therefore
        \u2013 after the initial conversion of RSS or Atom XML \u2013 I can use <a
        href=\"https://www.jsonfeed.org/\">JSON Feed</a> to describe blog metadata,
        and the format can be extended to the needs of the Rogue Scholar. To fetch
        the JSON Feed of a blog included in the Rogue Scholar, use the identifier.
        Either by appending <code>.json</code> to the identifier (e.g. <a href=\"https://rogue-scholar.org/h56tk29.json\">https://rogue-scholar.org/h56tk29.json</a>)
        or by entering the identifier (<a href=\"https://rogue-scholar.org/h56tk29.json\">https://rogue-scholar.org/h56tk29</a>)
        in your RSS reader. The reader will automatically find the JSON Feed via the
        link tag in the page header:</p><pre><code>&lt;link rel=\"alternate\" title=\"Jabberwocky
        Ecology\" type=\"application/feed+json\" href=\"https://rogue-scholar.org/h56tk29.json\"/&gt;</code></pre><p>The
        RSS Reader (assuming it supports JSON Feed, as most readers do) will subscribe
        you to the JSON Feed of the blog, simplifying the reading of science blogs.
        More work is needed to polish the RSS/Atom Feed conversion to JSON Feed done
        by the Rogue Scholar and streamline subscribing to multiple blogs at once,
        e.g. using <a href=\"https://doi.org/10.53731/wa7k5-v4t16\">OPML</a>. </p><p>JSON
        Feed can also be used for the metadata and content of blog posts, so again
        I don't need to use XML, e.g. Journal Article Tag Suite (<a href=\"https://jats.nlm.nih.gov/\">JATS</a>).
        For blog posts, I will continue to <a href=\"https://doi.org/10.53731/rb7xw01-97aq74v-ag7qh\">use
        DOIs</a>, as they work well, and I am making progress with Rogue Scholar integration
        (see for example this blog using DOIs already: <a href=\"https://rogue-scholar.org/f4wdg32\">https://rogue-scholar.org/f4wdg32</a>)</p><h3
        id=\"bringing-everything-together\">Bringing everything together</h3><p>How
        does the above help with finding, reading, sharing, or otherwise reusing science
        blogs? The work released today should make it easier to find interesting science
        blogs via the Rogue Scholar and subscribe to them via your RSS reader of choice.
        Over time we will hopefully see evolving community standards regarding blog
        persistent identifiers and metadata, following the <a href=\"https://www.go-fair.org/fair-principles/\">FAIR
        Principles</a>, while at the same time pushing hard for <a href=\"https://www.scienceeurope.org/our-priorities/open-access/diamond-open-access/\">Diamond
        Open Access</a>, keeping the cost and technical complexity affordable.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Feedback for science blog publishers ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/feedback-for-blog-publishers/\"
        />\n\t\t<id>https://doi.org/10.53731/h4b6c-h1444</id>\n        <published>2023-04-11T12:31:40.000+00:00</published>\n\t\t<updated>2023-04-14T20:50:32.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2023/04/Bildschirmfoto-2023-04-11-um-13.14.02.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2023/04/Bildschirmfoto-2023-04-11-um-13.14.02.png\"></p><p>The
        <a href=\"https://rogue-scholar.org/\">Rogue Scholar</a> science blog archive
        <a href=\"https://doi.org/10.53731/z9v2s-bh329\">launched last week</a>. Going
        forward the focus is on improving the service and adding more blogs. This
        includes giving blog authors feedback on how they can improve their RSS/Atom
        feeds \u2013 used by the Rogue Scholar to collect and archive the blog content.</p><h3
        id=\"feedback-for-science-blog-publishers\">Feedback for science blog publishers</h3><p>A
        good starting point is author information, which often can be improved. The
        first step is to support multiple authors and support their full (given and
        family) names instead of usernames. It is useful to include ORCID author identifiers,
        best done by using the author website field of the blogging platform. This
        information can then be included in the blog <a href=\"https://www.rfc-editor.org/rfc/rfc4287\">Atom
        feed</a>, which works better for this than <a href=\"https://en.wikipedia.org/wiki/RSS\">RSS
        feeds</a>.</p><p>The blog (RSS or Atom) feed includes a link for each blog
        post but also an <strong>id</strong> (Atom) or <strong>guid</strong> (RSS).
        Ideally, this id/guid is globally unique, does not change over time, and can
        be used as a web link. <a href=\"https://ask.library.uic.edu/faq/345899\">DOIs</a>
        are a perfect fit for this id/guid field, and several blogs included in the
        Rogue Scholar do this already (<a href=\"https://rogue-scholar.org/blogs/f0m0e38\">this
        blog</a> but also <a href=\"https://rogue-scholar.org/blogs/pm0p222\">Upstream</a>).
        Many blogging platforms have a <a href=\"https://developer.wordpress.org/reference/functions/wp_get_canonical_url/\">canonical_url</a>
        field that can be used to store the DOI, separate from the URL.</p><p>Abstracts
        are useful for blog posts and widely supported. Unfortunately, there is no
        standard way to provide them in RSS or Atom feeds. A good practice is to use
        text and not HTML and to limit the total number of characters (the Rogue Scholar
        limits abstracts to 210 characters).</p><p>Feature images for blog posts are
        again widely used but there is no standard way to do this in RSS or Atom feeds.
        Examples of Rogue Scholar blogs using feature images are <a href=\"https://rogue-scholar.org/blogs/n6x4a73\">Chris
        Hartgerink</a>, <a href=\"https://rogue-scholar.org/blogs/h7bpg11\">OA.Works</a>
        and <a href=\"https://rogue-scholar.org/blogs/f4wdg32\">Syldavia Gazette</a>.</p><h3
        id=\"blog-statistics\">Blog statistics</h3><p>This week I added <a href=\"https://rogue-scholar.org/#stats\">basic
        statistics</a> for the Rogue Scholar that give preliminary insights into the
        kind of science blogs covered by the Rogue Scholar. The <strong>category</strong>
        is the top-level classification of the <a href=\"https://www.oecd.org/science/inno/38235147.pdf\">OECD
        Fields of Science and Technology</a>. Many blogs cover Natural Sciences, Engineering
        and Technology, Social Sciences \u2013 Health and Medical Sciences, Humanities,
        and Agricultural Sciences are covered less. Almost all currently included
        blogs are in the English <strong>language</strong>, please reach out if you
        manage a blog in another language. Knowing the blogging <strong>platform</strong>
        helps integrate the various RSS feeds into the Rogue Scholar, and the results
        are as expected. Wordpress is the most popular blogging platform, \_but science
        blogs also use a variety of other platforms, including Ghost, Medium, and
        Blogger. Another interesting key performance indicator (KPI) is the total
        number of blogs and blog posts included, but this needs more work as this
        information is not immediately available.</p><figure class=\"kg-card kg-image-card
        kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2023/04/Bildschirmfoto-2023-04-11-um-13.19.27.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"716\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2023/04/Bildschirmfoto-2023-04-11-um-13.19.27.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/04/Bildschirmfoto-2023-04-11-um-13.19.27.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/04/Bildschirmfoto-2023-04-11-um-13.19.27.png
        1600w, https://blog.front-matter.io/content/images/2023/04/Bildschirmfoto-2023-04-11-um-13.19.27.png
        2152w\" sizes=\"(min-width: 720px) 720px\"><figcaption><a href=\"https://rogue-scholar.org/#stats\">Basic
        statistics for the Rogue Scholar</a></figcaption></figure><h3 id=\"usage-statistics\">Usage
        statistics</h3><p>The Usage Stats for the Rogue Scholar are publicly available
        <a href=\"https://plausible.io/rogue-scholar.org\">here</a>. The numbers are
        still small and don't cover individual posts, or usage numbers from the blog
        itself, both of which may come over time. The Rogue Scholar intentionally
        isn't collecting any personal information or using any cookies, but the available
        public information can give important insights (e.g. the countries or referer
        pages where users come from).</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2023/04/Bildschirmfoto-2023-04-11-um-13.18.09.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"1146\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2023/04/Bildschirmfoto-2023-04-11-um-13.18.09.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/04/Bildschirmfoto-2023-04-11-um-13.18.09.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/04/Bildschirmfoto-2023-04-11-um-13.18.09.png
        1600w, https://blog.front-matter.io/content/images/2023/04/Bildschirmfoto-2023-04-11-um-13.18.09.png
        2038w\" sizes=\"(min-width: 720px) 720px\"><figcaption><a href=\"https://plausible.io/rogue-scholar.org\">Daily
        traffic to the Rogue Scholar</a></figcaption></figure> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ The Rogue Scholar is now open for business
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/rogue-scholar-open-for-business/\"
        />\n\t\t<id>https://doi.org/10.53731/z9v2s-bh329</id>\n        <published>2023-04-04T08:43:36.000+00:00</published>\n\t\t<updated>2023-04-04T09:31:14.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://images.unsplash.com/photo-1575663620136-5ebbfcc2c597?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDR8fG9wZW4lMjBmb3IlMjBidXNpbmVzc3xlbnwwfHx8fDE2ODA1OTI3NTU&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://images.unsplash.com/photo-1575663620136-5ebbfcc2c597?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDR8fG9wZW4lMjBmb3IlMjBidXNpbmVzc3xlbnwwfHx8fDE2ODA1OTI3NTU&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"></p><p>The
        <a href=\"https://rogue-scholar.org/\">Rogue Scholar</a> science blog archive
        launched with limited functionality on April 3rd. Interested science blogs
        can go to the sign-up page, provide some basic information via the <a href=\"https://jvinjjenjik.typeform.com/to/uxgAsHPl\">sign-up
        form</a>, and then will be added to the Rogue Scholar archive within two business
        days. </p><p>To be included in the service, your blog needs to:</p><ul><li>be
        about science or scholarship and written in English or German (more languages
        will follow later, reach out to me if you can help),</li><li>make the full-text
        content available via RSS feed and distributed under the terms of the Creative
        Commons Attribution license (<a href=\"https://creativecommons.org/licenses/by/4.0/legalcode\">CC-BY</a>).</li></ul><p>Blogs
        that have signed up for the service (more than twenty so far) are listed in
        the <a href=\"https://rogue-scholar.org/blogs\">Rogue Scholar catalog of science
        blogs</a> that <a href=\"https://doi.org/10.53731/n7vvs-h6995\">launched last
        week</a>. And since yesterday summaries of the latest fifteen blog posts of
        each blog are also available.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2023/04/Bildschirmfoto-2023-04-04-um-10.12.58.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"1882\" height=\"1428\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2023/04/Bildschirmfoto-2023-04-04-um-10.12.58.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/04/Bildschirmfoto-2023-04-04-um-10.12.58.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/04/Bildschirmfoto-2023-04-04-um-10.12.58.png
        1600w, https://blog.front-matter.io/content/images/2023/04/Bildschirmfoto-2023-04-04-um-10.12.58.png
        1882w\" sizes=\"(min-width: 720px) 720px\"><figcaption><a href=\"https://rogue-scholar.org/blogs/pm0p222\">Blog
        posts displayed at the Rogue Scholar</a></figcaption></figure><p>These summaries
        (precisely the information you get in the RSS feed) serve two purposes:</p><ul><li>for
        readers: learn more about that particular science blog. Reading the full-text
        post or other blog posts is only one click away</li><li>for blog authors and
        Rogue Scholar staff: tweak the blog and/or Rogue Scholar if there are issues
        with archiving. </li></ul><p>The screenshot highlights several considerations
        when using the RSS Feed to archive a science blog in the Rogue Scholar:</p><ul><li>optional
        but desired metadata, e.g logo, description, and language for blogs or description,
        tags, and feature image for blog posts</li><li>handling authors, including
        full names instead of usernames, multiple authors, and author identifiers
        (ORCID)</li><li>handling DOIs, including exposing them in the RSS feed, and
        making sure no DOI exists for the post yet</li></ul><p>The Rogue Scholar is
        now open for business, and I hope the limited functionality (or <a href=\"https://www.zentao.pm/blog/mvp-minimum-viable-product-965.html\">minimum
        viable product</a>) launched this week makes it an attractive service for
        blog readers and authors to try out. The next big milestone is the launch
        of the full-text index for searching and archiving, and that is planned to
        happen within the next three months. Followed by DOI registration for blog
        posts.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ The Rogue Scholar releases its first catalog
        of science blogs ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/rogue-scholar-releases-first-catalog/\"
        />\n\t\t<id>https://doi.org/10.53731/n7vvs-h6995</id>\n        <published>2023-03-29T20:46:54.000+00:00</published>\n\t\t<updated>2023-04-04T09:22:41.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://images.unsplash.com/photo-1662582632158-7f0f6e9a617b?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDMzfHxjYXRhbG9nfGVufDB8fHx8MTY4MDEyMTQ2MQ&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://images.unsplash.com/photo-1662582632158-7f0f6e9a617b?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDMzfHxjYXRhbG9nfGVufDB8fHx8MTY4MDEyMTQ2MQ&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"></p><p>The
        Rogue Scholar blog archive today released its <a href=\"https://rogue-scholar.org/blogs\">first
        catalog of science blogs</a>, a total of nineteen science blogs that signed
        up for the Rogue Scholar via <a href=\"https://jvinjjenjik.typeform.com/to/uxgAsHPl\">submission
        form</a> and met the inclusion criteria: </p><ul><li>The blog is about science
        and in English or German (more languages will follow later, reach out to me
        if you can help).</li><li>The full-text content is available via RSS feed
        and distributed using a Creative Commons Attribution license (<a href=\"https://creativecommons.org/licenses/by/4.0/legalcode\">CC-BY</a>).</li></ul><p>The
        Rogue Scholar will launch in the second quarter of this year, and this list
        of science blogs is an important step. The RSS feeds of the included blogs
        will be used to archive content and register DOIs, and they contain important
        information that I will include over time, including license, language, blog
        description, blog logo, contact person, and blogging platform.</p><figure
        class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2023/03/Bildschirmfoto-2023-03-29-um-22.38.08.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"841\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2023/03/Bildschirmfoto-2023-03-29-um-22.38.08.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/03/Bildschirmfoto-2023-03-29-um-22.38.08.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/03/Bildschirmfoto-2023-03-29-um-22.38.08.png
        1600w, https://blog.front-matter.io/content/images/size/w2400/2023/03/Bildschirmfoto-2023-03-29-um-22.38.08.png
        2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Subset of the blogs
        included in the first <a href=\"https://rogue-scholar.org/blogs\">Rogue Scholar
        catalog</a></figcaption></figure><p>The first Rogue Scholar catalog can be
        used as a starting point to find interesting science blogs, but more importantly,
        the catalog is available as an <a href=\"https://doi.org/10.53731/wa7k5-v4t16\">OPML
        file</a> for download and can be imported (and modified) into any blog reader.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Starting the Rogue Scholar OPML Feed ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/starting-the-rogue-scholar-opml-feed/\"
        />\n\t\t<id>https://doi.org/10.53731/wa7k5-v4t16</id>\n        <published>2023-03-22T10:42:17.000+00:00</published>\n\t\t<updated>2023-03-22T10:42:17.000+00:00</updated>\n
        \       <media:content url=\"https://images.unsplash.com/photo-1611864581049-aca018410b97?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDQzfHxmZWVkfGVufDB8fHx8MTY3OTQ3NDc2NQ&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://images.unsplash.com/photo-1611864581049-aca018410b97?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDQzfHxmZWVkfGVufDB8fHx8MTY3OTQ3NDc2NQ&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"></p><p>While
        the launch of the <a href=\"https://rogue-scholar.org/\">Rogue Scholar</a>
        blog archive is still a few months away (happening in the second quarter of
        this year), I want to give an update on the ongoing work.</p><p>The <em>Rogue
        Scholar</em> blog archive will improve science blogs in important ways,<br>including
        full-text search, DOIs and metadata, and long-term archiving. The central
        piece of the underlying infrastructure is the <a href=\"https://inveniosoftware.org/products/rdm/\">InvenioRDM
        </a>open source repository software. Front Matter is one of the organizations
        helping with InvenioRDM development. For the <em>Rogue Scholar,</em> the specific
        work needed includes the following:</p><h3 id=\"support-for-rss-feeds\">Support
        for RSS Feeds</h3><p>All blogs provide RSS feeds, which will be central to
        automatically fetching metadata and content for the <em>Rogue Scholar</em>.
        RSS is not built into InvenioRDM and is not needed by most organizations planning
        to run InvenioRDM. I will therefore build a separate service for this functionality,
        integrating with InvenioRDM via its REST API. For a blog to be archived and
        indexed in the <em>Rogue Scholar</em>, users will use this RSS service, providing
        basic information such as RSS feed URL, language, license, and contact person
        \u2013 basically the information collected for the <em>Rogue Scholar</em>
        <a href=\"https://jvinjjenjik.typeform.com/to/uxgAsHPl?typeform-source=rogue-scholar.org\">waitlist</a>
        (feel free to sign up your blog if you haven't already).</p><p>Next Tuesday
        I will publish an <a href=\"https://en.wikipedia.org/wiki/OPML\">OPML</a>
        (Outline Processor Markup Language) file with all blogs on the <em>Rogue Scholar</em>
        waitlist. OPML is the standard for importing and exporting lists of blogs,
        e.g. when switching from one RSS reader to another. It is a natural fit for
        managing blogs in <em>Rogue Scholar</em>, and hopefully helps people sign
        up for interesting science blogs they want to read. If you are on the <em>Rogue
        Scholar </em>waitlist, please make sure your RSS Feed URL and Home Page URL
        are correct, and \u2013 if you haven't done so already \u2013 pick one (and
        only one) of the top-level categories from the <a href=\"https://www.oecd.org/science/inno/38235147.pdf\">OECD
        Fields of Science and Technology</a>:</p><ul><li>Natural Sciences</li><li>Engineering
        and Technology</li><li>Medical and Health Sciences</li><li>Agricultural Sciences</li><li>Social
        Sciences</li><li>Humanities</li></ul><p>The OPML file (and your RSS reader
        if you import that file) will group science blogs into these categories. Many
        blogs fall into more than one category, but that isn't supported by OPML.
        </p><h3 id=\"hosting-rogue-scholar-infrastructure\">Hosting Rogue Scholar
        infrastructure</h3><p>There are <a href=\"https://inveniordm.docs.cern.ch/install/\">several
        ways</a> to run InvenioRDM repository software, obviously depending on the
        resources available at the hosting organization, and the size and complexity
        of the repository. A small data repository for a university department has
        different needs than <a href=\"https://zenodo.org/\">Zenodo</a>, one of the
        most popular generalist repositories with almost three million records. The
        <em>Rogue Scholar</em> sits in the middle, a small to medium-sized repository,
        anticipating 2,000 to 20,000 blog posts twelve months after launch. InvenioRDM
        relies on <a href=\"https://www.docker.com/\">Docker</a> and Kubernetes for
        running production services. This makes sense for large instances such as
        Zenodo but adds unnecessary complexity to smaller instances such as the <em>Rogue
        Scholar</em>.</p><p>After a substantial amount of deliberation and discussion,
        I decided to use a different approach for the <em>Rogue Scholar</em>, and
        this might potentially be of interest to other organizations planning to use
        InvenioRDM:</p><ul><li>Using virtual machines instead of Docker containers</li><li>Automation
        of virtual machine building with <a href=\"https://www.packer.io/\">Packer</a>
        and <a href=\"https://www.ansible.com/\">Ansible</a></li><li>Hosting of virtual
        machines by cloud provider <a href=\"https://www.digitalocean.com/\">DigitalOcean</a>,
        fundamentally similar to hosting a Wordpress or Ghost blog</li><li>Making
        the automation generic to also work for other InvenioRDM instances, and other
        infrastructure providers, e.g. <a href=\"https://www.openstack.org/\">Openstack</a></li></ul><p>This
        will be the focus of my work in the next three months, and luckily I have
        learned a lot about infrastructure automation in my previous jobs at <a href=\"https://plos.org/\">PLOS</a>
        and <a href=\"https://datacite.org/\">DataCite</a>.</p><h3 id=\"support-for-crossref-doi-registration\">Support
        for Crossref DOI registration</h3><p>By default, InvenioRDM uses DataCite
        DOIs, but <em>Rogue Scholar</em> will use Crossref DOIs for blogs that don't
        already use DOIs. The Crossref pricing is much more favorable for startups
        such as Front Matter, and for annual DOI registration numbers that at least
        initially will be in the 100s or low 1000s. I spent a good part of January
        and February writing a Python scholarly metadata conversion library that I
        released two weeks ago (<a href=\"https://pypi.org/project/commonmeta-py/\">commonmeta-py</a>).
        Among other things, commonmeta-py can read and write Crossref metadata and
        can enable Crossref DOI registrations in InvenioRDM \u2013 which is written
        in Python (and Javascript for the frontend).</p><p>As always, reach out to
        me with questions and comments.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Announcing commonmeta-ruby ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/announcing-commonmeta-ruby/\" />\n\t\t<id>https://doi.org/10.53731/fawv321-14359c4</id>\n
        \       <published>2023-03-20T14:54:00.000+00:00</published>\n\t\t<updated>2023-03-22T12:32:52.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://images.unsplash.com/photo-1676284572206-2501ff5c6956?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDUwfHxiaWtlJTIwbSVDMyVCQ25zdGVyfGVufDB8fHx8MTY3OTMyMTU4MA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://images.unsplash.com/photo-1676284572206-2501ff5c6956?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDUwfHxiaWtlJTIwbSVDMyVCQ25zdGVyfGVufDB8fHx8MTY3OTMyMTU4MA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"></p><p>Following
        recent announcements of the <a href=\"https://commonmeta.org\">commonmeta</a>
        standard for scholarly metadata and a Python package that converts several
        metadata formats (<a href=\"https://github.com/front-matter/commonmeta-py\">commonmeta-py</a>),
        today I am happy to announce <a href=\"https://github.com/front-matter/commonmeta-ruby\">commonmeta-ruby</a>,
        a Ruby gem and command-line tool to convert scholarly metadata using commonmeta
        as the internal format. commonmeta-ruby is based on the <a href=\"https://github.com/datacite/bolognese\">bolognese
        Ruby library</a> that I started a few ago while working at DataCite, but is
        a major rewrite that uses commonmeta as its intermediary conversion format.</p><p>Originally
        planned for later this year, I decided to speed up the release as Ruby version
        2.x (currently 2.7.7) reaches its <a href=\"https://endoflife.date/ruby\">end
        of life</a> this month, and <a href=\"https://rubygems.org/gems/briard\">briard</a>
        (the fork I wrote to support additional metadata conversions such as <a href=\"https://citation-file-format.github.io/\">Citation
        File Format</a> and Crossref DOI registrations) didn't fully work with Ruby
        3.x. In addition to supporting Ruby 3.x and validating with the <a href=\"https://commonmeta.org/schema\">commonmeta
        JSON Schema</a>, commonmeta-ruby dropped support for DataCite XML. The DataCite
        REST API has always been a JSON API, and DOI registration using DataCite XML
        for many years has used JSON under the hood. Metadata conversion using XML
        is painful, and focussing on JSON metadata simplifies further development.</p><p>The
        next steps for commonmeta are:</p><ul><li>Refine the commonmeta-py and commonmeta-ruby
        libraries by adding tests and real-world implementations (such as the DOI
        registration for this blog post, which was done using commonmeta-ruby)</li><li>Work
        towards a commonmeta v1.0 JSON Schema</li><li>Add support for bibliographies
        (lists of resources) to commonmeta.</li><li>Commonmeta implementations in
        additional languages, in particular Javascript/Typescript.</li></ul> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Announcing Commonmeta ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/announcing-commonmeta/\" />\n\t\t<id>https://doi.org/10.53731/cp7apdj-jk5f471</id>\n
        \       <published>2023-03-09T17:36:44.000+00:00</published>\n\t\t<updated>2023-03-09T17:36:44.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2023/03/standards_2x.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2023/03/standards_2x.png\"></p><p>This
        week I launched <strong>Commonmeta</strong>, a new scholarly metadata standard
        described at <a href=\"https://commonmeta.org/\">https://commonmeta.org</a>.
        Commonmeta is the result of working on conversion tools for scholarly metadata
        for many years. One conclusion early on was that these conversions are many-to-many,
        so it becomes much easier to have an internal format that is the intermediate
        step for these conversions.</p><p>Commonmeta is inspired by two initiatives:
        <a href=\"https://codemeta.github.io/\">Codemeta</a> and <a href=\"https://commonmark.org\">Commonmark</a>.
        CodeMeta contributors are creating a minimal metadata schema for science software
        and code, in JSON and XML. The goal of CodeMeta is to create a concept vocabulary
        that can be used to standardize the exchange of software metadata across repositories
        and organizations. Commonmark is a strongly defined, highly compatible specification
        of Markdown, along with a suite of comprehensive tests to validate Markdown
        implementations against this specification. </p><p>These two specifications
        not only inspired the name but also the principles of how I want to see Commonmeta
        operate:</p><ul><li>driven by real-world implementations and not committees</li><li>features
        that focus on what is common in existing implementations/formats</li><li>a
        testable specification</li></ul><p>The website goes into a little bit more
        detail about why I didn't pick any the existing standards but instead came
        up with a new metadata standard. This is a familiar pattern made famous by
        the XKCD comic shown above.</p><p>As I want this to be driven by real-world
        implementations and not committees, I also in the last few weeks launched<a
        href=\"https://github.com/front-matter/commonmeta-py\"> commonmeta-py</a>,
        a Python implementation of the standard available on <a href=\"https://pypi.org/project/commonmeta-py/\">PyPi</a>.
        And in a few months, I hope to have tweaked the <a href=\"https://github.com/front-matter/briard\">Ruby
        Gem</a> that I originally wrote a few years ago to support Commonmeta as the
        internal format.</p><p>With testable specification, I mean both a JSON Schema
        to describe Commonmeta and many, many tests that validate the conversions
        with real-world data. The JSON Schema is available <a href=\"https://commonmeta.org/schema\">here</a>,
        and will become stable once it reaches version 1.0. commonmeta-py comes with
        lots of tests, but I hope to further improve the test coverage.</p><p>Please
        reach out to me if you want to help with Commonmeta, in particular, work on
        implementations in other languages, such as Javascript, PHP, or Java.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Talking about Talbot ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/talking-about-talbot/\" />\n\t\t<id>https://doi.org/10.53731/br4gac1-1k9ptea</id>\n
        \       <published>2023-02-13T19:19:08.000+00:00</published>\n\t\t<updated>2023-02-13T19:20:04.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2023/02/TalbotHound_Talbot_Shrewsbury_Book_1445.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2023/02/TalbotHound_Talbot_Shrewsbury_Book_1445.png\"></p><p><a
        href=\"https://github.com/front-matter/talbot\">Talbot</a> is a Python package
        I started working on at the end of 2022 and plan to release to the Python
        Package Index (<a href=\"https://pypi.org/\">PyPi</a>) in March. Talbot converts
        scholarly metadata in various formats, including Crossref, DataCite, Schema.org,
        BibTeX, RIS, and formatted citations \u2013 the complete list of supported
        formats is <a href=\"https://docs.front-matter.io/talbot#supported-metadata-formats\">here</a>.
        Talbot is a Python version of the <a href=\"https://github.com/datacite/bolognese\">Bolognese
        Ruby gem</a> that I worked on with my DataCite colleagues starting in 2018.
        After leaving DataCite in 2021 I <a href=\"https://doi.org/10.53731/rdv0jyq-vpb7a9j-zwqzg\">wrote
        a fork called Briard</a> that added important metadata conversions, namely
        writing Crossref XML for DOI registration and reading/writing Citation File
        Format (<a href=\"https://citation-file-format.github.io/\">CFF</a>) for software
        metadata.</p><p>Talbot, Bolognese, and Briard are all names for dog breeds,
        the naming convention I have used for most of the Open Source software I have
        written since releasing the Open Source software <a href=\"https://github.com/lagotto/lagotto\">Lagotto</a>
        for tracking article-level metrics in 2012.</p><p>My two main use cases for
        Talbot (and Bolognese) are <a href=\"https://citation.crosscite.org/docs.html\">DOI
        content negotiation</a>, using DOI metadata to generate metadata in other
        formats such as BibTeX or as formatted citation in one of the thousands of
        available citation styles. The Python version will enhance the <a href=\"https://inveniordm.docs.cern.ch/\">InvenioRDM</a>
        Open Source repository platform, e.g. adding RIS and Schema.org JSON-LD to
        the supported export formats. The other main use case is supporting DOI registration
        via multiple input formats. Since 2021 the Briard gem for example allows me
        to register DOIs for this blog as well as the <a href=\"https://upstream.force11.org/\">Force11
        Upstream blog</a> using metadata in Schema.org format. With Talbot I want
        to enable Crossref DOI registration in the InvenioRDM platform for use cases
        where this makes sense, e.g blog posts or preprints. Talbot will help register
        DOIs from RSS feeds as part of <a href=\"https://rogue-scholar.org/\">the
        Rogue Scholar </a>blog archive I am launching in Q2 2023. </p><p>One lesson
        learned with Bolognese/Briard is that the platform/language matters. The InvenioRDM
        backend is written in Python (the Frontend is in Javascript/React). And while
        Bolognese/Briard can be used via the command line or in environments such
        as GitHub Actions that use Docker-based microservices where the language doesn't
        really matter, having the scholarly metadata conversion available in a Python
        environment makes a huge difference. So I took the plunge of rewriting a fairly
        complex library in another language. I am fully aware that there are more
        languages used for writing scholarly infrastructure code, but for the next
        few years, Python addresses my needs and is hopefully useful to other infrastructure
        projects.</p><p>While the overall architecture for the evolving Talbot library
        looks rather similar to Briard, I am making some changes based on my experience
        over the last five years of working on generic scholarly metadata conversions:</p><ul><li><strong>JSON
        is the core serialization format</strong>. Metadata in XML format (e.g. DataCite,
        Crossref, JATS) are important, but no longer used internally for Talbot validation.
        I will instead migrate to JSON schema for metadata validations in Talbot.
        DataCite, Crossref, and InvenioRDM use Elasticsearch/OpenSearch and thus JSON
        to index metadata. DataCite XML is still widely used but deprecated for several
        years, as on submission the XML is converted to JSON internally.</li><li><strong>Type
        hints. </strong>Support for static typing is a trend in dynamic languages
        Javascript (where Typescript is very popular), Ruby (since Ruby 3.0), and
        also Python. Talbot uses type hints for linting and that helps with error
        checking.</li><li><strong>Support unstructured references</strong>. Before
        DataCite Metadata Schema 4.4 (released in April 2021), only references providing
        an identifier such as a DOI were supported. Crossref has always supported
        unstructured references, and an identifier isn't available unless content
        exists in digital form. In the first Talbot release, I take the \"fallback
        solution\" approach, providing unstructured metadata if a DOI or other persistent
        identifier for a reference doesn't exist.</li><li><strong>Author names are
        hard</strong>. One of the biggest challenges with scholarly metadata is author
        names. In formatted citations and BibTeX separate given and family names are
        important, and a single name field for both given and family names is a constant
        source of errors and frustrations. In Talbot I follow both Crossref and Citeproc
        JSON metadata in that you need either a single name or separate given and
        family names.</li><li><strong>Dates are hard</strong>. Dates are surprisingly
        hard in scholarly metadata. There are multiple kinds of dates not always used
        consistently, and incomplete dates such as year-only are very common. One
        approach to dealing with incomplete dates is encoding the parts year, month,
        and day separately, used by Citeproc JSON and Crossref in their REST API.
        The better solution is to use the ISO8601 standard that supports incomplete
        dates. Other challenges are approximate dates (e.g. <em>circa 1650</em>) and
        date ranges. These kinds of dates are supported via the Extended Date and
        Time Format (<a href=\"https://www.loc.gov/standards/datetime/\">EDTF</a>),
        but working with EDTF is hard in code.</li><li><strong>Idiosyncrasies and
        inconsistencies</strong>. There is always a balancing act between supporting
        a metadata standard thoughtfully and not getting lost in edge cases. DataCite
        metadata (via Dublin Core on which it is based) makes it hard to work with
        some of the bibliographic metadata common for books, articles, and other textual
        resources. For example page numbers or the journal name. Crossref metadata
        has the tendency to treat things differently depending on the content type,
        e.g. the ISSN. After working on Bolognese for five ideas I will make some
        changes to how to best support metadata across different formats. It is clear
        that there is no single overarching scholarly metadata format, the internal
        format used by Bolognese, Briard, and now Talbot is a pragmatic mix of the
        different implementations.</li></ul> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Guidelines for Scholarly Blogs ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/guidelines-for-scholarly-blogs/\"
        />\n\t\t<id>https://doi.org/10.53731/a0d9m3n-n7r8h0m</id>\n        <published>2023-02-06T11:52:24.000+00:00</published>\n\t\t<updated>2023-02-06T11:52:24.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://images.unsplash.com/photo-1584631277142-0ca0cfc76aec?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDZ8fGd1aWRlbGluZXxlbnwwfHx8fDE2NzU2ODM0NDc&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://images.unsplash.com/photo-1584631277142-0ca0cfc76aec?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDZ8fGd1aWRlbGluZXxlbnwwfHx8fDE2NzU2ODM0NDc&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"></p><p>These
        guidelines are recommendations for authors of scholarly blogs to help with
        long-term archiving, discoverability, and citation of blog content.<br>They
        are modeled after the publication <a href=\"https://doi.org/10.1038/s41597-019-0031-8\">A
        Data Citation Roadmap for Scholarly Data Repositories</a>, where many of the
        same guidelines apply, and where I was the first author and <a href=\"https://force11.org/group/data-citation-implementation-group/\">co-chair
        of the corresponding Force11 working group.</a></p><p>These guidelines focus
        on the required or recommended work for scholarly blog authors. For scholarly
        blog archives such as the <a href=\"https://rogue-scholar.org\">Rogue Scholar</a>,
        additional guidelines are in development.</p><!--kg-card-begin: html--><table>\n<thead>\n<tr>\n<th>Level</th>\n<th
        style=\"text-align: right\">#</th>\n<th>Guideline</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Required</td>\n<td
        style=\"text-align: right\">1</td>\n<td>The full-text content <em>must</em>
        be made available via public RSS feed (in RSS, Atom or JSON Feed format).</td>\n</tr>\n<tr>\n<td>Required</td>\n<td
        style=\"text-align: right\">2</td>\n<td>Each blog post in the RSS feed <em>must</em>
        have a title, author(s), and publication date.</td>\n</tr>\n<tr>\n<td>Required</td>\n<td
        style=\"text-align: right\">3</td>\n<td>Each blog post <em>must</em> have
        a URL that resolves to a public landing page specific for that blog post.</td>\n</tr>\n<tr>\n<td>Required</td>\n<td
        style=\"text-align: right\">4</td>\n<td>The full-text content <em>must</em>
        be made available via a Creative Commons Attribution (CC-BY) license.</td>\n</tr>\n<tr>\n<td>Required</td>\n<td
        style=\"text-align: right\">5</td>\n<td>The blog must provide documentation
        about long-term archiving, discoverability, and citation.</td>\n</tr>\n<tr>\n<td>Recommended</td>\n<td
        style=\"text-align: right\">6</td>\n<td>Each blog post in the RSS feed <em>should</em>
        have a persistent identifier, description, language, and last updated date.</td>\n</tr>\n<tr>\n<td>Recommended</td>\n<td
        style=\"text-align: right\">7</td>\n<td>The landing page <em>should</em> include
        metadata required for citation, and ideally also metadata facilitating discovery,
        in human-readable and machine-readable format.</td>\n</tr>\n<tr>\n<td>Recommended</td>\n<td
        style=\"text-align: right\">8</td>\n<td>The machine-readable metadata <em>should</em>
        use schema.org markup in JSON-LD format.</td>\n</tr>\n<tr>\n<td>Recommended</td>\n<td
        style=\"text-align: right\">9</td>\n<td>Metadata <em>should</em> be made available
        via HTML meta tags to facilitate use by reference managers.</td>\n</tr>\n<tr>\n<td>Recommended</td>\n<td
        style=\"text-align: right\">10</td>\n<td>Metadata <em>should</em> be made
        available for download in BibTeX and/or another standard bibliographic format.</td>\n</tr>\n</tbody>\n</table><!--kg-card-end:
        html--><p>The requirement for full-text content via RSS feed and with a CC-BY
        license comes from the need to make archiving and indexing as simple (and
        cheap) as possible. Dealing with multiple licenses, private feeds, and private
        content adds an extra level of complexity and is not supportive of Open Science.</p><p>Metadata
        via HTML meta tags and JSON-LD (using schema.org markup) are two main strategies
        to embed metadata in web pages, to support reference managers but also indexers.
        Schema.org is simpler to work with, e.g. for more complex author information
        such as separate given and family names, author identifiers such as ORCID,
        and affiliation information. On the other hand, reference managers and Google
        Scholar currently use HTML meta tags, and it is sometimes easier to add this
        information to a blog.</p><p>Registration of DOIs as other persistent identifiers
        for blog posts is something that I want to provide via the Rogue Scholar archive,
        as the effort required is not trivial. The information required (mainly title,
        author(s), publication date, and URL) is readily available via the RSS feed.
        Of course, displaying these DOIs on the blog is recommended, and for the DOIs
        to resolve to the blog itself rather than the blog archive at the Rogue Scholar
        or elsewhere.</p><p>The recommended or optional metadata for science blog
        posts is of course a big topic that needs more discussion. Description, language,
        and last updated date seem desired and readily available. References used
        in blog posts would be fantastic to be included in the metadata, but there
        is currently no easy and standard way of doing this. For better discoverability,
        it would make sense to provide geo coordinates and/or temporal information,
        and all blogs would benefit from using subject classification such as the
        <a href=\"https://www.oecd.org/science/inno/38235147.pdf\">OECD Fields of
        Science and Technology</a>, but all this would require significantly more
        effort.</p><p>These guidelines are a work in progress and are made available
        as part of the <a href=\"https://docs.rogue-scholar.org/guidelines\">Rogue
        Scholar Documentation</a>. Feedback is greatly appreciated.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Launching the Front Matter Gazette ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/launching-the-front-matter-gazette/\"
        />\n\t\t<id>https://doi.org/10.53731/88drdpz-znvdjr9</id>\n        <published>2023-01-30T12:48:26.000+00:00</published>\n\t\t<updated>2023-01-30T12:48:26.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://images.unsplash.com/photo-1521134976835-9963f2185519?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDE2fHxqb3VybmFsfGVufDB8fHx8MTY3NTAxMzMwNA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://images.unsplash.com/photo-1521134976835-9963f2185519?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDE2fHxqb3VybmFsfGVufDB8fHx8MTY3NTAxMzMwNA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"></p><p>On
        Wednesday this week I am launching the <em>Front Matter Gazette</em>, a weekly
        newsletter that highlights exciting science stories from around the web. The
        linked content highlighted in the newsletter is published elsewhere and is
        free to read whenever possible. The newsletter requires a paid subscription
        (<a href=\"https://blog.front-matter.io/#/portal/signup\">available here</a>),
        5 \u20AC/month or 50 \u20AC/year with a thirty-day free trial and free subscriptions
        on request. The subscription fees help pay for the curation effort \u2013
        finding and summarizing the most exciting science stories. </p><h3 id=\"why-do-we-need-to-highlight-the-most-interesting-science\">Why
        do we need to highlight the most interesting science?</h3><p>With the <em>Front
        Matter Gazette,</em> I try a new approach to addressing an old problem: information
        overload.</p><figure class=\"kg-card kg-embed-card kg-card-hascaption\"><iframe
        width=\"200\" height=\"150\" src=\"https://www.youtube.com/embed/LabqeJEOQyI?feature=oembed\"
        frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media;
        gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Web 2.0
        Expo NY: Clay Shirky (shirky.com) It&#39;s Not Information Overload. It&#39;s
        Filter Failure.\"></iframe><figcaption>Web 2.0 Expo NY: Clay Shirky (shirky.com)
        It's Not Information Overload. It's Filter Failure.</figcaption></figure><p>The
        approach traditionally often used in science has been to use journals as a
        filter. There are many reasons why this approach has failed, described for
        example in <a href=\"https://asapbio.org/addressing-information-overload-in-scholarly-literature\">this
        2021 post on the ASAPbio blog</a> by Christine Ferguson and me. Three important
        limitations are:</p><ul><li><strong>Delays</strong>. The time from submission
        to publication for peer-reviewed journal articles can be significant, which
        causes critical issues in situations that need quick actions based on science
        such as in the COVID pandemic, but also for early career researchers.</li><li><strong>Focus
        on the journal article</strong>. Journal articles are the main channel of
        scientific communication in many disciplines, but large parts of scholarship
        focus on something else, for example, conference proceedings in computer science
        or books in the humanities. In addition, newer outputs of scholarship such
        as research data or software source code are left out or only captured <em>by
        proxy</em>, publishing journals with articles describing software or data.</li><li><strong>Not
        Open Science</strong>. Leaving the decision to what is important in science
        to journal publishers, often commercial, instead of the scientists themselves,
        is the wrong choice as other interests interfere, and marginalized communities
        and regions are left out not only of science publishing but also of what science
        is highlighted and promoted.</li></ul><p>Two alternative approaches to journals
        as a filter are <strong>automation</strong> and <strong>curation</strong>.
        In the ASAPbio blog post mentioned earlier, Christine and I discussed an automation
        approach we tried out in 2021, filtering relevant biomedical preprints by
        the attention they received on Twitter immediately after publication. We have
        not continued this activity beyond early 2022 for two reasons: a) I spent
        the first <a href=\"https://doi.org/10.53731/bkkzj8g-gd14mb6\">five months
        of 2022 in the hospital</a>, and b) in November 2022 I left Twitter and moved
        to <a href=\"https://hachyderm.io/@mfenner\">Mastodon</a> after the change
        in Twitter ownership.</p><p>There are many initiatives in this space that
        try to use computer algorithms to find the most relevant scholarly content,
        but Christine and I felt that this was only the first step and that <strong>curation</strong>
        was key to finding what is interesting and relevant. Curation is what journal
        editors have always done, and what is helped with peer review since it became
        increasingly required in the 1960s, but when curation is used to find what
        is interesting and relevant, and not what should be published, there is no
        longer a need to leave the curation exclusively up to journals.</p><p>An Open
        Science approach to curation has many elements, but a newsletter feels like
        a good fit. It is a low-tech approach that works even for the busiest scientists,
        and it can be combined with the automation approaches discussed earlier. And
        curated newsletters about Science and Scholarship work with preprints, research
        data, source code, and other forms of scholarship. A related activity, no
        longer so low-tech, is science podcasts, which arguably are currently more
        popular than science newsletters.</p><h3 id=\"and-who-is-going-to-pay-for-this\">And
        who is going to pay for this?</h3><p>There are two elephants in the room for
        paying for this activity: advertising and grant funding. Advertising is not
        only a frustrating experience for readers and authors, but also doesn't really
        work in a niche market such as science. The current issues at the German <a
        href=\"https://scienceblogs.de/\">scienceblogs.de</a> are only the latest
        example of the difficulties sustaining science blogging infrastructure.</p><p>Grant
        funding is a well-established strategy to pay for Open Science activities,
        but has two major limitations: a) it is not a good fit for the long tail of
        science (Front Matter for example is not (yet) a non-profit organization because
        the time and money required to start a non-profit in Germany are far from
        trivial), and b) grant funding likes to pay for innovation and research, getting
        funding for open scholarly infrastructure is much harder.</p><p>Of course
        Front Matter is open for startup funding for the <em>Front Matter Gazette</em>,
        but it should not be a requirement to get the <em>Gazette</em> started, and
        I can not promise any financial returns for an investment.</p><p>Paying even
        a small fee of 5 \u20AC per month for a useful Open Science resource can be
        a hurdle, as <a href=\"https://blog.impactstory.org/subscription-announcement\">Impactstory
        can attest</a>. That is why we offer a no-questions-asked fee waiver, and
        why we start the Gazette as an experiment where we don't know the outcome
        yet.</p><h3 id=\"will-the-front-matter-gazette-work\">Will the Front Matter
        Gazette work?</h3><p>Only time will tell whether the Gazette can attract enough
        readers to become a sustainable operation, and I will work on the Gazette
        until 2024 to make that call. The <a href=\"https;//ghost.org\">Ghost publishing
        platform</a> powering this blog since 2021 is for people who believe in this
        vision (mostly in domains other than science):</p><blockquote>Ghost is a powerful
        app for new-media creators to publish, share, and grow a business around their
        content. It comes with modern tools to build a website, publish content, send
        newsletters &amp; offer paid subscriptions to members. \u2013 <a href=\"https://ghost.org/\">Ghost
        Homepage</a></blockquote><p>Future plans for the <em>Front Matter Gazette</em>
        in case of a successful start focus on expanding the coverage \u2013 five
        stories a week is not even the tip of the iceberg of what's happening every
        week in scholarship.</p><h3 id=\"what-is-the-relationship-to-the-rogue-scholar\">What
        is the relationship to the Rogue Scholar?</h3><p><a href=\"https://rogue-scholar.org/\">The
        Rogue Scholar</a> is a science blog archive that I am working on and plan
        to launch in Q2 2023. Making sure that science blogs can be found over time
        with the help of full-text search, DOIs plus metadata, and long-term archiving
        is the first critical step. Using this open content in creative ways is the
        next step, and curation is one important aspect that I try to start addressing
        with the <em>Front Matter Gazette</em>. The <em>Front Matter Gazette</em>
        will highlight all kinds of scholarly content, not just blogs, and not only
        content archived in the Rogue Scholar, but there are of course synergies that
        I will try to explore.</p><h3 id=\"what-is-in-the-first-issue-of-the-front-matter-gazette\">What
        is in the first issue of the Front Matter Gazette?</h3><p>In the February
        1st issue I will talk about Neanderthal families, ChatGPT in science publishing,
        the Tidyverse, eradicating an infectious disease, and medieval manuscripts.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Do we need to fix science blogs? ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/need-to-fix-science-blogs/\" />\n\t\t<id>https://doi.org/10.53731/avg2ykg-gdxppcd</id>\n
        \       <published>2023-01-25T15:14:17.000+00:00</published>\n\t\t<updated>2023-09-07T21:26:13.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://images.unsplash.com/photo-1585838017777-5003198884b5?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDMyfHxicm9rZW58ZW58MHx8fHwxNjc0NjUyMTEy&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://images.unsplash.com/photo-1585838017777-5003198884b5?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDMyfHxicm9rZW58ZW58MHx8fHwxNjc0NjUyMTEy&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"></p><p>Science
        blogs have been around for at least 20 years and have become an important
        part of science communication. So are there any fundamental issues that need
        fixing?</p>\n<h3 id=\"barriers-to-entry\">Barriers to Entry</h3>\n<p>Blogging
        platforms are mature at this point, and the technology is not imposing barriers
        to entry for most people. The user experience has greatly improved over the
        last few years and there are a number of affordable ways for hosting a blog
        that also work for science blogs, including free options such as <a href=\"https://pages.github.com/\">GitHub
        Pages</a>.</p>\n<h3 id=\"open-access\">Open Access</h3>\n<p>Science blogs
        have traditionally been free to read, but there is a general trend towards
        subscriptions for blogs (and related newsletters), as the advertising business
        model isn't really working for niche content such as most science. How to
        sustain science blogging in the long run is an unresolved question, and charging
        authors (beyond a nominal hosting fee) doesn't look like a path forward. Luckily
        the costs of publishing science blogs are very reasonable compared to journal
        publishing or hosting research data and code.</p>\n<h3 id=\"missing-functionality\">Missing
        Functionality</h3>\n<p>The basic functionality of formatted text with embedded
        figures and links is supported by many blogging platforms. The requirements
        of data-intensive science, e.g. interactive visualizations, can be a challenge,
        but that is also true for publishing journal articles. Interactive environments
        such as <a href=\"https://jupyter.org/\">Jupyter Notebooks</a> might be a
        better fit for these use cases. </p>\n<p>Reference management is probably
        the biggest gap in science blogging, as handling more than a few references
        in standard ways is not easily done by hand.</p>\n<h3 id=\"impact-or-credit\">Impact
        or Credit</h3>\n<p>Unfortunately a lot of the activities of scholars are driven
        by perceived <em>Impact </em>or<em> Credit</em>, and science blogs typically
        don't score high in this regard \u2013 with the exception of some disciplines
        such as mathematics. There is probably no short-term solution, and I am not
        even sure it is a problem that needs fixing. </p>\n<p>The long-term solution
        should focus on increasing the visibility and thus discoverability of science
        blogs to reach a larger audience. As I discussed in a <a href=\"https://doi.org/10.53731/br9f5xa-a556w2t\">previous
        post</a>, my preferred approach is a central repository for science blog content
        originally published in many different locations (the PubMed/PubMed Central)
        model.</p>\n<h3 id=\"persistence\">Persistence</h3>\n<p>This leaves persistence
        as the other main problem with science blogs besides discoverability that
        needs fixing. Link rot (the resource identified by a URI vanishes from the
        web) and content drift (the resource identified by a URI changes over time)
        are <a href=\"https://ceur-ws.org/Vol-3246/10_Paper3.pdf\">well-known problems
        with digital content</a>, from <a href=\"https://www.theverge.com/2021/5/21/22447690/link-rot-research-new-york-times-domain-hijacking\">newspapers</a>
        to scholarly content. There are mainly two approaches to address this problem:</p>\n<ul><li><strong>Archiving</strong>
        using generic services such as the <a href=\"https://archive.org/\">Internet
        Archive</a> and specialized services such as <a href=\"https://www.softwareheritage.org/\">Software
        Heritage</a> for software source code or <a href=\"https://www.portico.org/\">Portico</a>
        for scholarly content.</li><li><strong>Persistent Identifiers</strong> by
        maintaining links independent of URL host and path, both of which may change
        over time. This <a href=\"https://doi.org/10.53731/r294649-6f79289-8cw1h\">blog
        post of mine</a> is almost 14 years old, and the URL has changed at least
        four times as I changed blogging platforms. Since 2021 the post has had a
        persistent identifier in form of a DOI, and that DOI will not change going
        forward, eventually pointing to an archive when I retire.</li></ul>\n<p>Some
        science blog content is ephemeral and may not be worth archiving, but a lot
        of content is still worth reading years later (the <a href=\"ttps://doi.org/10.53731/r294649-6f79289-8cw1q\">first
        post of this blog</a> is more than 15 years old), even if only to provide
        historical context.</p>\n<h3 id=\"conclusions\">Conclusions</h3>\n<p>In summary,
        we don't need to <em>fix everything</em> with science blogs but rather focus
        on two aspects: discoverability and persistence. In doing that we also need
        to sort out better sustainability for science blogs, and as an added bonus
        improve their reference management.</p>\n<p>Discoverability and persistence
        are an issue for all science blogs, and we are trying to fix them by launching
        the <a href=\"https://rogue-scholar.org/\">Rogue Scholar</a> in the second
        quarter of 2023. If you are managing a science blog and care about discoverability
        and persistence, sign up for the <a href=\"https://rogue-scholar.org/\">Rogue
        Scholar waitlist</a>. Particularly if your blog is no longer actively maintained,
        for example, blogs hosted by grant-funded projects that have ended or are
        ending soon.</p>\n<p>Today I launched the <a href=\"https://docs.rogue-scholar.org\">Rogue
        Scholar Documentation</a> site, where I will document how to use the Rogue
        Scholar, e.g. what you can do to prepare your science blog for Rogue Scholar
        archiving. The site is written in markdown and hosted on GitHub, so feel free
        to ask questions or suggest additions via the links provided by the documentation
        site.</p>\n<h3 id=\"references\">References</h3>\n<p>Fenner, M. (2009). <em>Interview
        with Geoffrey Bilder</em>. <a href=\"https://doi.org/10.53731/r294649-6f79289-8cw1h\">https://doi.org/10.53731/r294649-6f79289-8cw1h</a></p>\n<p>Fenner,
        M. (2007). <em>Open access may become mandatory for NIH-funded research</em>.
        <a href=\"https://doi.org/10.53731/r294649-6f79289-8cw1q\">https://doi.org/10.53731/r294649-6f79289-8cw1q</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ RSS, Atom, JSON Feed ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/rss-atom-jsonfeed/\" />\n\t\t<id>https://doi.org/10.53731/d6vdvbt-tffmezj</id>\n
        \       <published>2023-01-16T16:57:54.000+00:00</published>\n\t\t<updated>2023-01-16T17:06:53.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://images.unsplash.com/photo-1597092451116-27787c07901d?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDJ8fGFyY2hpdmV8ZW58MHx8fHwxNjczODg2NDI2&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://images.unsplash.com/photo-1597092451116-27787c07901d?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDJ8fGFyY2hpdmV8ZW58MHx8fHwxNjczODg2NDI2&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"></p><p>As
        I discussed in a <a href=\"https://doi.org/10.53731/eyf75cj-jsgv26c\">recent
        post</a>, RSS is an essential building block for the upcoming <a href=\"https://rogue-scholar.org\">Rogue
        Scholar</a> Scholarly Blog Archive. RSS makes it easy to import blog posts
        (both metadata and content) automatically and is supported by all blogging
        platforms. This kind of automation is critical to keep the costs of running
        the Rogue Scholar low, allowing it to scale to cover a substantial number
        of science blog posts, and hopefully becoming an important Open Science resource.</p><p>But
        there are also challenges with using RSS:</p><ul><li>RSS is not a single standard
        but comes in multiple flavors: multiple versions of RSS, Atom, and the newer
        <a href=\"https://www.jsonfeed.org/\">JSON Feed</a>. Most libraries for consuming
        RSS (e.g. the Python <a href=\"https://github.com/kurtmckee/feedparser\">feedparser</a>)
        can handle RSS and Atom, and fewer tools (e.g. the Python <a href=\"https://pypi.org/project/reader/\">feeder</a>)
        also support the newer JSON Feed.</li><li>The Rogue Scholar will use the <a
        href=\"https://inveniordm.docs.cern.ch/\">InvenioRDM</a> open source platform,
        which uses <a href=\"https://opensearch.org/\">OpenSearch</a> to index content
        and metadata. OpenSearch \u2013 just like Elasticsearch on which it is based
        \u2013 works with JSON. Indexing and archiving science blogs therefore should
        first convert RSS and Atom feeds onto JSON, and JSON Feed, <a href=\"https://www.jsonfeed.org/mappingrssandatom/\">which
        has been mapped from RSS and Atom</a>, is the obvious choice.</li><li>Some
        blogs prefer to only publish summaries in their RSS feeds, there have been
        many discussions on this topic over the years. It would complicate the operation
        of the Rogue Scholar if full-text content has to retrieved by other means,
        and archiving full-text content is the primary goal for the Rogue Scholar.
        The Rogue Scholar needs one feed that provides the full-text content, it doesn't
        have to be the default blog feed.</li><li>Blogs, in particular personal blogs,
        may publish content that is out of the scope of the main science topics of
        the blog. Occasional out-of-scope posts, e.g. talking about major events such
        as job changes, sickness, or travel, are probably ok, and add a personal note.
        If this is frequently the case, and this has come up twice in initial Rogue
        Scholar discussions, it probably makes sense to provide a filtered RSS feed
        (e.g. using tags) with only a subset of posts.</li><li>Describing a blog and
        associated metadata (e.g. name, feed URL, language, license, contact) is not
        something that easily maps how InvenioRDM is modeled. The obvious choice would
        be <a href=\"https://inveniordm.web.cern.ch/communities\">communities</a>,
        but they can also be seen as a higher level of aggregation, e.g. all blog
        posts about biodiversity independent of the blog source. For now I will work
        with communities and enhance the InvenioRDM functionality where it also makes
        sense for other InvenioRDM use cases, of course coordinating with the InvenioRDM
        community.</li></ul><p>Two weeks ago I opened up the <a href=\"https://jvinjjenjik.typeform.com/to/uxgAsHPl\">waitlist</a>
        for the Rogue Scholar, and I am happy with the feedback I have received so
        far: sixteen submissions and a number of encouraging discussions. Consider
        adding your science blog to the waitlist, or learn more at the <a href=\"https://rogue-scholar.org\">Rogue
        Scholar</a> website. If you have questions, post them in the comments or join
        the <a href=\"https://discord.gg/wZcqPt4p\">Discord channel </a>(renamed from
        Front Matter to Rogue Scholar).</p><p>It has not escaped our notice that the
        specific use of RSS we have postulated immediately suggests a possible mechanism
        for the archiving and DOI registration of other scholarly content.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Sign up for the science blog archive waitlist
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/science-blog-archive-waitlist/\"
        />\n\t\t<id>https://doi.org/10.53731/cbvm43q-qdk3s1s</id>\n        <published>2023-01-02T11:31:52.000+00:00</published>\n\t\t<updated>2023-01-02T11:31:52.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://images.unsplash.com/photo-1577046823799-58b2d217d508?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDZ8fGhhcHB5JTIwbmV3JTIweWVhcnxlbnwwfHx8fDE2NzI2NTY4MzQ&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://images.unsplash.com/photo-1577046823799-58b2d217d508?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDZ8fGhhcHB5JTIwbmV3JTIweWVhcnxlbnwwfHx8fDE2NzI2NTY4MzQ&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"></p><p>The
        science blog archive that I have started to work on (<a href=\"https://doi.org/10.53731/eyf75cj-jsgv26c\">see
        previous posts</a>) finally has a name: the <em>Rogue Scholar</em>. I picked
        this name because I liked the description in the <a href=\"https://www.urbandictionary.com/define.php?term=rogue%20scholar\">Urban
        Dictionary</a>.</p><blockquote>A person with extensive knowledge pertaining
        to various subject matters that extends beyond formal education. This person
        often <strong>gathers</strong> knowledge from various sources, such as media,
        friends, casual reading or the internet.</blockquote><p>And I started a waitlist
        for people interested in having their science blog archived in the <em>Rogue
        Scholar</em>. There is still a lot of work to do, but I hope to launch the
        archive in the second quarter of 2023 with these core features:</p><ul><li>based
        on the <a href=\"https://inveniordm.docs.cern.ch/\">InvenioRDM</a> open source
        software, hosted by Front Matter</li><li>free to archive 50 blog posts per
        year. For larger blogs or a backfile of several years, the Rogue Scholar will
        charge a one-time fee of 1 \u20AC per blog post, and I have started to work
        on securing additional funding for this.</li><li>Full-text search of blog
        content, typically not available on self-hosted blogs</li><li>DOI registration
        for blog posts, facilitating discovery and integration of blogs into the scholarly
        record</li><li>free to read and reuse forever, using the Creative Commons
        Attribution (<a href=\"https://creativecommons.org/licenses/by/4.0/\">CC-BY</a>)
        license</li><li>initially support English and German language posts</li></ul><p>The
        form to sign up for the waitlist is available <a href=\"https://jvinjjenjik.typeform.com/to/uxgAsHPl\">here</a>.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Building Blocks for a Scholarly Blog Archive
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/building-blocks/\"
        />\n\t\t<id>https://doi.org/10.53731/eyf75cj-jsgv26c</id>\n        <published>2022-12-21T14:23:47.000+00:00</published>\n\t\t<updated>2022-12-21T20:57:38.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/12/James_Brown_-55208420--1.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/12/James_Brown_-55208420--1.jpeg\"></p><p>Another
        follow-up post, extending three earlier posts (see references), on the Scholarly
        Blog Archive that Front Matter is building and that I plan to launch in the
        first half of 2023. I have been thinking about the building blocks that make
        this blog archive work:</p><h3 id=\"diamond-open-access\">Diamond Open Access</h3><blockquote>Diamond
        open access (OA) is an open access business model in which no fees are charged
        to either authors or readers. <a href=\"https://www.dfg.de/en/research_funding/announcements_proposals/2022/info_wissenschaft_22_26/index.html\">German
        Research Foundation</a></blockquote><p>Using this term sounds strange in the
        context of scholarly blog posts, but it means that scholarly blog infrastructure
        should be free to publish and free to read. One challenge with Open Access
        for publications, particularly in disciplines such as medicine and life sciences
        where there is a lot of money, is that there are no drivers for driving down
        cost, and subscription fees have often been converted to article processing
        charges (APC). And instead of technological advances making scholarly publishing
        cheaper over time, the costs for authors and readers (and their institutions
        and funders who ultimately pay for this) are only increasing.</p><p>There
        is of course already a lot of Diamond Open Access, and infrastructures for
        research data and research software also typically don't charge authors or
        readers. This causes other problems in terms of sustainable scholarly infrastructure
        and innovation, but I think it is an essential building block for the science
        blog archive Front Matter is building. A lot of work is needed in 2023 to
        come up with a strategy for sustaining the Front Matter science blog archive
        in the long run, all I can say now is that it will not use advertising.</p><h3
        id=\"creative-commons-license\">Creative Commons License</h3><p>For content
        that is free to read we need a license that specifies that. The blog archive
        needs clear conditions for what it can do with the content, and the same is
        true for downstream users and services. History tells us that licenses should
        be clear and simple, so for scholarly blog posts I will aim to use the <a
        href=\"https://creativecommons.org/licenses/by/4.0/legalcode\">Creative Commons
        Attribution 4.0 License</a> (CC-BY 4.0) for all content. </p><figure class=\"kg-card
        kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/12/cc-by.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"250\" height=\"88\"></figure><h3
        id=\"central-blog-archive\">Central Blog Archive</h3><p>As I <a href=\"https://doi.org/10.53731/br9f5xa-a556w2t\">explained
        in a post last week</a>, a central blog archive for blog content published
        in many different places makes the most sense for science blog posts \u2013
        a model also used by <a href=\"https://www.ncbi.nlm.nih.gov/pmc/\">PubMed
        Central </a>for a free full-text archive of biomedical and life sciences journal
        articles. The <a href=\"https://inveniordm.docs.cern.ch/\">InvenioRDM</a>
        Open Source software is a good fit for this use case.</p><figure class=\"kg-card
        kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/12/Download--4--1.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"372\" height=\"120\"></figure><p>Starting
        a science blog is straightforward. There are plenty of cheap and free options
        available from <a href=\"https://wordpress.org/\">Wordpress</a> to <a href=\"https://pages.github.com/\">GitHub
        Pages</a>. You might run your blog as part of a larger platform, together
        with collaborators, or all for yourself.</p><h3 id=\"digital-object-identifier-doi-and-metadata\">Digital
        Object Identifier (DOI) and Metadata</h3><p>DOIs are frequently used as persistent
        identifiers for scholarly content and are integrated into the InvenioRDM platform.
        The blog archive can either archive blog posts with DOIs, or it can issue
        DOIs for existing blogs not using DOIs. In the latter case it is important
        that the DOI resolves to the original content in the hosting blog platform,
        and redirects to the blog platform only when the original blog is no longer
        available. </p><p>DOIs (e.g. from DataCite or Crossref) have a required set
        of metadata that makes sense for scholarly blogs. Optional metadata that are
        desired for the blog archive are license (see above), abstract, subject area
        (using the 43 <a href=\"https://en.wikipedia.org/wiki/Fields_of_Science_and_Technology\">OECD
        Fields of Science and Technology</a>), keywords, language, and persistent
        identifiers for the blog (<a href=\"https://www.issn.org/\">ISSN</a>), author
        (<a href=\"https://orcid.org/\">ORCID</a>) and affiliated institution (<a
        href=\"https://ror.org/\">ROR</a>).</p><h3 id=\"rich-site-summary-rss\">Rich
        Site Summary (RSS)</h3><p><a href=\"https://en.wikipedia.org/wiki/RSS\">RSS</a>
        is the standard protocol for distributing and consuming blog content. It is
        actually a group of protocols (Atom and multiple flavors of the RSS format),
        but they have been around for so long that the popular tools and services
        support the various protocols. RSS will be the standard way how content is
        ingested by the blog archive, and probably also how in turn content in the
        central blog archive is consumed, e.g. as an automated feed of all new science
        blog posts in a particular subject area and language.</p><figure class=\"kg-card
        kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/12/images--1-.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"128\" height=\"128\"></figure><p>Because
        RSS is so widely supported, other ways of registering content \u2013 e.g.
        via web form, API, or webhook \u2013 are less critical for the blog archive.
        Work is needed on the InvenioRDM software to add strong support for RSS feeds,
        but would allow the automation of a lot of the work needed to build and maintain
        the blog archive.</p><h3 id=\"markdown-and-pdf\">Markdown and PDF</h3><p><a
        href=\"https://daringfireball.net/projects/markdown/\">Markdown</a> is a markup
        language popular with many blogging platforms. It is typically used for editing
        blog posts and other documents in online environments but is not really used
        for consuming blog content via RSS. Markdown has<a href=\"https://pandoc.org/\">
        been extended</a> to support features needed for scholarly documents, e.g.
        tables and references, but the uptake of this added functionality in science
        blogs has been slow. </p><p>PDF is commonly used for reading scholarly publications.
        The workflows for submitting manuscripts to journals and preprint archives
        in PDF format are broken because it is tricky to extract structured documents
        from PDFs. The blog archive will support PDF as an output format at some point
        but is not a high priority. Blog posts are typically consumed via blog reader
        or email (if the blog produces a newsletter) rather than as PDF printed out
        on paper. There is work needed on the InvenioRDM platform to display full-text
        content rendered as HTML.</p><h3 id=\"curation-and-community\">Curation and
        Community</h3><p>Science blog posts typically see a lightweight review workflow
        before publication, and often receive feedback in the form of comments and/or
        social media mentions. For the Front Matter science blog archive, I want to
        keep that approach and not build any hurdles for inclusion. Some level of
        curation is needed, not only to check for quackery and hate speech but also
        to improve metadata that help with discovery, and to find blogs that should
        be included. Ideally we can build a community around the science blog archive,
        taking advantage of the <a href=\"https://inveniordm.web.cern.ch/communities\">communities</a>
        (focussing on different languages and subject areas) feature recently added
        to the InvenioRDM software.</p><h3 id=\"flashback\">Flashback?</h3><p>If reading
        this post feels like it is 2006 \u2013 the year <a href=\"https://en.wikipedia.org/wiki/James_Brown\">James
        Brown</a> (used for the feature image of this post) died \u2013 again with
        talk about blogs, RSS, Markdown, Creative Commons, and related technologies
        (I for example didn't mention Zotero, XML, or Wordpress), you are right. This
        is intentional, these technologies are not as sexy as using artificial intelligence
        or cryptocurrencies to drive this, but I want the Science Blog archive to
        become a scholarly resource that is useful, open, and inclusive.</p><h3 id=\"references\">References</h3><p>Fenner,
        M. (2022, September 28). Starting Work on the Front Matter Archive. <em>Front
        Matter</em>. <a href=\"https://doi.org/10.53731/9z6rz5d-djbay0y\">https://doi.org/10.53731/9z6rz5d-djbay0y</a></p><p>Fenner,
        M. (2022, December 12). Building an archive for scholarly blog posts. <em>Front
        Matter</em>. <a href=\"https://doi.org/10.53731/br9f5xa-a556w2t\">https://doi.org/10.53731/br9f5xa-a556w2t</a></p><p>Fenner,
        M. (2022, December 19). Launching the Front Matter Roadmap. <em>Front Matter</em>.
        <a href=\"https://doi.org/10.53731/cbdtfp1-1798beh\">https://doi.org/10.53731/cbdtfp1-1798beh</a></p><p>Fenner,
        M. (2010, October 6). Beyond the PDF \u2013 it is time for a workshop. <em>Front
        Matter</em>. <a href=\"https://doi.org/10.53731/r294649-6f79289-8cw7z\">https://doi.org/10.53731/r294649-6f79289-8cw7z</a></p><p>Fenner,
        M. (2013, June 19). Citations in Scholarly Markdown. <em>Front Matter</em>.
        <a href=\"https://doi.org/10.53731/r294649-6f79289-8cw1b\">https://doi.org/10.53731/r294649-6f79289-8cw1b</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Launching the Front Matter Roadmap ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/front-matter-roadmap/\" />\n\t\t<id>https://doi.org/10.53731/cbdtfp1-1798beh</id>\n
        \       <published>2022-12-19T14:20:17.000+00:00</published>\n\t\t<updated>2022-12-19T14:20:17.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/12/Bildschirm-foto-2022-12-19-um-15.16.52.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/12/Bildschirm-foto-2022-12-19-um-15.16.52.png\"></p><p>In
        a <a href=\"https://doi.org/10.53731/br9f5xa-a556w2t\">blog post last week</a>
        I talked about what I am currently working on, namely a) helping to make it
        easier (and safer) to run the <a href=\"https://inveniordm.docs.cern.ch/\">InvenioRDM</a>
        digital repository software in Docker container infrastructure, and b) working
        on converting the bolognese metadata conversion Ruby gem <a href=\"https://github.com/front-matter/talbot\">to
        Python</a> to enhance InvenioRDM functionality. </p><p>To get updates on this
        work you can follow the <a href=\"https://github.com/front-matter\">Front
        Matter GitHub repositories</a> \u2013 the work I am doing at Front Matter
        is mostly happening in public code repositories. But maybe you are really
        only interested in basic information, e.g. what I am working on, when it is
        ready, and providing some high-level input. There are several ways one can
        provide this high-level information, but usually, that is too much information
        for a blog like this one, and too much technical detail in a code repository.
        There are plenty of tools and services available for this typical <a href=\"https://www.atlassian.com/agile/product-management\">product
        management work</a>, but most of them are not a good fit more a small startup
        like Front Matter.</p><p>Today I am announcing four new (and related) ways
        you can follow the work Front Matter is doing, and provide feedback and other
        input:</p><ul><li>the <a href=\"https://feedback.front-matter.io/b/8mywxw07/feature-ideas\">Front
        Matter Ideas</a> Forum, where users can suggest features and improvements
        for Front Matter services \u2013 currently that is services planned to launch
        in 2023 like the Scholarly Blog Archive mentioned above,</li><li>the <a href=\"https://feedback.front-matter.io/roadmap\">Front
        Matter Roadmap</a> gives a high-level view (planned/in development/launched)
        of the work that Front Matter is doing,</li><li>the <a href=\"https://feedback.front-matter.io/announcements\">Front
        Matter Announcements</a> are a changelog of smaller achievements and bug fixes
        that don't make it into the Front Matter blog, and</li><li>the <a href=\"https://discord.gg/AZHDtKP3\">Front
        Matter Discord Server</a> for problems, ideas, and general discussions related
        to Front Matter.</li></ul><p>And of course, you can also interact with Front
        Matter via <a href=\"mailto:info@front-matter.io\">email</a> or <a href=\"https://hachyderm.io/@mfenner\">Mastodon</a>.
        You no longer find Front Matter or me personally on Twitter, as this has become
        a chaotic, unfriendly, and toxic place with an uncertain future.</p><p>With
        that, I wish all of you a peaceful and relaxing holiday season and a good
        start into 2023.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Building an archive for scholarly blog posts
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/building-an-archive-for-scholarly-blog-posts/\"
        />\n\t\t<id>https://doi.org/10.53731/br9f5xa-a556w2t</id>\n        <published>2022-12-12T12:58:33.000+00:00</published>\n\t\t<updated>2023-06-28T13:39:53.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/12/guidelines-4.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/12/guidelines-4.png\"></p><p>This
        blog post is a follow-up to a post in September (Fenner 2022a), where I announced
        that I had started working on an archive for scholarly blog posts based on
        the <a href=\"https://inveniordm.docs.cern.ch/\">InvenioRDM</a> open-source
        repository software. In the last two months, I focussed on two activities
        \u2013 besides lots of physical therapy and other training following a stroke
        earlier this year (Fenner 2022b): helping to make it easier (and safer) to
        run InvenioRDM in Docker container infrastructure, and working on converting
        the bolognese metadata conversion Ruby gem (Fenner 2017) to Python (work in
        progress on <a href=\"https://github.com/front-matter/talbot\">GitHub</a>)
        to enhance InvenioRDM functionality. </p><p>Building an archive of scholarly
        blog posts faces the same fundamental challenges as repositories for other
        types of scholarly content, whether data, software, preprints, or journal
        articles. You have to collect metadata and content, and that approach only
        scales with standardization and open licenses.</p><p>Luckily we already know
        a lot about required and optional but desired scholarly metadata, and they
        are fundamentally not different for scholarly blog posts. This means we can
        take similar approaches as we have for example taken for research data:</p><figure
        class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/12/guidelines-3.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"815\" height=\"363\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/12/guidelines-3.png
        600w, https://blog.front-matter.io/content/images/2022/12/guidelines-3.png
        815w\" sizes=\"(min-width: 720px) 720px\"><figcaption><strong>Guidelines for
        Repositories. </strong>Fenner et al. 2019.</figcaption></figure><p>Persistent
        identifiers for blog posts can be DOIs, as this blog is doing since earlier
        this year (Fenner 2022). The main advantage of using DOIs is registering standard
        metadata stored independently of the blogging platform, in case the platform
        changes or disappears (as has happened several times in the 15 years this
        blog exists). While there are several blogs using DOIs for their posts, they
        often fail in guideline #4: <em>the persistent identifier must be embedded
        in the landing page in machine-readable format. </em>This is important so
        that reference managers can capture the DOI and retrieve the associated metadata.</p><p>When
        the metadata are embedded directly in the blog post, schema.org markup in
        JSON-LD format (guideline #7) is much more convenient than HTML meta tags
        (guideline #8), but for the time being reference managers only work with the
        latter. The blogging platform used for this blog (<a href=\"https://ghost.org/\">https://ghost.org/</a>)
        has schema.org metadata built in, and there was only a small amount of work
        needed to expose all metadata needed (or desired) for DOI registration:</p><ul><li><a
        href=\"https://support.google.com/webmasters/answer/10347851\"><strong>Canonical
        URL</strong></a>: the DOI for the blog post</li><li><strong>License</strong>:
        the Creative Commons license for the content (this blog uses the <a href=\"https://creativecommons.org/licenses/by/4.0/legalcode\">Creative
        Commons Attribution 4.0 License</a>)</li><li><strong>ISSN</strong>: the Internal
        Standard Serial Number of this blog (2749-9952)</li></ul><p>An issue I have
        seen with schema.org metadata is that sometimes they are added by a script
        running in the browser instead of coming from the server, and this makes metadata
        harvesting unreliable. Multiple versions and different levels of granularity
        \u2013 a major challenge when working with data and software \u2013 luckily
        is not a major issue with scholarly blogs, in this regard, they behave similarly
        to preprints and journal articles.</p><h3 id=\"infrastructure-for-archiving-scientific-blog-posts\">Infrastructure
        for Archiving Scientific Blog Posts</h3><p>There are several possible approaches
        to building infrastructure for scholarly blog posts, and they all have well-known
        real-world examples:</p><ul><li><strong>A central repository</strong><br>A
        good example is the <a href=\"https://arxiv.org/\">ArXiv.org e-Print archive</a>,
        which hosts more than two million preprints in physics, mathematics, computer
        science, and some other fields, and is doing that for more than 25 years.
        All content and metadata are registered and stored in a central location (<a
        href=\"https://blog.arxiv.org/2022/02/17/new-arxiv-articles-are-now-automatically-assigned-dois/\">since
        earlier this year using DOIs</a>), and then distributed elsewhere, often domain-specific
        resources such as <a href=\"https://ui.adsabs.harvard.edu/\">ADS</a> (astrophysics)
        and <a href=\"https://inspirehep.net/\">InspireHEP</a> (high-energy physics).
        ArXiv is hosted by Cornell University.</li><li><strong>A central archive with
        content published in many places</strong><br><a href=\" https://pubmed.ncbi.nlm.nih.gov\">PubMed</a>
        (metadata) and <a href=\" https://www.ncbi.nlm.nih.gov\">PubMed Central</a>
        (metadata and content) are the main archives of biomedical and life sciences
        journal literature, again doing this for more than 25 years. The content with
        metadata is published in many different places but aggregated in PubMed/PubMed
        Central. Just like ADS and InspireHEP, PubMed and PubMed Central (and <a href=\"https://europepmc.org/\">Europe
        PMC</a>) are the central resources for scientists in the field to discover
        the relevant literature. PubMed uses the <a href=\"https://en.wikipedia.org/wiki/PubMed#PubMed_identifier\">PMID</a>,
        which can be mapped to the corresponding DOI as persistent identifier. For
        full-text content not included in PubMed Central, PubMed links out to publisher
        websites. PubMed is hosted by the <a href=\"https://www.nlm.nih.gov/\">National
        Library of Medicine</a> at the U.S. National Institutes of Health (NIH). NIH
        is the largest funder in the biomedical and life sciences, and its policies
        help PubMed Central host content.</li><li><strong>A central archive with content
        published elsewhere</strong><br>The repository <a href=\"https://zenodo.org/\">Zenodo</a>
        is the largest generic repository of scholarly content with more than 1.5
        million publications, and a million datasets, software, images, and presentations.
        Almost all content uses open licenses (either one of the Creative Commons
        licenses or <a href=\"https://opensource.org/licenses\">Open Source Initiative
        approved licenses</a> for software), facilitating the reuse of the content.
        Zenodo issues DOIs for its content, the DOI points to the Zenodo repository
        also for content originally registered elsewhere (e.g. software hosted on
        GitHub). Zenodo is particularly relevant for the planned blog posts archive,
        as the InvenioRDM software is based on Zenodo software and work is in progress
        for InvenioRDM to power Zenodo. Zenodo is hosted by <a href=\"https://home.cern/\">CERN</a>,
        the European Organization of Nuclear Research, the central resource for high-energy
        physics research.</li></ul><p>Based on the above, what makes sense for a scholarly
        blog post archive?</p><ul><li>Blogs are very decentralized based on their
        technology and 20-year history. While blogging platforms also have a long
        history (and Wordpress is the elephant in the room powering more than <a href=\"https://blog.hubspot.com/website/wordpress-stats\">40%
        of all websites</a>), a central blogging platform for science blogs similar
        to what ArXiv is doing in several fields is neither realistic nor desirable.</li><li>DOIs
        are a good fit as persistent identifiers for scholarly blogs. A lot of tools
        and services exist for them (including the InvenioRDM open source software),
        and the required and desired metadata for blogs are basically covered by DOI
        metadata (at least for Crossref and DataCite DOIs). Minor issues are that
        there is no dedicated content type for blog posts and that <strong>feature
        image</strong> metadata (supported by schema.org) would be beneficial.</li><li>The
        business models for DOI registrations need to be adapted to work better for
        scholarly blogs. A high fixed annual fee (DataCite) or a DOI pointing to a
        central archive instead of the original content (software in Zenodo) are hurdles
        for the long tail of independent science bloggers.</li><li>We need business
        models for sustainable science blogging infrastructure. Advertisements aren't
        working (the German platform scienceblogs.de is for example closing at the
        end of year) and individual readers paying for content might work for popular
        newsletters but doesn't align with Open Science practices. More work is needed,
        but one key element is cheap and simple infrastructure.</li><li>Existing blogging
        software (e.g. <a href=\"https://wordpress.org/\">Wordpress</a>, <a href=\"https://ghost.org/\">Ghost</a>,
        <a href=\"https://gohugo.io/\">Hugo</a>, or <a href=\"https://jekyllrb.com/\">Jekyll</a>)
        <em>almost</em> works for scholar blogs. Some minor changes (particularly
        around the canonical URL/persistent identifier) are required to improve the
        use in reference managers and archiving services.</li><li>We need a standard
        archiving format for scholarly blogs. <a href=\"https://jats.nlm.nih.gov/\">JATS</a>
        (Journal Article Tag Suite) is a standard for scholarly articles, but probably
        too heavy for blog posts. More work is needed and it should align with <a
        href=\"https://en.wikipedia.org/wiki/RSS\">RSS</a> (Really Simple Syndication),
        the 20-year-old standard for distributing content from blogs and similar sources.
        \_The biggest gap is maybe a standard way to describe links and references.</li><li>We
        need aggregation of science blog metadata and content in a central archive.
        This enables much easier discovery and long-term archiving, I still enjoy
        reading an interview I did with Geoff Bilder in 2009 (Fenner 2009), and the
        points he makes are still relevant. The blog posts had moved at least three
        times over the years and would have greatly benefitted from a DOI, standard
        archiving format, and a long-term archive as home.</li><li>I have started
        the work of building the infrastructure for archiving scholarly blogs, but
        I am fully aware that this is not only a technical challenge but even more
        so one of governance and community engagement. This needs much more work in
        2023 and onwards, and something I look forward to working on jointly with
        others.</li></ul><h3 id=\"references\">References</h3><p>Fenner, M. (2022a).
        <em>Starting Work on the Front Matter Archive</em> [Blog]. Front Matter. <a
        href=\"https://doi.org/10.53731/9z6rz5d-djbay0y\">https://doi.org/10.53731/9z6rz5d-djbay0y</a></p><p>Fenner,
        M. (2022b). <em>I spent the last five months in the hospital</em> [Blog].
        Front Matter. <a href=\"https://doi.org/10.53731/bkkzj8g-gd14mb6\">https://doi.org/10.53731/bkkzj8g-gd14mb6</a></p><p>Fenner,
        M. (2017). <em>Bolognese: A Ruby library for conversion of DOI Metadata</em>.
        DataCite. <a href=\"https://doi.org/10.5438/N138-Z3MK\">https://doi.org/10.5438/N138-Z3MK</a></p><p>Fenner,
        M., Crosas, M., Grethe, J. S., Kennedy, D., Hermjakob, H., Rocca-Serra, P.,
        Durand, G., Berjon, R., Karcher, S., Martone, M., &amp; Clark, T. (2019).
        A data citation roadmap for scholarly data repositories. <em>Scientific Data</em>,
        <em>6</em>(1), Article. <a href=\"https://doi.org/10.1038/s41597-019-0031-8\">https://doi.org/10.1038/s41597-019-0031-8</a></p><p>Fenner,
        M. (2022c). <em>DOI Registrations for all Ghost Blogs</em> [Blog]. Front Matter.
        <a href=\"https://doi.org/10.53731/fezg09h-hgn1gzm\">https://doi.org/10.53731/fezg09h-hgn1gzm</a></p><p>Fenner,
        M. (2009). <em>Interview with Geoffrey Bilder</em> [Blog]. Front Matter. <a
        href=\"https://doi.org/10.53731/r294649-6f79289-8cw1h\">https://doi.org/10.53731/r294649-6f79289-8cw1h</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Starting Work on the Front Matter Archive
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/starting-work-on-the-front-matter-archive/\"
        />\n\t\t<id>https://doi.org/10.53731/9z6rz5d-djbay0y</id>\n        <published>2022-09-28T16:10:57.000+00:00</published>\n\t\t<updated>2022-09-28T16:11:52.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://images.unsplash.com/photo-1628046902759-c94ab525fdaf?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDE1fHxhcmNoaXZlfGVufDB8fHx8MTY2NDM3NDk3OA&amp;ixlib&#x3D;rb-1.2.1&amp;q&#x3D;80&amp;w&#x3D;2000\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://images.unsplash.com/photo-1628046902759-c94ab525fdaf?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDE1fHxhcmNoaXZlfGVufDB8fHx8MTY2NDM3NDk3OA&amp;ixlib&#x3D;rb-1.2.1&amp;q&#x3D;80&amp;w&#x3D;2000\"></p><p>In
        August 2021 <a href=\"https://doi.org/10.53731/r8c26t1-97aq74v-ag66m\">I joined
        the InvenioRDM project</a> to help develop and host a modern repository platform
        for scholarly content. Things didn't exactly go as planned at the beginning
        of 2022, and I spent <a href=\"https://doi.org/10.53731/bkkzj8g-gd14mb6\">five
        months in the hospital</a> with serious personal health issues. Since returning
        home in early June, my health has improved considerably, and in September
        I was able to slowly start working again. This has worked well for me, so
        it is time to time to set goals for my work on the InvenioRDM project again.</p><h3
        id=\"announcing-the-front-matter-archive\">Announcing the Front Matter Archive</h3><blockquote>Front
        Matter will be launching a repository to host the full-text content of scholarly
        blogs in the first quarter of 2023. </blockquote><p>The starting point will
        be the over 450 blog posts that I have published <a href=\"https://doi.org/10.53731/bs60jms-sqaehsk\">over
        the last 15 years</a>, but the archive is of course open to content from all
        scholarly blogs. The goal is to both offer a useful resource for the scholarly
        community and to learn something about hosting InvenioRDM. An archive of scholarly
        blog posts is a good starting point, as blogs tend to change technology or
        location every few years, and older content then often becomes unavailable.
        Issuing DOIs for blog posts is part of the solution (e.g. this makes citing
        the blog posts much easier), but a stable long-term archive of the content
        is equally important. A challenge that scholarly blog posts share with many
        other often ephemeral scholarly resources, e.g. data and software.</p><h3
        id=\"setting-up-the-inveniordm-software\">Setting up the InvenioRDM Software</h3><p>The
        <a href=\"https://inveniosoftware.org/products/rdm/\">InvenioRDM</a> open-source
        software has seen a lot of work in the last several years and is currently
        at <a href=\"https://inveniordm.docs.cern.ch/releases/versions/version-v9.1.0/\">version
        9.1</a>. Several project partners are working on releasing a production version
        within the next twelve months, and the Caltech Library was the<a href=\"https://library.caltech.edu/blog/CaltechDATA-InvenioRDM\">
        first to do so last week</a>. Repository software is a complex piece of infrastructure,
        and a lot of work is expected for the proper configuration of the Front Matter
        Archive, including customization of the theme, authentication, etc.</p><h3
        id=\"running-the-front-matter-archive-in-a-kubernetes-cluster\">Running the
        Front Matter Archive in a Kubernetes Cluster</h3><p><a href=\"https://kubernetes.io/\">Kubernetes</a>
        in the last few years has become the de facto standard for deploying containerized
        applications such as InvenioRDM. Unfortunately running a Kubernetes cluster
        is not easy, but it will make things easier eventually (e.g. monitoring, scaling,
        and security), and it can be set up in a variety of environments from private
        clouds to public cloud providers. Front Matter will be using a managed Kubernetes
        cluster provided by <a href=\"https://www.digitalocean.com/\">Digitalocean</a>
        and provisioned by the infrastructure as code open source software tool <a
        href=\"https://www.terraform.io/\">Terraform</a>. Kubernetes will not host
        everything. At least in the initial version Front Matter will use hosted databases
        and hosted cloud object storage to store files and metadata, as Kubernetes
        (and containers) excel when running stateless applications, but more work
        is needed for <a href=\"https://cloud.google.com/kubernetes-engine/docs/how-to/stateful-apps\">stateful
        applications</a>.</p><h3 id=\"archiving-full-text-blog-content\">Archiving
        full-text Blog Content</h3><p>Front Matter will aim to archive blog posts
        via available APIs (as can be done with the Front Matter Blog), but we will
        have to take a flexible approach as full-text content will be provided in
        a variety of formats, e.g. RSS feeds. The initial focus will be on the <a
        href=\"https://ghost.org/\">Ghost</a> and <a href=\"https://wordpress.org/\">Wordpress</a>
        blogging platforms. We will help with issuing DOIs for this content and help
        to archive associated images. We are only interested in content with an open
        license (<a href=\"https://creativecommons.org/licenses/by/4.0/\">CC-BY</a>
        or <a href=\"https://creativecommons.org/publicdomain/zero/1.0/\">CCO</a>)
        to maximize the potential reuse of the blog archive.</p><h3 id=\"future-of-the-archive\">Future
        of the Archive</h3><p>After the initial setup of the blog archive, the focus
        will be on expanding content and on providing added value. Please reach out
        via email, Discord, or comments if you have scholarly blog content you want
        to be archived by Front Matter, or have suggestions for added functionality.
        One feature I want to see improved in InvenioRDM is better support for full-text
        HTML in addition to embedding PDF and other formats. In the coming months,
        I will also work on the cost model. There is a moderate cost to archive a
        blog post (mostly for ingesting content), but these costs would add up if
        blog posts are added by the thousands.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Adding Feature Images to Blog Posts ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/adding-feature-images/\" />\n\t\t<id>https://doi.org/10.53731/c6dwz6z-zzz0b3q</id>\n
        \       <published>2022-08-29T11:08:23.000+00:00</published>\n\t\t<updated>2022-12-11T21:47:40.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/DALL-E-2022-08-29-12.35.48---Picasso-painting-of-a-garden-gnome-with-an-umbrella-in-front-of-the-Artemis-launch-rocket.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/DALL-E-2022-08-29-12.35.48---Picasso-painting-of-a-garden-gnome-with-an-umbrella-in-front-of-the-Artemis-launch-rocket.png\"></p><p>Feature
        images are commonly used for blog posts, including on this blog. We can use
        our screenshots or photos or stock photos (ideally license free or with an
        open license) from sites like <a href=\"https://flickr.com/\">Flickr</a>,
        <a href=\"https://unsplash.com/\">Unsplash</a>, or <a href=\"https://www.pexels.com/\">Pexels</a>.
        More recently, we can also use artificial intelligence tools such as <a href=\"https://openai.com/dall-e-2/\">DALL\xB7E
        2</a> that generate images from a description in natural language.</p><p>As
        today is the launch of the first <a href=\"https://www.nasa.gov/specials/artemis-i/\">NASA
        mission</a> to the moon in fifty years, it seems appropriate to commemorate
        that historic event with a feature image showing a rocket, in this case with
        a garden gnome in the style of a Picasso painting generated by DALL\xB7E 2.
        I've added about a dozen feature images to this blog with various motives
        and styles all generated DALL\xB7E 2. The only thing they have in common is
        that they feature a garden gnome with an umbrella. Try to find them and tell
        me in the comments which one you like best.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ DOI Registrations for all Ghost Blogs ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/doi-registrations-for-all-blog/\"
        />\n\t\t<id>https://doi.org/10.53731/fezg09h-hgn1gzm</id>\n        <published>2022-08-25T16:39:40.000+00:00</published>\n\t\t<updated>2022-08-29T11:28:27.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://images.unsplash.com/photo-1554415707-6e8cfc93fe23?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDV8fHJlZ2lzdHJhdGlvbnxlbnwwfHx8fDE2NjE0NDU1MTA&amp;ixlib&#x3D;rb-1.2.1&amp;q&#x3D;80&amp;w&#x3D;2000\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://images.unsplash.com/photo-1554415707-6e8cfc93fe23?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDV8fHJlZ2lzdHJhdGlvbnxlbnwwfHx8fDE2NjE0NDU1MTA&amp;ixlib&#x3D;rb-1.2.1&amp;q&#x3D;80&amp;w&#x3D;2000\"></p><p>This
        blog since earlier this month is no longer using a <a href=\"https://doi.org/10.53731/cgdnpqv-vxss4fm\">JAMStack</a>
        setup but a regular Ghost setup using <a href=\"https://ghost.org/pricing/\">Ghost
        Pro </a>for hosting. The primary driver were the new native search and native
        comments, but I needed to do a little bit of work to keep the DOI registration
        working. This is done now, and an added benefit is that DOI registration is
        now straightforward for any blog that uses Ghost as a platform.</p><h3 id=\"requirements\">Requirements</h3><ul><li>An
        account to register DOIs with Crossref or DataCite</li><li>A Ghost blog that
        allows custom themes (e.g via <a href=\"https://ghost.org/pricing/\">Ghost
        Pro</a>, <a href=\"https://www.digitalpress.blog/pricing\">DigitalPress</a>,
        or self-hosted)</li></ul><h3 id=\"blog-configuration\">Blog Configuration</h3><p>We
        expose all metadata via schema.org upon publication, which is parsed and converted
        to Crossref or DataCite XML using a GitHub Action. All the metadata we need
        (e.g. author, title, and publication date) are already exposed as schema.org.
        The only required element missing is the DOI.</p><p>You can come up with your
        own unique DOI scheme, but it is easier (and <a href=\"https://blog.front-matter.io/posts/cool-dois/\">cooler</a>)
        using the <a href=\"https://rubygems.org/gems/briard\">briard Ruby gem</a>
        (version 2.4.2 and up) to generate a random DOI using your DOI prefix:</p><!--kg-card-begin:
        html--><code>briard encode 10.53731\n  => https://doi.org/10.53731/cgdnpqv-vxss4fm\n</code><!--kg-card-end:
        html--><p>This DOI is then entered in the post settings for the <a href=\"https://en.wikipedia.org/wiki/Canonical_link_element\">canonical
        URL</a>:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/Bildschirm-foto-2022-08-29-um-13.28.01.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"487\" height=\"102\"><figcaption>Canonical
        URL in Post -&gt; Post settings -&gt; Meta data</figcaption></figure><p>There
        are some optional metadata that you can add as well:</p><ul><li>The canonical
        URL should be displayed on each blog post:</li><li>The author ORCID, put the
        ID in the website settings of your author profile:</li><li>The license for
        the blog post content, put into a <strong>DCTERMS.license</strong> meta tag,
        and the ISSN:</li></ul><figure class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/Bildschirm-foto-2022-08-25-um-17.49.23.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"579\" height=\"111\"></figure><figure
        class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/Bildschirm-foto-2022-08-25-um-17.51.43.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"774\" height=\"62\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/Bildschirm-foto-2022-08-25-um-17.51.43.png
        600w, https://blog.front-matter.io/content/images/2022/08/Bildschirm-foto-2022-08-25-um-17.51.43.png
        774w\" sizes=\"(min-width: 720px) 720px\"></figure><p>To make working with
        these small changes easier, I forked the official <strong>headline</strong>
        theme, and you can download my forked version (renamed <strong>schlagzeile</strong>)
        as ZIP file from its <a href=\"https://github.com/front-matter/schlagzeile\">GitHub
        page.</a> After uploading the theme to your Ghost site, activate <strong>schlagzeile</strong>
        in the settings:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/Bildschirm-foto-2022-08-25-um-17.59.09.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"950\" height=\"421\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/Bildschirm-foto-2022-08-25-um-17.59.09.png
        600w, https://blog.front-matter.io/content/images/2022/08/Bildschirm-foto-2022-08-25-um-17.59.09.png
        950w\" sizes=\"(min-width: 720px) 720px\"></figure><p>You can use the site
        design settings to add license information and ISSN for your blog:</p><figure
        class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/Bildschirm-foto-2022-08-25-um-18.02.05.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"369\" height=\"269\"></figure><h3
        id=\"github-action\">GitHub Action</h3><p>Once the blog is configured as above,
        and you have a new post, use a GitHub Action to trigger the DOI registration.
        You can copy my <a href=\"https://github.com/front-matter/bloggable/blob/main/.github/workflows/webhook.yml\">webhook</a>
        GitHub Action and need to set these variables (for Crossref, similar variables
        for DataCite):</p><ul><li>CROSSREF_DEPOSITOR_NAME</li><li>CROSSREF_DEPOSITOR_EMAIL</li><li>CROSSREF_REGISTRANT</li><li>CROSSREF_USERNAME_WITH_ROLE</li><li>CROSSREF_PASSWORD</li></ul><p>You
        then trigger the workflow action by entering the path to the published blog
        post:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/Bildschirm-foto-2022-08-25-um-18.11.37.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"473\" height=\"326\"></figure><p>If
        your blog doesn't publish more than weekly, this semi-automated workflow is
        probably ok (and takes under a minute). Reach out to me in the comments for
        further questions or feedback. </p><p>Not every scholarly blog is using Ghost,
        but I currently can't provide guidance for other blogging platforms, for example
        Wordpress.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Now with native comments ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/native-comments/\" />\n\t\t<id>https://doi.org/10.53731/cgdnpqv-vxss4fm</id>\n
        \       <published>2022-08-17T14:56:06.000+00:00</published>\n\t\t<updated>2022-08-24T18:58:38.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/Bildschirm-foto-2022-08-15-um-19.51.47.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/Bildschirm-foto-2022-08-15-um-19.51.47.png\"></p><p>Since
        last year this blog is powered by the <a href=\"https://ghost.org/\">Ghost</a>
        open source blogging platform. Two important and long-standing shortcomings
        of the platform were search and comments, which I <a href=\"https://blog.front-matter.io/posts/front-matter-officially-launches-today/\">added</a>
        via integrating third-party tools (<a href=\"https://blog.front-matter.io/posts/full-text-search-front-matter-blog/\">Typesense</a>
        and <a href=\"https://www.discourse.org/\">Discourse</a>, respectively).</p><p>In
        the last several weeks Ghost team has worked hard to add these features to
        the core platform, described <a href=\"https://ghost.org/changelog/search/\">here</a>
        and <a href=\"https://ghost.org/changelog/native-comments/\">here</a>. These
        changes do not (yet) work well via the Ghost API, so I decided to drop my
        <a href=\"https://jamstack.org/\">Jamstack</a> setup with Ghost as a headless
        CMS backend and a <a href=\"https://github.com/front-matter/bloggable\">frontend</a>
        built with Next.js. Native comments and search are available now, more work
        is needed to register and display <a href=\"https://blog.front-matter.io/posts/the-front-matter-blog-now-uses-dois/\">DOIs
        for the blog posts</a>, based on schema.org metadata (which need minor tweaks,
        e.g. include the license of the blog content), and a Github Actions <a href=\"https://github.com/front-matter/bloggable/blob/main/.github/workflows/webhook.yml\">workflow</a>.</p><p>To
        use the new comments, you have to sign up as a Front Matter Blog member (signup
        links at the top and bottom of every page). Front Matter membership is free,
        is needed for commenting to control spam, and optionally includes a newsletter
        (each new blog post sent via email).</p><p>Of course, I am well aware that
        comments are not a technical problem, but a social problem. But building a
        community around the Front Matter blog is easier if commenting is easy and
        doesn't require signing up to an external service with unknown policies around
        handling personal data.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ This blog turned 15 (years old) this month
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/this-blog-turned-15-this-month/\"
        />\n\t\t<id>https://doi.org/10.53731/bs60jms-sqaehsk</id>\n        <published>2022-08-11T14:13:08.000+00:00</published>\n\t\t<updated>2022-08-14T14:09:25.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://images.unsplash.com/photo-1555607124-8531c7c702d0?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDQzfHxiaXJ0aGRheXxlbnwwfHx8fDE2NjAyMjQwOTA&amp;ixlib&#x3D;rb-1.2.1&amp;q&#x3D;80&amp;w&#x3D;2000\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://images.unsplash.com/photo-1555607124-8531c7c702d0?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDQzfHxiaXJ0aGRheXxlbnwwfHx8fDE2NjAyMjQwOTA&amp;ixlib&#x3D;rb-1.2.1&amp;q&#x3D;80&amp;w&#x3D;2000\"></p><p>The
        first post on this blog was published on August 3, 2007 (<a href=\"https://doi.org/10.53731/r294649-6f79289-8cw1q\">Open
        access may become mandatory for NIH-funded research</a>). This is post number
        465, and in the past 15 years the blog has seen changes in technology and
        hosting location \u2013 but I wrote all posts (with the exception of a few
        guest posts). The overall theme remained unchanged: technology used in scholarly
        communication. </p><p>Instead of a detailed analysis of recurring themes,
        or how scholarly communication has changed in the last 15 years, I want to
        pick one topic that continues to worry me, and has been the subject of multiple
        posts on this blog and elsewhere: the over-reliance on PDF as publishing format
        for scholarly articles.</p><p>This week I read two interesting articles related
        to climate change. One of them (<a href=\"https://doi.org/10.1038/s41558-022-01426-1\">Over
        half of known human pathogenic diseases can be aggravated by climate change</a>)
        did an impressive systematic review of the literature on the impacts of ten
        climatic hazards sensitive to greenhouse gas emissions on each known human
        pathogenic disease (in short: very scary). The second paper (<a href=\"https://doi.org/10.1073/pnas.2120584119\">Estimating
        the environmental impacts of 57,000 food products</a>) tried to estimate the
        environmental impact of more than 50K food products in the United Kingdom
        and Ireland (no big surprises, but again stressing that meat, fish, and cheese
        have a significant environmental impact).</p><p>Both articles are available
        online as full-text, but they come in PDF format. Fine for printing and then
        reading them (which I did), but in 2022 I expect to read papers on a tablet
        (which I use for almost all my reading) where the PDF letter or A4 size doesn't
        quite fit on the 10-inch screen. There are other problems with PDF (e.g. access
        to metadata such as references and using PDF as submission format, e.g. with
        preprints). These problems are not new and there are workarounds, but in the
        15 years of writing this blog \u2013 despite a lot of progress \u2013 scholarly
        communication continues to have an uneasy relationship with technology and
        is often stuck in the past. In contrast to many (but of course not all) other
        sectors.</p><p>This means there are many reasons to continue writing this
        blog. And since 2012, when I gave up my job as a medical doctor in a university
        hospital, I am working full-time on scholarly infrastructure, after recovering
        from the health issues I described in the last post (<a href=\"https://blog.front-matter.io/posts/i-spent-the-last-five-months-in-the-hospital\">I
        spent the last five months in the hospital</a>) with a focus on research data
        management.</p><p>Incidentally, August 3 saw another anniversary as Retraction
        Watch, the wonderful service tracking paper retractions turned 12 (<a href=\"https://retractionwatch.com/2022/08/03/happy-12th-birthday-retraction-watch-and-what-a-year-it-was/\">years
        old</a>). Congratulations Ivan and team!</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ I spent the last five months in the hospital
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/i-spent-the-last-five-months-in-the-hospital/\"
        />\n\t\t<id>https://doi.org/10.53731/bkkzj8g-gd14mb6</id>\n        <published>2022-07-28T11:45:56.000+00:00</published>\n\t\t<updated>2022-08-22T08:00:40.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/07/IMG_5831-1.jpg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/07/IMG_5831-1.jpg\"></p><p>In
        January I woke up one day and couldn't move my right arm and leg properly.
        As I have high blood pressure, and my father had a stroke the exact day seven
        years ago, I worried that I might have a stroke and went to the emergency
        room of the local university hospital. My worries were confirmed and I was
        admitted to the stroke unit, spending the next six weeks in the hospital,
        including two stays in the intensive care unit because of complications (pneumonia
        and pulmonary embolism). </p><p>In March I was transferred to a rehab clinic
        where I spent the next three months training to walk and use my right arm
        again. I made good progress and was discharged home in early June, continuing
        with physiotherapy and ergotherapy from home. I feel much better now and for
        example took the train to Berlin last week to visit my mother.</p><p>I am
        very thankful for all the support I got from the doctors, nurses, and therapists
        at the hospital and rehab clinic, family and friends, and above all from my
        wife Petra. I am trained as a medical doctor specializing in internal medicine
        and cancer medicine, and that helped me better understand some of the things
        that happened to me. I hope to get back to work in September, but it will
        be much longer until my life is back to where it was before January. When
        I was feeling better after the first weeks in the hospital, I had a lot of
        time to think about what I wanted to do when I would get back home, and what
        priorities I want to set going forward. </p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ A new membership model for the Front Matter
        blog ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/a-new-membership-model/\"
        />\n\t\t<id>https://doi.org/10.53731/revzwnv-rpd913d-8drwz</id>\n        <published>2022-01-10T10:17:39.000+00:00</published>\n\t\t<updated>2022-07-30T16:11:30.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/07/Bildschirmfoto-2022-01-14-um-16.43.39.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/07/Bildschirmfoto-2022-01-14-um-16.43.39.png\"></p><p>The
        Front Matter blog is launching a new membership model today. In August 2021
        this blog <a href=\"https://doi.org/10.53731/r8hb7h1-97aq74v-ag6ew\">started
        offering optional paid membership </a>via the <a href=\"https://www.buymeacoffee.com/\">Buy
        Me a Coffee</a> service. Unfortunately. two things happened: a) Paypal dropped
        supporting Buy Me a Coffee for membership payments at the end of last year,
        and b) there wasn't really any uptake of this support model, even if only
        charging $3 (or a cup of coffee) per month.</p><p>We are therefore doing two
        changes today:</p><ul><li>drop support for paid membership,</li><li>drop integration
        with Buy Me a Coffee and instead integrate with the built-in membership model
        of the Ghost blogging platform.</li></ul><p>Integrating with the built in
        membership of the Ghost blogging platform is not easy, as membership integration
        via official Ghost API calls is incomplete and this blog uses the popular
        <a href=\"https://jamstack.org/\">JAMstack</a> setup where backend (Ghost)
        and frontend (a custom open source solution built around Next.js) are separated
        into two separate services. We therefore need feedback by our users to iron
        out any glitches. The membership signup form is at the bottom of all category
        pages and the home page, and filling out the form triggers an email to confirm
        the membership. Users will then receive every blog post as email, as well
        as occasional emails from Front Matter staff.</p><p>For this convenience members
        allow Front Matter to track how many emails have been opened, helping Front
        Matter to collect feedback for the blog. Please report any issues you encounter
        to <a href=\"mailto:info@front-matter.io\">info@front-matter.io</a>.</p><p>We
        updated our <a href=\"https://blog.front-matter.io/pages/privacy-policy\">privacy
        policy</a> to reflect these changes. Most importantly, we are not tracking
        any personalized information without explicit user opt-in (for membership
        and/or authorship of blog posts). The usage stats of the Front Matter blog
        are collected by the <a href=\"https://plausible.io/\">Plausible Analytics</a>
        service and don't include any personal information such as IP addresses or
        detailed geographic information \u2013 in contrast to services such as the
        widely used Google Analytics which collects this and other personalized information
        (<a href=\"https://plausible.io/vs-google-analytics\">more background</a>).</p><p>We
        will continue to investigate other options to financially support this blogging
        platform. We are not interested in exclusive content only available to paying
        members, as this wouldn't align with Open Science principles. We are open
        to sponsorship and other suggestions.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Starting 2022 with a new feature: full-text
        search for the Front Matter blog ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/full-text-search-front-matter-blog/\"
        />\n\t\t<id>https://doi.org/10.53731/rejnyd0-ce6q0km-pr48v</id>\n        <published>2022-01-03T12:55:46.000+00:00</published>\n\t\t<updated>2022-07-30T16:13:58.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/07/Bildschirmfoto-2022-01-03-um-12.47.12.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/07/Bildschirmfoto-2022-01-03-um-12.47.12.png\"></p><p>Fresh
        into 2022, the Front Matter blog today is launching an important new feature:
        a full-text search of all blog posts. An example query would be for <strong>reference
        manager.</strong></p><p>As the Front Matter blog has a lot of posts about
        reference managers, a tag would also have worked in this particular case,
        but tags are much less flexible and become overwhelming when used too frequently.</p><p>The
        reason that tags have historically been used heavily in blogging platforms
        is technical, not that they provide the best user interface to find blog content.
        Relational databases such as MySQL that power blogging platforms \_(including
        Front Matter) are not good at full-text search, and a separate tool is needed.
        Solr and Elasticsearch are two widely used tools to provide full-text search.
        They are not trivial to set up and thus not used very often for full-text
        search of blogs. A popular alternative is a hosted search platform such as
        <a href=\"https://algolia.com\">Algolia</a>. </p><p>The full-text search Front
        Matter is launching today is built using <a href=\"https://typesense.org/\">Typesense</a>,
        open source software that is much easier to set up and maintain than Elasticsearch,
        and with a pricing model that is a better fit for Front Matter than Algolia
        \u2013 either self-hosted or in this case hosted by Typesense.org with a fee
        based on size and number of nodes in the cluster, not the number of requests
        as with Algolia.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/07/Bildschirmfoto-2022-01-03-um-13.04.27.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"1229\" height=\"743\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/07/Bildschirmfoto-2022-01-03-um-13.04.27.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/07/Bildschirmfoto-2022-01-03-um-13.04.27.png
        1000w, https://blog.front-matter.io/content/images/2022/07/Bildschirmfoto-2022-01-03-um-13.04.27.png
        1229w\" sizes=\"(min-width: 720px) 720px\"></figure><p>The new search functionality
        includes a small refactoring of pagination and filtering by tags that now
        are powered by Typesense, and are linked to the URL in the browser to make
        it easy to share search results, e.g. <a href=\"https://blog.front-matter.io/?query=reference+manager&amp;page=2\">https://blog.front-matter.io/?query=reference+manager&amp;page=2</a>.
        Tags are used for eight high-level categories of related content displayed
        on top of each page, but there are no plans to generate lots of additional
        tags for each blog post, as the full-text search obsoletes that need. Indexing
        in Typesense happens every time a blog post is published or updated, with
        negligible overhead and fully automated. </p><p>Front Matter is not the only
        place you can search for Front Matter blog posts. As all blog posts and core
        metadata are registered with a Crossref DOI, you can also search <a href=\"https://search.crossref.org\">Crossref
        Metadata Search</a>, for example, <a href=\"https://search.crossref.org/?q=reference+manager+overview&amp;from_ui=yes\">https://search.crossref.org/?q=reference+manager+overview&amp;from_ui=yes</a>,
        or all the other places where you find indexed Crossref DOIs that includes
        Front Matter content.</p><p>As this is version 1.0 of Front Matter full-text
        search, we expect to make adjustments based on user feedback in the coming
        months, but the new feature is available as of today, so please start 2022
        searching away. A good starting point would be a quick search and read on
        a mobile phone while on a commuter train, assuming you are not locked down
        in a home office. </p><p>The new search functionality is part of the <strong>bloggable</strong>
        open source library that powers this blog and is <a href=\"https://github.com/front-matter/bloggable\">available
        via GitHub.</a></p><p><em>Update Jan 4, 2022: Added link to source code.</em></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Improving software metadata conversion by
        adding CFF support ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/improving-software-metadata-conversion/\"
        />\n\t\t<id>https://doi.org/10.53731/rdv0jyq-vpb7a9j-zwqzg</id>\n        <published>2021-12-16T10:23:27.000+00:00</published>\n\t\t<updated>2023-07-03T10:10:29.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/07/cff_counts-1.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/07/cff_counts-1.png\"></p><p>In
        August GitHub added <a href=\"https://doi.org/10.53731/r9531p1-97aq74v-ag78v\">enhanced
        support for citation-file-format</a> (CFF) to all GitHub repositories. As
        you can see in the chart below (kindly provided by <a href=\"https://github.com/sdruskat\">Stephan
        Druskat</a> and based on GitHub queries for CFF files), this has led to a
        significant increase of repositories using CFF files and thus exposing software
        metadata that go beyond what GitHub provides via other means.</p><p>CFF support
        in GitHub provides an important building block that can be enhanced by a)
        making it easier to generate CFF files (text files using the <a href=\"https://en.wikipedia.org/wiki/YAML\">YAML</a>
        format and stored in the repository root folder), and b) converting the CFF
        into other metadata formats to make reuse easier elsewhere.</p><p>In 2017
        I started the metadata conversion library <a href=\"https://github.com/datacite/bolognese\">bolognese</a>
        that is heavily used internally by DataCite, focussing on the conversion of
        DOI metadata. During the <a href=\"https://doi.org/10.53731/rckvde5-tzg61kj-7zvc1\">Force2021
        hackathon</a> last week I expanded the bolognese library to support CFF conversion,
        and to allow the writing of DOI metadata in the Crossref XML format (not used
        for software metadata, but to <a href=\"https://doi.org/10.53731/rbjgna1-97aq74v-ag811\">register
        Crossref DOIs for this blog</a>). As these two changes are currently not a
        priority for the DataCite development team, it was easier to fork the bolognese
        software, so I started the <a href=\"https://rubygems.org/gems/briard\">briard
        Ruby gem</a>. For naming the new Ruby gem, I have continued the tradition
        I started almost 10 years ago of using dog breed names to name software libraries.</p><figure
        class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/07/1024px-Briard_R_01_Puppy.jpeg\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"1024\" height=\"685\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/07/1024px-Briard_R_01_Puppy.jpeg
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/07/1024px-Briard_R_01_Puppy.jpeg
        1000w, https://blog.front-matter.io/content/images/2022/07/1024px-Briard_R_01_Puppy.jpeg
        1024w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Briard dog. From https://commons.wikimedia.org/wiki/File:Briard_R_01_Puppy.jpg,
        using a CC BY SA license.</figcaption></figure><p>You can install briard via
        the command line with <code>gem install briard</code>, enabling reading and
        writing of CFF metadata via Ruby code or the command line:</p><p>Convert CFF
        metadata for the <strong>ruby-cff </strong>library into a formatted citation
        using the <strong>Vancouver</strong> citation style and the German language
        locale: </p><!--kg-card-begin: markdown--><pre><code>briard https://github.com/citation-file-format/ruby-cff
        -t citation --style vancouver --locale de\n\nHaines R, The Ruby Citation File
        Format Developers. Ruby CFF Library [Internet]. GitHub. GitHub; 2021. Verf\xFCgbar
        unter: https://github.com/citation-file-format/ruby-cff\n</code></pre>\n<!--kg-card-end:
        markdown--><p>Generate a CFF file from a GitHub repository archived in Zenodo
        with DOI metadata:</p><!--kg-card-begin: markdown--><pre><code>briard 10.5281/zenodo.5217599
        -t cff\n\n---\ncff-version: 1.2.0\nmessage: If you use Ruby CFF Library in
        your work, please cite it using the following\n  metadata\ndoi: https://doi.org/10.5281/zenodo.5217599\nrepository-code:
        https://zenodo.org/record/5217599\ntitle: Ruby CFF Library\nauthors:\n- given-names:
        Robert\n  family-names: Haines\n  orcid: https://orcid.org/0000-0002-9538-7919\n
        \ affiliation: The University of Manchester, UK\n- name: The Ruby Citation
        File Format Developers\nabstract: This library provides a Ruby interface to
        manipulate Citation File Format\n  files\nversion: 0.9.0\nkeywords:\n- ruby\n-
        credit\n- software citation\n- research software\n- software sustainability\n-
        metadata\n- citation file format\n- CFF\ndate-released: '2021-08-18'\nreferences:\n
        \ identifiers:\n  - type: url\n    value: https://github.com/citation-file-format/ruby-cff/tree/v0.9.0\n
        \ - type: doi\n    value: 10.5281/zenodo.1184077\n  - type: url\n    value:
        https://zenodo.org/communities/zenodo\n</code></pre>\n<!--kg-card-end: markdown--><p>As
        a command-line tool, briard can be integrated with a number of workflows,
        including <a href=\"https://docs.github.com/en/actions\">GitHub Actions</a>
        used in GitHub software development workflows.</p><p>Ultimately the goal is
        to increase the adoption of richer metadata for open source software, which
        in turn will enable important use cases from discovery to academic credit.
        As of today, <a href=\"https://commons.datacite.org/doi.org?query=*&amp;resource-type=software\">251,633
        DataCite DOIs have been registered for software</a>, including <a href=\"https://commons.datacite.org/doi.org?query=client.uid%3Acern.zenodo&amp;resource-type=software\">218,810
        DOIs (87.0%) via the Zenodo repository</a>. The briard library makes it straightforward
        to convert the metadata for these software libraries into CFF files that can
        then be stored with the source code repository. A good starting point would
        be the GitHub/Zenodo integration, where we could add CFF files to the GitHub
        repository (if not yet existing) in addition to writing DOI metadata.</p><p>Obviously
        not all source code for software DOIs is stored in GitHub, and for this reason,
        Stephan Druskat and I started to look into how to add similar <a href=\"https://gitlab.com/sdruskat/gitlab\">software
        citation functionality to GitLab</a> in the Force2021 hackathon last week.
        </p><h3 id=\"references\">References</h3><p>Fenner M. A step forward for software
        citation: GitHub\u2019s enhanced software citation support. Published online
        August 24, 2021. doi:<a href=\"https://doi.org/10.53731/r9531p1-97aq74v-ag78v\">10.53731/r9531p1-97aq74v-ag78v</a></p><p>Fenner
        M. Join us for the Force2021 Hackathon. Published online November 16, 2021.
        doi:<a href=\"https://doi.org/10.53731/rckvde5-tzg61kj-7zvc1\">10.53731/rckvde5-tzg61kj-7zvc1</a></p><p>Fenner
        M. Registering content with Crossref or DataCite. Published online October
        22, 2021. doi:<a href=\"https://doi.org/10.53731/rbjgna1-97aq74v-ag811\">10.53731/rbjgna1-97aq74v-ag811</a></p><p>Fenner
        M. Briard. Published online December 16, 2021. doi:<a href=\"https://doi.org/10.5281/ZENODO.5785519\">10.5281/ZENODO.5785519</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Join us for the Force2021 Hackathon ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/join-us-for-the-force2021-hackathon/\"
        />\n\t\t<id>https://doi.org/10.53731/rckvde5-tzg61kj-7zvc1</id>\n        <published>2021-11-16T17:02:26.000+00:00</published>\n\t\t<updated>2023-09-05T20:48:51.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/07/spoton12_hack-3.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/07/spoton12_hack-3.jpeg\"></p><p>The
        <a href=\"https://force2021.sched.com/\">Force2021 conference</a> will take
        place from December 7-9. The conference will be virtual, and <a href=\"https://www.eventbrite.com/e/force2021-tickets-94730321943\">registration</a>
        is free. And we will again be hosting a Force2021 hackathon, as co-located
        virtual event on December 6 and December 10. We will meet for four hours each
        (1 PM - 5 PM GMT) and will communicate via Zoom. Please check the tick box
        in the Force2021 registration form if you also want to participate in the
        hackathon, we will follow up with more logistics as we get closer to the event.
        </p><p>The overall theme of the hackathon is software citation, and it is
        coordinated by the Force11 Software Citation Implementation WG and <a href=\"https://scicodes.net/\">Scicodes</a>.
        This is a hackathon that is not only about code writing, but any collaborative
        activity around the overall theme. You can suggest a hackathon topic in the
        <a href=\"https://github.com/force11/force11-sciwg/issues\">Force11 Software
        Citation Implementation WG Issue Tracker</a>, but we make the final decision
        about topics and teams on December 6. Some ideas that have been expressed
        include:</p><ul><li>Improve Codemeta documentation and examples (add links
        to existing tools)</li><li>Update crosswalk between CITATION.cff and codemeta</li><li>Do
        crosswalk from BibLaTeX to codemeta</li><li>Improve citation style support
        in GitHub CFF implementation</li><li>Thinking session: tracking the impact
        of good metadata</li><li>if there will be a developer from SWH - Implement
        citation button for directories with codemeta or CFF (<a href=\"https://forge.softwareheritage.org/T3494\">T3494</a>)</li><li>Update
        the GitHub citable code guide <a href=\"https://guides.github.com/activities/citable-code/\">https://guides.github.com/activities/citable-code/</a>.</li><li>Write
        a GitHub Action to help authors keep their CFF files up to date (e.g., when
        a new release is published)</li><li>Write a GitHub Action (with configuration
        options) that allow people to follow best practices with their software citation
        practices (e.g., semantic versioning, archiving, generating metadata (Codemeta,
        CFF), ...)</li><li>Improve the codemeta generator tool</li><li>Discuss on
        how to have a support system for creating metadata/citation files</li><li>Get
        support for your metadata problems</li></ul><p>And please also join us for
        the main Force2021 conference. In particular on Tuesday December 7 at 5 PM
        UTC for the <a href=\"https://force2021.sched.com/event/pusm/deep-dive-software-citation\">Software
        citation deep dive</a> session.</p><p>Comment on the <a href=\"https://github.com/force11/force11-sciwg/issues\">Force11
        Software Citation Implementation WG Issue Tracker</a> or reach out to <a href=\"mailto:martin@front-matter.io\">me</a>
        if you have any comments or questions, and I hope to see many of you on December
        6.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Dryad: Interview with Jen Gibson ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/dryad-interview-jen-gibson/\" />\n\t\t<id>https://doi.org/10.53731/rceh7pn-tzg61kj-7zv63</id>\n
        \       <published>2021-11-15T10:52:02.000+00:00</published>\n\t\t<updated>2022-08-15T18:56:27.000+00:00</updated>\n\t\t<category
        term=\"Interview\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/07/jgibson.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/07/jgibson.png\"></p><p>In
        October Jen Gibson started as the new Executive Director for the Dryad Data
        Repository. I used the opportunity to ask Jen a few questions about Dryad,
        challenges with data sharing, and ideas about moving Dryad forward. I was
        particularly interested in the interview as I served on the Dryad Board of
        Directors from 2013 to 2016. In fact, one post on this blog is about a presentation
        I gave in 2013 (<a href=\"https://doi.org/10.53731/r294649-6f79289-8cw1x\">Metrics
        and attribution: my thoughts for the panel at the ORCID-Dryad symposium on
        research attribution</a>).</p><h3 id=\"1-can-you-describe-what-dryad-is\">1.
        Can you describe what Dryad is?</h3><p>Dryad is an open data publishing platform
        and community committed to the open availability and routine re-use of all
        research data. We\u2019re a generalist, curated data repository \u2013 working
        with researchers across disciplines to assemble details about their work and
        their data to increase its discoverability and use by others. We\u2019re a
        non-profit initiative working in partnership with other systems and communities
        working to advance open research.</p><h3 id=\"2-are-there-data-that-should-not-be-submitted-to-dryad\">2.
        Are there data that should not be submitted to Dryad?</h3><p>Dryad is designed
        to support openly accessible and fully re-usable data, and publishes under
        a Creative Commons Public Domain License (CC0). So, we\u2019re not able to
        publish data with incompatible licensing terms. We also don\u2019t accept
        datasets that contain personally identifiable human subject information or
        specific locations for endangered species \u2013 but our team of curators
        will work with researchers to see if the data can be made appropriate for
        sharing. </p><h3 id=\"3-are-there-limits-in-the-number-or-size-of-files-in-a-data-submission\">3.
        Are there limits in the number or size of files in a data submission?</h3><p>We
        can accept up to 300GB per dataset and thousands of files, but curators are
        looking for the most accessible file types and downloads to support re-use.
        So, we ask that files be small and zipped when possible. Users with files
        larger than 300GB are asked simply to contact us to coordinate. </p><h3 id=\"4-does-dryad-also-accept-software-submissions\">4.
        Does Dryad also accept software submissions?</h3><p>No, Dryad only publishes
        data. So, we\u2019ve partnered with <a href=\"https://zenodo.org\">Zenodo</a>
        so that users can load software and other supplementary information at the
        same time that they load data to Dryad. Software can then be made available
        under a different, more appropriate license and be given its own citation,
        but is also linked from the data publication at Dryad.</p><h3 id=\"5-does-a-data-submission-to-dryad-cost-money\">5.
        Does a data submission to Dryad cost money?</h3><p>Yes. Often the cost to
        researchers is covered or discounted through an arrangement with their institution,
        publisher, or funder. Where there is not yet an arrangement in place, the
        submitting researcher is asked to pay $120 \u2013 with overage fees if the
        data is larger than 300GB. Waivers are, of course, available. Publication
        fees, memberships, and partnerships with institutions, publishers and funders
        help cover our costs for data curation and long-term preservation.</p><h3
        id=\"6-what-are-the-main-challenges-for-authors\">6. What are the main challenges
        for authors?</h3><p>There are so many challenges for researchers with respect
        to open sharing of data \u2013 and they\u2019re different in every discipline.
        There are behaviour changes, and workflow changes and culture changes to overcome
        \u2013 although several disciplines have carved a path, including astronomy
        and ecology. I hope that the open data-sharing around COVID will help inspire
        more people to follow suit.</p><p>Dryad helps to overcome these challenges,
        of course. We help first of all by helping to make it <em>possible</em> to
        share data properly \u2013 openly, with a CC0 license, and second by making
        it <em>easy</em> to share data through our friendly user interface and our
        integrations with publishers and partners such as Zenodo. (With the terms
        \u2018possible, easy, rewarding and normative,\u2019 I\u2019m invoking Brian
        Nosek\u2019s <a href=\"https://www.cos.io/blog/strategy-for-culture-change\">Strategy
        for Culture Change</a>).</p><p>We\u2019re helping to make data sharing <em>rewarding</em>
        by standardising usage metrics (through <a href=\"https://makedatacount.org/\">Make
        Data Count</a> \u2013 an important, community-led initiative to develop metrics
        for open research data assessment) and encouraging citation, though these
        are just a couple of the pieces needed to put data and data sharing at the
        centre of research assessment.</p><p>Finally, what I\u2019m very much looking
        forward to doing with Dryad is supporting and building communities that share
        and re-use data to make this practice <em>normative</em>. Connecting people
        with people \u2013 and people with data \u2013 is key in nurturing and normalising
        the regular exchange and re-use of data. </p><h3 id=\"7-why-should-authors-submit-their-data-to-dryad\">7.
        Why should authors submit their data to Dryad?</h3><p>Authors whose communities
        don\u2019t already rely on a domain repository for data, such as WormBase
        or the Protein Data Bank, should publish their data with Dryad because:</p><ul><li>Our
        curation service increases the quality and discoverability of new data, by
        ensuring key descriptive information (metadata) is available alongside the
        data itself</li><li>Our curation service increases the integrity of new data,
        by ensuring it\u2019s readable and usable by other users</li><li>We put data
        in context, with links to publications, software, institutions, funders and
        more</li><li>Data published in Dryad is citable and accessible via a persistent
        DOI</li><li>As a non-profit and open-source initiative, our values are closely
        aligned with the research community</li><li>It\u2019s easy, and affordable
        </li></ul><h3 id=\"8-how-can-authors-give-feedback-eg-to-report-problems-or-request-features\">8.
        How can authors give feedback, e.g. to report problems or request features?</h3><p>We
        are an open source project and our work is driven by researchers' needs. Get
        in touch with the help desk to discuss feature needs with our product team
        or leave a ticket on our public <a href=\"https://github.com/CDL-Dryad/dryad-product-roadmap/projects/1\">Github
        product board</a>.</p><h3 id=\"9-what-did-you-do-before-starting-to-work-for-dryad\">9.
        What did you do before starting to work for Dryad?</h3><p>I\u2019ve worked
        in open research since 2005, when I joined <a href=\"https://sparcopen.org/\">SPARC</a>
        \u2013 the Scholarly Publishing and Academic Resources Coalition \u2013 to
        work on open-access advocacy and policy efforts. Immediately before Dryad
        I was a founding member of the team for eLife \u2013 the open-access journal
        for biology and medicine and initiative from three of the largest, most prestigious,
        private biomedical research funders to put science publishing back in the
        hands of science. I\u2019d say my main contributions so far have been in building
        communities (among librarians, open science advocates, students, early-career
        or late-stage researchers, and others), advocacy (for open research practice
        at different levels of practice and policy), and adoption strategies (for
        researchers in particular). </p><h3 id=\"10-do-you-want-to-talk-about-future-plans-for-dryad\">10.
        Do you want to talk about future plans for Dryad?</h3><p>Absolutely. Beyond
        my near-term objectives for optimising operations, I expect us to be:</p><ul><li>Leveraging
        support from institutions and expanding our membership program.</li><li>Working
        with our publisher partners to attract as much data as possible.</li><li>More
        actively diversifying our profile \u2013 specifically reaching out to different
        geographic and disciplinary communities.</li><li>Expanding our roadmap for
        modeling data publishing into the future, building on our progress over the
        last couple of years.</li></ul><p>Longer term, I\u2019m enthusiastic about
        the potential for pushing data to the forefront of discovery, and taking steps
        to facilitate re-use and extend credit. Like Make Data Count, Dryad is committed
        to making data a first-class citizen in research and research assessment,
        and I'll be really pleased if we\u2019re able to help properly reward researchers
        for their data publications. We\u2019re going to need to, to really accelerate
        discovery and build that open, global network for the exchange of research
        objects.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Open Citation Data reach critical Milestone
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/open-citation-data-reach-critical-milestone/\"
        />\n\t\t<id>https://doi.org/10.53731/rc3j5sn-tzg61kj-7ztra</id>\n        <published>2021-11-04T09:36:04.000+00:00</published>\n\t\t<updated>2023-07-02T06:09:28.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/07/Bildschirmfoto-2021-11-04-um-09.15.49.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/07/Bildschirmfoto-2021-11-04-um-09.15.49.png\"></p><p>Last
        Friday the OpenCitations blog <a href=\"https://opencitations.wordpress.com/2021/10/27/coverage-of-open-citation-data-approaches-parity-with-web-of-science-and-scopus/\">published
        a guest post</a> by <a href=\"mailto:albertomartin@ugr.es\">Alberto Mart\xEDn-Mart\xEDn</a>
        that describes the coverage by <a href=\"https://opencitations.net/index/coci\">COCI</a>
        and other open citation data compared to subscription citation indexes. This
        is an important blog post, as it changes how we think about citations and
        open metrics.</p><p><strong><strong><a href=\"https://opencitations.net/index/coci\">COCI</a></strong></strong>
        is the OpenCitations Index of Crossref open DOI-to-DOI citations, based on
        the open references made available by Crossref in the context of the Initiative
        for Open Citations (<a href=\"https://i4oc.org/\">I4OC</a>). As of October
        2021, 88% of the 56.9 million articles with references deposited with Crossref
        have open references.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2022/07/Bildschirmfoto-2021-11-04-um-09.08.20.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"820\" height=\"245\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/07/Bildschirmfoto-2021-11-04-um-09.08.20.png
        600w, https://blog.front-matter.io/content/images/2022/07/Bildschirmfoto-2021-11-04-um-09.08.20.png
        820w\" sizes=\"(min-width: 720px) 720px\"><figcaption>via https://i4oc.org/#faqs</figcaption></figure><p>I4OC,
        together with Crossref members, Crossref, and OpenCitations has come a long
        way since it started in 2017, and I am proud that I played a small role in
        getting I4OC started. Please keep in mind that not all Crossref members submit
        references for their DOIs. Crossref has issued 128 million DOIs for scholarly
        content to date, including 91 million DOIs for journal articles. Also, Crossref
        is including these open references in its <a href=\"https://www.crossref.org/documentation/retrieve-metadata/rest-api/\">REST
        API</a>, but is currently not making the processed references (aggregating
        them by cited DOI) openly available. The Crossref REST API provides the citation
        count as <code>referenced-by-count</code>, to see the actual references you
        need to either be a Crossref member participating in the <a href=\"https://www.crossref.org/services/cited-by/\">Crossref
        cited-by service</a>, or use COCI and other open citation indexes.</p><p>With
        the number of open references closing in on 90%, this is now a good time to
        take a closer look at the coverage of these open citation data compared to
        other available citation indexes and compare the results to the situation
        in 2019. And this is exactly what Alberto Mart\xEDn-Mart\xEDn and colleagues
        have done. Their 2019 analysis was published in 2020 (<a href=\"https://doi.org/10.1007/s11192-020-03690-4\">Mart\xEDn-Mart\xEDn
        et al. 2020</a>) and looked at 2,515 highly-cited English-language documents
        published in 2006 from 252 subject categories, and the citations to these
        publications found in the following services:</p><ul><li><a href=\"https://scholar.google.com/\">Google
        Scholar</a></li><li><a href=\"https://academic.microsoft.com/\">Microsoft
        Academic</a></li><li><a href=\"https://www.scopus.com/\">Scopus</a></li><li><a
        href=\"https://www.digital-science.com/product/dimensions/\">Dimensions</a></li><li><a
        href=\"https://clarivate.libguides.com/webofscienceplatform/woscc\">Web of
        Science Core Collection (WoS)</a></li><li><a href=\"https://opencitations.net/index/coci\">COCI</a></li></ul><p>In
        the 2020 publication, Google Scholar found the most citations with 88%, and
        COCI found the least citations with 28% (and Microsoft Academic 60%, Scopus
        57%, Dimensions 54%, and WoS 52%). The new analysis done for COCI with August
        2021 Crossref data for the same 2,515 papers published in 2006, and for citing
        papers published until 2019 shows a significant difference, with COCI now
        covering 50% of citations, or 53% when combined with the <a href=\"https://doi.org/10.1371/journal.pbio.3000385\">NIH
        Open Citation Collection</a>, another index of open citations.</p><figure
        class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/07/albertos-coci-post-final-fig-1.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"1024\" height=\"1005\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/07/albertos-coci-post-final-fig-1.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/07/albertos-coci-post-final-fig-1.png
        1000w, https://blog.front-matter.io/content/images/2022/07/albertos-coci-post-final-fig-1.png
        1024w\" sizes=\"(min-width: 720px) 720px\"><figcaption><em><em>Percentage
        of citations found by each database, relative to all citations (first row),
        and relative to the number of citations found by the other databases (subsequent
        rows).</em> From the <a href=\"https://opencitations.wordpress.com/2021/10/27/coverage-of-open-citation-data-approaches-parity-with-web-of-science-and-scopus/\">OpenCitations
        blog</a>.</em></figcaption></figure><p>These findings change everything, as
        coverage by open citation indexes is now comparable to the commercial services
        Web of Science, Scopus and Dimensions. Microsoft announced in May that Microsoft
        Academic will <a href=\"https://www.microsoft.com/en-us/research/project/academic/articles/microsoft-academic-to-expand-horizons-with-community-driven-approach/\">retire
        at the end of 2021</a>. And Google Scholar plays a special role, as it has
        the best coverage, but no API access (free or paid), making it basically impossible
        to build services on top of Google Scholar. A rather unusual decision by Google
        (compare to e.g. Google Maps) that can only be explained by existing license
        agreements with publishers.</p><p>The analysis was done using 2,515 papers
        published in 2006, and there are small differences between service providers
        depending on the subject area. As this was an analysis based on Crossref DOIs,
        the analysis misses citing publications not registered with Crossref, or not
        making their references available to Crossref. And the analysis focused on
        coverage, not looking at other aspects of the services provided. More work
        needs to happen in the coming years on these topics.</p><p>But the main conclusion
        is very clear: open citation indexes are comparable in terms of coverage to
        subscription citation services, and the decision to use a subscription service
        should be based on convenience rather than coverage. I can't emphasize enough
        the importance of this critical milestone, and I congratulate Alberto Mart\xEDn-Mart\xEDn
        and his team on doing this work.</p><p>I would not be surprised to see comments
        and publications in the coming weeks and months arguing with these findings.
        This reminds me of a discussion we had about 15 years ago comparing the reliability
        of Wikipedia compared to the Encyclopedia Britannica, started by a study published
        in <em>Nature</em> (<a href=\"https://doi.org/10.1038/438900a\">Giles 2015,
        Internet encyclopaedias go head to head</a>). I fully expect the final outcome
        here to be similar.</p><h3 id=\"references\">References</h3><p>Shotton D.
        Coverage of open citation data approaches parity with Web of Science and Scopus.
        OpenCitations blog. Published October 27, 2021. Accessed July 2, 2023. <a
        href=\"https://opencitations.wordpress.com/2021/10/27/coverage-of-open-citation-data-approaches-parity-with-web-of-science-and-scopus/\">https://opencitations.wordpress.com/2021/10/27/coverage-of-open-citation-data-approaches-parity-with-web-of-science-and-scopus/</a></p><p>Mart\xEDn-Mart\xEDn
        A, Thelwall M, Orduna-Malea E, Delgado L\xF3pez-C\xF3zar E. Google Scholar,
        Microsoft Academic, Scopus, Dimensions, Web of Science, and OpenCitations\u2019
        COCI: a multidisciplinary comparison of coverage via citations. <em>Scientometrics</em>.
        2021;126(1):871-906. doi:<a href=\"https://doi.org/10.1007/s11192-020-03690-4\">10.1007/s11192-020-03690-4</a></p><p>Giles
        J. Internet encyclopaedias go head to head. <em>Nature</em>. 2005;438(7070):900-901.
        doi:<a href=\"https://doi.org/10.1038/438900a\">10.1038/438900a</a></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ On Readability ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/on-readability/\"
        />\n\t\t<id>https://doi.org/10.53731/rc2nchn-tzg61kj-7ztfa</id>\n        <published>2021-11-03T16:53:17.000+00:00</published>\n\t\t<updated>2022-08-15T18:58:21.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/07/photo-1491309055486-24ae511c15c7.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/07/photo-1491309055486-24ae511c15c7.jpeg\"></p><blockquote><strong>Readability</strong>
        is the ease with which a reader can understand a written text. \u2013 <a href=\"https://en.wikipedia.org/wiki/Readability\">Wikipedia</a></blockquote><p>Readability
        is obviously important for any kind of scholarly communication, from writing
        papers to blog posts. I have written about scientific writing before (e.g.
        <a href=\"https://doi.org/10.53731/r294649-6f79289-8cw9n\">Scientific writers
        can help publish good papers</a>, <a href=\"https://doi.org/10.53731/r294649-6f79289-8cw8s\">Books
        about Science Writing</a>, <a href=\"https://doi.org/10.53731/https://doi.org/10.53731/r294649-6f79289-8cw92\">Do
        you know the Flesch score of your papers?</a>), and writing scholarly content
        that is understandable is something that can be taught and learned.</p><p>Something
        simple that can help is providing feedback in the form of readability scores,
        generated automatically with formulas that for example use the average sentence
        length (<em>ASL</em>) and average number of syllables per word (<em>ASW</em>),
        as in the Flesch Reading Ease score first published in 1948:</p><blockquote><em>206.835
        - 1.015 x ASL - 84.6 x ASW</em></blockquote><p>The score can be anywhere between
        0 and 100, with a higher scores meaning better readability.</p><!--kg-card-begin:
        html--><table style=\"box-sizing: inherit; border-collapse: collapse; border-spacing:
        0px; margin-bottom: 1.6rem; color: rgb(0, 0, 0); font-family: -apple-system,
        &quot;system-ui&quot;, &quot;Segoe UI&quot;, Roboto, Oxygen-Sans, Ubuntu,
        Cantarell, &quot;Helvetica Neue&quot;, sans-serif; font-size: 16px; font-style:
        normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight:
        400; letter-spacing: normal; orphans: 2; text-align: start; text-transform:
        none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width:
        0px; background-color: rgb(255, 255, 255); text-decoration-thickness: initial;
        text-decoration-style: initial; text-decoration-color: initial;\"><thead style=\"box-sizing:
        inherit;\"><tr style=\"box-sizing: inherit;\"><th style=\"box-sizing: inherit;
        padding: 0.4rem 0.8rem; border-width: 1px; border-style: solid; border-color:
        rgb(230, 230, 230) rgb(230, 230, 230) rgb(164, 40, 106); border-image: initial;
        border-collapse: collapse; text-align: left;\"><strong style=\"box-sizing:
        inherit; font-weight: 700;\">Score&nbsp;</strong></th><th style=\"box-sizing:
        inherit; padding: 0.4rem 0.8rem; border-width: 1px; border-style: solid; border-color:
        rgb(230, 230, 230) rgb(230, 230, 230) rgb(164, 40, 106); border-image: initial;
        border-collapse: collapse; text-align: left;\"><strong style=\"box-sizing:
        inherit; font-weight: 700;\">Notes</strong></th></tr></thead><tbody style=\"box-sizing:
        inherit;\"><tr style=\"box-sizing: inherit;\"><td style=\"box-sizing: inherit;
        padding: 0.4rem 0.8rem; border: 1px solid rgb(230, 230, 230); border-collapse:
        collapse; font-size: 0.9375rem;\">90-100</td><td style=\"box-sizing: inherit;
        padding: 0.4rem 0.8rem; border: 1px solid rgb(230, 230, 230); border-collapse:
        collapse; font-size: 0.9375rem;\">very easy to read, easily understood by
        an average 11-year-old student</td></tr><tr style=\"box-sizing: inherit;\"><td
        style=\"box-sizing: inherit; padding: 0.4rem 0.8rem; border: 1px solid rgb(230,
        230, 230); border-collapse: collapse; font-size: 0.9375rem;\">80-90</td><td
        style=\"box-sizing: inherit; padding: 0.4rem 0.8rem; border: 1px solid rgb(230,
        230, 230); border-collapse: collapse; font-size: 0.9375rem;\">easy to read</td></tr><tr
        style=\"box-sizing: inherit;\"><td style=\"box-sizing: inherit; padding: 0.4rem
        0.8rem; border: 1px solid rgb(230, 230, 230); border-collapse: collapse; font-size:
        0.9375rem;\">70-80</td><td style=\"box-sizing: inherit; padding: 0.4rem 0.8rem;
        border: 1px solid rgb(230, 230, 230); border-collapse: collapse; font-size:
        0.9375rem;\">fairly easy to read</td></tr><tr style=\"box-sizing: inherit;\"><td
        style=\"box-sizing: inherit; padding: 0.4rem 0.8rem; border: 1px solid rgb(230,
        230, 230); border-collapse: collapse; font-size: 0.9375rem;\">60-70</td><td
        style=\"box-sizing: inherit; padding: 0.4rem 0.8rem; border: 1px solid rgb(230,
        230, 230); border-collapse: collapse; font-size: 0.9375rem;\">easily understood
        by 13- to 15-year-old students</td></tr><tr style=\"box-sizing: inherit;\"><td
        style=\"box-sizing: inherit; padding: 0.4rem 0.8rem; border: 1px solid rgb(230,
        230, 230); border-collapse: collapse; font-size: 0.9375rem;\">50-60</td><td
        style=\"box-sizing: inherit; padding: 0.4rem 0.8rem; border: 1px solid rgb(230,
        230, 230); border-collapse: collapse; font-size: 0.9375rem;\">fairly difficult
        to read</td></tr><tr style=\"box-sizing: inherit;\"><td style=\"box-sizing:
        inherit; padding: 0.4rem 0.8rem; border: 1px solid rgb(230, 230, 230); border-collapse:
        collapse; font-size: 0.9375rem;\">30-50</td><td style=\"box-sizing: inherit;
        padding: 0.4rem 0.8rem; border: 1px solid rgb(230, 230, 230); border-collapse:
        collapse; font-size: 0.9375rem;\">difficult to read, best understood by college
        graduates</td></tr><tr style=\"box-sizing: inherit;\"><td style=\"box-sizing:
        inherit; padding: 0.4rem 0.8rem; border: 1px solid rgb(230, 230, 230); border-collapse:
        collapse; font-size: 0.9375rem;\">0-30</td><td style=\"box-sizing: inherit;
        padding: 0.4rem 0.8rem; border: 1px solid rgb(230, 230, 230); border-collapse:
        collapse; font-size: 0.9375rem;\">very difficult to read, best understood
        by university graduates</td></tr></tbody></table><!--kg-card-end: html--><p>The
        Flesch Reading Ease score has been researched extensively, with a particular
        influence on journalism, showing that higher scores can increase readership.</p><p>Many
        writing tools have the Flesch Reading Ease score built in, including <a href=\"https://support.microsoft.com/en-us/office/get-your-document-s-readability-and-level-statistics-85b4969e-e80a-4777-8dd3-f7fc3c8b3fd2\">Microsoft
        Word</a> and <a href=\"https://www.grammarly.com/blog/readability-scores/\">Grammerly</a>.
        And there are open source libraries in a number of languages. This week the
        Front Matter blog started calculating and displaying the Flesch Reading Ease
        score (<em>readability score</em> for short) using the <a href=\"https://www.npmjs.com/package/readability-cyr\">readability-cyr</a>
        javascript library. You can see the score in the byline at the top of individual
        posts, or in listings of blog posts.</p><figure class=\"kg-card kg-image-card\"><img
        src=\"https://blog.front-matter.io/content/images/2022/07/Bildschirmfoto-2021-11-03-um-17.25.18.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"547\" height=\"221\"></figure><p>I
        will do a more systematic analysis at some point (the numbers are in our database
        index), for now I will highlight the Front Matter posts with the highest and
        lowest readability scores:</p><ul><li><a href=\"https://doi.org/10.53731/r294649-6f79289-8cw85\">Having
        an impact (factor) and other stories from Gregory Petsko</a> 72.3</li><li><a
        href=\"https://doi.org/10.53731/r294649-6f79289-8cw80\">More Gobbledygook
        at PLoS Blogs</a> 71.3</li><li><a href=\"https://doi.org/10.53731/r294649-6f79289-8cw7s\">Researchers\u2019
        reasons for publishing their work</a> 70.5</li><li>...</li><li><a href=\"https://doi.org/10.53731/r79r1nh-97aq74v-ag4k9\">We
        need your feedback: Aligning the CodeMeta vocabulary for scientific software
        with schema.org</a> 17.0</li><li><a href=\"https://doi.org/10.53731/r294649-6f79289-8cwbs\">German
        Genetics Society Meeting 2009: Session VI</a> 14.6</li><li><a href=\"https://doi.org/10.53731/294649-6f79289-8cw2c\">Neelie
        Kroes talks Open Science</a> 12.3</li></ul><p>Most posts have a score between
        30 and 50, lower than most newspapers and novels, but higher than highly specialized
        scientific papers. Blog posts that have a score much higher or lower are particularly
        interesting, as we might learn something that can improve our writing. But
        take the readability score with a grain of salt, as other factors not really
        in our control might influence the score.</p><p><em>P.S. This post has a readability
        score of 52.4.</em></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Open Scholarly Metrics for the Journal of
        Open Source Software ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/open-scholarly-metrics-for-joss/\"
        />\n\t\t<id>https://doi.org/10.53731/rbqhe51-97aq74v-ag89n</id>\n        <published>2021-10-26T06:43:50.000+00:00</published>\n\t\t<updated>2023-07-03T10:05:10.000+00:00</updated>\n\t\t<category
        term=\"Chart\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/07/barchart-1.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/07/barchart-1.png\"></p><p>The
        Journal of Open Source Software (<a href=\"https://joss.theoj.org/\">JOSS</a>)
        is a developer friendly, open access journal for research software packages
        published as open source software. JOSS started publishing in 2016, and has
        published more than 1,500 articles so far. After five years and that many
        articles, it is time to have a closer look at how JOSS content is reused.
        Given the context of publishing open access articles about open source software,
        it is only natural to look at reuse using open (scholarly) metrics, taking
        advantage of the fact that JOSS is registering all its articles as Crossref
        DOIs, and Crossref keeps track of citation counts and makes them openly available
        in the Crossref REST API (via the <a href=\"https://stackoverflow.com/questions/48192924/crossref-api-tracing-doi-citations\">is-referenced-by-count</a>
        property). It is straightforward to collect this information from Crossref
        using a <a href=\"https://github.com/front-matter/journal-notebooks\">Jupyter
        notebook</a> and visualize it:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2022/07/scatterplot.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"752\" height=\"717\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/07/scatterplot.png
        600w, https://blog.front-matter.io/content/images/2022/07/scatterplot.png
        752w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Citations for JOSS articles
        as of October 26, 2021.</figcaption></figure><p>The most obvious finding in
        this chart is the small number of JOSS papers with very high citation counts,
        including 2,094 citations for the most-cited paper published in November 2019
        (<a href=\"https://doi.org/10.21105/joss.01686\">Wickham et al. 2019, Welcome
        to the Tidyverse</a>), and currently 19 papers with at least 19 citations
        \u2013 see all JOSS papers with DOI, title, publication date and citation
        count <a href=\"https://github.com/front-matter/journal-notebooks/blob/main/works_10.21105_2021-10-26.csv\">here</a>.</p><p>While
        we typically are most interested in citations, there are other dimensions
        of reuse, summarized for example in this table:</p><figure class=\"kg-card
        kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/07/pbio.1001687.g002.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"653\" height=\"276\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/07/pbio.1001687.g002.png
        600w, https://blog.front-matter.io/content/images/2022/07/pbio.1001687.g002.png
        653w\"><figcaption>Article-level metrics used by PLOS in August 2013 and their
        categories. From Fenner et al., 2013, <a href=\"https://doi.org/10.1371/journal.pbio.1001687\">What
        Can Article-Level Metrics Do for You?</a></figcaption></figure><p>Tracking
        views and downloads of scholarly articles is a significant effort as it requires
        a <a href=\"https://www.projectcounter.org/\">standardized approach</a>, but
        some of the other dimensions are made easily available via the Crossref Event
        Data service and can be collected via a <a href=\"https://github.com/front-matter/journal-notebooks/blob/main/index.ipynb\">Jupyter
        notebook</a>.</p><p>Here <strong>Crossref</strong> is the combined number
        of citations collected via the REST API, <strong>DataCite</strong> is the
        number of citations of JOSS articles by DataCite DOIs, typically for the software
        described in the JOSS article <a href=\"https://guides.github.com/activities/citable-code/\">archived
        via GitHub in the Zenodo software archive</a>, <strong>Twitter</strong> is
        the number of tweets referencing the JOSS article, <strong>Wikipedia</strong>
        is the number of Wikipedia edits referencing the JOSS article, <strong>Newsfeed</strong>
        is the number of blog posts or news articles mentioning a JOSS article, and
        <strong>Hypothesis</strong> is the number of publicly available <a href=\"https://web.hypothes.is/\">Hypothesis.is
        </a>annotations mentioning a JOSS article.</p><figure class=\"kg-card kg-embed-card\"><blockquote
        class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">ResumableFunctions: C#
        sharp style generators for Julia. <a href=\"https://t.co/F0JsProaQe\">https://t.co/F0JsProaQe</a></p>&mdash;
        JOSS Accepted Papers (@joss_papers) <a href=\"https://twitter.com/joss_papers/status/925360225284165633?ref_src=twsrc%5Etfw\">October
        31, 2017</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\"
        charset=\"utf-8\"></script>\n</figure><figure class=\"kg-card kg-image-card
        kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/07/Download--5-.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"1344\" height=\"960\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/07/Download--5-.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/07/Download--5-.png
        1000w, https://blog.front-matter.io/content/images/2022/07/Download--5-.png
        1344w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Distribution of software
        repo licenses</figcaption></figure><p>Using the <a href=\"https://github.com/front-matter/journal-notebooks/blob/main/index.ipynb\">Jupyter
        notebook</a> there are several paths one could follow to go into more detail.
        Or one can expand on the work done for JOSS by Charlotte Soneson (<a href=\"http://www.theoj.org/joss-analytics/joss-submission-analytics.html\">JOSS
        Submission Analysis</a>) addressing very similar questions and in much more
        detail (sans the social media usage), for example the software licenses used
        for the code repositories described in the JOSS papers:</p><p><em>Note: updated
        October 26, 2021 with a link to the JOSS analysis done by Charlotte Soneson.</em></p><h3
        id=\"references\">References</h3><p>Wickham H, Averick M, Bryan J, et al.
        Welcome to the Tidyverse. <em>JOSS</em>. 2019;4(43):1686. doi:<a href=\"https://doi.org/10.21105/joss.01686\">10.21105/joss.01686</a></p><p>Fenner
        M. What Can Article-Level Metrics Do for You? <em>PLoS Biol</em>. 2013;11(10):e1001687.
        doi:<a href=\"https://doi.org/10.1371/journal.pbio.1001687\">10.1371/journal.pbio.1001687</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Registering content with Crossref or DataCite
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/registering-content-with-crossref-or-datacite/\"
        />\n\t\t<id>https://doi.org/10.53731/rbjgna1-97aq74v-ag811</id>\n        <published>2021-10-22T10:36:23.000+00:00</published>\n\t\t<updated>2023-09-05T20:47:59.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/07/photo-1501504905252-473c47e087f8.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/07/photo-1501504905252-473c47e087f8.jpeg\"></p><p>This
        blog started registering DOIs for its content with Crossref last week, and
        all 450+ blog posts so far were registered by Monday morning. This enables
        the easy import into reference managers (here using Zotero):</p><figure class=\"kg-card
        kg-image-card kg-width-wide kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/07/Bildschirmfoto-2021-10-22-um-11.53.48.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"666\" height=\"1140\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/07/Bildschirmfoto-2021-10-22-um-11.53.48.png
        600w, https://blog.front-matter.io/content/images/2022/07/Bildschirmfoto-2021-10-22-um-11.53.48.png
        666w\"><figcaption>Zotero entry</figcaption></figure><p>Using Zotero or any
        other reference manager this blog post can now be easily cited:</p><figure
        class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/07/Bildschirmfoto-2021-10-22-um-11.47.52.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"1109\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/07/Bildschirmfoto-2021-10-22-um-11.47.52.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/07/Bildschirmfoto-2021-10-22-um-11.47.52.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2022/07/Bildschirmfoto-2021-10-22-um-11.47.52.png
        1600w, https://blog.front-matter.io/content/images/2022/07/Bildschirmfoto-2021-10-22-um-11.47.52.png
        2046w\" sizes=\"(min-width: 720px) 720px\"></figure><p>1. \tFenner M. The
        Front Matter blog now uses DOIs. Front Matter. Published online October 14,
        2021. doi:10.53731/rb7xw01-97aq74v-ag7qh</p><p>And as the author ORCID ID(s)
        are included in the Crossref metadata, <a href=\"https://support.orcid.org/hc/en-us/articles/360006971293-Auto-updates-in-third-party-systems-Crossref\">Crossref
        Auto-Update</a> was automatically updating <a href=\"https://orcid.org/0000-0003-1419-2405\">my
        ORCID record</a>:</p><p>It is too early to say whether the inclusion in the
        Crossref search index has increased the discoverability of the Front Matter
        blog. It is also too early to find any Front Matter blog posts referenced
        in <a href=\"https://www.crossref.org/services/event-data/\">Crossref Event
        Data</a>, e.g. tweets or Wikipedia pages. We will have some answers in a few
        months. But it is clear that DOIs can facilitate the discussion around scholarly
        content, which is the whole point of registering DOIs for blog posts.</p><p>DOI
        registration for blog posts is not very common. I started DOI registration
        for the DataCite blog in <a href=\"https://doi.org/10.5438/0000-00cc\">January
        2017</a>, and have now simplified the registration workflow for the Front
        Matter blog:</p><ol><li>Expose blog post schema.org metadata in JSON-LD format
        on blog post landing page</li><li>Convert metadata to DataCite XML or Crossref
        XML</li><li>Submit XML to DOI registration agency</li></ol><p>The initial
        work involves generating metadata in schema.org format:</p><!--kg-card-begin:
        markdown--><pre><code>{\n    &quot;@context&quot;: &quot;https://schema.org&quot;,\n
        \   &quot;@type&quot;: &quot;BlogPosting&quot;,\n    &quot;@id&quot;: &quot;https://doi.org/10.53731/rb7xw01-97aq74v-ag7qh&quot;,\n
        \   &quot;url&quot;: &quot;https://blog.front-matter.io/posts/the-front-matter-blog-now-uses-dois&quot;,\n
        \   &quot;name&quot;: &quot;The Front Matter blog now uses DOIs&quot;,\n    &quot;headline&quot;:
        &quot;The Front Matter blog now uses DOIs&quot;,\n    &quot;description&quot;:
        [\n        &quot;Yesterday I started registering DOIs for all Front Matter
        blog posts. I have registered 100 blog posts by now, and will have completed
        the registration process for all 450 blog posts on Monday. The DOIs are registered
        with Crossref which Front Matter joined in August. ...&quot;\n    ],\n    &quot;author&quot;:
        {\n        &quot;@type&quot;: &quot;Person&quot;,\n        &quot;@id&quot;:
        &quot;https://orcid.org/0000-0003-1419-2405&quot;,\n        &quot;name&quot;:
        &quot;Martin Fenner&quot;,\n        &quot;image&quot;: &quot;https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&amp;amp;d=mm&amp;amp;r=x&quot;\n
        \   },\n    &quot;isPartOf&quot;: {\n        &quot;@type&quot;: &quot;Blog&quot;,\n
        \       &quot;name&quot;: &quot;Front Matter&quot;,\n        &quot;issn&quot;:
        &quot;2749-9952&quot;\n    },\n    &quot;publisher&quot;: {\n        &quot;@type&quot;:
        &quot;Organization&quot;,\n        &quot;name&quot;: &quot;Front Matter&quot;\n
        \   },\n    &quot;keywords&quot;: &quot;news&quot;,\n    &quot;inLanguage&quot;:
        &quot;en&quot;,\n    &quot;license&quot;: &quot;https://creativecommons.org/licenses/by/4.0/legalcode&quot;,\n
        \   &quot;dateCreated&quot;: &quot;2021-10-14T08:49:04Z&quot;,\n    &quot;dateModified&quot;:
        &quot;2021-10-14T14:14:52Z&quot;,\n    &quot;datePublished&quot;: &quot;2021-10-14T13:43:48Z&quot;\n}</code></pre>\n<!--kg-card-end:
        markdown--><p>It makes sense to not only think about metadata required for
        DOI registration, but also include recommended metadata such as license, language,
        description and ORCID ID.</p><p>For steps 2. and 3. I have written a <a href=\"https://github.com/front-matter/bloggable/blob/main/.github/workflows/webhook.yml\">GitHub
        Action</a> that fully automates the DOI registration, triggered by a webhook
        when the blog post is published. As part of this work I had to enable Crossref
        XML generation in the <a href=\"https://github.com/datacite/bolognese\">bolognese</a>
        Ruby gem, this pull request is currently awaiting review. I hope that I can
        publish the GitHub Action in a few weeks.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ The Front Matter blog now uses DOIs ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/the-front-matter-blog-now-uses-dois/\"
        />\n\t\t<id>https://doi.org/10.53731/rb7xw01-97aq74v-ag7qh</id>\n        <published>2021-10-14T13:43:48.000+00:00</published>\n\t\t<updated>2022-08-15T19:06:26.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/07/Schema_org.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/07/Schema_org.png\"></p><p>Yesterday
        I started registering DOIs for all Front Matter blog posts. I have registered
        100 blog posts by now, and will have completed the registration process for
        all 450 blog posts on Monday. The DOIs are registered with Crossref which
        Front Matter joined in August. The blog posts are registered as <a href=\"https://www.crossref.org/documentation/content-registration/content-types-intro/posted-content-includes-preprints\">posted
        content</a>, and this is done via the metadata in <a href=\"https://schema.org/\">schema.org</a>
        format exposed on each blog page. Besides the required metadata we also register
        some optional metadata: currently abstract, keywords, license and author ORCID
        ID \u2013 which Crossref uses to automatically push the blog post metadata
        into the ORCID record. The main metadata missing are references, but that
        is much more work and something I want to address in 2022. All the required
        metadata are available from the blogging platform (<a href=\"https://ghost.org/\">Ghost</a>
        in our case), with a little bit of extra work needed for some:</p><ul><li>DOIs
        are generated from the prefix assigned to Front Matter (10.53731) combined
        with a suffix auto-generated from the database ID for the blog post \u2013
        using the <a href=\"https://github.com/salieri/uuid-encoder\">uuid-encoder</a>
        javascript library to turn the ID into a shorter string in base32 format.
        This for example turns the ID 6125186c149d573936a81d1b into the DOI 10.53731/r9531p1-97aq74v-ag78v.</li><li>The
        ORCID ID from each author is pulled from the <code>homepage</code> field in
        the author database.</li><li>The keyword(s) are taken from the tags configured
        for the blog and used in a particular post.</li><li>The abstract is the beginning
        of the full text (stripping all tags with the exception of &lt;b&gt;, &lt;i&gt;,
        &lt;em&gt; and &lt;strong&gt;, and limited to 250 characters). </li><li>The
        license is the same for every blog post, Creative Commons Attribution 4.0
        International (<a href=\"https://creativecommons.org/licenses/by/4.0/\">CC-BY
        4.0</a>).</li></ul><p>As you can see in the Crossref participating reports,
        this approach compares favorably with other Crossref members in terms of metadata
        completeness</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2022/07/Bildschirmfoto-2021-10-14-um-15.34.06.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"1023\" height=\"1091\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/07/Bildschirmfoto-2021-10-14-um-15.34.06.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/07/Bildschirmfoto-2021-10-14-um-15.34.06.png
        1000w, https://blog.front-matter.io/content/images/2022/07/Bildschirmfoto-2021-10-14-um-15.34.06.png
        1023w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Participation report
        Front Matter October 14, 2021.</figcaption></figure><p>The current focus is
        on registering all existing blog posts, going forward we will put a workflow
        in place that automatically registers a DOI when a new blog post is published.
        This DOI registration will be triggered by a webhook, and I am working on
        a freely available <a href=\"https://github.com/features/actions\">GitHub
        Action</a> for this. If you have an account with Crossref or DataCite, and
        your blog exposes the required DOI metadata as schema.org, you will be able
        to use this webhook. But if you rather don't want to get into the technical
        details but focus on writing meaningful blog posts, <a href=\"mailto:info@front-matter.io\">reach
        out to Front Matter</a> and we can set up a blog for you that automatically
        registers a DOI for each blog post, together with some other unique features
        such as a full-text search.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Editorial by more than 200 health journals:
        Call for emergency action to limit global temperature increases, restore biodiversity,
        and protect health ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/editorial-by-more-than-200-call-for-emergency-action-to-limit-global-temperature-increases-restore-biodiversity-and-protect-health/\"
        />\n\t\t<id>https://doi.org/10.53731/r9nqx6h-97aq74v-ag7bw</id>\n        <published>2021-09-06T07:50:05.000+00:00</published>\n\t\t<updated>2022-08-15T19:04:52.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/07/photo-1578403881967-084f9885be74.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/07/photo-1578403881967-084f9885be74.jpeg\"></p><p>More
        than 200 health journals today published an editorial calling for urgent action
        to keep average global temperature increases below 1.5\xB0C, halt the destruction
        of nature, and protect health. The editorial can be read for example <a href=\"https://doi.org/10.1136/bmj.n1734\">here</a>
        (published under a CC-BY Open Access license), and the full list of participating
        journals can be found <a href=\"https://www.bmj.com/content/full-list-authors-and-signatories-climate-emergency-editorial-september-2021\">here</a>.</p><blockquote>The
        greatest threat to global public health is the continued failure of world
        leaders to keep the global temperature rise below 1.5\xB0C and to restore
        nature. Urgent, society-wide changes must be made and will lead to a fairer
        and healthier world. We, as editors of health journals, call for governments
        and other leaders to act, marking 2021 as the year that the world finally
        changes course.</blockquote><p>The COVID Pandemic is currently taking up all
        our attention. But we should not loose time addressing the environmental crisis
        triggered by climate change, and having a significant negative impact on global
        health, both via direct effects of global heating and extreme weather events,
        and indirectly via reduced food production.</p><p>This joint editorial by
        more than 200 health journals worldwide is yet another clear sign of the urgency
        of the situation, and the need for action. And we should not forget that health
        is just one aspect of how the climate crisis is seriously affecting all our
        lives, in particular those most vulnerable.</p><p>The editorial makes a strong
        point that the time for action is now, and that wealthy nations must do much
        more, and much faster. It is also an opportunity to think about what we as
        individuals can do, whether it is about re-evaluating our individual carbon
        footprint, thinking about what political parties we support (Germany where
        I live for example has a federal election in three weeks), and whether the
        organizations we work for can do more to slow down global warming.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ A step forward for software citation: GitHub&#x27;s
        enhanced software citation support ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/step-forward-for-software-citation/\"
        />\n\t\t<id>https://doi.org/10.53731/r9531p1-97aq74v-ag78v</id>\n        <published>2021-08-24T16:57:24.000+00:00</published>\n\t\t<updated>2022-08-15T19:05:14.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/07/github-citation-screenshot.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/07/github-citation-screenshot.png\"></p><p>On
        August 19, <a href=\"https://github.blog/2021-08-19-enhanced-support-citations-github/\">GitHub
        announced</a> software citation support in GitHub repositories. Citation information
        provided by users (using a CITATION.cff YAML file in the root directory of
        the default branch) is parsed and made available as bibtex file or formatted
        citation, currently supporting the APA citation style. The APA style is a
        good start as it is the only popular citation style that labels software with
        the string <code>[Computer software]</code> but we hope to see support for
        more citation styles \u2013 including those popular in computer science \u2013
        going forward. Going forward we also hope to see support for biblatex and
        potentially <code>@software</code> as the bibtex entry type.</p><figure class=\"kg-card
        kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/07/Bildschirmfoto-2021-08-24-um-18.16.55.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"792\" height=\"626\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/07/Bildschirmfoto-2021-08-24-um-18.16.55.png
        600w, https://blog.front-matter.io/content/images/2022/07/Bildschirmfoto-2021-08-24-um-18.16.55.png
        792w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Cite this repository
        GitHub example</figcaption></figure><pre><code>@misc{Haines_Ruby_CFF_Library_2021,\n
        \ author = {Haines, Robert and {The Ruby Citation File\n  Format Developers}},\n
        \ doi = {10.5281/zenodo.1184077},\n  month = {8},\n  title = {{Ruby CFF Library}},\n
        \ url = {https://github.com/citation-file-format/ruby-cff},\n  year = {2021}\n}</code></pre><p>This
        is an important step forward for wider software citation adoption, as it allows
        software authors to provide the required information necessary for citing
        software directly in a GitHub code repository, and for tools and workflows
        to integrate with this information. Within days of the initial GitHub announcement
        via a tweet by GitHub CEO Nat Friedman, we saw support for this new workflow
        by the scholarly repository <a href=\"https://twitter.com/ZENODO_ORG/status/1420357001490706442\">Zenodo</a>
        and the reference manager <a href=\"https://twitter.com/zotero/status/1420515377390530560\">Zotero</a>
        (see below). The <a href=\"https://docs.softwareheritage.org/devel/swh-indexer/metadata-workflow.html\">swh-indexer</a>
        by <a href=\"https://www.softwareheritage.org/\">Software Heritage</a> (SWH)
        already indexed and supported searching over the CITATION.cff files available
        on the HEAD/master branch of a repository archived in SWH.</p><figure class=\"kg-card
        kg-embed-card\"><blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">We\u2019ve
        added support for GitHub\u2019s new citation feature. When saving GitHub repos
        to your library, Zotero can now use the enhanced metadata provided by developers.<br><br>If
        there\u2019s no citation file, Zotero will continue to use the existing repo
        metadata (Company, Prog. Language, etc.). <a href=\"https://t.co/Q34zPBRGFj\">https://t.co/Q34zPBRGFj</a></p>&mdash;
        Zotero (@zotero) <a href=\"https://twitter.com/zotero/status/1420515377390530560?ref_src=twsrc%5Etfw\">July
        28, 2021</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\"
        charset=\"utf-8\"></script>\n</figure><p>We also see hundreds of repositories
        adding CITATION.cff files every week since the initial announcement \u2013
        you can track the adoption via <a href=\"https://github.com/search?o=desc&amp;p=1&amp;q=CITATION.cff&amp;s=committer-date&amp;type=Commits\">this</a>
        GitHub query.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2022/07/Bildschirmfoto-2021-08-24-um-18.24.19.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"964\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/07/Bildschirmfoto-2021-08-24-um-18.24.19.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/07/Bildschirmfoto-2021-08-24-um-18.24.19.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2022/07/Bildschirmfoto-2021-08-24-um-18.24.19.png
        1600w, https://blog.front-matter.io/content/images/2022/07/Bildschirmfoto-2021-08-24-um-18.24.19.png
        2000w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Tracking Citation.CFF
        files via GitHub query</figcaption></figure><p>While a citation pointing to
        the GitHub code repository is a great start, ideally the software author wants
        to perform an important additional step: archive the source code in a long-term
        archive either via the Software Heritage universal software archive (detailed
        instructions <a href=\"https://www.softwareheritage.org/save-and-reference-research-software/\">here</a>,
        and automatable from the GitHub repository with a <a href=\"https://github.com/marketplace/actions/save-to-software-heritage\">GitHub
        Action</a>), and/or the scholarly repository Zenodo via the the <em>Making
        Your Code Citable</em> workflow described <a href=\"https://guides.github.com/activities/citable-code/\">here</a>,
        which will use the metadata provided in a CITATION.cff file.</p><p>One particular
        challenge with citing software is versioning, where there are multiple use
        cases to be supported, including the need to cite a specific version, and
        to aggregate the citations of all versions in a single place. There is more
        work needed to link <a href=\"https://docs.github.com/en/github/administering-a-repository/releasing-projects-on-github/managing-releases-in-a-repository\">GitHub
        releases</a> to the version information provided in this new GitHub feature,
        and to support the generic citation without a specific version \u2013 what
        Zenodo calls a <em>concept DOI</em>, and the Functional Requirements for Bibliographic
        Records (FRBR) call an <a href=\"https://en.wikipedia.org/wiki/Functional_Requirements_for_Bibliographic_Records\"><em>expression</em></a><em>.</em></p><p>Many
        software authors also want to link to a publication describing their software
        from the GitHub repository, and the <a href=\"https://citation-file-format.github.io/\">Citation
        File Format</a> (CFF) supports this via a \u2018<a href=\"https://github.com/citation-file-format/citation-file-format/blob/main/schema-guide.md#credit-redirection\">preferred-citation</a>\u2019
        field. Additionally, authors can cite the software (and other works) their
        software builds on in a \u2018<a href=\"https://github.com/citation-file-format/citation-file-format/blob/main/schema-guide.md#referencing-other-work\">references</a>\u2019
        section in CFF files. Software authors are expected to provide the relevant
        information in a CITATION.cff file in <a href=\"https://en.wikipedia.org/wiki/YAML\">YAML</a>
        format that follows the <a href=\"https://citation-file-format.github.io/\">Citation
        File Format</a> specification. An example CITATION.cff file can be found <a
        href=\"https://github.com/citation-file-format/ruby-cff/blob/main/CITATION.cff\">here</a>.</p><p>Some
        software authors might want to use tools to help generate the CITATION.cff
        file. A starting point is the CFF Initializer available <a href=\"https://citation-file-format.github.io/cff-initializer-javascript/\">here</a>,
        and a list of available tools for working with CFF files <a href=\"https://github.com/citation-file-format/citation-file-format/blob/main/README.md#tools-to-work-with-citationcff-files-wrench\">here</a>;
        we expect more tools to appear over time. There are many standards for describing
        software (we already mentioned bibtex and DOI metadata), and <a href=\"https://codemeta.github.io/\">CodeMeta</a>
        also plays a particularly important role by providing <a href=\"https://codemeta.github.io/crosswalk/\">crosswalks</a>
        and tools for converting between the various metadata standards for software.
        Going forward we expect to see more metadata conversion workflows, in particular
        via <a href=\"https://docs.github.com/en/actions\">GitHub Actions</a>, adding
        to the already existing <a href=\"https://github.com/marketplace/actions/cffconvert\">cffconvert</a>
        and <a href=\"https://github.com/marketplace/actions/codemeta2cff\">CodeMeta2CFF</a>
        GitHub Actions. We also hope to see similar software citation support appear
        in the GitLab platform.</p><p><em><a href=\"https://www.force11.org/blog/step-forward-software-citation-githubs-enhanced-software-citation-support\">Cross-posted</a>
        from the FORCE11 blog. Authors: Martin Fenner, Stephan Druskat, Neil Chue
        Hong, Daniel S. Katz, Morane Gruenpeter, Arfon Smith, Tom Morell and Robert
        Haines</em><br></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Support open source software as a GitHub
        sponsor ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/support-open-source/\"
        />\n\t\t<id>https://doi.org/10.53731/r8n4c91-97aq74v-ag6v9</id>\n        <published>2021-08-12T14:56:42.000+00:00</published>\n\t\t<updated>2022-08-15T19:06:37.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/07/images.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/07/images.png\"></p><p>Two
        years ago GitHub introduced the ability to sponsor an open source contributor
        \u2013 person or organization. They handle (and pay for) the payment logistics
        for a one-time or regular contribution. A <a href=\"https://github.blog/2019-06-12-faq-with-the-github-sponsors-team/\">blog
        post from June 2019</a> describes the thinking of the GiHub Sponsors team
        that went into this service, and the practicalities of using the service are
        documented <a href=\"https://docs.github.com/en/sponsors/sponsoring-open-source-contributors/sponsoring-an-open-source-contributor\">here</a>.</p><p>In
        my <a href=\"https://blog.front-matter.io/mfenner/how-readers-can-support\">last
        blog post</a> I talked about a similar concept, supporting this blog via a
        one-time donation or small monthly contribution. Similar to GitHub sponsors
        this is also a small voluntary contribution rather than a required payment,
        and it depends on a backend service that can handle small contributions of
        just a few dollars/euros.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2022/07/Bildschirmfoto-2021-08-12-um-16.06.31.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"1070\" height=\"555\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/07/Bildschirmfoto-2021-08-12-um-16.06.31.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/07/Bildschirmfoto-2021-08-12-um-16.06.31.png
        1000w, https://blog.front-matter.io/content/images/2022/07/Bildschirmfoto-2021-08-12-um-16.06.31.png
        1070w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Front Matter GitHub
        sponsoring</figcaption></figure><p>Readers of this blog know that I am a big
        fan of dog food (the <a href=\"https://en.wikipedia.org/wiki/Eating_your_own_dog_food\">saying</a>
        not the food). In this case it means that Front Matter should become a GitHub
        sponsor for open source software it depends on. As a small startup you have
        to start somewhere, and the pick for the first organization to support was
        an easy one: <a href=\"https://citationstyles.org/\">Citation Style Language</a>
        (CSL). For practical reasons Front Matter sponsors Rintze Zelle, one of the
        main contributors to CSL:</p><p>The reason I picked CSL is that I have never
        seen an open source project contributing to scholarly infrastructure so much
        with so few resources. CSL is everywhere (see the list of software products
        using CSL <a href=\"https://citationstyles.org/\">here</a>), and has been
        for many years. And there is no big organization standing behind CSL that
        pays a salary that allows one or more developers to work on CSL, a common
        pattern with important open source software. So a big thank you to <a href=\"https://twitter.com/bdarcus\">Bruce
        D'Arcus</a>, <a href=\"https://twitter.com/skornblith\">Simon Kornblith</a>,
        <a href=\"https://twitter.com/fgbjr\">Frank Bennett</a>, <a href=\"https://twitter.com/rintzezelle\">Rintze
        Zelle</a>, <a href=\"https://twitter.com/adam42smith\">Sebastian Karcher</a>,
        <a href=\"https://twitter.com/1nukshuk\">Sylvester Keil</a>, <a href=\"https://twitter.com/johanneskrtek\">Johannes
        Krtek</a>, Liam Magee, <a href=\"https://twitter.com/cparnot\">Charles Parnot</a>,
        Carles Pina, Andrea Rossato, <a href=\"https://twitter.com/danstillman\">Dan
        Stillman</a>, and <a href=\"https://twitter.com/zuphilip\">Philipp Zumstein</a>,
        to name just a few of the many contributors to CSL. You can thank them yourself
        in the <a href=\"https://discourse.citationstyles.org/\">CSL discussion forum</a>,
        but if your own software depends on CSL, please consider GitHub sponsorship.</p><p>GitHub
        sponsors and donations and memberships for the Front Matter blog are of course
        flavors of <a href=\"https://en.wikipedia.org/wiki/Crowdfunding\">crowdfunding</a>,
        which has an interesting history and many success stories you can learn from,
        and mistakes to avoid.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ How readers can support the Front Matter
        blog ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/how-readers-can-support/\"
        />\n\t\t<id>https://doi.org/10.53731/r8hb7h1-97aq74v-ag6ew</id>\n        <published>2021-08-10T14:19:57.000+00:00</published>\n\t\t<updated>2022-08-17T14:32:19.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/07/photo-1454165804606-c3d57bc86b40.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/07/photo-1454165804606-c3d57bc86b40.jpeg\"></p><p>The
        Front Matter blog <a href=\"https://blog.front-matter.io/posts/front-matter-officially-launches-today\">launched
        last week</a> and while the content is currently only written by me, I hope
        this will change in the coming months to include one-time guest posts and
        regular writers. One challenge is to figure out how to finance the blog in
        the long run. Running blog infrastructure is not overtly expensive, and in
        the case of the Front Matter blog amounts to about 120\u20AC/$140 a month:</p><ul><li>hosting
        Ghost blog editor 15\u20AC/month (<a href=\"https://www.digitalocean.com/\">Digital
        Ocean</a>)</li><li>hosting Next.js frontend 20\u20AC/month (<a href=\"https://vercel.com/\">Vercel</a>)</li><li>hosting
        full-text search index 35\u20AC/month (<a href=\"https://typesense.org/\">Typesense</a>)</li><li>hosting
        Discourse commenting platform 15\u20AC/month (<a href=\"https://www.digitalocean.com/\">Digital
        Ocean</a>)</li><li>web analytics \u20AC5/month (<a href=\"https://plausible.io/\">Plausible</a>)</li><li>registration
        domain name 35\u20AC/year (<a href=\"https://dnsimple.com/\">DNSimple</a>)
        </li><li>DOI registration \u20AC300/year (estimate, <a href=\"https://www.crossref.org/\">Crossref</a>)</li></ul><p>The
        cost not reflected above, is of course staff time for writing blog posts,
        but also editing, deciding on topics, reaching out to potential writers, etc.
        A reasonable goal would be to pay for an editor one day a week, which would
        add about 1280\u20AC/1500$ to the monthly cost running the blog. How can this
        be supported financially?</p><p>While there is always the hope of finding
        an organization (funder, publisher, institution, infrastructure provider,
        etc.) that cares enough about Open Science to pay for running this blog, a
        more realistic alternative is to depend on reader contributions, combined
        with volunteer donations. </p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2022/07/Bildschirmfoto-2021-08-09-um-20.21.20.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"1133\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/07/Bildschirmfoto-2021-08-09-um-20.21.20.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/07/Bildschirmfoto-2021-08-09-um-20.21.20.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2022/07/Bildschirmfoto-2021-08-09-um-20.21.20.png
        1600w, https://blog.front-matter.io/content/images/2022/07/Bildschirmfoto-2021-08-09-um-20.21.20.png
        2000w\" sizes=\"(min-width: 720px) 720px\"><figcaption><a href=\"https://www.buymeacoffee.com/frontmatter\">Buy
        Me a Coffee page</a> for Front Matter</figcaption></figure><p>Advertisements
        are a very painful way to recover even a fraction of the costs for running
        a blog that caters to a relatively small audience (scholarly communication).
        In response, several platforms, including <a href=\"https://medium.com/\">Medium</a>,
        <a href=\"https://ghost.org/\">Ghost</a> and <a href=\"https://substack.com/\">Substack</a>,
        have evolved with a business model focused on providing exclusive content
        to paying subscribers. This is obviously not an option for an Open Science
        blog, where the assumption is that content is free to read and reuse under
        a Creative Commons license.</p><p>Today the Front Matter blog is starting
        a newsletter with a small monthly subscription fee (3\u20AC/month or 30\u20AC/year).
        The newsletter does not provide exclusive content, but rather is a convenience
        for users to directly receive content in their email inbox rather than via
        the <a href=\"https://blog.front-matter.io/feed.xml\">Front Matter RSS Feed</a>.
        In addition, users can give one-time donations to support the Front Matter
        blog. These payment options are provided by <a href=\"https://www.buymeacoffee.com/\">Buy
        Me a Coffee</a>, with a <a href=\"https://blog.front-matter.io/support\">link</a>
        to the membership/support page in the footer of every Front Matter page \_(see
        screenshot below).</p><p>I hope that by the end of the year, some revenue
        will accrue that can support the Front Matter blog. It would definitely be
        a strong motivation to write regular Open Science blog posts with interesting
        content. A related aim is of course to nurture active and engaged readers
        who write comments in response to the posts, suggest topics to write about,
        and generally tell me via comments or email how Front Matter can do better.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ First InvenioRDM Long-Term Support (LTS)
        version released today \u2013 and Front Matter is joining as a participating
        partner ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/inveniordm-lts-announced/\"
        />\n\t\t<id>https://doi.org/10.53731/r8c26t1-97aq74v-ag66m</id>\n        <published>2021-08-05T17:15:49.000+00:00</published>\n\t\t<updated>2022-08-15T19:07:04.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/07/docs-site.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/07/docs-site.png\"></p><p>The
        open source research data management platform InvenioRDM <a href=\"https://inveniordm.docs.cern.ch/releases/versions/version-v6.0.0/
        \  \">today announced</a> the first Long-Term Support (LTS) release, usable
        on production services. And I am joining the effort as a participating partner
        via <a href=\"https://front-matter.io\">Front Matter</a>, the organization
        I started this week.</p><p>InvenioRDM was <a href=\"https://inveniosoftware.org/blog/2019-04-29-rdm/\">first
        announced in April 2019</a>:</p><blockquote>Our vision in the next five-years,
        is to make InvenioRDM a world-leading extensible research data management
        platform used by research institutions all around the world and with businesses
        providing services, support and customizations on top of InvenioRDM. </blockquote><p>The
        first concrete set of goals was defined as</p><ul><li>A stable InvenioRDM
        platform - A research data management platform based on <a href=\"https://zenodo.org/\">Zenodo</a>
        and the <a href=\"https://inveniosoftware.org/\">Invenio v3 Framework</a>.</li><li>A
        community of public and private institutions to sustain InvenioRDM.</li><li>Minimum
        two existing repositories migrated to InvenioRDM, with Zenodo being one of
        them.</li></ul><p>Today's release brings invenioRDM much closer to achieving
        these goals. The next major milestone for InvenioRDM is to migrate <a href=\"https://zenodo.org\">Zenodo</a>
        to run on top of InvenioRDM.</p><p>In the coming two months I will not only
        try to get up to speed with the invenioRDM project and start working with
        the CERN team and the other participating partners, but I also have the specific
        task of making sure invenioRDM fully supports the data citation roadmap for
        scholarly data repositories, work done by the <a href=\"https://www.force11.org/group/dcip\">Force11
        DCIP project</a> with Merce Crosas and me as co-leads, and described in a
        2019 <em>Scientific Data</em> paper (Fenner <em>et al</em>. 2019):</p><h3
        id=\"guidelines-for-repositories-1-5-required-6-9-recommended-10-11-optional\">Guidelines
        for Repositories (1-5 required, 6-9 recommended, 10-11 optional)</h3><ol><li>All
        datasets intended for citation must have a globally unique persistent identifier
        that can be expressed as an unambiguous URL.</li><li>Persistent identifiers
        for datasets must support multiple levels of granularity, where appropriate.</li><li>The
        persistent identifier expressed as an URL must resolve to a landing page specific
        for that dataset, and that landing page must contain metadata describing the
        dataset.</li><li>The persistent identifier must be embedded in the landing
        page in machine-readable format.</li><li>The repository must provide documentation
        and support for data citation.</li><li>The landing page should include metadata
        required for citation, and ideally also metadata facilitating discovery, in
        human-readable and machine-readable format.</li><li>The machine-readable metadata
        should use schema.org markup in JSON-LD format.</li><li>Metadata should be
        made available via HTML meta tags to facilitate use by reference managers.</li><li>Metadata
        should be made available for download in BibTeX and/or another standard bibliographic
        format.</li><li>Content negotiation for schema.org/JSON-LD and other content
        types may be supported so that the persistent identifier expressed as URL
        resolves directly to machine-readable metadata.</li><li>HTTP link headers
        may be supported to advertise content negotiation options</li></ol><p>Several
        of these recommendations are of course already addressed by invenioRDM, but
        there is more work needed in the details, e.g. how metadata are exposed in
        dataset landing pages using schema.org. And these recommendations have evolved,
        e.g. as described in the output of the <a href=\"https://www.rd-alliance.org/groups/research-metadata-schemas-wg\">Research
        Data Alliance (RDA) Research Metadata Schemas Working Group</a> published
        in June (Wu <em>et al. </em>2021).</p><p>Please reach out to me in the comments
        or via email if you have any questions or suggestions regarding this upcoming
        work, or more generally my new involvement in invenioRDM.</p><h3 id=\"references\">References</h3><p>Fenner,
        M., Crosas, M., Grethe, J. S., Kennedy, D., Hermjakob, H., Rocca-Serra, P.,
        Durand, G., Berjon, R., Karcher, S., Martone, M., &amp; Clark, T. (2019).
        A data citation roadmap for scholarly data repositories. <em>Scientific Data</em>,
        <em>6</em>(1). <a href=\"https://doi.org/10.1038/S41597-019-0031-8\">https://doi.org/10.1038/S41597-019-0031-8</a></p><p>Wu,
        M., Juty, N., RDA Research Metadata Schemas WG , Collins, J., Duerr, R., Ridsdale,
        C., Shepherd, A., Verhey, C., &amp; Castro, L. J. (2021). <em>Guidelines for
        publishing structured metadata on the Web</em>. <a href=\"https://doi.org/10.15497/RDA00066\">https://doi.org/10.15497/RDA00066</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Front Matter officially launches today ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/front-matter-officially-launches-today/\"
        />\n\t\t<id>https://doi.org/10.53731/r87krmh-97aq74v-ag5x0</id>\n        <published>2021-08-02T10:22:32.000+00:00</published>\n\t\t<updated>2023-07-24T11:16:19.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/07/photo-1484600899469-230e8d1d59c0.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/07/photo-1484600899469-230e8d1d59c0.jpeg\"></p><p>Front
        Matter describes the content preceding the main text of a book or journal.
        In science, several research journals, including <em>PLOS Biology</em>, <em>Nature,</em>
        and <em>Science</em>, have Front Matter sections, used for news, opinions,
        and other content that are not research articles. Front Matter is also the
        name of the company that I registered last month, as I think it is a good
        fit for what I am trying to accomplish, after leaving the DOI registration
        agency DataCite in July 2021 (<a href=\"https://doi.org/10.53731/r79qwf1-97aq74v-ag4j1\">Farewell
        to DataCite</a>), having been their Technical Director for six years.</p><p>I
        sincerely believe that there is a need for more venues that talk about emerging
        scholarly content types such as research data, research software, or preprints
        as scholarly outputs. The Front Matter Blog hopes to become such a venue.
        As a starting point I have added (almost) all my blog posts since 2007, collected
        from my previous blogging locations (<em>Nature Network</em>, <em>PLOS Blogs,
        </em>my Personal Blog, and the DataCite blog<em>)</em>, and I hope at least
        some of them still make an interesting read all these years later. Technically,
        the blog uses <a href=\"https://ghost.org/\">Ghost</a> and the Ghost Editor
        as a backend, and a frontend built with <a href=\"https://nextjs.org/\">Next.js</a>,
        a common <a href=\"https://jamstack.org/\">Jamstack</a> setup: </p><figure
        class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/07/jamstack-javascript-apis-markup.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"850\" height=\"394\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/07/jamstack-javascript-apis-markup.png
        600w, https://blog.front-matter.io/content/images/2022/07/jamstack-javascript-apis-markup.png
        850w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Jamstack, via <a href=\"https://snipcart.com/blog/jamstack\">Snipcart</a>.</figcaption></figure><p>Two
        features of the Front Matter Blog are particularly important to me:</p><ul><li>full-text
        search of all blog posts (with the help of \_<a href=\"https://typesense.org/\">Typesense</a>),
        as tags, categories, and search by title allow only limited content discovery,
        and \_</li><li>comments using a mature and open commenting system (<a href=\"https://www.discourse.org/\">Discourse</a>).</li></ul><p>There
        is more work planned for the coming months, with the next milestone being
        the registration of DOIs for all blog posts.</p><p>But Front Matter is more
        than a blogging platform. It is also a consulting business, which will help
        with building and hosting scholarly infrastructure. To kick this off, I am
        involved with development work for the <a href=\"https://inveniosoftware.org/products/rdm/\">InvenioRDM</a>
        data management repository platform. More on that in the next blog post on
        Thursday.</p><p><em>Special thanks to <a href=\"https://orcid.org/0000-0002-9317-6819\">Christine
        Ferguson</a> for reviewing the blog post before publishing.</em></p><h3 id=\"references\">References</h3><p>Fenner
        M. Farewell to DataCite. Published online July 9, 2021. doi:<a href=\"https://doi.org/10.53731/r79qwf1-97aq74v-ag4j1\">10.53731/r79qwf1-97aq74v-ag4j1</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Farewell to DataCite ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/farewell-to-datacite/\" />\n\t\t<id>https://doi.org/10.53731/r79qwf1-97aq74v-ag4j1</id>\n
        \       <published>2021-07-09T15:39:00.000+00:00</published>\n\t\t<updated>2022-08-15T19:06:05.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/07/photo-1529268209110-62be1d87fe75.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/07/photo-1529268209110-62be1d87fe75.jpeg\"></p><p>After
        six years as DataCite Technical Director, I am both sad and excited to announce
        that I will be leaving DataCite, beginning a new adventure as an independent
        developer for the <a href=\"https://inveniosoftware.org/products/rdm/\">invenioRDM</a>
        project on August 1st. My focus will remain on research data management, but
        with a different angle.</p><p>A lot has changed since 2015 at DataCite in
        general, and the DataCite technical architecture in particular. Rather than
        describe the work on DataCite infrastructure over the past six years in more
        detail, I want to provide a snapshot of where the DataCite infrastructure
        is with its core services, and what considerations the team is taking into
        account going forward.</p><h3 id=\"content-registration\">Content registration</h3><p>DataCite
        members can register DOIs and metadata for content using the Metadata Store
        (MDS). The MDS API hasn\u2019t changed much for users since 2012, although
        the technology powering the API has been replaced more than once, and the
        metadata schema is constantly evolving. We have added a JSON REST API and
        web frontend (<a href=\"https://doi.datacite.org/\">Fabrica</a>) starting
        in 2017. Going forward we hope to see more adoption of the JSON REST API,
        e.g. by finalizing and promoting the JSON schema. And we may want to explore
        other ways to register content, namely by embedding metadata in landing pages
        using schema.org in combination with sitemaps files.</p><h3 id=\"discovery\">Discovery</h3><p>In
        October 2020 DataCite launched <a href=\"https://commons.datacite.org/\">DataCite
        Commons</a> as a new discovery platform, followed by an announcement to retire
        DataCite Search by the end of 2021. DataCite Commons enables the discovery
        of connections between content, people, and organizations. DataCite Commons
        uses the existing DataCite backend infrastructure with relational databases
        and Elasticsearch in combination with a new <a href=\"https://graphql.org/\">GraphQL</a>
        API. Going forward we will see whether this approach scales appropriately,
        or whether a different technology is needed to power DataCite Commons. This
        would include the exploration of graph database technologies such as neo4j
        with or without GraphQL. Further, we will work to track the adoption of GraphQL
        and our REST API architecture.</p><h3 id=\"backend-services\">Backend services</h3><p>DataCite
        as an infrastructure provider has always focussed on backend APIs and related
        services. As part of this work, DataCite has migrated to a Docker container-based
        cloud architecture. There is still work ahead, from migrating to <a href=\"https://kubernetes.io/\">Kubernetes</a>
        to service meshes and better monitoring and handling of service loads.</p><h3
        id=\"frontend-services\">Frontend services</h3><p>The DataCite frontend service
        architecture has gradually evolved over the last six years, with the new services
        Fabrica and DataCite Commons using modern Javascript frameworks (Ember.js
        and Next.js, respectively). One side effect of this gradual evolution is a
        rather complex mix of technologies. Going forward, rewriting outdated services,
        and consolidating the various technologies are important goals. Combined with
        this could be the broader use of <a href=\"https://www.serverless.com/\">serverless
        architectures</a> which we started using in DataCite Commons.</p><h3 id=\"looking-ahead\">Looking
        ahead</h3><p>DataCite is in a good position to handle our technology projects
        during this transition. I have been working closely with the DataCite team
        to transition responsibilities and will continue to be involved in community
        initiatives. Matt will publish a blog post next week that will cover the future
        team structure.</p><p><em>This blog post was <a href=\"https://doi.org/10.5438/zx3k-3923\">originally
        published</a> on the DataCite Blog.</em></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ The DataCite Technology Stack ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/the-datacite-technology-stack/\"
        />\n\t\t<id>https://doi.org/10.53731/r79qyn1-97aq74v-ag4jh</id>\n        <published>2021-06-17T15:42:00.000+00:00</published>\n\t\t<updated>2023-09-07T11:58:43.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/07/reference_architecture-1.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/07/reference_architecture-1.png\"></p><p>DataCite
        is a DOI registration agency that enables the registration of scholarly content
        with a persistent identifier (DOI) and metadata. This content can then be
        searched for, reused, and connected to other scholarly resources. But how
        does the underlying infrastructure enable this? In this blog post, we will
        describe what we have built to make this work. This is a fairly technical
        post, as I tried to go a little deeper into the details.</p>\n<h3 id=\"cloud-hosting-and-devops\">Cloud
        hosting and DevOps</h3>\n<p>DataCite is a small nonprofit organization (<a
        href=\"https://datacite.org/team.html\">currently 12 team members</a>, including
        three in the development team), and the team is fully remote. All our infrastructure
        is running in the Cloud (most of it using Amazon Web Services (<a href=\"https://aws.amazon.com/\">AWS</a>),
        with the servers that store data located in Ireland). We have automated the
        operation of our services as much as possible, following <a href=\"https://en.wikipedia.org/wiki/DevOps\">DevOps</a>
        best practices. Because of the small team size, we have no separation of software
        development and system administration teams, and DevOps allows us to highly
        integrate these roles. Two important automation tools we use are <a href=\"https://docs.github.com/en/actions\">GitHub
        Actions</a> for Continues Integration/Continues Deployment (CI/CD) and <a
        href=\"https://www.terraform.io/\">Terraform</a> for managing \u201CInfrastructure
        as Code\u201D. While we are using Terraform since 2016, we have only recently
        migrated our CI/CD workflows from <a href=\"https://travis-ci.com/\">Travis
        CI</a> (finishing the migration in the next few months), mainly because GitHub
        Actions come with many ready-to-use actions for some of the more complex parts
        of our deployment pipeline. All DataCite software is available with an open
        license in a public GitHub repository, and that also includes our GitHub actions
        and Terraform configurations. You can for example find the code for our REST
        API <a href=\"https://github.com/datacite/lupo\">here</a>, and the corresponding
        GitHub actions <a href=\"https://github.com/datacite/lupo/tree/master/.github/workflows\">here</a>.</p>\n<h3
        id=\"datacite-backend-services\">DataCite backend services</h3>\n<p>The DataCite
        backend uses services that store data (files or databases), and we use managed
        AWS services for those, e.g. <a href=\"https://aws.amazon.com/rds/\">RDS</a>
        to manage our MySQL relational databases. Our APIs are all running as stateless
        Docker containers, and we use the Amazon Elastic Container Service (<a href=\"https://aws.amazon.com/ecs/\">ECS</a>),
        in combination with <a href=\"https://aws.amazon.com/elasticloadbalancing/application-load-balancer/\">Amazon
        Application Load Balancers</a> to manage those. The adoption of Docker containers
        was the biggest change in our infrastructure 2016-2019, and we have developed
        a lot of expertise in this area. Going forward we will switch to Kubernetes
        (<a href=\"https://aws.amazon.com/eks/\">AWS Kubernetes Service</a>) at some
        point, as it has become the de-facto standard for container management in
        the cloud and provides additional functionalities in a widely-used open source
        platform. In 2015 all backend services were written in Java, over the last
        six years \u2013 as we upgraded our services one after another \u2013 this
        has changed to backend services written in Ruby and Python. This might again
        change going forward, we have for example started to use an <a href=\"https://github.com/plausible/analytics\">open
        source software for collecting usage stats</a> that is written in Elixir.
        While we have to be careful as a small development team to not spread our
        expertise too wide, we need to be open to new technologies, and a grant-funded
        project that can be based on existing open source software</p>\n<h3 id=\"datacite-frontend-services\">DataCite
        frontend services</h3>\n<p>The DataCite frontend services have over time been
        clearly separated from backend services, with only one service still running
        as a full-stack service (mainly because of the special needs for authentication).
        <a href=\"https://github.com/datacite/bracco\">DataCite Fabrica</a> is our
        main service for account management and DOI registration and was originally
        launched in September 2017. Fabrica uses the Ember.js Javascript framework.
        Ember.js addresses the needs we have for this service but has not seen the
        same level of adoption as some other Javascript frameworks, namely React or
        Vue. When we launched <a href=\"https://commons.datacite.org/\">DataCite Commons</a>
        \u2013 our replacement for the DataCite Search discovery service \u2013 in
        October 2020, we decided to use the <a href=\"https://nextjs.org/\">Next.js</a>
        framework (based on React), together with GraphQL as the query language for
        our APIs. Next.js supports server-side rendering, which enabled us to provide
        embedded metadata (in particular in <a href=\"https://schema.org/\">schema.org</a>
        format) that are picked up by Google (e.g. for Google Dataset Search) and
        other indexers. The initial experience has been positive and we are going
        to not only build out the functionality \u2013 and performance \u2013 of DataCite
        Commons, but over time also transition our legacy frontend services to the
        same platform \u2013 currently we are using six different technologies for
        those, as they were built over time in the last ten years. We can then also
        explore more the use of <a href=\"https://www.serverless.com/\">serverless</a>
        as a technology to support our frontend services, as we are doing with DataCite
        Commons, running on the <a href=\"https://vercel.com/\">Vercel</a> platform.</p>\n<p>The
        following picture puts everything I talked about together into a single view
        (obviously omitting a lot of detail):</p>\n<figure class=\"kg-card kg-image-card\"><img
        src=\"https://blog.front-matter.io/content/images/2023/09/reference_architecture-1.png\"
        class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1280\" height=\"720\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2023/09/reference_architecture-1.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/09/reference_architecture-1.png
        1000w, https://blog.front-matter.io/content/images/2023/09/reference_architecture-1.png
        1280w\" sizes=\"(min-width: 720px) 720px\"></figure>\n<p>Please feel free
        to reach out to <a href=\"mailto:mfenner@datacite.org\">me</a> if you have
        any questions about the DataCite technology stack. If you are now interested
        in working for the DataCite development team, you can find more information
        about an open position <a href=\"https://doi.org/10.5438/wkc7-p624\">here</a>.</p>\n<h3
        id=\"acknowledgments\">Acknowledgments</h3>\n<p>This blog post was <a href=\"https://doi.org/10.5438/v5tc-zz53\">originally
        published</a> on the DataCite Blog.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ We need your feedback: Aligning the CodeMeta
        vocabulary for scientific software with schema.org ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/we-need-your-feedback-aligning-the-codemeta-vocabulary-for-scientific-software-with-schema-org/\"
        />\n\t\t<id>https://doi.org/10.53731/r79r1nh-97aq74v-ag4k9</id>\n        <published>2021-05-11T15:44:00.000+00:00</published>\n\t\t<updated>2022-07-30T18:51:43.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/07/photo-1516321497487-e288fb19713f.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/07/photo-1516321497487-e288fb19713f.jpeg\"></p><p>Metadata
        that describes scientific software in standard ways \u2013 in particular citation
        metadata such as title, authors, publication year, and venue \u2013 is essential
        for proper software citation implementation. The metadata should be generated
        by the software author, stored in the code repository, included in submissions
        to journals, and archived with the source code in a software archive. The
        CodeMeta community has created such a standard vocabulary, with version 2.0
        of the metadata schema released in 2017, and with mappings to common metadata
        standards for software source code, including DataCite metadata. Since that
        release, a task force of the Force11 Software Citation Implementation Working
        Group with co-chairs Morane Gruenpeter from Software Heritage and Martin Fenner
        from DataCite has worked on updating the schema to version 3.0, with a particular
        focus on aligning the CodeMeta schema with schema.org metadata.</p><p>The
        following terms in CodeMeta 2.0 are not (yet) part of schema.org:</p><ul><li>softwareSuggestions</li><li>maintainer</li><li>contIntegration</li><li>buildInstructions</li><li>developmentStatus</li><li>embargoDate</li><li>funding</li><li>issueTracker</li><li>referencePublication</li><li>Readme</li></ul><p>The
        CodeMeta Task Force of the Force11 Software Citation Implementation Working
        Group is now seeking community input via the CodeMeta GitHub issue tracker
        (summarized in <a href=\"https://github.com/codemeta/codemeta/issues/232\">https://github.com/codemeta/codemeta/issues/232</a>).
        The task force asks for input until June 15, so that CodeMeta version 3.0
        can ideally be finalized by July. After this work is done, the task force
        will propose the integration of all CodeMeta terms into the schema.org schema,
        so that CodeMeta becomes fully aligned with schema.org for better interoperability
        with existing documentation, tooling, and related communities. For any questions
        or comments that are not a good fit for the GitHub issue tracker, please reach
        out to the Task Force co-chairs Morane Gruenpeter and Martin Fenner via the
        <a href=\"https://www.force11.org/group/software-citation-implementation-working-group\">Force11
        Software Citation Implementation WG Homepage</a>.</p><p><em><em>This blog
        post was <a href=\"https://doi.org/10.5438/a49j-x692\">originally published</a>
        on the DataCite </em>B<em>log.</em></em></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ DataCite Commons at your service ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/datacite-commons-at-your-service/\"
        />\n\t\t<id>https://doi.org/10.53731/r79r7fh-97aq74v-ag4m5</id>\n        <published>2020-10-29T00:00:00.000+00:00</published>\n\t\t<updated>2023-09-07T11:54:41.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/07/bildschirmfoto-2020-10-28-um-12.02.32-1.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/07/bildschirmfoto-2020-10-28-um-12.02.32-1.png\"></p><p>DataCite
        and the <a href=\"https://www.project-freya.eu/en\">FREYA project</a> partners
        are proud to announce the official launch of <a href=\"https://commons.datacite.org/\">DataCite
        Commons</a> today. DataCite Commons is the web interface to explore the PID
        Graph, formed by the publications, datasets, research software, and other
        research outputs generated by researchers working at research institutions
        and supported by grant funding (<strong>???</strong>). The PID Graph depends
        on persistent identifiers to uniquely identify all these resources, and metadata
        that describe these resources and their connections.</p>\n<figure class=\"kg-card
        kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/07/bildschirmfoto-2020-10-28-um-11.42.23.png\"
        class=\"kg-image\" alt=\"\" loading=\"lazy\" title=\"DataCite Commons data
        sources summarized on the DataCite Commons statistics page.\" width=\"2000\"
        height=\"657\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/07/bildschirmfoto-2020-10-28-um-11.42.23.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/07/bildschirmfoto-2020-10-28-um-11.42.23.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2022/07/bildschirmfoto-2020-10-28-um-11.42.23.png
        1600w, https://blog.front-matter.io/content/images/2022/07/bildschirmfoto-2020-10-28-um-11.42.23.png
        2064w\" sizes=\"(min-width: 720px) 720px\"></figure>\n<p>We launched a pre-release
        version of DataCite Commons in August [Fenner (<a href=\"https://blog.datacite.org/datacite-commons-at-your-service/#ref-https://doi.org/10.5438/f4df-4817\">2020a</a>)]
        and have used the last two months not only for many small improvements and
        bug fixes, but also to add two important new features: a statistics page that
        describes the information available in the PID Graph, and personal accounts
        that allow for ORCID claiming and other functionality going forward.</p>\n<p>While
        DataCite Commons includes all PIDs and metadata from DataCite and Research
        Organization Registry (ROR), it currently includes only a subset of metadata
        from ORCID, and only a subset of DOIs and metadata from Crossref. Other persistent
        identifiers for scholarly resources will be added over time. The statistics
        page shows the current coverage of DataCite Commons and thus the FREYA PID
        Graph. The statistics page also shows the current numbers of the connections
        between works, between works and people, and between works and organizations,
        allowing us to track the growth of the PID Graph over time.</p>\n<p>User accounts
        are the other big change in this DataCite Commons release. They make it easier
        to navigate to your personal DataCite Commons page, listing all your publications,
        datasets, and software that DataCite Commons knows about. But more importantly,
        these personal accounts enable ORCID claiming, adding one or more works to
        your ORCID Record. When you search for works in DataCite Commons after logging
        in, you can see the works that have already been sent to your ORCID Record
        by DataCite, or an error message is shown if something went wrong. The next
        step, actual claiming from DataCite Commons search results, is in the final
        phase of development and will be open for beta testers in November.</p>\n<p>This
        release of DataCite Commons wraps up the work on the PID Graph in the FREYA
        project, which will end at the end of November. We went from the initial idea
        for the PID Graph concept to the implementation of a production service for
        users, following the process summarized below.</p>\n<h3 id=\"user-story-collection-and-prioritization\">User
        story collection and prioritization</h3>\n<p>In 2018 the FREYA project partners
        started collecting user stories that address important needs of their respective
        communities. In an August 2018 workshop, we discussed these user stories,
        grouped them together, and prioritized them. The main categories were the
        aggregation of scholarly outputs, e.g. by research institution, funder, or
        researcher; the versioning and granularity of data and software, and the grouping
        of all research outputs and other resources (e.g. data, software, people,
        funding) for a given publication. All these user stories depend on a PID Graph,
        with typically two connections needed in the graph, e.g. \u201Cshow me all
        citations for datasets funded by a particular grant\u201D.</p>\n<h3 id=\"technical-architecture-and-api-development\">Technical
        architecture and API development</h3>\n<p>Based on these requirements we started
        to investigate if our existing technical architecture supported these user
        stories, or what changes would be needed. The initial exploration looked at
        incremental changes to our existing REST APIs, but it became clear that more
        fundamental changes would be needed, supporting queries of the PID Graph in
        a number of different ways. In the spring of 2019, we decided to use GraphQL
        as the underlying technology for the PID Graph, as it supports the kinds of
        queries common in the PID Graph, is widely adopted in terms of software libraries,
        documentation, and developer community, and can be easily integrated into
        existing backend systems such as relational databases and search indexes such
        as Solr or Elasticsearch. DataCite released a GraphQL API pre-release version
        in May 2019, and a production version in May 2020 (Fenner, <a href=\"https://blog.datacite.org/datacite-commons-at-your-service/#ref-https://doi.org/10.5438/yfck-mv39\">2020b</a>).</p>\n<h3
        id=\"web-frontend-development\">Web frontend development</h3>\n<p>The GraphQL
        API we had developed allowed us to address the user stories we identified,
        and we started to write Jupyter notebooks as a platform that makes it easier
        to work with the GraphQL API, and in August 2020 the FREYA project released
        ten Jupyter notebooks addressing some of the user stories we had identified
        (Fenner &amp; Petryszak, <a href=\"https://blog.datacite.org/datacite-commons-at-your-service/#ref-https://doi.org/10.5281/zenodo.4004426\">2020</a>).
        But APIs and Juypter notebooks are still a significant hurdle for many users,
        and in the spring of 2020 we started work on a web frontend for the GraphQL
        API and thus the PID Graph. In August 2020 we launched a pre-release version
        of this web frontend and called it DataCite Commons (Fenner, <a href=\"https://blog.datacite.org/datacite-commons-at-your-service/#ref-https://doi.org/10.5438/f4df-4817\">2020a</a>).
        Today we are officially releasing DataCite Commons (Fenner, Hallett, Garza,
        &amp; Wimalaratne, <a href=\"https://blog.datacite.org/datacite-commons-at-your-service/#ref-https://doi.org/10.14454/qgk4-zs88\">2020</a>)
        as the web frontend for the FREYA PID Graph and as a key FREYA contribution
        to the European Open Science Cloud (EOSC).</p>\n<h3 id=\"monitoring-and-feedback\">Monitoring
        and feedback</h3>\n<p>The release of DataCite Commons is an important milestone,
        but more work is needed to make sure that DataCite Commons addresses the needs
        of its users, and that the service sees significant use by the community.
        The focus for the next few months will therefore be on monitoring for traffic,
        bugs and other issues, and feedback collection regarding additional features.
        Add your ideas to the <a href=\"https://datacite.org/roadmap.html\">DataCite
        Public Roadmap</a> or send comments and questions to <a href=\"mailto:info@datacite.org\">mailto:info@datacite.org</a>.</p>\n<h3
        id=\"acknowledgments\">Acknowledgments</h3>\n<p>This blog post was <a href=\"https://doi.org/10.5438/mkpq-4w71\">originally
        published</a> on the DataCite Blog. This work was funded by the European Union\u2019s
        Horizon 2020 research and innovation programme under&nbsp;<a href=\"https://doi.org/10.3030/777523\"
        rel=\"noreferrer\">grant agreement No.&nbsp;777523</a>.</p>\n<h3 id=\"references\">References</h3>\n<p>Fenner
        M. DataCite Commons - Exploiting the Power of PIDs and the PID Graph. Published
        online August 27, 2020. doi:<a href=\"https://doi.org/10.5438/F4DF-4817\">10.5438/F4DF-4817</a></p>\n<p>Fenner
        M. Powering the PID Graph: announcing the DataCite GraphQL API. Published
        online May 6, 2020. doi:<a href=\"https://doi.org/10.5438/YFCK-MV39\">10.5438/YFCK-MV39</a></p>\n<p>Fenner
        M, Petryszak R. FREYA webinar - The PID Graph in practice - Jupyter Notebook
        demonstration. Published online August 27, 2020. doi:<a href=\"https://doi.org/10.5281/ZENODO.4004426\">10.5281/ZENODO.4004426</a></p>\n<p>Fenner
        M, Hallett R, Garza K, Wimalaratne S. Frontend for the DataCite Commons service.
        Published online October 18, 2020. doi:<a href=\"https://doi.org/10.14454/QGK4-ZS88\">10.14454/QGK4-ZS88</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ DataCite switches to Globus for Authentication
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/datacite-switches-to-globus-for-authentication/\"
        />\n\t\t<id>https://doi.org/10.53731/r79ra81-97aq74v-ag4mr</id>\n        <published>2020-10-14T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-15T08:26:02.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/bildschirmfoto-2019-10-09-um-19.16.21-1.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/bildschirmfoto-2019-10-09-um-19.16.21-1.png\"></p><p>Access
        to some DataCite resources and services requires authentication so that DataCite
        knows who is making a request. This includes <a href=\"https://doi.datacite.org/\">Fabrica</a>,
        our DOI registration service that requires a member account, but also our
        integration with ORCID in the <a href=\"https://profiles.datacite.org/\">Profiles</a>
        service, where researchers authenticate with us to allow us to send information
        about content with DataCite DOIs authored by them to their ORCID record.</p><p>Authentication
        needs to be secure, not allowing access by the wrong people, but also practical,
        as otherwise poor password behavior with reduced security might result, as
        highlighted in the 2019 update of the NIST guidelines (Grassi, Garcia, &amp;
        Fenton (<a href=\"https://blog.datacite.org/globus-authentication/#ref-https://doi.org/10.6028/nist.sp.800-63-3\">2017</a>))
        that set the industry standard. With this in mind, we have two main goals
        for improving authentication with DataCite services: a) phase-out of institutional
        logins in favor of more secure personal accounts, and b) consolidate authentication
        into a single service to simply access to all secured resources.</p><p>We
        started work on improving DataCite authentication two months ago, beginning
        with a major upgrade of the <a href=\"https://profiles.datacite.org/\">Profiles</a>
        service. We are relaunching this upgraded service today. Most changes are
        under the hood and not visible to users; they include much-needed maintenance
        work, but also an improved administration interface for DataCite staff.</p><p>One
        visible change for users is the new sign in via Globus. <a href=\"https://www.globus.org/\">Globus</a>,
        an initiative at the University of Chicago - and a DataCite member -, is a
        non-profit service that provides reliable data transfer and sharing, and authentication
        services for the research community. Globus\u2019 overall mission not only
        aligns well with DataCite\u2019s mission but its authentication service, Globus
        Auth, provides the functionality needed by DataCite and DataCite users. The
        previous version of the Profiles service allowed login via ORCID, Google,
        and GitHub, but did not support the use of institutional identities. Globus
        allows users to login with their institutional account, supporting several
        hundred such federated identities via InCommon and eduGAIN federations and
        other custom identity providers.</p><p>DataCite now integrates with Globus
        via OpenID Connect, and requires that users login either with their ORCID
        identity or with another identity (e.g., an institutional account) linked
        to that ORCID identity via Globus. We use the ORCID ID to identify the user
        independent of email addresses or other information that may change over time,
        aligned with the recommendation of using the eduPersonORCID property in Federated
        Identity Management (Demeranville (<a href=\"https://blog.datacite.org/globus-authentication/#ref-https://doi.org/10.5281/zenodo.1064011\">2017</a>)).
        For authenticating ORCID claiming, a second step is needed, obtaining the
        required permissions directly from ORCID to write to the user\u2019s ORCID
        record. This integration of Globus allows DataCite to focus on providing persistent
        identifier services, while relying on Globus for authentication services.</p><p>While
        connecting authentication via OpenID Connect is straightforward, we made the
        process even easier for Ruby users by writing the omniauth-globus Ruby gem
        (Fenner (<a href=\"https://blog.datacite.org/globus-authentication/#ref-https://doi.org/10.14454/81gp-9y63\">2019</a>))
        that requires only the minimal configuration of a CLIENT_ID, CLIENT_SECRET,
        and REDIRECT_URL.</p><p>This change is just the first step in our work on
        improving authentication to DataCite services. As a next step, we will provide
        personal accounts, roles, and permissions for our DOI registration service
        Fabrica, which currently uses a separate authentication workflow and institutional
        accounts. We will continue partnering with Globus to wrap up this work before
        the end of 2019 but will keep the login option via institutional accounts
        until the end of 2020. In early 2020, we will start providing authentication
        tokens (in addition to basic authentication via username/password) for API
        users, and we will improve our integration with ORCID via a pilot of the <a
        href=\"https://members.orcid.org/service-provider-workflow\">ORCID token delegation</a>
        workflow.</p><p>If you have any questions about these authentication updates,
        don\u2019t hesitate to contact us at <a href=\"mailto:support@datacite.org\">mailto:support@datacite.org</a>.</p><p><em>This
        blog post was <a href=\"https://doi.org/10.5438/08jb-pn73\">originally published</a>
        on the DataCite Blog.</em></p><h2 id=\"references\">References</h2><p>Demeranville,
        T. (2017). Federated identity and identifiers. <a href=\"https://doi.org/10.5281/ZENODO.1064011\">https://doi.org/10.5281/ZENODO.1064011</a></p><p>Fenner,
        M. (2019). Omniauth-globus: Provides basic support for authenticating a client
        application via the globus service. DataCite. <a href=\"https://doi.org/10.14454/81GP-9Y63\">https://doi.org/10.14454/81GP-9Y63</a></p><p>Grassi,
        P. A., Garcia, M. E., &amp; Fenton, J. L. (2017). <em>Digital identity guidelines:
        Revision 3</em>. National Institute of Standards; Technology. Retrieved from
        <a href=\"https://doi.org/10.6028%2Fnist.sp.800-63-3\">https://doi.org/10.6028%2Fnist.sp.800-63-3</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Making the most out of available Metadata
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/making-the-most-out-of-available-metadata/\"
        />\n\t\t<id>https://doi.org/10.53731/r79rdp1-97aq74v-ag4nb</id>\n        <published>2020-09-07T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-15T08:33:57.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/bildschirmfoto-2020-07-09-um-07.35.30.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/bildschirmfoto-2020-07-09-um-07.35.30.png\"></p><p>Metadata
        are essential for finding, accessing, and reusing scholarly content, i.e.
        to increase the FAIRness [Wilkinson et al. (<a href=\"https://blog.datacite.org/making-the-most/#ref-https://doi.org/10.1038/sdata.2016.18\">2016</a>)]
        of datasets and other scholarly resources. A rich and standardized metadata
        schema that is widely used is the first step, encouraging users to register
        these metadata (as many of these are optional and not required) is the second
        step, while infrastructure providers such as DataCite facilitating metadata
        registration and making the most of the available metadata is the third step.
        While we all have put considerable energy into the first two steps, I want
        to use this blog post to describe what DataCite is doing to improve metadata
        FAIRness via our services. I will focus on three important optional metadata
        properties and on two approaches: encouraging metadata registration in a standardized
        way using the new DOI form in our Fabrica service, and improving discovery
        via search filters in the next major release of DataCite Search, that we have
        started development work on.</p><h3 id=\"language\">Language</h3><p>DataCite
        metadata can include the primary language of the resource, using either the
        <a href=\"https://tools.ietf.org/html/bcp47\">BCP 47</a> (e.g. <em>en-US</em>)
        or <a href=\"https://en.wikipedia.org/wiki/ISO_639-1\">ISO 639-1</a> (e.g.
        <em>en</em>) controlled vocabularies. In the context of discovery, the ISO
        639-1 code is most helpful, as we want to find resources we can understand
        because we speak the language, and not necessarily care about the nuances
        of for example U.S. English vs. British English. In Fabrica, the DOI form
        uses the list of languages in ISO 639-1, and that is also what we will use
        for filters in search.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/bildschirmfoto-2020-07-09-um-07.03.28-2.webp\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"DOI form language\" width=\"500\"
        height=\"370\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/bildschirmfoto-2020-07-09-um-07.03.56.webp\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"Search facet language\" width=\"300\"
        height=\"227\"></figure><p>Going forward, it would make sense to consider
        allowing multiple languages per resource. This will not only allow using both
        BCP 47 and ISO 639-1, addressing different use cases, but will also allow
        the proper description of multilingual resources.</p><h3 id=\"rights\">Rights</h3><p>Rights
        information about a resource is essential, as it informs the user if and under
        what conditions the resource can be reused. In order to allow users to filter
        by a specific license, rights information needs to be normalized. In theory,
        a URL pointing to a specific license is all that is needed, but we also need
        a human-readable string, and ideally also an abbreviation for the license
        (e.g. Creative Commons Attribution 4.0 International and CC-BY-4.0 for https://creativecommons.org/licenses/by/4.0/legalcode),
        and, more importantly, many licenses have more than one URL, e.g.</p><ul><li><a
        href=\"http://creativecommons.org/licenses/by/4.0\">http://creativecommons.org/licenses/by/4.0</a></li><li><a
        href=\"http://creativecommons.org/licenses/by/4.0/\">http://creativecommons.org/licenses/by/4.0/</a></li><li><a
        href=\"https://creativecommons.org/licenses/by/4.0/\">https://creativecommons.org/licenses/by/4.0/</a></li><li><a
        href=\"https://creativecommons.org/licenses/by/4.0/legalcode\">https://creativecommons.org/licenses/by/4.0/legalcode</a></li></ul><p>We
        can address this by normalizing the URLs for all licenses, and providing a
        standard name and abbreviation. Luckily, this work has already been done by
        the [Software Package Data Exchange](https://spdx.dev/) (SPDX) project of
        the Linux Foundation. While SPDX focusses on software licenses, it also includes
        all Creative Commons licenses, which are the most common licenses used in
        DataCite metadata for data and text. In metadata schema 4.2, released in March
        2019, we added the properties <em>rightsIdentifier</em>, <em>rightsIdentifierScheme</em>
        and <em>schemeURI</em>, and this enables the use of SPDX. In the past few
        months we have added SPDX support to the DOI form, and we will have search
        facets based on SPDX.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/bildschirmfoto-2020-07-09-um-07.35.30-3.png\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"DOI form rights\" width=\"1428\"
        height=\"822\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/bildschirmfoto-2020-07-09-um-07.35.30-3.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/08/bildschirmfoto-2020-07-09-um-07.35.30-3.png
        1000w, https://blog.front-matter.io/content/images/2022/08/bildschirmfoto-2020-07-09-um-07.35.30-3.png
        1428w\" sizes=\"(min-width: 720px) 720px\"></figure><figure class=\"kg-card
        kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/bildschirmfoto-2020-07-09-um-07.36.41.webp\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"Search facet license\" width=\"300\"
        height=\"179\"></figure><h3 id=\"subject-area\">Subject Area</h3><p>DataCite
        metadata have a very flexible Subject property, with sub-properties <em>SubjectScheme</em>,
        <em>SchemeURI</em>, and <em>ValueURI</em>. Unfortunately there is no standard
        way to describe the subject area covered by the resource. This makes it difficult
        to find content described by DataCite metadata in for example Mathematics,
        or to understand to what extend the various disciplines use DataCite DOIs.
        There are many subject area classification schemes, but the most widely used
        generic classification scheme is the <a href=\"https://www.oecd.org/science/inno/38235147.pdf\">OECD
        Fields of Science classification</a> with 6 top-level categories and 42 subcategories.
        We have implemented the OECD Fields of Science classification in the DOI form,
        and will do so in search facets.</p><figure class=\"kg-card kg-image-card\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/bildschirmfoto-2020-07-09-um-07.51.23.webp\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"DOI form subject\" width=\"500\"
        height=\"240\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/bildschirmfoto-2020-07-09-um-07.52.20.webp\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"Search field of science facet\"
        width=\"300\" height=\"389\"></figure><p>While OECD Fields of Science is the
        most commonly used generic subject classification, the most widely used subject
        classification we currently find in DataCite metadata is the <a href=\"https://www.abs.gov.au/Ausstats/abs@.nsf/Latestproducts/6BB427AB9696C225CA2574180004463E?opendocument\">Australian
        and New Zealand Standard Research Classification (ANZSRC) Fields of Research</a>.
        This classification is much more detailed, supporting different use cases.
        Luckily there is an official ANZSRC mapping to the OECD Fields of Science.
        This allows us to automatically add the OECD Fields of Science category or
        subcategory if the ANZSRC Fields of Research is used in DataCite metadata.</p><h3
        id=\"going-forward\">Going Forward</h3><p>We hope that the DOI form makes
        it easier to register more of the optional but important metadata in a standardized
        way, and that the new search filters we are launching in a few months will
        improve discoverability of the content. And that in turn this encourages DataCite
        members and their repositories to include this information in DOI metadata
        also when using one of the DataCite APIs for DOI registration. There are sometimes
        good reason to do things differently, and this also includes metadata for
        language, rights and subject. The DataCite metadata schema provides the flexibility
        needed, but we hope that in most cases the standard vocabularies ISO 639-1,
        SPDX and OECD Fields of Science will be used, improving the finding, accessing,
        and reusing of scholarly content with DataCite metadata for everyone.</p><p>Of
        course, we shouldn\u2019t forget the important work of the DataCite Metadata
        Working Group, which is busy working on the next DataCite schema version.
        That is a topic for another blog post, but I can already tell you that DataCite
        metadata will better support text documents.</p><p><em>This blog post was
        <a href=\"https://doi.org/10.5438/1dgk-1m22\">originally published</a> on
        the DataCite Blog.</em></p><h3 id=\"references\">References</h3><p>Wilkinson,
        M. D., Dumontier, M., Aalbersberg, I. J., Appleton, G., Axton, M., Baak, A.,
        \u2026 Mons, B. (2016). The FAIR guiding principles for scientific data management
        and stewardship. <em>Scientific Data</em>, <em>3</em>(1). <a href=\"https://doi.org/10.1038/sdata.2016.18\">https://doi.org/10.1038/sdata.2016.18</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ DataCite Commons - Exploiting the Power
        of PIDs and the PID Graph ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/datacite-commons-exploiting-the-power-of-pids-and-the-pid-graph/\"
        />\n\t\t<id>https://doi.org/10.53731/kx45q-14h82</id>\n        <published>2020-08-27T00:00:00.000+00:00</published>\n\t\t<updated>2023-09-07T11:52:47.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/bildschirmfoto-2020-08-25-um-06.33.07.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/bildschirmfoto-2020-08-25-um-06.33.07.png\"></p><p>Today
        DataCite is proud to announce the launch of <a href=\"https://commons.datacite.org/\">DataCite
        Commons</a>, available at <a href=\"https://commons.datacite.org/\">https://commons.datacite.org</a>.
        DataCite Commons is a discovery service that enables simple searches while
        giving users a comprehensive overview of connections between entities in the
        research landscape. This means that DataCite members registering DOIs with
        us will have easier access to information about the use of their DOIs and
        can discover and track connections between their DOIs and other entities.
        DataCite Commons was developed as part of the EC-funded project Freya and
        will form the basis of new DataCite services.</p>\n<h3 id=\"content\">Content</h3>\n<p>DataCite
        Commons has a lot of content to search for. One of the most important features
        is the ability to search for all DOIs, no matter whether registered with DataCite,
        Crossref, or one of the other scholarly DOI registration agencies. Users want
        to search for content or look up metadata for a particular DOI, and not worry
        about where to look. DataCite initially focused on registering DOIs for datasets
        (approaching 8 million DOIs so far), but our members to date have also registered
        almost 6 million DOIs for text publications. At the same time, Crossref members
        have given almost 2 million DOIs to datasets in addition to the DOIs for journal
        articles, book chapters, and other text publications. Other content types
        can be equally found at both DataCite and Crossref, e.g. dissertations or
        preprints. And there are 6 more <a href=\"https://www.doi.org/registration_agencies.html\">DOI
        registration agencies</a> that register DOIs for scholarly content. Including
        the more than 110 million Crossref DOIs in DataCite Commons is a huge undertaking.
        We currently have 10 million Crossref DOIs in DataCite Commons with the import
        of many more DOIs ongoing, together with 20 million DOIs from DataCite.</p>\n<h3
        id=\"connections\">Connections</h3>\n<p>DataCite Commons not only has a lot
        more content to search for but also exposes the connections between DOIs in
        the form of citations, versions, and collections. DataCite Commons also shows
        the connections between content with DOIs and people, research organizations,
        and funders \u2013 what we together call the PID Graph of scholarly resources
        identified via persistent identifiers (PIDs) and connected in standard ways.
        We integrate with both the <a href=\"https://orcid.org/\">ORCID</a> and <a
        href=\"https://ror.org/\">ROR</a> (Research Organization Registry) APIs to
        enable a search for (10 million) people and (100,000) organizations and to
        show the associated content. For funding, we take advantage of the inclusion
        of Crossref Funder IDs in ROR metadata. We combine these connections, showing
        a funder, research organization, or researcher not only their content but
        also the citations and views and downloads if available, together with aggregate
        statistics such as numbers by year or content type.</p>\n<figure class=\"kg-card
        kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/bildschirmfoto-2020-08-25-um-06.34.23.webp\"
        class=\"kg-image\" alt=\"\" loading=\"lazy\" title=\"Works by organization\"
        width=\"1940\" height=\"1354\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/bildschirmfoto-2020-08-25-um-06.34.23.webp
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/08/bildschirmfoto-2020-08-25-um-06.34.23.webp
        1000w, https://blog.front-matter.io/content/images/size/w1600/2022/08/bildschirmfoto-2020-08-25-um-06.34.23.webp
        1600w, https://blog.front-matter.io/content/images/2022/08/bildschirmfoto-2020-08-25-um-06.34.23.webp
        1940w\" sizes=\"(min-width: 720px) 720px\"></figure>\n<p>For a single work,
        e.g. the dataset registered with DOI <a href=\"https://commons.datacite.org/doi.org/10.5061/dryad.234\">https://doi.org/10.5061/dryad.234</a>,
        we show views, downloads and citations if available:</p>\n<figure class=\"kg-card
        kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/bildschirmfoto-2020-08-25-um-06.33.07.webp\"
        class=\"kg-image\" alt=\"\" loading=\"lazy\" title=\"Views, downloads and
        citations\" width=\"1458\" height=\"1190\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/bildschirmfoto-2020-08-25-um-06.33.07.webp
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/08/bildschirmfoto-2020-08-25-um-06.33.07.webp
        1000w, https://blog.front-matter.io/content/images/2022/08/bildschirmfoto-2020-08-25-um-06.33.07.webp
        1458w\" sizes=\"(min-width: 720px) 720px\"></figure>\n<h3 id=\"metadata\">Metadata</h3>\n<p>By
        mapping all Crossref metadata to corresponding metadata in DataCite, we can
        support much more granular search queries compared to just mapping basic metadata.
        With this release, we are also launching a new set of filters for content
        search. We added license type, fields of science, primary language, and DOI
        registration agency to the existing filters publication year and work type.
        As described in a July blog post (Fenner, <a href=\"https://blog.datacite.org/power-of-pids/#ref-https://doi.org/10.5438/1dgk-1m22\">2020a</a>),
        we are using existing controlled vocabularies for these filters (license type:
        <a href=\"https://spdx.dev/\">SPDX</a>, fields of science: <a href=\"https://www.oecd.org/science/inno/38235147.pdf\">OECD</a>,
        and language: <a href=\"https://www.iso.org/iso-639-language-codes.html\">ISO639-1</a>),
        and are re-indexing all our metadata (almost completed) to align with these
        standard vocabularies where possible. We encourage our members to use these
        standard vocabularies when registering content. This should help to find content
        that has a license that allows unrestricted re-use, and that is in the research
        field and language we are interested in. Using these widely used vocabularies
        should help with interoperability with other services.</p>\n<figure class=\"kg-card
        kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/bildschirmfoto-2020-08-25-um-06.29.39.webp\"
        class=\"kg-image\" alt=\"\" loading=\"lazy\" title=\"Filtering by license\"
        width=\"546\" height=\"494\"></figure>\n<h3 id=\"technology\">Technology</h3>\n<p>To
        make DataCite Commons possible, we built a technology platform that can properly
        handle the metadata from multiple sources and the rich connections between
        them. The underlying technology is <a href=\"https://graphql.org/\">GraphQL</a>.
        Our GraphQL API launched in May 2020 (Fenner, <a href=\"https://blog.datacite.org/power-of-pids/#ref-https://doi.org/10.5438/yfck-mv39\">2020b</a>)
        and uses the <a href=\"https://graphql-ruby.org/\">graphql-ruby</a> library
        that also powers the GitHub GraphQL API. The DataCite Commons web frontend
        is built with <a href=\"https://reactjs.org/\">React</a> (together with <a
        href=\"https://www.apollographql.com/docs/react/\">Apollo Client</a>), a popular
        Javascript Framework, to interact with this GraphQL API. Everything we have
        built is based on open source software and is made available (<a href=\"https://github.com/datacite/lupo\">API</a>
        and <a href=\"https://github.com/datacite/akita\">web frontend</a>) with a
        permissive open source license. As always, we welcome contributions to our
        source code and are more than happy to help others work with GraphQL.</p>\n<h3
        id=\"project-freya\">Project FREYA</h3>\n<p>The work on DataCite Commons is
        part of the <a href=\"https://www.project-freya.eu/en\">FREYA project</a>
        that is helping build the European Open Science Cloud (EOSC), funded by the
        European Commission. DataCite Commons fulfills the specific project goals
        of delivering one Common DOI Search for DOIs from all DOI registration agencies,
        and of providing an easy to use interface for the PID Graph powered by GraphQL.
        FREYA will end in November 2020, and we will use the remaining three months
        to improve the service based on the input we collected so far, and the feedback
        we will receive with this release. We will focus on supporting researchers
        and other end-users, building on the schema.org metadata export (Cousijn,
        Cruse, &amp; Fenner, <a href=\"https://blog.datacite.org/power-of-pids/#ref-https://doi.org/10.5438/5aep-2n86\">2018</a>),
        citation formatting, and ORCID claiming (Fenner, <a href=\"https://blog.datacite.org/power-of-pids/#ref-https://doi.org/10.5438/15x1-bj6r\">2015</a>)
        available in DataCite Search. What we released today is the first public version
        of the service, we will continue adding many more Crossref DOIs and more connections,
        and work on improving the performance as the system scales. Beyond FREYA,
        DataCite Commons will be maintained and further developed by DataCite in coordination
        with other PID providers and the broader open science community. Watch out
        for a FREYA webinar on DataCite Commons in September.</p>\n<h3 id=\"next-steps\">Next
        steps</h3>\n<p>While DataCite Commons is open to everyone to help with the
        discovery of scholarly resources and its connections that are part of the
        PID Graph, it provides particular value to DataCite members. The service makes
        their metadata and content available to a wide audience, helps them discover
        and report connections such as citations and affiliation and funding information,
        and provides an open platform for further integrations with other services
        going forward. We will closely work with DataCite members to further align
        the new service with their needs and the needs of the communities they serve.
        We will be actively seeking input as we continue to build on the DataCite
        Commons and there will be a dedicated Open Hours session in the coming months.
        If you have feedback at this point, please reach out to <a href=\"mailto:support@datacite.org\">DataCite
        Support</a> or post a message in the DataCite channel of the PID Forum.</p>\n<h3
        id=\"acknowledgments\">Acknowledgments</h3>\n<p>This blog post was <a href=\"https://doi.org/10.5438/f4df-4817\">originally
        published</a> on the DataCite Blog. This work was funded by the European Union\u2019s
        Horizon 2020 research and innovation programme under <a href=\"https://doi.org/10.3030/777523\"
        rel=\"noreferrer\">grant agreement No.&nbsp;777523</a>.</p>\n<h3 id=\"references\">References</h3>\n<p>Cousijn
        H, Cruse P, Fenner M. Taking discoverability to the next level: datasets with
        DataCite DOIs can now be found through Google Dataset Search. doi:<a href=\"https://doi.org/10.5438/5AEP-2N86\">10.5438/5AEP-2N86</a></p>\n<p>Fenner
        M. Announcing the DataCite Profiles Service. doi:<a href=\"https://doi.org/10.5438/15X1-BJ6R\">10.5438/15X1-BJ6R</a></p>\n<p>Fenner
        M. Making the most out of available Metadata. doi:<a href=\"https://doi.org/10.5438/1DGK-1M22\">10.5438/1DGK-1M22</a></p>\n<p>Fenner
        M. Powering the PID Graph: announcing the DataCite GraphQL API. Published
        online May 6, 2020. doi:<a href=\"https://doi.org/10.5438/YFCK-MV39\">10.5438/YFCK-MV39</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ The DataCite MDC Stack ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/the-datacite-mdc-stack/\" />\n\t\t<id>https://doi.org/10.53731/r79rgj1-97aq74v-ag4ny</id>\n
        \       <published>2020-06-22T00:00:00.000+00:00</published>\n\t\t<updated>2023-09-07T12:51:54.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/noun_dashboard_2172952.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/noun_dashboard_2172952.png\"></p><p>In
        May, the Make Data Count team <a href=\"https://makedatacount.org/2020/05/05/igniting-change-our-next-steps/\">announced</a>
        that we have received additional funding from the Alfred P. Sloan Foundation
        for work on the Make Data Count (MDC) initiative. This will enable DataCite
        to do additional work in two important areas:</p>\n<ul><li>Implement a bibliometrics
        dashboard that enables bibliometricians \u2013 funded by a <a href=\"https://www.scholcommlab.ca/2020/05/04/sloan-announcement/\">separate
        Sloan grant</a> \u2013 to do quantitative studies around data usage and citation
        behaviors.</li><li>Increase adoption of standardized data usage across repositories
        by developing a log processing service that offloads much of the hard work
        from repositories.</li></ul>\n<p>In this blog post, we want to provide more
        technical details about the upcoming work on the bibliometrics dashboard;
        the log processing service will be the topic of a future blog post. The bibliometrics
        dashboard will be based on several important infrastructure pieces that DataCite
        has built over the past few years, and that are again briefly described below.</p>\n<h3
        id=\"doi-registration-services\">DOI registration services</h3>\n<p>In the
        MDC initiative we track data citations in the scholarly literature, focussing
        on datasets registered with DataCite and publications registered with Crossref.</p>\n<h3
        id=\"event-data\">Event Data</h3>\n<p>We use the joint <a href=\"https://support.datacite.org/docs/eventdata-guide\">Crossref/DataCite
        Event Data</a> service to exchange information about connections between publications
        and datasets, contributed via Crossref and DataCite members through the metadata
        they register. These connections are also made available via a <a href=\"http://www.scholix.org/\">Scholix</a>-compliant
        REST API. In the previous MDC project, the Event Data service was expanded
        to include data usage stats and make retrieving information easier for DataCite
        members.</p>\n<h3 id=\"data-usage-reports\">Data Usage Reports</h3>\n<p>DataCite
        members and repositories upload monthly reports about data usage to DataCite
        using a standard format (<a href=\"https://www.projectcounter.org/counter-code-practice-research-data-usage-metrics-release-1/\">COUNTER
        Code of Practice for Research Data Usage Metrics</a> and protocol (<a href=\"https://www.projectcounter.org/code-of-practice-sections/sushi/\">SUSHI</a>).
        COUNTER Code of Practice for Research Data Usage Metrics and the DataCite
        <a href=\"https://support.datacite.org/docs/usage-reports-api-guide\">usage
        reports API</a> were developed in the previous MDC project.</p>\n<h3 id=\"graphql-api\">GraphQL
        API</h3>\n<p>The DataCite GraphQL API [Fenner (<a href=\"https://blog.datacite.org/datacite-mdc-stack/#ref-https://doi.org/10.5438/yfck-mv39\">2020</a>)]
        built in the EC-funded <a href=\"https://www.project-freya.eu/en\">FREYA</a>
        project brings together all of the above information in a single API that
        supports the complex queries typically needed for retrieving aggregated data
        citation information.</p>\n<h3 id=\"jupyter-notebooks\">Jupyter Notebooks</h3>\n<p>We
        use Jupyter notebooks to analyze and visualize the information made available
        in the GraphQL API [Fenner (<a href=\"https://blog.datacite.org/datacite-mdc-stack/#ref-https://doi.org/10.5438/hwaw-xe52\">2019</a>)],
        and have developed documentation, demos, and training material with our partners
        in the FREYA project.</p>\n<h3 id=\"common-doi-search\">Common DOI Search</h3>\n<p>Common
        DOI Search, a service currently under development by DataCite with help from
        Crossref and others in the FREYA project, and with a first version planned
        to be released in August, will bring a single search interface for all scholarly
        DOIs, no matter from which DOI registration agency (DataCite, Crossref, etc.).
        All DOIs in Common DOI Search are in a single Elasticsearch search cluster
        using the same DataCite metadata schema.</p>\n<h3 id=\"data-metrics-badge\">Data
        Metrics Badge</h3>\n<p>The Data Metrics Badge \u2013 developed as part of
        the <a href=\"http://www.belmontforum.org/projects/4057/\">Parsec</a> project
        \u2013 is an <a href=\"https://support.datacite.org/docs/displaying-usage-and-citations-in-your-repository\">easy
        to install</a> Javascript widget that displays up-to-date citations, views,
        and downloads for a single DOI, and links to the DataCite Search page for
        more detailed information.</p>\n<h3 id=\"researcher-profile\">Researcher Profile</h3>\n<p>Also
        as part of the PARSEC project, we have built the <a href=\"https://support.datacite.org/docs/datacite-researcher-profiles\">Researcher
        Profile</a> that, using the researcher's ORCID ID, brings all academic outputs
        and their metrics for a given researcher into a single dashboard. This work
        serves as a blueprint for other aggregations (e.g. by research organization)
        in the bibliometrics dashboard.</p>\n<h3 id=\"bibliometrics-dashboard\">Bibliometrics
        Dashboard</h3>\n<p>All the services described above are required building
        blocks for the bibliometrics dashboard we will start working on in August.
        What the dashboard will add is better insights into the data citation data
        we have collected, primarily helping the bibliometricians in the project,
        but also available to other users. We will use Jupyter notebooks for exploratory
        analyses and to address very specific research questions, and data visualizations
        in the bibliometrics dashboard that address the most common questions, such
        as the growth of data citations over time.</p>\n<p>The bibliometrics dashboard
        will expand the common DOI search service that we are currently building,
        beyond FREYA, which ends in November. Common DOI search, and also the bibliometrics
        dashboard, are built using <a href=\"https://reactjs.org/\">React</a>, not
        only the most popular Javascript framework right now, but also integrating
        very nicely with GraphQL APIs. More specifically we are using <a href=\"https://nextjs.org/\">next.js</a>
        to run react on the server, helping with faster page loading and search engine
        optimization (SEO).</p>\n<p>We have picked the popular <a href=\"https://vega.github.io/vega/\">Vega</a>
        library for our data visualizations. Vega is not only widely used and very
        flexible, but also available in versions for Jupyter notebooks (<a href=\"https://altair-viz.github.io/getting_started/installation.html\">Altair</a>)
        and React (<a href=\"https://github.com/vega/react-vega\">React-Vega</a>).</p>\n<h3
        id=\"using-the-bibliometrics-dashboard\">Using the Bibliometrics Dashboard</h3>\n<p>DataCite
        members and the repositories they work with contribute to the bibliometrics
        dashboard in important ways, registering content with a DOI and standard metadata
        facilitating citation, inclusion of references in the metadata, and submission
        of data repository usage stats. The bibliometrics dashboard will increase
        our understanding of data citation and data usage stats through the bibliometrics
        work, but will also provide aggregations of information of interest to our
        members \u2013 for example data citations and data usage over time, by discipline,
        or by repository \u2013 not available before. This information is displayed
        in the bibliometrics dashboard, and available via Jupyter notebooks and the
        GraphQL API.</p>\n<h3 id=\"acknowledgments\">Acknowledgments</h3>\n<p>This
        blog post was <a href=\"https://doi.org/10.5438/v9pp-7a27\">originally published</a>
        on the DataCite Blog.</p>\n<h3 id=\"references\">References</h3>\n<p>Fenner
        M. Using Jupyter Notebooks with GraphQL and the PID Graph. Published online
        2019. doi:<a href=\"https://doi.org/10.5438/HWAW-XE52\">10.5438/HWAW-XE52</a></p>\n<p>Fenner
        M. Powering the PID Graph: announcing the DataCite GraphQL API. Published
        online May 6, 2020. doi:<a href=\"https://doi.org/10.5438/YFCK-MV39\">10.5438/YFCK-MV39</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Powering the PID Graph: announcing the DataCite
        GraphQL API ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/powering-the-pid-graph-announcing-the-datacite-graphql-api/\"
        />\n\t\t<id>https://doi.org/10.53731/r79rkf1-97aq74v-ag4pj</id>\n        <published>2020-05-06T00:00:00.000+00:00</published>\n\t\t<updated>2023-09-07T11:51:39.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/pidgraph-2020-05-04.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/pidgraph-2020-05-04.png\"></p><p>Today
        DataCite launches a new API that powers the PID Graph, the graph formed by
        scholarly resources described by persistent identifiers (PIDs) and the connections
        between them. The API is powered by GraphQL, a widely adopted Open Source
        technology that enables queries of this graph, addressing use cases of our
        community in ways that were not possible before.</p>\n<p>We launched a pre-release
        version of the API in May 2019 (Fenner (<a href=\"https://blog.datacite.org/powering-the-pid-graph/#ref-https://doi.org/10.5438/qab1-n315\">2019b</a>))[],
        and have used the last 12 months to improve the performance and stability
        of the service, add functionality based on user feedback, decide on a stable
        GraphQL schema that describes the resources and links in the Graph, and add
        many additional resources. The PID Graph now includes all of DataCite's DOIs,
        nine million Crossref DOIs, all ORCID IDs, and all Research Organization Registry
        (ROR), Crossref Funder ID, and Registry of Research Data Repositories (re3data)
        records, for a total of about 35 million resources with PIDs and associated
        metadata, and about 9 million links between them.</p>\n<p>The PID Graph and
        the <a href=\"https://graphql.org/\">GraphQL</a> API announced today are an
        important output from the European Commission-funded <a href=\"https://www.project-freya.eu/en\">FREYA
        Project</a> (grant agreement No 777523), and have been developed in close
        collaboration with all FREYA partners, including the PID providers Crossref
        and ORCID. PID Graph is part of the Research Data Alliance (RDA) <a href=\"https://www.rd-alliance.org/groups/open-science-graphs-fair-data-ig\">Open
        Science Graphs for FAIR Interest Group</a>, where we coordinate with other
        initiatives building Open Science graphs.</p>\n<p>FREYA partners have used
        the last 12 months to start building client applications that take advantage
        of the GraphQL API, and you will see two new services built by DataCite using
        GraphQL launching later this year. While GraphQL is supported by a <a href=\"https://graphql.org/code/\">wide
        variety of programming languages</a>, with lots of documentation and community
        support available \u2013 including of course the <a href=\"https://support.datacite.org/docs/datacite-graphql-api-guide\">DataCite
        GraphQL API Guide</a> - it is a relatively new technology for scholarly communication
        infrastructure. We found that Jupyter notebooks are a powerful way to get
        started with the PID Graph and the DataCite GraphQL API Fenner (<a href=\"https://blog.datacite.org/powering-the-pid-graph/#ref-https://doi.org/10.5438/hwaw-xe52\">2019c</a>),
        and you find a number of example notebooks via the PID Graph section in the
        <a href=\"https://www.pidforum.org/c/pid-graph/17\">PID Forum</a>, which is
        also a good place to post questions or comments. The visualization in this
        blog post is of course also generated by a Jupyter notebook using the DataCite
        GraphQL API Fenner (<a href=\"https://blog.datacite.org/powering-the-pid-graph/#ref-https://doi.org/10.14454/3bpw-w381\">2019a</a>).
        Expect more Jupyter notebooks coming from FREYA in the coming months, addressing
        specific user stories that we have identified earlier in the project.</p>\n<h2
        id=\"acknowledgments\">Acknowledgments</h2>\n<p>This blog post was <a href=\"https://doi.org/10.5438/yfck-mv39\">originally
        published</a> on the DataCite Blog. This work was funded by the European Union\u2019s
        Horizon 2020 research and innovation programme under <a href=\"https://doi.org/10.3030/777523\"
        rel=\"noreferrer\">grant agreement No.&nbsp;777523</a>.</p>\n<h2 id=\"references\">References</h2>\n<p>Fenner,
        M. (2019a). FREYA pid graph key performance indicators (kpis). DataCite. <a
        href=\"https://doi.org/10.14454/3BPW-W381\">https://doi.org/10.14454/3BPW-W381</a></p>\n<p>Fenner,
        M. (2019b). The datacite graphql api is now open for (pre-release) business.
        <a href=\"https://doi.org/10.5438/QAB1-N315\">https://doi.org/10.5438/QAB1-N315</a></p>\n<p>Fenner,
        M. (2019c). Using jupyter notebooks with graphql and the pid graph. <a href=\"https://doi.org/10.5438/HWAW-XE52\">https://doi.org/10.5438/HWAW-XE52</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ 2020 Strategic Priorities for Services and
        Infrastructure ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/2020-strategic-priorities-for-services-and-infrastructure/\"
        />\n\t\t<id>https://doi.org/0.53731/r79rpj1-97aq74v-ag4qd</id>\n        <published>2020-02-27T00:00:00.000+00:00</published>\n\t\t<updated>2023-08-01T10:16:41.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://images.unsplash.com/photo-1527219525722-f9767a7f2884?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDMyfHxzdHJhdGVneXxlbnwwfHx8fDE2OTA4ODQ5NzJ8MA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://images.unsplash.com/photo-1527219525722-f9767a7f2884?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDMyfHxzdHJhdGVneXxlbnwwfHx8fDE2OTA4ODQ5NzJ8MA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"></p><p>In
        a blog post four weeks ago DataCite Executive Director Matt Buys talked about
        the DataCite strategic priorities for 2020 (Buys, <a href=\"https://blog.datacite.org/2020-strategic-priorities-for-services-and-infrastructure/#ref-https://doi.org/10.5438/9j86-bv91\">2020</a>).
        In this post we want to talk a bit more about the strategic priorities for
        this year we have regarding services and infrastructure work: a) consolidation
        of our services and infrastructure, and b) stronger emphasis on member-driven
        product development. They are based on the clear message we heard from our
        members, e.g. in the member survey that we shared yesterday (Cousijn, <a href=\"https://blog.datacite.org/2020-strategic-priorities-for-services-and-infrastructure/#ref-https://doi.org/10.5438/0x81-y943\">2020</a>).</p><h3
        id=\"consolidation-of-our-services-and-infrastructure\">Consolidation of our
        services and infrastructure</h3><p>The focus of development work over the
        past few years has been on upgrading existing DataCite infrastructure and
        building new services. With the relaunch of the OAI-PMH service in December
        2019 (Hallett, <a href=\"https://blog.datacite.org/2020-strategic-priorities-for-services-and-infrastructure/#ref-https://doi.org/10.5438/ppth-pz62\">2019</a>),
        we have now upgraded all major DataCite infrastructure that existed in 2015.
        For 2020, we want to spend more time consolidating our existing services and
        infrastructure, scaling back new service development, of course within the
        ramifications of what we promised to deliver in ongoing grants such as <a
        href=\"https://www.project-freya.eu/en\">FREYA</a>. The work planned includes</p><ul><li>Better
        monitoring and analytics of our services, e.g. better tracking of API performance</li><li>Prioritize
        stability of our infrastructure, e.g. spending more time fixing bugs</li><li>Consolidate
        the number of services available to our members, e.g. merging the public DataCite
        Search into the Fabrica service</li></ul><h3 id=\"stronger-emphasis-on-member-driven-product-development\">Stronger
        emphasis on member-driven product development</h3><p>This strategic priority
        includes two aspects: improving our process of feedback collection from DataCite
        members and how that informs our product development, and prioritizing our
        development efforts on new services or service improvements asked for by our
        members.</p><p>In 2020 we will improve the existing process of collecting
        input from our members regarding product development. These improvements will
        be based on how we currently collect member input via support emails, Open
        Hours, webinars and the DataCite General Assembly, other conversations with
        members, <a href=\"https://github.com/datacite/datacite/issues\">GitHub issues</a>
        opened by members and users, and our <a href=\"https://datacite.org/roadmap.html\">public
        roadmap</a> that allows comments and upvoting.</p><p>While continuing to improve
        the process of collecting feedback from members, there are a number of new
        services or service improvements that have been consistently asked for by
        our members, and that we will prioritize working on in 2020. This includes
        improvements of the DOI registration form in Fabrica to cover all optional
        metadata properties, a public dump of all DOI metadata available for download,
        improvements to the query interface for searching for DOIs, and better support
        for text documents in the metadata schema (e.g. support for journal name,
        volume, issue, and page numbers).</p><p><em>This blog post was <a href=\"https://doi.org/10.5438/9te8-5h68\">originally
        published</a> on the DataCite Blog.</em></p><h2 id=\"references\">References</h2><p>Buys
        M. Vision 2020. Published online January 24, 2020. doi:<a href=\"https://doi.org/10.5438/9J86-BV91\">10.5438/9J86-BV91</a></p><p>Cousijn
        H. Setting DataCites priorities: the 2019 member survey. Published online
        February 26, 2020. doi:<a href=\"https://doi.org/10.5438/0X81-Y943\">10.5438/0X81-Y943</a></p><p>Hallett
        R. OAI-PMH Service Updates. doi:<a href=\"https://doi.org/10.5438/PPTH-PZ62\">10.5438/PPTH-PZ62</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Announcing the new Member API ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/announcing-the-new-member-api/\"
        />\n\t\t<id>https://doi.org/10.53731/r79rw6h-97aq74v-ag4r1</id>\n        <published>2020-01-20T00:00:00.000+00:00</published>\n\t\t<updated>2023-07-02T06:31:14.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/bildschirmfoto-2020-01-20-um-10.40.10.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/bildschirmfoto-2020-01-20-um-10.40.10.png\"></p><p>When
        we launched the new version of the OAI-PMH service in November (Hallett (<a
        href=\"https://blog.datacite.org/announcing-member-api/#ref-https://doi.org/10.5438/ppth-pz62\">2019</a>)),
        and retired Solr (used by the old OAI-PMH service) in December, we completed
        the transition to Elasticsearch as our search index, and the <a href=\"https://api.datacite.org/\">REST
        API</a> as our main API. All our services now integrate via Elasticsearch
        and the REST API, including:</p><ol><li><a href=\"https://mds.datacite.org/\">MDS
        API</a> - DOI registration API</li><li><a href=\"https://ez.datacite.org/\">EZ
        API</a> - DOI registration API, compatible with CDL EZID service</li><li><a
        href=\"https://doi.datacite.org/\">Fabrica</a> - DOI registration and account
        management web interface</li><li><a href=\"https://oai.datacite.org/\">OAI-PMH</a>
        - Metadata harvesting</li><li><a href=\"https://search.datacite.org/\">DataCite
        Search</a> - public DOI search</li><li><a href=\"https://stats.datacite.org/\">Stats
        Portal</a> - statistics about DOI registrations and resolutions</li><li><a
        href=\"https://data.datacite.org/\">Content Negotiation</a> - DOI metadata
        in other formats</li></ol><p>This consolidation was a lot of work in 2019,
        but will greatly simplify the maintenance of our services and the development
        of new functionality going forward.!</p><p>This consolidation of course also
        has its downsides, and the most important one is supporting both member services
        and public services via the same API. While DataCite will always make all
        DOI metadata available in a public API and search interface, we also have
        to make sure our paying members get the best possible service quality when
        registering DOIs or otherwise interacting with DataCite services as member.</p><p>To
        address this challenge we have in December split the REST API into two versions:
        a <strong><strong>Public API</strong></strong> and a <strong><strong>Member
        API</strong></strong>. These two APIs use exactly the same URLs (starting
        with https://api.datacite.org), run exactly the same code, and provide exactly
        the same public data, the only difference being that traffic is directed to
        a different set of servers if users authenticate as a member. This change
        is subtle enough that you probably have not noticed the change yet.</p><p>The
        launch of separate <strong><strong>Public</strong></strong> and <strong><strong>Member</strong></strong>
        APIs allows us to monitor the uptime and response time for DataCite member
        services separately from our public services, and adjust as needed. We updated
        the <a href=\"https://status.datacite.org/\">DataCite status page</a> to reflect
        this change, you can now see separate metrics (both response time and request
        count) for the Public API and Member API:</p><p>There are of course other
        approaches to separate out member API calls from public API calls, including
        separate API endpoints, e.g. pub.orcid.org vs. api.orcid.org at ORCID, or
        separate APIs for members and non-members, e.g. the separate DOI registration
        API at Crossref. But we feel that our approach for accessing the member vs.
        public API aligns best with our strategy of offering a consolidated REST API
        for all services.</p><p><em>This blog post was <a href=\"https://doi.org/10.5438/ysq3-p703\">originally
        published</a> on the DataCite Blog.</em></p><h2 id=\"references\">References</h2><p>Hallett
        R. OAI-PMH Service Updates. Published online November 25, 2019. doi:<a href=\"https://doi.org/10.5438/PPTH-PZ62\">10.5438/PPTH-PZ62</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Upcoming Changes to DOI Content Negotiation
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/upcoming-changes-to-doi-content-negotiation/\"
        />\n\t\t<id>https://doi.org/10.53731/r79s2b1-97aq74v-ag4sc</id>\n        <published>2019-07-26T00:00:00.000+00:00</published>\n\t\t<updated>2023-08-01T10:22:58.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://images.unsplash.com/photo-1441974231531-c6227db76b6e?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDEyfHxuYXR1cmV8ZW58MHx8fHwxNjkwODg1MzUyfDA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://images.unsplash.com/photo-1441974231531-c6227db76b6e?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDEyfHxuYXR1cmV8ZW58MHx8fHwxNjkwODg1MzUyfDA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"></p><p>DOI
        content negotiation is one of the oldest DataCite services, launched in 2012.
        Content negotiation makes it easy to fetch DataCite metadata in other metadata
        formats, for example <em>BibTeX</em> or <em>schema.org</em>, or as formatted
        citation in one of more than 5,000 citation styles. For example:</p><pre><code>curl
        -LH \"Accept: application/x-bibtex\" https://doi.org/10.5438/0000-0C2G</code></pre><p>In
        2017 we updated the service, both adding new content types (e.g. schema.org),
        and improving the support for existing content types (Fenner, <a href=\"https://blog.datacite.org/changes-to-doi-content-negotiation/#ref-https://doi.org/10.5438/0000-01qj\">2017</a>).</p><p>In
        2018 we launched a new version of the REST API (Dasler, <a href=\"https://blog.datacite.org/changes-to-doi-content-negotiation/#ref-https://doi.org/10.5438/s8rt-zv48\">2018</a>)
        that complements content negotiation: you can now submit metadata in most
        of the metadata formats supported by content negotiation to register a DOI.</p><p>With
        this blog post we want to announce an important upcoming change to DataCite
        DOI content negotiation that addresses a long-standing issue. Content negotiation
        is used to provide different representations of the same resource in different
        formats. What content negotiation is not is a protocol to return the content
        itself described by the DOI instead of the metadata describing the content,
        e.g. a PDF or CSV file. The initial implementation of DataCite DOI content
        negotiation didn't make that clear distinction and allows registration of
        custom content types, including those that typically are associated with content
        rather than metadata, e.g. <code>application/pdf</code>. Registration of custom
        content types is still possible with the current version of the service, but
        we are today announcing that we will retire this functionality on January
        1st, 2020.</p><p>We know that many organizations make heavy use of custom
        content types for DataCite DOIs, so we provide both a long transition period
        and alternative approaches to achieve the same.</p><p>On October 1st, 2019
        we will retire support for custom content types via the DOI resolver <code>https://doi.org</code>.
        You can continue to use custom content types by using the DataCite content
        negotiation service at data.datacite.org directly, e.g.</p><pre><code>curl
        -LH \"Accept: application/x-bibtex\" https://data.datacite.org/10.5438/0000-0C2G</code></pre><p>Starting
        January 1st, 2020 custom content types will no longer be supported.</p><p>There
        are two alternatives to using custom content types in content negotiation:</p><ul><li>use
        the REST API, specifically the <code>/media</code> API endpoint to access
        exactly the information currently made available via content negotiation</li><li>use
        content negotiation at the landing page for the resource that the DOI resolves
        to. DataCite content negotiation is forwarding all requests with unknown content
        types to the URL registered in the handle system.</li></ul><p>Going forward,
        the upcoming changes will lead to improvements in two areas:</p><ul><li>the
        content negotiation service will become faster, easier to maintain, and more
        aligned with other DOI registration agencies such as Crossref. The new service
        is already running at https://data.crosscite.org.</li><li>we can improve the
        workflows for registering URLs to content in the DOI registration service.
        This will enable direct access to content, and will improve machine access
        to data.</li></ul><p>Please read our <a href=\"https://support.datacite.org/docs/datacite-content-resolver\">support
        documentation for content negotiation</a> for more details, or reach out to
        <a href=\"mailto:support@datacite.org\">DataCite support</a> if you need help
        transitioning from custom content types you have registered in the past.</p><p><em>This
        blog post was <a href=\"https://doi.org/10.5438/nz0m-rb06\">originally published</a>
        on the DataCite Blog.</em></p><h2 id=\"references\">References</h2><p>Dasler
        R. Create DOIs with the REST API. Published online September 28, 2018. doi:<a
        href=\"https://doi.org/10.5438/S8RT-ZV48\">10.5438/S8RT-ZV48</a></p><p>Fenner
        M. A Content Negotiation Update. Published online April 28, 2017. doi:<a href=\"https://doi.org/10.53731/r7adm61-97aq74v-ag5kv\">10.53731/r7adm61-97aq74v-ag5kv</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Tracking the Growth of the PID Graph ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/tracking-the-growth-of-the-pid-graph/\"
        />\n\t\t<id>https://doi.org/10.53731/r79s4nh-97aq74v-ag4t1</id>\n        <published>2019-07-01T00:00:00.000+00:00</published>\n\t\t<updated>2023-09-07T11:50:32.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/download-19-.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/download-19-.jpeg\"></p><p>The
        connections between scholarly resources generated by persistent identifiers
        (PIDs) and associated metadata form a graph: the PID Graph [Fenner &amp; Aryani
        (<a href=\"https://blog.datacite.org/tracking-the-growth-of-the-pid-graph/#ref-https://doi.org/10.5438/jwvf-8a66\">2019</a>)].
        We developed this PID Graph concept in the EC-funded <a href=\"https://www.project-freya.eu/en\">FREYA
        project</a>, and have identified important use cases and technical requirements.
        In May, DataCite introduced a GraphQL API to standardize and simplify how
        users can contribute to and consume the PID Graph [Fenner (<a href=\"https://blog.datacite.org/tracking-the-growth-of-the-pid-graph/#ref-https://doi.org/10.5438/qab1-n315\">2019b</a>)].
        Today we are announcing another important milestone: we added the required
        functionality to the DataCite GraphQL API that allows us to keep track of
        the growth of the PID Graph in terms of nodes (resources) and edges (connections).
        As before, we are using a Jupyter notebook to analyze and visualize the data.</p>\n<p>The
        graph visualizes the main resources currently available via the DataCite GraphQL
        API, and their connections. The required data are fetched via a single GraphQL
        API call:</p>\n<pre><code>{\n  publications {\n    totalCount\n    publicationConnectionCount\n
        \   datasetConnectionCount\n    softwareConnectionCount\n    researcherConnectionCount\n
        \   funderConnectionCount\n  }\n  datasets {\n    totalCount\n    datasetConnectionCount\n
        \   softwareConnectionCount\n    researcherConnectionCount\n    funderConnectionCount\n
        \ }\n  softwares {\n    totalCount\n    softwareConnectionCount\n    researcherConnectionCount\n
        \   funderConnectionCount\n  }\n  researchers {\n    totalCount\n  }\n  funders
        {\n    totalCount\n  }\n}</code></pre>\n<p>The numbers reflect what is currently
        available via the DataCite GraphQL API, not the total number of publications,
        datasets, etc. with persistent identifiers and linking metadata. This includes
        all publications, datasets and software with DataCite DOIs, all funders in
        the <a href=\"https://support.crossref.org/hc/en-us/articles/214360886-The-Open-Funder-Registry\">Crossref
        Open Funder Registry</a>, publications with Crossref DOIs linked to at least
        one DataCite DOI, and all researchers with an ORCID identifier linked to at
        least one DataCite DOI. A lot of work remains to be done to include the other
        resources with persistent identifiers made available by FREYA partners, including
        Crossref, ORCID and EMBL-EBI, as well as their connections. With this new
        API functionality we can now track the growth of the PID Graph with the key
        performance indicators (KPIs) number of <strong>nodes</strong> and number
        of <strong>connections</strong>.</p>\n<p>A few interesting observations can
        be made from the visualization: not surprisingly, given that datasets currently
        make up the largest number of resources in the PID Graph, by far the largest
        number of connections (9.4 million) is between datasets and other datasets.
        Looking at the relation type of these connections in the Event Data API, most
        of them (8.5 million) don't describe versioning or granularity (HasPart/IsPartOf
        relations), but use the relation type <strong>references</strong> between
        two <a href=\"https://www.gbif.org/en/\">GBIF</a> DOIs. This reflects the
        main <a href=\"https://www.gbif.org/en/document/81771/gbif-overview-powerpoint-slides\">use
        case for DOIs at GBIF</a>, tracking occurrences of species.</p>\n<p>The graph
        shows 1.5 million connections between publications and datasets, representing
        the data citations made available via the <a href=\"https://www.eventdata.crossref.org/guide/app-scholix/\">Crossref/DataCite
        Event Data Scholix API endpoint</a>. Twenty-five percent of datasets with
        DataCite DOIs have been referenced in the scholarly literature, according
        to this graph. We also see the number of software citations using DataCite
        DOIs for software found in the scholarly literature, and we can use this API
        call to keep track of them. Similarly, we can track the number of datasets,
        publications, and software linked to researchers (via their ORCID ID), and
        funding (via the Crossref Funder ID), but keep in mind that connections to
        researchers and funding via Crossref are still missing.</p>\n<p>The Jupyter
        notebook used to generate the visualization shown here is available via GitHub,
        where we store all PID Graph notebooks in a <a href=\"https://github.com/datacite/notebooks\">central
        repository</a>. Starting with this notebook [Fenner (<a href=\"https://blog.datacite.org/tracking-the-growth-of-the-pid-graph/#ref-https://doi.org/10.14454/3bpw-w381\">2019a</a>)]
        we are also issuing DOIs for the notebooks, which we generate using a <a href=\"https://codemeta.github.io/\">codemeta</a>
        file hosted in the same folder as the notebook. This should make these notebooks
        easier to discover, and they also become part of the PID Graph.</p>\n<p>Going
        forward we want to refine the GraphQL API to provide the numbers of <strong>nodes</strong>
        and <strong>connections</strong> as they change over time, making it easier
        to track progress. And of course, we will be adding more resource types and
        information from other FREYA partners. Keep an eye on this blog for further
        updates!</p>\n<h2 id=\"acknowledgments\">Acknowledgments</h2>\n<p>This blog
        post was <a href=\"https://doi.org/10.5438/bv9z-dc66\">originally published</a>
        on the DataCite Blog. This work was funded by the European Union\u2019s Horizon
        2020 research and innovation programme under <a href=\"https://doi.org/10.3030/777523\"
        rel=\"noreferrer\">grant agreement No.&nbsp;777523</a>.</p>\n<h2 id=\"references\">References</h2>\n<p>Fenner
        M. Jupyter Notebook FREYA PID Graph Key Performance Indicators (KPIs). Published
        online June 30, 2019. doi:<a href=\"https://doi.org/10.14454/3BPW-W381\">10.14454/3BPW-W381</a></p>\n<p>Fenner
        M. The DataCite GraphQL API is now open for (pre-release) business. Published
        online May 15, 2019. doi:<a href=\"https://doi.org/10.53731/r79sa71-97aq74v-ag4vc\">10.53731/r79sa71-97aq74v-ag4vc</a></p>\n<p>Fenner
        M, Aryani A. Introducing the PID Graph. Published online 2019. doi:<a href=\"https://doi.org/10.5438/JWVF-8A66\">10.5438/JWVF-8A66</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Using Jupyter Notebooks with GraphQL and
        the PID Graph ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/using-jupyter-notebooks-with-graphql-and-the-pid-graph/\"
        />\n\t\t<id>https://doi.org/10.53731/r79s7a1-97aq74v-ag4tq</id>\n        <published>2019-05-27T00:00:00.000+00:00</published>\n\t\t<updated>2023-09-07T11:49:43.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/download-3-.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/download-3-.jpeg\"></p><p>Two
        weeks ago DataCite announced the pre-release version of a GraphQL API [Fenner
        (<a href=\"https://blog.datacite.org/using-jupyter-notebooks-with-graphql-and-the-pid-graph/#ref-https://doi.org/10.5438/qab1-n315\">2019</a>)].
        GraphQL simplifies complex queries that for example want to retrieve information
        about the authors, funding and data citations for a dataset with a DataCite
        DOI. These connections together form the PID Graph [Fenner &amp; Aryani (<a
        href=\"https://blog.datacite.org/using-jupyter-notebooks-with-graphql-and-the-pid-graph/#ref-https://doi.org/10.5438/jwvf-8a66\">2019</a>)],
        and DataCite is working with the other partners in the EC-funded <a href=\"https://www.project-freya.eu/\">FREYA
        project</a> on making it easier to contribute to the PID Graph, and consume
        information in the PID Graph.</p>\n<p><a href=\"https://jupyter.org/\">Jupyter
        notebooks</a> are a very popular web-based interactive computational environment
        and are the perfect platform to explore the PID Graph via GraphQL APIs. Since
        interactions with GraphQL APIs are standardized and GraphQL libraries exist
        for many programming languages supported by Jupyter notebooks, all the user
        has to do is come up with interesting queries and process the information
        returned from the API as JSON, following exactly the format of the query.</p>\n<p>An
        example notebook can best explain this. We have created a GitHub repository
        for notebooks using the GraphQL API at <a href=\"https://github.com/datacite/notebooks\">https://github.com/datacite/notebooks</a>,
        and you find <a href=\"https://github.com/datacite/notebooks/blob/master/pid-graph/r-person-publications/r-person-publications.ipynb\">this
        notebook</a> in there. Open the notebook in your favorite Jupyter client (e.g.
        <a href=\"https://nteract.io/\">nteract</a>) or look at it directly in GitHub.</p>\n<p>The
        GraphQL query in the notebook is as follows:</p>\n<pre><code>{\n  researcher(id:
        \"https://orcid.org/0000-0003-1419-2405\") {\n    id\n    name\n    publications(first:
        50) {\n      totalCount\n      nodes {\n        id\n        relatedIdentifiers
        {\n          relatedIdentifier\n        }\n      }\n    }\n  }\n}</code></pre>\n<p>This
        query will return the first 50 publications with DataCite DOIs linked to my
        ORCID ID, together with information about content referenced by these publications.
        The Jupyter notebook is then processing the JSON API response with two major
        outputs:</p>\n<ul><li>two reference lists of all publications, and of all
        their references, using the APA citation style and the <a href=\"https://citation.crosscite.org/\">DOI
        citation formatter service</a>.</li><li>a network graph of all publications
        and their references (blue circles), with a node (green circle) representing
        the author of these publications (me).</li></ul>\n<p>Even with only 50 publications
        the graph already is rather complicated. Many of my publications with DataCite
        DOIs are for the DataCite Blog, and you see them connected to a blue node
        in the top part of the graph. In the lower left corner you see a blog post
        with an unusually high number of references (Fenner, <a href=\"https://blog.datacite.org/using-jupyter-notebooks-with-graphql-and-the-pid-graph/#ref-https://doi.org/10.5438/ct8b-x1ce\">2016</a>).
        A number of publications appear as pairs linked to each other, reflecting
        the figshare approach to versioning.</p>\n<p>This is only the starting point
        of what can be done with Jupyter notebooks and GraphQL, but it is clear that
        the possibilities are almost endless. You can use the above notebook as a
        starting point, e.g. to generate the graph of publications (with DataCite
        DOIs) using your ORCID ID. Or you do something very different, or use Python
        instead of R as programming language. You can of course contribute interesting
        notebooks to the above GitHub repository using a pull request.</p>\n<h2 id=\"acknowledgments\">Acknowledgments</h2>\n<p>This
        blog post was <a href=\"https://doi.org/10.5438/hwaw-xe52\">originally published</a>
        on the DataCite Blog. This work was funded by the European Union\u2019s Horizon
        2020 research and innovation programme under <a href=\"https://doi.org/10.3030/777523\"
        rel=\"noreferrer\">grant agreement No.&nbsp;777523</a>.</p>\n<h2 id=\"references\">References</h2>\n<p>Fenner
        M. Mysteries in Reference Lists. Published online December 23, 2016. doi:<a
        href=\"https://doi.org/10.53731/r79z0kh-97aq74v-ag5hb\">10.53731/r79z0kh-97aq74v-ag5hb</a></p>\n<p>Fenner
        M. The DataCite GraphQL API is now open for (pre-release) business. Published
        online May 15, 2019. doi:<a href=\"https://doi.org/10.53731/r79sa71-97aq74v-ag4vc\">10.53731/r79sa71-97aq74v-ag4vc</a></p>\n<p>Fenner
        M, Aryani A. Introducing the PID Graph. Published online 2019. doi:<a href=\"https://doi.org/10.5438/JWVF-8A66\">10.5438/JWVF-8A66</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ The DataCite GraphQL API is now open for
        (pre-release) business ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/the-datacite-graphql-api-is-now-open-for-pre-release-business/\"
        />\n\t\t<id>https://doi.org/10.53731/r79sa71-97aq74v-ag4vc</id>\n        <published>2019-05-15T00:00:00.000+00:00</published>\n\t\t<updated>2023-08-01T10:25:13.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://images.unsplash.com/photo-1614608792503-d76e3bfd024a?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDExfHxvcGVuJTIwYnVzaW5lc3N8ZW58MHx8fHwxNjkwODg1NDQ0fDA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://images.unsplash.com/photo-1614608792503-d76e3bfd024a?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDExfHxvcGVuJTIwYnVzaW5lc3N8ZW58MHx8fHwxNjkwODg1NDQ0fDA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"></p><p>DataCite
        DOIs describe resources such as datasets, samples, software and publications
        with rich metadata. An important part of this metadata is the description
        of connections between resources that use persistent identifiers (PIDs) provided
        by DataCite and others (Crossref, ORCID, ROR, ISNI, IGSN, etc.). Together
        these resources and their connections form a graph, the PID Graph (Fenner
        &amp; Aryani, <a href=\"https://blog.datacite.org/graphql-api-pre-release/#ref-https://doi.org/10.5438/jwvf-8a66\">2019</a>).</p><p>Accessing
        information available in this PID Graph, while preserving the rich connections
        between resources, is not trivial, and the JSON REST APIs that most PID service
        providers including DataCite are providing to users, while having a very good
        track record allowing users to access a single resource or a list of similar
        resources, might not be the best fit for more complex queries of the PID Graph.</p><p>Enter
        <a href=\"https://graphql.org/\">GraphQL</a>, a query language that uses a
        graph as the underlying data model and aligns well with the kinds of queries
        that need to be supported in the PID Graph. GraphQL was started by Facebook
        in 2012, made available as Open Source software in 2015, and in 2019 has become
        a mainstream technology with broad support in terms of <a href=\"https://graphql.org/code/\">libraries,
        tools and services</a>.</p><p>Today DataCite is announcing the pre-release
        version of the DataCite GraphQL API, and we invite you to try it out at <a
        href=\"https://api.datacite.org/graphql\">https://api.datacite.org/graphql</a>.
        GraphQL works very differently from the REST APIs that most of us are familiar
        with: you need a special client application (e.g. <a href=\"https://electronjs.org/apps/graphiql\">this
        one</a> or <a href=\"https://www.graphqlbin.com/\">this one</a>) to use a
        GraphQL API, and all API calls are done to the same URL and using the POST
        method.</p><p>A typical starting point for a query in the PID Graph using
        GraphQL is a resource such as a dataset, researcher, organization, etc. identified
        by it's PID. For example:</p><pre><code>{\n  dataset(id: \"https://doi.org/10.7910/dvn/nfzli3/cynkam\")
        {\n    titles {\n      title\n    }\n  }\n}</code></pre><pre><code>{\n  publication(id:
        \"https://doi.org/10.5438/jwvf-8a66\") {\n    titles {\n      title\n    }\n
        \ }\n}</code></pre><pre><code>{\n  software(id: \"https://doi.org/10.5281/zenodo.1013940\")
        {\n    titles {\n      title\n    }\n  }\n}</code></pre><pre><code>{\n  researcher(id:
        \"https://orcid.org/0000-0002-1642-628X\") {\n    givenName\n    familyName\n
        \ }\n}</code></pre><pre><code>{\n  organization(id: \"https://ror.org/05rrcem69\")
        {\n    name\n  }\n}</code></pre><p>Some of these PIDs are obviously not provided
        by DataCite, but the DataCite GraphQL supports them as well via a wrapper
        layer over, for example, the <a href=\"https://ror.org/\">ROR</a> API.</p><p>GraphQL
        allows you to specify exactly the fields the query should return, including
        linked resources. For example all publications (with a DataCite DOI) authored
        by a particular researcher, and including the titles and relatedIdentifiers
        for those publications:</p><pre><code>{\n  researcher(id: \"https://orcid.org/0000-0002-4695-7874\")
        {\n    id\n    name\n    givenName\n    familyName\n    publications {\n      totalCount\n
        \     edges {\n        node {\n          id\n          titles {\n            title\n
        \         }\n          relatedIdentifiers {\n            relationType\n            relatedIdentifier\n
        \         }\n        }\n      }\n    }\n  }\n}</code></pre><p>In addition
        to retrieving a specific resource using the PID, you can also do queries.
        For resources with DOIs, the query syntax is exactly the same as in DataCite
        Search or DOI Fabrica. For example:</p><pre><code>{\n  softwares(query: \"subjects.subject:python\")
        {\n    totalCount\n    \n    nodes {\n      id\n      titles {\n        title\n
        \     }\n      fundingReferences {\n        funderIdentifier\n        funderName\n
        \       awardTitle\n        awardNumber\n      }\n    }\n  }\n}</code></pre><figure
        class=\"kg-card kg-embed-card\"><iframe width=\"800\" height=\"450\" src=\"https://www.youtube.com/embed/efvxGfU_oVM\"
        frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope;
        picture-in-picture\" allowfullscreen=\"\" style=\"box-sizing: border-box;
        color: rgb(102, 97, 91); font-family: Raleway, Helvetica, Arial, sans-serif;
        font-size: 18px; font-style: normal; font-variant-ligatures: normal; font-variant-caps:
        normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align:
        start; text-indent: 0px; text-transform: none; white-space: normal; widows:
        2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255,
        255, 255); text-decoration-thickness: initial; text-decoration-style: initial;
        text-decoration-color: initial;\"></iframe></figure><p>After this short introduction
        it should have become clearer how GraphQL works differently from your typical
        REST API, and that GraphQL is a perfect fit for the kinds of queries one might
        want to do with the PID Graph. Now that you have had an introduction to the
        DataCite GraphQL API, you can try your own queries.</p><p>The DataCite GraphQL
        API is a pre-release version, which means it's not yet final. It may contain
        bugs or might be missing functionality you expect. In particular more complex
        queries of the PID Graph are not yet supported. Your feedback is valuable
        for improving the API, so we encourage you to try it out and let us know what
        you think. Please use the <a href=\"https://www.pidforum.org/c/pid-graph\">PID
        Graph section in the PID Forum</a> to ask questions or suggest features. We'll
        keep updating the API, and we aim to get a final release out sometime later
        this year.</p><p><em>This blog post was <a href=\"https://doi.org/10.5438/qab1-n315\">originally
        published</a> on the DataCite Blog.</em></p><h2 id=\"references\">References</h2><p>1Fenner
        M, Aryani A. Introducing the PID Graph. Published online 2019. doi:<a href=\"https://doi.org/10.5438/JWVF-8A66\">10.5438/JWVF-8A66</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Exposing DOI metadata provenance ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/exposing-doi-metadata-provenance/\"
        />\n\t\t<id>https://doi.org/10.53731/r79sd61-97aq74v-ag4w1</id>\n        <published>2019-04-10T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-29T19:48:27.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/DALL-E-2022-08-29-21.47.48---a-garden-gnome-with-umbrella-in-a-barrel-at-Niagara-Falls--digital-art.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/DALL-E-2022-08-29-21.47.48---a-garden-gnome-with-umbrella-in-a-barrel-at-Niagara-Falls--digital-art.png\"></p><p>DOI
        metadata provenance is describing the history of a particular DOI metadata
        record, i.e. what changes were made when and by whom. This information is
        now stored and provided via an API for all DOI registrations since March 10,
        2019.</p><p>The following provenance information is now available via a new
        <code>/activities</code> REST API endpoint:</p><ul><li><strong><strong>prov:wasGeneratedBy</strong></strong>.
        The unique identifier for the activity making changes to a DOI record.</li><li><strong><strong>prov:generatedAtTime</strong></strong>.
        Timestamp of the activity.</li><li><strong><strong>prov:wasDerivedFrom</strong></strong>.
        The DOI for which the changes are being tracked.</li><li><strong><strong>prov:wasAttributedTo</strong></strong>.
        The client or provider account responsible for the changes.</li><li><strong><strong>action</strong></strong>.
        Can be either create, update or delete.</li><li><strong><strong>version</strong></strong>.
        Version number for the DOI record.</li><li><strong><strong>changes</strong></strong>.
        Changes made to DOI metadata, broken down by attribute, with both old and
        new value.</li></ul><p>The main use case is more transparency about changes
        to DOI metadata, including changes of the URL. You will for example be able
        to see the provenance for the DOI metadata for this blog post via <em>https://api.datacite.org/dois/10.5438/wy92-xj57/activities</em>.
        This is mainly useful if something goes wrong, but for example helps explain
        why a DOI record sometimes has a new <code>updated date</code> even though
        the member didn't make any changes (the most likely reason is that we stored
        <a href=\"https://support.datacite.org/docs/link-checker\">link checker</a>
        results and you would see that in the provenance record).</p><p>We have captured
        more than 3.6 million activities around DOI metadata records since starting
        this new service in March. Going forward, we will enhance the functionality,
        e.g. by providing the same information in DOI Fabrica in addition to the API.
        Tracking the provenance also allows users to revert changes that were made
        inadvertently, and it allows DataCite to build services that are triggered
        when a particular change is made to DOI metadata.</p><p>This work has been
        done as part of the <a href=\"https://www.project-freya.eu/en/about/mission\">FREYA
        project</a>, which aims to expand the technical and social infrastructure
        for persistent identifiers in Europe. For more information about the new activities
        API please visit our <a href=\"https://support.datacite.org/docs/tracking-provenance\">support
        pages for this new service</a>, or <a href=\"mailto:support@datacite.org\">send
        us an email</a>.</p><p><em>This blog post was <a href=\"https://doi.org/10.5438/wy92-xj57\">originally
        published</a> on the DataCite Blog.</em></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Introducing the PID Graph ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/introducing-the-pid-graph/\" />\n\t\t<id>https://doi.org/10.53731/ewrv712-2k7rx6d</id>\n
        \       <published>2019-03-28T00:00:00.000+00:00</published>\n\t\t<updated>2023-09-07T11:48:44.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/pid_graph_image-1.webp\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/pid_graph_image-1.webp\"></p><p>Persistent
        identifiers (PIDs) are not only important to uniquely identify a publication,
        dataset, or person, but the metadata for these persistent identifiers can
        provide unambiguous linking between persistent identifiers of the same type,
        e.g. journal articles citing other journal articles, or of different types,
        e.g. linking a researcher and the datasets they produced.</p>\n<p>Work is
        needed to connect existing persistent identifiers to each other in standardized
        ways, e.g. to the outputs associated with a particular researcher, repository,
        institution or funder, for discovery and impact assessment. Some of the more
        complex but still important use cases can\u2019t be addressed by simply collecting
        and aggregating links between two persistent identifiers, including</p>\n<ol><li>Aggregate
        the citations for all versions of a dataset or software source code</li><li>Aggregate
        the citations for all datasets hosted in a particular repository, funded by
        a particular funder, or created by a particular researcher</li><li>Aggregate
        all citations for a <a href=\"http://www.researchobject.org/\">research object</a>:
        a publication, the data underlying the findings in the paper, and the software,
        samples, and reagents used to create those datasets.</li></ol>\n<p>To address
        these use cases we need a more complex model to describe the resources that
        are identified by PIDs, and the connections between them: a graph. In graph
        theory, the resources identified by PIDs correspond to the nodes in this graph,
        and the connections between PIDs correspond to the edges.</p>\n<p>Using a
        graph makes it easier to describe these more complex use cases and relationships,
        and this approach has been frequently applied to similar questions in the
        past. FREYA builds on the expertise and close collaboration with the <a href=\"http://researchgraph.org/\">Research
        Graph</a> team and adopts the outputs of the <a href=\"https://www.rd-alliance.org/groups/data-description-registry-interoperability.html\">Research
        Data Alliance DDRI Working group</a> to transform PID connections into an
        improved graph of research objects. This project takes advantage of the best
        practices of graph modelling and distributed network analysis techniques.
        We call this the <strong>PID Graph</strong>.</p>\n<h3 id=\"pid-graph-use-cases\">PID
        Graph Use Cases</h3>\n<p>Before starting work on implementing the PID Graph,
        the FREYA partners collected user stories from their communities relevant
        to the PID Graph work. We used GitHub issues in a public repository for this
        activity and then met in person in August 2018 to clarify, group and prioritize
        these user stories. In total, we identified 48 user stories, described <a
        href=\"https://github.com/datacite/freya/issues?utf8=%E2%9C%93&amp;q=is%3Aissue+is%3Aopen+label%3A%22PID+Graph%22++label%3A%22user+story%22+\">here</a>.
        The main outcomes of the August 2018 workshop were:</p>\n<ol><li>There is
        a significant number of relevant user stories that can only be addressed by
        implementing a PID Graph.</li><li>While there is a diverse number of stakeholder
        groups and persistent identifier types in these user stories, a number of
        common themes and major use cases emerged in the workshop.</li><li>We didn\u2019t
        identify any uses cases that require more than two connections between PIDs,
        simplifying the required implementation work needed.</li></ol>\n<p>After identifying
        and describing the most relevant use cases, summarized above, we started the
        implementation work for the FREYA PID Graph. Our goal was to implement the
        PID Graph as standard production service rather than a research activity or
        pilot service, so scalability and maintainability are of utmost importance.
        We learned a lot from the extensive experience gained in the <a href=\"http://researchgraph.org/\">Research
        Graph</a> initiative and decided to build PID Graph using a set of federated
        RESTful JSON APIs. PID Graph will not be a single service but federated between
        FREYA PID providers, FREYA disciplinary partners, and organizations outside
        of FREYA. PID Graph will be provided by <a href=\"https://restfulapi.net/\">RESTful
        JSON APIs</a> that describe the resources (nodes) and connections (edges)
        in this graph. All FREYA PID providers use RESTful JSON APIs to provide PID
        metadata so that this approach aligns with the extensive existing infrastructure.</p>\n<h3
        id=\"initial-pid-graph-implementation\">Initial PID Graph Implementation</h3>\n<p>The
        first working PID Graph implementation is provided by DataCite, extending
        the existing Event Data Service (Dasler &amp; Cousijn, <a href=\"https://blog.datacite.org/introducing-the-pid-graph/#ref-https://doi.org/10.5438/s6d3-k860\">2018</a>),
        a collaboration between Crossref and DataCite. Event Data is a service that
        provides connections (here called events) between PIDs and other resources,
        with an initial focus on social media mentions and data citations. The initial
        PID Graph work done by DataCite since the August 2018 workshop has added these
        functionalities to <a href=\"https://datacite.org/eventdata.html\">DataCite
        Event Data</a>:</p>\n<h4 id=\"include-metadata-about-resources\">Include metadata
        about resources</h4>\n<p>Include not only metadata about connections but also
        metadata about the resources identified by PIDs. This dramatically simplifies
        the API calls needed to construct a PID Graph. We do this by optionally including
        the metadata for the <strong>subj</strong> and <strong>obj</strong> (the resources
        linked via the event) in Event Data via an extra query parameter: <a href=\"https://api.datacite.org/events?include=subj,obj\">https://api.datacite.org/events?include=subj,obj</a></p>\n<p>Including
        the metadata for subj and obj also enables queries based on resource metadata,
        e.g. query by type of content that is connected: <a href=\"https://api.datacite.org/events?include=subj,obj&amp;citationType=ScholarlyArticle-SoftwareSourceCode\">https://api.datacite.org/events?include=subj,obj&amp;citationType=ScholarlyArticle-SoftwareSourceCode</a></p>\n<p>This
        query today returns 1,078 events connecting scholarly articles and software,
        including 834 from journal articles referencing software via Crossref metadata
        and 210 from software referencing journal articles via DataCite metadata.</p>\n<h4
        id=\"include-implicit-relations-in-metadata-about-resources\">Include implicit
        relations in metadata about resources</h4>\n<p>Metadata for resources contain
        a lot of information about connected PIDs. We can take advantage of this by
        including the information in DataCite Event Data, allowing queries that in
        effect connect two PIDs via an intermediary resource and two connections.
        Specifically, we include these relations and associated PIDs:</p>\n<ol><li>Version,
        e.g. dataset A <strong>isVersionOf</strong> dataset B (using DataCite <strong>relatedIdentifier</strong>
        metadata)</li><li>Granularity, e.g. dataset A <strong>isPartOf</strong> dataset
        B or dataset A <strong>isSupplementTo</strong> article B (using DataCite <strong>relatedIdentifier</strong>
        metadata)</li><li>Funding, e.g. dataset A <strong>isFundedBy</strong> funder
        B (using DataCite <strong>fundingReferences</strong> metadata)</li><li>Author,
        e.g. dataset A <strong>isAuthoredBy </strong>author B (using DataCite <strong>nameIdentifier</strong>
        metadata)</li></ol>\n<p>These connected PIDs can then act as a <strong>proxy</strong>
        in PID Graph queries, as demonstrated in this example:</p>\n<p><a href=\"https://api.datacite.org/events?include=subj,obj&amp;doi=10.5061/dryad.k5k9074\">https://api.datacite.org/events?include=subj,obj&amp;doi=10.5061/dryad.k5k9074</a></p>\n<p>The
        query today returns one data citation of the dataset identified by the DOI,
        and eight data files that are part of this dataset. If someone decides to
        cite one of these data files instead of the dataset (following principle 8
        Specificity and Verifiability of the Joint Declaration of Data Citation Principles
        (Data Citation Synthesis Group, <a href=\"https://blog.datacite.org/introducing-the-pid-graph/#ref-https://doi.org/10.25490/a97f-egyk\">2014</a>)),
        that data citation would also be included in the DataCite Event Data response.</p>\n<p>Similarly,
        the citation of a specific version of a dataset would be included if querying
        for the parent version of the dataset. Examples for funding and authorship
        are given in the next paragraph.</p>\n<h4 id=\"include-more-types-of-events\">Include
        more types of events</h4>\n<p>The initial focus in Event Data was on social
        media mentions and data citations. DataCite has added author-resource links
        and funder-resource links, using ORCID and Crossref Funder ID as PIDs, respectively.
        DataCite also include dataset usage statistics, as part of the work in the
        Make Data Count (Lowenberg, Budden, &amp; Cruse, <a href=\"https://blog.datacite.org/introducing-the-pid-graph/#ref-https://doi.org/10.5438/pre3-2f25\">2018</a>)
        project. This enables the following two use cases:</p>\n<ol><li>Show all datasets
        created by a particular researcher and their usage stats <a href=\"https://api.datacite.org/events?include=subj,obj&amp;orcid=0000-0002-1194-1055\">https://api.datacite.org/events?include=subj,obj&amp;orcid=0000-0002-1194-1055</a>.
        The query today returns four datasets created by a researcher identified via
        her ORCID ID, plus a combined 21 unique views of these datasets in February
        and March 2019.</li><li>Show all datasets funded by the European Commission
        that have been cited by a journal article <a href=\"https://api.datacite.org/events?include=subj,obj&amp;doi=10.13039/501100000780&amp;citation-type=Dataset-ScholarlyArticle\">https://api.datacite.org/events?include=subj,obj&amp;doi=10.13039/501100000780&amp;citation-type=Dataset-ScholarlyArticle</a>.
        The query today returns 69 datasets cited by 37 journal articles.</li></ol>\n<h3
        id=\"collaborating-on-research-data-graph-initiatives\">Collaborating on Research
        Data Graph Initiatives</h3>\n<p>The aim is for any interested parties within
        and beyond FREYA to implement PID Graph services, meaning that we have to
        figure out how best to coordinate and enable this federated PID Graph. And
        of course, there are initiatives outside of FREYA taking similar approaches
        and addressing similar use cases. These include:</p>\n<ol><li>The already
        mentioned Research Graph Foundation</li><li><a href=\"http://www.scholix.org/\">Scholix</a>:
        a framework for Scholarly Link Exchange coordinated by a Research Data Alliance
        (RDA) Working Group</li><li>The OpenAIRE Research Graph (Manghi &amp; Bardi,
        <a href=\"https://blog.datacite.org/introducing-the-pid-graph/#ref-https://doi.org/10.5281/zenodo.2600275\">2019</a>),
        an open metadata research graph of interlinked scientific products, with access
        rights information, linked to funding information and research communities.</li><li>Asclepias
        (Ioannidis &amp; Gonzalez Lopez, <a href=\"https://blog.datacite.org/introducing-the-pid-graph/#ref-https://doi.org/10.5281/zenodo.2548643\">2019</a>),
        a broker service initially developed to track software citations in astronomy.</li></ol>\n<p>To
        coordinate these activities we have organized a Birds of a Feather session
        at the RDA Plenary in Philadelphia next week (Wednesday at 2:30 PM): <a href=\"https://rd-alliance.org/bof-Research-Data-Graph-RDA-13th-Plenary-meeting\">Research
        Data Graph</a>.</p>\n<p>The initial implementation of the PID Graph in DataCite
        Event Data contains 5.38 million events as of today and more work is needed
        to convert existing events to the new format (we expect a total of 25 million
        events with the current data source), improve documentation, and build visualizations
        and other frontend services to make it easier to show the PID Graph information
        we already have. But if you can\u2019t wait and are not afraid working with
        JSON REST APIs, feel free to explore DataCite Event Data, which is a free
        service with no registration required, by starting with the <a href=\"https://support.datacite.org/docs/eventdata-guide\">documentation</a>.</p>\n<p>And
        please reach out to us via the <a href=\"https://www.pidforum.org/\">PID Forum</a>
        if you are interested to learn more about PID Graph, want to see your data
        in PID Graph, or are working on a related project and want to coordinate.
        And of course, join us for the RDA Plenary session next week in Philadelphia
        if you plan to attend the conference.</p>\n<h2 id=\"acknowledgments\">Acknowledgments</h2>\n<p>This
        post has been cross-posted from the <a href=\"https://www.project-freya.eu/en/blogs/blogs/the-pid-graph\">FREYA</a>
        and <a href=\"https://doi.org/10.5438/jwvf-8a66\">DataCite</a> blogs. This
        work was funded by the European Union\u2019s Horizon 2020 research and innovation
        programme under <a href=\"https://doi.org/10.3030/777523\" rel=\"noreferrer\">grant
        agreement No.&nbsp;777523</a>.</p>\n<h2 id=\"references\">References</h2>\n<p>Dasler
        R, Cousijn H. Are your data being used? Event Data has the answer! In: DataCite;
        2018. doi:<a href=\"https://doi.org/10.5438/S6D3-K860\">10.5438/S6D3-K860</a></p>\n<p>Data
        Citation Synthesis Group. <em>Joint Declaration of Data Citation Principles</em>.
        Force11; 2014. doi:<a href=\"https://doi.org/10.25490/A97F-EGYK\">10.25490/A97F-EGYK</a></p>\n<p>Ioannidis
        A, Gonzalez Lopez JB. Asclepias: Flower Power for Software Citation. Published
        online January 24, 2019. doi:<a href=\"https://doi.org/10.5281/ZENODO.2548643\">10.5281/ZENODO.2548643</a></p>\n<p>Lowenberg
        D, Budden A, Cruse P. It\u2019s Time to Make Your Data Count! Published online
        June 5, 2018. doi:<a href=\"https://doi.org/10.5438/PRE3-2F25\">10.5438/PRE3-2F25</a></p>\n<p>Manghi
        P, Bardi A. The OpenAIRE Research Graph - Opportunities and challenges for
        science. Published online March 20, 2019. doi:<a href=\"https://doi.org/10.5281/ZENODO.2600275\">10.5281/ZENODO.2600275</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ DataCite&#x27;s New Search ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/datacites-new-search/\" />\n\t\t<id>https://doi.org/10.53731/r79sjwh-97aq74v-ag4xc</id>\n
        \       <published>2019-01-07T00:00:00.000+00:00</published>\n\t\t<updated>2023-07-03T10:28:05.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/bildschirmfoto-2019-01-05-um-17.30.20.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/bildschirmfoto-2019-01-05-um-17.30.20.png\"></p><p>Today
        we are announcing our first new functionality of 2019, a much improved search
        for DataCite DOIs and metadata. While the <a href=\"https://search.datacite.org/\">DataCite
        Search</a> user interface has not changed, changes under the hood bring many
        important improvements and are our biggest changes to search since 2012.</p><h2
        id=\"faster-indexing\">Faster Indexing</h2><p>Newly registered (and tagged
        findable) DOIs now appear in the DataCite Search index within a few minutes,
        compared with the previous up to 12 hour lag. The same is true for metadata
        updates or DOIs removed from the public search index (by changing the DOI
        state from <strong><strong>findable</strong></strong> to <strong><strong>registered</strong></strong>).
        Faster indexing is particularly important when related content is published
        at the same time, e.g. a dataset with a DataCite DOI associated with a journal
        article with a Crossref DOI.</p><h2 id=\"advanced-doi-search-in-doi-fabrica\">Advanced
        DOI Search in DOI Fabrica</h2><p>This faster indexing makes it possible for
        members and clients to use the Search index also in <a href=\"https://doi.datacite.org/\">DOI
        Fabrica</a>, enabling the same advanced search functionality available in
        DataCite Search, but also including DOIs in <strong><strong>draft</strong></strong>
        or <strong><strong>registered</strong></strong> state. Our Solr search index
        could not be used in DOI Fabrica, as users would not see newly created or
        updated DOIs because of the indexing delay. This makes it much easier to manage
        DOIs and associated metadata, e.g. by filtering for DOIs in draft state or
        finding DOIs using the retired metadata schemata 2.1 and 2.2. And it is the
        first time that we provide DOI registration and search in a single user interface;
        this kind of simplification is one of our themes for 2019 [Dasler (<a href=\"https://blog.datacite.org/improving-search/#ref-https://doi.org/10.5438/bckb-qy95\">2018</a>)].</p><h2
        id=\"search-for-everything\">Search for Everything</h2><p>Our new search index
        covers all metadata and allows specific searches of every metadata field.
        For example <strong><strong>geoLocationPlace</strong></strong>:</p><figure
        class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/bildschirmfoto-2019-01-05-um-17.40.47.png\"
        class=\"kg-image\" alt=\"Search for geoLocationPlace Cuba\" loading=\"lazy\"
        width=\"1467\" height=\"997\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/bildschirmfoto-2019-01-05-um-17.40.47.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/08/bildschirmfoto-2019-01-05-um-17.40.47.png
        1000w, https://blog.front-matter.io/content/images/2022/08/bildschirmfoto-2019-01-05-um-17.40.47.png
        1467w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Search for geoLocationPlace
        Cuba</figcaption></figure><p>The supported search syntax is very similar to
        what was available before, and uses the <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-query-string-query.html#query-string-syntax\">Elasticsearch
        Query String Syntax</a>. You can for example specify field names, use wildcards,
        regular expressions, ranges, and boolean operators, e.g. use <code>creators.affiliation:stanford
        +creators.affiliation:ucsf</code> to find the 174 DOIs with collaborators
        from both of these two institutions.</p><h2 id=\"it-solves-the-deep-paging-problem\">It
        Solves the Deep Paging Problem</h2><p>One important limitation of our previous
        search index, and a common issue with many search implementations, was the
        <a href=\"https://solr.pl/en/2011/07/18/deep-paging-problem/\">deep paging
        problem</a>, making it hard if not impossible to fetch a very large number
        of results. Our new search index supports cursor-based pagination that overcomes
        this problem, allowing users to, for example, harvest all DOI metadata from
        a particular member. This is done in the REST API, specifying a larger number
        of records per page \u2013 e.g. <code>https://api.datacite.org/providers/caltech/dois?page[size]=1000</code>
        \u2013 and using the URL provided via <code>links.next</code> in the API response
        for the next query.</p><h2 id=\"implementation\">Implementation</h2><p>The
        above changes were made possible by updating our search index service from
        an old version of Solr (4.0) to a recent version of Elasticsearch (6.3). We
        switched to Elasticsearch, as it works better with our new JSON-based workflow
        \u2013 see our December blog post about JSON [Fenner (<a href=\"https://blog.datacite.org/improving-search/#ref-https://doi.org/10.5438/1pca-1y05\">2018</a>)]
        \u2013 and we can use a <a href=\"https://aws.amazon.com/elasticsearch-service/\">hosted
        service</a> tightly integrated with the rest of our infrastructure thereby
        reducing the support effort needed.</p><h2 id=\"next\">Next</h2><p>Not all
        DataCite services have been switched to the new search index, the <a href=\"https://stats.datacite.org/\">Stats
        Portal</a> and <a href=\"https://oai.datacite.org/\">OAI-PMH</a> service will
        be migrated within the next three months and continue to use the old Solr
        search index for now.</p><p>In the coming weeks and months, we will also provide
        better documentation, and improve performance and fix any bugs we encounter.
        We will also work with our members to better understand what kind of queries
        they are most interested in, and how we can better support these queries in
        the search interface.</p><p><em>This blog post was <a href=\"https://doi.org/10.5438/vyd9-ty64\">originally
        published</a> on the DataCite Blog.</em></p><h2 id=\"references\">References</h2><p>Dasler
        R. DataCite 2018 Wrap-up and 2019 Preview. Published online December 18, 2018.
        doi:<a href=\"https://doi.org/10.5438/BCKB-QY95\">10.5438/BCKB-QY95</a></p><p>Fenner
        M. Introducing DataCite JSON. Published online December 19, 2018. doi:<a href=\"https://doi.org/10.53731/r79spkh-97aq74v-ag4xz\">10.53731/r79spkh-97aq74v-ag4xz</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Introducing DataCite JSON ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/introducing-datacite-json/\" />\n\t\t<id>https://doi.org/10.53731/r79spkh-97aq74v-ag4xz</id>\n
        \       <published>2018-12-19T00:00:00.000+00:00</published>\n\t\t<updated>2023-07-02T06:56:03.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/bildschirmfoto-2018-12-19-um-15.36.18.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/bildschirmfoto-2018-12-19-um-15.36.18.png\"></p><p>All
        DataCite DOIs have associated metadata, described in the DataCite Metadata
        Schema Documentation (DataCite Metadata Working Group (<a href=\"https://blog.datacite.org/introducing-datacite-json/#ref-https://doi.org/10.5438/0014\">2017</a>)),
        validated and stored as XML in the DataCite Metadata Store (MDS). These metadata
        are then made available via DataCite APIs and services. For these services
        XML is not always the best format, and we are thus providing the metadata
        in other formats, most notably JSON. The problem with our approach so far
        has been that this JSON was not properly defined, creating overhead and ambiguity
        both for our internal services and for our users. To change this situation,
        and to make it easier to work with metadata for DataCite DOIs, we today are
        announcing <strong><strong>DataCite JSON</strong></strong>.</p><h3 id=\"what-is-datacite-json\">What
        is DataCite JSON?</h3><p>DataCite JSON represents all metadata elements and
        attributes available in DataCite XML, and can be converted from and to DataCite
        XML via several DataCite services (MDS API, EZ API, DOI Fabrica, Content Negotiation)
        that internally all use the bolognese metadata conversion library (Fenner
        (<a href=\"https://blog.datacite.org/introducing-datacite-json/#ref-https://doi.org/10.5438/n138-z3mk\">2017</a>)),
        which also provides a command-line utility. Both our new Elasticsearch Search
        index and the updated JSON REST API (more on those in another blog post) use
        DataCite JSON. The bolognese metadata conversion library uses DataCite JSON
        as the intermediary format, for example when converting BibTeX to schema.org
        JSON-LD or JATS XML.</p><h2 id=\"is-datacite-json-different-from-datacite-xml\">Is
        DataCite JSON different from DataCite XML?</h2><p>There are minor differences
        between DataCite JSON and DataCite XML, mainly to make working with the metadata
        easier. This includes an <strong><strong>identifiers</strong></strong> object
        that combines the <strong><strong>identifier</strong></strong> and <strong><strong>alternateIdentifier</strong></strong>
        properties, and a <strong><strong>types</strong></strong> object that not
        only stores <strong><strong>resourceTypeGeneral</strong></strong> and <strong><strong>resourceType</strong></strong>
        information, but also the type information from RIS, BibTeX, Citeproc and
        schema.org, to avoid losing type information when converting between these
        formats. There is also a new <strong><strong>container</strong></strong> property
        that stores information about the repository or journal where the content
        is located. We can provide this information in DataCite XML via the relatedidentifier
        (with relationType <strong><strong>isPartOf</strong></strong>) and description
        (via descriptionType <strong><strong>SeriesInformation</strong></strong>)
        elements, but the process is cumbersome. DataCite JSON also includes information
        not available in DataCite XML, including the url registered for the DOI, and
        the date the DOI was registered.</p><h2 id=\"do-you-have-examples-using-datacite-json\">Do
        you have examples using DataCite JSON?</h2><p>To see DataCite JSON in action,
        lookup the DOI metadata of your favorite DOI in our JSON REST API, e.g. <a
        href=\"https://api.datacite.org/dois/10.5438/0014\">https://api.datacite.org/dois/10.5438/0014</a>,
        or - if you are a DataCite member or client - in <a href=\"https://doi.datacite.org/\">DOI
        Fabrica</a>. Alternatively install bolognese (via <code>gem install bolognese</code>)
        and fetch metadata via the command <code>bolognese 10.5438/0014 -t datacite_json</code>.
        Documentation of DataCite JSON is unfortunately still sparse, in early 2019
        we will provide better documentation via our <a href=\"https://support.datacite.org/\">support
        site</a>, and this will also include updated documentation of the JSON REST
        API and a JSON Schema to validate the metadata, aligned with our XSD Schema
        for DataCite XML.</p><p>We hope that DataCite JSON makes it easier to work
        with DataCite metadata, helping to improve metadata quality and re-use. We
        encourage users to adapt their tools to take advantage of DataCite JSON, and
        to consider DataCite JSON also when working with metadata not associated with
        a DataCite DOI, but when a description of scholarly resources with standard
        metadata and using JSON is needed. Watch out for more information about DataCite
        JSON in 2019, or reach out to us with questions or feedback via <a href=\"mailto:support@datacite.org\">mailto:support@datacite.org</a>.</p><p><em>This
        blog post was <a href=\"https://doi.org/10.5438/1pca-1y05\">originally published</a>
        on the DataCite Blog.</em></p><h2 id=\"references\">References</h2><p>DataCite
        Metadata Working Group. DataCite Metadata Schema Documentation for the Publication
        and Citation of Research Data v4.1. Published online 2017:72 pages. doi:<a
        href=\"https://doi.org/10.5438/0014\">10.5438/0014</a></p><p>Fenner M. Bolognese:
        a Ruby library for conversion of DOI Metadata. Published online February 25,
        2017. doi:<a href=\"https://doi.org/10.5438/N138-Z3MK\">10.5438/N138-Z3MK</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ COUNTER Code of Practice for Research Data
        Usage Metrics release 1 ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/counter-code-of-practice-for-research-data-usage-metrics-release-1/\"
        />\n\t\t<id>https://doi.org/10.53731/r7ae7bh-97aq74v-ag5qn</id>\n        <published>2018-09-18T00:00:00.000+00:00</published>\n\t\t<updated>2023-08-01T10:27:52.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://images.unsplash.com/photo-1529078155058-5d716f45d604?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDIwfHxkYXRhfGVufDB8fHx8MTY5MDg4NTYzOHww&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://images.unsplash.com/photo-1529078155058-5d716f45d604?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDIwfHxkYXRhfGVufDB8fHx8MTY5MDg4NTYzOHww&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000\"></p><p>There
        is a need for the consistent and credible reporting of research data usage.
        Such usage metrics are required as an important component in understanding
        how publicly available research data are being reused.</p><p>To address this
        need, <a href=\"https://www.projectcounter.org/\">COUNTER</a> and members
        of the <a href=\"https://makedatacount.org/\">Make Data Count</a> team (<a
        href=\"https://www.cdlib.org/\">California Digital Library</a>, <a href=\"https://datacite.org/\">DataCite</a>,
        and <a href=\"https://www.dataone.org/\">DataONE</a> collaborated in drafting
        the <a href=\"https://www.projectcounter.org/code-of-practice-rd-sections/foreword/\">Code
        of Practice for Research Data Usage Metrics release 1</a>.</p><p><a href=\"https://www.projectcounter.org/code-of-practice-rd-sections/foreword/\">The
        Code of Practice for Research Data Usage Metrics release 1</a> is aligned
        as much as possible with the <a href=\"https://www.projectcounter.org/code-of-practice-five-sections/abstract/\">COUNTER
        Code of Practice Release 5</a> which standardizes usage metrics for many scholarly
        resources, including journals and books. Many definitions, processing rules
        and reporting recommendations apply to research data in the same way as they
        apply to the other resources to which the COUNTER Code of Practice applies.
        Some aspects of the processing and reporting of usage data are unique to research
        data, and the Code of Practice for Research Data Usage Metrics thus deviates
        from the Code of Practice Release 5 and specifically address them.</p><p>The
        Code of Practice for Research Data Usage Metrics release 1 provides a framework
        for comparable data by standardizing the generation and distribution of usage
        metrics for research data. Data repositories and platform providers can now
        report usage metrics following common best practices and using a standard
        report format.</p><p>COUNTER welcomes feedback from the data repositories
        that implement this first release of the Code of Practice. Their experiences
        will help to refine and improve it and inform a second release.</p><p><em>Crossposted
        from the <a href=\"https://www.projectcounter.org/counter-code-practice-research-data-usage-metrics-release-1/\">COUNTER
        announcement</a> from September 13, 2018, and from the <a href=\"https://doi.org/10.5438/nb24-t773\">DataCite
        Blog</a>.</em></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ DOI Registrations for Software ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/doi-registrations-for-software/\"
        />\n\t\t<id>https://doi.org/10.53731/r7ae36h-97aq74v-ag5pw</id>\n        <published>2018-05-17T00:00:00.000+00:00</published>\n\t\t<updated>2023-07-02T07:07:41.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/dois-for-software.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/dois-for-software.png\"></p><p>We
        know that software is important in research, and some of us in the scholarly
        communications community, for example, <a href=\"https://www.force11.org/group/software-citation-implementation-working-group\">in
        FORCE11</a>, have been pushing the concept of software citation as a method
        to allow software developers and maintainers to get academic credit for their
        work: software releases are published and assigned DOIs, and software users
        then cite these releases when they publish research that uses the software.</p><p>DataCite
        recently examined the DOIs that have been created for software, and found
        that the number of new DOIs created for software is growing roughly exponentially,
        now reaching about 2000 software DOIs per month, with spikes of around 4000
        per month in some of 2017. The data and results are shown here. The source
        code for the R script used to generate the data and figures is available (Fenner,
        Katz, Smith, &amp; Nielsen (<a href=\"https://blog.datacite.org/doi-registrations-software/#ref-https://doi.org/10.5438/wr0x-e194\">2018</a>)).</p><p>As
        of May 16, 2018, <a href=\"https://search.datacite.org/works?resource-type-id=software\">58,301
        DOIs</a> have been registered for software. We can break down this number
        by repository where the software source code is hosted \u2013 most DOIs for
        software have been registered at Zenodo.</p><!--kg-card-begin: html--><table
        style=\"box-sizing: border-box; border-collapse: collapse; border-spacing:
        0px; background-color: rgb(255, 255, 255); color: rgb(102, 97, 91); font-family:
        Raleway, Helvetica, Arial, sans-serif; font-size: 18px; font-style: normal;
        font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400;
        letter-spacing: normal; orphans: 2; text-align: start; text-transform: none;
        white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width:
        0px; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color:
        initial; width: 892.656px;\"><colgroup style=\"box-sizing: border-box;\"><col
        width=\"92%\" style=\"box-sizing: border-box;\"><col width=\"7%\" style=\"box-sizing:
        border-box;\"></colgroup><tbody style=\"box-sizing: border-box;\"><tr class=\"odd\"
        style=\"box-sizing: border-box;\"><td align=\"left\" style=\"box-sizing: border-box;
        padding: 0px; -webkit-font-smoothing: antialiased; font-family: Raleway, Helvetica,
        Arial, sans-serif;\">CERN.ZENODO - ZENODO - Research. Shared.</td><td align=\"right\"
        style=\"box-sizing: border-box; padding: 0px; -webkit-font-smoothing: antialiased;
        font-family: Raleway, Helvetica, Arial, sans-serif;\">41346</td></tr><tr class=\"even\"
        style=\"box-sizing: border-box;\"><td align=\"left\" style=\"box-sizing: border-box;
        padding: 0px; -webkit-font-smoothing: antialiased; font-family: Raleway, Helvetica,
        Arial, sans-serif;\">FIGSHARE.ARS - figshare Academic Research System</td><td
        align=\"right\" style=\"box-sizing: border-box; padding: 0px; -webkit-font-smoothing:
        antialiased; font-family: Raleway, Helvetica, Arial, sans-serif;\">4226</td></tr><tr
        class=\"odd\" style=\"box-sizing: border-box;\"><td align=\"left\" style=\"box-sizing:
        border-box; padding: 0px; -webkit-font-smoothing: antialiased; font-family:
        Raleway, Helvetica, Arial, sans-serif;\">PURDUE.NCIB - National Cancer Institute,
        Bioconductor</td><td align=\"right\" style=\"box-sizing: border-box; padding:
        0px; -webkit-font-smoothing: antialiased; font-family: Raleway, Helvetica,
        Arial, sans-serif;\">2769</td></tr><tr class=\"even\" style=\"box-sizing:
        border-box;\"><td align=\"left\" style=\"box-sizing: border-box; padding:
        0px; -webkit-font-smoothing: antialiased; font-family: Raleway, Helvetica,
        Arial, sans-serif;\">PURDUE.EZID - Purdue University</td><td align=\"right\"
        style=\"box-sizing: border-box; padding: 0px; -webkit-font-smoothing: antialiased;
        font-family: Raleway, Helvetica, Arial, sans-serif;\">2463</td></tr><tr class=\"odd\"
        style=\"box-sizing: border-box;\"><td align=\"left\" style=\"box-sizing: border-box;
        padding: 0px; -webkit-font-smoothing: antialiased; font-family: Raleway, Helvetica,
        Arial, sans-serif;\">OSTI.DOE - DOE Generic</td><td align=\"right\" style=\"box-sizing:
        border-box; padding: 0px; -webkit-font-smoothing: antialiased; font-family:
        Raleway, Helvetica, Arial, sans-serif;\">736</td></tr><tr class=\"even\" style=\"box-sizing:
        border-box;\"><td align=\"left\" style=\"box-sizing: border-box; padding:
        0px; -webkit-font-smoothing: antialiased; font-family: Raleway, Helvetica,
        Arial, sans-serif;\">INIST.INRA - Institut National de Recherche Agronomique</td><td
        align=\"right\" style=\"box-sizing: border-box; padding: 0px; -webkit-font-smoothing:
        antialiased; font-family: Raleway, Helvetica, Arial, sans-serif;\">223</td></tr><tr
        class=\"odd\" style=\"box-sizing: border-box;\"><td align=\"left\" style=\"box-sizing:
        border-box; padding: 0px; -webkit-font-smoothing: antialiased; font-family:
        Raleway, Helvetica, Arial, sans-serif;\">OCEAN.OCEAN - Code Ocean</td><td
        align=\"right\" style=\"box-sizing: border-box; padding: 0px; -webkit-font-smoothing:
        antialiased; font-family: Raleway, Helvetica, Arial, sans-serif;\">206</td></tr><tr
        class=\"even\" style=\"box-sizing: border-box;\"><td align=\"left\" style=\"box-sizing:
        border-box; padding: 0px; -webkit-font-smoothing: antialiased; font-family:
        Raleway, Helvetica, Arial, sans-serif;\">CRUI.INFNCNAF - Istituto Nazionale
        di Fisica Nucleare. Centro Nazionale Analisi Fotogrammi</td><td align=\"right\"
        style=\"box-sizing: border-box; padding: 0px; -webkit-font-smoothing: antialiased;
        font-family: Raleway, Helvetica, Arial, sans-serif;\">190</td></tr><tr class=\"odd\"
        style=\"box-sizing: border-box;\"><td align=\"left\" style=\"box-sizing: border-box;
        padding: 0px; -webkit-font-smoothing: antialiased; font-family: Raleway, Helvetica,
        Arial, sans-serif;\">CDL.UCI - UC Irvine Library</td><td align=\"right\" style=\"box-sizing:
        border-box; padding: 0px; -webkit-font-smoothing: antialiased; font-family:
        Raleway, Helvetica, Arial, sans-serif;\">120</td></tr><tr class=\"even\" style=\"box-sizing:
        border-box;\"><td align=\"left\" style=\"box-sizing: border-box; padding:
        0px; -webkit-font-smoothing: antialiased; font-family: Raleway, Helvetica,
        Arial, sans-serif;\">ETHZ.DA-RD - ETHZ Data Archive - Research Data</td><td
        align=\"right\" style=\"box-sizing: border-box; padding: 0px; -webkit-font-smoothing:
        antialiased; font-family: Raleway, Helvetica, Arial, sans-serif;\">88</td></tr></tbody></table><!--kg-card-end:
        html--><h3 id=\"changes-over-time\">Changes over Time</h3><p>How did these
        numbers change over time, since the he <a href=\"https://api.datacite.org/works?resource-type-id=software&amp;sort=registered&amp;order=asc&amp;page%5Bsize%5D=1\">first
        DataCite DOI for software</a> was registered September 7th, 2011 by the Leibniz
        Institute of Plant Genetics and Crop Plant Research (IPK) in Germany (Colmsee,
        Flemming, Klapperst\xFCck, Lange, &amp; Scholz (<a href=\"https://blog.datacite.org/doi-registrations-software/#ref-https://doi.org/10.5447/ipk/2011/0\">2011</a>))?</p><p>We
        can start by looking at the <a href=\"https://guides.github.com/activities/citable-code/\">Zenodo/GitHub
        integration</a>, where users can archive a GitHub repository in the Zenodo
        data repository. The integration was launched in February 2014 and we can
        see a nice correlation with this data, and with a <a href=\"https://github.com/blog/1840-improving-github-for-science\">May
        2014 blog post</a> by Arfon Smith on the GitHub blog, describing (and advertising)
        the integration work.</p><p>In September 2016, the FORCE11 Software Citation
        Principles (A. M. Smith, Katz, Niemeyer, &amp; FORCE11 Software Citation Working
        Group (<a href=\"https://blog.datacite.org/doi-registrations-software/#ref-https://doi.org/10.7717/peerj-cs.86\">2016</a>))
        were published, the Zenodo/GitHub integration was upgraded ((<strong><strong>???</strong></strong>)/),
        and in October 2016 the <a href=\"https://guides.github.com/activities/citable-code/\">GitHub
        Guide to Making your Code Citable</a> was updated. There appears to be a change
        of in the rate of growth around this time as well.</p><h2 id=\"looking-forward\">Looking
        forward</h2><p>We see a nice exponential growth in the number of DOIs for
        software, and we don't expect this to change in 2018 and beyond. The <a href=\"https://www.force11.org/group/software-citation-implementation-working-group\">FORCE11
        Software Citation Implementation Working Group</a> is working on implementation
        and adoption of the Software Citation Principles, and for a number of use
        cases, e.g., citation in a journal article, DOIs play an important role. The
        working group also tries to address the challenges in using DOIs as identifiers
        for software that still exist, and what is done to resolve them, including
        pre-registration APIs to smooth the automated push-style deposit; better semantic
        linkage supported by extensions to the DataCite schema, and group/collective/microcitation
        DOI use.</p><p>We expect initiatives such as <a href=\"http://citation-file-format.github.io/citation-file-format/\">Citation
        File Format</a> and <a href=\"https://www.softwareheritage.org/\">Software
        Heritage</a> to have a positive impact on the number of DOIs for software.
        A paper on persistent identification and citation of software using DOIs by
        Jones et al (C. M. Jones, Matthews, Gent, Griffin, &amp; Tedds (<a href=\"https://blog.datacite.org/doi-registrations-software/#ref-https://doi.org/10.2218/ijdc.v11i2.422\">2017</a>))
        was published in July 2017, based on earlier work from 2015 (Gent, Jones,
        &amp; Matthews (<a href=\"https://blog.datacite.org/doi-registrations-software/#ref-http://purl.org/net/epubs/work/24058274\">2015</a>)),
        and the DataCite Metadata 4.1 schema focussing on software citation was released
        in September 2017 (DataCite Metadata Working Group (<a href=\"https://blog.datacite.org/doi-registrations-software/#ref-https://doi.org/10.5438/0014\">2017</a>),
        Starr (<a href=\"https://blog.datacite.org/doi-registrations-software/#ref-https://doi.org/10.5438/nzhx-xx96\">2017</a>)).</p><p>CodeMeta
        (Boettiger (<a href=\"https://blog.datacite.org/doi-registrations-software/#ref-https://doi.org/10.6084/m9.figshare.4490588\">2017</a>),
        M. B. Jones et al. (<a href=\"https://blog.datacite.org/doi-registrations-software/#ref-https://doi.org/10.5063/schema/codemeta-2.0\">2017</a>))
        is particularly relevant; this new standard for software metadata simplifies
        the crosswalk between the wide variety of metadata standards for software,
        and is increasingly integrated into DOI registration workflows, including
        the CaltechDATA repository since <a href=\"https://www.library.caltech.edu/news/enhanced-software-preservation-now-available-caltechdata\">March
        2018</a>, the DataCite DOI registration service since May 2018 (Fenner (<a
        href=\"https://blog.datacite.org/doi-registrations-software/#ref-https://doi.org/10.5438/cxe5-rg55\">2018</a>),
        Dasler (<a href=\"https://blog.datacite.org/doi-registrations-software/#ref-https://doi.org/10.5438/0yk5-b755\">2018</a>))
        and is planned for the Zenodo/GitHub integration in autumn 2018. CodeMeta
        libraries are currently available for R (Codemetar, Boettiger et al. (<a href=\"https://blog.datacite.org/doi-registrations-software/#ref-https://doi.org/10.5281/zenodo.1241346\">2018</a>)),
        Ruby (Bolognese, Fenner (<a href=\"https://blog.datacite.org/doi-registrations-software/#ref-https://doi.org/10.5438/n138-z3mk\">2017</a>))
        and Python (<a href=\"https://github.com/proycon/codemetapy\">CodeMetaPy</a>).</p><p><em>This
        blog post was <a href=\"https://doi.org/10.5438/1nmy-9902\">originally published</a>
        on the DataCite Blog.</em></p><h2 id=\"references\">References</h2><p>Boettiger
        C. <em>Codemeta: A Rosetta Stone for Software Metadata</em>. figshare; 2017:6508668
        Bytes. doi:<a href=\"https://doi.org/10.6084/M9.FIGSHARE.4490588\">10.6084/M9.FIGSHARE.4490588</a></p><p>Boettiger
        C, Salmon M, Arfon Smith, Ross N, Leinweber K, Krystalli A. ropensci/codemetar:
        codemetar: Generate CodeMeta Metadata for R Packages. Published online May
        5, 2018. doi:<a href=\"https://doi.org/10.5281/ZENODO.1241346\">10.5281/ZENODO.1241346</a></p><p>Colmsee
        C, Flemming S, Klapperst\xFCck M, Lange M, Scholz U. A case study for efficient
        management of high throughput primary lab data: source code. Published online
        2011:2.2 MB. doi:<a href=\"https://doi.org/10.5447/IPK/2011/0\">10.5447/IPK/2011/0</a></p><p>Dasler
        R. DOI Fabrica 1.0 is Here! Published online May 9, 2018. doi:<a href=\"https://doi.org/10.5438/0YK5-B755\">10.5438/0YK5-B755</a></p><p>DataCite
        Metadata Working Group. DataCite Metadata Schema Documentation for the Publication
        and Citation of Research Data v4.1. Published online 2017:72 pages. doi:<a
        href=\"https://doi.org/10.5438/0014\">10.5438/0014</a></p><p>Fenner M. Bolognese:
        a Ruby library for conversion of DOI Metadata. Published online February 25,
        2017. doi:<a href=\"https://doi.org/10.5438/N138-Z3MK\">10.5438/N138-Z3MK</a></p><p>Fenner
        M. Frontend for the DataCite DOI Fabrica service. Published online May 9,
        2018. doi:<a href=\"https://doi.org/10.5438/CXE5-RG55\">10.5438/CXE5-RG55</a></p><p>Fenner
        M, Katz DS, Smith A, Nielsen LH. DOI Registrations for Software. Published
        online May 17, 2018. doi:<a href=\"https://doi.org/10.5438/WR0X-E194\">10.5438/WR0X-E194</a></p><p>Gent
        I, Jones C, Matthews B. <em>Guidelines for Persistently Identifying Software
        Using DataCite</em>.; 2015. Accessed July 2, 2023. <a href=\"https://epubs.stfc.ac.uk/work/24058274\">https://epubs.stfc.ac.uk/work/24058274</a></p><p>Jones
        CM, Matthews B, Gent I, Griffin T, Tedds J. Persistent Identification and
        Citation of Software. <em>IJDC</em>. 2017;11(2):104-114. doi:<a href=\"https://doi.org/10.2218/ijdc.v11i2.422\">10.2218/ijdc.v11i2.422</a></p><p>Jones
        MB, Boettiger C, Mayes AC, et al. CodeMeta: an exchange schema for software
        metadata. Published online 2017. doi:<a href=\"https://doi.org/10.5063/SCHEMA/CODEMETA-2.0\">10.5063/SCHEMA/CODEMETA-2.0</a></p><p>Smith
        AM, Katz DS, Niemeyer KE, FORCE11 Software Citation Working Group. Software
        citation principles. <em>PeerJ Computer Science</em>. 2016;2:e86. doi:<a href=\"https://doi.org/10.7717/peerj-cs.86\">10.7717/peerj-cs.86</a></p><p>Starr
        J. New DataCite Metadata Updates Support Software Citation. Published online
        October 23, 2017. doi:<a href=\"https://doi.org/10.5438/NZHX-XX96\">10.5438/NZHX-XX96</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Announcing DataCite DOI Fabrica ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/announcing-datacite-doi-fabrica/\"
        />\n\t\t<id>https://doi.org/10.53731/r7adsah-97aq74v-ag5mp</id>\n        <published>2017-10-18T00:00:00.000+00:00</published>\n\t\t<updated>2023-09-07T11:46:32.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/link-checking.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/link-checking.png\"></p><p>Today
        DataCite is launching <a href=\"https://doi.datacite.org/\">DOI Fabrica</a>,
        the next generation of DataCite\u2019s DOI registration service, replacing
        the Metadata Store (<a href=\"https://mds.datacite.org/\">MDS</a>). This is
        the biggest and most important product release DataCite has done in many years,
        and the result of nine months of hard work by the entire DataCite team.</p>\n<p>DOI
        registration is the core service that DataCite is providing to its members
        and the data centers they work with. The requirements for how DOI registration
        should work have changed significantly since the Metadata Store was originally
        launched in 2011. We began the DOI Fabrica project in early 2017 by collecting,
        categorizing, and prioritizing user stories for what is needed from the DataCite
        DOI registration service. Central to this activity was continuously engaging
        with our members and the DataCite community to make sure their needs were
        met. As part of this work, we rethought how we work with user stories and
        how develop our product roadmap (more details in <a href=\"https://blog.datacite.org/roadmap/\">this</a>
        blog post), and you can find all user stories directly relevant for DOI registration
        <a href=\"https://www.datacite.org/user-stories.html?=&amp;category=create#how-to-provide-feedback\">here</a>.</p>\n<p>Once
        it was clear that significant work was needed to improve the existing DOI
        registration service, and that incremental changes of the Metadata Store wouldn\u2019t
        be enough, we thought about how to best approach the development of a new
        service. The following principles guided us:</p>\n<ul><li>Implement and constantly
        improve a feedback process that can guide our development. In addition to
        the user stories and roadmap we also worked closely with the <a href=\"https://www.datacite.org/steering.html\">DataCite
        Services and Technology Steering Group</a> that was launched in September
        2016.</li><li>Do gradual, small changes as much as possible to reduce the
        risk of failures or significant delays \u2013 we have all experienced this
        with scholarly infrastructure projects. DOI Fabrica focusses on changes in
        the user interface, and we have left the MDS API unchanged for now.</li><li>Re-architect
        the existing DOI registration service into smaller, loosely coupled services
        to simplify maintenance and improvements. DOI Fabrica consists of one frontend
        service, one authentication service, and two APIs (the legacy MDS API plus
        a new API for managing members and data centers).</li><li>Make it easy to
        run the code in development, deploy code changes and receive automatic error
        messages. This includes continuous integration tools for automatically running
        tests after commits to the code repository.</li><li>Build user interfaces
        that engage users, and provide clear documentation and mechanisms to provide
        feedback.</li></ul>\n<p>What do all of the above have in common? They make
        the product development process faster, broken down into smaller steps, and
        more focused on what our members and users really care about. The most important
        feature of DOI Fabrica is thus the ongoing development it enables going forward,
        and you can expect important new functionality in the next few months (check
        our <a href=\"https://www.datacite.org/roadmap.html\">roadmap</a> for details
        and/or if you want to provide feedback). But of course, this first DOI Fabrica
        release comes with functionality directly addressing the needs identified
        in the user stories collected earlier this year. We want to highlight how
        we addressed five of these user stories:<a href=\"https://github.com/datacite/datacite/issues/132\">Single
        Sign-on</a></p>\n<p><em>As a member or data center, I want a single username/password
        to access all DataCite services, so that I don't spend extra time managing
        access.</em></p>\n<p>We have consolidated all login options for users into
        a single service, <a href=\"https://profiles.datacite.org/\">DataCite Profiles</a>,
        and defined roles and permissions for DOI Fabrica. To not break existing integrations,
        the MDS API will continue to use the old username/password authentication.</p>\n<h3
        id=\"powerful-mds-admin-user-interface-ui\"><a href=\"https://github.com/datacite/datacite/issues/56\">Powerful
        MDS Admin User Interface (UI)</a></h3>\n<p><em>As a member, I want a powerful
        admin UI (prefix transfer from one datacenter to another, editing/hiding the
        welcome email to data centers, expand the length of the field \u201Cdomain\u201D
        etc.) to manage all my data centers so that I reduce admin costs and can track
        changes.</em></p>\n<p>All functionality relevant for DOI registration (including
        management of data centers and prefixes) is now available via API calls. DOI
        Fabrica provides a powerful administrator UI that, for example, allows members
        to automatically fetch new prefixes from the DataCite pool when all their
        prefixes are in use, instead of sending an email to DataCite support.</p>\n<h3
        id=\"link-checker-reports\"><a href=\"https://github.com/datacite/datacite/issues/11\">Link
        checker reports</a></h3>\n<p><em>As a national library, I want services that
        check DOI resolution (broken links), so I can keep my responsibilities of
        persistence.</em></p>\n<p>DOI Fabrica includes a simple link checker that
        is particularly useful during DOI registration. A more robust link checker
        is on our <a href=\"https://www.datacite.org/roadmap.html\">roadmap</a> for
        the coming months.</p>\n<h3 id=\"reporting-tool\"><a href=\"https://github.com/datacite/datacite/issues/52\">Reporting
        tool</a></h3>\n<p><em>As a member, I want a reporting tool, so that I can
        stay informed about my DOIs.</em></p>\n<figure class=\"kg-card kg-image-card\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/stats.png\" class=\"kg-image\"
        alt=\"\" loading=\"lazy\" width=\"749\" height=\"303\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/stats.png
        600w, https://blog.front-matter.io/content/images/2022/08/stats.png 749w\"
        sizes=\"(min-width: 720px) 720px\"></figure>\n<p>While future DOI Fabrica
        releases will provide much more detailed reporting, with this release members
        will see a dashboard that summarizes the numbers of data centers (clients)
        they work with, and the number of DOIs registered per year.</p>\n<h3 id=\"dois-per-discipline\"><a
        href=\"https://github.com/datacite/datacite/issues/68\">DOIs per discipline</a></h3>\n<p><em>As
        a national library, I want to see how many datasets exist per discipline,
        so that I can decide about resourcing.</em></p>\n<figure class=\"kg-card kg-image-card\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/re3data.png\" class=\"kg-image\"
        alt=\"\" loading=\"lazy\" width=\"1052\" height=\"609\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/re3data.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/08/re3data.png
        1000w, https://blog.front-matter.io/content/images/2022/08/re3data.png 1052w\"
        sizes=\"(min-width: 720px) 720px\"></figure>\n<p>We are still a long way from
        understanding how many DOIs for research data exist per discipline, but we
        took an important first step by enabling the linking of data centers to <a
        href=\"https://www.re3data.org/\">re3data</a>, allowing us to automatically
        pull in information about the disciplines covered in any particular repository.</p>\n<p>With
        so many changes in DOI Fabrica we couldn\u2019t include everything we wanted
        in the first release, and one functionality in particular has to wait for
        the next release in six weeks: DOI registration. We need to first address
        technical dependencies before this can be implemented, and rather than delaying
        the first release of DOI Fabrica, we decided to focus on functionality important
        for our members, and to add DOI registration via XML upload and web form in
        the next release. We look forward to your feedback and to suggestions on how
        we can improve <a href=\"https://doi.datacite.org/\">DOI Fabrica</a>.</p>\n<h2
        id=\"acknowledgments\">Acknowledgments</h2>\n<p>This blog post was <a href=\"https://doi.org/10.5438/g7q1-7t10\">originally
        published</a> on the DataCite Blog.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ A Content Negotiation Update ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/a-content-negotiation-update/\"
        />\n\t\t<id>https://doi.org/10.53731/r7adm61-97aq74v-ag5kv</id>\n        <published>2017-04-28T00:00:00.000+00:00</published>\n\t\t<updated>2023-09-07T08:23:26.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/cite-apa.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/cite-apa.png\"></p><p>While
        it is a best practice for DOIs (expressed as URL) to send the user to the
        landing page for that resource (Starr et al., <a href=\"https://blog.datacite.org/content-negotiation-update/#ref-https://doi.org/10.7717/peerj-cs.1\">2015</a>),
        sometimes we want something else: <strong>metadata</strong>, e.g. to generate
        a citation, or to go to the <strong>content</strong> itself. The easiest way
        to do that is to use DOI content negotiation.</p>\n<p>In this blog post we
        will give an introduction to DOI content negotiation, describe some of the
        issues we identified with our current implementation, and announce a major
        service update addressing these issues and launching in two weeks.</p>\n<p>DOI
        Content Negotiation uses the HTTP <strong>Accept</strong> header together
        with the DOI expressed as URL. This is best explained by an example, using
        a recent post from this blog:</p>\n<pre><code>curl -LH \"Accept: application/x-bibtex\"
        https://doi.org/10.5438/0000-0C2G</code></pre>\n<p>This command returns BibTeX
        metadata for this DOI:</p>\n<pre><code>@misc{https://doi.org/10.5438/0000-0C2G,\n
        \ doi = {10.5438/0000-0C2G},\n  url = {https://doi.org/10.5438/0000-0C2G},\n
        \ author = {Cruse, Patricia},\n  publisher = {DataCite},\n  title = {The OI
        Project gets underway planning an Open Organization Identifier Registry},\n
        \ year = {2017}\n}</code></pre>\n<p>Or maybe you want to go directly to the
        content, in this case the JATS XML for the blog post (Fenner, <a href=\"https://blog.datacite.org/content-negotiation-update/#ref-https://doi.org/10.5438/0000-00cc\">2017c</a>):</p>\n<pre><code>curl
        -LH \"Accept: application/xml\" https://doi.org/10.5438/0000-0C2G</code></pre>\n<p>Sometimes
        it is easier to use a normal link instead, e.g. in a web browser where sending
        HTTP headers is a bit involved.</p>\n<pre><code>curl -L https://data.datacite.org/application/x-bibtex/10.5438/0000-0C2G</code></pre>\n<p>For
        this to work you have to go directly to the DataCite content negotiation service
        at <strong>data.datacite.org</strong> instead of using the <strong>doi.org</strong>
        DOI proxy.</p>\n<p>The most popular use of DOI content negotiation is citation
        formatting in any of the 1000s of citation styles provided by the Citation
        Style Language (<a href=\"http://citationstyles.org/\">CSL</a>) project. For
        this we combine DOI content negotiation, which generates a JSON file from
        the metadata in a format that CSL understands (<a href=\"https://bitbucket.org/fbennett/citeproc-js/\">Citeproc
        JSON</a>), with our <a href=\"https://blog.datacite.org/citation-formatting-service-upgrade/\">DOI
        citation formatting service</a>, which generates the formatted citation:</p>\n<pre><code>curl
        -LH \"Accept: text/x-bibliography; style=apa\" https://doi.org/10.5438/0000-0C2G</code></pre>\n<p>This
        command returns a citation formatted in <a href=\"http://www.apastyle.org/\">APA
        style</a>:</p>\n<pre><code>Cruse, P. (2017). The OI Project gets underway
        planning an Open Organization Identifier Registry. DataCite. https://doi.org/10.5438/0000-0C2G</code></pre>\n<p>There
        is an easier way to get this information from DataCite if you don't feel comfortable
        using the command line. First find the DOI you want to cite in DataCite Search,
        e.g. <a href=\"https://search.datacite.org/works/10.5438/0000-0C2G\">https://search.datacite.org/works/10.5438/0000-0C2G</a>
        in this case.</p>\n<figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/search-result.webp\"
        class=\"kg-image\" alt=\"Add to ORCID\" loading=\"lazy\" width=\"1078\" height=\"294\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/search-result.webp
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/08/search-result.webp
        1000w, https://blog.front-matter.io/content/images/2022/08/search-result.webp
        1078w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span>Add to ORCID</span></figcaption></figure>\n<p>Then
        click on the <strong>Cite</strong> button and select one of several popular
        citation styles. We again pick the APA style:</p>\n<figure class=\"kg-card
        kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/cite-apa-1.png\"
        class=\"kg-image\" alt=\"APA style\" loading=\"lazy\" width=\"1019\" height=\"363\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/cite-apa-1.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/08/cite-apa-1.png
        1000w, https://blog.front-matter.io/content/images/2022/08/cite-apa-1.png
        1019w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span>APA style</span></figcaption></figure>\n<p>This
        is the same formatted citation we saw earlier, as DataCite Search is using
        the content negotiation and citation formatting services in the background.
        These services have been around for several years, and we work together with
        other DOI registration agencies on this. The citation service in DataCite
        Search for example is based on Crossref <a href=\"https://github.com/crosscite/doi-metadata-search\">open
        source code</a> originally written for <a href=\"https://search.crossref.org/\">Crossref
        Metadata Search</a>.</p>\n<h2 id=\"upcoming-changes\">Upcoming Changes</h2>\n<p>There
        is still room for improvement of the content negotiation service. As part
        of work in the EC-funded THOR project (Farquhar et al., <a href=\"https://blog.datacite.org/content-negotiation-update/#ref-https://doi.org/10.5438/6423\">2015</a>)
        we took a closer look at what you can and can't do with DOI content negotiation.
        We identified a number of gaps and will address them by launching an updated
        content negotiation service in May.</p>\n<h3 id=\"many-content-types-only-supported-with-required-metadata\">Many
        content types only supported with required metadata</h3>\n<p>The current DataCite
        content negotiation only supports the required metadata (identifier, creator,
        title, publisher, publicationYear, resourceTypeGeneral) for most content types.
        This means that even for something as straightforward as BibTeX, DataCite
        is not converting the supported optional metadata such as <code>description</code>,
        <code>subject/keywords</code>, <code>version</code> or <code>license</code>.
        And for rich metadata such as RDF, a long list of properties is not converted.</p>\n<h3
        id=\"limited-person-name-parsing\">Limited person name parsing</h3>\n<p>Person
        names are very difficult to parse, in particular when not using the optional
        properties <code>givenName</code> and <code>familyName</code> introduced in
        DataCite Schema 4.0 last year (DataCite Metadata Working Group, <a href=\"https://blog.datacite.org/content-negotiation-update/#ref-https://doi.org/10.5438/0012\">2016</a>).
        But proper parsing is important for citations, as different citation styles
        use different formatting rules for names. And BibTex expects a particular
        format that is hard to support without proper person name parsing.</p>\n<h3
        id=\"better-support-for-consistent-metadata-across-doi-registration-agencies\">Better
        support for consistent metadata across DOI registration agencies</h3>\n<p>Although
        content negotiation is supported by several DOI registration agencies, there
        is only limited support for common metadata beyond the basic citation metadata.
        This makes it harder than it should it to combine metadata records from different
        DOI registration agencies. The current RDF support is limited, and no DOI
        registration agency is offering content negotiation that converts metadata
        from another registration agency.</p>\n<h3 id=\"support-for-additional-content-types\">Support
        for additional content types</h3>\n<p>The list of supported content types
        could be much longer, from emerging metadata standards such as <a href=\"https://schema.org/\">schema.org</a>
        or <a href=\"http://www.scholix.org/\">scholix</a> to community-specific standards
        such as <a href=\"https://www.ddialliance.org/\">DDI</a> for social sciences,
        DATS for the life sciences (Sansone et al., <a href=\"https://blog.datacite.org/content-negotiation-update/#ref-https://doi.org/10.1101/103143\">2017</a>),
        or <a href=\"http://codemeta.github.io/\">codemeta</a> for software.</p>\n<h3
        id=\"unrecognized-content-types-raise-an-error\">Unrecognized content types
        raise an error</h3>\n<p>When the DataCite DOI content negotiation encounters
        an unrecognized content type, it returns a <strong>406 Not Acceptable</strong>
        error. This means that it is impossible to implement content negotiation downstream
        at the data center, as all content negotiation requests will be redirected
        to DataCite. Data centers can register their custom content types in the DataCite
        MDS using the <code>media</code> API endpoint, but this feature is unfortunately
        not widely used.</p>\n<p>DataCite has rewritten most of the code of the content
        negotiation service, and has extracted out the metadata conversion into a
        standalone library (Fenner, <a href=\"https://blog.datacite.org/content-negotiation-update/#ref-https://doi.org/10.5438/n138-z3mk\">2017a</a>)
        that can also be used locally via the command line. The new service is currently
        in final testing at <a href=\"https://data.test.datacite.org/\">https://data.test.datacite.org</a>,
        and we plan to launch this into production ion May 9th. We have worked on
        all the limitations listed above, and some of the highlights include:</p>\n<ul><li>extensive
        support for schema.org/JSON-LD as a common metadata standard independent of
        a particular DOI registration agency</li><li>extensive RDF support as XML
        or Turtle via schema.org metadata</li><li>tested with DOIs from DataCite and
        Crossref, supports conversion of Crossref metadata to DataCite metadata</li><li>BibTeX
        and RIS files have proper file extension (.bib and .ris) for easier import
        into other applications.</li><li>new content type <code>codemeta</code>, other
        content types will be added in the coming months based on user feedback</li><li>available
        as open source software via Github (Fenner, <a href=\"https://blog.datacite.org/content-negotiation-update/#ref-https://doi.org/10.5438/t1jg-hvhn\">2017b</a>)
        and <a href=\"https://hub.docker.com/r/crosscite/content-negotiation/\">Docker
        Hub</a>.</li></ul>\n<p>There is one breaking change that users should be aware
        of: the content type <code>text/html</code> will no longer be supported, as
        the DOI proxy always forwards requests with this content type to the URL registered
        in the handle system. Users who want to see a HTML representation of the DOI
        metadata should go to DataCite Search, i.e. <a href=\"https://search.datacite.org/works/10.5438/0000-0C2G\">https://search.datacite.org/works/10.5438/0000-0C2G</a>
        instead of https://data.datacite.org/10.5438/0000-0C2G. We will be improving
        the information shown for a single DOI in DataCite Search in the coming months,
        and appreciate user feedback.</p>\n<h2 id=\"acknowledgments\">Acknowledgments</h2>\n<p>This
        blog post was <a href=\"https://doi.org/10.5438/0000-01qj\">originally published</a>
        on the DataCite Blog.</p>\n<h2 id=\"references\">References</h2>\n<p>DataCite
        Metadata Working Group. DataCite Metadata Schema Documentation for the Publication
        and Citation of Research Data v4.0. Published online 2016:45 pages. doi:<a
        href=\"https://doi.org/10.5438/0012\">10.5438/0012</a></p>\n<p>Farquhar A,
        Aryani A, Brown J, et al. Technical and Human Infrastructure for Open Research
        (THOR). Published online 2015. doi:<a href=\"https://doi.org/10.5438/6423\">10.5438/6423</a></p>\n<p>Fenner
        M. Bolognese: a Ruby library for conversion of DOI Metadata. Published online
        February 25, 2017. doi:<a href=\"https://doi.org/10.5438/N138-Z3MK\">10.5438/N138-Z3MK</a></p>\n<p>Fenner
        M. Content-Negotation: an API for DOI content negotiation. Published online
        April 28, 2017. doi:<a href=\"https://doi.org/10.5438/T1JG-HVHN\">10.5438/T1JG-HVHN</a></p>\n<p>Fenner
        M. Using Schema.org for DOI Registration. Published online January 9, 2017.
        doi:<a href=\"https://doi.org/10.5438/0000-00CC\">10.5438/0000-00CC</a></p>\n<p>Sansone
        SA, Gonzalez-Beltran A, Rocca-Serra P, et al. <em>DATS: The Data Tag Suite
        to Enable Discoverability of Datasets</em>. Bioinformatics; 2017. doi:<a href=\"https://doi.org/10.1101/103143\">10.1101/103143</a></p>\n<p>Starr
        J, Castro E, Crosas M, et al. Achieving human and machine accessibility of
        cited data in scholarly publications. <em>PeerJ Computer Science</em>. 2015;1:e1.
        doi:<a href=\"https://doi.org/10.7717/peerj-cs.1\">10.7717/peerj-cs.1</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Using Schema.org for DOI Registration ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/using-schema-org-for-doi-registration/\"
        />\n\t\t<id>https://doi.org/10.53731/r79zrr1-97aq74v-ag5k1</id>\n        <published>2017-01-09T00:00:00.000+00:00</published>\n\t\t<updated>2023-07-05T19:22:17.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/schema-org.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/schema-org.png\"></p><p>Three
        weeks ago we started assigning DOIs to every post on this blog (Fenner, <a
        href=\"https://blog.datacite.org/schema-org-register-dois/#ref-https://doi.org/10.5438/4K3M-NYVG\">2016c</a>).
        The process we implemented uses a new <a href=\"https://github.com/datacite/cirneco\">command
        line utility</a> and integrates well with our the publishing workflow, with
        (almost) no extra effort compared to how we published blog posts before.</p><p>Given
        that DataCite is a DOI registration agency, we obviously are careful about
        following best practices for assigning DOIs. DataCite focusses on DOIs for
        research data, but many of the general principles can also apply to blog posts.
        And we have learned a few things already.</p><h3 id=\"using-schemaorg-metadata-embedded-in-landing-pages\">Using
        schema.org metadata embedded in landing pages</h3><p>Our initial implementation
        collected the metadata required for DOI registration in a way that is specific
        to a particular type of blogging software, so-called <a href=\"https://davidwalsh.name/introduction-static-site-generators\">static
        site generators</a>. While popular, this leaves out a large number of blogs,
        for example every blog hosted by Wordpress, by far the most popular blogging
        platform. We have now relaunched our blog to collect metadata differently,
        generic enough to work for any blog, but also well aligned with best practices
        for DOIs.</p><p>Our practice is that every DOI should resolve to a landing
        page, and that landing page should provide both human- and machine-readable
        metadata. Machine-readable metadata can be embedded into web pages in a number
        of ways. Traditionally this was done using HTML meta tags, more recent approaches
        to embedding metadata in HTML include <a href=\"https://html.spec.whatwg.org/multipage/microdata.html\">microdata</a>,
        <a href=\"http://microformats.org/\">microformats</a> and <a href=\"https://www.w3.org/TR/2015/NOTE-rdfa-primer-20150317/\">RDFa</a>.
        An alternative approach is to embed the metadata using JSON and a <code>&lt;script&gt;</code>
        tag. The latter approach is easier to implement, as all metadata are in a
        single place, and the JSON can be embedded dynamically via a script.</p><p>As
        for the vocabulary, the DataCite Metadata Schema has never been widely used
        for metadata embedded in web pages. Dublin Core Metadata (\u201CDublin Core
        Metadata Element Set, Version 1.1,\u201D <a href=\"https://blog.datacite.org/schema-org-register-dois/#ref-http://dublincore.org/documents/2012/06/14/dces\">2012</a>)
        are often used for metadata in HTML <code>meta</code> tags. <a href=\"https://schema.org/\">Schema.org</a>
        is an initiative started in 2011 with many of the same goals as Dublin Core,
        namely to <em>create, maintain, and promote schemas for structured data on
        the Internet</em>.</p><p>Schema.org is widely adopted, not the least because
        the initiative was started by Google, Microsoft, Yahoo, and Yandex to help
        with indexing web pages for search. Schema.org metadata can be embedded using
        microdata, RDFa or JSON-LD.</p><p>DataCite has recently added support for
        schema.org in JSON-LD format to <a href=\"http://citation.crosscite.org/docs.html\">DOI
        content negotiation</a>, for example <code>curl -LH \"Accept: application/vnd.schemaorg.ld+json\"
        https://doi.org/10.5438/4K3M-NYVG</code>. Schema.org in JSON-LD is also embedded
        in search results on <a href=\"https://search.datacite.org/\">DataCite Search</a>
        using the tag <code>&lt;script type=\"application/vnd.schemaorg.ld+json\"&gt;</code>.</p><p>The
        DataCite blog now uses schema.org in JSON-LD format to embed metadata in machine-readable
        format, for example for the blog post mentioned earlier:</p><pre><code>{\n
        \   \"@context\": \"http://schema.org\",\n    \"@type\": \"BlogPosting\",\n
        \   \"@id\": \"https://doi.org/10.5438/4K3M-NYVG\",\n    \"name\": \"Eating
        your own Dog Food\",\n    \"alternateName\": \"MS-49-3632-5083\",\n    \"url\":
        \"https://blog.datacite.org/eating-your-own-dog-food/\",\n    \"author\":
        [\n        {\n            \"@type\": \"Person\",\n            \"@id\": \"http://orcid.org/0000-0003-1419-2405\",\n
        \           \"givenName\": \"Martin\",\n            \"familyName\": \"Fenner\",\n
        \           \"name\": \"Martin Fenner\"\n        }\n    ],\n    \"publisher\":
        {\n        \"@type\": \"Organization\",\n        \"name\": \"DataCite\"\n
        \   },\n    \"dateCreated\": \"2016-12-20\",\n    \"datePublished\": \"2016-12-20\",\n
        \   \"dateModified\": \"2016-12-20\",\n    \"keywords\": \"datacite, doi,
        metadata, featured\",\n    \"version\": \"1.0\",\n    \"description\": \"Eating
        your own dog food is a slang term to describe that an organization should
        itself use the products and services it provides. For DataCite this means
        that we should use DOIs with appropriate metadata and strategies for long-term
        preservation for...\",\n    \"license\": \"https://creativecommons.org/licenses/by/4.0/\",\n
        \   \"image\": \"https://blog.datacite.org/images/2016/12/230785.jpg\",\n
        \   \"encoding\": {\n        \"@type\": \"MediaObject\",\n        \"@id\":
        \"https://blog.datacite.org/eating-your-own-dog-food/4K3M-NYVG.xml\",\n        \"fileFormat\":
        \"application/xml\"\n    },\n    \"isPartOf\": {\n        \"@type\": \"Blog\",\n
        \       \"@id\": \"https://doi.org/10.5438/0000-00SS\",\n        \"name\":
        \"DataCite Blog\"\n    },\n    \"citation\": [\n        {\n            \"@type\":
        \"CreativeWork\",\n            \"@id\": \"https://doi.org/10.5438/0012\"\n
        \       },\n        {\n            \"@type\": \"CreativeWork\",\n            \"@id\":
        \"https://doi.org/10.5438/55E5-T5C0\"\n        }\n    ]\n}</code></pre><p>If
        you are familiar with the DataCite Metadata Schema, it is easy to see how
        schema.org metadata can be converted into DataCite metadata and used with
        the DataCite Metadata Store, DataCite\u2019s DOI registration and management
        service. The properties required by DataCite metadata (DOI, author, title,
        publisher, publicationYear, resourceTypeGeneral) are standard metadata for
        blog posts with the exception of the DOI. You can see that the JSON-LD <code>@id</code>
        is the DOI expressed as HTTPS URL (and that the <code>@id</code>for authors
        is their ORCID ID). And there are some naming differences e.g. <code>name</code>
        vs. <code>title</code>. The DataCite metadata corresponding to the above schema.org
        metadata look like this (and <a href=\"http://data.crosscite.org/application/vnd.datacite.datacite+xml/10.5438/4K3M-NYVG\">can
        be downloaded</a> via DOI content negotiation):</p><pre><code>&lt;resource
        xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n  xmlns=\"http://datacite.org/schema/kernel-4\"\n
        \ xsi:schemaLocation=\"http://datacite.org/schema/kernel-4 http://schema.datacite.org/meta/kernel-4/metadata.xsd\"&gt;\n
        \ &lt;identifier identifierType=\"DOI\"&gt;10.5438/4K3M-NYVG&lt;/identifier&gt;\n
        \ &lt;creators&gt;\n    &lt;creator&gt;\n      &lt;creatorName&gt;Fenner,
        Martin&lt;/creatorName&gt;\n      &lt;givenName&gt;Martin&lt;/givenName&gt;\n
        \     &lt;familyName&gt;Fenner&lt;/familyName&gt;\n      &lt;nameIdentifier
        schemeURI=\"http://orcid.org/\" nameIdentifierScheme=\"ORCID\"&gt;0000-0003-1419-2405&lt;/nameIdentifier&gt;\n
        \   &lt;/creator&gt;\n  &lt;/creators&gt;\n  &lt;titles&gt;\n    &lt;title&gt;Eating
        your own Dog Food&lt;/title&gt;\n  &lt;/titles&gt;\n  &lt;publisher&gt;DataCite&lt;/publisher&gt;\n
        \ &lt;publicationYear&gt;2016&lt;/publicationYear&gt;\n  &lt;resourceType
        resourceTypeGeneral=\"Text\"&gt;BlogPosting&lt;/resourceType&gt;\n  &lt;alternateIdentifiers&gt;\n
        \   &lt;alternateIdentifier alternateIdentifierType=\"Local accession number\"&gt;MS-49-3632-5083&lt;/alternateIdentifier&gt;\n
        \ &lt;/alternateIdentifiers&gt;\n  &lt;subjects&gt;\n    &lt;subject&gt;datacite&lt;/subject&gt;\n
        \   &lt;subject&gt;doi&lt;/subject&gt;\n    &lt;subject&gt;metadata&lt;/subject&gt;\n
        \   &lt;/subjects&gt;\n  &lt;dates&gt;\n    &lt;date dateType=\"Created\"&gt;2016-12-20&lt;/date&gt;\n
        \   &lt;date dateType=\"Issued\"&gt;2016-12-20&lt;/date&gt;\n    &lt;date
        dateType=\"Updated\"&gt;2016-12-20&lt;/date&gt;\n  &lt;/dates&gt;\n  &lt;relatedIdentifiers&gt;\n
        \   &lt;relatedIdentifier relatedIdentifierType=\"DOI\" relationType=\"References\"&gt;10.5438/0012&lt;/relatedIdentifier&gt;\n
        \   &lt;relatedIdentifier relatedIdentifierType=\"DOI\" relationType=\"References\"&gt;10.5438/55E5-T5C0&lt;/relatedIdentifier&gt;\n
        \   &lt;relatedIdentifier relatedIdentifierType=\"DOI\" relationType=\"IsPartOf\"&gt;10.5438/0000-00SS&lt;/relatedIdentifier&gt;\n
        \ &lt;/relatedIdentifiers&gt;\n  &lt;version&gt;1.0&lt;/version&gt;\n  &lt;descriptions&gt;\n
        \   &lt;description descriptionType=\"Abstract\"&gt;\n      Eating your own
        dog food is a slang term to describe that an organization should itself use
        the products and services it provides. For DataCite this means that we should
        use DOIs with appropriate metadata and strategies for long-term preservation
        for...\n    &lt;/description&gt;\n  &lt;/descriptions&gt;\n&lt;/resource&gt;</code></pre><p>Schema.org
        metadata in JSON-LD format can be added to Wordpress blogs using a <a href=\"https://wordpress.org/plugins/wp-structuring-markup/\">plugin</a>,
        and more generally can be added to any webpage using tools such as <a href=\"https://moz.com/blog/using-google-tag-manager-to-dynamically-generate-schema-org-json-ld-tags\">Google
        Tag Manager</a>.</p><h3 id=\"doi-minting-workflow\">DOI minting workflow</h3><p>Publishing
        a blog post with embedded schema.org metadata, which is then used to mint
        a DOI and register DOI metadata, changes the DOI minting workflow for this
        blog. Although the publication workflow of a blog is much simpler than for
        peer-reviewed content, there are still three distinct phases:</p><ul><li>post
        is drafted by author</li><li>post is shared for feedback with staff (and possibly
        others)</li><li>post is published</li></ul><p>A DOI for a DataCite blog post
        is minted in phase 2, i.e. as soon as it is clear that the post will be published.
        What we are not doing at this phase is making the metadata public \u2013 we
        set the <code>is_active</code> flag in the DataCite MDS to false. This prevents
        indexing in DataCite Search, and the post can only be found if you know the
        DOI. For sensitive content we could redirect the DOI to a generic landing
        page, but that would be overkill for the typical blog post. Once the post
        is published, we set the <code>is_active</code> flag to true, enabling indexing,
        and show the post on the DataCite blog homepage.</p><p>With this workflow
        we have the DOI before publication, which is helpful as a link to collect
        limited feedback, or for joint blog posts with other organizations, such as
        our organization identifier blog post in November (Fenner, <a href=\"https://blog.datacite.org/schema-org-register-dois/#ref-https://doi.org/10.5438/TNHX-54CG\">2016a</a>).</p><p>On
        the other hand, we should not register the DOI too early, e.g. for draft posts
        that are never published. What we should also avoid is using something that
        looks like a DOI, but is not registered with the Handle system. Geoff Bilder
        has described the problems with such DOI-like strings as internal identifiers
        in a June 2016 <a href=\"http://blog.crossref.org/2016/06/doi-like-strings-and-fake-dois.html\">post</a>
        on the Crossref blog.</p><p>The DataCite blog uses \"cool\" DOIs that are
        generated from random numbers using the base32 algorithm (Fenner, <a href=\"https://blog.datacite.org/schema-org-register-dois/#ref-https://doi.org/10.5438/55E5-T5C0\">2016b</a>).
        We have modified this process a little bit: we create an internal identifier
        (we call them accession number) that contains a random number unique to the
        DataCite blog for every draft post \u2013 this post has accession number <code>MS-12</code>.
        When we mint the DOI this accession number - ignoring letters and hyphens
        - is turned into a DOI, and the DOI can be predicted because of the base32
        algorithm. This workflow avoids using DOI-like strings as internal identifiers,
        and eliminates the small risk of using the same random number twice when minting
        a DOI.</p><h3 id=\"blog-posts-in-jats-xml\">Blog posts in JATS XML</h3><p>Blog
        posts are web pages and the landing page for the DOI also contains the fulltext
        of the post. But there are good reasons to make a blog post also available
        in downloadable form, most importantly to facilitate reuse, and for archiving.
        Journal Article Tag Suite (<a href=\"https://jats.nlm.nih.gov/\">JATS</a>)
        is an XML standard for tagging journal articles, used by the <a href=\"https://www.ncbi.nlm.nih.gov/pmc/\">PubMed
        Central</a> full-text archive of biomedical literature and by an increasing
        number of scholarly publishers.</p><p>JATS is an appropriate format for the
        blog posts of this blog, and starting this week all of our posts are also
        available in JATS XML format. You can see the download URL in the schema.org
        markup, we will add a more visible link to all posts once some minor tagging
        issues are resolved. We will also start registering the download URL with
        the DataCite MDS as <code>media</code>, making the JATS XML available to <a
        href=\"http://citation.crosscite.org/docs.html\">DOI content negotiation</a>,
        and thus direct download. This should facilitate reuse by others, e.g. aggregation
        of content from multiple sources and display of content in different formats.
        This blog uses the <a href=\"https://creativecommons.org/licenses/by/4.0/\">Creative
        Commons Attribution</a> license, allowing the copying, redistribution and
        remixing of the material in any medium or format for any purpose.</p><h3 id=\"the-blog-as-container\">The
        blog as container</h3><p>Also this week we assigned a DOI to the DataCite
        blog itself (Cruse, Rueda, Garza, &amp; Fenner, <a href=\"https://blog.datacite.org/schema-org-register-dois/#ref-https://doi.org/10.5438/0000-00SS\">2015</a>).
        The blog is added as a <code>isPartOf</code> relation to the schema.org and
        DataCite metadata of each blog post. This should facilitate discovery of related
        content via metadata, and allows users to also refer to the blog itself instead
        of individual posts. The blog is registered as a <code>resourceTypeGeneral</code>
        of Collection.</p><p>The alternative would have been to describe the DataCite
        blog as the <code>publisher</code> of our blog posts. We are using <strong><strong>DataCite</strong></strong>
        as <code>publisher</code> instead, as we feel the publisher should be a person
        or organization.</p><p><em>This blog post was <a href=\"https://doi.org/10.5438/0000-00cc\">originally
        published</a> on the DataCite Blog.</em></p><h2 id=\"references\">References</h2><p>Cruse,
        P., Rueda, L., Garza, K., &amp; Fenner, M. (2015). DataCite blog. DataCite.
        <a href=\"https://doi.org/10.5438/0000-00SS\">https://doi.org/10.5438/0000-00SS</a></p><p>Dublin
        Core Metadata Element Set, Version 1.1. (2012). Retrieved from <a href=\"http://dublincore.org/documents/2012/06/14/dces/\">http://dublincore.org/documents/2012/06/14/dces/</a></p><p>Fenner
        M. Announcing the Organization Identifier Project: a Way Forward. Published
        online November 1, 2016. doi:<a href=\"https://doi.org/10.53731/r79xvx1-97aq74v-ag5d5\">10.53731/r79xvx1-97aq74v-ag5d5</a></p><p>Fenner
        M. Cool DOIs. Published online December 15, 2016. doi:<a href=\"https://doi.org/10.53731/r79x921-97aq74v-ag5a2\">10.53731/r79x921-97aq74v-ag5a2</a></p><p>Fenner
        M. Eating your own Dog Food. Published online December 20, 2016. doi:<a href=\"https://doi.org/10.53731/r79vxn1-97aq74v-ag58n\">10.53731/r79vxn1-97aq74v-ag58n</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Mysteries in Reference Lists ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/mysteries-in-reference-lists/\"
        />\n\t\t<id>https://doi.org/10.53731/r79z0kh-97aq74v-ag5hb</id>\n        <published>2016-12-23T00:00:00.000+00:00</published>\n\t\t<updated>2023-07-02T07:33:31.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/journal.pone.0105948.g004.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/journal.pone.0105948.g004.png\"></p><p>On
        Tuesday the journal PLOS ONE celebrated its 10th anniversary (see <a href=\"http://blogs.plos.org/plos/2016/12/ten-years-of-advancing-science-as-one/\">blog
        post</a> by PLOS ONE Editor-in-Chief J\xF6rg Heber and <a href=\"http://blogs.plos.org/everyone/2016/12/20/the-ride-of-your-life-one-to-the-power-of-10/\">blog
        post</a> by PLOS ONE Managing Editor Iratxe Puebla and PLOS Advocacy Director
        Catriona MacCallum). PLOS ONE (and PLOS) have changed scholarly publishing
        in many ways, from a DataCite perspective probably most importantly via the
        data policy <a href=\"http://blogs.plos.org/everyone/2014/02/24/plos-new-data-policy-public-access-data-2/\">updated
        in February 2014</a> that states that</p><blockquote>PLOS journals require
        authors to make all data underlying the findings described in their manuscript
        fully available without restriction, with rare exception.</blockquote><p>PLOS
        ONE was not the first journal with a Joint Data Archiving Policy (Whitlock,
        <a href=\"https://blog.datacite.org/mysteries-in-reference-lists/#ref-https://doi.org/10.1016/j.tree.2010.11.006\">2011</a>),
        but this policy update moved proper archiving in public repositories of data
        used in papers into the mainstream, given that PLOS ONE had become the largest
        journal in the world by number of papers published.</p><h2 id=\"volumes-issues-and-pages\">Volumes,
        issues and pages</h2><p>Publishing so many papers, and doing this only in
        electronic form, means that PLOS ONE doesn't really have journal issues, and
        that papers are published daily as they become ready \u2013 a common pattern
        with online-only journals. This means that the traditional way of referencing
        a scholarly article via journal name, volume, issue and page numbers isn't
        really useful anymore, as a proxy PLOS ONE uses the publication year as volume,
        month as issue and an <a href=\"https://jats.nlm.nih.gov/publishing/tag-library/1.1/element/elocation-id.html\">electronic
        location identifier</a> instead of page numbers, for example <em>PLOS ONE</em>,
        9(8), e105948. But of course we don't use this information to uniquely identify
        and locate a PLOS ONE article, we use the DOI instead \u2013 <a href=\"https://doi.org/10.1371/journal.pone.0105948\">https://doi.org/10.1371/journal.pone.0105948</a>
        for this example.</p><p>This particular DOI is for an interesting article
        by Norris et al. (<a href=\"https://blog.datacite.org/mysteries-in-reference-lists/#ref-https://doi.org/10.1371/journal.pone.0105948\">2014</a>)
        that describes how rocks in Death Valley slide with the help of thin layers
        of ice and wind, a phenomenon known since the 1940s, but in this paper for
        the first time systematically analyzed using GPS.</p><p>Before joining DataCite
        in 2015 I worked for PLOS for three years, helping with they Article-Level
        Metrics initiative (Fenner, <a href=\"https://blog.datacite.org/mysteries-in-reference-lists/#ref-https://doi.org/10.1371/journal.pbio.1001687\">2013</a>).
        The sliding rocks paper has been a fascinating ALM example, as the paper <a
        href=\"http://journals.plos.org/plosone/article/metrics?id=10.1371/journal.pone.0105948\">drew
        a lot of attention</a> beyond traditional citations.</p><p>But the sliding
        rocks paper has of course also been cited, and I counted 12 citations this
        week. These citations are listed below, together with what is shown in the
        reference list:</p><ol><li><strong><strong>Journal of Geophysical Research
        Planets</strong></strong> (El-Maarry et al., <a href=\"https://blog.datacite.org/mysteries-in-reference-lists/#ref-https://doi.org/10.1002/2015JE004895\">2015</a>).
        Norris, R., J. Norris, R. Lorenz, J. Ray and B. Jackson, (2014), Sliding rocks
        on Racetrack Playa, Death Valley National Park: First observation of rocks
        in motion, PLoS One, 9(8), e105948, doi:10.1371/journal.pone.0105948.</li><li><strong><strong>Biophysical
        Journal</strong></strong> (Rambo &amp; Tainer, <a href=\"https://blog.datacite.org/mysteries-in-reference-lists/#ref-https://doi.org/10.1016/j.bpj.2015.04.023\">2015</a>).
        Norris, R. D., J. M. Norris, ., B. Jackson. 2014. Sliding rocks on Racetrack
        Playa, Death Valley National Park: first observation of rocks in motion. PLoS
        ONE. 9:e105948.</li><li><strong><strong>Earth Surface Dynamics Discussions</strong></strong>
        (R. D. Lorenz et al., <a href=\"https://blog.datacite.org/mysteries-in-reference-lists/#ref-https://doi.org/10.5194/esurfd-2-1005-2014\">2014</a>).
        Norris, R., Norris, J., Lorenz, R., Ray, J., and Jackson, B.: First observation
        of rock motion on Racetrack Playa, Death Valley, PLoS ONE, 9, e105948, doi:10.1371/journal.pone.0105948,
        2014. <em>Title is different from original publication.</em></li><li><strong><strong>Western
        North American Naturalist</strong></strong> (Baumgardner &amp; Shaffer, <a
        href=\"https://blog.datacite.org/mysteries-in-reference-lists/#ref-https://doi.org/10.3398/064.075.0213\">2015</a>).
        Norris, R.D., J.M. Norris, R.D. Lorenz, J. Ray, and B. Jackson. 2014. Sliding
        rocks on Racetrack Playa, Death Valley National Park: first observation of
        rocks in motion. PLOS ONE 9:1\u201311. dx.doi.org/10.1371/journal.pone.0105948.
        <em>PLOS ONE uses electronic location identifier instead of page numbers.</em></li><li><strong><strong>Aeolian
        Research</strong></strong> (Jones &amp; Hooke, <a href=\"https://blog.datacite.org/mysteries-in-reference-lists/#ref-https://doi.org/10.1016/j.aeolia.2015.08.001\">2015</a>).
        Norris, R.D., Norris, J.M., Lorenz, R.D., Ray, J., Jackson, B., 2014. Sliding
        rocks on Racetrack Playa, Death Valley National Park: first observation of
        rocks in motion. Plos One 9 (8), &lt;www.plosone.org&gt;. <em>Link goes to
        PLOS ONE homepage.</em></li><li><strong><strong>Aeolian Research</strong></strong>
        (Sanz-Montero, Cabestrero, &amp; Rodr\xEDguez-Aranda, <a href=\"https://blog.datacite.org/mysteries-in-reference-lists/#ref-https://doi.org/10.1016/j.aeolia.2016.01.003\">2016</a>).
        Norris, R.D., Norris, J.M., Lorenz, R.D., Ray, J., Jackson, B., 2014. Sliding
        rocks on Racetrack playa, death valley national park: first observation of
        rocks in motion. PLoS ONE 9 (8).</li><li><strong><strong>Earth Surfaces Processes
        and Landforms</strong></strong> (Sanz-Montero, Cabestrero, &amp; Rodr\xEDguez-Aranda,
        <a href=\"https://blog.datacite.org/mysteries-in-reference-lists/#ref-https://doi.org/10.1002/esp.3677\">2015</a>).
        Norris JM, Lorenz RD, Ray J, Jackson B. 2014. Sliding rocks on Racetrack Playa,
        Death Valley National Park: first observation of rocks in motion. PLoS One
        9: e1059448. <em>Name of first author missing, extra 4 in electronic location
        identifier</em>.</li><li><strong><strong>Journal of Geology &amp; Geophysics</strong></strong>
        Norris RD, Norris JM, Lorenz RD, Ray J, Jackson B (2014) Sliding Rocks on
        Racetrack Playa, Death Valley National Park: First Observation of Rocks in
        Motion. PLoS ONE 9 (8), doi: 10.1371/journal.pone.0105948.</li><li><strong><strong>Journal
        of Archaeological Science</strong></strong> (Grayson &amp; Meltzer, <a href=\"https://blog.datacite.org/mysteries-in-reference-lists/#ref-https://doi.org/10.1016/j.jas.2015.02.009\">2015</a>).
        Norris, R.D., Norris, J.M., Lorenz, R.D., Ray, J., Jackson, B., 2014. Sliding
        rocks on Racetrack Playa, Death Valley National Park: first observation of
        rocks in motion. PLoS One 9 (8), e105948.</li><li><strong><strong>Transactions
        of Tianjin University</strong></strong> (Li, Zhou, &amp; Wang, <a href=\"https://blog.datacite.org/mysteries-in-reference-lists/#ref-https://doi.org/10.1007/s12209-016-2596-z\">2016</a>).
        Norris R D, Norris J M, Lorenz R D et al. Sliding rocks on Racetrack Playa,
        Death Valley National Park: First observation of rocks in motion[J]. PLoS
        One, 2014, 9(8): e105948.</li><li><strong><strong>Creative Approaches to Research</strong></strong>
        (Hannigan, Raphael, White, Bragg, &amp; Cripps Clark, <a href=\"https://blog.datacite.org/mysteries-in-reference-lists/#ref-http://hdl.handle.net/10536/DRO/DU:30088291\">2016</a>).
        Norris, R. D., Norris, J. M., Lorenz, R. D., Ray, J., &amp; Jackson, B. (2014).
        Sliding Rocks on Racetrack Playa, Death Valley National Park: First Observation
        of Rocks in Motion. PLoS One, 9(8), e105948.</li><li><strong><strong>ArXiv</strong></strong>
        (Asorey, Nunez, &amp; Sarmiento-Cano, <a href=\"https://blog.datacite.org/mysteries-in-reference-lists/#ref-https://arxiv.org/abs/1501.04916\">2015</a>).
        Richard D Norris, James M Norris, Ralph D Lorenz, Jib Ray, and Brian Jackson.
        Sliding rocks on racetrack playa, death valley national park: First observation
        of rocks in motion. PloS one, 9(8):e105948, 2014.</li></ol><p>You can see
        something interesting in these references: only 4 in 12 include the DOI, only
        one reference includes a URL, but all 12 include the volume and 8 each include
        the issue and the electronic location identifier. In other words, the references
        are formatted for a journal article that can be found as physical copy in
        a library, sorted and shelved by publication name, volume and issue. Only
        one in three references use a DOI and/or URL, even though that is the only
        way to fetch the online-only article.</p><p>Journal name, volume, issue and
        electronic location identifier also don't work too well in uniquely identifying
        the journal article, as this information is human-readable, but difficult
        for a machine to extract from the reference list. Many publishers of course
        link to referenced articles using the DOI behind the scenes even when not
        displaying the DOI, but that is a brittle implementation. Reference lists
        are for example also used by authors in manuscript submissions, and without
        DOIs displayed in the reference list it becomes much harder for the author
        to provide machine-readable information about the references used.</p><h2
        id=\"citation-styles\">Citation styles</h2><p>Reference lists remain one of
        the mysteries in scholarly publishing. Not only does this small example demonstrate
        that they still have not been fully adapted to how journal articles are published,
        read and cited in 2016, but you can also see that the examples use multiple
        citation styles. There are <a href=\"https://github.com/citation-style-language/styles\">thousands
        of them</a>, displaying the same information in so many different ways that
        generating and consuming references has become a business in itself. Another
        mystery is the limitation of the number of references in an online-only journal.
        While it makes sense to set some limit, these numbers sometimes seem arbitrarily
        low, coming from a time when every extra page printed was costly.</p><p>It
        seems unrealistic in the near future to ever agree on a common citation style.
        But what we can do is at least use a citation style that is widely used instead
        of reinventing one for every journal, and use a style that includes the DOI
        in the reference. PLOS switched from a PLOS-specific style to the Vancouver
        or NLM style (Patrias, <a href=\"https://blog.datacite.org/mysteries-in-reference-lists/#ref-https://www.ncbi.nlm.nih.gov/books/NBK7256\">2015</a>)
        in 2015. This style is widely used by biomedical journals, and PLOS ONE articles
        now include DOIs in reference lists, as you can see for example in this 2015
        PLOS ONE paper (Tenopir et al., <a href=\"https://blog.datacite.org/mysteries-in-reference-lists/#ref-https://doi.org/10.1371/journal.pone.0134826\">2015</a>)
        \u2013 the sliding rocks paper was published in 2014.</p><p>Vancouver/NLM
        allows the inclusion of DOIs in references, but isn't really urging users
        to do so, and it still recommends a traditional style of referencing:</p><figure
        class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/ch1e1.webp\"
        class=\"kg-image\" alt=\"The general format for a reference to a journal article,
        taken from (Patrias, 2015)\" loading=\"lazy\" width=\"535\" height=\"173\"><figcaption>The
        general format for a reference to a journal article, taken from (Patrias,
        <a href=\"https://blog.datacite.org/mysteries-in-reference-lists/#ref-https://www.ncbi.nlm.nih.gov/books/NBK7256\">2015</a>)</figcaption></figure><p>This
        blog uses the <a href=\"http://www.apastyle.org/\">APA style</a>, a style
        that is not only widely used and documented, but also includes DOIs in references
        (as you can see in the reference list of this blog post), and is one of the
        few citation styles with <a href=\"http://blog.apastyle.org/apastyle/2013/12/how-to-cite-a-data-set-in-apa-style.html\">specific
        support for data citations</a> (adding <em>[Data set]</em> after the title).
        And in contrast to the Vancouver style this style uses the <a href=\"http://www.chicagomanualofstyle.org/tools_citationguide.html\">Author-Date</a>
        format for in-text citations, providing more context to the reader of the
        article.</p><p>Using journal name, volume, issue and page numbers in a reference
        poses a particular challenge for DataCite, as the DataCite metadata schema
        doesn't support them. The main reason for this is DataCite's focus on providing
        metadata for datasets. Also, the DataCite metadata schema is based on <a href=\"http://dublincore.org/documents/dc-citation-guidelines/\">Dublin
        Core</a>, which also doesn't have these properties (<a href=\"http://dublincore.org/documents/dcmi-terms/#bibliographicCitation\">bibliographicCitation</a>
        can be used instead). More than 1.5 million text documents have been registered
        with a DataCite DOI, and many of them probably would have had journal name,
        volume, issue and pages information available. Should we add support for these
        properties to the DataCite metadata schema, or should we see these properties
        as no longer essential for citation information in a reference and leave them
        out of the metadata schema? I would argue that resources that have a digital
        object identifier don't require volume, issue and pages information to uniquely
        identify and/or locate the resource.</p><p>The other challenge for DataCite
        is that the current state of reference lists in journal articles makes it
        harder than needed to include data citations in them. When DOIs are not included
        in reference lists since the citation style doesn't want them displayed, then
        manuscripts with data citations submitted by authors need special treatment,
        which limits adoption because of the extra effort required. Publishers routinely
        rebuild reference lists from scratch by fetching the DOI and associated metadata
        based on the citation information provided, and these tools are built around
        citation metadata typically found in journal articles (including volume, issue
        and page information) and Crossref DOIs.</p><p>The conclusions from the above
        are simple:</p><blockquote>As a publisher, require a citation style that includes
        the DOI.</blockquote><h2 id=\"mystery-solved\">Mystery solved?</h2><p>The
        X-Files is an American TV series about FBI special agents Fox Mulder and Dana
        Scully who investigate unsolved cases involving paranormal phenomena. And
        in an episode aired in February 2016 (<a href=\"https://doi.org/10.5240/68D6-DD1B-C9D5-AE84-9A9E-2\">The
        X-Files: Mulder &amp; Scully Meet the Were-Monster</a>, via <a href=\"http://www.imdb.com/title/tt4549942/quotes\">IMDB</a>),
        Fox Mulder refers to the PLOS ONE Sliding Rocks paper when he says:</p><blockquote>Scully,
        since we've been away, much of the \"unexplained\" has been explained. The
        \"Death Valley Racetrack\"? Turns out it was just ice formations, moving the
        rocks around as it melted. Yeah, ice.</blockquote><p>To refer to this episode
        you can again use <a href=\"https://doi.org/10.5240/68D6-DD1B-C9D5-AE84-9A9E-2\">a
        DOI</a>, which in this case is not for scholarly content but is an <a href=\"http://eidr.org/\">EIDR</a>
        \u2013 A universal unique identifier for movie and television assets. And
        now we have come full circle.</p><p><em>This blog post was <a href=\"https://doi.org/10.5438/ct8b-x1ce\">originally
        published</a> on the DataCite Blog.</em></p><h2 id=\"references\">References</h2><p>Asorey
        H, Nunez LA, Sarmiento-Cano C. Exposicion Temprana de Nativos Digitales en
        Ambientes, Metodologias y Tecnicas de Investigacion en la Universidad. Published
        online January 20, 2015. doi:<a href=\"https://doi.org/10.48550/arXiv.1501.04916\">10.48550/arXiv.1501.04916</a></p><p>Baumgardner
        GD, Shaffer BS. Sliding Bones: Movement of Skeletal Material Over Smith Creek
        Playa in Nevada and Its Taphonomic and Paleontologic Implications. <em>Western
        North American Naturalist</em>. 2015;75(2):236-243. doi:<a href=\"https://doi.org/10.3398/064.075.0213\">10.3398/064.075.0213</a></p><p>El-Maarry
        MR, Watters WA, Yoldi Z, et al. Field investigation of dried lakes in western
        United States as an analogue to desiccation fractures on Mars: Desiccation
        Cracks in Dried Lakes. <em>J Geophys Res Planets</em>. 2015;120(12):2241-2257.
        doi:<a href=\"https://doi.org/10.1002/2015JE004895\">10.1002/2015JE004895</a></p><p>Fenner
        M. What Can Article-Level Metrics Do for You? <em>PLoS Biol</em>. 2013;11(10):e1001687.
        doi:<a href=\"https://doi.org/10.1371/journal.pbio.1001687\">10.1371/journal.pbio.1001687</a></p><p>Grayson
        DK, Meltzer DJ. Revisiting Paleoindian exploitation of extinct North American
        mammals. <em>Journal of Archaeological Science</em>. 2015;56:177-193. doi:<a
        href=\"https://doi.org/10.1016/j.jas.2015.02.009\">10.1016/j.jas.2015.02.009</a></p><p>Hannigan
        S, Raphael J, White P, Bragg L, Cripps Clark J. Collaborative reflective experience
        and practice in education explored through self-study and arts-based research.
        Published online January 1, 2016. Accessed July 2, 2023. <a href=\"https://dro.deakin.edu.au/articles/journal_contribution/Collaborative_reflective_experience_and_practice_in_education_explored_through_self-study_and_arts-based_research/20875012/1\">https://dro.deakin.edu.au/articles/journal_contribution/Collaborative_reflective_experience_and_practice_in_education_explored_through_self-study_and_arts-based_research/20875012/1</a></p><p>Jones
        R, Hooke RLeB. Racetrack Playa: Rocks moved by wind alone. <em>Aeolian Research</em>.
        2015;19:1-3. doi:<a href=\"https://doi.org/10.1016/j.aeolia.2015.08.001\">10.1016/j.aeolia.2015.08.001</a></p><p>Li
        M, Zhou S, Wang G. 3D identification and stability analysis of key surface
        blocks of rock slope. <em>Trans Tianjin Univ</em>. 2016;22(4):317-323. doi:<a
        href=\"https://doi.org/10.1007/s12209-016-2596-z\">10.1007/s12209-016-2596-z</a></p><p>Lorenz
        RD, Norris JM, Jackson BK, Norris RD, Chadbourne JW, Ray J. <em>Trail Formation
        by Ice-Shoved </em>\u201C<em>Sailing Stones</em>\u201D<em> Observed at Racetrack
        Playa, Death Valley National Park</em>. Physical: Landscape Evolution: modelling
        and field studies; 2014. doi:<a href=\"https://doi.org/10.5194/esurfd-2-1005-2014\">10.5194/esurfd-2-1005-2014</a></p><p>Norris
        RD, Norris JM, Lorenz RD, Ray J, Jackson B. Sliding Rocks on Racetrack Playa,
        Death Valley National Park: First Observation of Rocks in Motion. Magar V,
        ed. <em>PLoS ONE</em>. 2014;9(8):e105948. doi:<a href=\"https://doi.org/10.1371/journal.pone.0105948\">10.1371/journal.pone.0105948</a></p><p>Patrias
        K. <em>Citing Medicine</em>. 2nd ed. National Library of Medicine (US); 2007.
        <a href=\"https://www.ncbi.nlm.nih.gov/books/NBK7256/\">https://www.ncbi.nlm.nih.gov/books/NBK7256/</a></p><p>Rambo
        RP, Tainer JA. Modeling Macromolecular Motions by X-Ray-Scattering-Constrained
        Molecular Dynamics. <em>Biophysical Journal</em>. 2015;108(10):2421-2423.
        doi:<a href=\"https://doi.org/10.1016/j.bpj.2015.04.023\">10.1016/j.bpj.2015.04.023</a></p><p>Sanz-Montero
        ME, Cabestrero \xD3, Rodr\xEDguez-Aranda JP. Sedimentary effects of flood-producing
        windstorms in playa lakes and their role in the movement of large rocks: EFFECTS
        OF FLOOD-PRODUCING STORMS IN PLAYA LAKES. <em>Earth Surf Process Landforms</em>.
        2015;40(7):864-875. doi:<a href=\"https://doi.org/10.1002/esp.3677\">10.1002/esp.3677</a></p><p>Sanz-Montero
        ME, Cabestrero \xD3, Rodr\xEDguez-Aranda JP. Comments on Racetrack playa:
        Rocks moved by wind alone. <em>Aeolian Research</em>. 2016;20:196-197. doi:<a
        href=\"https://doi.org/10.1016/j.aeolia.2016.01.003\">10.1016/j.aeolia.2016.01.003</a></p><p>Tenopir
        C, Dalton ED, Allard S, et al. Changes in Data Sharing and Data Reuse Practices
        and Perceptions among Scientists Worldwide. Van Den Besselaar P, ed. <em>PLoS
        ONE</em>. 2015;10(8):e0134826. doi:<a href=\"https://doi.org/10.1371/journal.pone.0134826\">10.1371/journal.pone.0134826</a></p><p>Whitlock
        MC. Data archiving in ecology and evolution: best practices. <em>Trends in
        Ecology &amp; Evolution</em>. 2011;26(2):61-65. doi:<a href=\"https://doi.org/10.1016/j.tree.2010.11.006\">10.1016/j.tree.2010.11.006</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Eating your own Dog Food ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/eating-your-own-dog-food/\" />\n\t\t<id>https://doi.org/10.53731/r79vxn1-97aq74v-ag58n</id>\n
        \       <published>2016-12-20T00:00:00.000+00:00</published>\n\t\t<updated>2023-09-07T08:34:41.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/230785.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/230785.jpeg\"></p><p><a
        href=\"https://newrepublic.com/article/115349/dogfooding-tech-slang-working-out-glitches\">Eating
        your own dog food</a> is a slang term to describe that an organization should
        itself use the products and services it provides. For DataCite this means
        that we should use DOIs with appropriate metadata and strategies for long-term
        preservation for the scholarly outputs we produce. For the most part this
        is not research data, but rather technical documents such as the DataCite
        Schema and its documentation (<a href=\"https://blog.datacite.org/eating-your-own-dog-food/#ref-https://doi.org/10.5438/0012\">2016</a>).</p>\n<p>These
        outputs also include the posts on this blog, where we discuss topics relevant
        for the DataCite community, but also of broader interest to anyone who cares
        about research data, persistent identifiers, and scholarly infrastructure.
        And starting today all blog posts on this blog will have a DOI, metadata and
        use a persistent storage mechanism.</p>\n<h3 id=\"technical-implementation\">Technical
        Implementation</h3>\n<p>This blog is powered by the static site generator
        <a href=\"https://middlemanapp.com/\">Middleman</a>, with blog posts written
        in <a href=\"http://commonmark.org/\">Markdown</a> and converted to HTML using
        <a href=\"http://pandoc.org/\">Pandoc</a> and the <a href=\"https://travis-ci.org/\">Travis
        CI</a> continuous integration service. Static site generator means that there
        is no database or application server powering the site, making website adminstration
        simpler, cheaper and safer. In addition to the blog, the <a href=\"https://www.datacite.org/\">DataCite
        homepage</a> and <a href=\"https://schema.datacite.org/\">Metadata Schema
        subsite</a> are also generated using Middleman.</p>\n<p>The simplicity is
        particularly important here, as registering the DOIs and metadata can be accomplished
        using a command line utility written by DataCite staff that doesn't need to
        know much about the internals of Middleman, and thus can be easily adapted
        to other static site generators such as <a href=\"http://jekyllrb.com/\">Jekyll</a>,
        <a href=\"http://gohugo.io/\">Hugo</a> or <a href=\"https://hexo.io/\">Hexo</a>.
        The command line utility is <a href=\"https://github.com/datacite/cirneco\">Cirneco</a>,
        generating the metadata XML according to the DataCite Metadata Schema, and
        registering DOI and metadata with the DataCite MDS. Like all tools mentioned
        in this post Cirneco is open source software, please reach out to us if you
        are interested in implementing similar functionality for your blog.</p>\n<h3
        id=\"generating-dois\">Generating DOIs</h3>\n<p>The DOIs for this blog are
        generated automatically, using a modified base32 encoding algorithm that is
        provided by Cirneco, as discussed last week (Fenner, <a href=\"https://blog.datacite.org/eating-your-own-dog-food/#ref-https://doi.org/10.5438/55E5-T5C0\">2016</a>).
        The DOI is generated and minted when a new post is pushed to <a href=\"https://blog.datacite.org/\">https://blog.datacite.org</a>.
        This avoids two problems: a) DOI-like strings in the wild before publication
        and b) the randomly generated DOI exists already (we can simply generate a
        new one). All DOIs are short, without semantic infomation that might change
        over time, and with a checksum to minimize transcription errors, for example
        <strong>https://doi.org/10.5438/XCBJ-G7ZY</strong>. Going forward we encourage
        users to link to the DataCite Blog using the DOI, as these links will continue
        to work even if we ever move the blog to a different location.</p>\n<h3 id=\"generating-metadata\">Generating
        Metadata</h3>\n<p>For the generation of metadata, we need to strike a balance
        between simple author provided metadata, but rich enough to aid discovery.
        We are doing this via three mechanisms:</p>\n<ul><li>metadata provided by
        the author</li><li>default metadata for the blog</li><li>metadata automatically
        extracted from content</li></ul>\n<p>The metadata provided by the author are
        the typical metadata for blog posts, provided via <a href=\"https://gohugo.io/content/front-matter/\">YAML
        front matter</a> at the beginning of each post:</p>\n<pre><code>---\nlayout:
        post\ntitle: Eating your own Dog Food\nauthor: mfenner\ndate: 2016-12-19\ntags:\n-
        datacite\n- doi\n- metadata\n---</code></pre>\n<p>We can reuse all these metadata
        when generating DataCite metadata, using the tags as <code>subjects</code>.</p>\n<p>The
        default metadata are metadata that always stay the same for the blog, such
        as <code>publisher</code>, <code>HostingInstitution</code> and <code>rights</code>.
        We can store them in a site-wide configuration file. We can also assume reasonable
        defaults that can be overridden in the YAML front matter, e.g. <code>resourceType</code>
        (we use <a href=\"https://schema.org/BlogPosting\">BlogPosting</a> with <code>resourceTypeGeneral</code>
        Text) and <code>version</code>. We store more information about authors outside
        the blog post, including <code>givenName</code>, <code>familyName</code> and
        <code>nameIdentifier</code> (we now show the ORCID ID of every blog author
        at the bottom of the post).</p>\n<p>Finally, there are metadata that we can
        automatically extract from the blog post, and we are currently doing this
        for the <code>description</code> and <code>relatedIdentifier</code>. This
        blog uses Pandoc and BibTex to generate the references section at the end,
        and we can fetch this information and convert it into the format needed for
        <code>relatedIdentifier</code>.</p>\n<p>Taken together we can provide all
        metadata that are <em>required</em> or <em>recommended</em> in the Metadata
        Schema documentation (<a href=\"https://blog.datacite.org/eating-your-own-dog-food/#ref-https://doi.org/10.5438/0012\">2016</a>),
        and we can do this without any extra effort for the author. The full XML is
        avalailable <a href=\"https://data.crosscite.org/application/vnd.datacite.datacite+xml/10.5438/4K3M-NYVG\">here</a>.</p>\n<p>Not
        all blog posts need to be cited formally with metadata in a <em>references</em>
        list formatted according to a specific citation style. But these metadata
        greatly help with discovery, a search in DataCite Search for <a href=\"http://search.datacite.org/works?query=eating+dog+food\">eating
        dog food</a> will for example bring up this blog post as the first hit.</p>\n<h3
        id=\"persistent-storage\">Persistent storage</h3>\n<p>Using DOIs means that
        readers not only expect rich metadata that help with citation and discovery,
        but also that DataCite takes extra care to preserve the blog posts, thinking
        beyond the particular technical implementation or even the contiuing existence
        of this blog. This is an area where we do need to do more work, starting with
        a decision about the best archival format for a blog post (HTML, PDF, <a href=\"https://jats.nlm.nih.gov/\">JATS</a>?).
        For now blog posts are hosted in multiple Git repositories (<a href=\"https://github.com/datacite/blog\">one
        of them on Github</a>), and in two independent Amazon S3 buckets that each
        use <a href=\"http://docs.aws.amazon.com/AmazonS3/latest/dev/Versioning.html\">versioning</a>.
        Multiple locations with versioning are a good start, but more work is clearly
        needed.</p>\n<h2 id=\"acknowledgments\">Acknowledgments</h2>\n<p>This blog
        post was <a href=\"https://doi.org/10.5438/4k3m-nyvg\">originally published</a>
        on the DataCite Blog.</p>\n<h2 id=\"references\">References</h2>\n<p>DataCite
        Metadata Working Group. DataCite Metadata Schema Documentation for the Publication
        and Citation of Research Data v4.0. Published online 2016:45 pages. doi:<a
        href=\"https://doi.org/10.5438/0012\">10.5438/0012</a></p>\n<p>Fenner M. Cool
        DOI\u2019s. Published online December 15, 2016. doi:<a href=\"https://doi.org/10.5438/55E5-T5C0\">10.5438/55E5-T5C0</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Reference Lists and Tables of Content ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/reference-lists-and-tables-of-content/\"
        />\n\t\t<id>https://doi.org/10.53731/r795v41-97aq74v-ag4cd</id>\n        <published>2016-12-19T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-15T09:08:52.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/article2-1.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/article2-1.png\"></p><p><a
        href=\"https://twitter.com/gbilder\">Geoff Bilder</a> from CrossRef likes
        to show the following slide at scholarly conferences, and then asks the audience
        what they see:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/article-1.png\"
        class=\"kg-image\" alt=\"Paper 1\" loading=\"lazy\" width=\"500\" height=\"733\"></figure><p>Most
        of us probably immediately recognize this document as a scholarly article.
        This immediate recognition includes essential parts of an article such as
        the title - or the reference list:</p><figure class=\"kg-card kg-image-card
        kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/article2-1-1.png\"
        class=\"kg-image\" alt=\"Paper 2\" loading=\"lazy\" width=\"500\" height=\"722\"><figcaption>Paper
        2</figcaption></figure><p>This immediate recognition is a powerful concept,
        it makes it easy for the reader to navigate a scholarly document, e.g. to
        quickly jump to the abstract or references.</p><p>We don't have the same immediate
        recognition for datasets. Given that a large number of datasets in DataCite
        are in CSV (comma separated values) format, the closest we come to a immediately
        recognized document is probably the spreadsheet:</p><figure class=\"kg-card
        kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/Spreadsheet_animation.gif\"
        class=\"kg-image\" alt=\"Container\" loading=\"lazy\" width=\"279\" height=\"155\"><figcaption>Container.
        <em>From: <a href=\"https://commons.wikimedia.org/wiki/File:Spreadsheet_animation.gif\">Wikimedia
        Commons</a>, licensed under <a href=\"http://creativecommons.org/licenses/by-sa/3.0\">CC
        BY-SA 3.0</a>.</em></figcaption></figure><p>A canonical format for datasets
        goes beyond immediate recognition of the essential parts by the user, it would
        also greatly facilitate reuse of data. As <a href=\"https://twitter.com/nickstenning\">Nick
        Stenning</a> from the Open Knowledge Foundation (OKFN) pointed out at CSV.conf
        last year, the cost of shipping of goods is in large part determined by the
        cost of loading and unloading, and the container has dramatically changed
        that equation. He argued that common formats such as the OKFN <a href=\"https://frictionlessdata.io/specs/data-package/\">data
        package</a> could do the same for data reuse.</p><figure class=\"kg-card kg-image-card
        kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/break-bulk-sacks.png\"
        class=\"kg-image\" alt=\"Bulk parcels\" loading=\"lazy\" width=\"1543\" height=\"1087\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/break-bulk-sacks.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/08/break-bulk-sacks.png
        1000w, https://blog.front-matter.io/content/images/2022/08/break-bulk-sacks.png
        1543w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Bulk parcels. <em>From:
        <a href=\"https://commons.wikimedia.org/wiki/File:Hafenarbeiter_bei_der_Verladung_von_Sackgut_-_MS_Rothenstein_NDL,_Port_Sudan_1960.png\">Wikimedia
        Commons</a>, licensed under <a href=\"http://creativecommons.org/licenses/by-sa/3.0\">CC
        BY-SA 3.0</a>.</em></figcaption></figure><p>Unfortunately there are at least
        three problems with using spreadsheets as canonical format for datasets:</p><ul><li>not
        every dataset can be represented as a CSV file, there are many specialized
        formats (including of course Excel <code>.xlsx</code>)</li><li>we can't include
        descriptive metadata (not even authors or document title) in a CSV file</li><li>many
        datasets actually include a collecting of files: not only in CSV format, but
        also other data formats and support files such as a README.</li></ul><p>The
        approach taken by the OKFN data package format - and related formats such
        as the <a href=\"https://researchobject.github.io/specifications/bundle/\">Research
        Object Bundle</a> - is to put all data files (in CSV or other formats) into
        a folder, together with a standardized machine-readable file that includes
        the metadata (e.g. title, authors, publication date and license). This folder
        can then compressed with <code>zip</code>, again yielding a single file (a
        very common approach used for example for <code>epub</code> and <code>docx</code>).</p><p>The
        concept described here (a collection of documents in a larger container, and
        a listing of all included documents) is of course at least as old as the scholarly
        article: the <strong><strong>book</strong></strong> as a canonical format
        for collections (of texts), and the <strong><strong>table of contents</strong></strong>
        to describe what is in the book.</p><figure class=\"kg-card kg-image-card
        kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/Table_of_Contents_PANARCHIE_published_in_1860.jpeg\"
        class=\"kg-image\" alt=\"Table of contents\" loading=\"lazy\" width=\"494\"
        height=\"590\"><figcaption>Table of contents. <em>From: <a href=\"https://commons.wikimedia.org/wiki/File:Table_of_Contents_PANARCHIE_published_in_1860.JPG\">Wikimedia
        Commons</a>, licensed under <a href=\"http://creativecommons.org/licenses/by-sa/3.0\">CC
        BY-SA 3.0</a>.</em></figcaption></figure><p>The approach described here would
        not only help package datasets into a more reusable standard format, but the
        scholarly article would also greatly benefit from migrating to a container
        format. We all know that the concept of the scholarly article described at
        the beginning of this posts is falling apart - an article is simply no longer
        a single text document. We have not only associated figures and tables, but
        also associated files that can't be easily included into the article PDF,
        in particular files that contain the data underlying the findings of the article,
        but also other supplementary information.</p><p>There are currently three
        common approaches referencing the underlying data in a scholarly article:</p><ul><li>inclusion
        in supporting information files without any specific linking</li><li>informal
        citation in the article text, most commonly in the materials and methods section</li><li>formal
        citation with inclusion in the reference list</li></ul><p>Until not too long
        ago I was a big proponent of including all data associated with an article
        in the reference list, mainly to make it easier to find the data. But the
        reference list isn't the appropriate place for something that is really part
        of the article - or as colleague <a href=\"http://bio.unc.edu/people/faculty/vision/\">Todd
        Vision</a> puts it: the data generated for an article are another <strong><strong>output</strong></strong>
        rather than an <strong><strong>input</strong></strong>. Reference lists summarize
        all the inputs to an article, whereas outputs belong into a <strong><strong>table
        of contents</strong></strong>. A table of contents isn't a standard feature
        of scholarly articles yet, but to me is a logical next step for the journal
        article format, together with using the underlying concept of a container
        format described earlier in this post. Extracting references to datasets from
        a table of contents should be as easy as extracting them from a reference
        list, in particular if we make sure that this table of contents is openly
        available.</p><p>Journal Article Tag Suite (<a href=\"http://jats.nlm.nih.gov/\">JATS</a>)
        is the standard machine-readable format for journal articles in the life sciences
        (and increasingly other sciences). At <a href=\"http://jats.nlm.nih.gov/jats-con/\">JATS-CON</a>
        in April this year I proposed (starting at minute 210) to extend JATS by providing
        it also as a container format:</p><figure class=\"kg-card kg-bookmark-card
        kg-card-hascaption\"><a class=\"kg-bookmark-container\" href=\"https://videocast.nih.gov/embed.asp?live&#x3D;16116\"><div
        class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">NIH VideoCasting
        Event</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img
        class=\"kg-bookmark-icon\" src=\"https://videocast.nih.gov/favicon.ico\" alt=\"\"></div></div></a><figcaption>JATS-CON
        2015 Day 2</figcaption></figure><p><em>This blog post was <a href=\"https://doi.org/10.5438/5aeg-weev\">originally
        published</a> on the DataCite Blog.</em></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Cool DOIs ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/cool-dois/\"
        />\n\t\t<id>https://doi.org/10.53731/r79x921-97aq74v-ag5a2</id>\n        <published>2016-12-15T00:00:00.000+00:00</published>\n\t\t<updated>2023-09-07T08:33:29.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/cool-dois-1.svg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/cool-dois-1.svg\"></p><p>In
        1998 Tim Berners-Lee coined the term cool URIs (<a href=\"https://blog.datacite.org/cool-dois/#ref-https://www.w3.org/Provider/Style/URI\">1998</a>),
        that is URIs that don\u2019t change. We know that URLs referenced in the scholarly
        literature are often not cool, leading to link rot (Klein et al., <a href=\"https://blog.datacite.org/cool-dois/#ref-https://doi.org/10.1371/journal.pone.0115253\">2014</a>)
        and making it hard or impossible to find the referenced resource.</p>\n<p>Cool
        URIs are, of course, a fundamental principle behind DOIs, with the two important
        concepts <a href=\"https://www.doi.org/doi_handbook/3_Resolution.html\"><em>resolution</em></a>
        (it is very hard to maintain a URL directly pointing at a resource) and <a
        href=\"https://www.doi.org/doi_handbook/6_Policies.html\"><em>policies</em></a>
        (that all DOI registration agencies and organizations minting DOIs agree to
        maintain the redirection). The third essential element for DOIs, their <a
        href=\"https://www.doi.org/doi_handbook/4_Data_Model.html\"><em>data model</em></a>,
        is not directly about persistent linking, but about the discoverability of
        the linked resources via standard metadata in a central index.</p>\n<p>All
        DOIs, expressed as HTTP URI, are therefore cool URIs. So what is a cool DOI?
        And, furthermore, how to create and use them? To understand what a cool DOI
        is, we have to explain the three parts that make up a DOI:</p>\n<figure class=\"kg-card
        kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/doi-parts.png\"
        class=\"kg-image\" alt=\"The three parts that make up a DOI\" loading=\"lazy\"
        width=\"600\" height=\"125\" srcset=\"https://blog.front-matter.io/content/images/2022/08/doi-parts.png
        600w\"><figcaption><span>The three parts that make up a DOI.</span></figcaption></figure>\n<h3
        id=\"proxy\">Proxy</h3>\n<p>The proxy is not part of the DOI specification,
        but almost all scholarly DOIs that users encounter today will be expressed
        as HTTP URLs. DataCite recommends that all DOIs are displayed as permanent
        URLs, consistent with the recommendations of other DOI registration agencies,
        e.g. the <a href=\"http://www.crossref.org/02publishers/doi_display_guidelines.html\">Crossref
        DOI display guidelines</a>. When the DOI system was originally designed, it
        was thought that the DOI protocol would become widely used, but that clearly
        has not happened and displaying DOIs as <strong>doi:10.5281/ZENODO.31780</strong>
        is therefore not recommended.</p>\n<p>The DOI proxy enables the functionality
        of expressing DOIs as HTTP URIs. Users should also be aware of two these two
        recommendations:</p>\n<ul><li>Use <a href=\"https://www.doi.org/doi_proxy/proxy_policies.html\">doi.org</a>
        instead of dx.doi.org as DNS name</li><li>Use the HTTPS protocol instead of
        HTTP protocol</li></ul>\n<p>Ed Pentz from Crossref makes the case for HTTPS
        in a <a href=\"http://blog.crossref.org/2016/09/new-crossref-doi-display-guidelines.html\">September
        blog post</a>. The web, and therefore also the scholarly web, is moving to
        HTTPS as the default. It is important that the DOI proxy redirects to HTTPS
        URLs, and it will take some time until all DataCite data centers use HTTPS
        for the landing pages their DOIs redirects to.</p>\n<p>What many users don\u2019t
        know is that doi.org is not the only proxy server for DOIs. DOIs use the handle
        system and any handle server will resolve a DOI, just as doi.org will resolve
        any handle. This means that <a href=\"https://hdl.handle.net/10.5281/ZENODO.31780\">https://hdl.handle.net/10.5281/ZENODO.31780</a>
        will resolve to the landing page for that DOI and that https://doi.org/10273/BGRB5054RX05201
        is a handle (for a <a href=\"http://www.igsn.org/\">IGSN</a>) and not a DOI.</p>\n<h3
        id=\"prefix\">Prefix</h3>\n<p>The DOI prefix is used as a namespace so that
        DOIs are globally unique without requiring global coordination for every new
        identifier. Prefixes in the handle system and therefore for DOIs are numbers
        without any semantic meaning. One lesson learned with persistent identifiers
        is that adding meaning to the identifier (e.g. by using a prefix with the
        name of the data repository) is always dangerous, because \u2013 despite best
        intentions \u2013 all names can change over time.</p>\n<p>Since the DOI prefix
        is a namespace to keep DOIs globally unique, there is usually no need for
        multiple prefixes for one organization managing DOI assignment. The tricky
        part is that these responsibilities can change, e.g. when an organization
        manages multiple repositories and one of them is migrated to another organization.
        It therefore makes sense to assign one prefix per list of resources that always
        stays together, e.g. one repository. It is possible that one prefix is managed
        by multiple organizations (as long as they use the same DOI registration agency),
        but that makes DOI management more complex.</p>\n<h3 id=\"suffix\">Suffix</h3>\n<p>The
        suffix for a DOI can be (almost) any string. Which is both a feature and a
        curse. It is a feature because it gives maximal flexibility, for example when
        migrating existing identifiers to the DOI system. And it is a curse because
        it not always works well in the web context, as the list of characters allowed
        in a URL is limited. A good example of this are SICIs (<a href=\"https://en.wikipedia.org/wiki/Serial_Item_and_Contribution_Identifier\">Serial
        Item and Contribution Identifier</a>), they were defined in 1996 before the
        DOI system was implemented, and could then be migrated to DOIs. Unfortunately
        they can contain many characters that are problematic in a URL or make it
        difficult to validate the DOI, as in <a href=\"https://doi.org/10.1002/(sici)1099-1409(199908/10)3:6/7%3C672::aid-jpp192%3E3.0.co;2-8\">https://doi.org/10.1002/(sici)1099-1409(199908/10)3:6/7&lt;672::aid-jpp192&gt;3.0.co;2-8</a>.
        A Crossref <a href=\"http://blog.crossref.org/2015/08/doi-regular-expressions.html\">blog
        post</a> by Andrew Gilmartin gives a good overview about the characters found
        in DOIs and suggests the following regular expression to check for valid DOIs:</p>\n<pre><code>/^10.\\d{4,9}/[-._;()/:A-Z0-9]+$/i</code></pre>\n<p>SICIs
        demonstrate two other pitfalls:</p>\n<ul><li>they contain semantic information
        (ISSN, volume, number, etc.) that may change over time, and</li><li>they are
        long, difficult to transcribe, with characters not allowed in URLs, and not
        very human-readable.</li></ul>\n<p>Semantic information might also lead users
        to expect certain functionalities. A common pattern that we see at DataCite
        is to include information about the version or parent in the suffix, e.g.
        <a href=\"https://doi.org/10.6084/M9.FIGSHARE.3501629.V1\">https://doi.org/10.6084/M9.FIGSHARE.3501629.V1</a>
        or <a href=\"https://doi.org/10.5061/DRYAD.0SN63/7\">https://doi.org/10.5061/DRYAD.0SN63/7</a>.
        While the decision on what to put into the suffix is up to each data center,
        we should make sure users don't think that these are functionalities of the
        DOI system (e.g. that adding <strong>.V2</strong> to any DOI name will resolve
        to version 2 of that resource).</p>\n<p>Another issue to keep in mind when
        assigning suffixes is that DOIs \u2013 in contrast to HTTP URIs \u2013 are
        case-insensitive, <a href=\"https://doi.org/10.5281/ZENODO.31780\">https://doi.org/10.5281/ZENODO.31780</a>
        and <a href=\"https://doi.org/10.5281/zenodo.31780\">https://doi.org/10.5281/zenodo.31780</a>
        are the same DOI. All DOIs are <a href=\"https://www.doi.org/doi_handbook/2_Numbering.html#2.4\">converted
        to upper case</a> upon registration and DOI resolution, but DOIs are not consistently
        displayed in such a way.</p>\n<h3 id=\"generating-cool-dois\">Generating cool
        DOIs</h3>\n<p>With all that, what should the ideal DOI look like? Its suffix
        should be:</p>\n<ul><li>opaque without semantic information</li><li>work well
        in a web environment, avoiding characters problematic in URLs</li><li>short
        and human-readable</li><li>Resistant to transcription errors</li><li>easy
        to generate</li></ul>\n<p>On Tuesday DataCite released a tool that helps generating
        such a suffix, an open source command line tool called <a href=\"https://github.com/datacite/cirneco\">cirneco</a>
        (a lot of our open source software uses Italian dog breed names). Cirneco
        is a Ruby gem that can be installed via</p>\n<pre><code>gem install cirneco</code></pre>\n<p>Cirneco
        uses base32 encoding, as <a href=\"http://www.crockford.com/wrmg/base32.html\">described</a>
        by Douglas Crockford. The encoding starts with a randomly generated number
        to guarantee uniqueness of the identifier, and then encodes the number into
        a string that uses all numbers and uppercase letters. It avoids the letters
        I, O and L as they can be confused with the letter 1 and 0, using 32 characters
        (and 5 checksum characters) in total. The last character is a checksum. The
        resulting string from cirneco always has a length of 8 characters, in groups
        of 4 separated by a hyphen to help with readability. The advantage of base32
        encoding over using only numbers (as for example ORCID is doing) is that the
        resulting string becomes much more compact, the available 7 characters (plus
        one for the checksum) can encode 34,359,738,367 strings, compared to 10 million
        when only using numbers. This number is large enough that the resulting suffix
        will not only be unique for a given prefix, but also unique for all DOIs (there
        is a very small chance to get the same random number twice, but this will
        be rejected when trying to register the DOI).</p>\n<p>Another common way to
        generate random strings would have been universally unique identifiers (<a
        href=\"https://en.wikipedia.org/wiki/Universally_unique_identifier\">UUID</a>),
        but they are long and not very human-readable, e.g. <a href=\"https://doi.org/10.4233/UUID:6D192FE2-DE18-4556-873A-D3CD56AB96A6\">https://doi.org/10.4233/UUID:6D192FE2-DE18-4556-873A-D3CD56AB96A6</a>.</p>\n<p>An
        example DOI generated by cirneco would be</p>\n<pre><code>cirneco doi generate
        --prefix 10.5555\n10.5555/KVTD-VPWM</code></pre>\n<p>The generated DOI is
        short enough that it should work well in places where space is limited, providing
        an alternative to the <a href=\"http://shortdoi.org/\">ShortDOI</a> service
        which shortens existing DOIs, but does this by adding another layer on top
        of the DOI proxy.</p>\n<p>Another cirneco command checks that this is a valid
        bas32 string using the checksum</p>\n<pre><code>cirneco doi check 10.5555/KVTD-VPWM\nChecksum
        for 10.5555/KVTD-VPWM is valid</code></pre>\n<p>This can be used to quickly
        verify a DOI, e.g. in a web form or API. The Ruby base32 encoding library
        used by cirneco is open source (<a href=\"https://github.com/datacite/base32\">https://github.com/datacite/base32</a>.
        I added the checksum to the existing library), and implementations of the
        Crockford base32 encoding pattern are available in many other languages, including
        <a href=\"https://github.com/jbittel/base32-crockford\">Python</a>, <a href=\"https://github.com/dflydev/dflydev-base32-crockford\">PHP</a>,
        <a href=\"https://www.npmjs.com/package/base32-crockford\">Javascript</a>,
        <a href=\"http://stackoverflow.com/questions/22385467/crockford-base32-encoding-for-large-number-java-implementation\">Java</a>,
        <a href=\"https://github.com/richardlehane/crock32\">Go</a> and <a href=\"https://www.nuget.org/packages/crockford-base32\">.NET</a>.</p>\n<p>To
        answer the question raised at the beginning: a cool DOI is a DOI expressed
        as HTTPS URI using the doi.org proxy and using a base32-encoded suffix, for
        example <strong>https://doi.org/10.5555/KVTD-VPWM</strong>. This DOI works
        well in a web environment, is human readable, easy to parse and detect (e.g.
        in text mining), and can be generated using an algorithm that is well understood
        and supported.</p>\n<h2 id=\"acknowledgments\">Acknowledgments</h2>\n<p>This
        blog post was <a href=\"https://doi.org/10.5438/55e5-t5c0\">originally published</a>
        on the DataCite Blog.</p>\n<h2 id=\"references\">References</h2>\n<p>Berners-Lee
        T. <em>Hypertext Style: Cool URIs Don\u2019t Change.</em>; 1998. Accessed
        December 14, 2016. <a href=\"https://www.w3.org/Provider/Style/URI\">https://www.w3.org/Provider/Style/URI</a></p>\n<p>Klein
        M, Van De Sompel H, Sanderson R, et al. Scholarly Context Not Found: One in
        Five Articles Suffers from Reference Rot. Bar-Ilan J, ed. <em>PLoS ONE</em>.
        2014;9(12):e115253. doi:<a href=\"https://doi.org/10.1371/journal.pone.0115253\">10.1371/journal.pone.0115253</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ A common API for retrieving DataCite Metadata
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/a-common-api-for-retrieving-datacite-metadata/\"
        />\n\t\t<id>https://doi.org/10.53731/r79x5j1-97aq74v-ag59c</id>\n        <published>2016-11-03T00:00:00.000+00:00</published>\n\t\t<updated>2023-09-01T21:26:27.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2023/09/api_search.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2023/09/api_search.png\"></p><p>Today
        we are launching a new version of the DataCite API at <a href=\"http://api.datacite.org/\">http://api.datacite.org</a>.
        This new version includes numerous bug fixes and now includes related resources
        (e.g. data centers, members or contributors) according to the <a href=\"http://jsonapi.org/format/#fetching-includes\">JSONAPI
        spec</a>. The changelog can be found <a href=\"https://github.com/datacite/spinone/blob/master/CHANGELOG.md\">here</a>.
        Current users of the API should watch out for breaking changes in the <code>meta</code>
        object used for faceting.</p><p>We first launched the DataCite API in June
        as what we hope will become the new standard way to retrieve metadata from
        DataCite. Most of the content in the API comes from our search index of the
        MDS and is about DOI metadata, but we are also including information from
        other services, e.g. our member database and the <a href=\"https://doi.org/10.53731/r79xf41-97aq74v-ag5bc\">Event
        Data</a> service. We ourselves use the API to power the web frontend for search,
        to <a href=\"https://www.datacite.org/members.html\">display member information</a>
        on our homepage, and to provide a search for our <a href=\"http://blog.datacite.org/\">blog</a>.</p><p>Other
        ways to obtain DataCite metadata include <a href=\"http://oai.datacite.org/\">OAI-PMH</a>
        for harvesting large volumes of metadata, and direct access to the Solr search
        index. This direct public access to the Solr search index will be discontinued
        in 2017 for performance and security reasons, so we encourage all users to
        migrate to the DataCite API as soon as possible. We will be adding missing
        API functionality in the coming months, most importantly provide all available
        DOI metadata in the API and thus search web frontend. Please <a href=\"mailto:tech@datacite.org\">contact
        us</a> if you have suggestions or bug reports regarding the DataCite API.</p><p><em>This
        blog post was <a href=\"https://doi.org/10.5438/6wcf-efw5\">originally published</a>
        on the DataCite Blog.</em></p><h3 id=\"references\">References</h3><p>Fenner
        M. It\u2019s all about Relations. Published online April 14, 2016. doi:<a
        href=\"https://doi.org/10.53731/r79xf41-97aq74v-ag5bc\">10.53731/r79xf41-97aq74v-ag5bc</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Announcing the Organization Identifier Project:
        a Way Forward ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/announcing-the-organization-identifier-project-a-way-forward/\"
        />\n\t\t<id>https://doi.org/10.53731/r79xvx1-97aq74v-ag5d5</id>\n        <published>2016-11-01T00:00:00.000+00:00</published>\n\t\t<updated>2023-09-20T07:00:40.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/london_institute.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/london_institute.png\"></p><p>The
        scholarly research community has come to depend on a series of open identifier
        and metadata infrastructure systems to great success. Content identifiers
        (through DataCite and Crossref) and contributor identifiers (through ORCID)
        have become foundational infrastructure for the community. But there is one
        piece of the infrastructure that is missing -- there currently is no open,
        stakeholder-governed infrastructure for organization identifiers and associated
        metadata.</p>\n<p>In early 2016, DataCite began a collaboration with ORCID
        and Crossref to explore the organization identifiers landscape and on how
        our organizations could work with the community to solve the organization
        identifier problem (Demeranville et al., <a href=\"https://blog.datacite.org/announcing-organization-identifier-project/#ref-https://doi.org/10.6084/M9.FIGSHARE.3479141\">2016</a>).
        Out of those conversations emerged a way forward as expressed in the following
        documents:</p>\n<ol><li>Organization Identifier Project: A Way Forward (Cruse,
        Haak, &amp; Pentz, <a href=\"https://blog.datacite.org/announcing-organization-identifier-project/#ref-https://doi.org/10.5438/2906\">2016</a>)</li><li>Organization
        Identifier Provider Landscape (Bilder, Brown, &amp; Demeranville, <a href=\"https://blog.datacite.org/announcing-organization-identifier-project/#ref-https://doi.org/10.5438/4716\">2016</a>)</li><li>Technical
        Considerations for an Organization Identifier Registry (Fenner, Paglione,
        Demeranville, &amp; Bilder, <a href=\"https://blog.datacite.org/announcing-organization-identifier-project/#ref-https://doi.org/10.5438/7885\">2016</a>)</li></ol>\n<p>We
        invite the community to comment on these papers online via email (<a href=\"mailto:oi-project@orcid.org\">oi-project@orcid.org</a>)
        or comments in the corresponding Google Docs (<a href=\"https://docs.google.com/document/d/1PpWRBnlrU_X6TwYzQlB89w4FNXMLqieJv-RW0irNTsg/edit?usp=sharing\">1</a>,
        <a href=\"https://docs.google.com/document/d/1lcKXWm9PxDvVWBxdlH7BVU7w8esnW0F_dppNiCJ9BW8/edit#\">2</a>
        or <a href=\"https://docs.google.com/document/d/1Zj5sRRdnjKLjY81AbaeUdal3n6VuQgi1H66vRMaayiA/edit?usp=sharing\">3</a>),
        or in person at <a href=\"https://crossreflive16.sched.org/\">Crossref LIVE16</a>
        on November 1st and 2nd or at <a href=\"http://pidapalooza.org/\">PIDapalooza</a>
        on November 9th and 10th. To move The OI Project forward, we will be forming
        a Community Working Group with the goal of holding an initial meeting before
        the end of 2016. The Working Group\u2019s main charge is to develop a plan
        to launch and sustain an open, independent, non-profit organization identifier
        registry to facilitate the disambiguation of researcher affiliations</p>\n<h2
        id=\"datacite%E2%80%99s-focus\">DataCite\u2019s Focus</h2>\n<p>An important
        focus of DataCite\u2019s work is to connect resources , which have a DataCite
        DOI, to other resources - for example <a href=\"https://blog.datacite.org/dynamic-data-citation-webinar/\">new
        versions of the same dataset</a>, <a href=\"https://blog.datacite.org/to-better-understand-research-communication-we-need-a-groid-group-object-identifier/\">collections
        of related datasets</a>, or <a href=\"https://blog.datacite.org/location-of-the-citation/\">articles
        citing the dataset</a>. Equally important is the support for linking these
        resources to the people and organizations who have contributed to their generation.
        We are working closely with ORCID to enable <a href=\"https://blog.datacite.org/announcing-datacite-profiles-service/\">linking
        between DataCite DOIs and ORCID IDs</a>. In July we <a href=\"https://blog.datacite.org/relaunching-datacite-search/\">relaunched
        our search</a> to better show these relations between DataCite DOIs and other
        resources. And in September we launched an updated DataCite Metadata Schema
        (DataCite Metadata Working Group, <a href=\"https://blog.datacite.org/announcing-organization-identifier-project/#ref-https://doi.org/10.5438/0012\">2016</a>)
        with better support for linking to funding information. Enabling all these
        relations are persistent identifiers and metadata describing these relations.</p>\n<p>DataCite
        also supports the linking of resources to academic institutions in one of
        two ways: Using the <strong>HostingInstitution</strong> contributor role,
        or via the <strong>affiliation</strong> attribute for creators and contributors.
        One gap we identified when analyzing linking to organizations (Fenner et al.,
        <a href=\"https://blog.datacite.org/announcing-organization-identifier-project/#ref-https://doi.org/10.5281/ZENODO.30799\">2015</a>)
        last September is the lack of adoption of organizational identifiers. Without
        broad adoption of identifiers for organizations similar to how DataCite DOIs,
        Crossref DOIs and ORCID IDs are widely used in the scholarly community, it
        becomes very difficult to track these relations to institutions in a way similar
        to how we can track relations to people.</p>\n<p>Again, we look forward to
        the community\u2019s feedback either via email or in person at the <a href=\"http://pidapalooza.org/\">PIDapalooza</a>
        conference next week.</p>\n<h2 id=\"acknowledgments\">Acknowledgments</h2>\n<p><em>This
        blog post was <a href=\"https://doi.org/10.5438/tnhx-54cg\"><em>originally
        published</em></a> on the DataCite Blog, with corresponding blog posts by
        <a href=\"https://orcid.org/blog/2016/10/31/organization-identifier-project-way-forward\"><em>ORCID</em></a>
        and <a href=\"http://blog.crossref.org/2016/10/the-oi-project.html\"><em>Crossref</em></a>.</em></p>\n<h2
        id=\"references\">References</h2>\n<p>Bilder G, Brown J, Demeranville T. <em>Organisation
        Identifiers: Current Provider Survey</em>. ORCID; 2016. doi:<a href=\"https://doi.org/10.5438/4716\">10.5438/4716</a></p>\n<p>Cruse
        P, Haak L, Pentz E. <em>Organization Identifier Project: A Way Forward</em>.
        ORCID; 2016. doi:<a href=\"https://doi.org/10.5438/2906\">10.5438/2906</a></p>\n<p>DataCite
        Metadata Working Group. DataCite Metadata Schema Documentation for the Publication
        and Citation of Research Data v4.0. Published online 2016:45 pages. doi:<a
        href=\"https://doi.org/10.5438/0012\">10.5438/0012</a></p>\n<p>Demeranville
        T, Brown J, Fenner M, et al. Organisation Identifiers - Minimum viable product
        requirements. Published online 2016:371099 Bytes. doi:<a href=\"https://doi.org/10.6084/M9.FIGSHARE.3479141\">10.6084/M9.FIGSHARE.3479141</a></p>\n<p>Fenner
        M, Demeranville T, Kotarski R, et al. <em>D2.1: Artefact, Contributor, And
        Organisation Relationship Data Schema</em>. Zenodo; 2015. doi:<a href=\"https://doi.org/10.5281/ZENODO.30799\">10.5281/ZENODO.30799</a></p>\n<p>Fenner
        M, Paglione L, Demeranville T, Bilder G. <em>Technical Considerations for
        an Organization Identifier Registry</em>. ORCID; 2016. doi:<a href=\"https://doi.org/10.5438/7885\">10.5438/7885</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Dynamic Data Citation Webinar ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/dynamic-data-citation-webinar/\"
        />\n\t\t<id>https://doi.org/10.53731/r79y01h-97aq74v-ag5dw</id>\n        <published>2016-07-18T00:00:00.000+00:00</published>\n\t\t<updated>2023-09-07T08:32:11.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/dynamic-data.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/dynamic-data.png\"></p><p>On
        July 12, 2016, DataCite invited <a href=\"http://www.ifs.tuwien.ac.at/~andi/\">Andreas
        Rauber</a> to present the recommendations for dynamic data citation of the
        <a href=\"https://rd-alliance.org/groups/data-citation-wg.html\">RDA Data
        Citation Working Group</a> in a webinar.</p>\n<p>Andreas is one of the co-chairs
        of the RDA working group, and he gave a throughout overview of the recommendations,
        and the thinking that went into them. The <a href=\"https://rd-alliance.org/system/files/documents/RDA-DC-Recommendations_151020.pdf\">final
        recommendations</a> are available since last fall, and the current focus of
        the working group is to help with implementations.</p>\n<p>The recommendations
        have to be implemented in the data center, but DataCite is happy to help coordinate
        the work, and to provide feedback to Andreas and the rest of the working group
        where needed. Of particular importance from a DataCite perspective is <strong>recommendation
        8</strong>:</p>\n<blockquote>Query PID: Assign a new PID to the query if either
        the query is new or if the result set returned from an earlier identical query
        is different due to changes in the data. Otherwise, return the existing PID.</blockquote>\n<p>Assigning
        a persistent identifier (not only) when a dataset is originally generated,
        but also when a dataset is about to be cited, is central not only to the working
        group recommendations for dynamic data citation, but also crucial for other
        data citation use cases. Data exist at different levels, from raw data possibly
        generated by a machine, to highly processed data used in a publication. The
        figure below \u2013 presented by Robin Dasler from CERN at the <a href=\"https://project-thor.eu/2016/06/21/july-7-2016-thor-workshop-identifiers-infrastructure-impact-and-innovation/\">THOR
        Workshop</a> on July 7 in Amsterdam - demonstrates this for high-energy physics
        (HEP):</p>\n<figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/hep.webp\" class=\"kg-image\"
        alt=\"HEP\" loading=\"lazy\" width=\"1920\" height=\"1080\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/hep.webp
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/08/hep.webp
        1000w, https://blog.front-matter.io/content/images/size/w1600/2022/08/hep.webp
        1600w, https://blog.front-matter.io/content/images/2022/08/hep.webp 1920w\"
        sizes=\"(min-width: 720px) 720px\"><figcaption><span>HEP</span></figcaption></figure>\n<p>DataCite
        DOIs are intended as citation identifiers. They are persistent identifiers
        and provide standardized metadata, including links to associated publications,
        contributors and funders. They thus focus on the data in the top section of
        the pyramid. While we can also use DataCite DOIs for the other levels of the
        pyramid, sometimes other identifiers are more appropriate for raw, non-persistent
        data generated by machines. Dynamic data citation can be seen as a variant
        of the process that this pyramid describes.</p>\n<p>If you could not attend
        last week or you want to review the session, the recording of the webinar
        is available:</p>\n<figure class=\"kg-card kg-embed-card\"><iframe src=\"https://player.vimeo.com/video/174795589?app_id=122963\"
        width=\"582\" height=\"360\" frameborder=\"0\" allow=\"autoplay; fullscreen;
        picture-in-picture\" title=\"RDA Dynamic Data Citation Recommendations Webinar\"></iframe></figure>\n<p>The
        <a href=\"https://project-thor.eu/\">THOR project</a> will work with interested
        data centers on dynamic data citation in the coming 12 months, hopefully leading
        to important feedback and a few more implementations of the RDA working group
        recommendations. Please contact us if you work for a data center and are interested
        in participating.</p>\n<h2 id=\"acknowledgments\">Acknowledgments</h2>\n<p>This
        blog post was <a href=\"https://doi.org/10.5438/y4ks-ksbc\">originally published</a>
        on the DataCite Blog.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Relaunching DataCite Search ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/relaunching-datacite-search/\" />\n\t\t<id>https://doi.org/10.53731/r79yhah-97aq74v-ag5fv</id>\n
        \       <published>2016-07-05T00:00:00.000+00:00</published>\n\t\t<updated>2023-09-07T08:31:06.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/search.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/search.png\"></p><p>This
        week we relaunched <a href=\"https://search.datacite.org/\">DataCite Search</a>,
        providing a more user-friendly search interface for DataCite metadata. We
        also added functionality that was not available before.</p>\n<p>The new search
        uses a single entry box for queries, and filters by resource type, publication
        year and data center. A new Cite button will generate a citation in several
        popular citation styles, and in BibTeX and RIS import formats. Users who sign
        in using their ORCID credentials can add works to their ORCID record using
        the DataCite Search and Link service, and will find a menu shortcut to a page
        with all DataCite DOIs associated with their ORCID ID.</p>\n<p>In addition
        to information about works, DataCite Search also allows queries for contributors,
        data centers, and members, and the works associated with them. Information
        from the <a href=\"https://www.datacite.org/eventdata.html\">DataCite Event
        Data service</a> is included in the search results where available, and can
        be specifically looked up via the <strong>Services</strong> tab.</p>\n<figure
        class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/eventdata.png\"
        class=\"kg-image\" alt=\"Data Citation Example\" loading=\"lazy\" width=\"800\"
        height=\"391\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/eventdata.png
        600w, https://blog.front-matter.io/content/images/2022/08/eventdata.png 800w\"
        sizes=\"(min-width: 720px) 720px\"><figcaption><span>Data Citation Example</span></figcaption></figure>\n<p>In
        contrast to the previous search user interface the new search is not using
        the Solr Search API directly, but rather the new DataCite API available at
        <a href=\"https://api.datacite.org/\">https://api.datacite.org</a>. This API
        uses the Solr Search API for metadata stored in the DataCite MDS, but also
        pulls in information from other services, including <a href=\"https://www.datacite.org/eventdata.html\">Event
        Data</a> and <a href=\"https://www.datacite.org/profiles.html\">Profiles</a>
        (the latter for information about members). Going forward we plan to add addition
        information to the DataCite API, e.g. from <a href=\"http://www.re3data.org/\">re3data.org</a>.</p>\n<p>The
        software that is providing the search frontend was originally written by Crossref
        and is also powering the <a href=\"http://search.crossref.org/\">Crossref
        Metadata Search</a>. As all DataCite software the code is <a href=\"https://github.com/crosscite/doi-metadata-search\">available</a>
        as open source software.</p>\n<p>The search has been running as Labs Search
        since last August and many users have provided valuable feedback. The old
        search user interface is still available at https://search.datacite.org/ui.</p>\n<h2
        id=\"acknowledgments\">Acknowledgments</h2>\n<p>This blog post was <a href=\"https://doi.org/10.5438/vq2t-vr4k\">originally
        published</a> on the DataCite Blog.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Publishing tabular data as blog post ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/publishing-tabular-data-as-blog-post/\"
        />\n\t\t<id>https://doi.org/10.53731/r79zath-97aq74v-ag5j8</id>\n        <published>2016-05-20T00:00:00.000+00:00</published>\n\t\t<updated>2023-07-02T07:54:09.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/periodic_table.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/periodic_table.jpeg\"></p><p>CSV
        in many ways is for data what Markdown is for text documents: a very simple
        format that is both human- and machine-readable, and that \u2013 despite a
        number of shortcomings - is widely used. Given the popularity of Markdown
        for writing blog posts, using CSV to publish blog posts with tabular data
        should be an obvious thing to do, and we have just published our first blog
        post using CSV data. The blog post shows Table 3 from the DataCite Metadata
        Schema (DataCite Metadata Working Group, <a href=\"https://blog.datacite.org/publishing-tabular-data-as-blog-post/#ref-https://doi.org/10.5438/0010\">2014</a>),
        describing the mandatory properties.</p><p>The DataCite blog uses the <a href=\"https://jekyllrb.com/\">Jekyll</a>
        static site generator, and all blog posts are written in Markdown format.
        All posts have their metadata in YAML format at the beginning of the file
        (separated by <code>---</code> from the main text).</p><pre><code>---\nlayout:
        post\ntitle: Publishing tabular data as blog post\nauthor: mfenner\ntags:\n
        - csv\n - metadata\n - blog\n---</code></pre><p>Markdown is a nice format
        for writing texts, but doesn't work so well for tabular data, as the current
        Markdown table implementations are difficult to edit and read for humans for
        all but the simplest tables. CSV is a much better fit for tabular data, and
        can be written both with a general text editor, or with a spreadsheet program
        or other specialized tool.</p><p>To add the metadata required for every Jekyll
        blog post we are again adding a YAML header, the resulting file format is
        <a href=\"http://csvy.org/\">CSVY</a>, about which we have talked before (Fenner,
        <a href=\"https://blog.datacite.org/publishing-tabular-data-as-blog-post/#ref-https://blog.datacite.org/thinking-about-csv\">2016b</a>).
        Jekyll can be extended to understand many file formats beyond Markdown. As
        a <code>CSVY</code> converter doesn't exist yet, we have written this converter
        and released <strong><strong>jekyll-csvy</strong></strong> as Ruby gem (Fenner,
        <a href=\"https://blog.datacite.org/publishing-tabular-data-as-blog-post/#ref-https://github.com/datacite/jekyll-csvy\">2016a</a>),
        so that <code>CSVY</code> support can be easily added to every Jekyll-powered
        blog.</p><p>In HTML tabular data are typically displayed as HTML tables, and
        this is what we are doing with the <code>CSVY</code> converter. This works
        well for tables that are not too wide, and the converter supports inline Markdown
        formatting (bold, italic, links, etc.) in table cells. Block formatting (e.g.
        lists) is on our list of future improvements, and we will polish the converter
        based on user feedback. We are of course also interested in embedding CSV
        tables within Markdown documents, as this is a common use case.</p><p>One
        important feature of using CSVY for blog posts is that the CSV remains available,
        and can be ingested and processed by tools that can read CSVY, e.g. using
        the R rio (Becker et al., <a href=\"https://blog.datacite.org/publishing-tabular-data-as-blog-post/#ref-https://cran.r-project.org/web/packages/rio/index.html\">2016</a>)
        package.</p><p><em>This blog post was <a href=\"https://doi.org/10.5438/5aeg-weev\">originally
        published</a> on the DataCite Blog.</em></p><h2 id=\"references\">References</h2><p>Becker
        J, Chan C hong, Chan GC, et al. rio: A Swiss-Army Knife for Data I/O. Published
        online 2016. <a href=\"https://cran.r-project.org/web/packages/rio/index.html\">https://cran.r-project.org/web/packages/rio/index.html</a></p><p>DataCite
        Metadata Working Group. DataCite Metadata Schema for the Publication and Citation
        of Research Data v3.1: Documentation. Published online 2014:38 pages. doi:<a
        href=\"https://doi.org/10.5438/0010\">10.5438/0010</a></p><p>Fenner M. jekyll-csvy:
        Jekyll converter for CSVY files. Published online 2016. <a href=\"https://github.com/datacite/jekyll-csvy\">https://github.com/datacite/jekyll-csvy</a></p><p>Fenner
        M. Thinking about CSV. Published online May 4, 2016. doi:<a href=\"https://doi.org/10.5438/4QX3-RP8Y\">10.5438/4QX3-RP8Y</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Data catalog cards: simplifying article/data
        linking ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/data-catalog-cards-simplifying-article-data-linking/\"
        />\n\t\t<id>https://doi.org/10.53731/r79xk11-97aq74v-ag5ca</id>\n        <published>2016-05-13T00:00:00.000+00:00</published>\n\t\t<updated>2023-07-02T07:49:28.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/medium_message.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/medium_message.png\"></p><p>Data
        citation is core to DataCite's mission and DataCite is involved in several
        projects that try to facilitate data citation, including <a href=\"https://project-thor.eu/\">THOR</a>,
        <a href=\"https://www.force11.org/group/dcip\">Data Citation Implementation
        Pilot (DCIP)</a>, <a href=\"https://rd-alliance.org/\">Research Data Alliance
        (RDA)</a>, and <a href=\"http://www.copdess.org/\">COPDESS</a>. The biggest
        roadblock for wider data citation adoption might be insufficient incentives
        for individual researchers, but another major challenge is that implementing
        data citation is still too complicated.</p><figure class=\"kg-card kg-image-card
        kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/Citation_needed_stickers.png\"
        class=\"kg-image\" alt=\"Citation needed. By User:Tfinc (Own work) CC BY-SA
        3.0, via Wikimedia Commons\" loading=\"lazy\" width=\"660\" height=\"495\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/Citation_needed_stickers.png
        600w, https://blog.front-matter.io/content/images/2022/08/Citation_needed_stickers.png
        660w\"><figcaption><a href=\"https://commons.wikimedia.org/wiki/File%3ACitation_needed_stickers.jpeg\">Citation
        needed</a>. By User:Tfinc (Own work) <a href=\"http://creativecommons.org/licenses/by-sa/3.0\">CC
        BY-SA 3.0</a>, via Wikimedia Commons</figcaption></figure><p>When we talk
        about data citation, we typically mean two related, but different scenarios:</p><ol><li>an
        article or other scholarly work cites an already published dataset.</li><li>all
        data and related metadata underlying the findings reported in a submitted
        manuscript should be deposited in an appropriate public repository (<a href=\"http://journals.plos.org/plosone/s/data-availability\">PLOS
        data availability statement</a>)</li></ol><p>The first scenario is not conceptually
        different from an article citing another article, where the common practice
        is to put everything that is cited into the reference list.</p><p>The second
        scenario is probably not only more common, but also requires more complex
        workflows, e.g. coordination of issuing persistent identifiers for article
        and data and linking them together via metadata. And we as a community are
        still working on common practices for doing this. Assuming again that incentives
        are the biggest driver of change, I would argue that researchers, publishers,
        and funders are all interested in making this work, but that data repositories
        have the strongest motivation to improve the current situation. If this is
        true then we should give data repositories a bigger role in the publication
        of data associated with an article.</p><p>While many publishers host supplementary
        information for articles, they leave the hosting of more complex research
        data to external data repositories specialized in this task. Properly referencing
        all associated data in the article is currently the job of the publisher,
        and I propose that we give more of this responsibility to the data repository.
        The data repository can create a data catalog card (with associated persistent
        identifier and metadata) that describes all data associated with an article.
        The data catalog card is a collection of metadata, and different from a data
        paper. The data described in the catalog card can be hosted in that repository
        or elsewhere.</p><p>The publisher then links to this data catalog card via
        the article metadata and can display the catalog card formatted as a data
        availability statement. The publisher could (and should) still link to individual
        data where appropriate, but the proposed solution helps solve several important
        issues:</p><ul><li>the data catalog card simplifies manuscript submission
        for publishers</li><li>the data record provides a machine-readable representation
        of the data availability statement that publishers are increasingly requiring</li><li>the
        publisher doesn't need to provide machine-readable metadata for all data used
        in an article, but can reference the data catalog card. Accession numbers
        that are not globally unique can be used in the article if they are properly
        referenced in the data catalog card. This facilitates the transition from
        current practices</li><li>some articles refer to thousands of datasets (e.g.
        genomics papers), and this number of links is difficult to describe in the
        traditional article format (e.g. <a href=\"http://jats.nlm.nih.gov/\">JATS</a>)</li></ul><p>Several
        general purpose data repositories already provide most or all of this functionality,
        I am most familiar with <a href=\"https://www.datadryad.org/\">Dryad</a>,
        BioStudies (McEntyre, Sarkans, &amp; Brazma, <a href=\"https://blog.datacite.org/data-catalog-cards-simplifying-article-data-linking/#ref-https://doi.org/10.15252/msb.20156658\">2015</a>)
        and Figshare (Hyndman, <a href=\"https://blog.datacite.org/data-catalog-cards-simplifying-article-data-linking/#ref-https://figshare.com/blog/Unveiling_figshare_Collections_a_new_way_to_group_content/202\">2016</a>).
        Data catalog cards probably work best for repositories that a flexible in
        the kinds of data they take, and repositories that already have integrations
        with publishers. Not every data repository needs to support this functionality.
        Data catalog cards are also an opportunity for differentiation, e.g. by providing
        data curation, help with data review, etc.</p><p>My thinking about this topic
        was triggered by a conversation with <a href=\"https://researchers.mgh.harvard.edu/profile?profile_id=1667831\">Tim
        Clark</a> in the context of the DCIP project. The guest post by Dan S. Katz
        (Katz, <a href=\"https://blog.datacite.org/data-catalog-cards-simplifying-article-data-linking/#ref-https://blog.datacite.org/to-better-understand-research-communication-we-need-a-groid-group-object-identifier\">2016</a>)
        and the discussion around it was another important motivation, and a DataCite
        blog post from last August (Fenner, <a href=\"https://blog.datacite.org/data-catalog-cards-simplifying-article-data-linking/#ref-https://blog.datacite.org/reference-lists-and-tables-of-content\">2015</a>)
        contains some of the ideas expressed here. Obviously this topic is of great
        interest to DataCite, as we hope that data catalog cards use DataCite DOIs,
        and that we can help both with making article/data publishing workflows easier,
        and with discovering data associated with an article.</p><p><em>This blog
        post was <a href=\"https://doi.org/10.5438/cab5-teg0\">originally published</a>
        on the DataCite Blog.</em></p><h2 id=\"references\">References</h2><p>Fenner
        M. Reference Lists and Tables of Content. Published online August 15, 2015.
        doi:<a href=\"https://doi.org/10.5438/5AEG-WEEV\">10.5438/5AEG-WEEV</a></p><p>Unveiling
        figshare \u201CCollections\u201D - a new way to group content. Accessed July
        2, 2023. <a href=\"https://figshare.com/blog/Unveiling_figshare_Collections_a_new_way_to_group_content/202\">https://figshare.com/blog/Unveiling_figshare_Collections_a_new_way_to_group_content/202</a></p><p>Katz
        DS. To better understand research communication, we need a GROUPID (group
        object identifier). Published online April 17, 2016. doi:<a href=\"https://doi.org/10.5438/SHR4-2BS2\">10.5438/SHR4-2BS2</a></p><p>McEntyre
        J, Sarkans U, Brazma A. The BioStudies database. <em>Molecular Systems Biology</em>.
        2015;11(12):847. doi:<a href=\"https://doi.org/10.15252/msb.20156658\">10.15252/msb.20156658</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Thinking about CSV ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/thinking-about-csv/\" />\n\t\t<id>https://doi.org/10.53731/r79xbr1-97aq74v-ag5ar</id>\n
        \       <published>2016-05-04T00:00:00.000+00:00</published>\n\t\t<updated>2023-08-06T12:58:05.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2023/08/garden_gnome_berlin.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2023/08/garden_gnome_berlin.png\"></p><p>This
        week some of us from DataCite are attending <a href=\"http://csvconf.com/\">CSVconf</a>
        in Berlin, and we are a conference sponsor and co-organizer.</p><blockquote>csv,conf
        is a non-profit community conference run by some folks who really love data
        and sharing knowledge. If you are as passionate about data and the application
        it has to society as us then you should join us in Berlin!</blockquote><p>One
        important reason we are at CSVconf is that providing persistent identifiers
        and starndard metadata for research data, which in most cases are stored in
        tabular data formats such as CSV, is central to what DataCite is doing. And
        while DataCite provides a searchable index of metadata for these datasets,
        getting the metadata into the index is not as frictionless as one would hope.</p><p>The
        presentations and informal discussions at the conference have been very valuable
        and entertaining so far, and we still have most of the second day ahead. My
        personal highlight from the first day: <a href=\"https://twitter.com/blahah404\">Richard
        Smith-Unna</a> talking about <strong><strong>Easy, massive-scale reuse of
        scientific outputs</strong></strong>.</p><p>One topic that I have been thinking
        about the past two days is how to add metadata to CSV files while keeping
        the simplicity of the format. This is important for DataCite, as we want to
        make the process of registering datasets with metadata painless, and for individual
        researchers and small research groups the process should be as simple as possible.
        Two groups have done great work in this area and Jeni Tennison and Dan Fowler
        gave presentations about their work at CSVconf:</p><ul><li><strong><strong>Jeni
        Tennison</strong></strong>: Making CSV part of the web, describing the work
        of the <a href=\"https://www.w3.org/2013/csvw/wiki/Main_Page\">CSV on the
        Web</a> W3C working group</li><li><strong><strong>Dan Fowler</strong></strong>:
        Data Packages and Frictionless Data for Research, talking about the work Open
        Knowledge has done on defining <a href=\"https://frictionlessdata.io/data-packages/\">data
        packages</a></li></ul><p>Both groups use a JSON file to describe the metadata
        of an associated CSV file. While it is a straightforward process, it still
        feels as if we are leaving the simplicity of the CSV format. And when we generate
        a JSON file to describe the metadata, we might as well convert the CSV into
        JSON and put the metadata into the same file.</p><p><a href=\"https://doi.org/10.53731/r79tfth-97aq74v-ag53f\">Back
        in September</a> I wrote about a different approach: adding the metadata directly
        to the CSV file. The following slides summarize this work:</p><!--kg-card-begin:
        html--><iframe class=\"speakerdeck-iframe\" frameborder=\"0\" src=\"https://speakerdeck.com/player/0485d6ed325144bcb155f771e6bfd842\"
        title=\"CSVY \u2013  CSV reimagined\" allowfullscreen=\"true\" style=\"border:
        0px; background: padding-box padding-box rgba(0, 0, 0, 0.1); margin: 0px;
        padding: 0px; border-radius: 6px; box-shadow: rgba(0, 0, 0, 0.2) 0px 5px 40px;
        width: 100%; height: auto; aspect-ratio: 560 / 420;\" data-ratio=\"1.3333333333333333\"></iframe><!--kg-card-end:
        html--><p>CSVY uses a <a href=\"https://jekyllrb.com/docs/frontmatter/\">YAML
        header</a> for the metadata. This keeps the CSV file human readable, and is
        extensible to add even complex metadata. The downside is of course that it
        breaks the CSV format, but many CSV parsers support comments and can skip
        lines at the beginning of a file. Implementing CSVY support would thus only
        be a small step, and should be backwards compatible in many cases. You can
        for example use Excel to open these files, of course not parsing the metadata
        in the YAML header.</p><p>The beauty of this approach from a DataCite perspective
        is that we can now build a workflow where sending a single CSVY file to an
        appropriate API is all that is needed to deposit a CSV file into a data repository,
        and register a DOI with metadata for it.</p><p>There are obviously synergies
        with <a href=\"http://commonmark.org/\">CommonMark</a>, <em>a strongly defined,
        highly compatible specification of Markdown</em>. Markdown is a lightweight
        markup format for text documents, similar to CSV being a lightweight format
        for data. Tables is one of the things in markdown that are not really lightweight,
        and CommonMark doesn't (yet) include a syntax for table formatting. We could
        use CSVY to make tables really simple in markdown. The metadata for the table
        can be added to the YAML header (something that is commonly used for markdown
        documents), and the CSV can be added directly to the markdown file. I use
        <code>,,,</code> to indicate that this is a table.</p><pre><code>,,,CSVconf
        Speakers\nid,name,title\nrsmithunna,Richard Smith-Unna,\"Easy, massive-scale
        reuse of scientific outputs\"\namoser,Aurelia Moser,\"This is Not a Map: Building
        Interactive Maps with CSVs, Creative Themes, and Curious Geometries\"\ntdoehman,Till
        Doehmen,There and back again - Automatic detection and conversion of logical
        table structures\n,,,</code></pre><p>Alternatively we might want to read in
        the CSV from an external file, using a tag that could look like this:</p><pre><code>,[CSVconf
        Speakers](/_data/speakers.csvy)</code></pre><p>CSVY is compatible with <a
        href=\"https://www.w3.org/2013/csvw/wiki/Main_Page\">CSV on the Web</a> and
        <a href=\"https://frictionlessdata.io/specs/data-package/\">data packages</a>
        described above as it should be easy to convert the CSVY file with YAML header
        into a CSV file and JSON file with the metadata, and then host the two files
        on the web using the CSV on the Web recommendations.</p><p>CSVY is not meant
        to cover all use cases for CSV files, but should be useful to many people
        working with CSV. The critical factor is of course tool support in languages
        that commonly are used to work with CSV files, e.g. Python, R, and Javascript.
        I learned today that the <a href=\"https://cran.r-project.org/web/packages/rio/index.html\">rio
        package for R</a> is supporting CSVY, so that is a great start. For more information
        about CSVY go to <a href=\"http://csvy.org/\">http://csvy.org</a>.</p><p><em>This
        blog post was <a href=\"https://doi.org/10.5438/4qx3-rp8y\">originally published</a>
        on the DataCite Blog.</em></p><h3 id=\"references\">References</h3><p>Fenner
        M. Using YAML Frontmatter with CSV. Published online September 3, 2015. doi:<a
        href=\"https://doi.org/10.53731/r79tfth-97aq74v-ag53f\">10.53731/r79tfth-97aq74v-ag53f</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ We were out in Force ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/we-were-out-in-force/\" />\n\t\t<id>https://doi.org/10.53731/r79ys5h-97aq74v-ag5gj</id>\n
        \       <published>2016-04-19T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-15T09:22:25.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/impactstory.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/impactstory.png\"></p><p>This
        week most of the DataCite staff is attending the <a href=\"https://www.force11.org/meetings/force2016\">Force16</a>
        conference in Portland, Oregon. Force16 brings together a large group of people
        who either already work with DataCite in one way or another, or are doing
        interesting projects of relevance to DataCite.</p><p><a href=\"https://impactstory.org/\">ImpactStory</a>
        is a non-profit that helps scientists learn where their research is being
        cited, shared, saved and more. Ten days ago ImpactStory <a href=\"http://blog.impactstory.org/new-better-freer/\">launched
        a new version</a> that is built all around ORCID IDs and DOIs. Both the data
        and the software running the service are open, and the new version integrates
        naturally with the ORCID/DOI integrations that DataCite is working on as part
        of the <a href=\"https://project-thor.eu/\">THOR project</a>. The ImpactStory
        co-founders Jason Priem and Heather Piwowar are both attending Force16 and
        we had a great conversation on how the new ImpactStory could be integrated
        with what DataCite is doing.</p><p><a href=\"https://github.com/\">GitHub</a>
        is a popular repository for software source code, and GitHub staff member
        <a href=\"https://github.com/arfon\">Arfon Smith</a> is at Force16 as co-chair
        of the Force11 <a href=\"https://www.force11.org/group/software-citation-working-group\">Software
        Citation Working Group</a>. In the past two years we have seen an increasing
        number of DOIs (currently about 7,200) <a href=\"https://guides.github.com/activities/citable-code/\">minted
        for archived versions of GitHub software releases</a>, deposited mainly in
        the <a href=\"https://zenodo.org/\">Zenodo</a> repository. Just as we want
        to use DOIs to make it easier for software to become part of the scholarly
        record, we want to link GitHub and ORCID accounts to facilitate the recognition
        of scientific software engineers in the current scholarly ecosystem.</p><p>The
        latest version of the <a href=\"https://profiles.datacite.org/\">DataCite
        Profiles</a> service released today has added support for ImpactStory and
        GitHub. If you have an orcid with publications in it you can see a summary
        from ImpactStory in DataCite Profiles, and a direct link will send you to
        your ImpactStory profile page. You can now link your GitHub account via OAuth
        authentication, linking the ORCID identifier used by DataCite Profiles with
        the GitHub username.</p><p>To try out this new functionality, go to the <a
        href=\"https://profiles.datacite.org/\">DataCite Profiles</a> service, and
        then after login to your <a href=\"https://profiles.datacite.org/settings/me\">Settings</a>.
        And sign up with Impactstory and GitHub if you haven't done so already.</p><p><em>This
        blog post was <a href=\"https://doi.org/10.5438/c3by-vyzs\">originally published</a>
        on the DataCite Blog.</em></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ It&#x27;s all about Relations ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/its-all-about-relations/\" />\n\t\t<id>https://doi.org/10.53731/r79xf41-97aq74v-ag5bc</id>\n
        \       <published>2016-04-14T18:52:00.000+00:00</published>\n\t\t<updated>2023-09-07T08:20:33.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/oak_ridge.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/oak_ridge.png\"></p><p>In
        a <a href=\"https://blog.datacite.org/location-of-the-citation/\">guest post</a>
        two weeks ago Elizabeth Hull explained that only 6% of Dryad datasets associated
        with a journal article are found in the reference list of that article, data
        she also presented at the IDCC conference in February (Mayo, Hull, &amp; Vision,
        <a href=\"https://blog.datacite.org/its-all-about-relations/#ref-https://doi.org/10.5281/zenodo.32412\">2015</a>).
        This number has increased from 4% to 8% between 2011-2014, but is still low.
        One important reason is missing incentives: we don't yet have the same automated
        citation linking between articles and data that exists between articles thanks
        to <a href=\"http://www.crossref.org/\">Crossref</a>.</p>\n<p>Wouldn't it
        be nice if a data publisher such as the Oak Ridge National Laboratory is automatically
        informed about journal articles citing one of their datasets?</p>\n<p>The
        challenge: both DataCite and Crossref collect metadata as part of the respective
        DOI registration services they provide. These metadata describe the information
        required for a citation (title, authors, publication date, etc.) (DataCite
        Metadata Working Group, <a href=\"https://blog.datacite.org/its-all-about-relations/#ref-https://doi.org/10.5438/0010\">2014</a>).
        And the metadata can contain references to related resources. But what is
        missing is an automated exchange of the information collected by Crossref
        and DataCite.</p>\n<p>We can't simply store information coming from Crossref
        in the DataCite Metadata Store (<a href=\"https://mds.datacite.org/\">MDS</a>)
        for two reasons:</p>\n<ol><li>Only the organization publishing the DOI can
        update the metadata, and it is important to keep it this way to to have a
        single authoritative source.</li><li>The DataCite MDS stores information about
        DataCite DOIs, but can't store metadata (again title, authors, publication
        date, etc.) for other resources such as Crossref DOIs.</li></ol>\n<p>DataCite
        thus needs a service to enhance its DataCite Metadata Store (MDS). Data citations
        are the most important use case, but his service should be flexible enough
        to also handle information coming from other providers besides Crossref, for
        example claims of DataCite DOIs in the ORCID registry or links of DataCite
        DOIs to code repositories such as Github.</p>\n<p>The new service is called
        <a href=\"https://eventdata.test.datacite.org/\">DataCite Event Data</a>,
        and the screenshot above shows six data citations coming from Crossref. The
        software powering the service is called <a href=\"http://www.lagotto.io/\">Lagotto</a>,
        open source software originally developed in 2009 by the Open Access publisher
        <a href=\"http://www.plos.org/\">Public Library of Science</a>. While Lagotto
        provides the basic functionality needed for the Event Data service, significant
        development effort was required to enable the full functionality described
        above. This work was done, and will continue, in close collaboration with
        Crossref, as Crossref wants to address similar use cases. Although the core
        Crossref infrastructure is built around citation linking of publications,
        Crossref is working on <a href=\"http://blog.crossref.org/2016/02/event-data-open-for-your-interpretation.html\">registering
        other online events associated with Crossref DOIs</a>, e.g. a Wikipedia page
        referencing one or more journal articles.</p>\n<p>This Tuesday we released
        version 5 of the Lagotto software (Fenner et al., <a href=\"https://blog.datacite.org/its-all-about-relations/#ref-https://doi.org/10.5281/ZENODO.49516\">2016</a>)
        with support for what we need for the Event Data service. The release would
        not have been possible without developer <a href=\"https://github.com/afandian\">Joe
        Wass</a> from Crossref. The list of changes is long and can be read about
        in detail in the <a href=\"https://github.com/lagotto/lagotto/releases/tag/v.5.0.1\">release
        notes</a>. The highlights include:</p>\n<ol><li>A <strong>deposits</strong>
        API allowing anyone with a valid API key to push events into the system using
        a JSON object which can be (almost) as simple as</li></ol>\n<pre><code>{ \"subj_id\":
        \"https://doi.org/10.1098/rspb.2015.2857\",\n  \"obj_id\": \"https://doi.org/10.5061/DRYAD.7BQ5T\",\n
        \ \"relation_type_id\": \"cites\",\n  \"sourceid\": \"europepmc_fulltext\"
        }</code></pre>\n<ol><li>A <strong>contributor</strong> model to aggregate
        resources by contributor, using the ORCID ID as persistent identifier.</li><li>Support
        for <strong>Github</strong>, describing the relations between software release,
        code repository, and repository owner, for the by now more than 7,000 DataCite
        DOIs for software linked to a Github release.</li></ol>\n<p>In the coming
        months DataCite and Crossref will continue developing the platform to build
        out their Event Data services, so stay tuned for updates. And if you don\u2019t
        mind minor bugs and incomplete data (currently about 1.2 million events for
        about 400,000 DataCite DOIs), take a look at <a href=\"https://eventdata.test.datacite.org/\">DataCite
        Event Data</a> and send us your feedback.</p>\n<figure class=\"kg-card kg-image-card
        kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/lagotto.jpeg\"
        class=\"kg-image\" alt=\"A real life lagotto. Credit: Anke B\xFCter and Najko
        Jahn (Exeter)\" loading=\"lazy\" width=\"800\" height=\"1067\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/lagotto.jpeg
        600w, https://blog.front-matter.io/content/images/2022/08/lagotto.jpeg 800w\"
        sizes=\"(min-width: 720px) 720px\"><figcaption><b><strong>A real life lagotto</strong></b><span>.
        Credit: Anke B\xFCter and Najko Jahn (Exeter)</span></figcaption></figure>\n<h2
        id=\"acknowledgments\">Acknowledgments</h2>\n<p>This blog post was <a href=\"https://doi.org/10.5438/pe54-zj5t\">originally
        published</a> on the DataCite Blog.</p>\n<h2 id=\"references\">References</h2>\n<p>DataCite
        Metadata Working Group. DataCite Metadata Schema for the Publication and Citation
        of Research Data v3.1: Documentation. Published online 2014:38 pages. doi:<a
        href=\"https://doi.org/10.5438/0010\">10.5438/0010</a></p>\n<p>Fenner M, Wass
        J, Song J, et al. Lagotto 5.0.1. Published online April 12, 2016. doi:<a href=\"https://doi.org/10.5281/ZENODO.49516\">10.5281/ZENODO.49516</a></p>\n<p>Mayo
        C, Hull EA, Vision TJ. The Location Of The Citation: Changing Practices In
        How Publications Cite Original Data In The Dryad Digital Repository. Published
        online October 19, 2015. doi:<a href=\"https://doi.org/10.5281/ZENODO.32412\">10.5281/ZENODO.32412</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Launching the DataCite Status Page ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/launching-the-datacite-status-page/\"
        />\n\t\t<id>https://doi.org/10.53731/r79y8rh-97aq74v-ag5ew</id>\n        <published>2016-01-11T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-15T09:25:40.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/subscribe-to-incidents.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/subscribe-to-incidents.png\"></p><p>As
        a provider of crucial scholarly infrastructure, it is critical that DataCite
        not only provides a reliable service, but also <a href=\"https://www.crossref.org/blog/problems-with-dx.doi.org-on-january-20th-2015-what-we-know./\">properly
        communicates problems</a>. The best way to do this is via a central status
        page, a best practice used by many organizations from <a href=\"https://status.github.com/\">Github</a>
        and <a href=\"https://status.disqus.com/\">Diqus</a> to <a href=\"https://status.slack.com/\">Slack</a>.
        Because you don't want to run the status page with the rest of your infrastructure
        (as the page may go down if there is a problem), many organizations use a
        third-party service.</p><p>Today DataCite is launching a status page for all
        its services at <a href=\"http://status.datacite.org/\">http://status.datacite.org</a>.
        You can also reach the status page via the navigation menu  in the upper right
        corner of recently launched DataCite services. Below is more information about
        the main features of the service.</p><h2 id=\"services-status\">Services status</h2><p>At
        the top of the status page we provide an overview of the status of all our
        services.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/services-overview-1.png\"
        class=\"kg-image\" alt=\"Services Overview\" loading=\"lazy\" width=\"956\"
        height=\"483\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/services-overview-1.png
        600w, https://blog.front-matter.io/content/images/2022/08/services-overview-1.png
        956w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Services Overview</figcaption></figure><p>We
        will update the status manually when there is an issue, possible values are</p><ul><li>Operational</li><li>Degraded
        Performance</li><li>Partial Outage</li><li>Major Outage</li></ul><p>The overall
        status at the top of the page reflects these changes.</p><h2 id=\"live-system-metrics\">Live
        system metrics</h2><p>The DataCite status page shows the aggregated uptime
        for all DataCite services. The data are generated by sending an HTTP/HTTPS
        request to each service from different locations around the world every 30
        sec (using <a href=\"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover.html\">Amazon
        AWS Route 53 Health Checks</a> and aggregation of data in <a href=\"https://www.librato.com/\">Librato</a>).</p><figure
        class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/live-metrics.png\"
        class=\"kg-image\" alt=\"Live Metrics\" loading=\"lazy\" width=\"977\" height=\"350\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/live-metrics.png
        600w, https://blog.front-matter.io/content/images/2022/08/live-metrics.png
        977w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Live Metrics</figcaption></figure><h2
        id=\"incidents\">Incidents</h2><p>Incidents such as service downtime will
        be reported with incident status (Investigating|Identified|Monitoring|Resolved)
        and time. This information will remain available after incidents are resolved
        on an incident history page.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/incidents.png\"
        class=\"kg-image\" alt=\"Incidents\" loading=\"lazy\" width=\"914\" height=\"173\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/incidents.png
        600w, https://blog.front-matter.io/content/images/2022/08/incidents.png 914w\"
        sizes=\"(min-width: 720px) 720px\"><figcaption>Incidents</figcaption></figure><h2
        id=\"scheduled-maintenance\">Scheduled maintenance</h2><p>The status page
        will inform users about scheduled maintenance such as server upgrades requiring
        server downtime.</p><h2 id=\"notifications\">Notifications</h2><p>Subscribing
        to updates via email, Twitter or RSS feed is the best way to stay informed
        about any issues affecting availability of DataCite services. You can do this
        by clicking on the <strong><strong>Subscribe to Updates</strong></strong>
        button:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/subscribe-to-incidents-1.png\"
        class=\"kg-image\" alt=\"Subscribe to incidents via email, Twitter or RSS\"
        loading=\"lazy\" width=\"963\" height=\"302\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/subscribe-to-incidents-1.png
        600w, https://blog.front-matter.io/content/images/2022/08/subscribe-to-incidents-1.png
        963w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Subscribe to incidents
        via email, Twitter or RSS</figcaption></figure><p>All DataCite mailing lists
        will automatically be notified. Please contact us by email if you want to
        integrate the DataCite service status information via API into your own services.</p><h2
        id=\"report-a-problem\">Report a problem</h2><p>If you encounter a problem
        with one of the DataCite services despite the status page not showing any
        issues, please report the problem by sending an email to <a href=\"mailto:support@datacite.org\">DataCite
        Support</a>. Please always use this email address to make it easier for us
        to keep track of problem reports.</p><p><em>This blog post was <a href=\"https://doi.org/10.5438/yhcj-p5hr\">originally
        published</a> on the DataCite Blog.</em></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Announcing the DataCite Blog Relaunch ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/announcing-the-datacite-blog-relaunch/\"
        />\n\t\t<id>https://doi.org/10.53731/r79szbh-97aq74v-ag4ze</id>\n        <published>2015-12-28T00:00:00.000+00:00</published>\n\t\t<updated>2023-09-07T08:29:33.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2023/09/typewriter-1.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2023/09/typewriter-1.png\"></p><p>The
        DataCite blog has migrated to a new platform, from a hosted version at <a
        href=\"https://ghost.org/\">Ghost</a> to a self-hosted version using <a href=\"https://jekyllrb.com/\">Jekyll</a>.
        The main reason for this change is that it gives us more control over the
        formatting of blog posts. The migration was easy as both Ghost and Jekyll
        use <a href=\"http://support.ghost.org/markdown-guide/\">markdown</a> to format
        blog posts, and the blog post URLs haven't changed.</p>\n<p>Other than some
        layout changes that make the blog look and feel more consistent with other
        DataCite sites, the other main difference that users will see is that the
        blog now uses formal citations and reference lists for scholarly content.
        A September blog post (Fenner, <a href=\"https://blog.datacite.org/announcing-blog-relaunch/#ref-https://blog.datacite.org/adding-references-to-the-datacite-blog\">2015</a>)
        described the background for this, and a good example where you can see the
        change is the post summarizing the September persistent identifier workshop
        in Paris (Cruse, <a href=\"https://blog.datacite.org/announcing-blog-relaunch/#ref-https://blog.datacite.org/recap\">2015</a>).</p>\n<p>Below
        are some tips if you also want to add formal references to your blog:</p>\n<ol><li>Use
        markdown format and Jekyll with <a href=\"http://pandoc.org/\">Pandoc</a>
        to convert markdown to html. You can add Pandoc support to Jekyll by adding
        <code>gem 'jekyll-pandoc'</code> to the Jekyll Gemfile and the following into
        <code>_config.yml</code>:</li></ol>\n<pre><code>pandoc:\n  extensions:\n    -
        normalize\n    - smart\n    - mathjax\n    - csl: _styles/apa.csl\n    - bibliography:
        bibliography/references.bib</code></pre>\n<p>The DataCite blog uses the <a
        href=\"http://www.apastyle.org/\">APA citation style</a> and stores the references
        in BibTex format. Pandoc uses the <a href=\"http://citationstyles.org/\">Citation
        Style Language</a>, so it is easy to switch to any of the 5000+ available
        styles.</p>\n<ol><li>You can use <a href=\"https://pages.github.com/\">Github
        Pages</a> to host the blog, but if you want to use <code>https</code>, and/or
        more flexibility with caching and domain names I recommend <a href=\"https://aws.amazon.com/s3/\">Amazon
        S3</a>. Unless your blog sees a lot of traffic I doubt that the monthly cost
        is more than $2-5. One other advantage is that you don't have to deal with
        multiple git branches \u2013 which is how Github Pages stores the deployed
        website \u2013 as this can be confusing.</li><li>Jekyll is a static site generator,
        i.e. all blog pages are generated as HTML and no database backend is needed.
        You can build and deploy to S3 from your local computer, but I highly recommend
        to use a continuous integration tool for this. DataCite uses <a href=\"https://travis-ci.com/\">Travis
        CI</a>, which is free to use for open source projects. Travis CI has nice
        support for deployment to Amazon S3, rebuilding all pages and deploying to
        Amazon S3 takes about three minutes, and is triggered when we commit new code
        (e.g. a new blog post) to the <a href=\"https://github.com/datacite/blog\">blog</a>
        git repository. For testing new features we deploy the <code>test</code> git
        branch to <a href=\"https://blog.test.datacite.org/\">https://blog.test.datacite.org</a>.</li><li>Since
        the <code>1.15.2</code> release in November Pandoc supports <code>://</code>
        in citation keys. This makes it easy to generate consistent citation keys
        using the <code>URL</code> field as the key, in particular when sharing references
        with others. One nice side effect is that we can use this key (which Pandoc
        puts into the <code>data-cites</code> attribute of the generated HTML) to
        generate a link from the in-text citation with a little bit of Javascript,
        e.g. this one: (Cruse, <a href=\"https://blog.datacite.org/announcing-blog-relaunch/#ref-https://blog.datacite.org/recap\">2015</a>).</li></ol>\n<p>This
        blog post is not only the last post on this blog in 2015 but also the 25th
        post since we launched this blog in August, a nice little milestone at the
        end of the year. We wish all readers a great start into the new year.</p>\n<h2
        id=\"acknowledgments\">Acknowledgments</h2>\n<p>This blog post was <a href=\"https://doi.org/10.5438/xcbj-g7zy\">originally
        published</a> on the DataCite Blog.</p>\n<h2 id=\"references\">References</h2>\n<p>Cruse
        P. Recap: Persistent Identifiers in Paris. Published online October 4, 2015.
        doi:<a href=\"https://doi.org/10.5438/85SN-MX23\">10.5438/85SN-MX23</a></p>\n<p>Fenner
        M. Adding References to the DataCite Blog. Published online September 16,
        2015. doi:<a href=\"https://doi.org/10.53731/r796n5h-97aq74v-ag4fn\">10.53731/r796n5h-97aq74v-ag4fn</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Infrastructure Tips for the Non-Profit Startup
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/infrastructure-tips-for-the-non-profit-startup/\"
        />\n\t\t<id>https://doi.org/10.53731/r7971ah-97aq74v-ag4gw</id>\n        <published>2015-12-23T00:00:00.000+00:00</published>\n\t\t<updated>2023-07-02T10:08:47.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-12-23-um-11-26-47.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-12-23-um-11-26-47.png\"></p><p>When
        I started as DataCite Technical Director four months ago, my first post (Fenner,
        <a href=\"https://blog.datacite.org/tips-for-the-non-profit-startup/#ref-https://blog.datacite.org/data-driven-development\">2015</a>)
        on this blog was about what I called <strong><strong>Data-Driven Development</strong></strong>.
        The post included a lot of ideas on how to approach development and technical
        infrastructure. In this post I want to take a second look.</p><p>While I think
        the ideas expressed in the blog post are still true, I also learned that the
        focus of a Technical Director working for a small non-profit is somewhere
        else. The main challenge might be to properly run infrastructure and technical
        development with limited resources, both in terms of staff and money. While
        DataCite isn't a startup (the organization turned six years old this month),
        we face many of the same challenges. And as a non-profit, we can't take the
        approach of the typical startup, which in the early stages might have a small
        staff, but usually can spend more money than it is taking in.</p><h3 id=\"automate-as-much-as-possible\">Automate
        as much as possible</h3><p>The biggest cost is obviously staff, so it is very
        important to automate the technical infrastructure as much as possible. Luckily
        many powerful services and best practices have been developed in the last
        few years, under the umbrella term <a href=\"http://theagileadmin.com/what-is-devops/\">DevOps</a>.
        The first step is to go with a cloud infrastructure provider rather than hosting
        your own servers. While the cost seems higher on paper, it is much easier
        to automate infrastructure using a cloud provider if you have a small technical
        team. DataCite infrastructure has been hosted by <strong><strong>Amazon Web
        Services</strong></strong> (AWS) since the beginning, and we currently see
        have no plans to change that.</p><p>A large number of tools integrate with
        AWS, three services that have become essential for DataCite in the past few
        months are <a href=\"https://terraform.io/\">Terraform</a>, <a href=\"https://www.packer.io/\">Packer</a>
        and <a href=\"https://blog.datacite.org/tips-for-the-non-profit-startup/\">Chef</a>:</p><ul><li><strong><strong>Terraform</strong></strong>
        treats infrastructure as code and allows us to have our AWS configuration
        (EC2 instances, Virtual Private Network, Security Groups, etc.) managed with
        a set of configuration files stored in a private git repo, e.g.</li></ul><pre><code>resource
        \"aws_route_table\" \"production\" {\n    vpc_id = \"${aws_vpc.production.id}\"\n
        \   route {\n        cidr_block = \"0.0.0.0/0\"\n        gateway_id = \"${aws_internet_gateway.production.id}\"\n
        \   }\n\n    tags {\n        Name = \"production\"\n    }\n}\n\nresource \"aws_main_route_table_association\"
        \"production\" {\n    vpc_id = \"${aws_vpc.production.id}\"\n    route_table_id
        = \"${aws_route_table.production.id}\"\n}\n\nresource \"aws_route_table_association\"
        \"production\" {\n    subnet_id = \"${aws_subnet.production.id}\"\n    route_table_id
        = \"${aws_route_table.production.id}\"\n}\n\nresource \"aws_security_group\"
        \"production\" {\n  name = \"production\"\n  description = \"production\"\n
        \ vpc_id = \"${aws_vpc.production.id}\"</code></pre><ul><li><strong><strong>Packer</strong></strong>
        automates the creation of machine and container images. We use Packer to automatically
        build Amazon Machine Images (AMIs) that we then deploy as EC2 instances using
        terraform</li></ul><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-12-23-um-11-29-50.webp\"
        class=\"kg-image\" alt=\"Packer\" loading=\"lazy\" width=\"774\" height=\"507\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/Bildschirmfoto-2015-12-23-um-11-29-50.webp
        600w, https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-12-23-um-11-29-50.webp
        774w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Packer</figcaption></figure><ul><li><strong><strong>Chef</strong></strong>
        for automated configuration management. We use Chef to help Packer build AMIs.</li></ul><pre><code>==&gt;
        default: [2015-12-22T23:03:53+00:00] INFO: template[/etc/nginx/sites-enabled/dlm.conf]
        updated file contents /etc/nginx/sites-enabled/dlm.conf\n==&gt; default:\n==&gt;
        default: - update content in file /etc/nginx/sites-enabled/dlm.conf from c2a428
        to fe08d6\n==&gt; default:\n==&gt; default: --- /etc/nginx/sites-enabled/dlm.conf
        \ 2015-12-22 22:31:52.136854399 +0000\n==&gt; default:\n==&gt; default: +++
        /etc/nginx/sites-enabled/.dlm.conf20151222-13309-1bw1o6p 2015-12-22 23:03:53.161869265
        +0000\n==&gt; default:\n==&gt; default: @@ -1,4 +1,4 @@\n==&gt; default:\n==&gt;
        default: -upstream $backend {\n==&gt; default:</code></pre><p>Terraform, Packer
        and Chef are open source. We use <a href=\"https://hashicorp.com/atlas.html\">Atlas</a>
        (commercial, but free for small installations) to combine them into a web-based
        team workflow. We hope to complete the migration for all DataCite services
        in the coming months.</p><h3 id=\"think-carefully-about-build-vs-buy\">Think
        carefully about Build vs. Buy</h3><p>A common approach in the commercial startup
        world is to focus on the particular product or service that the organization
        wants to build, and then outsource almost everything else. This is important
        when there is only a small number of staff and you want to move fast. While
        this approach also applies to non-profit organizations, the decision of <strong><strong>build
        vs. buy</strong></strong> will sometimes be different, because some of these
        outsourced services would just be too expensive, or create a lock-in that
        would be a problem later on.</p><p>But for the most part I think the risk
        of trying to build too much yourself is bigger, in particular since many external
        services have monthly plans, and there are often several alternatives. The
        biggest consideration is the risk of lock-in, which is of course what all
        service providers are aiming for.</p><h3 id=\"open-source-where-it-is-important\">Open
        Source where it is important</h3><p>The software written by DataCite staff
        to run the DataCite services is all open source, hosted in a <a href=\"https://github.com/datacite\">public
        Github repository</a>. This is important for a number of reasons, best explained
        in the Principles of Open Scholarly Infrastructures (Bilder, Lin, &amp; Neylon,
        <a href=\"https://blog.datacite.org/tips-for-the-non-profit-startup/#ref-https://doi.org/10.6084/M9.FIGSHARE.1314859\">2015</a>).
        One nice side effect is that a number of important external services are free
        for open source projects, for example Github or the <a href=\"https://travis-ci.org/\">Travis
        CI</a> continuous integration service.</p><p>What this doesn't mean is that
        all software that DataCite uses should be open source. I like the approach
        that ORCID has taken in the ORCID Principles (\u201COur principles,\u201D
        <a href=\"https://blog.datacite.org/tips-for-the-non-profit-startup/#ref-https://orcid.org/about/what-is-orcid/principles\">2011</a>):</p><blockquote>All
        software developed by ORCID will be publicly released under an Open Source
        Software license approved by the Open Source Initiative. For the software
        it adopts, ORCID will prefer Open Source.</blockquote><p>Some of the services
        mentioned above (e.g. Google Apps, Slack, AWS) are obviously not open source,
        and that is ok if they don't create a lock-in or serious dependency for running
        the DataCite infrastructure. An interesting approach is hosted open source
        software, such as this blog. We are currently paying <a href=\"https://ghost.org/\">ghost.org</a>
        a small amount of money to host the blog for us, but we can always move the
        blog somewhere else or start hosting it ourselves. Our use of AWS is more
        complex, but similar, all the software (databases, web servers, etc.) we are
        running is open source, and we can move to a different hosting provider if
        that is ever needed.</p><h3 id=\"get-non-profit-discounts\">Get Non-Profit
        Discounts</h3><p>Some organizations provide their infrastructure services
        for free or a discount to non-profit organizations. DataCite started using
        <a href=\"https://apps.google.com/\">Google Apps</a> and <a href=\"https://slack.com/\">Slack</a>
        in August. Both are free for eligible non-profits, for other services such
        as <a href=\"https://products.office.com/en-us/nonprofit/office-365-nonprofit\">Office
        365</a> we get a deep discount.</p><p>Slack has become an essential internal
        communication tool. Not only because the current five staff members are in
        three different countries, but also because Slack nicely integrates with a
        large number of services. This greatly helps with keeping everyone on the
        same page.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-12-23-um-11-26-47-1.png\"
        class=\"kg-image\" alt=\"Slack\" loading=\"lazy\" width=\"775\" height=\"355\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/Bildschirmfoto-2015-12-23-um-11-26-47-1.png
        600w, https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-12-23-um-11-26-47-1.png
        775w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Slack</figcaption></figure><h3
        id=\"start-small-but-make-changes-easy\">Start small but make changes easy</h3><p>One
        trap you can fall into is to think too big when starting out. You should build
        or buy what you need now or in the near future. At the same time you should
        make sure that whatever solution you come up with will scale up when needed.</p><p>There
        are a number of services out there that provide wonderful value, but are not
        really appropriate for a small non-profit. They solve problems of much larger
        organizations, e.g. auto-scaling of servers or centralized data analytics.</p><h3
        id=\"cooperate-with-other-non-profit-organizations\">Cooperate with other
        non-profit organizations</h3><p>One important advantage that non-profits have
        over commercial startups is that it is easier for them to cooperate with other
        organizations. In the case of DataCite this primarily means with DataCite
        members and CrossRef.</p><p>Cooperation takes time and effort, and staff time
        is usually limited when you are a small organization and also have a lot of
        technical work on your plate. But it is still a worthwhile investment. And
        I think non-profit organizations in the scholarly communication space could
        cooperate much more. While there are many cooperations around specific projects
        and initiatives, I think most of the basics of running the organization, and
        the technical infrastructure in particular, are not really discussed much.
        Small non-profits such as DataCite face particular challenges that are different
        from both commercial organizations and larger non-profits such as academic
        institutions. I want to spend more time in 2016 working on this, so please
        contact me if you are interested to help.</p><p><em>This blog post was <a
        href=\"https://doi.org/10.5438/t0ap-d5w7\">originally published</a> on the
        DataCite Blog.</em></p><h2 id=\"references\">References</h2><p>Bilder G, Lin
        J, Neylon C. Principles for Open Scholarly Infrastructures-v1. Published online
        2015:35186 Bytes. doi:<a href=\"https://doi.org/10.6084/M9.FIGSHARE.1314859\">10.6084/M9.FIGSHARE.1314859</a></p><p>Fenner
        M. Data-Driven Development. Published online August 3, 2015. doi:<a href=\"https://doi.org/10.53731/r79tt01-97aq74v-ag55w\">10.53731/r79tt01-97aq74v-ag55w</a></p><p>About
        ORCID. Accessed July 2, 2023. <a href=\"https://info.orcid.org/what-is-orcid/\">https://info.orcid.org/what-is-orcid/</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Announcing the DataCite Profiles Service
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/announcing-the-datacite-profiles-service/\"
        />\n\t\t<id>https://doi.org/10.53731/r79tcr1-97aq74v-ag52m</id>\n        <published>2015-11-09T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-15T09:30:42.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-11-09-um-20-02-45-1.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-11-09-um-20-02-45-1.png\"></p><p>DataCite
        Labs today is launching the <a href=\"https://profiles.datacite.org/\">DataCite
        Profiles</a> service, a central place for users to sign in with DataCite,
        using their ORCID credentials.</p><p>The first version of DataCite Profiles
        focusses on integration with ORCID via the <strong><strong>Search &amp; Link</strong></strong>
        and <strong><strong>Auto-Update</strong></strong> services, described in a
        <a href=\"https://blog.datacite.org/explaining-the-datacite-orcid-auto-update/\">previous
        blog post</a>. When users first sign-in, or when they go to their Settings
        page (accessible via the navigation menu in the upper right corner), they
        are presented with these two choices for adding their works to their ORCID
        record:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-11-09-um-20-02-45-1-1.png\"
        class=\"kg-image\" alt=\"ORCID Auto-Updated\" loading=\"lazy\" width=\"2000\"
        height=\"323\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/Bildschirmfoto-2015-11-09-um-20-02-45-1-1.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/08/Bildschirmfoto-2015-11-09-um-20-02-45-1-1.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2022/08/Bildschirmfoto-2015-11-09-um-20-02-45-1-1.png
        1600w, https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-11-09-um-20-02-45-1-1.png
        2000w\" sizes=\"(min-width: 720px) 720px\"><figcaption>ORCID Auto-Updated</figcaption></figure><p><strong><strong>Auto-Update</strong></strong>
        still needs a bit more work and hasn't launched yet, but by signing up for
        the Profiles service users give DataCite permission to automatically update
        their ORCID record with works with DataCite DOIs that include their ORCID
        identifier.</p><p><strong><strong>Search &amp; Link</strong></strong> can
        be started from the Settings page and automatically searches the DataCite
        Metadata Store for any of the name variants given in the ORCID record.</p><p>Together
        with the Profiles service we are launching a new common navigation bar with
        links to the most common services and a place to sign in.</p><figure class=\"kg-card
        kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-11-09-um-20-14-22.png\"
        class=\"kg-image\" alt=\"Search\" loading=\"lazy\" width=\"2000\" height=\"263\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/Bildschirmfoto-2015-11-09-um-20-14-22.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/08/Bildschirmfoto-2015-11-09-um-20-14-22.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2022/08/Bildschirmfoto-2015-11-09-um-20-14-22.png
        1600w, https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-11-09-um-20-14-22.png
        2264w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Search</figcaption></figure><p>DataCite
        Profiles, <a href=\"https://search.test.datacite.org/\">DataCite Labs Search</a>
        and the DataCite Labs Link Store already support this common layout, and other
        DataCite services will be added over time.</p><p>DataCite Profiles uses JSON
        Web Tokens (<a href=\"http://jwt.io/\">JWT</a>) to provide a single-sign on
        service for DataCite. JWT are an attractive alternative to setting up an OAuth
        provider for this use case. We use them to share additional profile information
        such as the user role across DataCite services.</p><p>The Profiles service
        currently does not provide authenticated access to other DataCite services
        such as the DataCite <strong><strong>Metadata Store</strong></strong>. And
        we currently only support sign-in via ORCID, not via other third-party providers
        such as Google, and not by username/password. As always we appreciate your
        feedback regarding issues and feature requests. Like all core DataCite services
        Profiles was written as an open source application, and can be found at <a
        href=\"https://github.com/datacite/volpino\">https://github.com/datacite/volpino</a>.</p><p><em>This
        blog post was <a href=\"https://doi.org/10.5438/15x1-bj6r\">originally published</a>
        on the DataCite Blog.</em></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Explaining the DataCite/ORCID Auto-update
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/explaining-the-datacite-orcid-auto-update/\"
        />\n\t\t<id>https://doi.org/10.53731/r79tzg1-97aq74v-ag56j</id>\n        <published>2015-10-29T00:00:00.000+00:00</published>\n\t\t<updated>2023-09-07T08:28:19.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-10-29-um-11-01-37-1.webp\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-10-29-um-11-01-37-1.webp\"></p><p>This
        Monday ORCID, CrossRef and DataCite announced (<a href=\"http://blog.orcid.org/blog/2015/10/26/auto-update-has-arrived-orcid-records-move-next-level\">ORCID
        post</a>, <a href=\"https://www.crossref.org/blog/auto-update-has-arrived-orcid-records-move-to-the-next-level/\">CrossRef
        post</a>, <a href=\"https://blog.datacite.org/auto-update-has-arrived/\">DataCite
        post</a>) the new auto-update service that automatically pushes metadata to
        ORCID when an ORCID identifier is found in newly registered DOI names.</p>\n<p>This
        is the first joint announcement by the three organizations, and shows the
        close collaboration between ORCID, CrossRef and DataCite. A good opportunity
        to learn more about these joint activities are the <a href=\"https://orcid.org/content/sf2015\">ORCID
        Outreach Meeting in San Francisco</a> November 3-4, and the <a href=\"https://www.crossref.org/crossref-live-annual/archive/\">CrossRef
        Annual Meeting in Boston</a> November 17-18.</p>\n<p>As promised in the Monday
        blog post, I want to explain the DataCite implementation of the ORCID auto-update
        functionality in a separate blog post. To start with the bad news: the DataCite
        service isn't ready yet, and will launch in November. There are two reasons
        for this: CrossRef started to work on this functionality much earlier, and
        \u2013 more importantly \u2013 DataCite feels that we need to make some major
        architectural changes in our systems to implement this properly. The good
        news is that the architectural changes will give us a more solid foundation
        for additional features we can add over time. Let me explain the most important
        issues below.</p>\n<h2 id=\"permissions\">Permissions</h2>\n<p>In order to
        update an ORCID record, an organization needs permission from the researcher
        who owns the record. These permissions can be short-lived for a specific update,
        or long-lived for many years. The latter is obviously the preferred option
        for the auto-update functionality.</p>\n<p>DataCite is already collecting
        permissions to update ORCID records from our <a href=\"https://search.datacite.org/\">Search
        and Link service</a> and we want to continue collecting permissions for the
        Auto-update service in the same place. To do this properly, we will launch
        a new Profiles service. It will act as a central place to interact with DataCite
        services. In the first version it will focus on ORCID permissions, but we
        can build this out over time with additional functionality. The service is
        currently under testing, we hope to launch <strong>Labs Profiles</strong>
        next week.</p>\n<p>One unresolved issue with the current implementation is
        that DataCite has to use the same ORCID client credentials for both the Search
        and Link and Auto-update services. This makes it impossible to distinguish
        self-claims by a researcher coming in from the Search and Link service, and
        links coming in from the Auto-update service. CrossRef's has an ORCID membership
        that allows them to use separate client credentials for Search and Link and
        Auto-update. We are working with ORCID to solve this.</p>\n<h2 id=\"multiple-sources\">Multiple
        Sources</h2>\n<p>Another challenge is the synchronization between the Search
        and Link and Auto-update services. ORCID records can contain multiple claims
        for the same DOI, e.g. from Search and Link, Auto-update, and possibly also
        other sources. Here is an example from my ORCID record with claims from Europe
        PubMed Central, CrossRef Metadata Search and Scopus:</p>\n<figure class=\"kg-card
        kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-10-29-um-11-01-37.webp\"
        class=\"kg-image\" alt=\"ORCID record\" loading=\"lazy\" width=\"1858\" height=\"616\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/Bildschirmfoto-2015-10-29-um-11-01-37.webp
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/08/Bildschirmfoto-2015-10-29-um-11-01-37.webp
        1000w, https://blog.front-matter.io/content/images/size/w1600/2022/08/Bildschirmfoto-2015-10-29-um-11-01-37.webp
        1600w, https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-10-29-um-11-01-37.webp
        1858w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span>ORCID record</span></figcaption></figure>\n<p>It
        is important for DataCite to allow claims from multiple sources, and to show
        the provenance of every item in a person's ORCID record. The way the Search
        and Link service currently works (and <a href=\"http://search.crossref.org/\">CrossRef
        Metadata Search</a> and <a href=\"http://search.test.datacite.org/\">DataCite
        Labs Search</a> use the same <a href=\"https://github.com/crosscite/doi-metadata-search\">codebase</a>
        for this) is that researchers can only add a claim to their ORCID records
        if that DOI is not yet claimed, even if the claim comes from another source.
        This is a pragmatic decision, as researchers will probably resort to self-claiming
        only for items that were not automatically added to their profiles. With the
        launch of Auto-update we need to rethink this approach, possibly allowing
        users to claim all works that have not yet been claimed via the Search and
        Link service.</p>\n<h2 id=\"push-api\">Push API</h2>\n<p><a href=\"https://support.orcid.org/hc/en-us/articles/360006972953\">Notifications</a>
        are an essential feature of ORCID's Auto-update. They allow CrossRef and DataCite
        to push information to the ORCID record of a person without prior permission.
        The ORCID record owner receives a message in his/her inbox and has the opportunity
        to decide whether or not to accept the claim(s).</p>\n<p>The way DataCite's
        end is implemented results in an information push to ORCID whenever an ORCID
        is found in our metadata. There is a big overlap between this functionality
        and what we do in the Search and Link service: authentication with ORCID,
        background workers for processing, XML generation, error tracking, etc. Therefore
        we want to move this functionality to a centralised place, separate from the
        core Search and Link and Auto-update functionalities. While the current focus
        is on pushing information to ORCID, we could build similar notification services
        for other organizations in the future, e.g. pushing information to a funder
        whenever we find a grant identifier in newly issued DOI names. The above requires
        refactoring of the Search and Link code and it is currently underway.</p>\n<h2
        id=\"round-trip\">Round-trip</h2>\n<p>Auto-update is a milestone in automating
        the workflow of linking ORCID identifiers and DOI names. What is still missing
        is the opposite direction: telling publishers and data centres about links
        to their DOIs found in the ORCID registry, e.g. via self-claiming services
        such as Search and Link. This is relevant for already published works, and
        for publishers and data centres that have not yet integrated ORCID into their
        submission systems.</p>\n<p>The ORCID registry focusses on a researcher view,
        i.e. the works associated with a particular researcher. We also need the inverse
        here, a service that shows all ORCID identifiers associated with a particular
        DOI. This information can be very helpful for publishers and data centres,
        as they can take this information, verify it, and add it to their internal
        systems and to the metadata they send to CrossRef or DataCite. DataCite is
        working with ORCID and CrossRef on this. We have aggregated this information
        for all 205,000 DataCite DOI names that are linked to at least one ORCID identifier.
        We found a total of about one million links (because most DOI names are linked
        to multiple ORCID identifiers) and a surprisingly small number of ORCID identifiers
        (about 2,500) responsibles for these one million links. Or maybe not so surprising
        if you remember <a href=\"https://blog.datacite.org/digging-into-data-using-r/\">this
        August blog post</a>.</p>\n<p>Please provide feedback regarding auto-update
        in the comments. We will follow-up with a new blog post in a few weeks when
        the DataCite Auto-update service has launched.</p>\n<h2 id=\"acknowledgments\">Acknowledgments</h2>\n<p>This
        blog post was originally published on the <a href=\"https://doi.org/10.5438/3dfw-z4kq\"
        rel=\"noreferrer\">DataCite Blog</a>, <a href=\"http://blog.orcid.org/blog/2015/10/26/auto-update-has-arrived-orcid-records-move-next-level\"
        rel=\"noreferrer\">ORCID blog</a>, and <a href=\"https://www.crossref.org/blog/auto-update-has-arrived-orcid-records-move-to-the-next-level/\"
        rel=\"noreferrer\">CrossRef blog</a>.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Auto-Update Has Arrived! ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/auto-update-has-arrived/\" />\n\t\t<id>https://doi.org/10.53731/r796hz1-97aq74v-ag4f3</id>\n
        \       <published>2015-10-26T00:00:00.000+00:00</published>\n\t\t<updated>2023-09-20T08:09:13.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/graph.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/graph.png\"></p><p><em>We
        will follow up with a blog post later this week explaining the DataCite auto-update
        implementation.</em></p>\n<p>Since ORCID\u2019s inception, our key goal has
        been to unambiguously identify researchers and provide tools to automate the
        connection between researchers and their creative works. We are taking a big
        step towards achieving this goal today, with the launch of <a href=\"http://orcid.org/blog/2014/11/21/new-functionality-friday-auto-update-your-orcid-record\">Auto-Update</a>
        functionality in collaboration with <a href=\"http://www.crossref.org/\">Crossref</a>
        and <a href=\"https://www.datacite.org/\">DataCite</a>.</p>\n<p>There\u2019s
        already been a lot of excitement about Auto-Update: <a href=\"https://www.crossref.org/blog/crossref-to-auto-update-orcid-records/\">Crossref\u2019s
        recent announcement</a> about the imminent launch generated a flurry of discussion
        and celebration on social media. Our own <a href=\"https://twitter.com/ORCID_Org/status/647020600192581633\">tweet</a>
        on the topic was viewed over 10,500 times and retweeted by 60 other accounts.</p>\n<p>So
        why all the fuss? We think Auto-Update will transform the way researchers
        manage their scholarly record. Until now, researchers have had to manually
        maintain their record, connecting new activities as they are made public.
        In ORCID, that meant using <a href=\"https://support.orcid.org/hc/en-us/articles/360006973653-Add-works-by-direct-import-from-other-systems\">Search
        &amp; Link</a> tools developed by our member organizations to claim works
        manually. Researchers frequently ask, \u201CWhy, if I include my ORCID iD
        when I submit a manuscript or dataset, isn\u2019t my ORCID record \u201Cautomagically\u201D
        updated when the work is published?\u201D</p>\n<p>With the launch of Auto-Update,
        that is just what will happen.</p>\n<p><strong>It might seem like magic but
        there are a few steps to make it work</strong>:</p>\n<ul><li><strong>Researchers</strong>.
        You need to do two things: (1) use your ORCID iD when submitting a paper or
        dataset, and (2) authorize Crossref and DataCite to update your ORCID record.
        In keeping with our commitment to ensuring that researchers maintain full
        control of their ORCID record, you may revoke this permission at any time,
        and may also choose privacy settings for the information posted on your record.</li><li><strong>Publishers
        and data centers</strong>. These organizations also have two things to do:
        (1) collect ORCID identifiers during the submission workflow, using a process
        that involves authentication (not a type-in field!), and (2) embed the iD
        in the published paper and include the iD when submitting information to Crossref
        or DataCite.</li><li><strong>Crossref and DataCite</strong>. Upon receipt
        of data from a publisher or data center with a valid identifier, Crossref
        or DataCite can automatically push that information to the researcher\u2019s
        ORCID record. More information about how to opt out of this service can be
        found here: <a href=\"https://support.orcid.org/hc/en-us/articles/360006972953\">the
        ORCID Inbox</a>.</li></ul>\n<h3 id=\"why-is-this-so-revolutionary\">Why is
        this so revolutionary?</h3>\n<p>A bit of background, first. Crossref and DataCite,
        both non-profit organizations, are leaders in minting DOIs (Digital Object
        Identifiers) for research publications and datasets. A <a href=\"http://www.crossref.org/01company/16fastfacts.html#sthash.o7NGwOnP.dpuf\">DOI</a>
        is a unique alphanumeric string assigned to a digital object \u2013 in this
        case, an electronic journal article, book chapter, or a dataset. Each DOI
        is associated with a set of basic metadata and a URL pointer to the full text,
        so that it uniquely identifies the content item and provides a persistent
        link to its location on the internet.</p>\n<p>Crossref, working with over
        a thousand scholarly publishers, has generated well over 75 million DOIs for
        journal articles and book chapters. DataCite works with nearly 600 data centers
        worldwide and has generated over 6.5 million DOIs to date. Between them, Crossref
        and DataCite have already received almost half a million works from publishers
        and data centers that include an ORCID iD validated by the author/contributor.
        With Auto-Update functionality in place, information about these articles
        can transit (with the author\u2019s permission) to the author\u2019s ORCID
        record.</p>\n<p>Auto-Update doesn\u2019t stop at a researcher\u2019s ORCID
        record. Systems that have integrated ORCID APIs and have a researcher\u2019s
        ORCID record connected to that system -- their faculty profile system, library
        repository, webpage, funder reporting system -- can receive alerts from ORCID.
        Information can move easily and unambiguously across systems.</p>\n<p>This
        is the beginning of the end for the endless rekeying of information that plagues
        researchers -- and anyone involved in research reporting. Surely something
        to celebrate!</p>\n<p><strong>Questions you may have</strong>:</p>\n<h4 id=\"q-what-do-i-need-to-do-to-sign-up-for-auto-update\">Q.
        What do I need to do to sign up for auto-update?</h4>\n<p>You need to grant
        permission to Crossref and DataCite to post information to your ORCID record.
        You can do this today by using the Search and Link wizard for DataCite available
        through the ORCID Registry or the <a href=\"https://search.datacite.org/\">DataCite
        Search</a> page. We also have added a new ORCID Inbox, so that you can receive
        a message from Crossref or DataCite if they receive a datafile with your iD,
        and you can grant permission directly. See <a href=\"https://support.orcid.org/hc/en-us/articles/360006972953\">more
        on the ORCID Inbox</a>.</p>\n<h4 id=\"q-will-crossref-and-datacite-be-able-to-update-my-orcid-record-with-already-published-works-for-which-i-did-not-use-my-orcid-id\">Q.
        Will Crossref and DataCite be able to update my ORCID record with already
        published works for which I did not use my ORCID iD?</h4>\n<p>No. The auto-update
        process only applies to those works that these organizations receive that
        include your ORCID iD. For previous works that did not include your ORCID
        iD, you will need to use the DataCite and Crossref Search and Link wizards
        to connect information with your iD.</p>\n<h4 id=\"q-what-information-will-be-posted-to-my-record\">Q.
        What information will be posted to my record?</h4>\n<p>With your permission,
        basic information about the article (such as title, list of contributors,
        journal, or publisher) or dataset (such as data center name and date of publication)
        will be posted, along with a DOI that allows users to navigate to the source
        paper or dataset landing page.</p>\n<h4 id=\"q-what-if-my-journal-or-data-center-doesn%E2%80%99t-collect-orcid-ids\">Q.
        What if my journal or data center doesn\u2019t collect ORCID iDs?</h4>\n<p>Ask
        them too! This simple step can be accomplished using either the Public or
        Member ORCID APIs. Information about integrating ORCID iDs in <a href=\"http://members.orcid.org/publisher-workflow\">publishing</a>
        and <a href=\"http://members.orcid.org/repository-systems\">repository</a>
        workflows is publicly available.</p>\n<h3 id=\"acknowledgments\">Acknowledgments</h3>\n<p>This
        blog post was <a href=\"https://doi.org/10.5438/ferw-cwhq\">originally published</a>
        on the DataCite blog and has been cross-posted from the <a href=\"https://info.orcid.org/auto-update-has-arrived-orcid-records-move-to-the-next-level/\"
        rel=\"noreferrer\">ORCID blog</a>. </p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Happy Birthday ORCID ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/happy-birthday-orcid/\" />\n\t\t<id>https://doi.org/10.53731/mgt0y-0hj40</id>\n
        \       <published>2015-10-16T00:00:00.000+00:00</published>\n\t\t<updated>2023-09-01T21:44:54.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2023/09/birthday.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2023/09/birthday.png\"></p><p>Three
        years ago today Open Researcher &amp; Contributor ID (<a href=\"http://orcid.org/\">ORCID</a>)
        launched its service at the Outreach Meeting in Berlin. One of many tweets
        from the launch day:</p><figure class=\"kg-card kg-embed-card\"><blockquote
        class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">Congrats to <a href=\"https://twitter.com/ORCID_Org?ref_src=twsrc%5Etfw\">@orcid_org</a>
        the ORCID registry is live (<a href=\"http://t.co/2lxn0nLa\">http://t.co/2lxn0nLa</a>)
        NPG is a proud launch partner (PR): <a href=\"http://t.co/9eiqe44x\">http://t.co/9eiqe44x</a></p>&mdash;
        Nature Research (@nresearchnews) <a href=\"https://twitter.com/nresearchnews/status/258256101676564480?ref_src=twsrc%5Etfw\">October
        16, 2012</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\"
        charset=\"utf-8\"></script>\n</figure><p>Executive Director Laure Haak was
        written a nice <a href=\"http://orcid.org/blog/2015/10/15/celebrating-our-third-anniversary\">blog
        post</a> summarizing the achievements in the past few years, going from 0
        to 1.7 million registered users, 400 members, and a staff of 20. Congratulations!</p><p>On
        October 17, a day after the ORCID launch, DataCite started to work with ORCID
        in the European Commission-funded ORCID and DataCite Interoperability Network
        <a href=\"http://odin-project.eu/\">ODIN</a>, a project that has laid the
        groundwork for the integration of both the two services, and associated datasets.
        DataCite is continuing work with ORCID in the follow-up project <a href=\"http://project-thor.eu/\">THOR</a>
        that started in June, and there will soon be an exciting announcement about
        a new integration of the two services.</p><p>This birthday has a special meaning
        for me, as I was a member of the ORCID Board at the time, and had helped organize
        the launch event in Berlin, as well as the kickoff meeting of the ODIN project,
        and a well-attended German-language <a href=\"https://dini.de/veranstaltungen/workshops/autorenidentifikation/\">event
        on author identification</a> in the same venue two days before the launch,
        co-organized by <a href=\"https://dini.de/\">DINI</a> and the Helmholtz Association.
        It is really amazing how far we have come since then.</p><p>Thank you ORCID
        for all your great contributions!</p><p><em>This blog post was <a href=\"https://doi.org/10.5438/c61q-z2k7\">originally
        published</a> on the DataCite Blog.</em></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Software Citation Workflows ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/software-citation-workflows/\" />\n\t\t<id>https://doi.org/10.53731/r796bk1-97aq74v-ag4dq</id>\n
        \       <published>2015-10-15T00:00:00.000+00:00</published>\n\t\t<updated>2023-09-07T08:27:06.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-10-18-um-14-01-39.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-10-18-um-14-01-39.png\"></p><p><em>This
        blog post provides more detail for a short presentation I will give today
        at the <a href=\"http://www.software.ac.uk/software-credit\"><em>Software
        Credit Workshop</em></a> in London. The aim is to look at the infrastructure
        pieces needed for software discovery and credit, and at the workflows linking
        these different parts of the infrastructure.</em></p>\n<h2 id=\"code-repository\">Code
        Repository</h2>\n<p>Code repositories are the places where the actual work
        on software takes place, and for scientific software this often means that
        it happens in public with the use of an open license. Code repositories are
        increasingly integrated with additional services from issue trackers to continuous
        integration testing.</p>\n<figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/code_repositories.webp\"
        class=\"kg-image\" alt=\"Code repositories\" loading=\"lazy\" width=\"675\"
        height=\"371\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/code_repositories.webp
        600w, https://blog.front-matter.io/content/images/2022/08/code_repositories.webp
        675w\"><figcaption><span>Code repositories</span></figcaption></figure>\n<p>One
        big problem with code repositories is that they are not intended as long-term
        archives for code. Github and Bitbucket didn't even exist 8 years ago, and
        Google Code will be <a href=\"http://google-opensource.blogspot.de/2015/03/farewell-to-google-code.html\">shut
        down in January 2016</a>.</p>\n<h2 id=\"data-repository\">Data Repository</h2>\n<p>Long-term
        archiving of software is best done in dedicated data repositories, the two
        most popular in terms of DataCite DOIs are <a href=\"https://zenodo.org/\">Zenodo</a>
        (close to <a href=\"https://search.datacite.org/?query=%2A&amp;resourceType_facet=Software&amp;datacentre_facet=CERN.ZENODO+-+ZENODO+-+Research.+Shared.\">5000</a>
        DOIs for software) and <a href=\"https://nanohub.org/\">NanoHub</a> (about
        <a href=\"https://search.datacite.org/?query=%2A&amp;resourceType_facet=Software&amp;datacentre_facet=PURDUE.EZID+-+Purdue+University\">2,000</a>
        DOIs for software). NanoHub uses the open source <a href=\"https://hubzero.org/\">HubZero</a>
        software that integrates a subversion code repository, whereas Zenodo has
        built an integration with Github, described in this <a href=\"https://guides.github.com/activities/citable-code/\">guide</a>.</p>\n<figure
        class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-10-18-um-14-01-39-1.png\"
        class=\"kg-image\" alt=\"Making your code citable\" loading=\"lazy\" width=\"1970\"
        height=\"1226\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/Bildschirmfoto-2015-10-18-um-14-01-39-1.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/08/Bildschirmfoto-2015-10-18-um-14-01-39-1.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2022/08/Bildschirmfoto-2015-10-18-um-14-01-39-1.png
        1600w, https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-10-18-um-14-01-39-1.png
        1970w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span>Making your code
        citable</span></figcaption></figure>\n<p>Providing a long-term archive for
        code is needed to properly cite software, similarly to what we expect for
        research data and scholarly articles. We of course don't have to use DOIs
        for this, but DOIs make citation easier by requiring basic citation metadata,
        are supported by reference managers, and we can provide formatted citations
        via <a href=\"http://www.crosscite.org/\">DOI content negotiation</a>, e.g.
        in <a href=\"https://search.datacite.org/?query=10.5281/ZENODO.32193\">DataCite
        Labs Search</a>:</p>\n<figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-10-18-um-13-59-34.webp\"
        class=\"kg-image\" alt=\"Citation style\" loading=\"lazy\" width=\"1940\"
        height=\"562\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/Bildschirmfoto-2015-10-18-um-13-59-34.webp
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/08/Bildschirmfoto-2015-10-18-um-13-59-34.webp
        1000w, https://blog.front-matter.io/content/images/size/w1600/2022/08/Bildschirmfoto-2015-10-18-um-13-59-34.webp
        1600w, https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-10-18-um-13-59-34.webp
        1940w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span>Citation style</span></figcaption></figure>\n<p>The
        Github/Zenodo integration assigns a DOI to a particular <a href=\"https://github.com/blog/1547-release-your-software\">Github
        release</a> of a software repo. This is perfect for a citation, which should
        be specific for the software version used in a particular research project.
        In addition, users of software and software authors want to know who is citing
        or otherwise re-using all versions of the software. In order for this to work
        we need to think beyond a specific release and link that release to other
        releases and to the Github repository itself. The repository has no DOI attached
        to it in the current workflow, so this has to be done in a service separate
        from the DataCite Metadata Store.</p>\n<h2 id=\"claim-store\">Claim Store</h2>\n<p>We
        can expand the DataCite Data-Level Metrics service or Claim Store <a href=\"https://blog.datacite.org/announcing-data-level-metrics-in-datacite-labs/\">described
        in an earlier post</a> to properly handle Github repositories, and the first
        implementation is <a href=\"https://eventdata.test.datacite.org/\">available
        now</a> in DataCite Labs. Continuing with the earlier example of the Python
        <strong>librosa</strong> library, the DataCite Claim store tracks links between
        release, repository and repository owner:</p>\n<figure class=\"kg-card kg-image-card
        kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-10-18-um-17-40-51.webp\"
        class=\"kg-image\" alt=\"Claim store\" loading=\"lazy\" width=\"836\" height=\"291\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/Bildschirmfoto-2015-10-18-um-17-40-51.webp
        600w, https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-10-18-um-17-40-51.webp
        836w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span>Claim store</span></figcaption></figure>\n<p>These
        links are made available in DataCite Labs Search (<a href=\"https://search.datacite.org/?query=librosa+python\">link</a>),
        so that users can go directly to either the specific release or the code repository
        landing page instead of the archived version on Zenodo:</p>\n<figure class=\"kg-card
        kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-10-18-um-17-40-51-1.webp\"
        class=\"kg-image\" alt=\"Zenodo\" loading=\"lazy\" width=\"836\" height=\"291\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/Bildschirmfoto-2015-10-18-um-17-40-51-1.webp
        600w, https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-10-18-um-17-40-51-1.webp
        836w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span>Zenodo</span></figcaption></figure>\n<p>We
        can use the claim store to not only store those links, but also to track metrics
        around the software package over time, e.g. the number of Github stars and
        forks (349 and 68 for a combined 417 in this case):</p>\n<figure class=\"kg-card
        kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-10-18-um-17-11-46-1.webp\"
        class=\"kg-image\" alt=\"GitHub\" loading=\"lazy\" width=\"1176\" height=\"578\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/Bildschirmfoto-2015-10-18-um-17-11-46-1.webp
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/08/Bildschirmfoto-2015-10-18-um-17-11-46-1.webp
        1000w, https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-10-18-um-17-11-46-1.webp
        1176w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span>GitHub</span></figcaption></figure>\n<p>We
        will be building out this service in the coming months with the goal of tracking
        all software packages with DOIs linked to a Github release. Future iterations
        may also show the number of Github stars and forks directly in the search
        results. And because the Claim Store provides an open API, this information
        can also be integrated in other places, most obviously Zenodo.</p>\n<h2 id=\"language-and-domain-repository\">Language
        and Domain Repository</h2>\n<p>Language-specific repositories hold all software
        packages from a particular language, e.g. <a href=\"https://pypi.python.org/pypi\">pypi</a>
        for Python or <a href=\"https://cran.r-project.org/\">CRAN</a> for R, with
        a search interface for discovery and a specific format that allows for automatic
        installation. Although not all scientific software is submitted to these repositories,
        they are usually the place that software developers go to first for discovery
        and installation, using a package manager working with these repositories.</p>\n<p>Domain-specific
        repositories such as the Astrophysics Source Code Library (<a href=\"http://ascl.net/\">ASCL</a>)
        or <a href=\"https://www.bioconductor.org/\">Bioconductor</a> serve important
        roles for discovery and community building. Both their strength and limitation
        is their domain-specific nature. They complement the source code repositories
        mentioned above. One important function of domain-specific repositories is
        to act as a filter for scientific software. Other approaches to identify software
        as scientific include:</p>\n<ul><li>software that has a DOI (Zenodo, above)</li><li>software
        using specific tags (Depsy, see below)</li><li>software cited in the scholarly
        literature (ScienceToolbox)</li></ul>\n<h2 id=\"metrics-data-provider\">Metrics
        Data Provider</h2>\n<p>Language-specific repositories provide the detailed
        information that is needed to more extensively track reuse of a software package.
        <a href=\"http://depsy.org/\">Depsy</a> is a new software metrics data provider
        by the Impactstory Team that will launch later this month, and will provide
        detailed information about reuse, including citations in the scholarly literature.
        Again using <strong>librosa</strong> as an example, Depsy provides the following
        information:</p>\n<figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-10-18-um-12-14-48.webp\"
        class=\"kg-image\" alt=\"Depsy\" loading=\"lazy\" width=\"1336\" height=\"752\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/Bildschirmfoto-2015-10-18-um-12-14-48.webp
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/08/Bildschirmfoto-2015-10-18-um-12-14-48.webp
        1000w, https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-10-18-um-12-14-48.webp
        1336w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span>Depsy</span></figcaption></figure>\n<p>Of
        particular interest is how Depsy tracks reuse, as the service follows all
        the dependencies and dependencies of dependencies of a software package, described
        as transitive credit by Dan Katz (<a href=\"https://blog.datacite.org/software-citation-workflows/#ref-https://doi.org/10.5334/jors.be\">2014</a>).
        Depsy is currently tracking software packages in <strong>pypi</strong> and
        <strong>CRAN</strong>, and an open API is available. Once Depsy has launched,
        it would of course be of great interest to integrate data from the service
        into the DataCite Claim Store, and Depsy is providing an open API for this.</p>\n<h2
        id=\"acknowledgments\">Acknowledgments</h2>\n<p>This blog post was <a href=\"https://doi.org/10.5438/1h7n-3cen\">originally
        published</a> on the DataCite Blog.</p>\n<h2 id=\"references\">References</h2>\n<p>Transitive
        Credit as a Means to Address Social and Technological Concerns Stemming from
        Citation and Attribution of Digital Products. <em>Journal of Open Research
        Software</em>. 2014;2(1):e20. doi:<a href=\"https://doi.org/10.5334/jors.be\">10.5334/jors.be</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Contributor Information in DataCite Metadata
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/contributor-information-in-datacite-metadata/\"
        />\n\t\t<id>https://doi.org/10.53731/r79vp7h-97aq74v-ag583</id>\n        <published>2015-10-12T00:00:00.000+00:00</published>\n\t\t<updated>2023-09-07T08:15:36.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-10-12-um-08-30-30.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-10-12-um-08-30-30.png\"></p><p>The
        Force11 Joint Declaration of Data Citation Principles (Data Citation Synthesis
        Group, <a href=\"https://blog.datacite.org/contributor-information-in-datacite-metadata/#ref-https://doi.org/10.25490/a97f-egyk\">2014</a>)
        highlight the importance of giving scholarly credit to all contributors:</p>\n<blockquote>Data
        citations should facilitate giving scholarly credit and normative and legal
        attribution to all contributors to the data, recognizing that a single style
        or mechanism of attribution may not be applicable to all data.</blockquote>\n<p>The
        EC-funded <a href=\"http://project-thor.eu/\">THOR project</a> that DataCite
        is involved in addresses these issues, and I have summarized the findings
        of one of our first reports in a <a href=\"https://blog.datacite.org/differences-between-orcid-and-datacite-metadata/\">previous
        blog post</a>. One of problems identified in the report was the use of a single
        entry field for personal names, as done by DataCite and many other scholarly
        services. We need separate fields for family and given names, the most important
        reason is to allow proper formatting of a data citation (different citation
        styles have different rules about author name formatting). As a small first
        step I have implemented proper personal name parsing, using the <a href=\"https://github.com/berkmancenter/namae\">Namae</a>
        tool, in <a href=\"http://search.test.datacite.org/\">DataCite Labs Search</a>
        and the upcoming <a href=\"http://eventdata.test.datacite.org/\">DataCite
        Labs claim store</a>. One of the next places we can implement this is in the
        DOI content negotiation service, where we currently provide personal names
        as literal strings when using an output format that supports family and given
        names (<a href=\"http://data.crosscite.org/application/vnd.citationstyles.csl+json/10.6084/M9.FIGSHARE.791569\">http://data.crosscite.org/application/citeproc+json/10.6084/M9.FIGSHARE.791569</a>):</p>\n<pre><code>{\n
        \ \"type\": \"dataset\",\n  \"DOI\": \"10.6084/M9.FIGSHARE.791569\",\n  \"URL\":
        \"http://dx.doi.org/10.6084/M9.FIGSHARE.791569\",\n  \"title\": \"rOpenSci
        - a collaborative effort to develop R-based tools for facilitating Open Science\",\n
        \ \"publisher\": \"Figshare\",\n  \"issued\": {\n    \"raw\": \"2013\"\n  },\n
        \ \"author\": [{\n    \"literal\": \"Scott Chamberlain\"\n  }, {\n    \"literal\":
        \"Edmund Hart\"\n  }, {\n    \"literal\": \"Karthik Ram\"\n  }, {\n    \"literal\":
        \"Carl Boettiger\"\n  }]\n}</code></pre>\n<p>To correctly identify contributors
        we have to use unique identifiers rather than personal names. The Force11
        Joint Declaration of Data Citation Principles (Data Citation Synthesis Group,
        <a href=\"https://blog.datacite.org/contributor-information-in-datacite-metadata/#ref-https://doi.org/10.25490/a97f-egyk\">2014</a>)
        highlight the importance of unique identifiers for data, and I had suggested
        in an early draft of the principles to also mention the importance of unique
        identifiers for contributors.</p>\n<p><a href=\"http://orcid.org/\">ORCID</a>
        identifiers are by far the most widely used identifiers in DataCite metadata
        \u2013 they can be found in the metadata of about <a href=\"https://search.test.datacite.org/?query=nameIdentifier%3AORCID%5C%3A*\">208,000
        DOI names</a> (other identifiers such as ISNI are also supported). In addition
        there are self-claims of DataCite DOI names in the ORCID registry (e.g. generated
        via the DataCite Search &amp; Link Service that is part of <a href=\"https://search.test.datacite.org/\">Labs
        Search</a>), the exact number of which we currently don't know. DataCite is
        working with ORCID on a frictionless exchange of these DataCite/ORCID links
        in both directions.</p>\n<p>But how are these DataCite/ORCID links shared
        with other services? A good starting point is the DataCite Search API. We
        can include <code>creator</code> and <code>nameIdentifier</code> in the results,
        but unfortunately these two fields are not linked together. Until we update
        the Solr schema for the Search API we therefore have to use the <code>xml</code>
        field that includes all metadata, and parse out the creator names and associated
        identifiers. We have recently implemented this in Labs Search, turning names
        with associated ORCID identifiers into clickable links that return a list
        of all DataCite DOI names associated with that person (<a href=\"http://search.test.datacite.org/?query=10.6084%2FM9.FIGSHARE.791569\">http://search.test.datacite.org/?query=10.6084%2FM9.FIGSHARE.791569</a>):</p>\n<figure
        class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-10-12-um-08-30-30-1.png\"
        class=\"kg-image\" alt=\"Link name via ORCID ID\" loading=\"lazy\" width=\"782\"
        height=\"180\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/Bildschirmfoto-2015-10-12-um-08-30-30-1.png
        600w, https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-10-12-um-08-30-30-1.png
        782w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span>Link name via
        ORCID ID.</span></figcaption></figure>\n<p>Labs Search also provides a <strong>Cite</strong>
        button that formats the metadata according to common citation styles such
        as <strong>APA</strong>, or in common exchange formats such as <strong>BibTeX</strong>.
        These formats unfortunately don't support ORCID identifiers (nothing has changed
        since I wrote about this in 2011), so that the DataCite/ORCID links would
        be lost using these formats.</p>\n<p>Citeproc JSON is a modern alternative
        to BibTeX, RIS and similar exchange formats, and is used as the machine-readable
        representation to format references in the reference managers Zotero, Mendeley,
        Papers (and others) using <a href=\"http://citationstyles.org/\">Citation
        Style Language</a>. Although Citeproc JSON doesn't support ORCID identifiers,
        it is much easier to extend than for example BibTeX, where adding ORCID identifiers
        without breaking the format is difficult to impossible. Last week I implemented
        this modified Citeproc JSON in a new DataCite service I am working on (e.g.
        using the example from above:</p>\n<pre><code>\"author\": [{\n      \"family\":
        \"Chamberlain\",\n      \"given\": \"Scott\",\n      \"ORCID\": \"http://orcid.org/0000-0003-1444-9135\"\n
        \   }, {\n      \"family\": \"Hart\",\n      \"given\": \"Edmund\"\n    },
        {\n      \"family\": \"Ram\",\n      \"given\": \"Karthik\",\n      \"ORCID\":
        \"http://orcid.org/0000-0002-0233-1757\"\n    }, {\n      \"family\": \"Boettiger\",\n
        \     \"given\": \"Carl\",\n      \"ORCID\": \"http://orcid.org/0000-0002-1642-628X\"\n
        \   }]</code></pre>\n<p>DataCite is not the first DOI registration agency
        to implement this, CrossRef is doing the same for some time in their REST
        API, e.g. for <a href=\"http://api.crossref.org/works/10.1111/1365-2745.12293\">http://api.crossref.org/works/10.1111/1365-2745.12293</a>:</p>\n<pre><code>\"author\":
        [{\n  \"affiliation\": [{\n    \"name\": \"Department of Biological Sciences;
        Simon Fraser University; Burnaby BC Canada\"\n  }],\n  \"family\": \"Chamberlain\",\n
        \ \"given\": \"Scott\",\n  \"ORCID\": \"http://orcid.org/0000-0003-1444-9135\"\n},
        {\n  \"affiliation\": [{\n    \"name\": \"CONICET; Instituto Argentino de
        Investigaciones de las Zonas Aridas; Mendoza Argentina\"\n  }, {\n    \"name\":
        \"Instituto de Ciencias B\xE1sicas; Universidad Nacional de Cuyo; Mendoza
        Argentina\"\n  }],\n  \"family\": \"V\xE1zquez\",\n  \"given\": \"Diego P.\"\n},
        {\n  \"affiliation\": [{\n    \"name\": \"School of Biology; University of
        Leeds; Leeds UK\"\n  }, {\n    \"name\": \"Naturalis Biodiversity Center;
        PoBox 9517 Leiden 2300RA The Netherlands\"\n  }],\n  \"family\": \"Carvalheiro\",\n
        \ \"given\": \"Luisa\"\n}, {\n  \"affiliation\": [{\n    \"name\": \"Department
        of Biological Sciences; Simon Fraser University; Burnaby BC Canada\"\n  }],\n
        \ \"family\": \"Elle\",\n  \"given\": \"Elizabeth\"\n}, {\n  \"affiliation\":
        [{\n    \"name\": \"Biology Department; University of Calgary; Calgary AB
        Canada\"\n  }],\n  \"family\": \"Vamosi\",\n  \"given\": \"Jana C.\"\n}]</code></pre>\n<p>You
        see one difference: CrossRef also provides the affiliation, as a list of text
        fields. DataCite metadata also contain an <code>affiliation</code> field.
        This is a text string, ideally DataCite should also support unique identifiers
        for the affiliation, as we already do for <code>HostingInstitution</code>
        which can have a <code>nameIdentifier</code> and <code>nameIdentifierScheme</code>.</p>\n<p>Funding
        information is similar to affiliation in that it is something not related
        to the dataset itself, but to one or more contributors. We could therefore
        encode funding information similar to affiliation, as a <code>funding</code>
        field for each author. The big advantage would be that DataCite and ORCID
        would have consisting funding information, rather than DataCite listing funding
        for works, and ORCID listing funding for people, and no direct connection
        between the two.</p>\n<p>Lastly, we can use Citeproc JSON to describe the
        contributor role of the author. DataCite distinguishes between <code>creator</code>
        \u2013 <em>the main researchers involved in producing the data, or the authors
        of the publication, in priority order</em> \u2013 and <code>contributor</code>
        for other contributions, with a controlled vocabulary for <code>contributorType</code>.
        The THOR report mentioned above (Fenner et al., <a href=\"https://blog.datacite.org/contributor-information-in-datacite-metadata/#ref-https://doi.org/10.5281/ZENODO.30799\">2015</a>)
        goes into detail in the different contributor role vocabularies used by DataCite
        and ORCID (there is little overlap), and also describes <a href=\"https://www.casrai.org/credit.html\">Project
        CRediT</a>, a community initiative to harmonize contributor roles across stakeholders,
        standardizing on 14 common roles. CRediT is closely link to <a href=\"https://www.mozillascience.org/contributorship-badges-a-new-project\">contributorship
        badges</a>, a project started by the Mozilla Science Lab, with an example
        journal article using the CRediT roles and badges <a href=\"http://gigasciencejournal.com/blog/putting-credit-hands-researchers/\">here</a>:</p>\n<figure
        class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-10-12-um-09-39-34.png\"
        class=\"kg-image\" alt=\"Contributor badges\" loading=\"lazy\" width=\"938\"
        height=\"317\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/Bildschirmfoto-2015-10-12-um-09-39-34.png
        600w, https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-10-12-um-09-39-34.png
        938w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span>Contributor badges</span></figcaption></figure>\n<p>Taking
        all the above together, the JSON to describe all this information could look
        similar to the following (some of the data are made up):</p>\n<pre><code>\"author\":
        [{\n      \"affiliation\": [{\n        \"name\": \"Department of Biological
        Sciences; Simon Fraser University; Burnaby BC Canada\",\n        \"ISNI\":
        \"0000-0004-1936-7494\"\n      }],\n      \"funding\": [{\n        \"funder-name\":
        \"Alfred P. Sloan Foundation\",\n        \"funder-identifier\": \"https://doi.org/10.13039/100000879\",\n
        \       \"award-number\": \"555-1212\",\n        \"award-uri\": \"http://www.sloan.org/awards/555-1212\"\n
        \     }],\n      \"family\": \"Chamberlain\",\n      \"given\": \"Scott\",\n
        \     \"ORCID\": \"http://orcid.org/0000-0003-1444-9135\",\n      \"CRediT\":
        [\"conceptualization\", \"writing_initial\", \"writing_review\"]\n    }, {\n
        \     \"family\": \"Hart\",\n      \"given\": \"Edmund\"\n    }, {\n      \"family\":
        \"Ram\",\n      \"given\": \"Karthik\",\n      \"ORCID\": \"http://orcid.org/0000-0002-0233-1757\"\n
        \   }, {\n      \"family\": \"Boettiger\",\n      \"given\": \"Carl\",\n      \"ORCID\":
        \"http://orcid.org/0000-0002-1642-628X\"\n    }]</code></pre>\n<p>The above
        obviously contains a lot more information than the original Citeproc JSON.
        And event though <code>affiliation</code>, <code>funding</code> and <code>CRediT</code>
        are optional fields, this goes beyond the scope of Citeproc JSON, which is
        used to format references, rather than as a generic bibliographic exchange
        format. We should therefore call this JSON differently, and I propose <strong>Crosscite
        JSON</strong>, a common JSON format to describe scholarly works used by the
        DOI registration agencies CrossRef and DataCite. One particular challenge
        will be to strike the right balance between important information that we
        want to share easily, vs. keeping the JSON simple and not move away too much
        from Citeproc JSON, which after all is already implemented in a lot of tools
        and workflows. While the above JSON example looks a bit scary at first, it
        provides the level of detail asked for by institutions and funders, and -
        in contrast to the Data Citation Principles - <em>uses a single mechanism
        of attribution applicable to all scholarly works, including data</em>.</p>\n<h2
        id=\"acknowledgments\">Acknowledgments</h2>\n<p>This blog post was <a href=\"https://doi.org/10.5438/d98m-9125\">originally
        published</a> on the DataCite Blog. This work was funded by the European Union\u2019s
        Horizon 2020 research and innovation programme under&nbsp;<a href=\"https://doi.org/10.3030/654039\"
        rel=\"noreferrer\">grant agreement No.&nbsp;654039</a>.</p>\n<h2 id=\"references\">References</h2>\n<p>Data
        Citation Synthesis Group. (2014). <em>Joint Declaration of Data Citation Principles</em>.
        Force11. <a href=\"https://doi.org/10.25490/A97F-EGYK\">https://doi.org/10.25490/A97F-EGYK</a></p>\n<p>Fenner,
        M., Demeranville, T., Kotarski, R., Vision, T., Rueda, L., Dasler, R., Haak,
        L., &amp; Cruse, P. (2015). <em>D2.1: Artefact, Contributor, And Organisation
        Relationship Data Schema</em>. Zenodo. <a href=\"https://doi.org/10.5281/ZENODO.30799\">https://doi.org/10.5281/ZENODO.30799</a></p>\n<p>Chamberlain,
        S., V\xE1zquez, D. P., Carvalheiro, L., Elle, E., &amp; Vamosi, J. C. (2014).
        Phylogenetic tree shape and the structure of mutualistic networks. <em>Journal
        of Ecology</em>, <em>102</em>(5), 1234\u20131243. <a href=\"https://doi.org/10.1111/1365-2745.12293\">https://doi.org/10.1111/1365-2745.12293</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Discussing the Scholarly Container ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/discussing-the-scholarly-container/\"
        />\n\t\t<id>https://doi.org/10.53731/r79sve1-97aq74v-ag4yt</id>\n        <published>2015-10-02T00:00:00.000+00:00</published>\n\t\t<updated>2023-09-07T08:24:54.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/DALL-E-2022-08-29-21.36.17---An-oil-painting-by-Matisse-of-a-garden-gnome-with-umbrella-in-front-of-Notre-Dame-in-Paris-on-a-sunny-summer-day.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/DALL-E-2022-08-29-21.36.17---An-oil-painting-by-Matisse-of-a-garden-gnome-with-umbrella-in-front-of-Notre-Dame-in-Paris-on-a-sunny-summer-day.png\"></p><p>One
        of my personal highlights in last week's Research Data Alliance (RDA) <a href=\"https://rd-alliance.org/plenary-meetings/rda-sixth-plenary-meeting.html\">6th
        Plenary Meeting</a> in Paris was the <a href=\"https://rd-alliance.org/data-packages-bof-p6-bof-session.html\">Data
        Packages</a> Birds of a Feather (BoF), organized by <a href=\"http://rufuspollock.org/\">Rufus
        Pollock</a> from the Open Knowledge Foundation (<a href=\"https://okfn.org/\">OKFN</a>).
        He highlighted the urgent need for packacking data in a standard format to
        facilitate reuse, and described the extensive work the OKFN has done on <a
        href=\"http://data.okfn.org/doc/data-package\">data packages</a>. A particular
        focus is on packacking CSV files, the most widely used format for exchanging
        data.</p>\n<p>I was sold on the importance of CSV and the idea of packacking
        data in a standard format since attending <a href=\"http://okfnlabs.org/blog/2014/05/05/csv-conf-2014.html\">CSVconf</a>
        (co-organized by Rufus) in July 2014, and have written about this several
        times (<a href=\"https://blog.front-matter.io/posts/roads-not-stagecoaches/\">Build
        Roads not Stagecoaches</a>, <a href=\"https://blog.front-matter.io/posts/reference-lists-and-tables-of-content/\">Reference
        Lists and Tables of Content</a>), most recently a few weeks ago (<a href=\"https://blog.front-matter.io/posts/using-yaml-frontmatter-with-csv/\">Using
        YAML frontmatter with CSV</a>). In the RDA session I suggested two important
        improvements to the OKFN data package format:</p>\n<ul><li><strong>Single
        file.</strong> One very important aspect of packaging is to provide everything
        in a single file, generated by zipping a folder of multiple files. This pattern
        has become very common and is used for example for electronic books (<code>epub</code>),
        Microsoft Word documents (<code>docx</code>), or <a href=\"https://developer.chrome.com/extensions/packaging\">Google
        Chrome extensions</a> (<code>crx</code>).</li><li><strong>Identifier</strong>.
        The OKFN data package spec uses a <code>name</code> attribute to uniquely
        identify the package. This approach falls short because enforcing the uniqueness
        of a human readable identifier requires a registry, and this not part of the
        data package spec. What is needed is a persistent identifier, and DataCite
        obviously has a lot of experience in this area.</li></ul>\n<p>Container-based
        digital infrastructure is a very hot topic thanks to <a href=\"https://www.docker.com/whatisdocker\">Docker</a>,
        and it has become clear that tools and workflows are at least as important
        as the spec for the container itself. If we want to move to scholarly infrastructure
        based on containers, used here interchangeably with packages, we need registries
        for these containers that not only provide globally unique identifiers, but
        also a central index for finding these containers - the <a href=\"https://hub.docker.com/\">Docker
        Hub</a> for scholarly containers. DataCite is providing persistent identifiers
        and standardized metadata for scholarly content with a focus on research data
        and is therefore in a perfect position to become such a registry and in the
        RDA session I therefore said:</p>\n<blockquote>I want DataCite to become a
        registry for data containers</blockquote>\n<p>While data, in particular in
        CSV format, are probably the first and most important use case, containers
        make sense for all scholarly content, and DataCite DOIs are used for text
        documents, images, software, etc. in addition to datasets. For this reason
        I prefer the term <strong>scholarly container</strong> over <strong>data container</strong>.</p>\n<p>As
        important as the containers themselves are tools and services that work with
        them, in particular packing and unpacking. The <code>CSVY</code> format discussed
        here in a <a href=\"https://blog.front-matter.io/posts/using-yaml-frontmatter-with-csv/\">recent
        blog post</a> could be used by an individual as intermediate step towards
        a data container. I see tool support as the critical step that decides whether
        scholarly containers take off as a standard format. Karthik Ram from <a href=\"https://ropensci.org/\">rOpenSci</a>
        attended the session in Paris (and CSV.conf last year) and expressed great
        interest in adding support for scholarly containers in their suite of tools.</p>\n<h2
        id=\"next-steps\">Next Steps</h2>\n<ul><li>specify the work needed for DataCite
        to fully support scholarly containers</li><li>work with Rufus and OKFN, e.g.
        on registry support and packaging into a single file</li><li>work with the
        broader community on supporting scholarly containers: data repositories, reference
        managers, tools to analyze datasets, etc.</li><li>propose a pre-conference
        workshop for the <a href=\"https://www.force11.org/event/force2016-mark-your-calendars\">Force2016
        conference</a> in April 2016. This conference started out as Beyond the PDF
        in 2011, and scholarly containers are a perfect thematic fit.</li></ul>\n<h2
        id=\"acknowledgments\">Acknowledgments</h2>\n<p>This blog post was <a href=\"https://doi.org/10.5438/d9eq-9dga\">originally
        published</a> on the DataCite Blog.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Thoughts on the Research Data Alliance 6th
        Plenary ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/thoughts-on-the-research-data-alliance-6th-plenary/\"
        />\n\t\t<id>https://doi.org/10.53731/r79t8y1-97aq74v-ag51m</id>\n        <published>2015-10-01T17:04:00.000+00:00</published>\n\t\t<updated>2022-08-29T09:46:27.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/DALL-E-2022-08-29-11.44.19---garden-gnome-with-an-umbrella-in-front-of-the-eiffel-tower-ate-as-a-painting-from-monet.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/DALL-E-2022-08-29-11.44.19---garden-gnome-with-an-umbrella-in-front-of-the-eiffel-tower-ate-as-a-painting-from-monet.png\"></p><p>The
        <a href=\"https://www.rd-alliance.org/plenaries/rda-sixth-plenary-meeting-paris-france\">Research
        Data Alliance 6th Plenary</a> last week discussed numerous topics very relevant
        to DataCite. Below is a short subjective list of topics I found interesting.
        If you attended RDA, feel free to add your thoughts in the comments. And if
        you didn't attend, you can still provide feedback.</p><h3 id=\"interoperability-between-persistent-identifiers\">Interoperability
        between Persistent Identifiers</h3><p>The <a href=\"https://rd-alliance.org/ig-pid-p6-meeting-session.html\">Persistent
        Identifiers IG</a> discussed the different persistent identifier activities
        in various RDA working and interest groups. The EC-funded <a href=\"http://project-thor.eu/\">THOR</a>
        project that started in June was presented by Josh Brown from ORCID and Trisha
        Cruse from DataCite. I presented the DataCite perspective on persistent identifier
        interoperability. One important shortcoming of many persistent identifiers
        including DataCite DOI names is that only one organization \u2013 the publisher
        - can update the metadata. What is also needed is a <strong><strong>claim
        store</strong></strong> where multiple organizations and not just the publisher
        can deposit links between different persistent identifiers, e.g. citations,
        funding information, ORCID identifiers, etc. CrossRef and DataCite are working
        on such a claim store (more info <a href=\"https://blog.datacite.org/announcing-data-level-metrics-in-datacite-labs/\">here</a>
        and <a href=\"https://www.crossref.org/blog/det-poised-for-launch/\">here</a>).</p><h3
        id=\"data-repository-registries\">Data repository registries</h3><p>Several
        sessions discussed repositories that collect information about data repositories.
        <a href=\"http://www.re3data.org/\">re3data</a> is one of the more important
        initiatives in this space, and <a href=\"http://www.re3data.org/2015/05/datacite-to-manage-and-develop-re3data-org/\">will
        become a DataCite service in 2016</a>. One critical step is <a href=\"http://www.re3data.org/2015/08/introduction-of-the-re3data-org-persistent-identifier/\">persistent
        identifiers for data repositories</a> that are used across data services,
        including the DataCite Metadata Store.</p><h3 id=\"dynamic-data-citation\">Dynamic
        Data Citation</h3><p>Unfortunately I missed the session of the <a href=\"https://rd-alliance.org/wg-data-citation-p6-meeting-session.html\">Data
        Citation WG</a> - I presented in the parallel <a href=\"https://rd-alliance.org/wg-rdawds-publishing-data-bibliometrics-p6-meeting-session.html\">RDA/WDS
        Publishing Data Bibliometrics WG</a>. But I had interesting discussions about
        this topic durig the coffee breaks. I need to better understand the proposed
        solutions and how they fit into DataCite's existing infrastructure.</p><h3
        id=\"data-packages\">Data Packages</h3><p>The <a href=\"https://rd-alliance.org/data-packages-bof-p6-bof-session.html\">Data
        packages BoF</a> was organized by Rufus Pollock from the Open Knowledge Foundation
        (<a href=\"https://okfn.org/\">OKFN</a>), and he kindly invited me to present
        my perspective. This is an exciting topic and look for more on this topic
        in a future blog post.</p><h3 id=\"publishing-data-services\">Publishing Data
        Services</h3><p>The <a href=\"https://rd-alliance.org/wg-rdawds-publishing-data-services-p6-meeting-session.html\">RDA/WDS
        Publishing Data Services</a> presented their work on a data - literature <a
        href=\"https://dliservice.research-infrastructures.eu/\">linking service</a>.
        DataCite has worked closely with CrossRef on this topic since last year, and
        it was good to see a lot of overlap in the approaches taken, e.g. using the
        <code>relationType</code> vocabulary from the DataCite Metadata Schema.</p><h3
        id=\"data-citation\">Data Citation</h3><p>On the last day of RDA I gave a
        short presentation in the <a href=\"https://rd-alliance.org/ig-rdawds-publishing-data-p6-joint-session.html\">Joint
        meeting of RDA/WDS Publishing Data WGs and IGs</a>, summarizing some of the
        challenges implementing data citation:</p><!--kg-card-begin: html--><script
        async class=\"speakerdeck-embed\" data-id=\"804df2be5af148ffa0a048c0777d75ee\"
        data-ratio=\"1.33333333333333\" src=\"//speakerdeck.com/assets/embed.js\"></script><!--kg-card-end:
        html--><p>In the session we had a good discussion on how to move forward with
        the work started by the working group and its various interest groups.</p><p><em>This
        blog post was <a href=\"https://doi.org/10.5438/7rxd-s8a3\">originally published</a>
        on the DataCite Blog.</em></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Persistent Identifiers: Enabling Services
        for Data Intensive Research ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/persistent-identifiers-enabling-services-for-data-intensive-research/\"
        />\n\t\t<id>https://doi.org/10.53731/r796skh-97aq74v-ag4gb</id>\n        <published>2015-09-22T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-15T09:43:58.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"https://images.unsplash.com/photo-1502602898657-3e91760cbb34?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDF8fHBhcmlzfGVufDB8fHx8MTY2MDU1NjU3NQ&amp;ixlib&#x3D;rb-1.2.1&amp;q&#x3D;80&amp;w&#x3D;2000\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://images.unsplash.com/photo-1502602898657-3e91760cbb34?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDF8fHBhcmlzfGVufDB8fHx8MTY2MDU1NjU3NQ&amp;ixlib&#x3D;rb-1.2.1&amp;q&#x3D;80&amp;w&#x3D;2000\"></p><p>Yesterday
        DataCite and <a href=\"http://www.pidconsortium.eu/\">ePIC</a> co-hosted the
        workshop <a href=\"http://www.eventbrite.com/e/persistent-identifiers-enabling-services-for-data-intensive-research-tickets-17500184523\">Persistent
        Identifiers: Enabling Services for Data Intensive Research</a>. Below is a
        short summary of the tweets, all using the hashtag <a href=\"https://twitter.com/hashtag/pid_paris?src=hash\">#pid_paris</a>.</p><figure
        class=\"kg-card kg-embed-card\"><iframe id=\"twitter-widget-0\" scrolling=\"no\"
        frameborder=\"0\" allowtransparency=\"true\" allowfullscreen=\"true\" class=\"\"
        title=\"Twitter Tweet\" src=\"https://platform.twitter.com/embed/Tweet.html?dnt=false&amp;embedId=twitter-widget-0&amp;features=eyJ0ZndfZXhwZXJpbWVudHNfY29va2llX2V4cGlyYXRpb24iOnsiYnVja2V0IjoxMjA5NjAwLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X2hvcml6b25fdHdlZXRfZW1iZWRfOTU1NSI6eyJidWNrZXQiOiJodGUiLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X3R3ZWV0X2VtYmVkX2NsaWNrYWJpbGl0eV8xMjEwMiI6eyJidWNrZXQiOiJjb250cm9sIiwidmVyc2lvbiI6bnVsbH19&amp;frame=false&amp;hideCard=false&amp;hideThread=false&amp;id=645921435593125888&amp;lang=en&amp;origin=https%3A%2F%2Fblog.datacite.org%2Fpersistent-identifiers-enabling-services-for-data-intensive-research%2F&amp;sessionId=7b2e292f01ce83f25ada939b503670e7ae7c277b&amp;theme=light&amp;widgetsVersion=82e1070%3A1619632193066&amp;width=550px\"
        data-tweet-id=\"645921435593125888\" style=\"box-sizing: border-box; position:
        static; visibility: visible; width: 550px; height: 504px; display: block;
        flex-grow: 1;\"></iframe></figure><figure class=\"kg-card kg-embed-card\"><iframe
        id=\"twitter-widget-1\" scrolling=\"no\" frameborder=\"0\" allowtransparency=\"true\"
        allowfullscreen=\"true\" class=\"\" title=\"Twitter Tweet\" src=\"https://platform.twitter.com/embed/Tweet.html?dnt=false&amp;embedId=twitter-widget-1&amp;features=eyJ0ZndfZXhwZXJpbWVudHNfY29va2llX2V4cGlyYXRpb24iOnsiYnVja2V0IjoxMjA5NjAwLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X2hvcml6b25fdHdlZXRfZW1iZWRfOTU1NSI6eyJidWNrZXQiOiJodGUiLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X3R3ZWV0X2VtYmVkX2NsaWNrYWJpbGl0eV8xMjEwMiI6eyJidWNrZXQiOiJjb250cm9sIiwidmVyc2lvbiI6bnVsbH19&amp;frame=false&amp;hideCard=false&amp;hideThread=false&amp;id=645917238839635968&amp;lang=en&amp;origin=https%3A%2F%2Fblog.datacite.org%2Fpersistent-identifiers-enabling-services-for-data-intensive-research%2F&amp;sessionId=7b2e292f01ce83f25ada939b503670e7ae7c277b&amp;theme=light&amp;widgetsVersion=82e1070%3A1619632193066&amp;width=550px\"
        data-tweet-id=\"645917238839635968\" style=\"box-sizing: border-box; position:
        static; visibility: visible; width: 550px; height: 225px; display: block;
        flex-grow: 1;\"></iframe></figure><figure class=\"kg-card kg-embed-card\"><iframe
        id=\"twitter-widget-2\" scrolling=\"no\" frameborder=\"0\" allowtransparency=\"true\"
        allowfullscreen=\"true\" class=\"\" title=\"Twitter Tweet\" src=\"https://platform.twitter.com/embed/Tweet.html?dnt=false&amp;embedId=twitter-widget-2&amp;features=eyJ0ZndfZXhwZXJpbWVudHNfY29va2llX2V4cGlyYXRpb24iOnsiYnVja2V0IjoxMjA5NjAwLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X2hvcml6b25fdHdlZXRfZW1iZWRfOTU1NSI6eyJidWNrZXQiOiJodGUiLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X3R3ZWV0X2VtYmVkX2NsaWNrYWJpbGl0eV8xMjEwMiI6eyJidWNrZXQiOiJjb250cm9sIiwidmVyc2lvbiI6bnVsbH19&amp;frame=false&amp;hideCard=false&amp;hideThread=false&amp;id=645920334420537345&amp;lang=en&amp;origin=https%3A%2F%2Fblog.datacite.org%2Fpersistent-identifiers-enabling-services-for-data-intensive-research%2F&amp;sessionId=7b2e292f01ce83f25ada939b503670e7ae7c277b&amp;theme=light&amp;widgetsVersion=82e1070%3A1619632193066&amp;width=550px\"
        data-tweet-id=\"645920334420537345\" style=\"box-sizing: border-box; position:
        static; visibility: visible; width: 550px; height: 225px; display: block;
        flex-grow: 1;\"></iframe></figure><figure class=\"kg-card kg-embed-card\"><iframe
        id=\"twitter-widget-3\" scrolling=\"no\" frameborder=\"0\" allowtransparency=\"true\"
        allowfullscreen=\"true\" class=\"\" title=\"Twitter Tweet\" src=\"https://platform.twitter.com/embed/Tweet.html?dnt=false&amp;embedId=twitter-widget-3&amp;features=eyJ0ZndfZXhwZXJpbWVudHNfY29va2llX2V4cGlyYXRpb24iOnsiYnVja2V0IjoxMjA5NjAwLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X2hvcml6b25fdHdlZXRfZW1iZWRfOTU1NSI6eyJidWNrZXQiOiJodGUiLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X3R3ZWV0X2VtYmVkX2NsaWNrYWJpbGl0eV8xMjEwMiI6eyJidWNrZXQiOiJjb250cm9sIiwidmVyc2lvbiI6bnVsbH19&amp;frame=false&amp;hideCard=false&amp;hideThread=false&amp;id=645961061858963456&amp;lang=en&amp;origin=https%3A%2F%2Fblog.datacite.org%2Fpersistent-identifiers-enabling-services-for-data-intensive-research%2F&amp;sessionId=7b2e292f01ce83f25ada939b503670e7ae7c277b&amp;theme=light&amp;widgetsVersion=82e1070%3A1619632193066&amp;width=550px\"
        data-tweet-id=\"645961061858963456\" style=\"box-sizing: border-box; position:
        static; visibility: visible; width: 550px; height: 225px; display: block;
        flex-grow: 1;\"></iframe></figure><figure class=\"kg-card kg-embed-card\"><iframe
        id=\"twitter-widget-4\" scrolling=\"no\" frameborder=\"0\" allowtransparency=\"true\"
        allowfullscreen=\"true\" class=\"\" title=\"Twitter Tweet\" src=\"https://platform.twitter.com/embed/Tweet.html?dnt=false&amp;embedId=twitter-widget-4&amp;features=eyJ0ZndfZXhwZXJpbWVudHNfY29va2llX2V4cGlyYXRpb24iOnsiYnVja2V0IjoxMjA5NjAwLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X2hvcml6b25fdHdlZXRfZW1iZWRfOTU1NSI6eyJidWNrZXQiOiJodGUiLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X3R3ZWV0X2VtYmVkX2NsaWNrYWJpbGl0eV8xMjEwMiI6eyJidWNrZXQiOiJjb250cm9sIiwidmVyc2lvbiI6bnVsbH19&amp;frame=false&amp;hideCard=false&amp;hideThread=false&amp;id=645928078288506880&amp;lang=en&amp;origin=https%3A%2F%2Fblog.datacite.org%2Fpersistent-identifiers-enabling-services-for-data-intensive-research%2F&amp;sessionId=7b2e292f01ce83f25ada939b503670e7ae7c277b&amp;theme=light&amp;widgetsVersion=82e1070%3A1619632193066&amp;width=550px\"
        data-tweet-id=\"645928078288506880\" style=\"box-sizing: border-box; position:
        static; visibility: visible; width: 550px; height: 225px; display: block;
        flex-grow: 1;\"></iframe></figure><figure class=\"kg-card kg-embed-card\"><iframe
        id=\"twitter-widget-5\" scrolling=\"no\" frameborder=\"0\" allowtransparency=\"true\"
        allowfullscreen=\"true\" class=\"\" title=\"Twitter Tweet\" src=\"https://platform.twitter.com/embed/Tweet.html?dnt=false&amp;embedId=twitter-widget-5&amp;features=eyJ0ZndfZXhwZXJpbWVudHNfY29va2llX2V4cGlyYXRpb24iOnsiYnVja2V0IjoxMjA5NjAwLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X2hvcml6b25fdHdlZXRfZW1iZWRfOTU1NSI6eyJidWNrZXQiOiJodGUiLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X3R3ZWV0X2VtYmVkX2NsaWNrYWJpbGl0eV8xMjEwMiI6eyJidWNrZXQiOiJjb250cm9sIiwidmVyc2lvbiI6bnVsbH19&amp;frame=false&amp;hideCard=false&amp;hideThread=false&amp;id=645930412980727808&amp;lang=en&amp;origin=https%3A%2F%2Fblog.datacite.org%2Fpersistent-identifiers-enabling-services-for-data-intensive-research%2F&amp;sessionId=7b2e292f01ce83f25ada939b503670e7ae7c277b&amp;theme=light&amp;widgetsVersion=82e1070%3A1619632193066&amp;width=550px\"
        data-tweet-id=\"645930412980727808\" style=\"box-sizing: border-box; position:
        static; visibility: visible; width: 550px; height: 225px; display: block;
        flex-grow: 1;\"></iframe></figure><figure class=\"kg-card kg-embed-card\"><iframe
        id=\"twitter-widget-6\" scrolling=\"no\" frameborder=\"0\" allowtransparency=\"true\"
        allowfullscreen=\"true\" class=\"\" title=\"Twitter Tweet\" src=\"https://platform.twitter.com/embed/Tweet.html?dnt=false&amp;embedId=twitter-widget-6&amp;features=eyJ0ZndfZXhwZXJpbWVudHNfY29va2llX2V4cGlyYXRpb24iOnsiYnVja2V0IjoxMjA5NjAwLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X2hvcml6b25fdHdlZXRfZW1iZWRfOTU1NSI6eyJidWNrZXQiOiJodGUiLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X3R3ZWV0X2VtYmVkX2NsaWNrYWJpbGl0eV8xMjEwMiI6eyJidWNrZXQiOiJjb250cm9sIiwidmVyc2lvbiI6bnVsbH19&amp;frame=false&amp;hideCard=false&amp;hideThread=false&amp;id=645932993652097024&amp;lang=en&amp;origin=https%3A%2F%2Fblog.datacite.org%2Fpersistent-identifiers-enabling-services-for-data-intensive-research%2F&amp;sessionId=7b2e292f01ce83f25ada939b503670e7ae7c277b&amp;theme=light&amp;widgetsVersion=82e1070%3A1619632193066&amp;width=550px\"
        data-tweet-id=\"645932993652097024\" style=\"box-sizing: border-box; position:
        static; visibility: visible; width: 550px; height: 729px; display: block;
        flex-grow: 1;\"></iframe></figure><figure class=\"kg-card kg-embed-card\"><iframe
        id=\"twitter-widget-7\" scrolling=\"no\" frameborder=\"0\" allowtransparency=\"true\"
        allowfullscreen=\"true\" class=\"\" title=\"Twitter Tweet\" src=\"https://platform.twitter.com/embed/Tweet.html?dnt=false&amp;embedId=twitter-widget-7&amp;features=eyJ0ZndfZXhwZXJpbWVudHNfY29va2llX2V4cGlyYXRpb24iOnsiYnVja2V0IjoxMjA5NjAwLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X2hvcml6b25fdHdlZXRfZW1iZWRfOTU1NSI6eyJidWNrZXQiOiJodGUiLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X3R3ZWV0X2VtYmVkX2NsaWNrYWJpbGl0eV8xMjEwMiI6eyJidWNrZXQiOiJjb250cm9sIiwidmVyc2lvbiI6bnVsbH19&amp;frame=false&amp;hideCard=false&amp;hideThread=false&amp;id=645944999692120065&amp;lang=en&amp;origin=https%3A%2F%2Fblog.datacite.org%2Fpersistent-identifiers-enabling-services-for-data-intensive-research%2F&amp;sessionId=7b2e292f01ce83f25ada939b503670e7ae7c277b&amp;theme=light&amp;widgetsVersion=82e1070%3A1619632193066&amp;width=550px\"
        data-tweet-id=\"645944999692120065\" style=\"box-sizing: border-box; position:
        static; visibility: visible; width: 550px; height: 480px; display: block;
        flex-grow: 1;\"></iframe></figure><figure class=\"kg-card kg-embed-card\"><iframe
        id=\"twitter-widget-8\" scrolling=\"no\" frameborder=\"0\" allowtransparency=\"true\"
        allowfullscreen=\"true\" class=\"\" title=\"Twitter Tweet\" src=\"https://platform.twitter.com/embed/Tweet.html?dnt=false&amp;embedId=twitter-widget-8&amp;features=eyJ0ZndfZXhwZXJpbWVudHNfY29va2llX2V4cGlyYXRpb24iOnsiYnVja2V0IjoxMjA5NjAwLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X2hvcml6b25fdHdlZXRfZW1iZWRfOTU1NSI6eyJidWNrZXQiOiJodGUiLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X3R3ZWV0X2VtYmVkX2NsaWNrYWJpbGl0eV8xMjEwMiI6eyJidWNrZXQiOiJjb250cm9sIiwidmVyc2lvbiI6bnVsbH19&amp;frame=false&amp;hideCard=false&amp;hideThread=false&amp;id=645964076804276225&amp;lang=en&amp;origin=https%3A%2F%2Fblog.datacite.org%2Fpersistent-identifiers-enabling-services-for-data-intensive-research%2F&amp;sessionId=7b2e292f01ce83f25ada939b503670e7ae7c277b&amp;theme=light&amp;widgetsVersion=82e1070%3A1619632193066&amp;width=550px\"
        data-tweet-id=\"645964076804276225\" style=\"box-sizing: border-box; position:
        static; visibility: visible; width: 550px; height: 528px; display: block;
        flex-grow: 1;\"></iframe></figure><figure class=\"kg-card kg-embed-card\"><iframe
        id=\"twitter-widget-9\" scrolling=\"no\" frameborder=\"0\" allowtransparency=\"true\"
        allowfullscreen=\"true\" class=\"\" title=\"Twitter Tweet\" src=\"https://platform.twitter.com/embed/Tweet.html?dnt=false&amp;embedId=twitter-widget-9&amp;features=eyJ0ZndfZXhwZXJpbWVudHNfY29va2llX2V4cGlyYXRpb24iOnsiYnVja2V0IjoxMjA5NjAwLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X2hvcml6b25fdHdlZXRfZW1iZWRfOTU1NSI6eyJidWNrZXQiOiJodGUiLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X3R3ZWV0X2VtYmVkX2NsaWNrYWJpbGl0eV8xMjEwMiI6eyJidWNrZXQiOiJjb250cm9sIiwidmVyc2lvbiI6bnVsbH19&amp;frame=false&amp;hideCard=false&amp;hideThread=false&amp;id=645967582332366848&amp;lang=en&amp;origin=https%3A%2F%2Fblog.datacite.org%2Fpersistent-identifiers-enabling-services-for-data-intensive-research%2F&amp;sessionId=7b2e292f01ce83f25ada939b503670e7ae7c277b&amp;theme=light&amp;widgetsVersion=82e1070%3A1619632193066&amp;width=550px\"
        data-tweet-id=\"645967582332366848\" style=\"box-sizing: border-box; position:
        static; visibility: visible; width: 550px; height: 900px; display: block;
        flex-grow: 1;\"></iframe></figure><blockquote>Emerging theme: the number of
        PID solutions is overwhelming to researchers. What we need to provide are
        reliable suggestions. <a href=\"https://twitter.com/hashtag/pid_paris?src=hash\">#pid_paris</a>(<strong><strong>???</strong></strong>)
        <a href=\"https://twitter.com/elisedunham/status/645970130627887105\">September
        21, 2015</a></blockquote><figure class=\"kg-card kg-embed-card\"><iframe id=\"twitter-widget-11\"
        scrolling=\"no\" frameborder=\"0\" allowtransparency=\"true\" allowfullscreen=\"true\"
        class=\"\" title=\"Twitter Tweet\" src=\"https://platform.twitter.com/embed/Tweet.html?dnt=false&amp;embedId=twitter-widget-11&amp;features=eyJ0ZndfZXhwZXJpbWVudHNfY29va2llX2V4cGlyYXRpb24iOnsiYnVja2V0IjoxMjA5NjAwLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X2hvcml6b25fdHdlZXRfZW1iZWRfOTU1NSI6eyJidWNrZXQiOiJodGUiLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X3R3ZWV0X2VtYmVkX2NsaWNrYWJpbGl0eV8xMjEwMiI6eyJidWNrZXQiOiJjb250cm9sIiwidmVyc2lvbiI6bnVsbH19&amp;frame=false&amp;hideCard=false&amp;hideThread=false&amp;id=645939233652375552&amp;lang=en&amp;origin=https%3A%2F%2Fblog.datacite.org%2Fpersistent-identifiers-enabling-services-for-data-intensive-research%2F&amp;sessionId=7b2e292f01ce83f25ada939b503670e7ae7c277b&amp;theme=light&amp;widgetsVersion=82e1070%3A1619632193066&amp;width=550px\"
        data-tweet-id=\"645939233652375552\" style=\"box-sizing: border-box; position:
        static; visibility: visible; width: 550px; height: 225px; display: block;
        flex-grow: 1;\"></iframe></figure><figure class=\"kg-card kg-embed-card\"><iframe
        id=\"twitter-widget-12\" scrolling=\"no\" frameborder=\"0\" allowtransparency=\"true\"
        allowfullscreen=\"true\" class=\"\" title=\"Twitter Tweet\" src=\"https://platform.twitter.com/embed/Tweet.html?dnt=false&amp;embedId=twitter-widget-12&amp;features=eyJ0ZndfZXhwZXJpbWVudHNfY29va2llX2V4cGlyYXRpb24iOnsiYnVja2V0IjoxMjA5NjAwLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X2hvcml6b25fdHdlZXRfZW1iZWRfOTU1NSI6eyJidWNrZXQiOiJodGUiLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X3R3ZWV0X2VtYmVkX2NsaWNrYWJpbGl0eV8xMjEwMiI6eyJidWNrZXQiOiJjb250cm9sIiwidmVyc2lvbiI6bnVsbH19&amp;frame=false&amp;hideCard=false&amp;hideThread=false&amp;id=645940553293647872&amp;lang=en&amp;origin=https%3A%2F%2Fblog.datacite.org%2Fpersistent-identifiers-enabling-services-for-data-intensive-research%2F&amp;sessionId=7b2e292f01ce83f25ada939b503670e7ae7c277b&amp;theme=light&amp;widgetsVersion=82e1070%3A1619632193066&amp;width=550px\"
        data-tweet-id=\"645940553293647872\" style=\"box-sizing: border-box; position:
        static; visibility: visible; width: 550px; height: 225px; display: block;
        flex-grow: 1;\"></iframe></figure><figure class=\"kg-card kg-embed-card\"><iframe
        id=\"twitter-widget-13\" scrolling=\"no\" frameborder=\"0\" allowtransparency=\"true\"
        allowfullscreen=\"true\" class=\"\" title=\"Twitter Tweet\" src=\"https://platform.twitter.com/embed/Tweet.html?dnt=false&amp;embedId=twitter-widget-13&amp;features=eyJ0ZndfZXhwZXJpbWVudHNfY29va2llX2V4cGlyYXRpb24iOnsiYnVja2V0IjoxMjA5NjAwLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X2hvcml6b25fdHdlZXRfZW1iZWRfOTU1NSI6eyJidWNrZXQiOiJodGUiLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X3R3ZWV0X2VtYmVkX2NsaWNrYWJpbGl0eV8xMjEwMiI6eyJidWNrZXQiOiJjb250cm9sIiwidmVyc2lvbiI6bnVsbH19&amp;frame=false&amp;hideCard=false&amp;hideThread=false&amp;id=645974819046060032&amp;lang=en&amp;origin=https%3A%2F%2Fblog.datacite.org%2Fpersistent-identifiers-enabling-services-for-data-intensive-research%2F&amp;sessionId=7b2e292f01ce83f25ada939b503670e7ae7c277b&amp;theme=light&amp;widgetsVersion=82e1070%3A1619632193066&amp;width=550px\"
        data-tweet-id=\"645974819046060032\" style=\"box-sizing: border-box; position:
        static; visibility: visible; width: 550px; height: 201px; display: block;
        flex-grow: 1;\"></iframe></figure><figure class=\"kg-card kg-embed-card\"><iframe
        id=\"twitter-widget-14\" scrolling=\"no\" frameborder=\"0\" allowtransparency=\"true\"
        allowfullscreen=\"true\" class=\"\" title=\"Twitter Tweet\" src=\"https://platform.twitter.com/embed/Tweet.html?dnt=false&amp;embedId=twitter-widget-14&amp;features=eyJ0ZndfZXhwZXJpbWVudHNfY29va2llX2V4cGlyYXRpb24iOnsiYnVja2V0IjoxMjA5NjAwLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X2hvcml6b25fdHdlZXRfZW1iZWRfOTU1NSI6eyJidWNrZXQiOiJodGUiLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X3R3ZWV0X2VtYmVkX2NsaWNrYWJpbGl0eV8xMjEwMiI6eyJidWNrZXQiOiJjb250cm9sIiwidmVyc2lvbiI6bnVsbH19&amp;frame=false&amp;hideCard=false&amp;hideThread=false&amp;id=645978800589795328&amp;lang=en&amp;origin=https%3A%2F%2Fblog.datacite.org%2Fpersistent-identifiers-enabling-services-for-data-intensive-research%2F&amp;sessionId=7b2e292f01ce83f25ada939b503670e7ae7c277b&amp;theme=light&amp;widgetsVersion=82e1070%3A1619632193066&amp;width=550px\"
        data-tweet-id=\"645978800589795328\" style=\"box-sizing: border-box; position:
        static; visibility: visible; width: 550px; height: 900px; display: block;
        flex-grow: 1;\"></iframe></figure><figure class=\"kg-card kg-embed-card\"><iframe
        id=\"twitter-widget-15\" scrolling=\"no\" frameborder=\"0\" allowtransparency=\"true\"
        allowfullscreen=\"true\" class=\"\" title=\"Twitter Tweet\" src=\"https://platform.twitter.com/embed/Tweet.html?dnt=false&amp;embedId=twitter-widget-15&amp;features=eyJ0ZndfZXhwZXJpbWVudHNfY29va2llX2V4cGlyYXRpb24iOnsiYnVja2V0IjoxMjA5NjAwLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X2hvcml6b25fdHdlZXRfZW1iZWRfOTU1NSI6eyJidWNrZXQiOiJodGUiLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X3R3ZWV0X2VtYmVkX2NsaWNrYWJpbGl0eV8xMjEwMiI6eyJidWNrZXQiOiJjb250cm9sIiwidmVyc2lvbiI6bnVsbH19&amp;frame=false&amp;hideCard=false&amp;hideThread=false&amp;id=645983872187023360&amp;lang=en&amp;origin=https%3A%2F%2Fblog.datacite.org%2Fpersistent-identifiers-enabling-services-for-data-intensive-research%2F&amp;sessionId=7b2e292f01ce83f25ada939b503670e7ae7c277b&amp;theme=light&amp;widgetsVersion=82e1070%3A1619632193066&amp;width=550px\"
        data-tweet-id=\"645983872187023360\" style=\"box-sizing: border-box; position:
        static; visibility: visible; width: 550px; height: 876px; display: block;
        flex-grow: 1;\"></iframe></figure><figure class=\"kg-card kg-embed-card\"><iframe
        id=\"twitter-widget-16\" scrolling=\"no\" frameborder=\"0\" allowtransparency=\"true\"
        allowfullscreen=\"true\" class=\"\" title=\"Twitter Tweet\" src=\"https://platform.twitter.com/embed/Tweet.html?dnt=false&amp;embedId=twitter-widget-16&amp;features=eyJ0ZndfZXhwZXJpbWVudHNfY29va2llX2V4cGlyYXRpb24iOnsiYnVja2V0IjoxMjA5NjAwLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X2hvcml6b25fdHdlZXRfZW1iZWRfOTU1NSI6eyJidWNrZXQiOiJodGUiLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X3R3ZWV0X2VtYmVkX2NsaWNrYWJpbGl0eV8xMjEwMiI6eyJidWNrZXQiOiJjb250cm9sIiwidmVyc2lvbiI6bnVsbH19&amp;frame=false&amp;hideCard=false&amp;hideThread=false&amp;id=646000851794980865&amp;lang=en&amp;origin=https%3A%2F%2Fblog.datacite.org%2Fpersistent-identifiers-enabling-services-for-data-intensive-research%2F&amp;sessionId=7b2e292f01ce83f25ada939b503670e7ae7c277b&amp;theme=light&amp;widgetsVersion=82e1070%3A1619632193066&amp;width=550px\"
        data-tweet-id=\"646000851794980865\" style=\"box-sizing: border-box; position:
        static; visibility: visible; width: 550px; height: 480px; display: block;
        flex-grow: 1;\"></iframe></figure><p>The last tweet shows the views from the
        reception. If you have any questions or comments about the event, use the
        hashtag <a href=\"https://twitter.com/hashtag/pid_paris?src=hash\">#pid_paris</a>
        on Twitter, or use the comments of this blog.</p><p><em>This blog post was
        <a href=\"https://doi.org/10.5438/jm9f-325f\">originally published</a> on
        the DataCite Blog.</em></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Differences between ORCID and DataCite Metadata
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/differences-between-orcid-and-datacite-metadata/\"
        />\n\t\t<id>https://doi.org/10.53731/r79v4e1-97aq74v-ag578</id>\n        <published>2015-09-18T00:00:00.000+00:00</published>\n\t\t<updated>2023-09-07T08:14:45.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2023/09/cat_and_dog-1.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2023/09/cat_and_dog-1.png\"></p><p>One
        of the first tasks for DataCite in the European Commission-funded <a href=\"http://project-thor.eu/\">THOR
        project</a>, which started in June, was to contribute to a comparison of the
        ORCID and DataCite metadata standards. Together with ORCID, CERN, the British
        Library and Dryad we looked at how contributors, organizations and artefacts
        - and the relations between them - are described in the respective metadata
        schemata, and how they are implemented in two example data repositories, <a
        href=\"http://archaeologydataservice.ac.uk/\">Archaeology Data Service</a>
        and <a href=\"https://www.datadryad.org/\">Dryad Digital Repository</a>.</p>\n<p>The
        focus of our work was on identifying major gaps. Our report was finished and
        made publicly available last week (Fenner et al., <a href=\"https://blog.datacite.org/differences-between-orcid-and-datacite-metadata/#ref-https://doi.org/10.5281/ZENODO.30799\">2015</a>).
        The key findings are summarized below:</p>\n<ul><li>Common Approach to Personal
        Names</li><li>Standardized Contributor Roles</li><li>Standardized Relation
        Types</li><li>Metadata for Organisations</li><li>Persistent Identifiers for
        Projects</li><li>Harmonization of ORCID and DataCite Metadata</li></ul>\n<h3
        id=\"common-approach-to-personal-names\">Common Approach to Personal Names</h3>\n<p>While
        a single input field for contributor names is common, separate fields for
        given and family names are required for <a href=\"http://docs.citationstyles.org/en/stable/specification.html#names\">proper
        formatting of citations</a>. As long as citations to scholarly content rely
        on properly formatted text rather than persistent identifiers, services holding
        bibliographic information have to support these separate fields. Further work
        is needed to help with the transition to separate input fields for given and
        famliy names, and to handle contributors that are organizations or groups
        of people.</p>\n<h3 id=\"standardized-contributor-roles\">Standardized Contributor
        Roles</h3>\n<p>The currently existing vocabularies for <strong>contributor
        type</strong> (DataCite) and <strong>contributor role</strong> (ORCID) provide
        a high-level description, but fall short when trying to describe the author/creator
        contribution in more detail. <a href=\"http://docs.casrai.org/CRediT\">Project
        CRediT</a> is a multi-stakeholder initiative that has developed a common vocabulary
        with 14 different contributor roles, and this vocabulary can be used to provide
        this detail, e.g. who provided resources such as reagents or samples, who
        did the statistical analysis, or who contributed to the methodology of a study.</p>\n<p>CRediT
        is complementary to existing contributor role vocabularies such as those by
        ORCID and DataCite. For contributor roles it is particularly important that
        the same vocabulary is used across stakeholders, so that the roles described
        in the data center can be forwarded first to DataCite, then to ORCID, and
        then also to other places such as institutional repositories.</p>\n<h3 id=\"standardized-relation-types\">Standardized
        Relation Types</h3>\n<p>Capturing relations between scholarly works such as
        datasets in a standardized way is important, as these relations are used for
        citations and thus the basis for many indicators of scholarly impact. Currently
        used vocabularies for relation types between scholarly works, e.g. by CrossRef
        and DataCite, only partly overlap. In addition we see differences in community
        practices, e.g. some scholars but not others reserve the term citation for
        links between two scholarly articles. The term data citation is sometimes
        used for all links from scholarly works to datasets, but other times reserved
        for formal citations appearing in reference lists.</p>\n<h3 id=\"metadata-for-organisations\">Metadata
        for Organisations</h3>\n<p>Both ORCID and DataCite not only provide persistent
        identifiers for people and data, but they also collect metadata around these
        persistent identifiers, in particular links to other identifiers. The use
        of persistent identifiers for organizations lags behind the use of persistent
        identifiers for research outputs and people, and more work is needed.</p>\n<h3
        id=\"persistent-identifiers-for-projects\">Persistent Identifiers for Projects</h3>\n<p>Research
        projects are collaborative activities among contributors that may change over
        time. Projects have a start and end date and are often funded by a grant.
        The existing persistent identifier (PID) infrastructure does support artefacts,
        contributors and organisations, but there is no first-class PID support for
        projects. This creates a major gap that becomes obvious when we try to describe
        the relationships between funders, contributors and research outputs.</p>\n<p>Both
        the ORCID and DataCite metadata support funding information, but only as direct
        links to contributors or research outputs, respectively. This not only makes
        it difficult to exchange funding information between DataCite and ORCID, but
        also fails to adequately model the sometimes complex relationships, e.g. when
        multiple funders and grants were involved in supporting a research output.
        We therefore not only need persistent identifiers for projects, but also infrastructure
        for collecting and aggregating links to contributors and artefacts.</p>\n<h3
        id=\"harmonization-of-orcid-and-datacite-metadata\">Harmonization of ORCID
        and DataCite Metadata</h3>\n<p>We identified significant differences between
        the ORCID and DataCite metadata schema, and these differences hinder the flow
        of information between the two services. Several different approaches to overcome
        these differences are conceivable:</p>\n<ol><li>only use a common subset,
        relying on linked persistent identifiers to get the full metadata</li><li>harmonize
        the ORCID and DataCite metadata schemata</li><li>common API exchange formats
        for metadata</li></ol>\n<p>The first approach is the linked open data approach,
        and was designed specifically for scenarios like this. One limitation is that
        it requires persistent identifiers for all relevant attributes (e.g. for every
        creator/contributor in the DataCite metadata). One major objective for THOR
        is therefore to increase the use of persistent identifiers, both by THOR partners,
        and by the community at large.</p>\n<p>A common metadata schema between ORCID
        and DataCite is neither feasible nor necessarily needed. In addition, we have
        to also consider interoperability with other metadata standards (e.g. CASRAI,
        OpenAIRE, COAR), and with other artifacts, such as those having CrossRef DOIs.
        What is more realistic is harmonization across a limited set essential metadata.</p>\n<p>The
        third approach to improve interoperability uses a common API format that includes
        all the metadata that need to be exchanged, but doesn\u2019t require the metadata
        schema itself to change. This approach was <a href=\"https://www.crossref.org/blog/crossref-and-datacite-unify-support-for-http-content-negotiation/\">taken
        by DataCite and CrossRef a few years ago</a> to provide metadata for DOIs
        in a consistent way despite significant differences in the CrossRef and DataCite
        metadata schema. Using HTTP content negotiation, metadata are provided in
        a variety of formats.</p>\n<h2 id=\"acknowledgments\">Acknowledgments</h2>\n<p>This
        blog post was <a href=\"https://doi.org/10.5438/bc11-cqw1\">originally published</a>
        on the DataCite Blog. This work was funded by the European Union\u2019s Horizon
        2020 research and innovation programme under <a href=\"https://doi.org/10.3030/654039\"
        rel=\"noreferrer\">grant agreement No.&nbsp;654039</a>.</p>\n<h2 id=\"references\">References</h2>\n<p>Fenner
        M, Demeranville T, Kotarski R, et al. <em>D2.1: Artefact, Contributor, And
        Organisation Relationship Data Schema</em>. Zenodo; 2015. doi:<a href=\"https://doi.org/10.5281/ZENODO.30799\">10.5281/ZENODO.30799</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Adding References to the DataCite Blog ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/adding-references-to-the-datacite-blog/\"
        />\n\t\t<id>https://doi.org/10.53731/r796n5h-97aq74v-ag4fn</id>\n        <published>2015-09-16T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-15T09:45:39.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-09-15-um-20-19-48.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-09-15-um-20-19-48.png\"></p><p>We
        launched this blog six weeks ago on a hosted version of <a href=\"https://ghost.org/\">Ghost</a>,
        the open source blogging platform. Ghost doesn't have all the features of
        Wordpress or other more mature blogging platforms, but it is a pleasure to
        use. The other alternative would have been to put the blog up on the Drupal-based
        main <a href=\"http://www.datacite.org/\">DataCite website</a>, but Drupal
        is really a content-management system and usually not the best choice for
        a serious blog.</p><p>What all the above systems (Ghost, Wordpress, Drupal)
        have in common is that they need a web server and database backend. This is
        fine for the standard blog, but it becomes a problem once you start thinking
        about customizing your blog. In the case of the DataCite blog I want to be
        able to provide the following:</p><ul><li>the addition of proper citations
        and references</li><li>a PDF (and possibly ePub) version for downloading and
        archiving</li><li>a register blog posts with a DOI</li></ul><p>Since DataCite
        is in the business of providing DOI names for scholarly content, the above
        is a pretty obvious wish list. Some people might argue about the content of
        this blog needing a DOI, but DOIs have been used for similar content for many
        years, whether it is for frontmatter content (editorials, opinion pieces,
        etc.) in journals, or in services such as <a href=\"https://www.nature.com/news\">Nature
        News</a>.</p><p>Out of the box the standard blogging platforms mentioned above
        don't support references or DOI registration, so a bit of extra work is needed.
        The easiest way to do this is to switch to a simpler blogging platform. Luckily
        there are a lot of choices among these so-called <strong><strong>static site
        generators</strong></strong>, which don't need a database and simply generate
        HTML files. Adding the features from the above wish list then becomes a straightforward
        process and that is what I have started doing.</p><p>As of this week, we support
        references, as you can see in this blog post(<strong><strong>???</strong></strong>)
        from two weeks ago.</p><p>The picture is from the PDF version of the post,
        where the integration with the blog is still ongoing.</p><p>The <em>DataCite
        Labs Blog</em> looks very similar to the <em>DataCite Blog</em>, but under
        the hood is using the <a href=\"https://github.com/jekyll/jekyll\">Jekyll</a>
        static site generator, and the <a href=\"http://pandoc.org/README.html\">Pandoc</a>
        document conversion software. This is a popular combination used by several
        scholarly bloggers, e.g. <a href=\"http://www.carlboettiger.info/2015/01/07/automated-knitr-in-jekyll.html\">Carl
        Boettiger</a>. Jekyll is written in Ruby, and there are at least two Ruby
        gems that allow automatic deposition in Zenodo (<a href=\"https://github.com/sprotocols/zenodo\">zenodo
        gem</a>), or the DataCite Metadata Store (<a href=\"https://github.com/datacite/datacite_doi_ify\">datacite_doi_ify
        gem</a>) to automate archiving and DOI registration.</p><p>Of course DOI registration
        doesn't all of the sudden make blog content more \u200B\u200B<em>scholarly</em>\u200B,
        but it can make it easier to find. For example, blog posts can be found by
        searching CrossRef or DataCite's metadata, and links can be discovered between
        blog posts and scholarly articles (or datasets) by using the DataCite metrics
        pilot, which we <a href=\"https://blog.datacite.org/announcing-data-level-metrics-in-datacite-labs\">announced
        last week</a>. To facilitate this we need to deposit the references with the
        metadata we send to DataCite, e.g. for the three scholarly articles, one software
        repository, one dataset and one data paper you see in the picture above.</p><p>A
        little more work is needed before the <em>Labs Blog</em> can become the official
        <em>DataCite Blog</em>, and as always we appreciate your feedback. The blog
        itself is stored in a <a href=\"https://github.com/datacite/blog\">public
        Github repository</a>, so feel free to reuse any of the code. We use the <a
        href=\"https://travis-ci.org/\">Travis</a> continuous integration tool to
        automatically generate the HTML pages for the blog, and then push the newly
        generated HTML content to <a href=\"https://aws.amazon.com/s3/\">Amazon S3</a>
        for hosting.</p><p><em>This blog post was <a href=\"https://doi.org/10.5438/2wfx-2hz1\">originally
        published</a> on the DataCite Blog.</em></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Announcing Data-Level Metrics in DataCite
        Labs ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/announcing-data-level-metrics-in-datacite-labs/\"
        />\n\t\t<id>https://doi.org/10.53731/r79t5ph-97aq74v-ag50s</id>\n        <published>2015-09-09T00:00:00.000+00:00</published>\n\t\t<updated>2023-09-18T08:08:49.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-09-09-um-17-02-56.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-09-09-um-17-02-56.png\"></p><p>Last
        week Jennifer Lin shared information on the <strong>Making Data Count</strong>
        (MDC) project <a href=\"https://blog.datacite.org/when-counting-is-hard/\">on
        this blog</a>. MDC is a project funded by the U.S. National Science Foundation
        (NSF) to design and develop metrics that track and measure data use \u2013
        <strong>data-level metrics</strong> (DLM).</p>\n<p>Funding for the 12 month
        project ends October 1st, with a no-cost extension until March 1st. MDC is
        a research project and has delivered some interesting questions and important
        results. One open question is whether and how to turn MDC research into a
        service that is not limited to the grant-funding period and possibly includes
        other datasets beyond those from the <a href=\"https://www.dataone.org/current-member-nodes\">DataONE
        repository network</a>. These important decisions require analysis and feedback
        from the broader community.</p>\n<p>In order to better understand and analyze
        these questions DataCite has taken over hosting of the DLM service from PLOS
        and will provide this service until at least March 1st, when the MDC funding
        formally ends. The DLM service is now hosted by DataCite Labs and can be found
        at <a href=\"https://dlm.datacite.org/\">https://dlm.datacite.org</a>. The
        following chart (directly from <a href=\"https://dlm.datacite.org/sources\">https://dlm.datacite.org/sources</a>)
        gives an overview about the data we have collected so far.</p>\n<p>DLM is
        primarily an API for metrics, with documentation found at <a href=\"https://dlm.datacite.org/docs/sources\">https://dlm.datacite.org/docs/sources</a>,
        and live API documentation at <a href=\"https://dlm.datacite.org/api\">https://dlm.datacite.org/api</a>.
        API clients in <a href=\"https://github.com/ropensci/alm\">R</a>, <a href=\"https://github.com/lagotto/pyalm\">Python</a>
        and <a href=\"https://github.com/lagotto/lagotto-rb\">Ruby</a> exist, and
        there is <a href=\"https://github.com/lagotto/almviz\">example code</a> in
        Javascript. A discussion forum helps with questions regarding the API or clients.</p>\n<p>Most
        users will not be using the API directly, but rather want to see the metrics
        data displayed together with the datasets they are interested in. About half
        of the about 140,000 datasets in the DLM service use DataCite DOIs and, as
        a first step, we have integrated DataCite DOIs into <a href=\"https://search.test.datacite.org/\">Labs
        Search</a>. If your search results include datasets from one of the DataONE
        data centers that use DOIs (including Long Term Ecological Research Network,
        National Center for Ecological Analysis and Synthesis and Dryad Digital Repository)
        and we have found links for them (e.g. for <a href=\"https://search.datacite.org/works?query=10.5061/dryad.f1cb2\">10.5061/dryad.f1cb2</a>),
        we will display them:</p>\n<figure class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-09-09-um-17-18-36.png\"
        class=\"kg-image\" alt=\"Data from: rise of the machines\" loading=\"lazy\"
        width=\"1600\" height=\"428\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/Bildschirmfoto-2015-09-09-um-17-18-36.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/08/Bildschirmfoto-2015-09-09-um-17-18-36.png
        1000w, https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-09-09-um-17-18-36.png
        1600w\" sizes=\"(min-width: 720px) 720px\"></figure>\n<p>Let's dig into the
        Dryad example a bit more -- every Dryad data package is associated with a
        journal article (or other textual output) and the metadata deposited in DataCite
        links to that particular article. Dryad has provided <code>Is referenced by</code>
        for this relationship:</p>\n<figure class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-09-09-um-17-21-42.png\"
        class=\"kg-image\" alt=\"Show &quot;isReferencedBy&quot; relationship\" loading=\"lazy\"
        width=\"1844\" height=\"444\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/Bildschirmfoto-2015-09-09-um-17-21-42.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/08/Bildschirmfoto-2015-09-09-um-17-21-42.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2022/08/Bildschirmfoto-2015-09-09-um-17-21-42.png
        1600w, https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-09-09-um-17-21-42.png
        1844w\" sizes=\"(min-width: 720px) 720px\"></figure>\n<p>When you click on
        the <code>Is Cited By</code> link you will find 6 citations, all of which
        are different from the article in the <code>Is referenced by</code> link.</p>\n<p>We
        included the names of the data sources (e.g. Europe PMC, PLOS, etc.) to distinguish
        DataCite metadata from external data pulled in from DLM. We are not currently
        deduplicating links if they are found in different sources - in this case
        two citations where found both via PLOS fulltext search and via Europe PMC
        API:</p>\n<figure class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-09-09-um-17-21-21.png\"
        class=\"kg-image\" alt=\"PLOS fulltext search and Europe PMC\" loading=\"lazy\"
        width=\"1862\" height=\"692\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/Bildschirmfoto-2015-09-09-um-17-21-21.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/08/Bildschirmfoto-2015-09-09-um-17-21-21.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2022/08/Bildschirmfoto-2015-09-09-um-17-21-21.png
        1600w, https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-09-09-um-17-21-21.png
        1862w\" sizes=\"(min-width: 720px) 720px\"></figure>\n<p>Although citations
        in the scholarly literature are the most interesting links the DLM service
        can discover, DLM also searches other data sources such as the bookmarking
        service <a href=\"http://citeulike.org/\">CiteULike</a>, the <a href=\"http://orcid.org/\">ORCID</a>
        registry of personal author identifiers, and Wikipedia (in this case for <a
        href=\"http://search.datacite.org/?query=10.5061/DRYAD.868SM%5D\">10.5061/DRYAD.868SM</a>:</p>\n<figure
        class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-09-09-um-17-33-21.png\"
        class=\"kg-image\" alt=\"Data from: ontogeny, morphology and taxonomy\" loading=\"lazy\"
        width=\"1680\" height=\"828\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/Bildschirmfoto-2015-09-09-um-17-33-21.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/08/Bildschirmfoto-2015-09-09-um-17-33-21.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2022/08/Bildschirmfoto-2015-09-09-um-17-33-21.png
        1600w, https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-09-09-um-17-33-21.png
        1680w\" sizes=\"(min-width: 720px) 720px\"></figure>\n<p>We hope you find
        this information useful when you use <a href=\"http://search.test.datacite.org/\">Labs
        Search</a>, but there still remains a lot of work to do, including:</p>\n<ul><li>display
        numerical data, e.g. download counts or Mendeley readers,</li><li>integrate
        the DLM data into the search index, so that we can use the data for filtering
        and sorting, e.g. <em>show me all datasets from data center x that have been
        cited at least 3 times</em>),</li><li>harmonize the use of <code>relationType</code>,
        e.g. be consistent with <code>Is referenced By</code> vs. <code>Is cited By</code>,</li><li>display
        more information rather than only links (DLM stores at least title, authors
        and publication date for all links),</li><li>potentially show citations for
        the corresponding journal article if the data were published together with
        the article (as in the Dryad case above) - DLM is collecting this information,
        and</li><li>learn from the community about the utility of a DLM service.</li></ul>\n<p>As
        always with DataCite Labs projects, your feedback is greatly appreciated.</p>\n<h2
        id=\"acknowledgments\">Acknowledgments</h2>\n<p>This blog post was <a href=\"https://doi.org/10.5438/jzg5-vcqv\">originally
        published</a> on the DataCite Blog.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Using YAML Frontmatter with CSV ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/using-yaml-frontmatter-with-csv/\"
        />\n\t\t<id>https://doi.org/10.53731/r79tfth-97aq74v-ag53f</id>\n        <published>2015-09-03T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-19T08:03:55.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p><a href=\"https://en.wikipedia.org/wiki/Comma-separated_values\">CSV</a>
        (comma-separated values) is a popular file format for data. It is popular
        because it is very simple: CSV is text-based and any application that can
        open text files can read or write CSV. This makes it a good fit for <a href=\"http://www.digitalpreservation.gov/formats/fdd/fdd000323.shtml\">digital
        preservation</a>. We don't know how many of the datasets in DataCite use CSV
        because the <code>format</code> metadata attribute is not used much (<a href=\"https://search.datacite.org/works?query=format%3Acsv\">this
        query</a> gives you some examples), but we know that the number is big.</p><p>The
        CSV format has two important shortcomings: a) it is not clearly defined, and
        b) because of its simplicity it is almost impossible to add metadata describing
        the data in the CSV file. The closest thing we have to a CSV standard definition
        is <a href=\"https://tools.ietf.org/html/rfc4180\">RFC 4180</a>, but that
        RFC clearly states that <em>It does not specify an Internet standard of any
        kind</em>.</p><p>If for some reason you think that the above sounds very similar
        to the situation with <em>markdown</em>, a simple format for text documents
        that <a href=\"http://spec.commonmark.org/0.22/\">until recently</a> was not
        clearly defined and that provides no easy way to add metadata (such as author,
        title or date), then you are smarter than me, since I didn't see the connection
        until <a href=\"https://github.com/jrovegno\">Javier Rovegno</a> <a href=\"https://blog.front-matter.io/posts/metadata-in-scholarly-markdown\">commented
        on my personal blog last week</a>. He <a href=\"http://jrovegno.github.io/csvy/\">proposes</a>
        to use the <em>YAML frontmatter</em> spec for CSV files, and I think it is
        a brilliant idea.</p><p><a href=\"http://jekyllrb.com/docs/frontmatter/\">YAML
        frontmatter</a> is a popular way to add metadata to markdown files. <a href=\"http://yaml.org/\">YAML</a>
        is a data serialization format that is very human-readable (in contrast to
        XML and to a lesser degree JSON). Frontmatter simply means to have the YAML
        section at the beginning of the document, e.g. the following, taken from the
        <a href=\"http://pandoc.org/README.html\">Pandoc documentation</a>:</p><pre><code>---\ntitle:
        \ 'This is the title: it contains a colon'\nauthor:\n- name: Author One\n
        \ affiliation: University of Somewhere\n- name: Author Two\n  affiliation:
        University of Nowhere\ntags: [nothing, nothingness]\nabstract: |\n  This is
        the abstract.\n\n  It consists of two paragraphs.\n---</code></pre><p>By adding
        a similar section to CSV files we can add arbitrary metadata, including longer
        text such as a file description. In other words, all the metadata required
        to submit a CSV to a data repository and obtain a DOI. This makes data submission
        even simpler than using a zip bundle <a href=\"https://blog.front-matter.io/posts/reference-lists-and-tables-of-content/\">as
        discussed in an earlier post</a>, or using the <a href=\"https://doi.org/10.12688/f1000research.3-6.v2\">DataUp
        tool</a>, a Microsoft Excel add-in that is unfortunately no longer available.</p><p>Javier
        has picked <code>.csvy</code> as file extension for this modified file format
        (I like <code>.ycsv</code> a little bit better). I don't think we need to
        define what metadata can go into the YAML frontmatter, because there a number
        of different use cases. The only exception would be a standardized way to
        describe the columns in the CSV file, e.g.:</p><pre><code>---\ncolumns:\n
        \ - title: Purchase Date\n    type: date\n  - title: Item\n    type: string\n
        \ - title: Amount (\u20AC)\n    type: float\n---</code></pre><p>The best alternative
        to using CSV in combination with YAML is JSON, but that format is probably
        less popular than CSV for the typical data scientist (I like JSON for nested
        data, which would be very painful in CSV). Most people generate a separate
        file for CSV metadata now, risking that the data and metadata are separated.</p><p>Many
        tools for reading CSV files - including Microsoft Excel and the <code>read.csv</code>
        function in R - can ignore an arbitrary number of lines at the beginning of
        a CSV file, making the proposed format at least to some extend backwards-compatible.
        But I hope to soon see tools reading and writing YAML frontmatter in CSV files,
        taking full advantage of the format. In my own work I produce a lot of CSV
        files using R, and adding metadata to them will greatly enhance their usability.
        Even better if we start to see YAML frontmatter support for CSV in multiple
        languages, including Python, Javascript, Ruby and Julia.</p><p><em>This blog
        post was <a href=\"https://doi.org/10.5438/5hzj-5kds\">originally published</a>
        on the DataCite Blog.</em></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Digging into Metadata using R ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/digging-into-metadata-using-r/\"
        />\n\t\t<id>https://doi.org/10.53731/r79tp4h-97aq74v-ag54x</id>\n        <published>2015-08-20T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-15T12:30:51.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/unnamed-chunk-10-1.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/unnamed-chunk-10-1.png\"></p><p>In
        the first post of this new blog a few weeks ago I talked about <a href=\"https://blog.datacite.org/data-driven-development/\">Data-Driven
        Development</a>, and that service monitoring is an important aspect of this.
        The main service DataCite is providing is registration of digital object identifiers
        (DOIs) for scholarly content, in particular research data.</p><p>Monitoring
        this service should include the following:</p><ol><li>number of DOIs registered</li><li>metadata
        associated with these DOIs</li><li>are the DOIs working as expected, e.g.
        are they resolving to the appropriate landing page</li><li>are these DOIs
        actually used, based on number of downloads, citations, etc. of the resources
        they are describing</li></ol><p>We can use the DataCite Search API to address
        #1 and #2. The <a href=\"http://stats.datacite.org/\">DataCite Statistics
        Portal</a> uses the API and is an excellent starting point for #1, showing
        the number of DOIs registered broken down by allocator and data center.</p><p>To
        get more detailed information about #1, and to look into #2, we can use the
        statistical programming language <a href=\"https://www.r-project.org/\">R</a>
        and the <a href=\"https://github.com/ropensci/rdatacite\">rdatacite</a> package
        by Scott Chamberlain from the <a href=\"https://ropensci.org/\">rOpenSci</a>
        to talk to the DataCite API. I have started to work on this and have created
        the public repository <a href=\"https://github.com/datacite/metadata-reports\">metadata-reports</a>
        on Github for this purpose. The first two reports are</p><ul><li><a href=\"https://github.com/datacite/metadata-reports/blob/master/overview/index.md\">overview</a>:
        number of registered DOI names</li><li><a href=\"https://github.com/datacite/metadata-reports/blob/master/orcid/index.md\">orcid</a>:
        DOI names with ORCIDs in the metadata</li></ul><p>In the overview report I
        look at the number of DOI names registered over time, with some examples where
        these numbers are broken down by data center and resource type. Below are
        two examples for data packages from <strong><strong>Dryad</strong></strong>
        and software from <strong><strong>Zenodo</strong></strong>:</p><figure class=\"kg-card
        kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/unnamed-chunk-10-1.webp\"
        class=\"kg-image\" alt=\"Dryad data packages by month\" loading=\"lazy\" width=\"960\"
        height=\"480\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/unnamed-chunk-10-1.webp
        600w, https://blog.front-matter.io/content/images/2022/08/unnamed-chunk-10-1.webp
        960w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Dryad data packages
        by month</figcaption></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/unnamed-chunk-12-1.webp\"
        class=\"kg-image\" alt=\"Zenodo resources of type software created by month\"
        loading=\"lazy\" width=\"960\" height=\"480\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/unnamed-chunk-12-1.webp
        600w, https://blog.front-matter.io/content/images/2022/08/unnamed-chunk-12-1.webp
        960w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Zenodo resources of
        type software created by month</figcaption></figure><p>In the orcid report
        I look at the number of DOI names that have at least one Open Researcher and
        Contributor ID (ORCID) in the metadata.</p><figure class=\"kg-card kg-image-card
        kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/unnamed-chunk-3-1.webp\"
        class=\"kg-image\" alt=\"DataCite DOI names with ORCID IDs by month\" loading=\"lazy\"
        width=\"960\" height=\"480\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/unnamed-chunk-3-1.webp
        600w, https://blog.front-matter.io/content/images/2022/08/unnamed-chunk-3-1.webp
        960w\" sizes=\"(min-width: 720px) 720px\"><figcaption>DataCite DOI names with
        ORCID IDs by month</figcaption></figure><p>The report goes in more detail
        explaining the two peaks, basically two small group of researchers producing
        a large number of data sets (at Pangaea and Imperial College, respectively),
        and including their ORCID identifiers will all of them.</p><p>Removing these
        two groups of researchers shows a more organic pattern, with about 500 DOIs
        with associated ORCIDs created every month.</p><figure class=\"kg-card kg-image-card
        kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/unnamed-chunk-11-1.webp\"
        class=\"kg-image\" alt=\"DOI names with ORCID IDs filtered\" loading=\"lazy\"
        width=\"960\" height=\"480\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/unnamed-chunk-11-1.webp
        600w, https://blog.front-matter.io/content/images/2022/08/unnamed-chunk-11-1.webp
        960w\" sizes=\"(min-width: 720px) 720px\"><figcaption>DOI names with ORCID
        IDs filtered</figcaption></figure><p>R is a nice reporting tool for these
        kinds of data, and the <a href=\"https://github.com/ropensci/rdatacite\">rdatacite</a>,
        <a href=\"http://rmarkdown.rstudio.com/\">rmarkdown</a> and <a href=\"http://yihui.name/knitr/\">knitr</a>
        packages make the analysis and visualization a straightforward process. Feel
        free to adapt the code in the Github repository to your specific questions,
        or let me know what other reports you would like to see.</p><p><em>This blog
        post was <a href=\"https://doi.org/10.5438/1hv8-2gc2\">originally published</a>
        on the DataCite Blog.</em></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ From Pilot to Service ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/from-pilot-to-service/\" />\n\t\t<id>https://doi.org/10.53731/r795jkh-97aq74v-ag4bs</id>\n
        \       <published>2015-08-17T00:00:00.000+00:00</published>\n\t\t<updated>2023-09-07T08:17:34.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-08-17-um-14-05-16-1.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-08-17-um-14-05-16-1.png\"></p><p>Today
        I am pleased to announce the launch of a new service, DataCite Labs Search
        \u2013 the service is available immediately at <a href=\"https://search.datacite.org/\">https://search.datacite.org/</a>.
        This is one of <a href=\"http://project-thor.eu/\">THOR</a>\u2019s first services
        and is based on work in the earlier EC-funded <a href=\"http://odin-project.eu/\">ODIN
        Project</a>.</p>\n<p>The ODIN project <a href=\"http://odin-project.eu/2013/05/13/new-orcid-integrated-data-citation-tool/\">launched
        the DataCite/ORCID claiming tool</a> in June 2013. The DataCite/ORCID claiming
        tool allows users to add works from the DataCite Metadata Store (MDS) to their
        ORCID profile. This was a successful pilot, enabling researchers to add their
        datasets to the ORCID service infrastructure.</p>\n<p>THOR, the follow-up
        project to ODIN, started in June 2015. One of the goals of THOR is to build
        sustainable persistent identifier services based upon the piloting work done
        in ODIN.</p>\n<p>The new DataCite Labs Search includes all functionality of
        the DataCite/ORCID claiming tool, but we have made some additional changes:</p>\n<ul><li>re-deployed
        the service in the DataCite data center,</li><li>merged the code repository
        back with the original CrossRef repo, and</li><li>started work on making the
        service the default DataCite search.</li></ul>\n<p><a href=\"http://blog.datacite.org/overcoming-development-pain/\">Last
        week</a> I spoke a bit about the differences between how to deploy a pilot
        project and a production service.</p>\n<h3 id=\"crosscite\">Crosscite</h3>\n<p>The
        DataCite/ORCID claim tool was started in 2013 as a fork of the <a href=\"https://github.com/CrossRef/cr-search\">open
        source code</a> for the <a href=\"http://search.crossref.org/\">CrossRef Metadata
        Search</a>. There are some subtle, but important differences between the CrossRef
        and DataCite Search API, and some other changes were introduced as well. Going
        forward we wanted to bring the two code bases together again, both for faster
        development and to make it easier for users: there shouldn't for example be
        much of a difference for a user between claiming a work to your ORCID profile
        from the CrossRef Metadata Search and the DataCite Labs Search. Since this
        month development happens in a common code repository in the <strong>Crosscite</strong>
        Github organization, and the project has been renamed to <a href=\"https://github.com/crosscite/doi-metadata-search\">doi-metadata-search</a>.
        You can follow along development via Github Issues or <a href=\"https://waffle.io/crosscite/doi-metadata-search\">this
        waffle.io board</a>:</p>\n<figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-08-17-um-15-27-14.png\"
        class=\"kg-image\" alt=\"Waffle.io\" loading=\"lazy\" width=\"2000\" height=\"1128\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/Bildschirmfoto-2015-08-17-um-15-27-14.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/08/Bildschirmfoto-2015-08-17-um-15-27-14.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2022/08/Bildschirmfoto-2015-08-17-um-15-27-14.png
        1600w, https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-08-17-um-15-27-14.png
        2120w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span>Waffle.io</span></figcaption></figure>\n<h3
        id=\"search\">Search</h3>\n<p>Allowing users to add works with DataCite DOIs
        to their ORCID profile should not be done in a separate service, but is ideally
        part of the standard search interface to DataCite that users use anyway. We
        therefore have to make <a href=\"https://search.datacite.org/\">DataCite Labs
        Search</a> at least as good as the current DataCite Search. Both services
        use the DataCite Search API as their backend, but the user interface they
        provide is different. Some of the differences in Labs Search include:</p>\n<ul><li>a
        single search box</li><li>all information is shown in a list view, no linking
        to pages on data.datacite.org</li><li>citation formatter</li><li>filter results
        by Creative Commons license</li><li>an updated user interface</li></ul>\n<p>The
        single input field for searching should be appropriate for most queries, but
        Labs Search also supports <a href=\"https://cwiki.apache.org/confluence/display/solr/The+DisMax+Query+Parser\">DisMax</a>
        query syntax for more complex searches, and automatically detects DOI and
        ORCID names. Try some more complex queries, e.g. all presentations by a particular
        person.</p>\n<figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-08-17-um-14-13-09.png\"
        class=\"kg-image\" alt=\"Citation\" loading=\"lazy\" width=\"1848\" height=\"780\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/Bildschirmfoto-2015-08-17-um-14-13-09.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/08/Bildschirmfoto-2015-08-17-um-14-13-09.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2022/08/Bildschirmfoto-2015-08-17-um-14-13-09.png
        1600w, https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-08-17-um-14-13-09.png
        1848w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span>Citation</span></figcaption></figure>\n<p>Providing
        the metadata as formatted citation is an important feature that facilitates
        data citation. With BibTeX and RIS two standard import formats for reference
        managers are also supported. This feature is basically unchanged since 2013,
        and relies on the <a href=\"http://crosscite.org/\">DOI content negotiation</a>
        API provided by several DOI registration agencies. In addition, COinS is supported,
        allowing the import of multiple items at once, e.g. into a reference manager.</p>\n<figure
        class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-08-17-um-14-22-48.png\"
        class=\"kg-image\" alt=\"COinS\" loading=\"lazy\" width=\"2000\" height=\"993\"
        srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/Bildschirmfoto-2015-08-17-um-14-22-48.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/08/Bildschirmfoto-2015-08-17-um-14-22-48.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2022/08/Bildschirmfoto-2015-08-17-um-14-22-48.png
        1600w, https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-08-17-um-14-22-48.png
        2066w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span>COinS</span></figcaption></figure>\n<p>Allowing
        users to search for content based on what they are allowed to do with it is
        another important feature of Labs Search. We are using the <strong>rightsURI</strong>
        metadata field and the standard Creative Commons licenses. You can for example
        limit your search to content that uses the standard Wikipedia license <a href=\"https://en.wikipedia.org/wiki/Wikipedia:CC_BY-SA_Compliance\">CC-BY-SA</a>
        (see above), or you might exclude content that doesn't allow commercial reuse
        and/or derivative works. The <strong>rightsURI</strong> field allows for multiple
        licenses, but unfortunately, less than 25% of DataCite DOI metadata include
        a Creative Commons license.</p>\n<h3 id=\"labs\">Labs</h3>\n<p>We are launching
        this updated tool as a DataCite Labs service instead of replacing the production
        service at search.datacite.org. There are two reasons: a) there are still
        some rough edges and possibly bugs, and b) we need to collect broader feedback
        from users before this can replace the current DataCite search. We plan to
        do this switch in the next 1-3 months, depending on user feedback. Please
        comment on this blog post, open a <a href=\"https://github.com/crosscite/doi-metadata-search/issues\">Github
        issue</a>, tweet about it mentioning #datacite, or send an email to <strong>support@datacite.org</strong>.</p>\n<p>Expect
        to see more new/updated DataCite services first appearing as DataCite Labs
        in the future.</p>\n<h3 id=\"acknowledgments\">Acknowledgments</h3>\n<p>This
        is a collaborative effort and I want to thank the DataCite and THOR teams,
        and in particular Karl Ward, Gudmundur Thorisson, Sebastian Peters, Rob Peters,
        Laura Rueda, Tom Demeranville, Geoff Bilder, Laure Haak, and Laura Paglione.
        This blog post was <a href=\"https://doi.org/10.5438/s8gf-0ck9\">originally
        published</a> on the DataCite Blog. This work was funded by the European Union\u2019s
        Horizon 2020 research and innovation programme under&nbsp;<a href=\"https://doi.org/10.3030/654039\"
        rel=\"noreferrer\">grant agreement No.&nbsp;654039</a>.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Overcoming Development Pain ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/overcoming-development-pain/\" />\n\t\t<id>https://doi.org/10.53731/r79t1hh-97aq74v-ag504</id>\n
        \       <published>2015-08-15T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-15T12:36:15.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-08-11-um-20-14-30.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-08-11-um-20-14-30.png\"></p><p>Today
        DataCite received an email from a user alerting us that there are some small
        inconsistencies with our recommended data citation format:</p><pre><code>Creator
        (PublicationYear): Title. Publisher. Identifier</code></pre><p>at <a href=\"https://www.datacite.org/services/cite-your-data.html\">https://www.datacite.org/services/cite-your-data.html</a></p><pre><code>Creator;
        (PublicationYear): Title; Publisher. Identifier</code></pre><p>at <a href=\"https://search.datacite.org/works/10.5061/DRYAD.8C1P6\">search.datacite.org</a></p><p>Removing
        two semicolons at <strong><strong>data.datacite.org</strong></strong> looks
        like an easy fix, but this is a bit more complicated since the data citation
        at <strong><strong>data.datacite.org</strong></strong> is automatically generated
        using an existing citation style, which looks just slightly different (<a
        href=\"http://citationstyles.org/\">http://citationstyles.org/</a> doesn't
        have a <strong><strong>DataCite</strong></strong> style). Support for data
        citation style is a topic for another blog post, but here I want to talk about
        what it takes to make changes to DataCite's website or services to fix a bug
        or add a feature.</p><p>In most cases even small changes like this one require
        us to deploy new code. Fixing the code in place is usually a bad idea because
        it makes it hard to track changes over time. When we deploy new code we have
        to make sure that we are really only making that small change and not changing
        something else in the process, e.g. because a support library is automatically
        updated to a newer version. So we should run tests to make sure everything
        is ok and we have to deploy the new code to our test system first. Before
        we know it this seemingly small change becomes a bigger undertaking.</p><p>The
        end result is of course - and this is not something limited to DataCite -
        that we deploy code that fixes bugs, adds new features or applies security
        updates far less frequently than we would like.</p><p>This is frustrating
        to everyone involved, and not surprisingly, many people have tried to speed
        up the software deployment process with concepts such as <a href=\"http://12factor.net/dev-prod-parity\">dev-prod-parity</a>
        (keep development, staging, and production as similar as possible) and <a
        href=\"http://www.thoughtworks.com/continuous-integration\">continuous integration</a>,
        and tools such as <a href=\"https://www.vagrantup.com/\">Vagrant</a> and <a
        href=\"https://www.docker.com/\">Docker</a>.</p><p>For the project I am <a
        href=\"https://github.com/crosscite/doi-metadata-search\">currently working
        on</a> I have started to add better test coverage and the continuous integration
        build is currently passing:</p><figure class=\"kg-card kg-image-card\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/failing.svg\" class=\"kg-image\"
        alt=\"Build Status\" loading=\"lazy\" width=\"90\" height=\"20\"></figure><p>It
        is a Ruby project and I can use <a href=\"http://capistranorb.com/\">capistrano</a>
        to deploy a new version to the production server in about a minute.</p><h3
        id=\"the-data-center\">The data center</h3><p>The above is unfortunately a
        very developer-centric view. Deployment is more than pushing updated code
        to a server. We also need to worry about installing/updating all required
        software on the server and making configuration changes where needed. And
        we need to worry about how the server is configured in our data center in
        terms of access to the internet, security settings, etc. Although there is
        often an overlap in the tools we can use, deployment really has three aspects:</p><ol><li>code
        deployment</li><li>server configuration/bootstrapping</li><li>infrastructure
        configuration</li></ol><p>Since starting at DataCite last week, I have spent
        a good amount of my time working on #2 and #3. The basic assumption is that
        <a href=\"http://www.thoughtworks.com/insights/blog/infrastructure-code-reason-smile\">infrastructure
        is code</a>.</p><p>Server configurations don't change that often, so it is
        more important to make sure the server is configured exactly as expected rather
        than saving a few minutes of time. A good approach is therefore to automate
        the building of a virtual machine or container of the server. DataCite is
        using Amazon AWS for hosting, and I am using <a href=\"https://www.packer.io/\">Packer</a>
        and <a href=\"https://www.chef.io/\">Chef</a> to automatically build an Amazon
        Machine Image (AMI) for the server I am working on currently. If you want
        to follow along (and have an AWS account and the open source Packer and Chef
        installed), <a href=\"https://github.com/crosscite/doi-metadata-search\">git
        clone the repo</a> and issue this command:</p><pre><code>packer build template.json</code></pre><p>To
        add the AMI we just build to the data center; I use <a href=\"https://www.terraform.io/\">terraform</a>.
        The beginning of the server configuration (in a private repo because security
        groups, etc. are also included) is:</p><pre><code>provider \"aws\" {\n    access_key
        = \"${var.access_key}\"\n    secret_key = \"${var.secret_key}\"\n    region
        = \"${var.region}\"\n}\n\nresource \"atlas_artifact\" \"labs-search\" {\n
        \   name = \"datacite/doi-metadata-search\"\n    type = \"amazon.ami\"\n    build
        = \"latest\"\n}</code></pre><p>A <code>terraform apply</code> will build the
        infrastructure described by terraform. As the last step we need to run <strong><strong>capistrano</strong></strong>
        to deploy the latest code (not included in the AMI because the app is currently
        under heavy development).</p><p>To link the above workflows together we use
        <a href=\"https://atlas.hashicorp.com/\">Atlas</a>, a commercial tool, but
        free for the number of servers that we need to manage at DataCite. One of
        the nice features of Atlas is that we can trigger terraform runs by changing
        the terraform configuration files stored in a Github repository, so really
        infrastructure as code:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-08-11-um-20-14-30.webp\"
        class=\"kg-image\" alt=\"Infrastructure as code\" loading=\"lazy\" width=\"1870\"
        height=\"872\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/Bildschirmfoto-2015-08-11-um-20-14-30.webp
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/08/Bildschirmfoto-2015-08-11-um-20-14-30.webp
        1000w, https://blog.front-matter.io/content/images/size/w1600/2022/08/Bildschirmfoto-2015-08-11-um-20-14-30.webp
        1600w, https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-08-11-um-20-14-30.webp
        1870w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Infrastructure as code</figcaption></figure><p>Finally,
        we want to notify the team when applying these changes to the DataCite infrastructure,
        and we use email and Slack for this:</p><figure class=\"kg-card kg-image-card
        kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-08-11-um-20-20-48.webp\"
        class=\"kg-image\" alt=\"Email and Slack\" loading=\"lazy\" width=\"1102\"
        height=\"482\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/Bildschirmfoto-2015-08-11-um-20-20-48.webp
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/08/Bildschirmfoto-2015-08-11-um-20-20-48.webp
        1000w, https://blog.front-matter.io/content/images/2022/08/Bildschirmfoto-2015-08-11-um-20-20-48.webp
        1102w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Email and Slack</figcaption></figure><p>I
        am working on integrating <strong><strong>Docker</strong></strong> into this
        workflow, as Docker containers are much more flexible than Amazon Machine
        Images.</p><p>This post is a pretty long-winded way of saying we need to fix
        a typo at <strong><strong>data.datacite.org</strong></strong>, but this is
        of course only one of several issues on our list of <a href=\"https://github.com/datacite/content-resolver/issues\">bugs
        to fix</a>.</p><p><em>This blog post was <a href=\"https://doi.org/10.5438/xc6c-ef54\">originally
        published</a> on the DataCite Blog.</em></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Data-Driven Development ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/data-driven-development/\" />\n\t\t<id>https://doi.org/10.53731/r79tt01-97aq74v-ag55w</id>\n
        \       <published>2015-08-03T00:00:00.000+00:00</published>\n\t\t<updated>2023-07-02T10:11:27.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/Fel_048248-RE-2.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/Fel_048248-RE-2.jpeg\"></p><p>This
        week I start as the new DataCite Technical Director. While I get up to speed
        with existing DataCite services and infrastructure, and we start to launch
        new services (e.g. this blog), this is also a good time to communicate the
        overall approach I am taking. I like to call it <strong><strong>Data-Driven
        Development</strong></strong>, or <strong><strong>DDD</strong></strong> as
        we all love acronyms.</p><h2 id=\"definition\">Definition</h2><p>Data-Driven
        Development and related terms are in use in several contexts, in particular
        <a href=\"http://reports.weforum.org/data-driven-development/\">economics</a>,
        and <a href=\"https://en.wikipedia.org/wiki/Data-driven_programming\">programming</a>.
        The term sounds similar to <a href=\"https://en.wikipedia.org/wiki/Test-driven_development\">test-driven
        development</a> and <a href=\"https://en.wikipedia.org/wiki/Behavior-driven_development\">behavior-driven
        development</a>, two related software development processes. <a href=\"https://en.wikipedia.org/wiki/Business_intelligence\">Business
        intelligence</a> and <a href=\"https://en.wikipedia.org/wiki/Data_science\">data
        science</a> are of course closely related. My definition is as follows:</p><blockquote>We
        develop and maintain our services based on data.</blockquote><p>This shouldn't
        come as a surprise as DataCite's mission is <strong><strong>Helping you to
        find, access and reuse data</strong></strong>. And my last job at the Open
        Access publisher <a href=\"http://plos.org/\">PLOS</a> was all about <a href=\"https://doi.org/10.1371/journal.pbio.1001687\">collecting
        and presenting data</a> about the reuse of scholarly articles (citations,
        downloads, social media mentions, etc.). But here I mean <strong><strong>data</strong></strong>
        in a much broader sense.</p><h2 id=\"product-development\">Product Development</h2><p>While
        the overall strategic direction is determined by the Board together with the
        DataCite working groups and members, we can collect data that help with decisions
        in product development, for example</p><ul><li>service monitoring (see below):
        how are our services used over time, are there any components that are particularly
        popular, etc.</li><li><a href=\"https://www.uservoice.com/\">user feedback</a>:
        ideas, feedback, <a href=\"https://www.optimizely.com/ab-testing/\">A/B testing</a></li><li><a
        href=\"https://github.com/blog/1866-the-new-github-issues\">bug reports</a></li><li><a
        href=\"http://www.discourse.org/\">discussion boards</a> and <a href=\"https://slack.com/is\">direct
        group messages</a>: related to the last two points, but more allowing a more
        open discussion</li><li>community events</li></ul><p>Compared with the next
        two sections, tools for data-driven product development are less commonplace
        (unless I missed them, in which case please provide feedback).</p><h2 id=\"software-development\">Software
        Development</h2><p>The data generated during software development are increasingly
        made available through automated tools. We can</p><ul><li>get detailed information
        out of the <a href=\"https://github.com/datacite\">version control system</a></li><li>check
        for passing and failing tests in <a href=\"https://travis-ci.org/\">continuous
        integration servers</a></li><li>check <a href=\"https://codeclimate.com/\">test
        coverage and overall code quality</a></li><li><a href=\"https://houndci.com/\">check
        for consistent coding style</a></li></ul><h2 id=\"service-monitoring\">Service
        Monitoring</h2><p>Any web-based service can and should be monitored for</p><ul><li><a
        href=\"https://bugsnag.com/\">crashes and other serious errors</a></li><li><a
        href=\"http://newrelic.com/\">server load</a>, <a href=\"https://www.pingdom.com/\">server
        outages</a> and <a href=\"https://www.nagios.org/\">internal server problems</a></li><li><a
        href=\"http://www.google.com/analytics/\">server traffic</a>, including traffic
        to particular pages, percentage of mobile and non-English users, etc.</li><li>specific
        monitoring for the services you are offering, e.g. in the case of DataCite
        <a href=\"http://stats.datacite.org/\">number of DOIs registered</a> (broken
        down by data center), number of DOIs with specific metadata (e.g. ORCID identifiers
        for creators and funding information), and number of DOI resolutions (tricky
        because there is no easy way to filter out bots)</li><li>user-generated feedback
        (see section product development)</li></ul><h2 id=\"communication\">Communication</h2><p>We
        don't want to stop at collecting all these data, we also need a strategy for
        providing them to the DataCite Board, DataCite working groups, DataCite members
        and data centers, DataCite staff, and everyone else who cares about these
        data. The default should be open, exceptions are mostly data that would raise
        privacy or security concerns, e.g. IP addresses in usage stats. Most of the
        services mentioned in this post are open for everyone to look at.</p><h2 id=\"synthesis\">Synthesis</h2><p>Good
        data-driven development should not only collect lots of data and make them
        available, but we also need to aggregate the information in meaningful ways.
        Service monitoring is a good example where staff needs to understand exactly
        what is going on, but the typical DataCite user only cares about whether all
        services are running as expected. A <a href=\"https://status.github.com/\">status
        dashboard</a> would be a good solution here.</p><p>The data we are generating
        also need to be put into the broader context. We need</p><ul><li>the DataCite
        Board to use them for strategic planning</li><li>to provide these data to
        the DataCite working groups to feed into their work (e.g. stats on what metadata
        are submitted by data centers for the <a href=\"https://www.datacite.org/tags/metadata-working-group\">Metadata
        Working Group</a></li><li>the DataCite staff to integrate them in their work
        (e.g. the Communications Director utilizing the website usage stats)</li><li>these
        data to adapt the software development roadmap and service infrastructure</li></ul><h2
        id=\"implementation\">Implementation</h2><p>Of course I am aware that this
        is an ambitious agenda, in particular since DataCite is a small non-profit
        that has limited staff and financial resources. But I don't think that data-drive
        development should be left to for-profit organizations and/or to organizations
        of a certain size. There are several things DataCite can do:</p><ul><li>implement
        DDD practices over time, starting with one service and one aspect</li><li>use
        service providers wherever it makes sense (<a href=\"http://thenewstack.io/new-stack-mitchell-hashimoto-containers-no-containers-one-question-2015/\">there
        is a future where you yourself are running less servers</a>). This means anything
        that is not core to the DataCite mission and where the service provider is
        better and/or cheaper than what you could do internally. This evaluation can
        of course change over time</li><li>collaborate with other scholarly non-profits
        on infrastructure, including DataCite members and data centers, and other
        persistent identifier providers such as CrossRef and ORCID</li></ul><p><em>This
        blog post was <a href=\"https://doi.org/10.5438/dhsm-8219\">originally published</a>
        on the DataCite Blog.</em></p><h2 id=\"references\">References</h2><p>Unknown.
        <em>Hannover, Blick auf Hannover</em>. ETH-Bibliothek Z\xFCrich, Bildarchiv;
        1931. doi:<a href=\"https://doi.org/10.3932/ETHZ-A-000159123\">10.3932/ETHZ-A-000159123</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Thank you PLOS ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/thank-you-plos/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cvzn</id>\n        <published>2015-07-29T10:52:00.000+00:00</published>\n\t\t<updated>2023-09-02T08:16:13.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2023/09/thankyou-1.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2023/09/thankyou-1.png\"></p><p><a
        href=\"https://www.datacite.org/news/martin-fenner-and-laura-rueda-join-datacite-team.html\">Starting
        next week</a> I will work as the DataCite Technical Director, and I am excited
        about this new opportunity. But this is material for another post, here I
        want to reflect on the last three years working as Technical Lead for the
        <a href=\"http://lagotto.io/plos/\">PLOS Article-Level Metrics</a> project.</p><p>It
        feels much longer than three years, but until May 2012 I worked as medical
        oncologist at Hannover Medical School, treating patient with cancer, attending
        interdisciplinary tumor boards and helping with clinical trials. It was a
        very brave move by PLOS to hire me at this point, especially since I <a href=\"https://blog.front-matter.io/posts/why-should-we-work-where-we-live\">worked
        remotely</a> from Germany rather than in the San Francisco office. I will
        be forever thankful to PLOS for giving me this opportunity.</p><p>Two factors
        probably played a role in this decision: I have been blogging about how the
        internet is changing scholarly communication since 2007, and since September
        2010 I had <a href=\"http://blogs.plos.org\">my blog on the PLOS Blogs Network</a>.
        I had also visited the PLOS offices in San Francisco, and had met several
        PLOS people at conferences, including Pete Binfield, Rich Cave, Mark Patterson,
        Brian Mossop, Jennifer Lin and Liz Allen. I had <a href=\"https://blog.front-matter.io/posts/plos-one-interview-with-peter-binfield\">interviewed</a>
        Pete Binfield about PLOS ONE and the PLOS Article-Level Metrics project in
        August 2009, shortly after the project was launched.</p><p>The other factor
        was the hackathon at the 2011 Science Online London conference. We were a
        really small group of people (I remember Jason Hoyt, Victor Henning, Kristi
        Holmes and Cameron Neylon, Mendeley was hosting the event), but I had the
        idea to hack the open source PLOS Article-Level Metrics application. This
        hack turned into <a href=\"https://blog.front-matter.io/posts/announcing-sciencecard/\">ScienceCard</a>,
        a version of the PLOS Article-Level Metrics application focussing on people
        rather than articles, and the application was a finalist for the <a href=\"http://blog.mendeley.com/highlighting-research/the-top-101-apps-in-the-mendeley-plos-binary-battle/\">Mendeley/PLOS
        API Binary Battle</a>. ScienceCard doesn\u2019t exist anymore, but the concept
        of organizing metrics around a person lives on in ImpactStory, facilitated
        by the launch of ORCID in October 2012. More importantly - without me knowing
        it - ScienceCard demonstrated that I could work with and extend the PLOS Article-Level
        Metrics code, and I think I was the first person outside of PLOS doing this.
        Which must have helped when PLOS was looking for a technical lead for the
        project a few months later.</p><p>In other words, blogging and hacking code
        can lead to great job opportunities.</p><p>While at PLOS I not only learned
        a ton of things about article-level metrics and all its challenges and opportunities,
        but also many basic skills needed in software development. Which is important,
        as my formal training is in clinical medicine and molecular biology, and doing
        software development in your free time (which I had done since the 1990s)
        only gets you so far. Some of the unexpected things I learned:</p><ul><li><strong><strong>Visualizations</strong></strong>:
        while it was clear that I was expected to generate visualizations for the
        PLOS Article-Level Metrics data, I didn\u2019t expect this to go so deep,
        first with R and later with <a href=\"http://d3js.org/\">d3.js</a>. Najko
        Jahn introduced me to using R to analyze the PLOS data, and I later worked
        closely with Scott Chamberlain from the <a href=\"https://ropensci.org/\">rOpenSci</a>
        project to help improve their <a href=\"https://ropensci.org/tutorials/alm_tutorial.html\">alm
        package</a>. The Javascript work with d3.js started with AlmViz at the 2012
        ALM hackathon and later was done in close collaboration with Juan Alperin
        from the <a href=\"https://pkp.sfu.ca/\">Public Knowledge Project</a>.</li><li><strong><strong>DevOps</strong></strong>:
        the intersection of software development and system administration. I became
        a big fan and have spent endless hours learning how to automate the configuration
        and deployment of servers and other infrastructure.</li><li><strong>O<strong>pen
        source community building</strong></strong>: again something I was expected
        to do around the PLOS article-level metrics open source application, but I
        never expected this to be so challenging and time-consuming, but also rewarding.</li></ul><p>I
        thank everyone at PLOS who I had the pleasure to work with over the years,
        in particular Kristen Ratan, Cameron Neylon, Donna Okubo, Mei Yan Leung, Liz
        Allen, Catriona MacCallum, Matt Hodgkinson, Theo Bloom, Damian Pattinson,
        Ginny Barbour, Emma Ganley, Roli Roberts, Eric Martens, Susan Au, Matt Willman,
        Edgar Munoz, Rachel Drysdale, CJ Rayhill, Lisa Siegel, Jennifer Song, Polina
        Grinbaum, John Bertrand, Mike Baehr, Clark Hartsock, Adam Hyde, and Holly
        Allen. A very special thanks goes to Jennifer Lin, Rich Cave and John Chodacki
        who worked with me on a daily basis.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Component DOIs Revisited ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/component-dois-revisited/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cvzp</id>\n
        \       <published>2015-07-09T10:19:00.000+00:00</published>\n\t\t<updated>2023-07-12T09:13:16.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Four years ago I wrote a <a
        href=\"https://doi.org/10.53731/r294649-6f79289-8cw6x\">blog post</a> about
        component DOIs. It is time to revisit the topic, in particular since our approach
        to citing data associated with a publication has changed since 2011.</p><p>Component
        DOIs are explained in the <a href=\"http://help.crossref.org/components\">CrossRef
        Help System</a>:</p><blockquote>DOIs may be assigned to items that are part
        of a journal article, book chapter, or any other content item. A component
        would typically be a figure, table, or image which is part of or referred
        to by the parent item. Assigning a DOI to a component allows direct linking
        to the component item.</blockquote><p>Component DOIs are DOIs, i.e. persistent
        identifiers that link directly to the resource in question, e.g. a figure
        in a publication. The component DOI for a figure in a PLOS paper used in the
        2011 post still <a href=\"https://doi.org/10.1371/journal.pone.0006022.g002\">works
        as expected</a>, despite changes to the URL of the journal landing page.</p><p>The
        problem with component DOIs is the problem with DOIs in general: there is
        basic functionality common to all DOIs, and there are additional services
        specific to subgroups of DOIs. This confuses users - in particular since there
        is no easy way to immediately see what kind of DOI they have in front of them
        - and in the case of component DOIs, there is one important feature missing.</p><p>DOis
        are assigned by registration agencies (CrossRef and DataCite are the most
        relevant ones for scholarly content), and these RAs have built different services
        around DOIs, e.g. different ways to describe and search the metadata (title,
        authors, etc.) associated with a DOI. Component DOIs are again different,
        the most important difference is that in the CrossRef implementation they
        they are not discoverable by <a href=\"https://doi.org/10.3789/isqv22n3.2010.06\">querying
        the CrossRef system</a>. Component DOIs are also always associated with a
        parent DOI (for the article, book, etc.). Although this is the expected behavior,
        we shouldn\u2019t expect component DOIs to always look like an extension of
        the parent DOI, as in <code>10.1371/journal.pone.0006022.g002</code> used
        in the example above.</p><p>In essence, a component DOI is a <strong><strong>DOI
        light</strong></strong>. We can use them for persistent linking, but we can\u2019t
        use them for discovery via the CrossRef Metadata Search (and by extension
        other indexing services). A common use case for component DOIs is supplementary
        information in a journal article. Content in supplementary information files
        is already much harder to find than content in the body of an article, using
        component DOIs instead of regular DOIs makes the content again harder to find.</p><p>All
        of this might not have been much of an issue when I wrote the 2011 post, but
        making the data underlying a publication publicly available and discoverable
        is increasingly becoming something that funders, publishers, and institutions
        expect. Most of these data are not deposited in dedicated data repositories,
        but in supplementary information files (for PLOS articles published since
        March 2014 this is true for more than 50% of papers). Using regular DOIs for
        supplementary information files with proper metadata and proper inclusion
        in indexing services will make it easier to find, access, and reuse these
        data.</p><p>Unfortunately, that still leaves us with the problem that the
        supplementary information files then will have CrossRef DOIs, whereas data
        repositories typically use DataCite DOIs, so we need to search for these datasets
        in two different places. But that is material for another post.</p><h3 id=\"references\">References</h3><p>Fenner
        M. Direct links to figures and tables using component DOIs. Published online
        March 26, 2011. doi:<a href=\"https://doi.org/10.53731/r294649-6f79289-8cw6x\">10.53731/r294649-6f79289-8cw6x</a></p><p>Bollen
        J, Van De Sompel H, Hagberg A, Chute R. A Principal Component Analysis of
        39 Scientific Impact Measures. Mailund T, ed. <em>PLoS ONE</em>. 2009;4(6):e6022.
        doi:<a href=\"https://doi.org/10.1371/journal.pone.0006022\">10.1371/journal.pone.0006022</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Why should we work where we live? ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/why-should-we-work-where-we-live/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cvzq</id>\n        <published>2015-06-28T10:23:00.000+00:00</published>\n\t\t<updated>2022-08-15T12:38:37.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/photo-1502786129293-79981df4e689.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/photo-1502786129293-79981df4e689.jpeg\"></p><p>At
        the <a href=\"http://www.digital-science.com/events/scifoo-camp-2015/\">SciFoo
        Camp</a> this weekend <a href=\"https://emckiernan.wordpress.com/\">Erin McKiernan</a>
        and I moderated an unconference session on the topic <strong>Why should we
        work where we live?</strong> This was a spontaneous idea after we had talked
        about this topic on Friday (Erin lives in Mexico with a job in Canada, I live
        in Germany and work for an organization in San Francisco).</p><p>We quickly
        realized that this situation is far from uncommon in the space we work in
        (science and science communication). Most commonly the reason is compromises
        we have to make when both partners have to find an adequate job. It can be
        a big challenge for a couple to find senior jobs in academia in the same city
        or region, especially outside of academic clusters such as Boston, New York
        or London.</p><p>The other big reason for work remote is that some research
        can only happen in special places, for example in high-energy physics, astronomy
        or the geosciences. And of course there are other flavors of the same situation,
        e.g. when a principal investigator moves to a new institution and PhD students
        or postdocs can\u2019t or don\u2019t want to move with him/her. And most academics
        have to do at least some remote work, since they will spend a good amount
        of time traveling to conferences or collaboration partners.</p><p>The discussion
        in the session centered on the social and technical challenges of working
        remotely. We didn\u2019t have time to go into the legal aspects (e.g. taxes
        when you work in a different country), or the challenges organizing your personal
        life, particular difficult when you have children.</p><p>We shared our experience
        with online collaboration tools, and video conferencing with Skype, Google
        Hangouts or similar was central to this. Videoconferencing can be a challenge
        with slow internet connectivity, a situation that luckily is constantly improving.</p><p>Private
        group chat tool such as <a href=\"https://en.wikipedia.org/wiki/HipChat\">HipChat</a>
        or <a href=\"https://slack.com/\">Slack</a> are becoming increasingly popular
        outside the Tech sector and are a great alternative to email. They not only
        provide a platform for quick messages between two people, but also serve as
        a backchannel for informal \u201Cwater cooler\u201D discussions in an organization.</p><p>Another
        essential category is tools that track your work so that your remote colleagues
        not only can collaborate with you, but also see the work you are doing. As
        a supervisor you quickly see the work that was done the past week, a much
        more reasonable approach than looking at physical presence at work (where
        people might be doing all kinds of other things and personal productivity
        varies). Tracking your work is easy if you are a software developer like me
        and can look at code committed to version control, tickets closed, etc. For
        research this is more challenging, in particular if the workflow is not digital
        yet and for example all experiments are documented in a paper notebook. It
        seems that one requirement for remote work in science is digitalization of
        your work, but that is a direction we are heading anyway and which has other
        advantages (e.g. improving reproducibility). If there are no specialized tools
        for documenting your work available, then a note-taking tool such as <a href=\"https://www.onenote.com/\">OneNote</a>
        or <a href=\"https://evernote.com/\">Evernote</a> can be helpful. The digitization
        and automation of work is obviously limited in wet labs that require direct
        interactions with samples and instruments.</p><p>The social aspects of remote
        work might be the bigger challenge. There is still a big reluctance in supervisors
        and administrators to this, assuming that people will only be productive if
        someone is watching them. This assumption is very short sighted, as what drives
        PhDs and postdocs to work hard is not supervision, but the intrinsic motivation
        to accomplish something, in particular in light of the very competitive situation
        for permanent jobs in academia. The book <a href=\"http://37signals.com/remote/\">Remote</a>
        by Jason Fried talks about this in great detail in the context of software
        development, but the same principles apply to work in science. What supervisors
        and administrators loose in direct oversight they can in attracting talent
        they would otherwise not get. Remote work only works if supported by the host
        institution, for example by adapting internal workflows and communications
        to make remote work the default rather than an exception.</p><p>Remote work
        is usually more successful and satisfying if combined with physical presence
        at the workplace. Reasons for this are not only the part of the work that
        can\u2019t be done remotely, but more importantly the social aspect. How extensive
        this physical presence is depends on the circumstances. Some level of remote
        work has become part of almost everyone\u2019s job in science, as it includes
        working at home in the evenings or on weekends, or work while traveling.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Persistent Identifiers and URLs ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/persistent-identifiers-and-urls/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cvzr</id>\n        <published>2015-06-03T10:43:00.000+00:00</published>\n\t\t<updated>2022-08-17T08:52:49.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Just like the rest of the
        internet, much of our scholarly infrastructure is built around the Hypertext
        Transfer Protocol (HTTP), increasingly HTTPS for security, and soon <a href=\"https://http2.github.io/\">HTTP/2</a>
        for better performance. In this infrastructure Universal Resource Locators
        (URLs) are essential to locate resources (sic) such as scholarly articles,
        datasets, researchers, organizations, or grants. Read <a href=\"http://site.thomsonreuters.com/site/data-identifiers/\">this</a>
        recent Thomson Reuters report for a good recent perspective on this topic.
        While this works for the most part, there are some issues with URLs - not
        specific to scholarly content, but particularly import here:</p><ol><li>multiple
        URLs can point to the same resource</li><li>URLs can be long and look ugly</li><li>URLs
        can change or break, making it hard or impossible to locate the resource</li><li>we
        are used to central indexes (or databases) describing these resources, allowing
        us to do sophisticated queries not possible in a generic web search, e.g.
        find all publications by author John Doe, published since 2012.</li></ol><p>No.
        1 is a problem relevant to all URLs, e.g. web searches or liking/commenting
        a particular web page. Originally suggested by Google, <a href=\"https://support.google.com/webmasters/answer/139066?hl=en\">Canonical
        URLs</a> are essential for services such as Facebook or <a href=\"https://hypothes.is/blog/cross-format-annotation/\">Hypothes.is</a>.
        They have been formalized in <a href=\"http://tools.ietf.org/html/rfc6596\">rfc6596</a>
        and are commonly used.</p><p>No. 2 can be a problem, in particular if we are
        not careful in designing appropriate URLs for landing pages (see next paragraph),
        but rather use something long and unreadable that also includes query parameters,
        etc. If we have no control over how the URL looks like, we can use URL shortener
        services such as <a href=\"https://bitly.com/\">bit.ly</a>, which of course
        have become a common sight on the web. <a href=\"http://shortdoi.org/\">ShortDOIs</a>
        are an URL shortener for DOIs, but they don\u2019t seem to have gained much
        traction.</p><p>No. 3 is a particularly important issue, commonly referred
        to as <strong><strong>link rot</strong></strong> and described extensively
        for the scholarly literature, e.g. by <a href=\"https://doi.org/10.1371/journal.pone.0115253\">Klein</a>.
        There are several technical solutions to this problem, a common approach is
        to use a landing page for the resource that will never change (and follows
        the recommendations by Tim Berners-Lee for <a href=\"http://www.w3.org/Provider/Style/URI.html\">Cool
        URIs</a>, and then use redirection to point to the current location of the
        resource. This is easily for changes of the URL path using web server <a href=\"http://httpd.apache.org/docs/2.4/rewrite/remapping.html\">redirect
        rules</a>. It gets more complicated if the server name also changes, in particular
        if it is the server holding the landing page. Thinking this through you realize
        that the only way this can be done on a larger scale is via one or more centralized
        services that not only provide the technical infrastructure for a central
        redirection (or resolver) service, but also come with a social contract of
        rules that everyone submitting URLs to the service has to follow - a major
        difference to URL shorteners, which don\u2019t solve the link rot problem.</p><p>The
        above is of course a description of the DOI service provided by CrossRef,
        DataCite, and others, as well as similar persistent identifier services. Unfortunately
        some persistent identifier services don\u2019t do the above: they create and
        use persistent identifiers, but there is no central resolver service that
        maps these identifiers back to URLs. This breaks the integration with the
        bigger scholarly infrastructure based on URLs. One common example are nucleotide
        sequences such as U65091, there is no single corresponding URL because the
        sequence can be found in all three main nucleotide databases: <a href=\"http://www.ncbi.nlm.nih.gov/nuccore/U65091\">http://www.ncbi.nlm.nih.gov/nuccore/U65091</a>.
        It would help to have a central resolver, e.g. http://nucleotide.org/U65091
        that then redirects to one of the three databases based on geographical location
        or user preference.</p><p>There are also problems with DOIs. They use the
        <a href=\"http://www.handle.net/\">Handle</a> system to resolve the identifier
        to a location, and this system was built in the 1990s as infrastructure <a
        href=\"http://www.handle.net/faq.html\">independent of</a> URLs or DNS (Domain
        Name Service), at a time when it wasn\u2019t clear yet that URLs and associated
        standards would become ubiquitous. I don\u2019t have numbers, but practically
        all DOIs are of course now resolved to URLs using the <a href=\"http://www.doi.org/factsheets/DOIProxy.html\">DOI
        proxy server</a> at http://doi.org (preferred) or http://dx.doi.org. One main
        consequence of this is that DOIs are frequently not written as URLs - e.g.
        doi:10.5555/24242424x instead of <a href=\"https://doi.org/10.5555/24242424x\">https://doi.org/10.5555/24242424x</a>
        - again breaking the integration with the bigger scholarly infrastructure.
        The CrossRef <a href=\"http://www.crossref.org/02publishers/doi_display_guidelines.html\">DOI
        display guidelines</a> clearly state that DOIs should be written as URLs in
        <em>the online environment</em>, which basically is whenever DOIs are used,
        as PDFs and even Word documents know how to handle URLs. Unfortunately this
        guideline is still frequently ignored. The above is of course also true for
        other persistent identifiers using the Handle system, e.g. <a href=\"http://www.pidconsortium.eu/\">ePIC</a>.</p><p>The
        other problem with the DOI system is that it doesn\u2019t address issue No.
        4, i.e. provide a central metadata index for the resources that use the system.
        This job is left to the DOI registration agencies such as CrossRef and DataCite,
        who have implemented a central metadata store (e.g. <a href=\"https://search.crossref.org/\">CrossRef</a>
        or <a href=\"https://search.datacite.org/\">DataCite</a>) in different ways
        (e.g. using different metadata schemata), or not at all. This means that we
        have to look in several places to find all DOIs associated with author John
        Doe, published since 2012. Obviously we are used to looking up information
        in multiple places, but not being able to look up the metadata for a DOI without
        some extra work (finding out the registration agency for the DOI and then
        going to the respective metadata store) is a problem. One way around these
        problems is to use the <a href=\"https://citation.crosscite.org/docs.html\">DOI
        Content Negotiation Service</a>.</p><p>Another problem with the DOI system
        is more a social than a technical issue. Neither CrossRef nor DataCite seem
        to enforce that DOIs should always resolve to URLs when using a computer program.
        DOI resolution for humans works fine, but computers, e.g. command line tools
        such as cURL, can run into issues such as requiring cookies, javascript or
        user input, or permission problems getting to the journal landing page (see
        <a href=\"https://blog.front-matter.io/posts/challenges-in-automated-doi-resolution\">this
        earlier blog post</a> for some numbers). People seem to forget that a DOI
        that is not actionable is not really useful, and that scholarly infrastructure
        is not only used by people, but of course also by automated tools.</p><p>The
        persistent identifiers used in our scholarly infrastructure would benefit
        from a clearer focus on the problems they should solve, starting with No.
        1-4 above. One problem is that we probably focus too much on the persistence
        problem, implied also by the term <strong><strong>persistent identifier</strong></strong>
        or <strong><strong>PID</strong></strong>. What we have neglected is the resolvable
        problem, i.e. making as easy as possible to get from the persistent identifier
        to the resource and/or its metadata. Based on the Den Haag Manifesto and suggested
        by Todd Vision, we therefore proposed the term <strong><strong>trusted identifier</strong></strong>
        with the following characteristics in the <a href=\"https://doi.org/10.6084/m9.figshare.824314\">conceptual
        model of interoperability</a> for the <a href=\"http://odin-project.eu/\">ODIN
        Project</a>:</p><ul><li>are unique on a global scale, allowing large numbers
        of unique identifiers</li><li>resolve as HTTP URI\u2019s with support for
        content negotiation, and these HTTP URI\u2019s should be persistent.</li><li>come
        with metadata that describe their most relevant properties, including a minimum
        set of common metadata elements. A search of metadata elements across all
        trusted identifiers of that service should be possible.</li><li>are interoperable
        with other identifiers through metadata elements that describe their relationship.</li><li>are
        issued and managed by an organization that focuses on that goal as its primary
        mission, has a sustainable business model and a critical mass of member organizations
        that have agreed to common procedures and policies, has a governing body,
        and is committed to using open technologies.</li></ul><p>While not directly
        relevant for resolving persistent identifiers as URLs, the last point is really
        important for any persistent identifier infrastructure, <a href=\"https://doi.org/10.6084/m9.figshare.1314859\">described
        in detail recently</a>.</p><p>If I would design a persistent identifier service
        today (as if we would need yet another persistent identifier service), I would
        build the system around an URL shortening service that I control. The URLs
        could look very similar to what we have with DOIs now, e.g. <a href=\"http://doi.org/10.5555/12345678\">https://doi.org/10.5555/12345678</a>,
        but it would be clear that persistent identifiers are URLs, not something
        separate. Plus we could take advantage of all the lessons learned - and possibly
        even reuse open source code - with URL shorteners, which are much more widely
        used than scholarly persistent identifiers.</p><p><em>Update 6/4/15: added
        link to Thomson Reuters <a href=\"http://site.thomsonreuters.com/site/data-identifiers/\">report</a>
        on identifiers and open data.</em></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Human-readable and machine-readable Persistent
        Identifiers ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/human-readable-and-machine-readable-persistent-identifiers/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cvzs</id>\n        <published>2015-05-27T10:45:00.000+00:00</published>\n\t\t<updated>2023-09-04T16:56:21.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Yesterday Julie McMurry and
        co-authors <a href=\"https://doi.org/10.5281/zenodo.18003\">published a preprint</a>
        <strong><strong>10 Simple rules for design, provision, and reuse of persistent
        identifiers for life science data</strong></strong>. This is an important
        paper trying to address a fundamental problem: how can we make persistent
        identifiers both human-readable and machine-readable?</p><p>Don\u2019t be
        fooled by the title (used frequently by <a href=\"https://collections.plos.org/collection/ten-simple-rules/\">PLOS
        Computational Biology</a>) - the paper doesn\u2019t describe simple rules
        that help the average life sciences researcher. Rather, the paper deals with
        rather complex issues, and has 36 authors.</p><p>There is general agreement
        that we need persistent identifiers for scholarly communication, and that
        also includes life sciences datasets, the focus of the paper. What is less
        clear is how to express these persistent identifiers. An identifier such as
        <strong><strong>AB020317</strong></strong> - for the mouse p53 gene - is ambiguous.
        It is not clear without additional information that this is an identifier
        for the GenBank nucleotide database, rather than <a href=\"https://www.flickr.com/photos/alexcycu/8936663973/\">something
        completely different</a>. One common approach to make this identifier unambiguous
        is to use URIs (Uniform Resource Identifiers), e.g. <a href=\"http://www.ncbi.nlm.nih.gov/nuccore/AB020317\">http://www.ncbi.nlm.nih.gov/nuccore/AB020317</a>
        in this case.</p><p>The paper doesn\u2019t like this approach, and even states
        that \u201CURIs are still among the most commonly used and most problematic
        identifiers in the bio-data ecosystem\u201D. The text also states that \u201Ctheir
        length makes them unwieldy for humans working with the data or for referencing
        in publications or other text\u201D, but doesn\u2019t go into any detail why
        URIs are \u201Cproblematic identifiers\u201D, or why length is an issue in
        an online environment.</p><p>This is an important weakness of the paper, because
        the authors propose an alternative: CURIEs or <strong><strong>compact URIs</strong></strong>.
        CURIEs were <a href=\"http://www.w3.org/TR/curie/\">proposed</a> by the W3C
        a few years ago, as a way to make URIs <a href=\"https://www.crossref.org/blog/curies-a-cure-for-uris/\">more
        human-readable</a>. The idea is simple, we use a namespace in addition to
        the local identifier, separated by a colon, e.g. <strong><strong><a href=\"http://www.ebi.ac.uk/ena/data/view/AB020317\">Genbank:AB020317</a></strong></strong>.</p><p>This
        approach has of course been common practice in the life sciences before CURIEs
        or even the WWW existed, and is still the most common approach how identifiers
        for life sciences data are referenced in the scholarly literature. Unfortunately
        there are important problems with CURIEs, most of them mentioned in the paper:</p><ul><li>Persistent
        identifiers need to be resolvable, without additional information we don\u2019t
        know what to do with <strong><strong><a href=\"http://www.ebi.ac.uk/ena/data/view/AB020317\">Genbank:AB020317</a></strong></strong>.
        Most life sciences researchers understand this CURIE, but that might not necessarily
        be true for less commonly used namespaces</li><li>Namespaces are not necessarily
        unique, the paper uses <strong><strong>GEO</strong></strong> (which could
        mean Gene Expression Omnibus or GeoNames Ontology) as an example</li><li>Rule
        3 in the paper goes into great detail what characters and patterns should
        be avoided in local identifiers that are part of a CURIE. It is not clear
        whether these recommendations will always be followed or how to check them</li><li>CURIEs
        should follow a pattern (regular expression) so that they can be extracted
        from a text. We <a href=\"https://doi.org/10.1371/journal.pone.0063184\">know</a>
        that extracting identifiers from journal articles is possible, but difficult.</li></ul><p>URIs
        don\u2019t have the problems listed above: they resolve, are unique, and there
        is good understanding (and available tools) of how a valid URI should look
        like and how to extract URIs from text documents. That is why URIs are good
        representations of persistent identifiers.</p><p>Another problem I have with
        CURIEs: the idea doesn\u2019t seem to have caught on from the initial work
        more than five years ago (background reading <a href=\"http://manu.sporny.org/2011/case-for-curies/\">here</a>).
        I\u2019m not even sure what percentage of persistent identifier experts know
        about CURIEs.</p><p>My recommendation for life sciences data: express persistent
        identifiers as URIs. Now that can go into 10 simple rules for the average
        life sciences researcher.</p><p><em>P.S. This blog uses a tool <a href=\"https://blog.front-matter.io/posts/auto-generating-links-to-data-and-resources/\">I
        wrote two years ago</a> that automatically turns CURIEs in the text into links.</em></p><h3
        id=\"references\">References</h3><p>McMurry, J., Blomberg, N., Burdett, T.,
        Conte, N., Dumontier, M., Fellows, D. K., Gonzalez-Beltran, A., Gormanns,
        P., Hastings, J., Haendel, M. A., Hermjakob, H., H\xE9rich\xE9, J.-K., Ison,
        J. C., Jimenez, R. C., Jupp, S., Juty, N., Laibe, C., Le Nov\xE8re, N., Malone,
        J., \u2026 Parkinson, H. (2015). <em>10 Simple Rules For Design, Provision,
        And Reuse Of Persistent Identifiers For Life Science Data</em>. <a href=\"https://doi.org/10.5281/ZENODO.18003\">https://doi.org/10.5281/ZENODO.18003</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Introducing the Scholarly Markdown Bundle
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/introducing-the-scholarly-markdown-bundle/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cvzt</id>\n        <published>2015-04-23T11:48:00.000+00:00</published>\n\t\t<updated>2022-08-18T15:24:44.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Using Markdown to author scholarly
        documents is an attractive alternative to the standard authoring tools Microsoft
        Word and LaTeX. The feeling shared by many is that <a href=\"https://blog.front-matter.io/posts/what-is-scholarly-markdown/\">Scholarly
        Markdown</a> is 80% there, and that more effort is needed for the remaining
        20% - moving markdown from a niche into the mainstream. What is mainly needed
        is building tools that connect the existing tools and ideas, resulting in
        one or more services attractive to a critical number of users. But maybe we
        also need to rethink the essential parts of Scholarly Markdown. In this post
        I propose that we expand the concept and define the <em>Scholarly Markdown
        Bundle</em>.</p><p>It is becoming increasingly clear that scholarly work can\u2019t
        be adequately described in a single text document, most commonly the journal
        article. Not only are there associated metadata, assets such as figures and
        supplementary information, but also the research data and software needed
        to produce the work described in the publication. The obvious next step is
        to think of scholarly work as a collection of objects, most clearly described
        by Carol Goble and others as <a href=\"https://researchobject.github.io/specifications/bundle/\">Research
        Object Bundle</a>.</p><p>There will probably never be a single authoring tool
        and format that pleases everyone. Markdown has particular inherent strengths
        and weaknesses, complex math or tables will probably always be easier with
        other formats. The strength of markdown is the simplicity of the format. Some
        things are hard or impossible to do, but many other things are much simpler.
        Creating a useful markdown editor is much easier than a word processor reading/writing
        <code>docx</code> format. Markdown is also a perfect format to <a href=\"https://blog.front-matter.io/posts/using-microsoft-word-with-git/\">work
        with</a> version control systems such as git.</p><p>This low barrier of entry
        makes markdown perfect to be integrated into many workflows. And we can go
        one step further than ePub and Research Object Bundle, which use the related
        Universal Container Format (<a href=\"https://wikidocs.adobe.com/wiki/display/PDFNAV/Universal+Container+Format\">UCF</a>)
        and ePub Open Container Format (<a href=\"http://www.idpf.org/epub/301/spec/epub-ocf.html\">OCF</a>),
        respectively. Instead of using zip to compress a folder into a single file
        we can use git version control instead: git provides the commands <code>git
        bundle</code> and <code>git archive</code> to compress a project under version
        control with or without version history. I feel this format is both more powerful
        So I propose the <em>Scholarly Markdown Bundle</em>:</p><ul><li>a git repository
        with one or more markdown files, either as a folder, or compressed into a
        single file using <code>git bundle</code></li><li>a particular flavor or markdown
        called Scholarly Markdown, and discussed here and elsewhere before</li><li>a
        <code>citeproc.json</code> file in the root of the project that contains all
        metadata relevant to the container, including references</li></ul><p>The <code>citeproc.json</code>
        file is similar to the minimal metadata schema <a href=\"https://github.com/mbjones/codemeta\">codemeta</a>
        proposed by Matt Jones and others, but is in the format used by Pandoc today.
        This is <a href=\"https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/\">important</a>
        because it adds citation parsing support out of the box. The last two points
        rely on the <a href=\"http://pandoc.org/\">Pandoc</a> document conversion
        tool, so Scholarly Markdown bundles are really <strong><strong>markdown</strong></strong>
        + <strong><strong>Pandoc</strong></strong> + <strong><strong>Citeproc/CSL</strong></strong>
        + <strong><strong>git</strong></strong>. The format is flexible enough to
        not only describe scholarly articles, but also other kinds of scholarly works,
        including scientific software managed with git version control. And it integrates
        nicely with a number of existing workflows, e.g. an R project using RStudio
        for both code and text (in Rmarkdown). This format should also work for blogs
        like this one, but I would have to separate the blog posts from the Jekyll
        site generator code, a direction I suggested in the <a href=\"https://blog.front-matter.io/posts/blogging-beyond-jekyll/\">last</a>
        post.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Blogging Beyond Jekyll ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/blogging-beyond-jekyll/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cvzv</id>\n
        \       <published>2015-03-23T11:50:00.000+00:00</published>\n\t\t<updated>2022-08-18T15:41:43.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/logo-2x.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/logo-2x.png\"></p><p>This
        blog has been on four different platforms since starting in 2007: a custom
        blogging engine and then <a href=\"https://movabletype.org/\">Movable Type</a>
        on <a href=\"http://network.nature.com/\">Nature Network</a> 2007-2010, Wordpress
        on the <a href=\"http://blogs.plos.org\">PLOS Blogs Network</a> 2010-2013,
        and the static blogging engine <a href=\"https://jekyllrb.com/\">Jekyll</a>
        hosted on Github Pages since 2013. It might be time for yet another blogging
        platform change.</p><p>The main reason to switch from Wordpress to Jekyll
        was the concept of a static site generator: write posts in <a href=\"http://commonmark.org/\">markdown
        format</a>, store them in a Github repository, and then have Jekyll automatically
        generate the HTML pages hosted on <a href=\"https://pages.github.com/\">Github
        Pages</a>. The main attraction was the blog posts in markdown format stored
        in git version control without the need of a database. Jekyll is the glue
        to make all this work, and I was able to customize Jekyll to my needs, e.g.
        by using <a href=\"https://pandoc.org/\">Pandoc</a> for the markdown to html
        conversion.</p><p>While this workflow still makes sense for this blog, there
        are a number of shortcomings:</p><ul><li>Jekyll needs to rebuild the entire
        site every time I publish a new post. While this isn\u2019t much of a problem
        for the size of this blog, it doesn\u2019t scale well for larger sites. And
        the process is more complex if you use custom jekyll plugins like this blog,
        as you can\u2019t use the automatic Jekyll pipeline provided by Github (hint:
        use a Travis continuous integration server <a href=\"https://blog.front-matter.io/posts/continuous-publishing/\">to
        build the site</a>)</li><li>the web is moving to increasingly sophisticated
        javascript frontends, using frameworks such as <a href=\"https://angularjs.org/\">Angular.js</a>,
        <a href=\"http://emberjs.com/\">Ember.js</a>, or frontend libraries for scholarly
        documents such as <a href=\"http://elifesciences.org/elife-news/lens\">Lens</a>.
        While they can be used together with Jekyll, that is not a typical use case.</li><li>the
        tight integration between the code to generate the website and the content
        (Wordpress and other blogging engines have the same approach) is not always
        the best solution, e.g. when you want to want to generate the pages for something
        that is not a blog (e.g. a <a href=\"http://book.openingscience.org/\">book</a>).</li></ul><p>What
        could we do instead?</p><blockquote>Build a Javascript frontend where the
        content is served via an API built around markdown documents, stored in git
        version control.</blockquote><h3 id=\"api\">API</h3><p>The blog posts are
        still written in markdown, stored (and version-controlled in a Github repository),
        but we would now access the content via API. The easiest solution is to use
        the <a href=\"https://developer.github.com/v3/repos/contents/\">Github Contents
        API</a> and either do the markdown to html conversion in javascript yourself,
        or let the Github API do the conversion to HTML for you. Alternatively we
        could build our own API, e.g. because we want to control the markdown to html
        conversion, or need additional functionality such as fulltext search. And
        of course the two approaches can be combined, e.g. via a Github webhook that
        triggers the markdown to html conversion every time a document is added or
        updated, and stores the converted documents in the same repo.</p><h3 id=\"frontend\">Frontend</h3><p>The
        frontend should be written as a one-page javascript application, not requiring
        a server backend. In contrast to the Jekyll workflow the frontend code doesn\u2019t
        need to be updated every time we post a blog post. Since this is a very common
        scenario, there are probably several solutions out there already. Please mention
        them in the comments if you have suggestions. One candidate is <a href=\"https://github.com/elifesciences/lens/\">Lens</a>
        mentioned above - a beautiful frontend for scholarly documents. Lens displays
        documents in the <a href=\"http://jats.nlm.nih.gov/publishing/tag-library/1.0/index.html\">JATS</a>
        XML format, so your API would have to provide that format.</p><h3 id=\"conclusions\">Conclusions</h3><p>The
        separation into API and frontend is of course old news. But for blogs this
        seems to still be a fairly new concept, in particular when combined with a
        backend using documents stored in git version control rather than in a database.
        Wordpress added a <a href=\"https://wordpress.org/plugins/json-rest-api/\">REST
        API Plugin</a> in 2014, and the Ghost blogging framework (which uses a database
        backend) also seems to <a href=\"https://trello.com/b/EceUgtCL/ghost-roadmap\">go
        into that general direction</a>. Please ping me if you like the idea and want
        to contribute, or have implemented something like this already.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Metadata in Microsoft Word documents ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/metadata-in-microsoft-word-documents/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cvzw</id>\n        <published>2015-03-20T11:52:00.000+00:00</published>\n\t\t<updated>2022-08-18T15:43:06.000+00:00</updated>\n\t\t<category
        term=\"Science Hack\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/IC164149.gif\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/IC164149.gif\"></p><p>Metadata
        such as author, title, journal or persistent identifier are essential for
        scholarly documents, and some of us are spending a significant part of our
        time adding or fixing metadata. Unfortunately we sometimes don\u2019t pay
        enough attention to the flow of metadata, i.e. we ignore already existing
        metadata, or reinvent the wheel in how we describe or store them.</p><p>Storing
        metadata in text-based formats is usually straightforward. This blog post
        is written in markdown with a <a href=\"http://yaml.org/\">YAML header</a>
        - think of YAML as the more human-readable version of JSON - at the beginning
        of the document:</p><pre><code>---\ntitle: Metadata in Microsoft Word documents\n---</code></pre><p>This
        is then translated into this HTML when the blog post is published:</p><pre><code>&lt;meta
        property=\"dc:title\" content=\"Metadata in Microsoft Word documents\" /&gt;</code></pre><p>XML
        is of course a very natural format for metadata, here for example <a href=\"http://jats.nlm.nih.gov/publishing/tag-library/1.0/index.html\">JATS</a>
        used for scholarly articles:</p><pre><code>&lt;article-title&gt;Metadata in
        Microsoft Word documents&lt;/article-title&gt;</code></pre><p>Many scholarly
        documents start out as Microsoft Word documents. And while the <code>docx</code>
        format introduced by Microsoft in Microsoft Office 2007 <a href=\"http://officeopenxml.com/\">is
        XML-based</a>, few users are aware of this fact. And probably even fewer users
        (including myself) ever go to the <code>Properties\u2026</code> settings of
        a <code>docx</code> document and add a <code>title</code>, <code>keywords</code>
        or other metadata (the <code>author</code> is usually set automatically).</p><p>This
        is very unfortunate, as these metadata are very often required, e.g. in a
        journal article submission, and then need to be collected again, usually either
        by asking the author to fill out a web form, and/or by extracting the metadata
        (e.g. title) from the document.</p><p>The best place for metadata is with
        the document (not <em>in</em> the document), and if the file format (<code>docx</code>
        in this case) supports it, we should take advantage of this. The main benefit:
        metadata stay with the text when the document is sent to co-authors via email,
        or put on a file server, or into Dropbox.</p><p>In the case of <code>docx</code>,
        the metadata support is actually pretty good, using the standard <a href=\"http://dublincore.org/\">Dublin
        Core</a>, and storing the metadata in a separate file called <code>core.xml</code>.
        You can see this file if you unzip your <code>docx</code> file (e.g. after
        giving it a <code>zip</code> extension). The <code>core.xml</code> file for
        this blog post (after converting the markdown file to <code>docx</code> using
        <a href=\"https://pandoc.org\">Pandoc</a>) looks like this:</p><pre><code>&lt;?xml
        version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;cp:coreProperties xmlns:cp=\"http://schemas.openxmlformats.org/package/2006/metadata/core-properties\"
        xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:dcterms=\"http://purl.org/dc/terms/\"
        xmlns:dcmitype=\"http://purl.org/dc/dcmitype/\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"&gt;&lt;dc:title&gt;Metadata
        in Microsoft Word documents&lt;/dc:title&gt;&lt;dc:creator&gt;&lt;/dc:creator&gt;&lt;/cp:coreProperties&gt;</code></pre><p>Because
        <code>docx</code> is XML, we can read/write this file not only in Microsoft
        Word, e.g. using macros, but also outside of Microsoft Word, e.g. in workflows
        that converts <code>docx</code> documents into other formats, or tools that
        check <code>docx</code> files for required metadata (e.g. by using <a href=\"https://blog.front-matter.io/posts/introducing-rakali/\">rakali</a>
        that I wrote last year). So please encourage authors to use the Microsoft
        Word <code>Properties\u2026</code> settings, and update existing tools to
        take advantage of the Dublin Core metadata stored in every <code>docx</code>
        file.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ First analysis of software metrics ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/first-analysis-of-software-metrics/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cvzx</id>\n        <published>2015-02-28T11:55:00.000+00:00</published>\n\t\t<updated>2022-08-15T12:43:05.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/software.lagotto.io_2.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/software.lagotto.io_2.png\"></p><p>Last
        week <a href=\"https://blog.front-matter.io/posts/metrics-for-scientific-software/\">I
        wrote about</a> software.lagotto.io, an instance of the <a href=\"https://github.com/articlemetrics/lagotto\">lagotto</a>
        open source software collecting metrics for the about 1,400 software repositories
        included in Sciencetoolbox. In this post I want to report the first results
        analyzing the data.</p><p>If you want to follow along, please go to <a href=\"https://github.com/mfenner/software-analysis\">https://github.com/mfenner/software-analysis</a>,
        this repository holds all the data, as well as the R code used for analysis.
        A special thanks goes to <a href=\"http://scottchamberlain.info/\">Scott Chamberlain</a>
        who greatly helped me by tweaking the <a href=\"https://github.com/ropensci/alm\">alm</a>
        R package to support URLs instead of DOIs as identifiers.</p><p>The first
        step in the analysis is to get an overview of the external sources citing
        or discussing the software package:</p><p>This is basically the same figure
        as in the <a href=\"https://blog.front-matter.io/posts/metrics-for-scientific-software/\">previous
        post</a>, but with two differences: I have added a <a href=\"http://www.nature.com/opensearch/\">Nature.com
        OpenSearch</a> data source, and I have found an additional 64 repositories
        cited in scholarly articles via an Europe PMC full-text Search that also includes
        the reference lists (thanks to <a href=\"http://www.ebi.ac.uk/about/people/johanna-mcentyre\">Jo
        McEntyre</a>).</p><p>I am not sure why we are not picking up any Wikipedia
        citations, and have to take a closer look. The ORCID source also needs tweaking,
        and there are some issues with the <a href=\"http://wordpress.com/\" rel=\"nofollow\">Wordpress.com</a>
        data that I have to look into as well. Citations in the scholarly literature
        are obviously the most interesting data, and we have three Github repos with
        more than 25 citations, including <a href=\"https://github.com/najoshi/sickle\">https://github.com/najoshi/sickle</a>
        with 54 citations. As most repositories in our sample are cited only once
        if at all, a correlation with Github stars and forks is not useful. Sickle
        is popular on Github (52 stars and 32 forks), but it is not clear that this
        activity is correlated to citations (e.g. because there are more citations
        than stars).</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/github_likes_readers-1.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"672\" height=\"480\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/github_likes_readers-1.png
        600w, https://blog.front-matter.io/content/images/2022/08/github_likes_readers-1.png
        672w\"><figcaption>Correlation between combined Facebook activity and Github
        forks, log-log scale. Data from <a href=\"http://software.lagotto.io\">software.lagotto.io</a></figcaption></figure><figure
        class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/facebook_github_readers-1.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"672\" height=\"480\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/facebook_github_readers-1.png
        600w, https://blog.front-matter.io/content/images/2022/08/facebook_github_readers-1.png
        672w\"><figcaption>Correlation between Github stargazers and forks, log-log
        scale. Data from <a href=\"http://software.lagotto.io\">software.lagotto.io</a></figcaption></figure><p>The
        vast majority of software repos in this analysis are hosted by Github, so
        we have the numbers of stars and forks for those. It is interesting, although
        probably not very surprising, that the number of Github stargazers and forks
        is highly correlated:</p><p>We can find Facebook activity (likes, comments
        or shares) for one third of the repositories. There is a reasonably good correlation
        between Facebook activity and number of Github forks:</p><p>One interesting
        analysis would be to look at the repositories that have been forked much more
        often relative to their Facebook activity, e.g. <a href=\"https://github.com/cloudera/impala\">Impala</a>
        with 1,207 Github stars and 458 forks, but only 5 Facebook shares. One limitation
        of the analysis is that we are not tracking Facebook (or other social media)
        activity for all forks of a repo.</p><p>We found Reddit discussions mentioning
        one of the repositories in 7% of cases. Once we have a larger sample size
        it would be interesting to correlate this activity with Github stars and forks,
        similar to what we did for Facebook. By far the most popular repository from
        our sample on Reddit is <a href=\"https://github.com/Bitcoin/Bitcoin\">Bitcoin</a>,
        followed by <a href=\"https://github.com/jquery/jquery\">JQuery</a>. Twitter
        activity is notoriously difficult to collect since Twitter doesn\u2019t keep
        tweets very long, hence probably the low numbers compared to Facebook and
        Reddit.</p><p>Feel free to play with the data and scripts provided at <a href=\"https://github.com/mfenner/software-analysis\">https://github.com/mfenner/software-analysis</a>,
        my next step is probably to include a much larger number of software repositories.</p><p>It
        has not escaped our notice that the kind of analysis described above could
        be applied to any software repository, not just scientific software.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Why there is no iTunes for science papers
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/why-there-is-no-itunes-for-science-papers/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cvzy</id>\n        <published>2015-02-23T11:58:00.000+00:00</published>\n\t\t<updated>2022-08-15T12:44:02.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/pay_per_view_nature-1.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/pay_per_view_nature-1.png\"></p><p>The
        iTunes Store was opened by Apple in 2003 to sell digital music and other digital
        assets. Since 2009 music purchased in the iTunes store is free of Digital
        Rights Management (DRM). Apple became the largest music vendor worldwide in
        2010, and by 2013 had sold 25 billion songs.</p><p>Scholarly articles are
        distributed almost exclusively in digital form. While there is an increasing
        number of journal articles freely available via green or gold open access,
        the majority of them still can only be read if the reader works at an institution
        with a subscription to the journal. Many journals also allow the reader to
        buy a single article of interest, for prices between $10 and more than $30:</p><figure
        class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/pay_per_view_lancet.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"606\" height=\"554\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/pay_per_view_lancet.png
        600w, https://blog.front-matter.io/content/images/2022/08/pay_per_view_lancet.png
        606w\"><figcaption>For an article in Lancet</figcaption></figure><p>There
        is also a document delivery service provided by libraries, but that option
        varies considerably by country and in Germany for example means a scanned
        article as printout rather than the original PDF because of a change in German
        copyright law a few years ago. There are also the services <a href=\"https://www.deepdyve.com/\">DeepDyve</a>
        and <a href=\"https://www.readcube.com/\">ReadCube</a>, but again you don\u2019t
        get the PDF (or only for prices similar to those quoted above), but rather
        limited access for reading and printing.</p><p>In summary, affordable access
        to scholarly content by subscription publishers is in a dire state: you either
        have to work at an academic institution subscribing to the desired journal,
        get only a crippled version of the article (online viewing only), or pay up
        to $30 for a single article, which clearly doesn\u2019t scale beyond very
        occasional use.</p><p>With this background it is obvious that several people
        have discussed the iTunes Store-like model to sell scholarly articles:</p><ul><li><a
        href=\"http://crosstech.crossref.org/2009/09/prc_report_and_ipub_revisited.html\">PRC
        Report and \u201CiPub\u201D revisited</a></li><li><a href=\"http://www.popsci.com/science/article/2009-10/deepdyve-launches-itunes-science-papers\">DeepDyve
        launches iTunes Store-like service for science papers</a></li><li><a href=\"http://scienceblogs.com/digitalbio/2012/01/10/could-an-itunes-like-model-wor/\">Could
        an iTunes-like model work with scientific publishing?</a></li><li><a href=\"http://www.bostonglobe.com/business/2012/10/07/start-readcube-program-uses-itunes-payment-model-for-access-scientific-articles/1UopCX1qfEE3uO2UEzuM7L/story.html\">A
        plan to open up science journals</a></li><li><a href=\"http://www.newyorker.com/tech/elements/when-the-rebel-alliance-sells-out\">When
        the Rebel Alliance Sells Out</a></li></ul><p>The best already existing platforms
        to build such as service are reference managers, as most of them have learned
        now to manage PDF files, and have an online component. ReadCube is offering
        a pay-per-view option already, Papers, Mendeley, Endnote or others could get
        into this business.</p><p>One of the big advantages of payments for single
        articles is transparency, as institutions and users only pay for what they
        actually use. Price transparency is one of the big problems with the <em>big
        deal</em> contracts that academic institutions have with publishers - read
        <a href=\"https://doi.org/10.1073/pnas.1403006111\">this article</a> for more
        info.</p><p>But rather than becoming the predominant way to pay for digital
        music, services such as DeepDyve and ReadCube are only playing a marginal
        role. Why is that so?</p><ul><li>whereas digital music is paid for by the
        consumer, there is usually a middleman in the form of the library for scholarly
        articles, which makes the payment process more complex.</li><li>subscription
        publishers have focused all their efforts on selling big deals with increasing
        numbers of journals to libraries. Prices of $30 per article are clearly intended
        to discourage payment for single articles (which could jeopardize journal
        bundles) rather than offering an earnest payment option.</li><li>Apple was
        in a strong negotiation position with record labels when starting the iTunes
        store (the extremely popular iPod, record labels scared of file-sharing platforms
        such as Napster). No organization is in a similar position with scientific
        publishers, and services such as ReadCube or Mendeley are handicapped because
        they are associated with a particular publisher</li></ul><p>Unless several
        large publishers and/or a smart third-party with enough muscle start an initiative
        in this space, e.g. by bringing the pay-per-view prices to a reasonable level
        (e.g. $4.99), we will never see an iTunes Store-like service for scholarly
        articles, and this currently looks like the most likely outcome. We may have
        reached the point where it is too late, as most publishers seem to already
        work towards another payment model: gold open access where the authors pay
        the article costs.</p><p><em>Update 3/2/15: added link to 2009 CrossTech blog
        post.</em></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Metrics for scientific software ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/metrics-for-scientific-software/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cvzz</id>\n        <published>2015-02-19T12:00:00.000+00:00</published>\n\t\t<updated>2022-08-18T15:44:46.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/software.lagotto.io.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/software.lagotto.io.png\"></p><p>One
        of the challenges of collecting metrics for scholarly outputs is persistent
        identifiers. For journal articles the Digital Object Identifier (DOI) has
        become the de-facto standard, other popular identifiers are the pmid from
        PubMed, the identifiers used by Scopus and Web of Science, and the arxiv ID
        for ArXiV preprints.</p><p>For other research outputs the picture is less
        clear. DOIs are also used for datasets, but so are many other identifiers,
        in particular in the life sciences.</p><p>To collect metrics for research
        outputs, the requirements are slightly different. We need identifiers understood
        by the services collecting the metrics, not by the data repository or other
        service that is holding the research output (the only exception is usage stats,
        which are generated locally). For many services, in particular social media
        such as Facebook, Twitter or Reddit, the primary identifier for a resource
        is a URL. This means that we should have one or more URLs for every research
        output where we want to track the metrics - typically the publisher or data
        repository landing page. Since URLs can be messy, Google, Facebook and others
        have come up with the concept of a <a href=\"http://googlewebmastercentral.blogspot.de/2009/02/specify-your-canonical.html\">canonical
        URL</a>, and some care should go into constructing proper canonical URLs (see
        <a href=\"https://blog.front-matter.io/posts/challenges-in-automated-doi-resolution\">this
        blog post</a> for examples of what can go wrong).</p><p>The Den Haag Manifesto
        is the result of a <strong><strong>Knowledge Exchange</strong></strong> workshop
        held in June 2011 and tries to bring Persistent Identifiers and Linked Open
        Data together. The first principle is very much in line with what I said above:</p><blockquote>Make
        sure PIDs can be referred to as HTTP URI\u2019s, including support for content
        negotiation.</blockquote><p>Or, to put this differently: URLs are good enough
        to start collecting metrics for scholarly outputs. Scientific software is
        a good example where persistent identifiers are not commonly used (despite
        efforts such as <a href=\"https://guides.github.com/activities/citable-code/\">this
        one</a>), but we can still collect many meaningful metrics using the repository
        URL (and the open source software <a href=\"https://github.com/articlemetrics/lagotto\">lagotto</a>):</p><figure
        class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/software.lagotto.io-1.png\"
        class=\"kg-image\" alt=\"Number of software repositories (out of 1,404) with
        at least one event. Data from software.lagotto.io\" loading=\"lazy\" width=\"1468\"
        height=\"686\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/software.lagotto.io-1.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/08/software.lagotto.io-1.png
        1000w, https://blog.front-matter.io/content/images/2022/08/software.lagotto.io-1.png
        1468w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Number of software
        repositories (out of 1,404) with at least one event. Data from software.lagotto.io</figcaption></figure><p>The
        last three rows are citations in the scholarly literature found via fulltext
        search of BioMed Central, Europe PMC and PLOS. URLs (in contrast to persistent
        identifiers represented as strings and/or numbers) are easy to find, the main
        limitation is not so much using a URL rather than a DOI, but that scientific
        software typically is mentioned in the text without appearing in the reference
        list. This makes it hard to impossible to find articles mentioning the software
        that are not open access, which unfortunately is still the majority of them.</p><p>We
        are of course also tracking the discussion of the software in social media,
        and are collecting the number of stars and forks in Github and Bitbucket.
        Overall there is quite a lot of activity, here are some examples:</p><ul><li><a
        href=\"https://github.com/najoshi/sickle\">Windowed Adaptive Trimming for
        fastq files using quality</a></li><li><a href=\"https://github.com/lh3/wgsim\">Reads
        simulator</a></li><li><a href=\"http://software.lagotto.io/works/url/https://github.com/lh3/seqtk\">Toolkit
        for processing sequences in FASTA/Q formats</a></li></ul><p>All three software
        repos have been cited in the scholarly literature at least ten times. What
        is missing is infrastructure that tracks the citations of scientific software,
        so that we can give proper scientific credit to the authors of the software,
        and can discover other research projects using the same tools. software.lagotto.io
        uses a list of software repos collected by Jure Triglav for ScienceToolbox,
        and a scientific software index is indeed one of the important missing pieces.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Manifests and Reference Lists ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/manifests-and-reference-lists/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw00</id>\n        <published>2015-02-05T12:03:00.000+00:00</published>\n\t\t<updated>2022-08-18T15:52:45.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/photo-1567966181174-55151ffbd185.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/photo-1567966181174-55151ffbd185.jpeg\"></p><p>Last
        month at the <a href=\"https://www.force11.org/meetings/force2015/pre-conference-meeting-list\">Force15
        conference</a> in Oxford <a href=\"https://twitter.com/IanMulvany\">Ian Mulvany</a>
        and I ran a workshop on <a href=\"https://blog.front-matter.io/posts/data-citation-support-in-reference-managers/\">data
        citation support in reference managers</a>. The report of that workshop isn\u2019t
        done yet, but I can say that it was a success - we now have a pretty good
        idea what the problems are and what needs to be done to fix them. The short
        summary of the workshop is in <a href=\"https://speakerdeck.com/mfenner/workshop-summary-reference-managers-and-data-citation\">this</a>
        slide deck of the presentation that summarized the workshop for the other
        Force15 attendees.</p><p>The whole idea of the workshop was to treat data
        citation as similar as possible to the citation of journal articles, i.e.
        to allow authors to use the same tools (reference managers) and conventions
        (citation styles). Putting a data citation into a reference list makes it
        easier to find that data citation because reference lists contain more metadata,
        are more structured, and more accessible than data citations in the form of
        identifiers or links within the body text of the article.</p><p>But I have
        to admit that there is one problem with reference lists: although there is
        always some self-citation, reference lists usually contain references to articles
        (and other resources) created by other people and before the article was published.
        It feels a little bit odd to put a dataset created by the same group of people
        and published at the same time into the reference list. And although we could
        use a separate reference list or highlight the data associated with the article
        in some other way, what we really want is something slightly different, a
        manifest file.</p><p>The journal article has been a (mainly) textual document
        for many centuries not because this is the essence of science communication,
        but rather because there was no practical way to include all the other information
        (raw data, tools used for experiments, etc.). Very few of these limitations
        remain with the digital journal article that we have since the 1990s, but
        we have for the most part failed to change the format other than going from
        paper to PDF. One of many examples: figures in publications typically still
        are has limited as they were decades ago with no way to see the data underlying
        the figure, options for selecting what data points are shown, or animation
        for time-based information.</p><p>So what we really care about is the sum
        of artifacts and resources that together make what Carol Goble and others
        call <a href=\"https://doi.org/10.1038/npre.2010.4626.1\">research object</a>,
        the journal article is an important part, but clearly doesn\u2019t include
        everything that is needed to understand and reproduce the work. Reference
        lists can help with linking to some of the resources not included in the article
        text, but they typically don\u2019t link to supplementary information or other
        places where the underlying data are made available, or to the figures of
        the article. Although some publishers provide navigation tools for readers
        to get to this information, what we really need is a machine-readable list
        of all the resources used in an article.</p><p>As it happens, this is exactly
        what the ePub format for electronic books is doing, as every ePub must include
        a manifest file that lists all the files that are part of the publication,
        defined in the <a href=\"http://www.idpf.org/epub/20/spec/OPF_2.0.1_draft.htm\">Open
        Packaging Format (OPF)</a>. I need to do more research to figure out how to
        do this with <a href=\"http://jats.nlm.nih.gov/archiving/tag-library/1.0/index.html\">JATS</a>,
        the standard for scholarly articles, and how to generate something similar
        to the manifest file when using different formats, e.g. html or markdown.
        This has to be linked to some of the information we are collecting already,
        e.g. described in <a href=\"https://doi.org/10.3998/3336451.0014.106\">JATS</a>,
        or the <code>relatedIdentifier</code> in the <a href=\"https://doi.org/10.5438/0010\">DataCite
        metadata</a>.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Data Citation Support in Reference Managers
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/data-citation-support-in-reference-managers/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw01</id>\n        <published>2015-01-05T14:55:00.000+00:00</published>\n\t\t<updated>2022-08-18T15:59:58.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/journal.pone.0115253.g002.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/journal.pone.0115253.g002.png\"></p><p>This
        is the title of an upcoming workshop next Sunday organized by Ian Mulvany
        and myself. The workshop is a <a href=\"https://www.force11.org/meetings/force2015/pre-conference-meeting-list\">pre-conference
        event</a> of the <a href=\"https://www.force11.org/meetings/force2015\">Force15</a>
        conference in Oxford. This blog post summarizes some of the issues and work
        that needs to be done.</p><p>Data Citation is one of the big themes of the
        Force15 conference, and a lot of progress has been made, including the Joint
        Declaration of Data Citation Principles (Data Citation Synthesis Group 2014)
        that start with the following paragraph on <strong><strong>Importance</strong></strong>:</p><blockquote>Data
        should be considered legitimate, citable products of research. Data citations
        should be accorded the same importance in the scholarly record as citations
        of other research objects, such as publications.</blockquote><p>Convincing
        researchers, funders, university administrators and others that data citation
        is important is crucial. But for researchers to actually adopt data citation
        to the same degree as citations of the scholarly literature, more needs to
        be done:</p><ul><li>incentives (both carrots and sticks) by funders, institutions,
        and scholarly societies</li><li>training in data management</li><li>data repositories
        and other tools and services for the public sharing of data</li><li>tools
        and services that help citing those datasets</li></ul><p>The focus of the
        workshop is on the last bullet point, and I would argue that more work still
        needs to be done here compared to the first three bullet points.</p><h2 id=\"reference-managers\">Reference
        Managers</h2><p>Researchers use reference managers to handle the citations
        in the manuscripts they write. This is both a common practice that everybody
        understands, and there are a plethora of tools - both free and paid - available.
        Most reference managers were originally built to handle citations of journal
        articles and maybe books or book chapters, and many of them also help with
        managing the associated PDF files. In the last 15 years we have seen an dramatic
        increase of non-article citations in reference lists, mainly to web resources
        (Klein et al., 2014):</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/journal.pone.0115253.g002-1.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"1864\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/journal.pone.0115253.g002-1.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/08/journal.pone.0115253.g002-1.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2022/08/journal.pone.0115253.g002-1.png
        1600w, https://blog.front-matter.io/content/images/size/w2400/2022/08/journal.pone.0115253.g002-1.png
        2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption>From Fig. 2: STM articles
        and URI references per publication year - Elsevier corpus (Klein et al. 2014)</figcaption></figure><p>References
        managers have started to adapt to these changes in citation patterns. Similarly
        they have become better in handling non-textual resources such as slide decks,
        datasets, or movies. Nobody should type in references by hand in 2015, as
        reference managers have come up with several ways of importing metadata about
        citations:</p><ul><li>import references stored in a file using a format such
        as BibTex or RIS</li><li>import references by talking to an external API</li><li>import
        references via a bookmarklet that grabs information from the current webpage
        in the browser</li></ul><p>Endnote and Papers typically use the second approach
        whereas Mendeley, Zotero (and others) work almost exclusively via bookmarklets
        (and there are of course combinations of both). Bookmarklets in general work
        better for web resources and other content that is not indexed in a central
        service such as Web of Science or Scopus. This is also true for research data,
        as there are currently few central research data indexing services - the Thomson
        Reuters <a href=\"http://wokinfo.com/products_tools/multidisciplinary/dci/\">Data
        Citation Index</a> and <a href=\"https://www.datacite.org/\">DataCite</a>
        are two examples in this category. But there are also thousands of data repositories,
        many of them listed in re3data (Pampel et al., 2013).</p><p>The reference
        manager <a href=\"https://www.zotero.org/\">Zotero</a> has built a large open
        source ecosystem around bookmarklets (what they call <a href=\"https://github.com/zotero/translators\">web
        translators</a>), making it straightforward to add support for a new resource,
        as I have done for <a href=\"https://github.com/zotero/translators/blob/master/NCBI%20Nucleotide.js\">GenBank
        nucleotide sequence datasets</a> in November after learning the basics in
        a <a href=\"https://blog.front-matter.io/posts/webinar-on-writing-zotero-translators/\">webinar</a>
        given by Sebastian Karcher, a frequent contributor to Zotero web translators.</p><p>There
        is no technical reason that reference managers can\u2019t support a broad
        range of objects to cite, including datasets. And integration of data citation
        into the reference manager workflow is not only the easiest and most natural
        way for the author of a paper, but also makes it easier to discover these
        citations - reference lists are simply much better for that than links in
        the text, in particular if the content is behind subscription walls. There
        is a long tradition in the life sciences to put identifiers for genetic sequences
        used in a publication right into the text (usually into the methods section).
        Links in the body text are worse than references in reference lists, <a href=\"https://blog.front-matter.io/posts/auto-generating-links-to-data-and-resources/\">identifiers
        without a link</a> are even worse, as they are very hard to find in an automated
        way (Kafkas, Kim, &amp; McEntyre, 2013).</p><p>Please come to our workshop
        on Sunday afternoon if you are in Oxford and are interested in this topic.
        <a href=\"https://www.eventbrite.com/e/data-citation-support-in-reference-managers-tickets-15136593960\">Registration</a>
        is free, and the workshop will include both presentations about the current
        state of data citation support in the reference managers Endnote, Papers,
        Mendeley and Zotero, and work in smaller groups on practical implementations.</p><h2
        id=\"references\">References</h2><p>Kafkas, \u015E., Kim, J.-H., &amp; McEntyre,
        J. R. (2013). Database Citation in Full Text Biomedical Articles. <em>PLoS
        ONE</em>. https://doi.org/<a href=\"https://doi.org/10.1371/journal.pone.0063184\">10.1371/journal.pone.0063184</a></p><p>Klein,
        M., Van de Sompel, H., Sanderson, R., Shankar, H., Balakireva, L., Zhou, K.,
        &amp; Tobin, R. (2014). Scholarly context not found: one in five articles
        suffers from reference rot. <em>PLoS ONE</em>, <em>9</em>(12), e115253. https://doi.org/<a
        href=\"https://doi.org/10.1371/journal.pone.0115253\">10.1371/journal.pone.0115253</a></p><p>Pampel,
        H., Vierkant, P., Scholze, F., Bertelmann, R., Kindling, M., Klump, J., \u2026
        Dierolf, U. (2013). Making Research Data Repositories Visible: The re3data.org
        Registry. <em>PLoS ONE</em>, <em>8</em>(11), e78080. https://doi.org/<a href=\"https://doi.org/10.1371/journal.pone.0078080\">10.1371/journal.pone.0078080</a></p><p>Data
        Citation Synthesis Group. (2014). <em>Joint Declaration of Data Citation Principles</em>.
        Force11. <a href=\"https://doi.org/10.25490/A97F-EGYK\">https://doi.org/10.25490/A97F-EGYK</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Webinar on Writing Zotero Translators ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/webinar-on-writing-zotero-translators/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw02</id>\n        <published>2014-10-17T14:59:00.000+00:00</published>\n\t\t<updated>2023-08-06T13:10:57.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2023/08/mfenner__garden_gnome_in_a_webinar_listening_hyperrealistic_sty_88f261c0-e7e2-41a2-9f17-ce31b7c8990d.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2023/08/mfenner__garden_gnome_in_a_webinar_listening_hyperrealistic_sty_88f261c0-e7e2-41a2-9f17-ce31b7c8990d.png\"></p><p>In
        a <a href=\"https://doi.org/10.53731/r294649-6f79289-8cw04\">blog post two
        weeks ago</a> I argued for the need for reference managers to properly support
        data citation, if we want data citation to become a standard activity. I am
        happy to announce two events working towards that goal.</p><h2 id=\"november-3rd-webinar-on-writing-zotero-web-translators\">November
        3rd: Webinar on writing Zotero web translators</h2><p><a href=\"https://www.zotero.org/blog/community-spotlight-sebastian-karcher/\">Sebastian
        Karcher</a>, one of the most prolific authors of Zotero web translators (and
        citation styles), has kindly offered to hold an introductory webinar on writing
        Zotero web translators. These web translators allow Zotero to import metadata
        about a scholarly work from a variety of places, and new web translators for
        repositories that hold research data (or software) would go a long way towards
        making data citation easier for authors. <a href=\"https://www.zotero.org/support/dev/translators\">Web
        translators</a> are written in Javascript and only basic Javascript knowledge
        is required. The free webinar takes place on November 3rd on 5 PM UK time
        (12 PM EST) and the registration form is <a href=\"http://www.eventbrite.com/e/writing-zotero-translators-webinar-tickets-13768797845\">here</a>.</p><h2
        id=\"january-11-force11-pre-conference-workshop-on-data-citation-support-in-reference-managers\">January
        11: Force11 Pre-Conference workshop on Data Citation Support in Reference
        Managers</h2><p><a href=\"https://www.force11.org/meetings/force2015/pre-conference-meeting-list\">This
        workshop</a>, co-organized with Ian Mulvany, will extend the Zotero web translator
        work to other reference managers, including Papers and Mendeley. This will
        be a hackathon with the goal to get some things working in these reference
        managers, but it should also be interesting for others, as we will discuss
        what is missing to make data citation work in reference managers.</p><p>My
        personal goal is to learn to write a Zotero web translator in the webinar,
        and then write a working web translator for the three biological databases
        ENA, PDB and Uniprot before the January workshop. And hopefully these activities
        generate enough interest that other people write web translators for their
        favorite research data database or software repository, and that the proprietary
        reference managers Papers and Mendeley (and hopefully others) also add support
        for these data sources.</p><h3 id=\"references\">References</h3><p>Fenner
        M. Please keep it simple: citations, links and references. Published online
        October 1, 2014. doi:<a href=\"https://doi.org/10.53731/r294649-6f79289-8cw04\">10.53731/r294649-6f79289-8cw04</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Let&#x27;s do an unconference ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/lets-do-an-unconference/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw03</id>\n
        \       <published>2014-10-14T15:02:00.000+00:00</published>\n\t\t<updated>2022-08-18T16:02:35.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/photo-1448906654166-444d494666b3.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/photo-1448906654166-444d494666b3.jpeg\"></p><p>This
        year\u2019s <a href=\"http://blogs.nature.com/ofschemesandmemes/2014/10/09/how-to-get-a-ticket-for-this-years-spoton-london\">SpotOn
        London conference</a> takes place November 14-15 and the registration has
        opened this Monday. I am helping organize this conference since 2009, and
        I again look forward to the sessions, and - more importantly - the discussions
        with people in and between sessions this year.</p><p>The name (ScienceBlogging
        London, ScienceOnline London, SpotOn London), the location (Royal Institution,
        British Library, Wellcome Conference Center), the people organizing (too many
        to mention, but Nature Publishing Group always at the core), and the fringe
        events (lots of cool things from <a href=\"http://blog.mendeley.com/academic-life/science-blogging-2008-part-i/\">science
        tours</a> to <a href=\"http://www.nature.com/spoton/event/spoton-london-2012-fringe-event-the-story-collider-2/\">Story
        Collider</a>) and the format have always changed slightly over the years,
        and this year again is a bit different. The biggest change is obviously that
        <a href=\"https://twitter.com/louwoodley\">Lou Woodley</a> is no longer an
        organizer (as she announced at last year\u2019s conference), but this is also
        the first SpotOn conference with a theme:</p><blockquote>The challenges of
        balancing the public and the private in the digital age</blockquote><p>This
        is obviously a very broad topic, but nicely encompasses many important issues
        that we are dealing with in scholarly communication today. The draft program
        is posted <a href=\"http://blogs.nature.com/ofschemesandmemes/2014/10/13/spoton-london-2014-draft-programme\">here</a>,
        and I\u2019m helping organize the sessions on <strong><strong>sharing sensitive
        data</strong></strong> and <strong><strong>open peer review</strong></strong>.
        More details will follow for all these sessions.</p><figure class=\"kg-card
        kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/2817131778_e8e04ed68e_o.jpg\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"1500\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/2817131778_e8e04ed68e_o.jpg
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/08/2817131778_e8e04ed68e_o.jpg
        1000w, https://blog.front-matter.io/content/images/size/w1600/2022/08/2817131778_e8e04ed68e_o.jpg
        1600w, https://blog.front-matter.io/content/images/2022/08/2817131778_e8e04ed68e_o.jpg
        2048w\" sizes=\"(min-width: 720px) 720px\"><figcaption><a href=\"https://www.flickr.com/photos/dullhunk/2817131778/\">Flickr
        photo by Duncan Hull</a></figcaption></figure><p>The second day of the conference
        will be in unconference (or barcamp) format and the program drafted by the
        delegates in the morning. This format is popular in the science communications
        community (I first heard about the project that became my current job at <a
        href=\"https://blog.front-matter.io/lets-do-an-unconference/i-was-at-scibarcamp-palo-alto\">SciBarCamp
        in 2009</a>), and SpotOn London has used this format in the first conference
        in 2008 (and again in 2009):</p><p>For people not familiar with this format
        the idea of a conference (day) without predetermined topics or speakers sounds
        scary. As it turns out, the problem is usually not the lack of ideas or people
        wanting to talk, but rather how to coordinate this in a way that everyone
        who wants to get involved can do so, and it doesn\u2019t become a discussion
        among those with the loudest voices (and biggest egos). My experience with
        SpotOn London and other conferences I enjoyed is that the best sessions are
        usually those that allow for a good discussion, and not those with the most
        polished PowerPoint slides. Some suggestions for when you attend an unconference
        for the first time:</p><ul><li>go to sessions with topics you know little
        about, but want to learn more</li><li>when suggesting a session, do this together
        with others</li><li>suggest topics that are focussed and unusual, not the
        obvious ones we always talk about</li><li>don\u2019t even think about doing
        a PowerPoint presentation</li><li>when moderating a session, be a good moderator,
        not a good speaker</li></ul><h2 id=\"further-reading\">Further reading</h2><ul><li><a
        href=\"http://en.wikipedia.org/wiki/Science_Foo_Camp\">Wikipedia: SciFoo</a></li><li><a
        href=\"http://blogs.nature.com/nascent/2007/08/barcamb_cambridge.html\">Ian
        Mulvany: BarCamp Cambridge 2007</a></li><li><a href=\"http://science.easternblot.net/?p=613\">Eva
        Amsen: SciBarCamp Toronto 2008</a></li><li><a href=\"https://blog.front-matter.io/posts/action_points\">Me:
        BibCamp Hannover 2010</a></li></ul> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Please keep it simple: citations, links
        and references ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/please-keep-it-simple-citations-links-and-references/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw04</id>\n        <published>2014-10-01T15:06:00.000+00:00</published>\n\t\t<updated>2023-08-01T21:15:10.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/lego_discussion-1.jpg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/lego_discussion-1.jpg\"></p><p>In
        my <a href=\"https://doi.org/10.53731/r294649-6f79289-8cw05\">last post</a>
        I wrote about the importance of keeping things simple in scholarly publishing,
        today I want to go into more detail with one example: citations in scholarly
        documents.</p><p>Citations are an essential part of scholarly documents, and
        they are summarized in the references section at the end of the article or
        book chapter. The problem is that not everything that is cited in a scholarly
        document ends up in the references list. Examples of this include:</p><ul><li>web
        links, e.g. to reagents or other resources</li><li>identifiers for biological
        databases such as GenBank that are typically included in the text as identifiers
        or as links</li><li>footnotes with links to external resources</li></ul><p>In
        other words: we are not consistent in how we cite other content. And this
        is a problem because we are making it more difficult than necessary for authors,
        publishers, and everyone else to handle these various citation flavors, and,
        more importantly, we are losing citations along the way. This is a particular
        problem for data citation, as the seminal 2013 paper by <a href=\"https://doi.org/10.1371/journal.pone.0063184\">Kafkas
        et al</a>. has shown for citations to the three biological databases ENA (European
        Nucleotide Archive), PDB, and Uniprot:</p><ul><li>there is a large number
        of accession numbers in the Open Access subset of PubMed Central (e.g. 160,112
        ENA accession numbers for papers published up until June 2012)</li><li>text
        mining using the <a href=\"http://www.ebi.ac.uk/webservices/whatizit/\">Whatizit</a>
        tool can retrieve most of these identifiers</li><li>there is only partial
        overlap between database identifiers annotated by publishers and database
        identifiers found by text mining</li><li>the overlap is even smaller between
        papers citing database identifiers, and papers cited in biological databases
        such as ENA</li><li>the study was limited to Open Access journals, as only
        for them the full-text articles could be text mined</li></ul><figure class=\"kg-card
        kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/ena_overlap.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"415\" height=\"194\"><figcaption>Comparison
        between article-to-database and database to citations (Kafkas et al., 2013).</figcaption></figure><p>In
        other words, even though including identifiers for biological databases has
        been an accepted community standard that every author and publisher is following
        for a long time, the proper citation of these identifiers is still often broken.
        The picture doesn\u2019t seem to be any better for DOIs for datasets: while
        they are fairly common by now, their use in scholarly articles differs widely
        from appearance in the references list to links in the materials and methods
        section to no mention at all.</p><p>There are various ways how this can be
        fixed (e.g. requiring authors to use biological database identifiers in a
        consistent way, better text mining tools, opening up subscription content
        to text mining), but the best solution is the simplest one: every citation
        in a paper should go into the references list. As an example I have added
        the ENA mRNA U65091 (Shioda, Fenner, &amp; Isselbacher, 1997) - something
        I worked on a long time ago - to the references list of this post.</p><h2
        id=\"technology\">Technology</h2><p>For this to work, it is essential that
        reference managers - the software authors use to generate the references list
        - properly support citations to data, including biological databases. It appears
        that all major reference managers support datasets as reference type and there
        is good community agreement what a data citation should look like (<a href=\"https://doi.org/10.25490/A97F-EGYK\">Joint
        Declaration of Data Citation Principles</a>). What is missing is support for
        easily importing the required metadata for these datasets, and reference managers
        use two approaches for this:</p><ul><li>query external databases via API and
        pull in the required metadata (e.g. Papers, Endnote)</li><li>browse to the
        webpage describing the database entry and import the metadata via bookmarklet/web
        importer (e.g. Zotero, Mendeley)</li></ul><p>Both approaches require custom
        code for every database. Whereas many reference managers use Citation Style
        Language (<a href=\"http://citationstyles.org/\">CSL</a>) as a standard way
        to format references, no such standard exists for web importers. Which means
        that every reference manager has to implement this separately, and most of
        them are not open source software so that the community could help.</p><p>PLOS
        Labs is holding a <a href=\"http://www.ploslabs.org/citation-hackathon/\">Citation
        Hackathon</a> on October 18 in their San Francisco office. While I can\u2019t
        attend in person, I want to contribute to this hackathon in three ways:</p><ul><li>do
        an evaluation of how the reference managers Papers, Mendeley and Zotero (the
        three reference managers I use) support citations to the biological databases
        ENA, PDB and Uniprot and what is missing</li><li>look at existing aggregators
        of this information (e.g. <a href=\"http://identifiers.org/\">Identifiers.org</a>)
        to figure out whether the import process can be simplified</li><li>start work
        on Zotero <a href=\"https://www.zotero.org/support/dev/translators/coding#web_translators\">web
        translators</a> for these three databases. Zotero is open source software
        and the web translators are written in Javascript</li></ul><p>Please contact
        me if you are interested in helping with this, e.g. with a joint virtual hackathon
        on the 18th (or in person in London or Cambridge on October 15 if that works
        better).</p><p>Together with <a href=\"https://twitter.com/IanMulvany\">Ian
        Mulvany</a> from eLife and others from Papers and Mendeley we have also submitted
        a proposal for a pre-conference workshop/hackathon for the <a href=\"https://www.force11.org/meetings/force2015\">Force2015
        Conference</a> in January to work on this for a broader set of databases,
        which should for example also include software repositories. One question
        is how we properly handle the citation of large numbers of datasets (1000s
        to millions), we could for example allow a range of identifiers in a citation.
        We also need tools to convert identifiers and links in existing documents
        to proper references, something that we <a href=\"https://doi.org/10.53731/r294649-6f79289-8cw19\">have
        also discussed on this blog</a>, and we need to discuss how our bibliographic
        file formats (e.g. bibtex) support these citation types. I <a href=\"https://doi.org/10.53731/r294649-6f79289-8cw12\">said
        before</a> that I am a big fan of Citeproc YAML (or JSON, the bibliographic
        format used by CSL) as bibliographic exchange format, and I know that the
        PLOS Labs hackathon will also touch on this.</p><h2 id=\"community\">Community</h2><p>While
        adding reference manager support for a wider range of citations is the first
        step, the bigger challenge is community support. I don\u2019t think that it
        is a big mental jump for an author to use the reference manager to cite a
        biological database rather than typing in the identifier directly in the text
        (the hard work is registering the identifier in the first place), but this
        needs support by the community, and in particular journal editors. The important
        message is that citations should be done in a consistent way and authors don\u2019t
        have to think about doing this differently for datasets or other relevant
        resources, or different publishers implementing this differently. I think
        the paper by Kafkas et al. (2013) clearly shows that our current recommendations
        for adding identifiers to biological databases is broken, and that we need
        to do something if we take data citation seriously.</p><p>There are several
        concerns about adding every citation to the references list. One of them is
        that we shouldn\u2019t mix citations of scholarly articles with citations
        of other things, e.g. research data. I would argue that not only are we seeing
        an increasing number of <a href=\"https://doi.org/10.1016/j.ipm.2011.10.002\">citations
        to other resources in reference lists</a>, but that we can of course group
        citations by citation type, in addition to the sorting by appearance in the
        text or last name of first author that is common now.</p><p>Another concern
        is that citations of datasets are something else that citations to scholarly
        articles, because the former are typically citations of content created by
        the same group of people at the time the journal article was also created.
        I would argue that again we can highlight this by how we display the references,
        and that I hope that this changes once data citation becomes more widespread.</p><p>What
        should or should not be cited in a scholarly document is of course a big discussion
        topic. What I am arguing is that everything that is cited should go into the
        references list, but that doesn\u2019t change at all what should be cited.
        Personal communications are an example of something that should probably not
        be cited and therefore should also not go into the references list.</p><h3
        id=\"references\">References</h3><p>Fenner M. Please keep it simple. Published
        online September 16, 2014. doi:<a href=\"https://doi.org/10.53731/r294649-6f79289-8cw05\">10.53731/r294649-6f79289-8cw05</a></p><p>Kafkas
        \u015E, Kim JH, McEntyre JR. Database Citation in Full Text Biomedical Articles.
        Larivi\xE8re V, ed. <em>PLoS ONE</em>. 2013;8(5):e63184. doi:<a href=\"https://doi.org/10.1371/journal.pone.0063184\">10.1371/journal.pone.0063184</a></p><p>Data
        Citation Synthesis Group. <em>Joint Declaration of Data Citation Principles</em>.
        Force11; 2014. doi:<a href=\"https://doi.org/10.25490/A97F-EGYK\">10.25490/A97F-EGYK</a></p><p>Fenner
        M. Citations in Markdown Part 3. Published online June 24, 2013. doi:<a href=\"https://doi.org/10.53731/r294649-6f79289-8cw19\">10.53731/r294649-6f79289-8cw19</a></p><p>Fenner
        M. Citeproc YAML for bibliographies. Published online July 30, 2013. doi:<a
        href=\"https://doi.org/10.53731/r294649-6f79289-8cw12\">10.53731/r294649-6f79289-8cw12</a></p><p>Yang
        S, Han R, Ding J, Song Y. The distribution of Web citations. <em>Information
        Processing &amp; Management</em>. 2012;48(4):779-790. doi:<a href=\"https://doi.org/10.1016/j.ipm.2011.10.002\">10.1016/j.ipm.2011.10.002</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Please keep it simple ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/please-keep-it-simple/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw05</id>\n
        \       <published>2014-09-16T15:08:00.000+00:00</published>\n\t\t<updated>2022-08-15T12:51:09.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/photo-1448932284983-0c7b152eba33.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/photo-1448932284983-0c7b152eba33.jpeg\"></p><p>Doing
        scientific research is becoming increasingly complex, both in terms of the
        tools and technologies used, and in the collaboration across disciplines and
        locations that is increasingly commonplace. While the way we write up and
        publish research is of course also very different from 25 years ago, I would
        argue that our tools and services haven\u2019t quite evolved at the same pace.</p><p>Of
        course there are important trends that enable what the Royal Institution <a
        href=\"https://royalsociety.org/policy/projects/science-public-enterprise/Report/\">calls</a>
        <em>Science as an Open Enterprise</em>, most importantly Open Access, which
        has broken down many barriers for open collaboration. But very few organizations
        - commercial or non-profit - see it as their primary mission to make it easier
        for researchers to collaborate and produce great science, in the sense that
        everything else is secondary and this focus is really obvious to everyone.</p><p>The
        following are just some examples that make you laugh hard or cry out loud:</p><ul><li>Finding
        relevant scholarly content. Why is still so hard?</li><li>Reading a paper.
        The majority of scholalry content is still not Open Access. It is embarassing
        how difficult it can be to get the fulltext paper from a subscription journal
        - too slow, too expensive, and sometimes even crippled in functionality.</li><li>Creating
        figures for publication. This process is still so painful that it hurts. And
        publishers often create artificial limitations in file type (TIFF or Postscript)
        and file size (10 MB??).</li><li>Licenses for scholarly content. We don\u2019t
        need choice, but a few licenses that everyone understands and that don\u2019t
        hinder sharing and collaboration</li><li>Secure login. I can use my Facebook
        or Google login almost everywhere, but as a scholar I have a different username
        and password at my institution, funder, the various publishers I submit too,
        and the scholarly services I frequently use?</li><li>Citation styles. Why
        do we still have at least 3,000 styles?</li></ul><p>Citation styles is a perfect
        example of a problem that should have been solved as soon as we made the switch
        to digital publishing. I can travel through half of Europe without showing
        my passport, and using the same currency, but I need to reformat citations
        every time I submit to a different journal? And I have to use the same tool
        for this as my coauthors, as the different reference managers don\u2019t work
        with each other?</p><p>Too often there are other intentions at work in parallel.
        While notable, they sometimes stand in conflict with the goal of making a
        researcher\u2019s life easier. A perfect example is the manuscript submission
        process. In parallel to the tools getting better and easier to use, the demands
        on the author seem to be increasing at an even greater rate, both in the data
        and metadata he or she should provide, and in the work submitting authors
        are asked to do that traditionally have been done by publishers. Another good
        example are peer review and evaluation. The proportion of time spent doing
        research vs. time spent doing administrative work seems to decreasing and
        not increasing.</p><p>I wish more people and organizations would stand up
        and state that keeping it simple is their primary goal.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ CommonMark and the Future of Scholarly Markdown
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/commonmark-and-the-future-of-scholarly-markdown/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw06</id>\n        <published>2014-09-07T15:10:00.000+00:00</published>\n\t\t<updated>2023-09-01T22:07:56.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2023/09/typewriter.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2023/09/typewriter.png\"></p><p>One
        of the important outcomes of the <a href=\"https://github.com/scholmd/scholmd/wiki\">Markdown
        for Science</a> workshop that took place in June 2013 was a decision on a
        name - <em>Scholarly Markdown</em> - and a brief <a href=\"https://github.com/scholmd/scholmd/wiki/What-is-Markdown\">definition</a>:</p><ol><li>Markdown
        that supports the requirements of scientific texts</li><li>Markdown as format
        that glues open scientific text resources together</li><li>A reference implementation
        with documentation and tests</li><li>A community</li></ol><p>In my eyes this
        is still a great definition. And this week something important happened that
        is very relevant for Scholarly Markdown. A small group of people deeply involved
        in Markdown announced <a href=\"http://commonmark.org/\">Standard Markdown</a>:</p><blockquote>We
        propose a standard, unambiguous syntax specification for Markdown, along with
        a suite of comprehensive tests to validate Markdown implementations against
        this specification. We believe this is necessary, even essential, for the
        future of Markdown.</blockquote><p>Markdown is in widespread use, but a lack
        of standard syntax and set of comprehensive tests has hindered the adoption
        for more complex use cases, the development of cross-platform tools, and the
        use of markdown as a document interchange format. I am therefore 100% behind
        this initiative. In particular since this is not just an initiative by large
        commercial organizations heavily using Markdown such as Stack Exchange, Github
        or Reddit, but that the entire spec and both reference implementations have
        been written by <a href=\"http://johnmacfarlane.net/\">John MacFarlane</a>,
        the author of Pandoc, the universal document converter. Not only does Pandoc
        already support many of the features required by Scholarly Markdown (e.g.
        math and citations), but John is the Chair of the Department of Philosophy
        at UC Berkeley.</p><p>Markdown was developed in 2004 by John Gruber, and he
        <a href=\"http://daringfireball.net/projects/markdown/license\">holds the
        rights</a> to the name Markdown. He didn\u2019t want this initiative to use
        the name <strong><strong>Standard Markdown</strong></strong>, so the implementation
        was <a href=\"http://blog.codinghorror.com/standard-markdown-is-now-common-markdown/\">renamed</a>
        to <a href=\"http://commonmark.org/\">CommonMark</a>.</p><p>The consequences
        of all this for Scholarly Markdown?</p><ul><li>CommonMark focusses on the
        basic features of the language, but once the specification is agreed upon
        and implemented by a critical mass of tools, it is clear that there needs
        to be a standardized way to handle extensions of the language. This is both
        about features used by lots of people such as tables, but also functionality
        relevant only for scholarly content.</li><li>This brings us one gigantic step
        closer to a reference implementation and set of tests for Scholarly Markdown,
        as hopefully Scholarly Markdown can build upon the work by John and the CommonMark
        team.</li><li>The name Scholarly Markdown might not be a good idea going forward.
        We should either change the name to align with CommonMark, or we should come
        up with a totally different name, something that the screenwriters have done
        with <a href=\"http://fountain.io/\">their</a> implementation of Markdown.</li></ul>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Using Microsoft Word with git ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/using-microsoft-word-with-git/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw07</id>\n        <published>2014-08-25T15:12:00.000+00:00</published>\n\t\t<updated>2022-08-18T16:08:00.000+00:00</updated>\n\t\t<category
        term=\"Science Hack\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/data_versioning.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/data_versioning.jpeg\"></p><p>One
        of the major challenges of writing a journal article is to keep track of versions
        - both the different versions you create as the document progresses, and to
        merge in the changes made by your collaborators. For most academics Microsoft
        Word is the default writing tool, and it is both very good and very bad in
        this. Very good because the <em>track changes</em> feature makes it easy to
        see what has changed since the last version and who made the changes. Very
        bad because this feature is built around keeping everything in a single Word
        document, so that only one person can work on on a manuscript at a time. This
        usually means sending manuscripts around by email, and being very careful
        about not confusing different versions of the document, which requires <a
        href=\"http://www.phdcomics.com/comics/archive.php?comicid=1531\">creativity</a>.</p><p>Approaches
        to overcome these challenges are to a) integrate the Word documents into collaboration
        tools such as Sharepoint and Office 365, or document sharing services such
        as Dropbox and Google Docs (if you use it just for that), or b) use a different
        authoring tool altogether. If neither of these approaches works for you, you
        have a third option: use the version control system <strong><strong>git</strong></strong>.</p><p><a
        href=\"http://www.mulvany.net/presentations/WikimaniaOpenScholarshipTalk.slides.html#/3\">Git</a>
        is software that helps with <a href=\"https://git-scm.com/book/en/Getting-Started-About-Version-Control\">tracking
        changes to files</a> so that you can recall specific versions later. Git is
        typically used to track changes of software source code (and was originally
        developed by Linus Torvalds for Linux kernel development in 2005), but in
        fact git can be used for any file where we need to keep track of versions
        over time. Git is open source software that runs locally on your computer,
        so please go ahead and start tracking changes to your manuscripts (or other
        complex documents) with git. Any time you want to store a version, do a <code>git
        commit</code> with a little description and an optional tag.</p><p>This approach
        is not ideal, as git was written with source code in text format in mind and
        for example doesn\u2019t understand what has changed between two revisions
        of a Word document. Some people will tell you to never store binary files
        in a version control system, but don\u2019t listen to them. Instead give git
        a tool to convert Word documents into plain text, and git will then happily
        tell you what has changed between revisions. Several tools can do this, but
        since earlier this month Pandoc can read Word documents in <code>docx</code>
        format. Do the following to have Pandoc convert Word documents into markdown,
        and to compare the revisions by word and not by line (which makes more sense):</p><pre><code>#
        .gitattributes file in root folder of your git project\n*.docx diff=pandoc</code></pre><pre><code>#
        .gitconfig file in your home folder\n[diff \"pandoc\"]\n  textconv=pandoc
        --to=markdown\n  prompt = false\n[alias]\n  wdiff = diff --word-diff=color
        --unified=1</code></pre><p>You can then use <code>git wdiff important_file.docx</code>
        to see the changes (with deletions in red and insertions in green), or <code>git
        log -p --word-diff=color important_file.docx</code> to see all changes over
        time.</p><p>While you can now track revisions of a Word document and see the
        changes, you also want to be able to merge different versions of a Word document
        together so that you and your collaborators can work on the manuscript in
        parallel. Git can\u2019t merge binary files together, so you need to first
        convert the Word document into a format that git understands. Just as in the
        previous example we can use Pandoc for that, with markdown as the textual
        format. This would also work with HTML or LaTeX, but the simplicity of markdown
        makes it better suited for version control which doesn\u2019t know about the
        markup of these formats.</p><p>One of the reasons that git became so popular
        with software developers is that it is a <strong><strong>distributed version
        control system</strong></strong> instead of a centralized system such as Subversion.
        This means that you can track all revisions locally on your computer, but
        can still synchronize your revisions with another user. <strong><strong>Github</strong></strong>
        is a popular service that facilitates this synchronization and adds some nice
        features on top. One way to collaborate with your co-authors is therefore
        to set up a Github repository (public or private) for your manuscript, and
        store the master version of the manuscript in markdown format. Instead of
        working on the master version directly, you would use Pandoc to convert back
        and forth between this master version in markdown format and your Word document,
        and would continue to use Word as authoring tool. <a href=\"https://blog.front-matter.io/posts/introducing-rakali/\">Rakali</a>
        is a Pandoc tool that I released last week that can help automate this document
        conversion. Github has a a number of features to facilitate collaboration
        that can be used here, e.g. Github issues for discussion and task management.</p><p>There
        are still a few rough edges in the workflow described above (e.g. only partial
        support of Word track changes), but it is an interesting approach to collaborate
        using Microsoft Word and git. And this workflow can of course be enhanced
        to also include authors that write in LaTeX or one of the other formats that
        Pandoc supports. One nice side effect of using markdown is that Github will
        automatically render a webpage for the document (which it will not do for
        HTML without extra effort).</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Introducing Rakali ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/introducing-rakali/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw08</id>\n
        \       <published>2014-08-18T15:16:00.000+00:00</published>\n\t\t<updated>2022-08-18T16:13:46.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>In July and August I attended
        the <a href=\"http://2014.okfestival.org/\">Open Knowledge Festival</a> and
        <a href=\"http://wikimania2014.wikimedia.org/wiki/Programme\">Wikimania</a>.
        At both events I had many interesting discussions around open source tools
        for open access scholarly publishing, and I was part of a <a href=\"http://wikimania2014.wikimedia.org/wiki/Submissions/The_Full_OA_Stack_-_Open_Access_and_Open_Source\">panel</a>
        on that topic at Wikimania last Sunday. Some of my thoughts were summarized
        in a blog post a few weeks ago (<a href=\"https://blog.front-matter.io/posts/roads-not-stagecoaches/\">Build
        Roads not Stagecoaches</a>). Today I am happy to announce the first public
        release of a tool that hopefully contributes to making publishing of open
        content a bit easier.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/lego_discussion-1-1.jpg\"
        class=\"kg-image\" alt=\"LEGO Researchers are excited that they don\u2019t
        have to use Microsoft Word for manuscript writing anymore.\" loading=\"lazy\"
        width=\"700\" height=\"600\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/lego_discussion-1-1.jpg
        600w, https://blog.front-matter.io/content/images/2022/08/lego_discussion-1-1.jpg
        700w\"><figcaption>LEGO Researchers are excited that they don\u2019t have
        to use Microsoft Word for manuscript writing anymore.</figcaption></figure><p><a
        href=\"https://github.com/rakali/rakali.rb\">Rakali</a> is a Ruby gem that
        acts as a wrapper for the <a href=\"https://pandoc.org\">Pandoc</a> universal
        document converter. Pandoc is a wonderful tool to convert documents between
        file formats and supports many file formats and features important for scholarly
        publishing. Pandoc 1.13 was <a href=\"http://johnmacfarlane.net/pandoc/releases.html\">released</a>
        last Friday, and one of the most exciting new features is a reader for Microsoft
        Word (<code>docx</code>) documents. Pandoc has supported the conversion to
        <code>docx</code> for a while, but now you can use the most popular file format
        for writing scholarly documents and turn your <code>docx</code> files into
        HTML, PDF, LateX, markdown, or a number of other formats, making it much easier
        to collaborate, and to use <code>docx</code> with Pandoc in scholarly publishing
        workflows. A good example would be arXiv, which <a href=\"http://arxiv.org/help/submit#text\">doesn\u2019t
        support</a> <code>docx</code> for text submissions. Instead of turning it
        into PDF the manuscript can now be converted to LaTeX - the preferred file
        format at arXiv - before submission.</p><p>I built <strong><strong>Rakali</strong></strong>
        to make it easier to use Pandoc to convert large numbers of documents in an
        automated way:</p><ul><li>bulk conversion of all files in a folder with a
        specific extension, e.g. <code>md</code>.</li><li>input via a configuration
        file in yaml format instead of via the command line</li><li>validation of
        documents via <a href=\"http://json-schema.org/\">JSON Schema</a>, using the
        <a href=\"https://github.com/hoxworth/json-schema\">json-schema</a> Ruby gem.</li><li>Logging
        via <code>stdout</code> and <code>stderr</code>.</li></ul><p>One interesting
        way to use Rakali and Pandoc is as part of a <a href=\"https://blog.front-matter.io/posts/continuous-publishing/\">continuous
        publishing</a> workflow that involves git and Github, automatically converting
        all files in a folder when something is pushed to the repository using a continuous
        integration tool, and exiting the continuous integration run when one of the
        files doesn\u2019t validate. Look into the Rakali <a href=\"https://github.com/rakali/rakali.rb\">repo</a>
        for an example.</p><p>The most interesting aspect of Rakali is probably validation
        via JSON Schema. File conversion with Pandoc is a two-step process, the intermediate
        format is an internal representation of the document in something called the
        <a href=\"https://blog.front-matter.io/posts/the-grammar-of-scholarly-communication/\">abstract
        syntax tree</a> or AST. Pandoc makes the AST accessible in JSON format, making
        it straightforward to manipulate a document before the conversion into the
        target format with something called <a href=\"http://johnmacfarlane.net/pandoc/scripting.html\">JSON
        filters</a>.</p><p>Validation of XML documents using <a href=\"https://en.wikipedia.org/wiki/Document_type_definition\">DTDs</a>,
        <a href=\"http://relaxng.org/\">RELAX NG</a> and other standards has of course
        been around for a long time, but validation of JSON documents is still relatively
        new. Since many Pandoc document conversion workflows don\u2019t involve any
        XML I thought it would make more sense to validate against the AST, and we
        can use JSON Schema for that. I have started a <a href=\"https://github.com/rakali/pandoc-schemata\">Github
        repository</a> with schemata for the Pandoc AST, and hope to evolve them over
        time using Rakali as a tool. An example log output (from the Rakali test suite,
        stopping file conversion because title and layout metadata are missing) looks
        like this:</p><pre><code>Validation Error: The property '#/0/unMeta' did not
        contain a required property of 'title' in schema 9b6d454d-e609-537b-b761-9599b6c01072#
        for file empty.md\nValidation Error: The property '#/0/unMeta' did not contain
        a required property of 'layout' in schema 9b6d454d-e609-537b-b761-9599b6c01072#
        for file empty.md\nFatal: Conversion of file empty.md failed.</code></pre><p>As
        I had argued before, the challenge for building open source tools for science
        is to <a href=\"https://blog.front-matter.io/posts/dont-reinvent-the-wheel/\">not
        duplicate the work of others</a>, and to integrate well with existing tools
        by focussing on one aspect and doing that aspect well. It also helps to think
        about infrastructure (<a href=\"https://blog.front-matter.io/posts/roads-not-stagecoaches/\">the
        roads</a>) instead of only focussing on the user-facing aspects. There are
        obviously many document conversion tools out there, but Pandoc is certainly
        one of the oldest and most established ones for scholarly content. Rakali
        therefore builds on top of Pandoc and tries to play well with other existing
        tools and services, e.g. by using the UNIX <code>stdout</code> and <code>stderr</code>
        for reporting, and by using a file-based approach that works well with version
        control systems such as git. And since Rakali is a Ruby gem it can not only
        be used as a standalone command line tool, but can also be easily integrated
        into other Ruby applications.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Visualizing Scholarly Content ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/visualizing-scholarly-content/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw09</id>\n        <published>2014-08-09T15:19:00.000+00:00</published>\n\t\t<updated>2022-08-15T12:54:57.000+00:00</updated>\n\t\t<category
        term=\"Chart\"/>\n\t\t<category term=\"Meeting Report\"/>\n        <media:content
        url=\"https://blog.front-matter.io/content/images/2022/08/photo-1434626881859-194d67b2b86f.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/photo-1434626881859-194d67b2b86f.jpeg\"></p><p>One
        topic I will cover this Sunday in a presentation on <a href=\"http://wikimania2014.wikimedia.org/wiki/Submissions/Open_Scholarship_Tools_-_a_whirlwind_tour.\">Open
        Scholarship Tools</a> at <em>Wikimania 2014</em> together with <a href=\"https://twitter.com/ianmulvany\">Ian
        Mulvany</a> is visualization.</p><p>Data visualization is all about <em>telling
        stories with data</em>, something that is of course not only important for
        scholarly content, but for example increasingly common in journalism. This
        is a big and complex topic, but I hope the following will get you started.</p><h3
        id=\"learn-the-basics\">Learn the Basics</h3><p>Work on visualization of scientific
        data should start with a good understanding of the best practices and pitfalls
        of data visualization in general, as well as the specific aspects of visualizing
        scientific data. The following resources have helped me get started - please
        suggest more in the comments:</p><ul><li><a href=\"http://book.flowingdata.com/\">Visualize
        this</a>. A book from Nathan Yau published in 2011. Very helpful in understanding
        the different ways data can be visualized (e.g. when to use a treemap or what
        is a <a href=\"https://en.wikipedia.org/wiki/Choropleth_map\">chloropleth
        map</a>), and an introduction to some tools using practical examples. Nathan\u2019s
        <a href=\"http://flowingdata.com/\">FlowingData</a> blog is also a great resource.</li><li><a
        href=\"https://github.com/mbostock/d3/wiki/Gallery\">D3 Gallery</a>. Lots
        of examples generated using Mike Bostock\u2019s d3.js visualization library.
        A great inspiration for data visualization on the web, even if you use a different
        visualization tool.</li><li><a href=\"http://docs.ggplot2.org/current/index.html\">ggplot2</a>.
        Not only a very popular visualization library for the R language by Hadley
        Wickham, but also an implementation of Leland Wilkison\u2019s Grammar of Graphics.
        The <a href=\"http://www.springer.com/statistics/computational+statistics/book/978-0-387-98140-6\">ggplot2
        book</a> describes this powerful concept (p. 14):</li></ul><blockquote>In
        brief, the grammar tells us that a statistical graphic is a mapping from data
        to aesthetic attributes (colour, shape, size) of geometric objects (points,
        lines, bars). The plot may also contain statistical transformations of the
        data and is drawn on a specific coordinate system. Faceting can be used to
        generate the same plot for different subsets of the dataset. It is the combination
        of these independent components that make up a graphic.</blockquote><h3 id=\"learn-to-use-at-least-one-visualization-tool\">Learn
        to use at least one visualization tool</h3><p>There are many great tools available,
        pick one and learn it well. Some options include:</p><ul><li><strong><strong>Excel</strong></strong>.
        Probably the most popular tool for data visualization. Commercial, with open
        source alternatives such as Libre Office.</li><li><strong><strong>R</strong></strong>.
        Software for statistical computing and analysis. Open source. <a href=\"http://www.rstudio.com/\">RStudio</a>
        is a powerful user interface for R and a good way to get started.</li><li><a
        href=\"http://d3js.org/\"><strong>d3.js</strong></a>. A visualization library
        for Javascript. Open source.</li><li><a href=\"http://www.graphpad.com/scientific-software/prism/\"><strong>Prism</strong></a>.
        A popular visualization tool among scientists. Commercial.</li><li><a href=\"https://datawrapper.de/\"><strong>Datawrapper</strong></a>.
        An open source tool and hosted service for data visualization.</li></ul><p>I
        do most visualizations in either R or d3.js. Both are open source tools with
        a large community and a rich set of libraries, examples and documentation,
        and both take a systematic approach to data visualization (see grammar of
        graphics above).</p><h3 id=\"learn-data-analysis\">Learn data analysis</h3><p>Unless
        your interest is more in information design - see <a href=\"http://www.informationisbeautiful.net/\">Information
        is beautiful</a> for some great examples - data visualization is tightly coupled
        with data analysis. You need to know at least the basics of data analysis
        to do proper data visualizations, e.g. how to handle wrongly formatted data
        (e.g. text in a number column), missing values and outliers. The most time-consuming
        step in my experience is data transformation, i.e. bringing data into the
        format that you want for the analysis and visualization.</p><p>R, Python and
        the relatively new <a href=\"http://julialang.org/\">Julia</a> are popular
        languages for data analysis available as open source. There are many packages
        for these languages that help with common data analysis problems. One additional
        advantage of using a proper language over a set of tools cobbled together
        is that it is easy to automatically recreate a visualization with a new set
        of data - convenient when you need to analyze and visualize an ongoing experiment
        that repeatedly produces new data.</p><h3 id=\"use-a-vector-file-format\">Use
        a vector file format</h3><p>Too many scientific data are still visualized
        using bitmap graphic formats such as <code>tiff</code>, <code>jpg</code> and
        <code>png</code>. These formats are not appropriate for charts and only make
        sense for images. They don\u2019t scale to the screen resolution, and it is
        <a href=\"http://blog.f1000research.com/2014/02/20/the-importance-of-providing-data-and-not-just-images-of-data/\">very
        hard to impossible</a> to reuse or even modify them. Use vector graphic formats
        such as <code>svg</code> or <code>pdf</code> instead. <code>svg</code> is
        my preferred format because in contrast to <code>pdf</code> it can be embedded
        into a larger HTML document, and R and d3.js (my preferred visualization tools)
        can generate this format. <a href=\"http://www.inkscape.org/\">Inkscape</a>
        is an open source SVG editor, and the commercial <strong><strong>Adobe Illustrator</strong></strong>
        can be used to manually polish graphics in <code>svg</code> or <code>pdf</code>
        format, e.g. for journal publication.</p><h3 id=\"get-inspired-by-great-visualizations\">Get
        inspired by great visualizations</h3><p>At the end of the day data visualization
        is all about telling a story with data. Unfortunately the current state of
        affairs for scientific visualizations is very different. In my opinion most
        graphs and figures used in publications don\u2019t provide the data underlying
        the visualization (<a href=\"https://datawrapper.de/\">Datawrapper</a> is
        a great example how this can be done), focus too much on detail rather than
        the overall message, don\u2019t take advantage of the different chart types
        available, and are sometimes even misleading. And I\u2019m not even talking
        about the fact that figures in scholarly papers are <a href=\"https://doi.org/10.12688/f1000research.4263.1\">almost
        never</a> interactive. It rarely happens that I read a paper and get excited
        by looking at a figure - if I do it is usually because the underlying data
        are so compelling that even the simplest visualization will convey the right
        message.</p><p>We should become more creative with visualizing data in scholarly
        documents, and one important step towards that goal is publishers accepting
        more reasonable file formats in manuscript submissions - instead of just <code>tiff</code>
        and <code>eps</code> (<a href=\"http://www.plosone.org/static/figureGuidelines#figures\">PLOS</a>),
        or <code>tiff</code>, <code>eps</code> and <code>pdf</code> (<a href=\"http://www.sciencemag.org/site/feature/contribinfo/prep/prep_revfigs.xhtml#format\">Science</a>),
        and often with a 10 MB file site limit.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ What is a DOI? ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/what-is-doi/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw0a</id>\n        <published>2014-08-06T15:24:00.000+00:00</published>\n\t\t<updated>2022-08-29T09:53:01.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/DALL-E-2022-08-29-11.52.30---garden-gnome-with-an-umbrella-on-the--london-tower-bridge-as-a-William-turner-painting.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/DALL-E-2022-08-29-11.52.30---garden-gnome-with-an-umbrella-on-the--london-tower-bridge-as-a-William-turner-painting.png\"></p><p>This
        Sunday <a href=\"https://twitter.com/ianmulvany\">Ian Mulvany</a> and I will
        do a presentation on <a href=\"http://wikimania2014.wikimedia.org/wiki/Submissions/Open_Scholarship_Tools_-_a_whirlwind_tour.\">Open
        Scholarship Tools</a> at <em>Wikimania 2014</em> in London. From the abstract:</p><blockquote>This
        presentation will give a broad overview of tools and standards that are helping
        with Open Scholarship today.</blockquote><p>One of the four broad topics we
        have picked are <em>digital object identifiers (DOI)s</em>. We want to introduce
        them to people new to them, and we want to show some tricks and cool things
        to people who already now them. Along the way we will also try to debunk some
        myths about DOIs.</p><h3 id=\"what-a-doi-looks-like\">What a DOI looks like</h3><p>DOIs
        - or better DOI names - start with a prefix in the format <code>10.x</code>
        where x is 4-5 digits. The suffix is determined by the organization registering
        the DOI, and there is no consistent pattern across organizations. The DOI
        name is typically expressed as a URL (see below). An example DOI would look
        like: <a href=\"http://dx.doi.org/10.5555/12345678\">http://dx.doi.org/10.5555/12345678</a>.
        Something in the format <strong><strong>10/hvx</strong></strong> or <a href=\"http://doi.org/hvx\">http://doi.org/hvx</a>
        is a <a href=\"http://shortdoi.org/\">shortDOI</a>, and <strong><strong>1721.1/26698</strong></strong>
        or <a href=\"http://hdl.handle.net/1721.1/26698\">http://hdl.handle.net/1721.1/26698</a>
        is a handle. BTW, all DOIs names are also handles, so <a href=\"http://hdl.handle.net/10/hvx\">http://hdl.handle.net/10/hvx</a>
        for the shortDOI example above will resolve correctly.</p><h3 id=\"dois-are-persistent-identifiers\">DOIs
        are persistent identifiers</h3><p>Links to resources can change, particularly
        over long periods of time. Persistent identifiers are needed so that readers
        can still find the content we reference in a scholarly work (or anything else
        where persistent linking is important) 10 or 50 years later. There are many
        kinds of persistent identifiers, one of the key concepts - and a major difference
        to URLs - is to separate the identifier for the resource from its location.
        Persistent identifiers require technical infrastructure to resolve identifiers
        (DOIs use the <a href=\"http://www.handle.net/\">Handle System</a>) and to
        allow long-term archiving of resources. DOI registration agencies such as
        DataCite or CrossRef are required to provide that persistence. Other persistent
        identifier schemes besides DOIs include <a href=\"http://en.wikipedia.org/wiki/PURL\">persistent
        uniform resource locators (PURLs)</a> and <a href=\"http://en.wikipedia.org/wiki/Archival_Resource_Key\">Archival
        Resource Keys (ARKs)</a>.</p><h3 id=\"dois-have-attached-metadata\">DOIs have
        attached metadata</h3><p>All DOIs have metadata attached to them. The metadata
        are supplied by the resource provider, e.g. publisher, and exposed in services
        run by registration agencies, for example metadata search and content negotiation
        (see below). There is a minimal set of required metadata for every DOI, but
        beyond that, different registration agencies will use different metadata schemata,
        and most metadata are optional. Metadata are important to build centralized
        discovery services, making it easier to describe a resource, e.g. journal
        article citing another article. Some of the more recent additions to metadata
        schemata include persistent identifiers for people (<a href=\"http://orcid.org/\">ORCID</a>)
        and funding agencies (<a href=\"http://www.crossref.org/fundref/\">FundRef</a>),
        and license information. The following API call will retrieve all publications
        registered with CrossRef that use a <a href=\"http://creativecommons.org/licenses/by/3.0/deed.en_US\">Creative
        Commons Attribution license</a> (and where this information has been provided
        by the publisher):</p><pre><code>http://api.crossref.org/funders/10.13039/100000001/works?filter=license.url:http://creativecommons.org/licenses/by/3.0/deed.en_US</code></pre><h3
        id=\"dois-support-link-tracking\">DOIs support link tracking</h3><p>Links
        to other resources are an important part of the metadata, and describing all
        citations between a large number scholarly documents is a task that can only
        really be accomplished by a central resource. To solve this very problem DOIs
        were invented and the CrossRef organization started around 15 years ago.</p><h3
        id=\"not-every-doi-is-the-same\">Not every DOI is the same</h3><p>The DOI
        system <a href=\"http://www.doi.org/doi_handbook/1_Introduction.html\">originated
        from an initiative by scholarly publishers</a> (first announced at the Frankfurt
        Book Fair in 1997), with citation linking of journal articles its first application.
        This citation linking system is managed by <a href=\"http://www.crossref.org/\">CrossRef</a>,
        a non-profit member organization of scholarly publishers, and <a href=\"http://search.crossref.org/help/status\">more
        than half</a> of the about <a href=\"http://www.doi.org/faq.html\">100 million
        DOIs</a> that have been assigned to date are managed by them.</p><p>But many
        DOIs are assigned by one of the other 8 <a href=\"http://www.doi.org/RA_Coverage.html\">registration
        agencies</a>. You probably know <a href=\"http://www.datacite.org/\">DataCite</a>,
        but did you know that the <a href=\"http://publications.europa.eu/index_en.htm\">Publications
        Office of the European Union (OP)</a> and the <a href=\"http://www.eidr.org/\">Entertainment
        Identifier Registry (EIDR)</a> also assign DOIs? The distinction is important,
        because some of the functionality is a service of the registration agency
        - metadata search for example is offered by CrossRef (<a href=\"http://search.crossref.org/\">http://search.crossref.org</a>)
        and DataCite (<a href=\"http://search.datacite.org/\">http://search.datacite.org</a>),
        but you can\u2019t search for a DataCite DOI in the CrossRef metadata search.
        There is an API to find out the registration agency behind a DOI so that you
        know what services to expect:</p><pre><code>http://api.crossref.org/works/10.6084/m9.figshare.821213/agency\n\n{\n
        \ \"status\": \"ok\",\n  \"message-type\": \"work-agency\",\n  \"message-version\":
        \"1.0.0\",\n  \"message\": {\n    \"DOI\": \"10.6084/m9.figshare.821213\",\n
        \   \"agency\": {\n      \"id\": \"datacite\",\n      \"label\": \"DataCite\"\n
        \   }\n  }\n}</code></pre><h3 id=\"dois-are-urls\">DOIs are URLs</h3><p><a
        href=\"http://www.doi.org/faq.html\">DOI names may be expressed as URLs (URIs)
        through a HTTP proxy server</a> - e.g. <a href=\"http://dx.doi.org/10.5555/12345679\">http://dx.doi.org/10.5555/12345679</a>,
        and this is how DOIs are typically resolved. For this reason the <a href=\"http://www.crossref.org/02publishers/doi_display_guidelines.htm\">CrossRef
        DOI Display Guidelines</a> recommend that <em>CrossRef DOIs should always
        be displayed as permanent URLs in the online environment</em>. Because DOIs
        can be expressed as URLs, they also have their features:</p><h4 id=\"special-characters\">Special
        characters</h4><p>Because DOIs can be expressed as URLs, DOIs <a href=\"http://www.crossref.org/02publishers/15doi_guidelines.html\">should
        only include characters allowed in URLs</a>, something that wasn\u2019t always
        true in the past and can cause problems, e.g. when using SICIs (<a href=\"https://en.wikipedia.org/wiki/Serial_Item_and_Contribution_Identifier\">Serial
        Item and Contribution Identifier</a>), an extension of the ISSN for journals:</p><pre><code>10.4567/0361-9230(1997)42:&lt;OaEoSR&gt;2.0.TX;2-B</code></pre><h4
        id=\"content-negotiation\">Content negotiation</h4><p>The DOI resolver at
        <em>doi.org</em> (or <em>dx.doi.org</em>) normally resolves to the resource
        location, e.g. a landing page at a publisher website. Requests that are not
        for content type <code>text/html</code> are redirected to the registration
        agency metadata service (currently for CrossRef, DataCite and mEDRA DOIs).
        Using <a href=\"http://www.crosscite.org/cn/\">content negotiation</a>, we
        can ask the metadata service to send us the metadata in a format we specify
        (e.g. Citeproc JSON, bibtex or even a formatted citation in one of thousands
        of citation styles) instead of getting redirected to the resource. This is
        a great way to collect bibliographic information, e.g. to format citations
        for a manuscript. In theory we could also use content negotiation to get a
        particular representation of a resource, e.g. <code>application/pdf</code>
        for a PDF of a paper or <code>text/csv</code> for a dataset in CSV format.
        This is not widely support and I don\u2019t know the details of the implementation
        in the DOI resolver, but you can try this (content negotation is easier with
        the command line than with a browser):</p><pre><code>curl -LH \"Accept: application/pdf\"
        http://dx.doi.org/10.7717/peerj.500 &gt;peerj.500.pdf</code></pre><p>This
        will save the PDF of the 500th PeerJ paper published last week.</p><h4 id=\"fragment-identifiers\">Fragment
        identifiers</h4><p>As discussed in <a href=\"https://blog.front-matter.io/posts/fragment-identifiers-and-dois/\">my
        last blog post</a>, we can use fragment identifiers to subsections of a document
        with DOIs, e.g. <a href=\"http://dx.doi.org/10.1371/journal.pone.0103437#s2\">http://dx.doi.org/10.1371/journal.pone.0103437#s2</a>
        or <a href=\"http://doi.org/10.5446/12780#t=00:20,00:27\">http://doi.org/10.5446/12780#t=00:20,00:27</a>,
        just as we can with every other URL. This is a nice way to directly link to
        a specific document section, e.g. when discussing a paper on Twitter. Fragment
        identifiers are implemented by the client (typically web browser) and depend
        on the document type, but for DOIs that resolve to full-text HTML documents
        they can add granularity to the DOI without much effort.</p><h4 id=\"queries\">Queries</h4><p>URLs
        obviously support queries, but that is a feature I haven\u2019t yet seen with
        DOIs. Queries would allow interesting features, partly overlapping with what
        is possible with fragment identifiers and content negotiation, e.g. <code><a
        href=\"http://dx.doi.org/10.7717/peerj.500?format=pdf\" rel=\"nofollow\">http://dx.doi.org/10.7717/peerj.500?format=pdf</a></code>.
        II hope to find out more until Sunday.</p><h3 id=\"outlook\">Outlook</h3><p>My
        biggest wish? Make DOIs more machine-readable. They are primarily intended
        for human users, enabling them to find the content associated with a DOI.
        But they sometimes don\u2019t work as well as they could with automated tools,
        one example are the <a href=\"https://blog.front-matter.io/posts/broken-dois/\">challenges
        automatically resolving a DOI</a> that I described in a blog post last year.
        Thinking about DOIs as URLs - and using them this way - is the right direction.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Fragment Identifiers and DOIs ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/fragment-identifiers-and-dois/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw0b</id>\n        <published>2014-08-02T15:26:00.000+00:00</published>\n\t\t<updated>2022-08-19T08:05:49.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/Folio_-number-.jpg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/Folio_-number-.jpg\"></p><p>Before
        all our content turned digital, we already used <strong><strong>page numbers</strong></strong>
        to describe a specific section of a book or longer document, with older manuscripts
        using the <a href=\"https://en.wikipedia.org/wiki/Folio\">folio</a> before
        that. Page numbers have transitioned to electronic books with readers such
        as the Kindle <a href=\"http://pogue.blogs.nytimes.com/2011/02/08/page-numbers-for-kindle-books-an-imperfect-solution/?_php=true&amp;_type=blogs&amp;_r=0\">supporting
        them eventually</a>.</p><p>For content on the web we can use the <code>#</code>
        fragment identifier, e.g. <a href=\"https://en.wikipedia.org/wiki/Fragment_identifier#Proposals\">https://en.wikipedia.org/wiki/Fragment_identifier#Proposals</a>
        to navigate to a specific section of a web page. How the linking to this fragment
        is handled, depends on the <strong><strong>MIME</strong></strong> type of
        the document, and will for example be done differently for a text page than
        a video - YouTube understands minutes and seconds into a video as fragment
        identifier, e.g. <a href=\"https://www.youtube.com/watch?v=0UNRZEsLxKc#t=54m52s\">https://www.youtube.com/watch?v=0UNRZEsLxKc#t=54m52s</a>.
        Fragment identifiers are not only helpful to link to a subsection of a document,
        but of course also for navigation within a document.</p><p>All this is of
        course very relevant to scholarly content, which is usually much more structured,
        with most journal articles following the <a href=\"https://en.wikipedia.org/wiki/IMRAD\">IMRAD</a>
        - introduction, methods, results, and discussion - format, usually with additional
        sections such as abstract, references, etc. One approach for linking to figures
        and tables within scholarly articles is using <a href=\"https://blog.front-matter.io/posts/direct-links-to-figures-and-tables-using-component-dois/\">component
        DOIs</a>, e.g. specific DOIs for parts of a larger document. The publisher
        <strong><strong>PLOS</strong></strong> has been using them for a long time,
        and the <a href=\"https://blog.front-matter.io/2014/07/24/dont-reinvent-the-wheel/\">number
        of component DOIs is rising</a>, but most scholarly journal articles don\u2019t
        use component DOIs. And whereas component DOIs are a great concept for content
        such as figures (allowing us to describe the MIME type and other relevant
        metadata), they are probably not the best tool to link to a section or paragraph
        of a scholarly document.</p><p>As it turns out, we already have a tool for
        that, as the DOI proxy server gracefully forwards fragment identifiers (how
        did I miss this?). We can therefore use a DOI with a fragment identifier to</p><ul><li>Results
        section: <a href=\"https://doi.org/10.1371/journal.pone.0103437#s2\">http://doi.org/10.1371/journal.pone.0103437#s2</a></li><li>Specific
        reference: <a href=\"https://doi.org/10.12688/f1000research.4263.1#ref-7\">http://doi.org/10.12688/f1000research.4263.1#ref-7</a></li><li>Decision
        letter: <a href=\"https://doi.org/10.7554/eLife.00471#decision-letter\">http://doi.org/10.7554/eLife.00471#decision-letter</a></li></ul><p>Obviously,
        this only works if the DOI is resolved to the full-text of a resource, and
        not a landing page. And how the fragment identifiers are named and implemented
        is up to the publisher, and the DOI resolver has no information about them.
        These specific links are particularly nice for discussions of a paper, whether
        it is on Twitter or in a discussion forum. It appears that at least the Twitter
        link shortener keeps the fragment identifier, the link to the eLife decision
        letter is shortened to <a href=\"http://t.co/URWaYmGHnY\">http://t.co/URWaYmGHnY</a>.
        This kind of linking works particularly well if the publisher is using a fine-grained
        system of fragment identifiers, the publisher PeerJ for example allows links
        to a specific paragraph - e.g. <a href=\"http://doi.org/10.7717/peerj.500#p-15\">http://doi.org/10.7717/peerj.500#p-15</a>
        - and allows users to <a href=\"http://blog.peerj.com/post/62886292466/peerj-questions-a-new-way-to-never-publish-forget\">ask
        a question</a> right next to that section.</p><p>The examples above all use
        MIME type <code>text/html</code>, as this is what the example DOIs resolve
        to by default. I don\u2019t if and how publishers have implemented fragment
        identifiers for other formats such as PDF or ePub, and what happens if you
        combine fragment identifiers with <a href=\"http://www.crosscite.org/cn/\">content
        negotiation</a>. The shortDOI service works with fragment identifiers as well:
        <a href=\"http://doi.org/pxd#decision-letter\">http://doi.org/pxd#decision-letter</a>.
        Another interesting question would be how fragment identifiers are handled
        for datasets. Typically separate DOIs are assigned for multiple related datasets,
        but there could also be a place for fragment identifiers as well, e.g. to
        specify a subset via a date range. The solution depends again on the content
        type, and the popular <code>text/csv</code> is unfortunately not well suited
        for this, whereas JSON \u2013 using <a href=\"http://tools.ietf.org/html/rfc6901\">JSON
        Pointer</a> \u2013 would work well.</p><p><em>Update 8/2/14: <a href=\"https://twitter.com/ldodds\">Leigh
        Dodds</a> points out that handling the fragment identifier is up to the client
        and the fragment identifier is not sent to the server. Acrobat reader for
        example supports the <code>#page=</code> fragment identifier. He also mentions
        that there is a <a href=\"http://tools.ietf.org/html/rfc7111\">RFC7111</a>
        for fragment identifiers for the text/csv media type - browsers in the future
        might support something like <code><a href=\"http://example.com/data.csv#row=5-7\"
        rel=\"nofollow\">http://example.com/data.csv#row=5-7</a></code>.</em></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ One Ring to Rule them All ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/one-ring-to-rule-them-all/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw0c</id>\n
        \       <published>2014-07-30T15:29:00.000+00:00</published>\n\t\t<updated>2022-08-15T13:00:15.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><blockquote>One Ring to rule
        them all, One Ring to find them, One Ring to bring them all and in the darkness
        bind them.</blockquote><p>Yesterday 60 years ago the first volume of the <em>Lord
        of the Rings</em> trilogy by <em>J.R.R. Tolkien</em> was published. The quote
        above obviously doesn\u2019t quiet apply to scholarly publishing, but one
        recurring theme that I have often heard in the last few years is that of a
        need for a canonical digital document format for scholarly content that rules
        all other formats.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/Download.jpeg\"
        class=\"kg-image\" alt=\"Document formats in scholarly Publishing\" loading=\"lazy\"
        width=\"223\" height=\"226\"><figcaption>Document formats in scholarly Publishing</figcaption></figure><p>A
        few years ago almost everyone you would have said that <code>xml</code> is
        that format, with the NLM Archiving and Interchange Tag Suite - which has
        evolved into <a href=\"http://jats.nlm.nih.gov/publishing/\">JATS</a> - probably
        the most commonly used Document Type Definition (DTD). <code>xml</code> does
        many things really well, but also has important shortcomings, most importantly
        that it is probably not a good format for authors (and don\u2019t tell me
        that <code>docx</code> and <code>odt</code> are XML-based). We therefore don\u2019t
        really expect authors to submit manuscripts in JATS <code>xml</code>, but
        rather convert documents into this format after a manuscript has been accepted
        for publication. This conversion step is often time-consuming and labor-intensive.</p><p>More
        recently <code>html</code> has become the most interesting candidate for a
        canonical scholarly document format. The big advantage over <code>xml</code>
        is that <code>html</code> - or at least <code>html5</code> which is most popular
        today - is an attractive format for online authoring tools (that is why <code>html</code>
        is listed both as input and output format) The downside of this flexibility
        is that it is much harder to embed structure and metadata into <code>html5</code>
        compared to <code>xml</code>. There are initiatives such as <a href=\"http://schema.org/\">schema.org</a>
        and <a href=\"https://github.com/oreillymedia/HTMLBook\">HTMLBook</a> that
        hope to change that, but we aren\u2019t quite there yet.</p><p>Or maybe we
        should learn from Tolkien and give up on the idea of a canonical document
        format and rather spend our energy on building tools that make it easier to
        transition from one format to another. <a href=\"https://pandoc.org\">Pandoc</a>
        is such as tool, but can\u2019t do all the required conversions, e.g. it can\u2019t
        yet use <code>docx</code> as input. The downside here is that every file conversion
        runs the risk of loosing important information. But the increase in flexibility
        hopefully outweights these shortcomings.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Don&#x27;t Reinvent the Wheel ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/dont-reinvent-the-wheel/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw0d</id>\n
        \       <published>2014-07-24T15:33:00.000+00:00</published>\n\t\t<updated>2022-08-18T16:18:49.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/4AxDk-component-dois-per-year.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/4AxDk-component-dois-per-year.png\"></p><p>In
        a <a href=\"https://blog.front-matter.io/posts/build-roads-not-stagecoaches/\">post
        last week</a> I talked about roads and stagecoaches, and how work on scholarly
        infrastructure can often be more important than building customer-facing apps.
        One important aspect of that infrastructure work is to not duplicate efforts.</p><figure
        class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/5673321593_e6a7faa36d_z.jpg\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"478\" height=\"640\"><figcaption>Image
        by Cocoabiscuit <a href=\"https://www.flickr.com/photos/jfgallery/5673321593/\">on
        Flickr</a></figcaption></figure><p>A good example is information (or metadata)
        about scholarly publications. I am the technical lead for the open source
        <a href=\"http://articlemetrics.github.io/\">article-level metrics (ALM) software</a>.
        This software can be used in different ways, but most people use it for tracking
        the metrics of scholarly articles, with articles that have DOIs issued by
        CrossRef. The ALM software needs three pieces of information for every article:
        <strong><strong>DOI</strong></strong>, <strong><strong>publication date</strong></strong>,
        and <strong><strong>title</strong></strong>. This information can be entered
        via a web interface, but that is of course not very practical for adding dozens
        or hundreds of articles at a time. The ALM software has therefore long supported
        the import of multiple articles via a text file and the command line.</p><p>This
        approach is working fine for the ALM software <a href=\"http://articlemetrics.github.io/plos/\">running
        at PLOS since 2009</a>, but is for example a problem if the ALM software runs
        as a service for multiple publishers. A more flexible approach is to provide
        an API to upload articles, and I\u2019ve <a href=\"http://articlemetrics.github.io/docs/api/\">added
        an API</a> for creating, updating and deleting articles in January 2014.</p><p>While
        the API is an improvement, it still requires the integration into a number
        of possibly very different publisher workflows, and you have to deal with
        setting up the permissions, e.g. so that publisher A can\u2019t delete an
        article from publisher B.</p><p>The next ALM release (3.3) will therefore
        add a third approach to importing articles: using the <a href=\"http://api.crossref.org/\">CrossRef
        API</a> to look up article information. Article-level metrics is about tracking
        already published works, so we really only care about articles that have DOIs
        registered with CrossRef and are therefore published. ALM is now talking to
        a single API, and this makes it much easier to do this for a number of publishers
        without writing custom code. Since ALM is an open source application already
        used by several publishers that aspect is important. And because we are importing,
        we have don\u2019t have to worry about permissions. The only requirement is
        that CrossRef has the correct article information, and has this information
        as soon as possible after publication.</p><p>At this point I have a confession
        to make: I regularly use other CrossRef APIs, but wasn\u2019t aware of <strong><strong>api.crossref.org</strong></strong>
        until fairly recently. That is sort of understandable since the reference
        platform was deployed only September last year. The documentation to get you
        started is on <a href=\"https://github.com/CrossRef/rest-api-doc/blob/master/rest_api.md\">Github</a>
        and the version history shows frequent API updates (now at v22). The API will
        return all kinds of information, e.g.</p><ul><li>how many articles has publisher
        x published in 2012</li><li>percentage of DOIs of publisher Y that include
        at least one ORCID identifier</li><li>list all books with a Creative Commons
        CC-BY license that were published this year</li></ul><p>Funder (via FundRef)
        information is also included, but is still incomplete. Another interesting
        result is the number of <a href=\"https://blog.front-matter.io/posts/direct-links-to-figures-and-tables-using-component-dois/\">component
        DOIs</a> (DOIs for figures, tables or other parts of a document) per year.</p><p>For
        my specific use case I wanted an API call that returns all articles published
        by PLOS (or any other publisher) in the last day which I can then run regularly.
        To get all DOIs from a specific publisher, use their CrossRef member ID -
        DOI prefixes don\u2019t work, as publishers can own more than one DOI prefix.
        To make this task a little easier I built a CrossRef member search interface
        into the ALM application:</p><figure class=\"kg-card kg-image-card\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/crossref_api.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"1170\" height=\"774\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/crossref_api.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/08/crossref_api.png
        1000w, https://blog.front-matter.io/content/images/2022/08/crossref_api.png
        1170w\" sizes=\"(min-width: 720px) 720px\"></figure><p>We can filter API responses
        by publication date, but it is a better idea to use the update date, as it
        is possible that the metadata have changed, e.g. a correction of the title.
        We also want to increase the number of results per page (using the <code>rows</code>
        parameter). The final API call for all DOIs updated by PLOS since the beginning
        of the week would be</p><pre><code>http://api.crossref.org/members/340/works?filter=from-update-date:2014-07-21,until-update-date:2014-07-24&amp;rows=1000</code></pre><p>The
        next step is of course to parse the JSON of the API response, and you will
        notice that CrossRef is using <a href=\"http://gsl-nagoya-u.net/http/pub/citeproc-doc.html\">Citeproc
        JSON</a>. This is a standard JSON format for bibliographic information used
        internally by several reference managers for citation styles, but increasingly
        also by APIs and other places where you encounter bibliographic information.</p><p>Citeproc
        JSON is helpful for one particular problem with CrossRef metadata: the exact
        publication date for an article is not always known, and CrossRef (and similarly
        DataCite) only requires the publication year. Citeproc JSON can nicely handle
        partial dates, e.g. year-month:</p><pre><code>issued: {\n  date-parts: [\n
        \   [\n      2014,\n      7\n    ]\n  ]\n},</code></pre><p>I think that a
        similar approach will work for many other systems that require bibliographic
        information about scholarly content with CrossRef DOIs. If are not already
        using <strong><strong>api.crossref.org</strong></strong>, consider integrating
        with it, I find the API fast, well documented, easy to use - and CrossRef
        is very responsive to feedback. As you can always wish for more, I would like
        to see the following: fix the problem were some journal articles are missing
        the publication date (a required field, even if only the year), and consider
        adding the canonical URL to the article metadata (which ALM currently has
        to look up itself, and which is needed to track social media coverage of an
        article).</p><p><em>Update July 24, 2014: added chart with number of component
        DOIs per year</em></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Build Roads not Stagecoaches ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/build-roads-not-stagecoaches/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw0e</id>\n        <published>2014-07-18T15:36:00.000+00:00</published>\n\t\t<updated>2022-08-15T13:03:30.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/break-bulk-sacks-1.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/break-bulk-sacks-1.png\"></p><p>I
        attended the <a href=\"http://2014.okfestival.org/\">Open Knowledge Festival</a>
        this week and I had a blast. For three days (I also attended the fringe event
        <a href=\"http://csvconf.com/\">csv,conf</a> on Tuesday) I listed to wonderful
        presentations and was involved in great discussions - both within sessions,
        but more importantly all the informal discussions between and after sessions.</p><p>Of
        all the things that were discussed I want to pick one theme that resonated
        in particular with me. It surfaced in many places, but was articulated particularly
        well by <a href=\"https://twitter.com/erichysen\">Eric Hysen</a> - who heads
        the <a href=\"http://www.google.com/elections/ed/us\">Google Politics &amp;
        Elections Group</a> - in his keynote yesterday (starting at 54:52, but please
        also watch the keynote by Neelie Kroes, Vice-President of the European Commission):</p><figure
        class=\"kg-card kg-embed-card\"><iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/0UNRZEsLxKc?feature=oembed\"
        frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media;
        gyroscope; picture-in-picture\" allowfullscreen></iframe></figure><p>In his
        keynote he described how travel from Cambridge to London in the 18th and early
        19th century improved mainly as a result of better roads, made possible by
        changes in how these roads were financed. Translated to today, he urged the
        audience to think more about the infrastructure and less about the end products:</p><blockquote>Ecosystems,
        not apps \u2013 Eric Hysen</blockquote><figure class=\"kg-card kg-image-card
        kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/break-bulk-sacks-2.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"1543\" height=\"1087\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/break-bulk-sacks-2.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/08/break-bulk-sacks-2.png
        1000w, https://blog.front-matter.io/content/images/2022/08/break-bulk-sacks-2.png
        1543w\" sizes=\"(min-width: 720px) 720px\"><figcaption><a href=\"https://commons.wikimedia.org/wiki/File:Hafenarbeiter_bei_der_Verladung_von_Sackgut_-_MS_Rothenstein_NDL,_Port_Sudan_1960.png\">Wikimedia
        Commons</a> image used in <a href=\"https://github.com/nickstenning/put-it-in-a-box\">Nick
        Stelling's presentation</a></figcaption></figure><p>On Tuesday at <a href=\"http://csvconf.com/#nickstenning\">csv,conf</a>,
        <a href=\"https://twitter.com/nickstenning\">Nick Stenning</a> - Technical
        Director of the Open Knowledge Foundation - talked about <a href=\"http://dataprotocols.org/data-packages/\">data
        packages</a>, an evolving standard to describe data that are passed around
        betwen different systems. He used the metaphor of containers, and how they
        have dramatically changed the transportation of goods in the last 50 years.
        He <a href=\"https://github.com/nickstenning/put-it-in-a-box\">argued</a>
        that the cost of shipping was in large part determined by the cost of loading
        and unloading, and the container has dramatically changed that equation. We
        are in a very similar situation with datasets, where most of the time is spent
        translating between different formats, joining things together that use different
        names for the same thing, etc.</p><p>What the two presentations have in common
        is not only that they link the building of an open digital infrastructure
        to important transforming events in the history of transportation, but also
        the emphasis on the building blocks rather than the finished product. When
        I thought more about this I realized that these building blocks are exactly
        the projects I get most excited about, i.e. projects that develop standards
        or provide APIs or libraries. Some examples would be</p><ul><li><a href=\"http://orcid.org/\">ORCID</a>:
        unique identifiers for scholarly authors</li><li><a href=\"http://citationstyles.org/\">Citation
        Style Language</a>: a language to describe the formatting of citations and
        bibliographies</li><li><a href=\"https://pandoc.org\">Pandoc</a>: a universal
        document converter</li><li><a href=\"http://ropensci.org/\">rOpenSci</a>:
        packages for the statistical programming language R to access data repositories</li><li><a
        href=\"http://www.niso.org/topics/tl/altmetrics_initiative/\">NISO Alternative
        Assessment Metrics</a>: standards and best practices for novel scholarly metrics</li><li><a
        href=\"http://www.re3data.org/\">re3data</a>: a registry of research data
        repositories</li><li><a href=\"http://creativecommons.org/\">Creative Commons</a>:
        copyright licenses for creative works</li><li><a href=\"https://github.com/articlemetrics/alm\">ALM</a>:
        software to collect comprehensive information about the discussion of scholarly
        articles on the web</li></ul><p>This list doesn\u2019t include all the generic
        software needed to build open science tools, with <strong>git</strong> being
        a perfect example. The last project is obviously the project I have been working
        on the past two years for PLOS, but I have tried to support the other projects
        mentioned in various ways from small code contributions to promotion via this
        blog and presentations, or direct work in these projects. But strangely enough,
        I haven\u2019t really realized this until now.</p><p>Not surprisingly infrastructure,
        servers, libraries and other building blocks are exactly the areas where open
        source software has been most successful so far, and this is of course a core
        part of the UNIX philosophy of building parts that work well together rather
        than big monolithic programs that do everything.</p><h2 id=\"next\">Next</h2><p>We
        need more <strong><strong>Open Science Infrastructure</strong></strong> and
        it is the stuff that I really care about. I think we need to better support
        those projects that build these essential building blocks via advice, cooperation,
        promotion, and financial support. I am willing to help with that effort, and
        I have started to think how I can best contribute.</p><p>On the other hand
        there are many great open science projects that don\u2019t fall in this category,
        maybe even the majority of them. I wish them good luck, but I would advice
        them to think more about infrastructure, and whether there is a small area
        where they can focus on. It still amazes me how successful projects such as
        <strong><strong>Citation Style Language</strong></strong> and <strong><strong>Pandoc</strong></strong>
        have been with no or almost no funding and a very small core group of people
        doing the majority of the work. One critical ingredient is the total focus
        on a very specific problem that is both important and can be solved with specific
        actions. Too many open science projects want to solve too many problems at
        once, try to solve the exact same problems that many other parallel projects
        work on, don\u2019t cooperate enough with those parallel projects, and require
        a critical mass of users to work.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Literate Blogging ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/literate-blogging/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw0f</id>\n
        \       <published>2014-04-14T15:39:00.000+00:00</published>\n\t\t<updated>2022-08-15T13:07:10.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><blockquote>Literate programming
        is a methodology that combines a programming language with a documentation
        language, thereby making programs more robust, more portable, more easily
        maintained, and arguably more fun to write than programs that are written
        only in a high-level language. The main idea is to treat a program as a piece
        of literature, addressed to human beings rather than to a computer. The program
        is also viewed as a hypertext document, rather like the World Wide Web.</blockquote><p>Literate
        Programming by <a href=\"http://www-cs-faculty.stanford.edu/~uno/\">Donald
        Knuth</a> (1983) is a seminal book that introduces the concept of literate
        programming. Using technology available in 2014 we can make a small but important
        change to the last sentence:</p><blockquote>The program is also viewed as
        a hypertext document on the World Wide Web.</blockquote><p>This blog post
        is an example for such a document. The page is written in <strong><strong>markdown</strong></strong>
        (markdown file available <a href=\"https://github.com/mfenner/mfenner.github.io/blob/source/_posts/2014-04-04-literate-blogging.Rmd\">here</a>),
        and all embedded code was executed when this page was generated, i.e. when
        the markdown was converted to HTML and the blog post was published. To demonstrate
        this I have embedded code in three different languages below - the output
        is the second code block.</p><p>In R you have</p><pre><code>cat('Hello, R
        world!\\n')</code></pre><pre><code>Hello, R world!</code></pre><p>Or Python</p><pre><code>print
        \"Hello, Python world!\"</code></pre><pre><code>Hello, Python world!</code></pre><p>Or
        Ruby</p><pre><code>puts 'Hello, Ruby world!'</code></pre><pre><code>Hello,
        Ruby world!</code></pre><p>You can also embed code within text blocks (inline),
        so that <code>3.48 * 723</code> becomes <strong><strong>2516.04</strong></strong>.
        Another important option is to generate figures using the embedded code, e.g.
        the following figure taken from a recent publication.</p><pre><code># code
        for figure 1: density plots for citation counts for PLOS Biology\n# articles
        published in 2010\n\n# load May 20, 2013 ALM report\nalm &lt;- read.csv(\"data/alm_report_plos_biology_2013-05-20.csv\",
        stringsAsFactors = FALSE)\n\n# only look at research articles\nalm &lt;- subset(alm,
        alm$article_type == \"Research Article\")\n\n# only look at papers published
        in 2010\nalm$publication_date &lt;- as.Date(alm$publication_date)\nalm &lt;-
        subset(alm, alm$publication_date &gt; \"2010-01-01\" &amp; alm$publication_date
        &lt;=\n    \"2010-12-31\")\n\n# labels\ncolnames &lt;- dimnames(alm)[[2]]\nplos.color
        &lt;- \"#1ebd21\"\nplos.source &lt;- \"scopus\"\n\nplos.xlab &lt;- \"Scopus
        Citations\"\nplos.ylab &lt;- \"Probability\"\n\nquantile &lt;- quantile(alm[,
        plos.source], c(0.1, 0.5, 0.9), na.rm = TRUE)\n\n# plot the chart\nopar &lt;-
        par(mai = c(0.5, 0.75, 0.5, 0.5), omi = c(0.25, 0.1, 0.25, 0.1), mgp = c(3,\n
        \   0.5, 0.5), fg = \"black\", cex.main = 2, cex.lab = 1.5, col = plos.color,\n
        \   col.main = plos.color, col.lab = plos.color, xaxs = \"i\", yaxs = \"i\")\n\nd
        &lt;- density(alm[, plos.source], from = 0, to = 100)\nd$x &lt;- append(d$x,
        0)\nd$y &lt;- append(d$y, 0)\nplot(d, type = \"n\", main = NA, xlab = NA,
        ylab = NA, xlim = c(0, 100), frame.plot = FALSE)\npolygon(d, col = plos.color,
        border = NA)\nmtext(plos.xlab, side = 1, col = plos.color, cex = 1.25, outer
        = TRUE, adj = 1,\n    at = 1)\nmtext(plos.ylab, side = 2, col = plos.color,
        cex = 1.25, outer = TRUE, adj = 0,\n    at = 1, las = 1)\n\npar(opar)</code></pre><figure
        class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/pbio.1001687.g001.png\"
        class=\"kg-image\" alt=\"Figure 1. Citation counts for PLOS Biology articles
        published in 2010. Scopus citation counts plotted as a probability distribution
        for all 197 PLOS Biology research articles published in 2010. Data collected
        May 20, 2013. Median 19 citations; 10% of papers have at least 50 citations.
        From Fenner (2013).\" loading=\"lazy\" width=\"1339\" height=\"812\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/pbio.1001687.g001.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/08/pbio.1001687.g001.png
        1000w, https://blog.front-matter.io/content/images/2022/08/pbio.1001687.g001.png
        1339w\" sizes=\"(min-width: 720px) 720px\"><figcaption><strong style=\"box-sizing:
        border-box; font-weight: bold;\">Figure 1. Citation counts for PLOS Biology
        articles published in 2010.</strong> Scopus citation counts plotted as a probability
        distribution for all 197 <em style=\"box-sizing: border-box;\">PLOS Biology</em>
        research articles published in 2010. Data collected May 20, 2013. Median 19
        citations; 10% of papers have at least 50 citations. From Fenner <span class=\"citation\"
        data-cites=\"fenner2013\" style=\"box-sizing: border-box;\">(2013)</span>.</figcaption></figure><p>All
        this functionality is provided by <a href=\"http://yihui.name/knitr/\">knitr</a>,
        a package for the R statistical programming language. knitr has been around
        for a while, but integration into the <a href=\"http://jekyllrb.com/\">Jekyll</a>
        blogging platform is still fragile. Earlier this week at the <a href=\"https://github.com/ropensci/hackathon\">rOpenSci
        hackathon</a> (more on this later) a group of us worked hard to improve this
        integration. We are still not completely done, but the source code is available
        <a href=\"https://github.com/ropensci/docs\">here</a>. Most importantly, all
        the conversion happens on the server, and we are only using freely available
        tools. I have now enabled this functionality for this blog, so expect more
        code embedded examples in the future.</p><h2 id=\"references\">References</h2><p>Fenner,
        M. (2013). What can article-level metrics do for you? <em>PLoS Biol</em>,
        <em>11</em>(10), e1001687. <a href=\"http://doi.org/10.1371/journal.pbio.1001687\">doi:10.1371/journal.pbio.1001687</a></p><p>Knuth,
        D. E., Stanford University, &amp; Computer Science Department. (1983). <em>Literate
        programming</em>. Stanford, CA: Dept. of Computer Science, Stanford University.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Continuous Publishing ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/continuous-publishing/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw0g</id>\n
        \       <published>2014-03-10T15:44:00.000+00:00</published>\n\t\t<updated>2022-08-18T16:23:44.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/Agile-vs-iterative-flow.jpg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/Agile-vs-iterative-flow.jpg\"></p><p>Earlier
        this week Bj\xF6rn Brembs wrote in a blog post (<a href=\"http://bjoern.brembs.net/2014/03/what-is-the-difference-between-text-data-and-code/\">What
        Is The Difference Between Text, Data And Code?</a>):</p><blockquote>To sum
        it up: our intellectual output today manifests itself in code, data and text.</blockquote><p>The
        post is about the importance of publication of data and software where currently
        <em>the rewards are stacked disproportionately in favor of text publications</em>.
        The intended audience is probably mainly other scientists (Bj\xF6rn is a neurobiologist)
        who are reluctant to publish data and/or code, but there is another interesting
        aspect to this.</p><p>Just as scientific publication increasingly means more
        than just text and includes data and software, we are also increasingly seeing
        tools and methodologies common in software development applied to scientific
        publishing. This in particular includes the ideas behind Open Source software
        (which shares many commonalities with Open Access and Open Science), but also
        tools like the git version control system (<a href=\"http://marciovm.com/i-want-a-github-of-science/\">We
        Need a Github of Science</a>) or the markdown markdown language (<a href=\"https://blog.front-mattetr.io/posts/a-call-for-scholarly-markdown/\">A
        Call for Scholarly Markdown</a>).</p><p>Continuous Delivery is another concept
        increasingly popular in software development that has many implications on
        how research can be performed and reported. Martin Fowler describes it as:</p><blockquote>Continuous
        Delivery is a software development discipline where you build software in
        such a way that the software can be released to production at any time.</blockquote><p>The
        concept of frequent small releases is of course familiar to everyone practicing
        <a href=\"http://usefulchem.wikispaces.com/\">Open Notebook Science</a>, writing
        science blogs, presenting preliminary data at conferences or publishing <a
        href=\"http://arxiv.org/\">preprints</a>, and is even relevant to <a href=\"http://www.crossref.org/crossmark/\">CrossMark</a>,
        a service that tracks corrections, enhancements and other changes of scholarly
        documents.</p><p>When you read the definition given by Martin Fowler carefully,
        you see that Continuous Delivery is about more than the frequency of software
        updates \u2013 it is in fact about improving the process of releasing software.
        The scientific publication is the corresponding event in science, and I think
        that nobody would argue with me that the experience publishing a paper is
        too complex, time-consuming and often frustrating. The focus here is not on
        the time it takes to do peer review, or the multiple revisions needed before
        a manuscript is accepted. I am talking about the pain submitting a manuscript,
        the back and forth regarding file formats, citation styles and other technical
        requirements, the reformatting of manuscripts, and also the time it takes
        from accepting a manuscript to finally publishing it online.</p><p>I would
        argue that the main reason publishing is so painful for everyone involved
        is that it is still very much a manual process. Just as software development
        is creative work, but still can benefit tremendously from tools such as automated
        tests and build tools, we can apply the same principles to scientific publishing.
        This means that everything that can be automated should be automated so that
        we can focus on those areas that need human judgement. The mistake that I
        think is commonly made is that automation for many publishers means automation
        for the publisher, with even more work for the author who submits a manuscript.
        A good example is that authors are increasingly asked to submit publication-ready
        manuscripts even though typesetting and desktop publishing is not their area
        of expertise and the manuscript text will be very different after one or more
        rounds of revision. The pain of processing manuscripts into something that
        can be published was summarized perfectly by typesetter and friend Kaveh Bazargan
        at the <a href=\"http://www.youtube.com/watch?feature=player_embedded&amp;v=CGkcsvofjdg\">SpotOn
        London 2012 Conference</a> (via <a href=\"http://rossmounce.co.uk/2012/11/19/yet-another-solo12-recap-part2/\">Ross
        Mounce\u2019s blog</a>):</p><blockquote>It\u2019s madness really. I\u2019m
        here to say I shouldn\u2019t be in business.</blockquote><p>The promise of
        Continuous Delivery for publishing is to develop tools and best practices
        that make the process of publication faster, with better quality, and less
        frustrating. Continuous Integration (<a href=\"http://martinfowler.com/articles/continuousIntegration.html\">again
        Martin Fowler</a>) is an important part of Continuous Delivery and means frequently
        merging all developer working copies of a software project into a central
        repository, combined with running automated unit tests and software builds
        using an integration server.</p><p>We can apply Continuous Integration to
        scholarly documents - instead of automated tests and software builds we can
        automate the transformation of documents into <a href=\"https://blog.front-matter.io/posts/from-markdown-to-jats-xml-in-one-step/\">JATS
        XML</a> and other output formats, and we can automate the process of checking
        for required metadata, correct file formats for images, etc. And we can use
        the same software tools for this, many of which are freely available to Open
        Source projects.</p><p>As an example of how this can be done <a href=\"https://github.com/mfenner/jekyll-travis\">I
        have integrated</a> the <a href=\"https://travis-ci.org/\">Travis CI</a> Continuous
        Integration server with the book project <a href=\"http://book.openingscience.org/\">Opening
        Science</a>. The recently published book is a dynamic book that hopefully
        is updated frequently in the coming months. Every time an editor approves
        a correction to the text - <a href=\"https://github.com/openingscience/book\">hosted
        in markdown format on Github</a> - the Travis CI server is automatically triggered
        to build a new HTML version of the book and to push the new version to the
        book website. The Travis server is running the <a href=\"http://johnmacfarlane.net/pandoc/\">Pandoc</a>
        document converter to not only convert the changed document from markdown
        to HTML, but Pandoc will also insert and format references, and the <a href=\"http://jekyllrb.com/\">Jekyll</a>
        site generator will build a nice website around the markdown files. Over time
        this build process can be extended to do other things as well, from <a href=\"https://blog.front-matter.io/posts/auto-generating-links-to-data-and-resources/\">auto-generating
        links to data and resources</a> to transforming the document into <a href=\"https://blog.front-matter.io/posts/from-markdown-to-jats-xml-in-one-step/\">other
        file formats</a> besides HTML.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Are static Websites the Future or the Past?
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/are-static-websites-the-future-or-the-past/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw0h</id>\n        <published>2014-03-05T15:47:00.000+00:00</published>\n\t\t<updated>2022-08-15T13:10:58.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/3781208877_936e1a162c_z.jpg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/3781208877_936e1a162c_z.jpg\"></p><p>Last
        week I had a little discussion on Twitter about a great blog post by Zach
        Holman: <a href=\"http://zachholman.com/posts/only-90s-developers/\">Only
        90s Web Developers Remember This</a>. The post is not only fun to read, but
        also reminded me that it is now almost 20 years (1995) that I built my first
        website - of course using some of the techniques (the one pixel gif!, the
        <code>&amp;nbsp;</code> tag!) described in the post.</p><figure class=\"kg-card
        kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/scriptwebtitle.gif\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"250\" height=\"50\"><figcaption>ScriptWeb
        logo 1995</figcaption></figure><p>We started ScriptWeb back in 1995 as a central
        resource for scripting on the Mac (AppleScript and Frontier). It was a nice
        collaborative effort and I was resposible for a directory of scripting additions
        (or osaxen), joining forces with MacScripter.net a few years later:</p><figure
        class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/osaxen.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"587\" height=\"639\"><figcaption>Scripting
        Additions at Macscripter.net 2000</figcaption></figure><p>Since then I have
        built many other websites for fun and work, adapting to how technology changed
        over the years:</p><ul><li>1995: website running on a Mac Quadra 610 using
        the WebSTAR HTTP server and server side includes (<a href=\"https://en.wikipedia.org/wiki/Server_Side_Includes\">SSI</a>)</li><li>1995:
        static site generation with outline navigation using AppleScript. FTP to transfer
        files</li><li>1995: Visual HTML editors (Adobe PageMill 1.0)</li><li>1999:
        database server and application layer (too long ago to remember the technology)</li><li>2001:
        Open source database and application code with MySQL and PHP. CVS for version
        control</li><li>2001: web frameworks with PHP and MySQL: PostNuke and Xaraya</li><li>2005:
        more complex web application frameworks: Ruby on Rails. Subversion version
        control</li><li>2008: git for version control</li><li>2011: more complex frontend
        Javascript</li><li>2013: static site generator Jekyll</li></ul><p>Since last
        June this blog is running on Github pages and the site is generated with <a
        href=\"http://jekyllrb.com/\">Jekyll</a>. Jekyll works really well to build
        static websites such as this blog, but I am increasingly using it for more
        complex projects, e.g. for the online version of a <a href=\"http://book.openingscience.org/\">book
        on Open Science</a>.</p><p>What I find interesting in this timeline is that
        with Jekyll there is a shift in focus. Rather than building even more complex
        web pages that are generated dynamically by the server, we are going back
        to a two-stage process where the HTML pages are built first and then served
        as HTML, CSS and Javascript without any database or server application layer.
        Doesn\u2019t sound too different from what we did in the 1990s. This approach
        obviously works well for content-heavy sites like this blog or book chapters,
        not so much for dynamically generated content that changes every few minutes,
        or where the page is put together from many different page fragments.</p><p>What
        I don\u2019t know, and I am really interested to find out, is how well this
        scales to larger sites, specifically publisher websites that host thousands
        of scholarly journal articles - again content that is very text-heavy and
        doesn\u2019t change that much. The potential benefits of replacing the paradigm
        of a database layer that holds all content with a paradigm that stores all
        content in files managed by git version control are clear: serving the content
        on the web becomes less complex, cheaper and faster. The tradeoff is of course
        that generating the static content becomes more complex and time-consuming,
        and it can become a challenge to mix the static content with dynamic content
        generated by servers as well as the user\u2019s browser. For a now infamous
        example using this technology, look no further than <a href=\"http://www.huffingtonpost.com/john-pavley/obamacare-website-problems_b_4057618.html\">Heathcare.gov</a>.
        I don\u2019t know enough details to understand what went wrong, and it might
        have more to do with the scale of the project and the tight timeline to launch.
        For scholarly journal articles this might be a reasonable approach, as even
        when there is no longer a printed version of the journal, articles are still
        published on a specific date, and changing the content is a very formal process.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Six Misunderstandings about Scholarly Markdown
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/six-misunderstandings-about-scholarly-markdown/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw0j</id>\n        <published>2014-03-03T15:50:00.000+00:00</published>\n\t\t<updated>2022-08-18T16:26:04.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>In this post I want to talk
        about some of the misunderstandings I frequently encounter when discussing
        <a href=\"https://blog.front-matter.io/posts/what-is-scholarly-markdown/\">markdown
        as a format for authoring scholarly documents</a>.</p><h2 id=\"scholars-will-always-use-microsoft-word\">Scholars
        will always use Microsoft Word</h2><p>Microsoft Word is of course what almost
        all authors use in the life sciences and many other disciplines. One big reason
        for this is the file formats accepted my manuscript submission systems. By
        limiting the options to Microsoft Word (and maybe LaTeX), you make it impossible
        for authors to use other tools, even if they wanted to. Publishers should
        accept manuscripts in any reasonable file format, as I have <a href=\"https://blog.front-matter.io/posts/the-grammar-of-scholarly-communication/\">argued
        before</a>.</p><h2 id=\"my-markup-language-is-better-than-markdown\">My markup
        language is better than markdown</h2><p>There are of course numerous alternatives
        to markdown, including <a href=\"http://txstyle.org/\">Textile</a>, <a href=\"http://www.methods.co.nz/asciidoc/\">AsciiDoc</a>,
        <a href=\"http://www.mediawiki.org/wiki/Help:Formatting\">MediaWiki Markup</a>,
        and <a href=\"http://docutils.sourceforge.net/docs/ref/rst/introduction.html\">reStructuredText</a>.
        There will always be features that are better implemented in one of these
        languages, but I don\u2019t think there is room for more than one major initiative
        for a scholarly markup language. And markdown has the right mix of features
        and broad support from tools and the community.</p><p>Related to this there
        is the argument against markdown that the format <a href=\"http://blog.codinghorror.com/the-future-of-markdown/\">is
        a mess</a> and that there are too many versions (or flavors) of it. While
        that is certainly a big problem with markdown, I would argue that with <a
        href=\"http://johnmacfarlane.net/pandoc/\">Pandoc</a> we have a nice standard
        and reference implementation for Scholarly Markdown. Pandoc is constantly
        evolving, and the addition of support for arbitrary YAML metadata was the
        biggest new feature in 2013 for me.</p><h2 id=\"scholarly-markdown-is-too-complex-and-we-might-as-well-use-latex\">Scholarly
        Markdown is too complex and we might as well use LaTeX</h2><blockquote>LaTeX
        is a high-quality typesetting system; it includes features designed for the
        production of technical and scientific documentation. <br>The LaTeX Team,
        2014</blockquote><p>Although LaTeX has solved many of the problems Scholarly
        Markdown tries to tackle a long time ago, it is still something else. LaTeX
        at its core is a typesetting system, which is not something Scholarly Markdown
        cares about for two reasons: a) the focus is on authoring documents, which
        are then submitted to other systems at publishers and elsewhere that are specialized
        in producing the final document, and b) the focus is on HTML and the web as
        this is where we want most of the interactions with scholarly documents to
        take place. This means that</p><ul><li>Markdown is a great input format to
        convert into other formats, including XML (see for example my <a href=\"https://github.com/mfenner/pandoc-jats\">pandoc-jats</a>).</li><li>LaTeX
        will always be the best choice for some content, e.g. documents rich in mathematical
        formulas</li><li>If the ultimate goal was to produce high-quality PDF documents,
        Scholarly Markdown would be a bad choice. It is the right format for HTML
        and the related ePub.</li></ul><p>We have to be very careful that we keep
        the right balance of simplicity and features in Scholarly Markdown. This means
        that sometimes we should just include the LaTeX code, e.g. for math.</p><h2
        id=\"scientists-need-a-wysiwyg-editor-and-then-the-file-format-doesn-t-matter\">Scientists
        need a WYSIWYG Editor, and then the file format doesn\u2019t matter</h2><p><a
        href=\"http://en.wikipedia.org/wiki/WYSIWYG\">WYSIWYG</a> - What You See Is
        What You Get - is a user interface metaphor that is both a blessing and a
        curse. We desperately need better writing tools, and this of course also means
        user interfaces that help with that task. But the focus on creating a new
        authoring environment that focuses too much on WYSIWYG creates several problems:</p><ul><li>WYSIWYG
        is not always a good metaphor for scholarly documents. Typographic features
        such as fonts, line spacing, etc. are not something that belong into an authoring
        environment - this is done during the publishing step, as is the formatting
        of references according to a specific citation style.</li><li>WYSIWYG is for
        human interactions, but content in scholarly documents is increasingly created
        by computers. Two good examples are statistics and figures created in <a href=\"http://yihui.name/knitr/\">R/knitr</a>
        or <a href=\"http://ipython.org/notebook.html\">iPython Notebook</a>. Scholarly
        Markdown works perfectly with these workflows.</li><li>WYSIWYG authoring environments
        run the high risk of vendor lock-in. This is understandable if you run a startup
        and want to promote your tool, but is not in the best interest of the scholarly
        community.</li></ul><p>Version control via git is central to Scholarly Markdown,
        and this can also be challenging for a WYSIWYG environment. But there are
        many good examples of how to make this work.</p><h2 id=\"scientists-should-submit-their-manuscripts-in-jats-xml-the-standard-format-for-scholarly-documents\">Scientists
        should submit their manuscripts in JATS XML, the standard format for scholarly
        documents</h2><p>At the end of the day most scholarly publications in the
        life sciences are converted into JATS XML. Unfortunately, central aspects
        of the format (e.g. the required document structure or required attributes)
        are difficult to enforce in an authoring environment. Even if you build a
        tool that can nicely handle this, I\u2019m not so sure we want to burden an
        author with this, especially since the manuscript will usually undergo a lot
        of changes before it is accepted and then published.</p><h2 id=\"the-future-is-html\">The
        future is HTML</h2><p>Although the future for consuming scholarly documents
        is clearly HTML (and ePub), and there are great HTML editors, I\u2019m not
        so sure that HTML will become the default for authoring environments. This
        is the reason why markdown and related markup languages were invented, and
        even with modern WYSIWYG editors working directly with HTML is not always
        the best choice. HTML has two problems: a) it is not as human-readable as
        markdown and therefore requires an additional layer for authoring, and b)
        it is not as structured as XML, which makes it difficult to create some of
        the rigid document structure required for scholarly documents. O\u2019Reilly
        is trying to get more structure into HTML for print and digital books with
        <a href=\"https://github.com/oreillymedia/htmlbook\">HTMLBook</a>, but with
        too much structure you might run into similar problems for authoring as discussed
        above for JATS XML. And of course, you can include HTML in markdown documents.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ From Markdown to JATS XML in one Step ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/from-markdown-to-jats-xml-in-one-step/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw0k</id>\n        <published>2013-12-12T15:54:00.000+00:00</published>\n\t\t<updated>2022-08-18T16:32:27.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>The Journal Article Tag Suite
        (<a href=\"http://jats.nlm.nih.gov/\">JATS</a>) is a NISO standard that defines
        a set of XML elements and attributes for tagging journal articles. JATS is
        not only used for fulltext content at PubMed Central (and JATS has evolved
        from the NLM Archiving and Interchange Tag Suite originally developed for
        PubMed Central), but is also increasinly used by publishers.</p><p>For many
        publishers the <em>version of record</em> of an article is stored in XML,
        and other formats (currently HTML, PDF and increasingly ePub) are generated
        from this XML. Unfortunately the process of converting author-submitted manuscripts
        into JATS-compliant XML is time-consuming and costly, and this is a problem
        in particular for small publishers.</p><p>In a recent blog post (<a href=\"https://blog.front-matter.io/posts/the-grammar-of-scholarly-communication/\">The
        Grammar of Scholarly Communication</a>) I argued that publishers should accept
        manuscripts in any reasonable file format, including Microsoft Word, Open
        Office, LaTeX, Markdown, HTML and PDF. Readers of this blog know that I am
        a big fan of <a href=\"https://blog.front-matter.io/posts/a-call-for-scholarly-markdown/\">markdown</a>
        for scholarly documents, but I am of course well aware that at the end of
        the day these documents have to be converted into JATS.</p><p>As a small step
        towards that goal I have today released the first public version of <a href=\"https://github.com/mfenner/pandoc-jats\">pandoc-jats</a>,
        a <a href=\"http://johnmacfarlane.net/pandoc/README.html#custom-writers\">custom
        writer for Pandoc</a> that converts markdown documents into JATS XML with
        a single command, e.g.</p><pre><code>pandoc -f example.md --filter pandoc-citeproc
        --bibliography=example.bib --csl=apa.csl -t JATS.lua -o example.xml</code></pre><p>Please
        see the <a href=\"https://github.com/mfenner/pandoc-jats\">pandoc-jats</a>
        Github repository for more detailed information, but using this custom writer
        is as simple as downloading a single <code>JATS.lua</code>file. The big challenge
        is of course to make this custom writer work with as many documents as possible,
        and that will be my job the next few weeks. Two example JATS documents are
        below (both markdown versions of scholarly articles and posted on this blog
        as HTML):</p><ul><li><a href=\"https://blog.front-matter.io/posts/a-call-for-scholarly-markdown/\">Nine
        simple ways to make it easier to (re)use your data</a></li><li><a href=\"https://blog.front-matter.io/posts/what-can-article-level-metrics-do-for-you\">What
        Can Article Level Metrics Do for You?</a></li></ul><p>Both JATS files were
        validated against the JATS DTD and XSD and showed no errors with the NLM XML
        StyleChecker - using the excellent <a href=\"https://github.com/PeerJ/jats-conversion\">jats-conversion</a>
        conversion and validation tools written by Alf Eaton. Markdown is actually
        a nice file format to convert to XML - in contrast to HTML authors can\u2019t
        for example put closing tags at the wrong places. And a Pandoc custom writer
        written in the Lua scripting language is an interesting alternative to XSLT
        transformations, the more common way to create JATS XML. The custom writer
        has not been tested with other Pandoc input formats besides markdown, of particular
        interest are of course HTML and LaTeX - Microsoft Word .docx is unfortunately
        only a Pandoc output format.</p><p>This is the first public release and there
        is of course a lot of room for improvement. Many elements and attributes are
        not yet supported - although <a href=\"http://orcid.org/blog/2013/03/22/orcid-how-more-specifying-orcid-ids-document-metadata\">ORCID
        author identifiers</a> are of course included. Please help me improve this
        tool using the Github <a href=\"https://github.com/mfenner/pandoc-jats/issues\">Issue
        Tracker</a>.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Example article with embedded code and data
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/example-article-with-embedded-code-and-data/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw0n</id>\n        <published>2013-12-11T16:04:00.000+00:00</published>\n\t\t<updated>2022-08-19T08:11:21.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>In October I published an
        essay on Article-Level Metrics (ALM) in PLOS Biology (Fenner, 2013). The essay
        is a good introduction into Article-Level Metrics, and I am proud that it
        is part of the <a href=\"http://dx.doi.org/10.1371/issue.pcol.v06.i03\">Tenth
        Anniversary PLOS Biology Collection</a>. Like all PLOS content, the article
        was published with a <a href=\"http://blogs.plos.org/tech/creative-commons-for-science-interview-with-puneet-kishor/\">Creative
        Commons attribution license</a>, allowing me to republish the article on this
        blog. I have now done so and the article is available <a href=\"https://blog.front-matter.io/posts/what-can-article-level-metrics-do-for-you/\">here</a>.</p><p>Of
        course I didn\u2019t want to simply republish the article, but I wanted to
        publish an improved version. The article has five figures, four of them show
        visualizations of ALM data that were generated using R (the fifth figure is
        a table reproduced from another article). The PLOS article includes the ALM
        dataset and the R scripts used to generate the figures as <a href=\"http://dx.doi.org/10.1371/journal.pbio.1001687.s001\">supplementary
        information</a>. What I have done now is to recreate the article as a single
        markdown file (available <a href=\"https://github.com/mfenner/blog/blob/master/_posts/2013-12-11-what-can-article-level-metrics-do-for-you.Rmd\">here</a>)
        that has all R code embedded. Using R and <a href=\"http://yihui.name/knitr/\">knitr</a>
        - and the <a href=\"http://blog.martinfenner.org/data/alm_report_plos_biology_2013-05-20.csv\">CSV
        file with the ALM data</a> - everyone can now reproduce the figures from the
        paper by simply running the embedded code, and can dig deeper into the data.</p><figure
        class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/pbio.1001687.g003.png\"
        class=\"kg-image\" alt=\"Figure 3. Views vs.\_citations for PLOS Biology articles
        published in 2010.\" loading=\"lazy\" width=\"2000\" height=\"1223\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/pbio.1001687.g003.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/08/pbio.1001687.g003.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2022/08/pbio.1001687.g003.png
        1600w, https://blog.front-matter.io/content/images/size/w2400/2022/08/pbio.1001687.g003.png
        2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><strong style=\"box-sizing:
        border-box; font-weight: bold;\">Figure 3.</strong> Views vs.&nbsp;citations
        for PLOS Biology articles published in 2010.</figcaption></figure><p>This
        was a good opportunity to improve the accessibility of the article in other
        ways. Instead of the raster image formats PNG, JPEG and TIFF used by PLOS
        and almost every other publisher, I generated the figures in the vector format
        SVG. Not only does SVG produce images independent of device resolution and
        screen size (try to zoom in on the figure above), but SVG can also easily
        be manipulated in the browser since it is XML. This is beyond the scope of
        this blog post, but look at the <a href=\"http://d3js.org/\">d3.js</a> Javascript
        library for great examples of how SVG can be dynamically generated and changed
        in the browser. <strong><strong>Figure 3</strong></strong> above could for
        example be enhanced so that the article title is displayed when you hover
        over one of the bubbles, or we could enable zooming to show more detail.</p><p>Like
        all content on this blog, the article was created using <a href=\"http://johnmacfarlane.net/pandoc/\">Pandoc</a>,
        and the bibliography was dynamically generated. This makes it easy to change
        the citation style, and I decided to use the <a href=\"http://www.apastyle.org/\">APA
        Style</a> that shows the citations in the text as author-date rather than
        numbered as with the PLOS style (see the example citation in the first paragraph).
        The combined bibliography for all blog posts including the article can be
        downloaded in bibtex format <a href=\"http://blog.martinfenner.org/bibliography/references.bib\">here</a>.</p><p>Lastly,
        I wanted to generate nicer HTML for a better online reading experience. I
        haven\u2019t done anything fancy, but most publishers seem to focus on navigation
        around an article, so that very little screen real estate is left for the
        actual content of the article. I\u2019ve tried to improve readability by reducing
        the navigation areas to a minimum, by using readable fonts in larger sizes:
        <a href=\"https://typekit.com/fonts/minion-pro\">Adobe Minion Pro</a> for
        the body text and <a href=\"https://typekit.com/fonts/myriad-pro\">Adobe Myriad
        Pro</a> for headings, tables and figure legends.</p><h2 id=\"references\">References</h2><p>Fenner,
        M. (2013). What can article-level metrics do for you? <em>PLoS Biol</em>,
        <em>11</em>(10), e1001687. <a href=\"http://doi.org/10.1371/journal.pbio.1001687\">doi:10.1371/journal.pbio.1001687</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ What Can Article-Level Metrics Do for You?
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/what-can-article-level-metrics-do-for-you/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw0m</id>\n        <published>2013-12-11T15:58:00.000+00:00</published>\n\t\t<updated>2023-09-07T22:59:24.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/2013-12-11_figure_1-1.svg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/2013-12-11_figure_1-1.svg\"></p><p><em>Article-level
        metrics (ALMs) provide a wide range of metrics about the uptake of an individual
        journal article by the scientific community after publication. They include
        citations, usage statistics, discussions in online comments and social media,
        social bookmarking, and recommendations. In this essay, we describe why article-level
        metrics are an important extension of traditional citation-based journal metrics
        and provide a number of examples from ALM data collected for PLOS Biology.</em></p>\n<p>The
        scientific impact of a particular piece of research is reflected in how this
        work is taken up by the scientific community. The first systematic approach
        that was used to assess impact, based on the technology available at the time,
        was to track citations and aggregate them by journal. This strategy is not
        only no longer necessary since now we can easily track citations for individual
        articles but also, and more importantly, journal-based metrics are now considered
        a poor performance measure for individual articles (Campbell, 2008; Gl\xE4nzel
        &amp; Wouters, 2013). One major problem with journal-based metrics is the
        variation in citations per article, which means that a small percentage of
        articles can skew, and are responsible for, the majority of the journal-based
        citation impact factor, as shown by Campbell (2008) for the 2004 <em>Nature</em>
        Journal Impact Factor. <strong>Figure 1</strong> further illustrates this
        point, showing the wide distribution of citation counts between <em>PLOS Biology</em>
        research articles published in 2010. <em>PLOS Biology</em> research articles
        published in 2010 have been cited a median 19 times to date in Scopus, but
        10% of them have been cited 50 or more times, and two articles (Dickson, Wang,
        Krantz, Hakonarson, &amp; Goldstein, 2010; Narendra et al., 2010) more than
        300 times. <em>PLOS Biology</em> metrics are used as examples throughout this
        essay, and the dataset is available in the supporting information (<strong>Data
        S1</strong>). Similar data are available for an increasing number of other
        publications and organizations.</p>\n<pre><code># code for figure 1: density
        plots for citation counts for PLOS Biology\n# articles published in 2010\n\n#
        load May 20, 2013 ALM report\nalm &lt;- read.csv(\"data/alm_report_plos_biology_2013-05-20.csv\",
        stringsAsFactors = FALSE)\n\n# only look at research articles\nalm &lt;- subset(alm,
        alm$article_type == \"Research Article\")\n\n# only look at papers published
        in 2010\nalm$publication_date &lt;- as.Date(alm$publication_date)\nalm &lt;-
        subset(alm, alm$publication_date &gt; \"2010-01-01\" &amp; alm$publication_date
        &lt;=\n    \"2010-12-31\")\n\n# labels\ncolnames &lt;- dimnames(alm)[[2]]\nplos.color
        &lt;- \"#1ebd21\"\nplos.source &lt;- \"scopus\"\n\nplos.xlab &lt;- \"Scopus
        Citations\"\nplos.ylab &lt;- \"Probability\"\n\nquantile &lt;- quantile(alm[,
        plos.source], c(0.1, 0.5, 0.9), na.rm = TRUE)\n\n# plot the chart\nopar &lt;-
        par(mai = c(0.5, 0.75, 0.5, 0.5), omi = c(0.25, 0.1, 0.25, 0.1), mgp = c(3,\n
        \   0.5, 0.5), fg = \"black\", cex.main = 2, cex.lab = 1.5, col = plos.color,\n
        \   col.main = plos.color, col.lab = plos.color, xaxs = \"i\", yaxs = \"i\")\n\nd
        &lt;- density(alm[, plos.source], from = 0, to = 100)\nd$x &lt;- append(d$x,
        0)\nd$y &lt;- append(d$y, 0)\nplot(d, type = \"n\", main = NA, xlab = NA,
        ylab = NA, xlim = c(0, 100), frame.plot = FALSE)\npolygon(d, col = plos.color,
        border = NA)\nmtext(plos.xlab, side = 1, col = plos.color, cex = 1.25, outer
        = TRUE, adj = 1,\n    at = 1)\nmtext(plos.ylab, side = 2, col = plos.color,
        cex = 1.25, outer = TRUE, adj = 0,\n    at = 1, las = 1)\n\npar(opar)</code></pre>\n<figure
        class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/2013-12-11_figure_1-1-1.svg\"
        class=\"kg-image\" alt=\"Figure 1. Citation counts for PLOS Biology articles
        published in 2010. Scopus citation counts plotted as a probability distribution
        for all 197 PLOS Biology research articles published in 2010. Data collected
        May 20, 2013. Median 19 citations; 10% of papers have at least 50 citations.\"
        loading=\"lazy\" width=\"960\" height=\"672\"><figcaption><b><strong>Figure
        1. Citation counts for PLOS Biology articles published in 2010.</strong></b><span>
        Scopus citation counts plotted as a probability distribution for all 197 </span><i><em
        class=\"italic\">PLOS Biology</em></i><span> research articles published in
        2010. Data collected May 20, 2013. Median 19 citations; 10% of papers have
        at least 50 citations.</span></figcaption></figure>\n<p>Scientific impact
        is a multi-dimensional construct that can not be adequately measured by any
        single indicator (Bollen, Sompel, Hagberg, &amp; Chute, 2009; Gl\xE4nzel &amp;
        Wouters, 2013; Schekman &amp; Patterson, 2013). To this end, PLOS has collected
        and displayed a variety of metrics for all its articles since 2009. The array
        of different categorised article-level metrics (ALMs) used and provided by
        PLOS as of August 2013 are shown in <strong>Figure 2</strong>. In addition
        to citations and usage statistics, i.e., how often an article has been viewed
        and downloaded, PLOS also collects metrics about: how often an article has
        been saved in online reference managers, such as Mendeley; how often an article
        has been discussed in its comments section online, and also in science blogs
        or in social media; and how often an article has been recommended by other
        scientists. These additional metrics provide valuable information that we
        would miss if we only consider citations. Two important shortcomings of citation-based
        metrics are that (1) they take years to accumulate and (2) citation analysis
        is not always the best indicator of impact in more practical fields, such
        as clinical medicine (Eck, Waltman, Raan, Klautz, &amp; Peul, 2013). Usage
        statistics often better reflect the impact of work in more practical fields,
        and they also sometimes better highlight articles of general interest (for
        example, the 2006 <em>PLOS Biology</em> article on the citation advantage
        of Open Access articles (Eysenbach, 2006), one of the 10 most-viewed articles
        published in <em>PLOS Biology</em>).</p>\n<figure class=\"kg-card kg-image-card
        kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/2013-12-11_figure_2.jpg\"
        class=\"kg-image\" alt=\"Figure 2. Article-level metrics used by PLOS in August
        2013 and their categories. Taken from (Lin &amp; Fenner, 2013) with permission
        by the authors.\" loading=\"lazy\" width=\"2000\" height=\"843\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/2013-12-11_figure_2.jpg
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/08/2013-12-11_figure_2.jpg
        1000w, https://blog.front-matter.io/content/images/size/w1600/2022/08/2013-12-11_figure_2.jpg
        1600w, https://blog.front-matter.io/content/images/2022/08/2013-12-11_figure_2.jpg
        2007w\" sizes=\"(min-width: 720px) 720px\"><figcaption><b><strong>Figure 2.
        Article-level metrics used by PLOS in August 2013 and their categories.</strong></b><span>
        Taken from (Lin &amp; Fenner, 2013) with permission by the authors.</span></figcaption></figure>\n<p>A
        bubble chart showing all 2010 <em>PLOS Biology</em> articles (<strong>Figure
        3</strong>) gives a good overview of the year\u2019s views and citations,
        plus it shows the influence that the article type (as indicated by dot color)
        has on an article\u2019s performance as measured by these metrics. The weekly
        <em>PLOS Biology</em> publication schedule is reflected in this figure, with
        articles published on the same day present in a vertical line. <strong>Figure
        3</strong> also shows that the two most highly cited 2010 <em>PLOS Biology</em>
        research articles are also among the most viewed (indicated by the red arrows),
        but overall there isn\u2019t a strong correlation between citations and views.
        The most-viewed article published in 2010 in <em>PLOS Biology</em> is an essay
        on Darwinian selection in robots (Floreano &amp; Keller, 2010). Detailed usage
        statistics also allow speculatulation about the different ways that readers
        access and make use of published literature; some articles are browsed or
        read online due to general interest while others that are downloaded (and
        perhaps also printed) may reflect the reader\u2019s intention to look at the
        data and results in detail and to return to the article more than once.</p>\n<pre><code>#
        code for figure 3: Bubblechart views vs. citations for PLOS Biology\n# articles
        published in 2010.\n\n# Load required libraries\nlibrary(plyr)\n\n# load May
        20, 2013 ALM report\nalm &lt;- read.csv(\"../data/alm_report_plos_biology_2013-05-20.csv\",
        stringsAsFactors = FALSE,\n    na.strings = c(\"0\"))\n\n# only look at papers
        published in 2010\nalm$publication_date &lt;- as.Date(alm$publication_date)\nalm
        &lt;- subset(alm, alm$publication_date &gt; \"2010-01-01\" &amp; alm$publication_date
        &lt;=\n    \"2010-12-31\")\n\n# make sure counter values are numbers\nalm$counter_html
        &lt;- as.numeric(alm$counter_html)\n\n# lump all papers together that are
        not research articles\nreassignType &lt;- function(x) if (x == \"Research
        Article\") 1 else 0\nalm$article_group &lt;- aaply(alm$article_type, 1, reassignType)\n\n#
        calculate article age in months\nalm$age_in_months &lt;- (Sys.Date() - alm$publication_date)/365.25
        * 12\nstart_age_in_months &lt;- floor(as.numeric(Sys.Date() - as.Date(strptime(\"2010-12-31\",\n
        \   format = \"%Y-%m-%d\")))/365.25 * 12)\n\n# chart variables\nx &lt;- alm$age_in_months\ny
        &lt;- alm$counter\nz &lt;- alm$scopus\n\nxlab &lt;- \"Age in Months\"\nylab
        &lt;- \"Total Views\"\n\nlabels &lt;- alm$article_group\ncol.main &lt;- \"#1ebd21\"\ncol
        &lt;- \"#666358\"\n\n# calculate bubble diameter\nz &lt;- sqrt(z/pi)\n\n#
        calculate bubble color\ngetColor &lt;- function(x) c(\"#c9c9c7\", \"#1ebd21\")[x
        + 1]\ncolors &lt;- aaply(labels, 1, getColor)\n\n# plot the chart\nopar &lt;-
        par(mai = c(0.5, 0.75, 0.5, 0.5), omi = c(0.25, 0.1, 0.25, 0.1), mgp = c(3,\n
        \   0.5, 0.5), fg = \"black\", cex = 1, cex.main = 2, cex.lab = 1.5, col =
        \"white\",\n    col.main = col.main, col.lab = col)\n\nplot(x, y, type = \"n\",
        xlim = c(start_age_in_months, start_age_in_months + 13),\n    ylim = c(0,
        60000), xlab = NA, ylab = NA, las = 1)\nsymbols(x, y, circles = z, inches
        = exp(1.3)/15, bg = colors, xlim = c(start_age_in_months,\n    start_age_in_months
        + 13), ylim = c(0, ymax), xlab = NA, ylab = NA, las = 1,\n    add = TRUE)\nmtext(xlab,
        side = 1, col = col.main, cex = 1.25, outer = TRUE, adj = 1, at = 1)\nmtext(ylab,
        side = 2, col = col.main, cex = 1.25, outer = TRUE, adj = 0, at = 1,\n    las
        = 1)\n\npar(opar)</code></pre>\n<figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/2013-12-11_figure_3.svg\"
        class=\"kg-image\" alt=\"Figure 3. Views vs.&nbsp;citations for PLOS Biology
        articles published in 2010. All 304 PLOS Biology articles published in 2010.
        Bubble size correlates with number of Scopus citations. Research articles
        are labeled green; all other articles are grey. Red arrows indicate the two
        most highly cited papers. Data collected May 20, 2013.\" loading=\"lazy\"
        width=\"960\" height=\"672\"><figcaption><b><strong>Figure 3. Views vs.&nbsp;citations
        for PLOS Biology articles published in 2010.</strong></b><span> All 304 </span><i><em
        class=\"italic\">PLOS Biology</em></i><span> articles published in 2010. Bubble
        size correlates with number of Scopus citations. Research articles are labeled
        green; all other articles are grey. Red arrows indicate the two most highly
        cited papers. Data collected May 20, 2013.</span></figcaption></figure>\n<p>When
        readers first see an interesting article, their response is often to view
        or download it. By contrast, a citation may be one of the last outcomes of
        their interest, occuring only about 1 in 300 times a PLOS paper is viewed
        online. A lot of things happen in between these potential responses, ranging
        from discussions in comments, social media, and blogs, to bookmarking, to
        linking from websites. These activities are usually subsumed under the term
        \xE2\u20AC\u0153altmetrics,\xE2\u20AC\x9D and their variety can be overwhelming.
        Therefore, it helps to group them together into categories, and several organizations,
        including PLOS, are using the category labels of Viewed, Cited, Saved, Discussed,
        and Recommended (<strong>Figures 2 and 4</strong>, see also (Lin &amp; Fenner,
        2013)).</p>\n<pre><code># code for figure 4: bar plot for Article-level metrics
        for PLOS Biology\n\n# Load required libraries\nlibrary(reshape2)\n\n# load
        May 20, 2013 ALM report\nalm &lt;- read.csv(\"../data/alm_report_plos_biology_2013-05-20.csv\",
        stringsAsFactors = FALSE,\n    na.strings = c(0, \"0\"))\n\n# only look at
        research articles\nalm &lt;- subset(alm, alm$article_type == \"Research Article\")\n\n#
        make sure columns are in the right format\nalm$counter_html &lt;- as.numeric(alm$counter_html)\nalm$mendeley
        &lt;- as.numeric(alm$mendeley)\n\n# options\nplos.color &lt;- \"#1ebd21\"\nplos.colors
        &lt;- c(\"#a17f78\", \"#ad9a27\", \"#ad9a27\", \"#ad9a27\", \"#ad9a27\", \"#ad9a27\",\n
        \   \"#dcebdd\", \"#dcebdd\", \"#789aa1\", \"#789aa1\", \"#789aa1\", \"#304345\",
        \"#304345\")\n\n# use subset of columns\nalm &lt;- subset(alm, select = c(\"f1000\",
        \"wikipedia\", \"researchblogging\", \"comments\",\n    \"facebook\", \"twitter\",
        \"citeulike\", \"mendeley\", \"pubmed\", \"crossref\", \"scopus\",\n    \"pmc_html\",
        \"counter_html\"))\n\n# calculate percentage of values that are not missing
        (i.e. have a count of\n# at least 1)\ncolSums &lt;- colSums(!is.na(alm)) *
        100/length(alm$counter_html)\nexactSums &lt;- sum(as.numeric(alm$pmc_html),
        na.rm = TRUE)\n\n# plot the chart\nopar &lt;- par(mar = c(0.1, 7.25, 0.1,
        0.1) + 0.1, omi = c(0.1, 0.25, 0.1, 0.1),\n    col.main = plos.color)\n\nplos.names
        &lt;- c(\"F1000Prime\", \"Wikipedia\", \"Research Blogging\", \"PLOS Comments\",\n
        \   \"Facebook\", \"Twitter\", \"CiteULike\", \"Mendeley\", \"PubMed Citations\",
        \"CrossRef\",\n    \"Scopus\", \"PMC HTML Views\", \"PLOS HTML Views\")\ny
        &lt;- barplot(colSums, horiz = TRUE, col = plos.colors, border = NA, xlab
        = plos.names,\n    xlim = c(0, 120), axes = FALSE, names.arg = plos.names,
        las = 1, adj = 0)\ntext(colSums + 6, y, labels = sprintf(\"%1.0f%%\", colSums))\n\npar(opar)</code></pre>\n<figure
        class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/2013-12-11_figure_4.svg\"
        class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"960\" height=\"672\"><figcaption><b><strong>Figure
        4. </strong></b><span>Article-level metrics for PLOS Biology. Proportion of
        all 1,706 </span><i><em class=\"italic\">PLOS Biology</em></i><span> research
        articles published up to May 20, 2013 mentioned by particular article-level
        metrics source. Colors indicate categories (Viewed, Cited, Saved, Discussed,
        Recommended), as used on the PLOS website.</span></figcaption></figure>\n<p>All
        <em>PLOS Biology</em> articles are viewed and downloaded, and almost all of
        them (all research articles and nearly all front matter) will be cited sooner
        or later. Almost all of them will also be bookmarked in online reference managers,
        such as Mendeley, but the percentage of articles that are discussed online
        is much smaller. Some of these percentages are time dependent; the use of
        social media discussion platforms, such as Twitter and Facebook for example,
        has increased in recent years (93% of <em>PLOS Biology</em> research articles
        published since June 2012 have been discussed on Twitter, and 63% mentioned
        on Facebook). These are the locations where most of the online discussion
        around published articles currently seems to take place; the percentage of
        papers with comments on the PLOS website or that have science blog posts written
        about them is much smaller. Not all of this online discussion is about research
        articles, and perhaps, not surprisingly, the most-tweeted PLOS article overall
        (with more than 1,100 tweets) is a <em>PLOS Biology</em> perspective on the
        use of social media for scientists (Bik &amp; Goldstein, 2013).</p>\n<p>Some
        metrics are not so much indicators of a broad online discussion, but rather
        focus on highlighting articles of particular interest. For example, science
        blogs allow a more detailed discussion of an article as compared to comments
        or tweets, and journals themselves sometimes choose to highlight a paper on
        their own blogs, allowing for a more digestible explanation of the science
        for the non-expert reader (Fausto et al., 2012). Coverage by other bloggers
        also serves the same purpose; a good example of this is one recent post on
        the OpenHelix Blog (\u201CVideo Tip of the Week: Turkeys and their genomes,\u201D
        2012) that contains video footage of the second author of a 2010 <em>PLOS
        Biology</em> article (Dalloul et al., 2010) discussing the turkey genome.</p>\n<p>F1000Prime,
        a commercial service of recommendations by expert scientists, was added to
        the PLOS Article-Level Metrics in August 2013. We now highlight on the PLOS
        website when any articles have received at least one recommendation within
        F1000Prime. We also monitor when an article has been cited within the widely
        used modern-day online encyclopedia, Wikipedia. A good example of the latter
        is the Tasmanian devil Wikipedia page (\u201CTasmanian devil,\u201D 2013)
        that links to a <em>PLOS Biology</em> research article published in 2010 (Nilsson
        et al., 2010). While a F1000Prime recommendation is a strong endorsement from
        peer(s) in the scientific community, being included in a Wikipedia page is
        akin to making it into a textbook about the subject area and being read by
        a much wider audience that goes beyond the scientific community.</p>\n<p><em>PLOS
        Biology</em> is the PLOS journal with the highest percentage of articles recommended
        in F1000Prime and mentioned in Wikipedia, but there is only partial overlap
        between the two groups of articles because they focus on different audiences
        (<strong>Figure 5</strong>). These recommendations and mentions in turn show
        correlations with other metrics, but not simple ones; you can\u2019t assume,
        for example, that highly cited articles are more likely to be recommended
        by F1000Prime, so it will be interesting to monitor these trends now that
        we include this information.</p>\n<pre><code># code for figure 5: Venn diagram
        F1000 vs. Wikipedia for PLOS Biology\n# articles\n\n# load required libraries\nlibrary(\"plyr\")\nlibrary(\"VennDiagram\")\n\n#
        load May 20, 2013 ALM report\nalm &lt;- read.csv(\"../data/alm_report_plos_biology_2013-05-20.csv\",
        stringsAsFactors = FALSE)\n\n# only look at research articles\nalm &lt;- subset(alm,
        alm$article_type == \"Research Article\")\n\n# group articles based on values
        in Wikipedia and F1000\nreassignWikipedia &lt;- function(x) if (x &gt; 0)
        1 else 0\nalm$wikipedia_bin &lt;- aaply(alm$wikipedia, 1, reassignWikipedia)\nreassignF1000
        &lt;- function(x) if (x &gt; 0) 2 else 0\nalm$f1000_bin &lt;- aaply(alm$f1000,
        1, reassignF1000)\nalm$article_group = alm$wikipedia_bin + alm$f1000_bin\nreassignCombined
        &lt;- function(x) if (x == 3) 1 else 0\nalm$combined_bin &lt;- aaply(alm$article_group,
        1, reassignCombined)\nreassignNo &lt;- function(x) if (x == 0) 1 else 0\nalm$no_bin
        &lt;- aaply(alm$article_group, 1, reassignNo)\n\n# remember to divide f1000_bin
        by 2, as this is the default value\nsummary &lt;- colSums(subset(alm, select
        = c(\"wikipedia_bin\", \"f1000_bin\", \"combined_bin\",\n    \"no_bin\")),
        na.rm = TRUE)\nrows &lt;- nrow(alm)\n\n# options\nplos.colors &lt;- c(\"#c9c9c7\",
        \"#0000ff\", \"#ff0000\")\n\n# plot the chart\nopar &lt;- par(mai = c(0.5,
        0.75, 3.5, 0.5), omi = c(0.5, 0.5, 1.5, 0.5), mgp = c(3,\n    0.5, 0.5), fg
        = \"black\", cex.main = 2, cex.lab = 1.5, col = plos.color,\n    col.main
        = plos.color, col.lab = plos.color, xaxs = \"i\", yaxs = \"i\")\n\nvenn.plot
        &lt;- draw.triple.venn(area1 = rows, area2 = summary[1], area3 = summary[2]/2,\n
        \   n12 = summary[1], n23 = summary[3], n13 = summary[2]/2, n123 = summary[3],\n
        \   euler.d = TRUE, scaled = TRUE, fill = plos.colors, cex = 2, fontfamily
        = rep(\"sans\",\n        7))\n\npar(opar)</code></pre>\n<figure class=\"kg-card
        kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/2013-12-11_figure_5.svg\"
        class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"480\" height=\"480\"><figcaption><b><strong>Figure
        5.</strong></b><span> PLOS Biology articles: sites of recommendation and discussion.
        Number of </span><i><em class=\"italic\">PLOS Biology</em></i><span> research
        articles published up to May 20, 2013 that have been recommended by F1000Prime
        (red) or mentioned in Wikipedia (blue).</span></figcaption></figure>\n<p>With
        the increasing availability of ALM data, there comes a growing need to provide
        tools that will allow the community to interrogate them. A good first step
        for researchers, research administrators, and others interested in looking
        at the metrics of a larger set of PLOS articles is the recently launched ALM
        Reports tool (\u201CALM Reports,\u201D 2013). There are also a growing number
        of service providers, including <a href=\"http://altmetric.com/\" rel=\"nofollow\">Altmetric.com</a>
        (\u201C<a href=\"http://altmetric.com/\" rel=\"nofollow\">Altmetric.com</a>,\u201D
        2013), ImpactStory (\u201CImpactStory,\u201D 2013), and Plum Analytics (\u201CPlum
        Analytics,\u201D 2013) that provide similar services for articles from other
        publishers.</p>\n<p>As article-level metrics become increasingly used by publishers,
        funders, universities, and researchers, one of the major challenges to overcome
        is ensuring that standards and best practices are widely adopted and understood.
        The National Information Standards Organization (NISO) was recently awarded
        a grant by the Alfred P. Sloan Foundation to work on this (\u201CNISO Alternative
        Assessment Metrics (Altmetrics) Project,\u201D 2013), and PLOS is actively
        involved in this project. We look forward to further developing our article-level
        metrics and to having them adopted by other publishers, which hopefully will
        pave the way to their wide incorporation into research and researcher assessments.</p>\n<h3
        id=\"supporting-information\">Supporting Information</h3>\n<p><a href=\"http://dx.doi.org/10.1371/journal.pbio.1001687.s001\"><strong>Data
        S1</strong></a><strong>. Dataset of ALM for PLOS Biology articles used in
        the text, and R scripts that were used to produce figures.</strong> The data
        were collected on May 20, 2013 and include all <em>PLOS Biology</em> articles
        published up to that day. Data for F1000Prime were collected on August 15,
        2013. All charts were produced with R version 3.0.0.</p>\n<h2 id=\"acknowledgments\">Acknowledgments</h2>\n<p>This
        is a preprint authored by me and published<em> </em>in <em>PLOS Biology</em>
        in<em> </em>a <a href=\"http://doi.org/10.1371/journal.pbio.1001687\" rel=\"noreferrer\">peer-reviewed
        version</a>.</p>\n<h2 id=\"references\">References</h2>\n<p>ALM Reports. (2013).
        Retrieved from <a href=\"http://almreports.plos.org/\">http://almreports.plos.org</a></p>\n<p><a
        href=\"http://altmetric.com/\" rel=\"nofollow\">Altmetric.com</a>. (2013).
        Retrieved from <a href=\"http://www.altmetric.com/\" rel=\"nofollow\">http://www.altmetric.com/</a></p>\n<p>Bik,
        H. M., &amp; Goldstein, M. C. (2013). An introduction to social media for
        scientists. <em>PLOS Biology</em>, <em>11</em>(4), e1001535. <a href=\"http://doi.org/10.1371/journal.pbio.1001535\">doi:10.1371/journal.pbio.1001535</a></p>\n<p>Bollen,
        J., Sompel, H. de, Hagberg, A., &amp; Chute, R. (2009). A Principal Component
        Analysis of 39 Scientific Impact Measures. <em>PLoS ONE</em>, <em>4</em>(6),
        e6022. <a href=\"http://doi.org/10.1371/journal.pone.0006022\">doi:10.1371/journal.pone.0006022</a></p>\n<p>Campbell,
        P. (2008). Escape from the impact factor. <em>Ethics in Science and Environmental
        Politics</em>, <em>8</em>, 5\u20137. Journal article. <a href=\"http://doi.org/10.3354/esep00078\">doi:10.3354/esep00078</a></p>\n<p>Dalloul,
        R. A., Long, J. A., Zimin, A. V., Aslam, L., Beal, K., Blomberg, L. A., \u2026
        Reed, K. M. (2010). Multi-platform next-generation sequencing of the domestic
        turkey (Meleagris gallopavo): genome assembly and analysis. <em>PLOS Biology</em>,
        <em>8</em>(9). <a href=\"http://doi.org/10.1371/journal.pbio.1000475\">doi:10.1371/journal.pbio.1000475</a></p>\n<p>Dickson,
        S. P., Wang, K., Krantz, I., Hakonarson, H., &amp; Goldstein, D. B. (2010).
        Rare variants create synthetic genome-wide associations. <em>PLOS Biology</em>,
        <em>8</em>(1), e1000294. <a href=\"http://doi.org/10.1371/journal.pbio.1000294\">doi:10.1371/journal.pbio.1000294</a></p>\n<p>Eck,
        N. J. van, Waltman, L., Raan, A. F. J. van, Klautz, R. J. M., &amp; Peul,
        W. C. (2013). Citation analysis may severely underestimate the impact of clinical
        research as compared to basic research. <em>PLOS ONE</em>, <em>8</em>(4),
        e62395. <a href=\"http://doi.org/10.1371/journal.pone.0062395\">doi:10.1371/journal.pone.0062395</a></p>\n<p>Eysenbach,
        G. (2006). Citation advantage of open access articles. <em>PLOS Biology</em>,
        <em>4</em>(5), e157. <a href=\"http://doi.org/10.1371/journal.pbio.0040157\">doi:10.1371/journal.pbio.0040157</a></p>\n<p>Fausto,
        S., Machado, F. A., Bento, L. F. J., Iamarino, A., Nahas, T. R., &amp; Munger,
        D. S. (2012). Research blogging: indexing and registering the change in science
        2.0. <em>PLOS ONE</em>, <em>7</em>(12), e50109. <a href=\"http://doi.org/10.1371/journal.pone.0050109\">doi:10.1371/journal.pone.0050109</a></p>\n<p>Floreano,
        D., &amp; Keller, L. (2010). Evolution of adaptive behaviour in robots by
        means of Darwinian selection. <em>PLOS Biology</em>, <em>8</em>(1), e1000292.
        <a href=\"http://doi.org/10.1371/journal.pbio.1000292\">doi:10.1371/journal.pbio.1000292</a></p>\n<p>Gl\xE4nzel,
        W., &amp; Wouters, P. (2013). The dos and don\u2019ts in individudal level
        bibliometrics. Retrieved from <a href=\"http://de.slideshare.net/paulwouters1/issi2013-wg-pw\">http://de.slideshare.net/paulwouters1/issi2013-wg-pw</a></p>\n<p>ImpactStory.
        (2013). Retrieved from <a href=\"http://impactstory.org/\">http://impactstory.org/</a></p>\n<p>Lin,
        J., &amp; Fenner, M. (2013). Altmetrics in Evolution: Defining and Redefining
        the Ontology of Article-Level Metrics. <em>Information Standards Quarterly</em>,
        <em>25</em>(2), 20. <a href=\"http://doi.org/10.3789/isqv25no2.2013.04\">doi:10.3789/isqv25no2.2013.04</a></p>\n<p>Narendra,
        D. P., Jin, S. M., Tanaka, A., Suen, D.-F., Gautier, C. A., Shen, J., \u2026
        Youle, R. J. (2010). PINK1 is selectively stabilized on impaired mitochondria
        to activate Parkin. <em>PLOS Biology</em>, <em>8</em>(1), e1000298. <a href=\"http://doi.org/10.1371/journal.pbio.1000298\">doi:10.1371/journal.pbio.1000298</a></p>\n<p>Nilsson,
        M. A., Churakov, G., Sommer, M., Tran, N. V., Zemann, A., Brosius, J., &amp;
        Schmitz, J. (2010). Tracking marsupial evolution using archaic genomic retroposon
        insertions. <em>PLOS Biology</em>, <em>8</em>(7), e1000436. <a href=\"http://doi.org/10.1371/journal.pbio.1000436\">doi:10.1371/journal.pbio.1000436</a></p>\n<p>NISO
        Alternative Assessment Metrics (Altmetrics) Project. (2013). Retrieved from
        <a href=\"http://www.niso.org/topics/tl/altmetrics/initiative\">http://www.niso.org/topics/tl/altmetrics/initiative</a></p>\n<p>Plum
        Analytics. (2013). Retrieved from <a href=\"http://www.plumanalytics.com/\">http://www.plumanalytics.com/</a></p>\n<p>Schekman,
        R., &amp; Patterson, M. (2013). Reforming research assessment. <em>eLife</em>,
        <em>2</em>, e00855. <a href=\"http://doi.org/10.7554/eLife.00855\">doi:10.7554/eLife.00855</a></p>\n<p>Tasmanian
        devil. (2013). Retrieved from <a href=\"http://en.wikipedia.org/wiki/Tasmanian%5Cdevil\">http://en.wikipedia.org/wiki/Tasmanian\\devil</a></p>\n<p>Video
        Tip of the Week: Turkeys and their genomes. (2012). Retrieved from <a href=\"http://blog.openhelix.eu/?p=14388\">http://blog.openhelix.eu/?p=14388</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Opening Science - the Book ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/opening-science-the-book/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw0p</id>\n
        \       <published>2013-12-05T16:06:00.000+00:00</published>\n\t\t<updated>2022-08-15T13:17:08.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/B00HD102QG.01._SCLZZZZZZZ_SX500_.jpg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/B00HD102QG.01._SCLZZZZZZZ_SX500_.jpg\"></p><p><a
        href=\"http://www.openingscience.org/get-the-book/\">Opening Science: The
        Evolving Guide on How the Internet is Changing Research, Collaboration and
        Scholarly Publishing</a> is a SpringerOpen book (using a <a href=\"http://book.openingscience.org/cases_recipes_howtos/creative_commons_licences\">Creative
        Commons Attribution-NonCommercial license</a>) that will be published in a
        few weeks. If you can\u2019t wait for the book to be published and/or you
        want to make comments or suggestions, go to the dynamic book online version
        at <a href=\"http://book.openingscience.org/\">http://book.openingscience.org</a>.
        I am an author or co-author of three chapters (<a href=\"http://book.openingscience.org/tools/reference_management\">Reference
        Management</a>, <a href=\"http://book.openingscience.org/vision/altmetrics\">Altmetrics
        and Other Novel Measures for Scientific Impact</a>, <a href=\"http://book.openingscience.org/cases_recipes_howtos/unique_identifiers_for_researchers\">Unique
        Identifiers for Researchers</a>) and have helped put the dynamic book together.
        The book is generated from markdown files hosted in a <a href=\"https://github.com/openingscience/book/\">public
        Github repo</a> using <a href=\"http://jekyllrb.com/\">Jekyll</a> and <a href=\"http://johnmacfarlane.net/pandoc/\">Pandoc</a>,
        and we use <a href=\"http://prose.io/\">Prose</a> to enable online editing
        of the content.</p><p>Using markdown, github, jekyll and pandoc is nothing
        new for blogs, but this is probably one of the first scholarly books using
        this workflow. The dynamic book is therefore still very much work in progress
        and feedback is greatly appreciated.</p><p>Another great example using a very
        similar workflow is the upcoming book <a href=\"http://adv-r.had.co.nz/\">Advanced
        R Programming</a> by Hadley Wickham, but he is of course using R and <a href=\"http://yihui.name/knitr/\">knitr</a>
        to create most of the markdown. In contrast to Hadley we stored the individual
        chapters as Jekyll posts rather than pages, as this better integrates with
        other Jekyll functionality, e.g. tags.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ The Grammar of Scholarly Communication ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/the-grammar-of-scholarly-communication/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw0q</id>\n        <published>2013-11-17T16:10:00.000+00:00</published>\n\t\t<updated>2022-08-18T16:39:38.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/1278021067_0bf5c8aa82_c.jpg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/1278021067_0bf5c8aa82_c.jpg\"></p><p>Authoring
        of scholarly articles is a recurring theme in this blog since it started in
        2008. Authoring is still in desperate need for improvement, and nobody has
        convincingly figured out how to solve this problem. Authoring involves several
        steps, and it helps to think about them separately:</p><ul><li><strong><strong>Writing</strong></strong>.
        Manuscript writing, including formatting, collaborative authoring</li><li><strong><strong>Submission</strong></strong>.
        Formatting a manuscript according to a publisher\u2019s author guidelines,
        and handing it over to a publishing platform</li><li><strong><strong>Revision</strong></strong>.
        Changes made to a manuscript in the peer review process, or after publication</li></ul><p>Although
        authoring typically involves text, similar issues arise for other research
        outputs, e.g research data. And these considerations are also relevant for
        other forms of publishing, whether it is self-publication on a blog or website,
        or publishing of preprints and white papers.</p><p>For me the main challenge
        in authoring is to go from human-readable unstructured content to highly structured
        machine-readable content. We could make authoring simpler by either forgoing
        any structure and just publishing in any format we want, or we can force authors
        to structure their manuscripts according to a very specific set of rules.
        The former doesn\u2019t seem to be an option, not only do we have a set of
        community standards that have evolved for a very long time (research articles
        for example have title, authors, results, references, etc.), but it also makes
        it hard to find and reuse scholarly research by others.</p><p>The latter option
        is also not really viable since most researchers haven\u2019t learned to produce
        their research outputs in machine-readable highly standardized formats. There
        are some exceptions, e.g. <a href=\"http://www.consort-statement.org/\">CONSORT</a>
        and other reporting standards in clinical medicine or the <a href=\"http://blogs.ch.cam.ac.uk/pmr/2012/01/23/brian-mcmahon-publishing-semantic-crystallography-every-science-data-publisher-should-watch-this-all-the-way-through/\">semantic
        publishing in Crystallography</a>, but for the most part research outputs
        are too diverse to easily find a format that works for all of them. The current
        trend is certainly towards machine-readable rather than towards human-readable,
        but there is still a significant gap - scholarly articles are transformed
        from documents in Microsoft Word (or sometimes LaTeX) format into XML (for
        most biomedical research that means <a href=\"http://jats.nlm.nih.gov/publishing/\">JATS</a>)
        using kludgy tools and lots of manual labor.</p><p>What solutions have been
        tried to overcome the limitations of our current authoring tools, and to make
        the process more enjoyable for authors and more productive for publishers?</p><ol><li>Do
        the conversion manually, still a common workflow.</li><li>Tools for publishers
        such as <a href=\"https://blog.front-matter.io/posts/extyles_interview_with_elizabeth_blake_and_bruce_rosenblum/\">eXtyles</a>,
        <a href=\"http://www.shabash.net/merops/\">Merops</a> - both commercial -
        or the evolving Open Source <a href=\"http://www.lib.umich.edu/mpach/modules\">mPach</a>
        that convert Microsoft Word documents into JATS XML and do a lot of automated
        checks along the way.</li><li>Tools for authors that directly generate JATS
        XML, either as a Microsoft Word plugin (the <a href=\"https://blog.front-matter.io/interview-with-pablo-fernicola\">Article
        Authoring Add-In</a>, not actively maintained) in the browser (e.g. <a href=\"https://blog.front-matter.io/posts/lemon8_xml_interview_with_mj_suhonos/\">Lemon8-XML</a>,
        not actively maintained), or directly in a publishing platform such as Wordpress
        (<a href=\"http://annotum.org/\">Annotum</a>).</li><li>Forget about XML and
        use HTML5 has the canonical file format, e.g. as <a href=\"https://blog.front-matter.io/posts/a-very-brief-history-of-scholarly-html/\">Scholarly
        HTML</a> or HTML5 specifications such as <a href=\"https://github.com/oreillymedia/HTMLBook/blob/master/specification.asciidoc\">HTMLBook</a>.
        Please read Molly Sharp\u2019s <a href=\"http://blogs.plos.org/tech/structured-documents-for-science-jats-xml-as-canonical-content-format/\">blog
        post</a> for background information about HTML as an alternative to XML.</li><li>Use
        file formats for authoring that are a better fit for the requirements of scholarly
        authors, in particular <a href=\"https://blog.front-matter.io/posts/a-call-for-scholarly-markdown/\">Scholarly
        Markdown</a>.</li><li>Build online editors for scientific content that hide
        the underlying file format, and guide users towards a structured format, e.g.
        by not allowing input that doesn\u2019t conform to specifications.</li></ol><p><strong><strong>Solution
        1.</strong></strong> isn\u2019t really an option, as it makes scholarly publishing
        unnecessarily slow and expensive. Typesetter Kaveh Bazergan has gone on record
        at the <a href=\"http://www.nature.com/spoton/2012/11/spoton-london-2012-a-global-conference/\">SpotOn
        London Conference 2012</a> by saying that the current process is insane and
        that he wants to be \u201Cput out of business\u201D.</p><p><strong><strong>Solution
        2.</strong></strong> is probably the most commonly used workflow used by larger
        publishers today, but is very much centered around a Microsoft Word to XML
        workflow. LaTeX is a popular authoring environment in some disciplines but
        still requires work to convert documents into web-friendly formats such as
        HTML and XML.</p><p><strong><strong>Solutions 3. to 5.</strong></strong> have
        never picked up any significant traction. Overall the progress in this area
        has been modest at best, and the mainstream of authoring today isn\u2019t
        too different from 20 years ago. Although I have gone on record for saying
        that <a href=\"https://blog.front-matter.io/posts/a-call-for-scholarly-markdown/\">Scholarly
        Markdown</a> has a lot of potential, the problem is much bigger than finding
        a single file format, and markdown will never be the solution for all authoring
        needs.</p><p><strong><strong>Solution 6.</strong></strong> is an area where
        a lot of exciting development is currently happening, examples include <a
        href=\"https://www.authorea.com/\">Authorea</a>, <a href=\"https://www.writelatex.com/\">WriteLateX</a>,
        <a href=\"https://www.sharelatex.com/\">ShareLaTeX</a>. Although the future
        of scholarly authoring will certainly include online authoring tools (making
        it much easier to collaborate, one of the authoring pain points), we run the
        risk of locking in users into one particular authoring environment.</p><h3
        id=\"going-forward\">Going Forward</h3><p>How can we move forward? I would
        suggest the following:</p><ol><li>Publishers should accept manuscripts in
        any reasonable file format, which means at least Microsoft Word, Open Office,
        LaTeX, Markdown, HTML and PDF, but possibly more. This will create a lot of
        extra work for publishers, but will open the doors for innovation, both in
        the academic and commercial sector. We will never see significant progress
        in scholarly authoring tools if the submission step requires manuscripts to
        be in a single file format (Microsoft Word) - in particular since this file
        format is a general purpose word processsing format and not something designed
        specifically for scholarly content. And we want researchers to spend their
        time doing research and writing up their research, not formatting documents.</li><li>To
        handle this avalanche of unstructured documents, publishers need conversion
        tools that can transform all these documents into a format that can feed into
        their editorial and publishing workflows. A limited number of these tools
        exist already, but this will require a significant development effort. Again,
        opening up submissions to a variety of file formats will not only foster innovation
        in authoring tools, but also in document conversion tools.</li><li>We should
        think beyond XML. Many of the workflows designed today center around conversions
        from one XML format to another, e.g. Microsoft Word to JATS or <a href=\"http://www.tei-c.org/index.xml\">TEI</a>
        (popular in the humanities), often using XLST transforms. Not only is XML
        difficult for humans to read or edit, but the web and many of the technologies
        built around it are moving away from XML towards HTML5 and JSON. XML is fine
        as an important output format for publishing, but maybe not the best format
        to hold everything together.</li><li>As we haven\u2019t come up with a canonical
        file format for scholarly documents by now, we should give up that idea. XML
        is great for publisher workflows, but is not something humans can easily edit
        or read. PDF is still the most widely read format by humans, but is not a
        good intermediary format. LaTeX is too complex for authors outside of mathematics,
        physics and related fields, and is not built with web standards in mind. Markdown
        is promising, but doesn\u2019t easily support highly structured content. And
        HTML5 and the related ePub are widely popular, but can be hard to edit without
        a visual editor, and currently don\u2019t include enough standard metadata
        to support scholarly content out of the box.</li><li>The focus should not
        be on canonical file formats for scholarly documents, but on tools that understand
        the manuscripts created by researchers and can transform them into something
        more structured. As we have learned from document conversion tools such as
        <a href=\"http://johnmacfarlane.net/pandoc/\">Pandoc</a>, we can\u2019t do
        this with a simple find and replace using regular expressions, but need a
        more structured approach. Pandoc is taking the input document (markdown, LaTeX
        or HTML) apart and is constructing an abstract syntax tree (<a href=\"http://en.wikipedia.org/wiki/Abstract_syntax_tree\">AST</a>)
        of the document, using parsing expression grammar (<a href=\"http://en.wikipedia.org/wiki/Parsing_expression_grammar\">PEG</a>),
        which includes a set of parsing rules. Parsing expression grammars are fairly
        new, <a href=\"http://bford.info/pub/lang/peg\">first described by Bryan Ford</a>
        about 10 years ago, but in my mind are a very good fit for the formal grammar
        of scientific documents. It should be fairly straightforward to generate a
        variety of output formats from the AST (Pandoc can convert into more than
        30 document formats), the hard part is the parsing of the input.</li></ol><p>All
        this requires a lot of work. Pandoc is a good model to start, but is written
        in Haskell, a functional programming language that not many people are familar
        with. For small changes Pandoc allows you to directly manipulate the AST (represented
        as JSON) using <a href=\"http://johnmacfarlane.net/pandoc/scripting.html\">filters</a>
        written in Haskell or Python. And <a href=\"https://github.com/jgm/pandoc\">custom
        writers</a> for other document formats can be written using <a href=\"http://www.lua.org/\">Lua</a>,
        another interesting programming language that not many people know about.
        Lua is a fast and relatively easy to learn scripting language that can be
        easily embedded into other languages, and for similar reasons is also used
        to <a href=\"http://en.wikipedia.org/wiki/Wikipedia:Lua\">extend the functionality
        of Wikipedia</a>. PEG parsers in other languages include <a href=\"http://treetop.rubyforge.org/\">Treetop</a>
        (Ruby), <a href=\"http://pegjs.majda.cz/\">PEG.js</a> (Javascript), and <a
        href=\"http://www.antlr.org/\">ANTLR</a>, a popular parser generator that
        also includes PEG features.</p><p>But I think the effort to build a solid
        open source conversion tool for scholarly documents is worth it, in particular
        for smaller publishers and publishing platforms who can\u2019t afford the
        commercial Microsoft Word to JATS conversion tools. We shouldn\u2019t take
        any shortcuts - e.g. by focussing on XML and XLST transforms - and we can
        improve this tool over time, e.g. by starting with a few input and output
        formats. This tool will be valuable beyond authoring, as it can also be very
        helpful to convert published scholarly content into other formats such as
        ePub, and in text mining, which in many ways tries to solve many of the same
        problems. The <a href=\"http://johnmacfarlane.net/pandoc/scripting.html\">Pandoc
        documentation</a> includes an example of extracting all URLs out of a document,
        and this can be modified to extract other content. In case you wonder whether
        I gave up on the idea of <a href=\"https://blog.front-matter.io/posts/a-call-for-scholarly-markdown/\">Scholarly
        Markdown</a> - not at all. To me this is a logical next step, opening up journal
        submission systems to Scholarly Markdown and other evolving file formats.
        And Pandoc, one of the most interesting tools in this space, is a markdown
        conversion tool at its heart. The next steps could be the following:</p><ul><li>write
        a custom writer in Lua that generates JATS output from Pandoc</li><li>explore
        how difficult it would be to add Microsoft Word .docx as Pandoc input format</li><li>develop
        Pandoc filters relevant for scholarly documents (e.g. <a href=\"https://blog.front-matter.io/posts/auto-generating-links-to-data-and-resources/\">auto-linking
        accession numbers of biomedical databases</a>)</li></ul><hr> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ What is holding us back? ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/what-is-holding-us-back/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw0r</id>\n
        \       <published>2013-11-11T16:14:00.000+00:00</published>\n\t\t<updated>2022-08-15T13:20:23.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/10739125344_fb8533423a_o.jpg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/10739125344_fb8533423a_o.jpg\"></p><p>Last
        Friday and Saturday the 6th <a href=\"http://www.nature.com/spoton/event/spoton-london2013/\">SpotOn
        London conference</a> tool place at the British Library. I had a great time
        with many interesting sessions and good conversations both in and between
        sessions. But I might be biased, since I helped organize the event, and in
        particular did help put the <a href=\"http://www.nature.com/spoton/?cat=11\">sessions
        for the Tools strand</a> together.</p><p>The following blog post summarizes
        some of my thoughts before, during and after the conference, and I want to
        focus on innovation in scholarly publishing, or rather: what is holding us
        back?</p><h2 id=\"reason-1\">Reason #1</h2><p>The <a href=\"http://www.nature.com/spoton/event/spoton-london-2013-whats-your-number-altmetrics-session/\">#solo13alt</a>
        session on Saturday looked at <em>the role of altmetrics in the evaluation
        of scientific research</em>. I was one of the panelists and had summarized
        my ideas prior to the session in a <a href=\"http://blogs.plos.org/tech/evaluating-impact-whats-your-number/\">blog
        post</a> written together with Jennifer Lin. It was an interesting session,
        although a bit too controversial for my taste. But it became obvious to me
        in this and a few other sessions that other obsession with quantitative assessment
        of science is increasingly dangerous. Other people have said this more eloquently:</p><ul><li>The
        mania for measurement - Stephen Curry in the <a href=\"http://www.nature.com/spoton/event/spoton-london-2013-whats-your-number-altmetrics-session/\">#solo13alt</a>
        session</li><li>Why research assessment is out of control - <a href=\"http://www.theguardian.com/education/2013/nov/04/peter-scott-research-excellence-framework\">Peter
        Scott</a></li><li>Universities are becoming metrics factories, driven by large
        corporates - <a href=\"http://blogs.ch.cam.ac.uk/pmr/2013/11/10/spoton2013-yet-another-wonderful-meeting/\">Peter
        Murray-Rust</a></li><li>The \u2018real\u2019 revolution in science will come
        when the scientific egosystem gets rid of the credit-imperative - <a href=\"https://twitter.com/Villavelius/status/399157271793762304\">Jan
        Velterop</a></li><li>Excellence by Nonsense: The Competition for Publications
        in Modern Science - <a href=\"http://book.openingscience.org/basics_background/excellence_by_nonsense/\">Mathias
        Binswanger</a></li></ul><p>My job title is <em>Technical Lead Article-Level
        Metrics</em> so it might sound surprising that I say this. But we have to
        differentiate of what we do now and in the next few years - which is mainly
        to get away from the Journal Impact Factor to more reasonable metrics that
        look at individual articles and include other metrics besides citations -
        to where we want to be in 10 or more years. And for the latter it is essential
        that journal articles and other research outputs are valued for the research
        they contain, rather than serving as a currency for <em>merit</em> that can
        be exchanged into grants and acadmic advancement. This is a very difficult
        problem to solve and I have no answers yet. Going back to how science was
        conducted until about 50 years ago - as a small elite club that worked based
        on closed personal networks - is definitely not the answer.</p><h2 id=\"reason-2\">Reason
        #2</h2><p>In <a href=\"http://www.nature.com/spoton/event/spoton-london-2013-keynote-1-boson-50-years-50003-scientists-understanding-our-universe-through-global-scientific-collaboration-and-open-access/\">his
        keynote</a> Salvatore Mele from CERN explained to us that Open Access in High
        Energy Phsics is 50 years old, and that the culture of sharing preprints preceeded
        the <a href=\"http://arxiv.org/\">ArXiv</a> e-prints service - scientists
        were mailing their manuscripts to each other at least 20 years before ArXiV
        launched in 1991. A similar culture doesn\u2019t exist in the life sciences
        and therefore the preprint services for biologists launched this year (e.g.
        <a href=\"https://peerj.com/preprints/\">PeerJ Preprints</a> and <a href=\"http://biorxiv.org/\">bioRxiv</a>)
        will have a hard time gaining traction.</p><p>Email is one of those services
        that every researcher uses, and we should think much more about how we can
        create innovative services around email rather than only considering new tools
        and services that are still used only by early adopters. AJ Cann had coordinated
        a workshop around email at SpotOn London that he called <a href=\"http://www.nature.com/spoton/event/spoton-london-2013-the-dark-art-of-dark-social-email-the-antisocial-medium-which-will-not-die-workshop/\">the
        dark art of dark social: email, the antisocial medium that will not die</a>.
        I am still puzzled why most researchers prefer to receive tables of content
        by email rather than as a RSS feed, but we shouldn\u2019t confuse what we
        get excited about as software developers and early adopters of online tools
        with what the mainstream scientist would be likely to use.</p><p>Another good
        example is <a href=\"http://royalsociety.org/policy/projects/science-public-enterprise/report/\">data
        sharing</a>, a topic that was discussed in at least three SpotOn sessions.
        Even though most attendees at SpotOn London agreed that sharing of research
        data is important, it is obvious that this is currently not common practice
        in most scientific disciplines. Funders have created data sharing policies
        (e.g. <a href=\"http://www.nsf.gov/bfa/dias/policy/dmp.jsp\">NSF</a> or the
        <a href=\"http://www.wellcome.ac.uk/About-us/Policy/Spotlight-issues/Data-sharing/\">Wellcome
        Trust</a>), as <a href=\"http://dx.doi.org/10.1371/journal.pone.0067111\">have
        publishers</a>, and many organizations are thinking about incentives for data
        sharing, including data journals such as <a href=\"http://www.nature.com/scientificdata/\">Scientific
        Data</a> that will launch in 2014 and was presented by Ruth Wilson in the
        <a href=\"http://www.nature.com/spoton/event/spoton-london-2013-how-can-we-encourage-data-sharing-discussion/\">motivations
        for data sharing</a> session. Even though incentives can help promote changes,
        I am pessimistic that something as central to the conduct of science as data
        sharing can be changed without more scientists being intrinsically motivated
        to do so. This is a much slower process that should start as early as possible
        during training, as pointed out by Kaitlin Thaney in the <a href=\"http://www.nature.com/spoton/event/spoton-london-2013-how-can-we-encourage-data-sharing-discussion/\">#solo13carrot</a>
        session.</p><h2 id=\"reason-3\">Reason #3</h2><p>In terms of the technology
        that is holding us back, I increasingly think that publisher manuscript submission
        systems may be the single most important place that is slowing down innovation.
        I participated in the first <a href=\"https://sites.google.com/site/beyondthepdf/\">Beyond
        the PDF</a> workshop in 2011, and I think now that <strong><strong>Beyond
        the MTS (or manuscript tracking system)</strong></strong> might have been
        a better motto than <strong><strong>Beyond the PDF</strong></strong>, as many
        of the problems we discussed relate to typical editorial workflows we use
        today. These systems need to implement many of the ideas discussed at SpotOn
        London and other places, from opening up peer review (<a href=\"http://www.nature.com/spoton/event/spoton-london-2013-how-should-peer-review-evolve/\">#solo13peer</a>)
        to making it easier to integrate research data into manuscripts (<a href=\"http://www.nature.com/spoton/event/spoton-london-2013-how-should-peer-review-evolve/\">#solo13carrot</a>)
        and to ideas of how the scientific record should like in the digital age (<a
        href=\"http://www.nature.com/spoton/event/spoton-london-2013-what-should-the-scientific-record-look-like-in-the-digital-age-discussion/\">#solo13digital</a>).
        In the latter panel we discussed both new authoring tools such as <a href=\"https://www.writelatex.com/\">WriteLaTeX</a>,
        and new ideas of what a research object should look like and how the different
        parts are linked to each other. A major theme here was reproducibility highlighted
        both by Carol Goble (also see her <a href=\"http://www.slideshare.net/carolegoble/ismb2013-keynotecleangoble\">ISMB/ECCB
        2013 Keynote</a>) and Peter Kraker (see also his <a href=\"http://science.okfn.org/2013/10/18/its-not-only-peer-reviewed-its-reproducible/\">Open
        Knowledge Foundation blog post</a>).</p><p>The problem with today\u2019s manuscript
        submission systems is that they have grown so big and complex that any change
        is slow and cumbersome, rather than iterative and part of an ongoing dialogue.
        I don\u2019t want to blame any single vendor of these systems, but rather
        suggest that we carefully re-evaluate the workflow from the manuscript written
        by one or more authors to the accepted manuscript. My personal interest is
        mainly in authoring tools, and I have recently written about and experimented
        with <a href=\"http://localhost:4000/tags.html#markdown-ref\">Markdown</a>.
        This process of re-evaluating manuscript tracking systems is not simply about
        technology, but is rather about how we approach this problem as author, publisher,
        tool vendor and as a community.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ What is the Value of Hack Days? ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/what-is-the-value-of-hack-days/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw0s</id>\n        <published>2013-11-04T16:18:00.000+00:00</published>\n\t\t<updated>2022-08-19T08:24:43.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/spoton12_hack-1.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/spoton12_hack-1.jpeg\"></p><p>This
        Friday and Saturday the <a href=\"http://www.nature.com/spoton/event/spoton-london2013/\">SpotOn
        London Conference</a> will take place at the British Library in London. I
        am very excited, as I have come to this conference since the <a href=\"https://twitter.com/McDawg/status/397068628102610945\">first
        one in 2008</a>, and have helped organize the event since 2009. The conference
        is about science communication in the broadest sense, and has three strands
        that focus on <em>science communication, science policy and tools</em>. Equally
        important as the sessions are of course the many highly engaging informal
        discussions of the 250 participants that take place between and after the
        sessions.</p><p>SpotOn London sessions are also more conversations than presentations,
        as they usually have 2-4 panelists with ample time for discussion with the
        audience. I will take part in two panels:</p><ul><li><a href=\"http://www.nature.com/spoton/event/spoton-london-2013-what-the-hack-part-one-hackdays-session/\">What
        the hack?!</a> (Friday 10:30 AM, hashtag <a href=\"https://twitter.com/search?q=%23solo13hack\">#solo13hack</a>),
        with Peter Murray-Rust, Ross Mounce and Helen Jackson</li><li><a href=\"http://www.nature.com/spoton/event/spoton-london-2013-whats-your-number-altmetrics-session/\">What\u2019s
        your number? - Altmetrics session</a> (Saturday 10:30 AM, hashtag <a href=\"https://twitter.com/search?q=%23solo13alt\">#solo13alt</a>),
        with Marie Boran, David Colquhoun, Jean Liu and Stephen Curry</li></ul><p>I
        will summarize my thoughts regarding the altmetrics session in another post,
        but want to talk about the first session in more detail. According to the
        <a href=\"http://en.wikipedia.org/wiki/Hackathon\">English Wikipedia</a></p><blockquote>A
        <strong><strong>hackathon</strong></strong> (also known as a <strong><strong>hack
        day</strong></strong>, <strong><strong>hackfest</strong></strong> or <strong><strong>codefest</strong></strong>)
        is an event in which computer programmers and others involved in software
        development, including graphic designers, interface designers and project
        managers, collaborate intensively on software projects.</blockquote><figure
        class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/Wikimedia_hackathon_020_-_Berlin_2012_03.jpg\"
        class=\"kg-image\" alt=\"Wikimedia Hackathon Berlin June 2012. Largest hackathon
        I have attended so far with 100 people. Photo by Gulliaume Paumier, CC-BY
        license.\" loading=\"lazy\" width=\"512\" height=\"769\"><figcaption><strong
        style=\"box-sizing: border-box; font-weight: bold;\">Wikimedia Hackathon Berlin
        June 2012</strong>. Largest hackathon I have attended so far with 100 people.
        Photo by Gulliaume Paumier, CC-BY license.</figcaption></figure><p>It is too
        bad that we will have no hackathon at year\u2019s SpotOn London for logistical
        reasons, but the session is a great opportunity to reflect on the value of
        science hackdays. It is clear that hackdays for scientific software have become
        popular, with almost too many opportunities to participate.</p><h3 id=\"what-i-like\">What
        I like</h3><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/group_foto.jpg\"
        class=\"kg-image\" alt=\"#hack4ac. Our team working on PLOS Author Contributions.\"
        loading=\"lazy\" width=\"800\" height=\"600\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/group_foto.jpg
        600w, https://blog.front-matter.io/content/images/2022/08/group_foto.jpg 800w\"
        sizes=\"(min-width: 720px) 720px\"><figcaption><strong style=\"box-sizing:
        border-box; font-weight: bold;\">#hack4ac</strong>. Our team working on <a
        href=\"http://hack4ac.com/plos-author-contributions/\" style=\"box-sizing:
        border-box; background: transparent; color: rgb(52, 152, 219); text-decoration:
        none;\">PLOS Author Contributions</a>.</figcaption></figure><ul><li>Do stuff.
        And have plenty of time to do stuff instead sessions in short intervals</li><li>Hackdays
        let you do great team work</li><li>Learn about other interesting projects
        and meet people doing cool work</li></ul><figure class=\"kg-card kg-image-card
        kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/alm12_anti_gaming.png\"
        class=\"kg-image\" alt=\"ALM 2012 hackathon. Brainstorming board from anti-gaming
        group.\" loading=\"lazy\" width=\"720\" height=\"341\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/alm12_anti_gaming.png
        600w, https://blog.front-matter.io/content/images/2022/08/alm12_anti_gaming.png
        720w\" sizes=\"(min-width: 720px) 720px\"><figcaption><a href=\"http://article-level-metrics.plos.org/alm-workshop-2012/hackathon/\"
        style=\"box-sizing: border-box; background: transparent; color: rgb(52, 152,
        219); text-decoration: none;\"><strong style=\"box-sizing: border-box; font-weight:
        bold;\">ALM 2012 hackathon</strong></a>. Brainstorming board from anti-gaming
        group.</figcaption></figure><h3 id=\"what-i-don-t-like\">What I don\u2019t
        like</h3><ul><li>Hackdays are very much targeted at intermediate to advanced
        software developers, and it is sometimes not easy for beginners to participate</li><li>Too
        much time spent setting up stuff</li><li>Some of the work done at hackdays
        can be better done in virtual collaborations over weeks or months</li><li>Not
        many projects make it beyond the hackday and actually turn into a useable
        product. One example where this is not true are the visualizations started
        at the ALM 2012 hackathon that were implemented by OJS in 2013 (<a href=\"http://dx.doi.org/10.3402/gha.v6i0.19283\">see
        article for more</a>), and of course <a href=\"http://impactstory.org/\">ImpactStory</a>
        that started at a hackathon at the <a href=\"http://beyond-impact.org/\">Beyond
        Impact</a> conference in May 2011.</li></ul><figure class=\"kg-card kg-image-card
        kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/alm_d3.png\"
        class=\"kg-image\" alt=\"ALM 2012 hackathon. Sparkline visualization implemented
        by OJS based on work at the workshop.\" loading=\"lazy\" width=\"542\" height=\"368\"><figcaption><a
        href=\"http://article-level-metrics.plos.org/alm-workshop-2012/hackathon/\"
        style=\"box-sizing: border-box; background: transparent; color: rgb(52, 152,
        219); text-decoration: none;\"><strong style=\"box-sizing: border-box; font-weight:
        bold;\">ALM 2012 hackathon</strong></a>. Sparkline visualization implemented
        by OJS based on work at the workshop.</figcaption></figure><h3 id=\"some-of-the-challenges\">Some
        of the challenges</h3><ul><li>Coming up with projects where progress can be
        made in a day or two</li><li>Technology: WiFi access, access to servers for
        code deployment, collaboration tools, etc.</li><li>Come up with a good unifying
        theme, so that the various projects during the hackday relate to each other.
        The theme at <a href=\"http://hack4ac.com/\">#hack4ac</a> was to demonstrate
        the value of the CC-BY license within academia.</li></ul><h3 id=\"some-ideas-to-improve-science-hackdays\">Some
        ideas to improve science hackdays</h3><ul><li>Go beyond software development.
        We <a href=\"http://blogs.plos.org/tech/alm-data-challenge-metrics-for-a-standard-set-of-dois/\">recently
        tried a data challenge using Altmetrics data</a>, and at a <a href=\"https://blog.front-matter.io/posts/auto-generating-links-to-data-and-resources/\">hackathon
        between IGSN, DataCite, PANGAEA and ORCID in July</a> we focussed on a high-level
        discussion of technical issues. There is a continuum towards the <a href=\"http://en.wikipedia.org/wiki/BarCamp\">BarCamp</a>
        format, although I don\u2019t like to drift too much from <em>doing</em> to
        <em>talking</em>. A good example of a workshop open to everyone and not just
        software developers is the SpotOn London workshop this Saturday on <a href=\"http://www.nature.com/spoton/event/spoton-london-2013-wikipedia-editing-workshop/\">Wikipedia
        Editing</a> run by Brian Kelly and Toni Sant.</li><li>Meet before and after
        the hackathon. This can be done online, but it helps to focus on what can
        be achieved in the limited time available for a hackathon, and to follow up
        on projects that have just been started. But a hackathon is also a great opportunity
        to meet new people and new ideas, so meeting afterwards is more important
        than before.</li><li>Involve remote people. A lot of the fun of hackdays comes
        from sitting around a table and doing something together. But sometimes this
        is not possible for everyone, so think about remote participation where it
        makes sense.</li></ul> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Commenting on scientific papers ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/commenting-on-scientific-papers/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw0t</id>\n        <published>2013-10-25T16:21:00.000+00:00</published>\n\t\t<updated>2023-09-02T08:27:59.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2023/09/comments.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2023/09/comments.png\"></p><p>I
        think it is fair to say that commenting on scientific papers is broken. And
        with commenting I mean online comments that are publicly available, not informal
        discussions in journal clubs or at meetings. This definition would include
        discussions of papers on social media such as Twitter or Facebook. Why do
        I think that commenting is broken?</p><ul><li>the number of papers with online
        comments is low. <a href=\"https://doi.org/10.1371/journal.pbio.1001687\">For
        PLOS Biology</a> we have comments on the journal platform for 11% of articles,
        tweets for 14% of articles and Facebook activity for 22% of articles. The
        numbers for Twitter and Facebook are much higher for more recently published
        articles, but are nowhere close to every article having at least one comment.</li><li>even
        though there is a fair amount of social media activity around articles, the
        quality of the discussion is varied. Twitter for example seems to work mostly
        as an alerting service for interesting articles with little more than the
        title of the article in the tweet text and not much discussion.</li><li>when
        comments are made, they are really hard to find coming from the article. Unless
        they are made on the journal platform, or the publisher tracks article-level
        metrics and links out to these comments.</li></ul><p>What can be done to address
        these issues, i.e. increase the number of comments, increase the depth of
        the discussion, and make it easier to link comments to articles? Some of the
        thoughts that I and others have had include the following:</p><ul><li>lower
        the technical barriers for commenting by providing a common and familiar commenting
        platform with an attractive user interface. Many blogs (including this one)
        and <a href=\"http://elife.elifesciences.org/\">some publishers</a> use Disqus,
        which is arguably the most popular third-party commenting platform.</li><li>develop
        new features that make commenting more attractive, including comments linked
        to specific sections of the text and notes that can be public, semi-public
        or private. See for example <a href=\"https://medium.com/about/5972c72b18f2\">what
        Medium is doing</a>, check out <a href=\"http://hypothes.is/\">Hypothes.is</a>
        and <a href=\"http://blog.peerj.com/post/62886292466/peerj-questions-a-new-way-to-never-publish-forget\">PeerJ
        Questions</a>, or study what services such as <a href=\"http://stackoverflow.com/\">Stackoverflow</a>
        are doing.</li><li>Link comments made in different places about the same object
        together, e.g. through Article-Level Metrics services.</li><li>create incentives
        for scientists to comment, e.g. through <a href=\"http://openbadges.org/\">Mozilla
        Open Badges</a> or by making them part of a community.</li></ul><p>On Tuesday
        the US National Library of Medicine launched <a href=\"http://ncbiinsights.ncbi.nlm.nih.gov/2013/10/22/pubmed-commons-a-new-forum-for-scientific-discourse/\">PubMed
        Commons</a> as a <em>New Forum for Scientific Discourse</em>:</p><blockquote>We
        hope that PubMed Commons will leverage the social power of the internet to
        encourage constructive criticism and high quality discussions of scientific
        issues that will both enhance understanding and provide new avenues of collaboration
        within the community.</blockquote><p>PubMed Commons is still a pilot project
        and in order to read or write comments you have to be a PubMed Commons participant
        and be signed in with your My NCBI account. PubMed Commons has some important
        features:</p><ul><li>PubMed is probably the place where most life sciences
        researchers search for literature. Having comments and discussion there makes
        perfect sense, and is probably a better place than a publisher platform that
        only targets particular journals. PubMed also has a reputation that is very
        different from social media tools that are popular, but not really familiar
        to most scientists.</li><li>Access to PubMed Commons is restricted to researchers,
        and this is one strategy to have the comments focus on scientific discourse.
        It has to be seen whether the process of registering for PubMed Commons (which
        currently is a bit more involved than most commenting systems) is a barrier
        for scientists to take part in the discussion, or whether it generates an
        audience that makes it more likely that scientists contribute.</li><li>For
        people signing in with their My NCBI account (I don\u2019t know the percentage
        of PubMed users that do that on a regular basis), commenting is really easy
        and the interface is straightforward. The comment editor uses markdown, which
        makes it easy to format comments and to include links.</li></ul><p><em>10/26/13:
        added link to the recently launched <a href=\"http://blog.peerj.com/post/62886292466/peerj-questions-a-new-way-to-never-publish-forget\">PeerJ
        Questions</a> which uses a question and answer format (thanks to Jason Hoyt
        for reminding me).</em></p><h3 id=\"references\">References</h3><p>Fenner,
        M. (2013). What Can Article-Level Metrics Do for You? <em>PLoS Biology</em>,
        <em>11</em>(10), e1001687. <a href=\"https://doi.org/10.1371/journal.pbio.1001687\">https://doi.org/10.1371/journal.pbio.1001687</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ What Can Article-Level Metrics Do for You?
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/what-can-article-level-metrics-do-for-you-2/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw0v</id>\n        <published>2013-10-23T16:23:00.000+00:00</published>\n\t\t<updated>2022-08-19T08:15:10.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/2013-12-11_figure_5-3.svg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/2013-12-11_figure_5-3.svg\"></p><p>Yesterday
        PLOS Biology published an essay by me: <a href=\"http://dx.doi.org/10.1371/journal.pbio.1001687\">What
        Can Article Level Metrics Do for You?</a> (Fenner, 2013). I had help from
        many others in writing the essay, in particular PLOS Biology editor Emma Ganley.
        I hope that the essay can help researchers get introduced to article-level
        metrics, and I am honored that the essay is part of the <a href=\"http://dx.doi.org/10.1371/journal.pbio.1001688\">PLOS
        Biology 10th anniversary collection</a>.</p><p>The essay is an Open Access
        article published under a CC-BY license, so not only can everyone read it,
        but the text and figures can be freely reused, as long as proper attribution
        is provided, e.g. Fig. 5:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/2013-12-11_figure_5-2.svg\"
        class=\"kg-image\" alt=\"PLOS Biology articles: sites of recommendation and
        discussion. Number of PLOS Biology research articles published until May 20,
        2013 that have been recommended by F1000Prime (red) and/or mentioned in Wikipedia
        (blue). Taken from doi:10.1371/journal.pbio.1001687.g005\" loading=\"lazy\"
        width=\"480\" height=\"480\"><figcaption><strong style=\"box-sizing: border-box;
        font-weight: bold;\">PLOS Biology articles: sites of recommendation and discussion</strong>.
        Number of PLOS Biology research articles published until May 20, 2013 that
        have been recommended by F1000Prime (red) and/or mentioned in Wikipedia (blue).
        Taken from <a href=\"http://dx.doi.org/10.1371/journal.pbio.1001687.g005\"
        style=\"box-sizing: border-box; background: transparent; color: rgb(52, 152,
        219); text-decoration: none;\">doi:10.1371/journal.pbio.1001687.g005</a></figcaption></figure><p>Although
        this is an essay and not a research article, I\u2019ve added the data and
        R scripts used to generate the figures (1, 3-5) as <a href=\"http://dx.doi.org/10.1371/journal.pbio.1001687.s001\">supporting
        information</a>. As I <a href=\"https://blog.front-matter.io/posts/the-complete-article/\">have
        said earlier</a>, I think it is important that an article contains more than
        the text. With the open source software <a href=\"http://www.r-project.org/\">R</a>
        or <a href=\"http://www.rstudio.com/\">RStudio</a>, everyone can recreate
        the figures, and can look at the data underlying the figures in the essay.
        One can for example look into the data behind Fig. 5 to better understand
        how articles with F1000Prime recommendations <strong><strong>and</strong></strong>
        Wikipedia mentions differ from those <strong><strong>only</strong></strong>
        recommended in F1000Prime. Feel free to ask for help getting started in the
        comments.</p><p>Incidentally this is also my first PLOS article (my wife is
        way ahead of me with 5 research articles), so that I can finally look at PLOS
        article-level metrics as an author - after being the technical lead for this
        project since May 2012.</p><h2 id=\"references\">References</h2><p>Fenner,
        M. (2013). What can article-level metrics do for you? <em>PLoS Biol</em>,
        <em>11</em>(10), e1001687. <a href=\"http://doi.org/10.1371/journal.pbio.1001687\">doi:10.1371/journal.pbio.1001687</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ The Complete Article ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/the-complete-article/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw0w</id>\n
        \       <published>2013-10-20T16:26:00.000+00:00</published>\n\t\t<updated>2022-08-15T13:59:49.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/complete_paper.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/complete_paper.png\"></p><p>Open
        access to research data is becoming increasingly important, as manifested
        by memos or press releases from the <a href=\"http://www.wellcome.ac.uk/About-us/Policy/Policy-and-position-statements/WTX035043.htm\">Wellcome
        Trust</a>, the <a href=\"http://europa.eu/rapid/press-release_IP-12-790_en.htm\">European
        Commission</a>, and the <a href=\"http://www.whitehouse.gov/blog/2013/02/22/expanding-public-access-results-federally-funded-research\">the
        Office of Science and Technology Policy</a> (OSTP) from the White House.</p><p>Open
        access to research data is important as this makes it easier for other researchers
        to reproduce the research, and to build upon the research by others by re-analysis
        of data or combination with other research data. In other words, <a href=\"http://royalsociety.org/policy/projects/science-public-enterprise/report/\">Science
        as an open enterprise</a>.</p><p>The major challenge to open access to research
        data is that data sharing is not a widespread practice. Several strategies
        have been developed to create incentives for researchers to share research
        data, including services that make it easier to share research data (e.g.
        <a href=\"http://figshare.com/\">figshare</a>, <a href=\"http://dataup.cdlib.org/\">DataUp</a>
        and <a href=\"http://www.zenodo.org/\">Zenodo</a>), <a href=\"http://www.knowledge-exchange.info/Default.aspx?ID=586\">metrics
        for research data</a>, and data journals such as <a href=\"http://www.earth-system-science-data.net/\">Earth
        System Science Data</a>, <a href=\"http://www.gigasciencejournal.com/\">GigaScience</a>
        or the <a href=\"http://openarchaeologydata.metajnl.com/\">Journal of open
        archaeology data</a>. Some of the sticks that have been tried in addition
        to the carrots above include data management plan requirements such as those
        <a href=\"http://www.nsf.gov/bfa/dias/policy/dmp.jsp\">set forth by the National
        Science Foundation (NSF)</a> in 2011.</p><p>I would argue that all these carrots
        and sticks will eventually fall short, unless we redefine what the journal
        article (and similarly monograph) in the digital age should be about. Research
        data should become a required part of any research article, rather than an
        optional afterthought, or taking on a life on their own in a separate data
        journal.</p><p>The <em>complete article</em> - as I would like to call this
        journal article made fit for the digital age - should not only include the
        research data used to create figures and tables and reportes as results. Equally
        important are descriptions of reagents, workflows and software tools that
        go into much more detail compared to what is common practice today.</p><p>The
        <em>complete article</em> does not have to come as one big file. More likely
        the research data will be hosted at one or more data centers elsewhere. Authorship
        will turn into contributorship and will include all roles required to put
        the <em>complete article</em> together, including for example data collection
        and -analysis, and writing software needed to analyze the data. The <em>complete
        article</em> can be shorter or longer than the typical article today, important
        is not article length, but the combination of text, data, and description
        of reagents and analysis tools.</p><p>The <em>complete article</em> should
        also include (or link to) the text of the peer reviews and previous article
        versions, including preprints. This makes it much easier to understand the
        article (and the data) in context. The <em>complete article</em> should also
        link to article-level metrics post-publication for similar reasons.</p><p>This
        idea of a <em>complete article</em> is not too far away from the best practices
        used today, but it is important to make it the default for scientific publication.
        Too much of what we publish today is still centered around the concept of
        what can be printed on paper, and telling exciting stories that have impact
        counts more than telling complete stories that can be reproduced.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Challenges in automated DOI resolution ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/challenges-in-automated-doi-resolution/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw0x</id>\n        <published>2013-10-13T16:29:00.000+00:00</published>\n\t\t<updated>2022-07-31T11:07:09.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Yesterday we created a set
        of roughly 10,000 DOIs for journal articles published in 2011 or 2012. We
        used these DOIs as a reference set in a <a href=\"http://almdatachallenge.eventbrite.com/\">data
        hackathon</a> around article-level metrics/altmetrics - material for another
        blog post.</p><p>The random DOis were generated using the <a href=\"http://random.labs.crossref.org/\">CrossRef
        RanDOIm service</a>, with article titles fetched from the <a href=\"http://labs.crossref.org/openurl/\">CrossRef
        OpenURL API</a>. We didn\u2019t have time to properly parse the publication
        date and only used the publication year. We used the <code>crossref_r</code>
        and <code>crossref</code> functions from the rOpenSci <a href=\"http://ropensci.github.io/rplos/\">rplos
        package</a> (and some extra help from Scott Chamberlain) to achieve this,
        the datasets were deposited to figshare and can be found <a href=\"https://doi.org/10.6084/m9.figshare.821209\">here</a>
        (2011) and <a href=\"https://doi.org/10.6084/m9.figshare.821213\">here</a>
        (2012).</p><p>The basic idea behind DOI names is summarized well in the <a
        href=\"http://en.wikipedia.org/wiki/Digital_object_identifier\">Wikipedia
        entry</a>:</p><blockquote>A digital object identifier (DOI) is a character
        string (a \u201Cdigital identifier\u201D) used to uniquely identify an object
        such as an electronic document. Metadata about the object is stored in association
        with the DOI name and this metadata may include a location, such as a URL,
        where the object can be found. The DOI for a document is permanent, whereas
        its location and other metadata may change. Referring to an online document
        by its DOI provides more stable linking than simply referring to it by its
        URL, because if its URL changes, the publisher need only update the metadata
        for the DOI to link to the new URL.</blockquote><p>DOIs for journal articles
        should provide users with a URL specific for that journal article. This URL
        could point to a digital copy of the journal article in HTML or PDF format,
        or could point to a landing page (with an abstract or other basic metadata)
        for journal articles that require a subscription. This should work not only
        for humans using a web browser, but also for automated services using command
        line tools such as <a href=\"http://curl.haxx.se/\">curl</a> as scientific
        infrastructure depends heavily on automation and computers talking to each
        other. In our use case we want to find content linking to a specific article,
        and as some services (e.g. social media) will use the URL and not DOI of an
        article, we need to find out that URL.</p><p>Unfortunately it was difficult
        to find a URL for many DOIs in our reference set using automated tools. All
        these DOIs resolve to URLs for human users using a web browser, but for automated
        tools there are a number of challenges:</p><h3 id=\"requiring-a-cookie\">Requiring
        a cookie</h3><p>Some publishers require a cookie, and that can cause problems
        for automated tools. We can use the popular command line tool <code>curl</code>
        with the options <code>-L</code> to follow redirects and <code>-I</code> to
        only send the header (as we care about the location and not the content of
        the page).</p><pre><code>curl -I -L \"http://dx.doi.org/10.1080/13658816.2010.531020\"</code></pre><p>This
        command will lead us not to a page specific for that article, but to a \u201CCookie
        absent\u201D page. You can work around this by having curl accept cookies:</p><pre><code>curl
        -I -L --cookie \"tmp\" \"http://dx.doi.org/10.1080/13658816.2010.531020\"</code></pre><p>Unfortunately
        not all tools do this. The way Facebook tracks likes, shares, comments, etc.
        is a prominent example.</p><h3 id=\"too-many-redirects\">Too many redirects</h3><p>Some
        DOIs never resolve using a HEAD request, and curl stops after 50 redirects:</p><pre><code>curl
        -I -L \"http://dx.doi.org/10.1097/SLA.0b013e318235e525\"</code></pre><p>This
        error may relate to the \u201Crequiring a cookie\u201D error above.</p><h3
        id=\"method-not-allowed\">Method not allowed</h3><p>Some DOis HEAD requests
        result in a \u201C405 Method Not Allowed\u201D error. The reason is that the
        journal platform doesn\u2019t accept the HEAD request, but wants a GET instead.</p><pre><code>curl
        -I -L \"http://dx.doi.org/10.1002/sam.10120\"</code></pre><p>The <a href=\"http://www.w3.org/Protocols/rfc2616/rfc2616-sec9.html\">HTTP
        1.1 protocol</a> says about HEAD:</p><blockquote>The HEAD method is identical
        to GET except that the server MUST NOT return a message-body in the response.
        \u2026 This method is often used for testing hypertext links for validity,
        accessibility, and recent modification.</blockquote><p>We can work around
        this error by using a GET request, which unfortunately creates extra overhead
        and is not the recommended way to obtain this kind of information.</p><h3
        id=\"empty-reply-from-server\">Empty reply from server</h3><p>Some DOIs never
        resolve using a HEAD because curl reports \u201CEmpty reply from server\u201D
        and we don\u2019t get a HTTP 200 status code.</p><pre><code>curl -I -L \"http://dx.doi.org/10.1016/j.cca.2011.04.012\"</code></pre><p>You
        can again work around this by using the location information before the last
        redirect, but maybe resolving a DOI should not result in curl routinely throwing
        an error. It looks as if this error is related to \u201Cmethod not allowed\u201D,
        as a GET request resolves to a landing page.</p><p>This problem is not specific
        to the <code>curl</code> tool, we get exactly the same error with <code>wget</code>:</p><pre><code>wget
        -S --spider \"http://dx.doi.org/10.1016/j.cca.2011.04.012\"</code></pre><h3
        id=\"timeout-errors\">Timeout errors</h3><p>Some DOI resolutions resulted
        in timeout errors, but this was temporary and much less frequent than the
        errors above.</p><h3 id=\"resource-not-found\">Resource not found</h3><p>We
        didn\u2019t specifically look into this error, which is a well-known problem
        with URLs. The DOI names we used were from 2011 and 2012, and it is known
        that <a href=\"http://en.wikipedia.org/wiki/Link_rot\">link rot</a> is more
        common the older the resource is.</p><h3 id=\"content-negotiation\">Content
        negotiation</h3><p>As Karl Ward has pointed out in the comments there are
        other ways to get to the URL from the DOI name, e.g. using content negotiation:</p><pre><code>curl
        -LH \"Accept: application/vnd.crossref.unixref+xml\" \"http://dx.doi.org/10.1016/j.cca.2011.04.012\"</code></pre><p>The
        URL is stored in the <code>doi_data/resource</code> attribute. The URL stored
        there is unfortunately not always the final landing page for the article,
        e.g. for the DOI name used in the example above.</p><h3 id=\"conclusions\">Conclusions</h3><p>We
        created a reference set of 10,000 DOIs to collect metrics around them. The
        first conclusion from this exercise is that getting the URL for these articles
        is a challenge in many cases. This does not seem to relate to a permission
        problem for subscription content, but rather how the HTTP HEAD request is
        handled. Content negotiation is one alternative, but sometimes leads to different
        URLs for the landing page than where the user would get via the browser. We
        therefore have to rewrite our code to use GET requests and to better handle
        the scenarios above.</p><p><em>Update 10/13/13: Updated the title and the
        text to make it clear that I am not talking about DOIs that don\u2019t resolve
        for human users, but rather about the problems automating this process using
        command-line tools.</em></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Altmetrics coming of age? Not for Wikipedia
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/altmetrics-coming-of-age-not-for-wikipedia/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw0y</id>\n        <published>2013-08-10T16:31:00.000+00:00</published>\n\t\t<updated>2022-08-15T14:01:29.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/wikipedia_redirect.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/wikipedia_redirect.png\"></p><p>Ten
        days ago Information Standards Quarterly (ISQ) published a <a href=\"http://www.niso.org/publications/isq/2013/v25no2/\">special
        issue on altmetrics</a>. I was the guest editor for the five altmetrics articles,
        and in the <a href=\"https://doi.org/10.3789/isqv25no2.2013.01\">editorial</a>
        that I titled <strong><strong>Altmetrics have come of age</strong></strong>
        I argued that</p><blockquote>We no longer need to talk about whether it is
        possible to reliably collect altmetrics, or whether this is valuable information
        that can complement citations and usage statistics.</blockquote><p>In June
        we have seen that the National Information Standards Organization (<a href=\"http://www.niso.org/home/\">NISO</a>)
        was <a href=\"https://doi.org/10.3789/isqv25no2.2013.07\">awarded a grant</a>
        by the <a href=\"http://www.sloan.org/\">Sloan Foundation</a> to develop standards
        and recommended best practices for altmetrics.</p><p>Unfortunately Wikipedia
        - which is of course an important source of altmetrics information and was
        also mentioned in the editorial - doesn\u2019t think so. When you try to go
        to the <a href=\"https://en.wikipedia.org/w/index.php?title=Altmetrics&amp;redirect=no\">Altmetrics</a>
        page on the English Wikipedia, you get this:</p><figure class=\"kg-card kg-image-card
        kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/wikipedia_redirect-1.png\"
        class=\"kg-image\" alt=\"Wikipedia doesn\u2019t think Altmetrics need their
        own page\" loading=\"lazy\" width=\"700\" height=\"349\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/wikipedia_redirect-1.png
        600w, https://blog.front-matter.io/content/images/2022/08/wikipedia_redirect-1.png
        700w\"><figcaption>Wikipedia doesn\u2019t think Altmetrics need their own
        page</figcaption></figure><p>In other words, you are redirected to a short
        section on the <a href=\"https://en.wikipedia.org/wiki/Impact_factor#Article_level_metrics_and_altmetrics\">Impact
        Factor</a> page. I would go and start an altmetrics (and article-level metrics)
        page, but with my professional involvement in altmetrics it is difficult to
        write from a <a href=\"http://en.wikipedia.org/wiki/Wikipedia:Neutral_point_of_view\">neutral
        point of view</a>, one of the core Wikipedia policies.</p><p><em>Update August
        13, 2013: We now have a nice <a href=\"http://en.wikipedia.org/wiki/Altmetrics\">altmetrics</a>
        Wikipedia page thanks to the hard work of <a href=\"http://en.wikipedia.org/wiki/User:Egonw\">Egon
        Willighagen</a> and others.</em></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ CSL is more than citation styles ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/csl-is-more-than-citation-styles/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw0z</id>\n        <published>2013-08-08T16:33:00.000+00:00</published>\n\t\t<updated>2022-08-19T09:02:37.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>According to the <a href=\"http://citationstyles.org/\">description</a>
        on the Citation Style Language (CSL) website, CSL <em>is an open XML-based
        language to describe the formatting of citations and bibliographies</em>.
        We use reference managers such as <strong>Zotero</strong>, <strong><strong>Mendeley</strong></strong>,
        or <strong><strong>Papers</strong></strong> to format our references in manuscripts
        we submit for publication, and underneath a CSL processor such as <a href=\"https://bitbucket.org/fbennett/citeproc-js/wiki/Home\">Citeproc-js</a>
        - together with a CSL file for a particular citation style - is doing the
        work:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2021/02/csl.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"394\" height=\"577\"><figcaption>Citation
        processing during manuscript writing</figcaption></figure><p>When the journal
        article is accepted the publisher takes the text with the formatted text citation
        and turns it into XML, a process that is error-prone and takes time:</p><figure
        class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2021/02/csl2.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"454\" height=\"414\"><figcaption>Citation
        processing by the publisher</figcaption></figure><p>It is not hard to see
        that something is very wrong here:</p><ul><li>Authors are required to use
        a specific citation style (there are probably about 1,000 different citation
        styles and many more dependent styles) even though the publisher doesn\u2019t
        directly use the formatted text. The publisher eLife <a href=\"http://www.elifesciences.org/elife-references/\">accepts
        references in any format</a>.</li><li>Turning structured information into
        plain text and back into structured XML is always a bad idea. <a href=\"http://twitter.com/kaveh1000\">Kaveh
        Bazargan</a> is a typesetter who has gone on record for saying that we should
        stop this nonsense and put him out of business.</li></ul><p>It is also obvious
        how the ideal workflow should look like:</p><figure class=\"kg-card kg-image-card
        kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2021/02/csl3.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"768\" height=\"908\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2021/02/csl3.png
        600w, https://blog.front-matter.io/content/images/2021/02/csl3.png 768w\"
        sizes=\"(min-width: 720px) 720px\"><figcaption>Ideal workflow of citation
        processing</figcaption></figure><p>We go from structured content to structured
        content, and never use citations formatted as text as intermediary steps in
        the workflow.</p><p>What is surprising is that this is an ideal workflow and
        not something that publishers actually do. Most journal author instructions
        don\u2019t even mention CSL styles (I work for PLOS and they are no exception).
        There are some issues to be solved, but they are all minor:</p><ul><li>The
        Citeproc JSON citation format isn\u2019t really an official standard, but
        rather something invented for the most popular CSL processor, Citeproc-js.</li><li>People
        like to fight over standards, and there are always people you prefer bibtex,
        RIS, MODS or BibJSON over Citeproc JSON, or want authors to to use JATS XML.</li></ul><p>I
        would really like to push Citeproc JSON as a standard bibliographic exchange
        format for authors. There are several things I like about Citeproc JSON:</p><ul><li>It
        is the native format to format citations, so it is used internally by many
        reference managers anyway.</li><li>Citeproc JSON is really good in handling
        all the possible variations of author names. Putting all authors into a single
        text field as in bibtex requires a lot of trickery to get it right.</li><li>JSON
        is a standard serialization format and there are a kinds of libraries in different
        programming languages to do things like searching, sorting or finding of duplicates.
        And JSON is easily extensible, e.g. if we would want to add ORCID identifiers
        for authors.</li></ul><p>I have five suggestions to move forward:</p><ul><li>Make
        a specification for Citeproc JSON that is as clear as the CSL specification.</li><li>Consider
        extending the specification to include content other than citations. Ideally
        we should be able to add arbitrary <a href=\"https://blog.front-matter.io/posts/metadata-in-scholarly-markdown/\">metadata
        about a manuscript</a>.</li><li>Consider other serialization formats besides
        JSON. I particularly <a href=\"https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/\">like
        YAML</a> as it is very similar to JSON, but human-readable, but other people
        might prefer XML. It is relatively easy to transform data between these serialization
        formats, in particular between JSON and YAML. In my <a href=\"http://blog.martin-fenner.io/about\">About
        page</a> I only need the <a href=\"https://github.com/nodeca/js-yaml\">js-yaml</a>
        library and one extra line of code to use Citeproc YAML instead of Citeproc
        JSON (in the d3.js visualization).</li><li>Add Citeproc JSON (and YAML) support
        to reference managers. Zotero is already doing this, but it should be an easy-to-add
        feature if the reference manager is already using CSL internally (Mendeley
        and Papers).</li><li>Push publishers to accept Citeproc JSON with manuscript
        submissions.</li></ul> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ What a publication timeline can tell you
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/what-a-publication-timeline-can-tell-you/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw10</id>\n        <published>2013-08-06T16:35:00.000+00:00</published>\n\t\t<updated>2023-09-02T08:39:52.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Now that I can <a href=\"https://doi.org/10.53731/axtz227-73n18e7\">automatically
        import my publications from my ORCID profile and display them</a> in this
        blog, I also want to visualize them. I have started with <a href=\"https://github.com/mfenner/blog/blob/master/_includes/by_year.js\">d3.js
        code</a> that displays the number of publications per year - using the list
        of my publications in Citeproc JSON format. The chart is displayed on my <a
        href=\"https://blog.front-matter.io/about\">About page</a>, but I have also
        embedded the Javascript here:</p><p>I am a big fan of data visualizations
        because they can highlight something that you would otherwise miss. In this
        case, I was really surprised to see how well my different academic jobs over
        the years (1991-1993, 1994-1998, 1998-2000, 2000-2005, 2005-2012) are reflected
        in my publication pattern. You clearly see the gaps between the jobs, indicating
        that I not only switched jobs but also changed the research focus every time.
        The publications are listed chronologically on the <a href=\"https://blog.front-matter.io/about\">About
        page</a> page and you can look at the papers I wrote since my first publication
        in 1993. My publication pattern seems to indicate that I was never really
        on track for a typical academic career, so it should not be a surprise that
        I left academia in 2012.</p><p>There are at least two other visualizations
        I want to do: publications by type (journal article, book chapter, dataset,
        etc.), and author position with the number of co-authors. You can reuse the
        Javascript code with small modifications (CSS and the JSON query) even if
        you are not running a Jekyll blog.</p><h3 id=\"references\">References</h3><p>Fenner,
        M. (2013). <em>Automatically list all your publications in your blog</em>.
        <a href=\"https://doi.org/10.53731/axtz227-73n18e7\">https://doi.org/10.53731/axtz227-73n18e7</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Automatically list all your publications
        in your blog ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/automatically-list-all-your-publications-in-your-blog/\"
        />\n\t\t<id>https://doi.org/10.53731/axtz227-73n18e7</id>\n        <published>2013-08-04T16:37:00.000+00:00</published>\n\t\t<updated>2022-08-15T14:10:49.000+00:00</updated>\n\t\t<category
        term=\"Science Hack\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>A common
        feature of blogs written by scientists is a listing of all their publications.
        Publication lists are a great way to provide background information about
        your research. Publication lists should provide links to the fulltext versions
        of these publications, should be nicely formatted - e.g. using a common citation
        style such as APA - and should be easy to maintain. A number of tools for
        a variety of blogging platforms (including Wordpress and Jekyll) are available
        to help with this task, but maintaining the list of publications has remained
        difficult.</p><p>Publication lists are best maintained in a system built for
        this purpose. This could be either a reference manager, or a profile page
        in a social network for scientists. Even better suited for this task is your
        Open Researcher &amp; Contributor ID (<a href=\"http://orcid.org/\">ORCID</a>)
        profile, as this service (<strong><strong>???</strong></strong>) directly
        integrates with a number of bibliographic databases and makes the profile
        information available via an open API.</p><h3 id=\"orcid-feed\">ORCID Feed</h3><p>Last
        week I have started work on <a href=\"http://feed.labs.orcid-eu.org/\">ORCID
        Feed</a>, a service that reformats the API response from ORCID into RSS, bibtex
        and formattted citations, making it easier for scientists to reuse the content
        stored in their ORCID profile. This service is still experimental, so please
        report any issues <a href=\"https://github.com/orcid-eu-labs/orcid-feed/issues\">here</a>.</p><h3
        id=\"jekyll-orcid\">jekyll-orcid</h3><p>I have now added the final piece to
        automatically import my publications into this blog. <a href=\"https://github.com/mfenner/jekyll-orcid\">jekyll-orcid</a>
        is a Jekyll plugin that automatically downloads all my publications from my
        ORCID profile via <strong><strong>ORCID Feed</strong></strong> and stores
        them in a subfolder of this blog, both in bibtex and Citeproc JSON format.
        It does this every time you regenerate your blog, so that the publication
        list will be automatically updated with new content. I can then use <a href=\"https://github.com/inukshuk/jekyll-scholar\">jekyll-scholar</a>,
        a popular Jekyll plugin written by Sylvester Keil to generate a bibliography
        (<code>jekyll-orcid</code> automatically adds a YAML frontmatter section to
        the files so that jekyll-scholar can process it). I can format this auto-generated
        bibliography in a variety of ways - you can see the result in my <a href=\"http://blog.martinfenner.org/about.html\">About</a>
        page where I also provide a download link of the bibtex file.</p><p>My publications
        are of course also available if I want to cite them in the text, e.g. our
        recent publication summarizing the main findings from the 2011 European Consensus
        Conference on germ-cell cancer (<strong><strong>???</strong></strong>), or
        last year\u2019s case report on liver toxicity induced by the cancer drug
        imatinib (<strong><strong>???</strong></strong>).</p><p>Similar tools also
        exist for Wordpress, e.g. <a href=\"http://wordpress.org/plugins/papercite/\">Papercite</a>,
        which can import the bibtex file directly from ORCID Feed.</p><h3 id=\"next\">Next</h3><p>Now
        there is only one step missing to have your paper that was just published
        automatically appear in your publication list. Assuming you have provided
        your ORCID identifier when you submitted the paper, and the publisher has
        included your ORCID identifier in the metadata sent to CrossRef (both are
        already common practices), we only need CrossRef to automatically push that
        paper into your ORCID profile.</p><p>And once we have this workflow in place,
        we can automatically add additional information, including links to the full-text
        paper in the institutional repository, copyright information, and metrics.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Citeproc YAML for bibliographies ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw12</id>\n        <published>2013-07-30T16:39:00.000+00:00</published>\n\t\t<updated>2022-08-19T08:36:43.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/standards.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/standards.png\"></p><p>The
        standard local file formats for bibliographic data are probably bibtex and
        RIS. They have been around for a long time, and are supported by all reference
        managers and many other tools and services. Unfortunately these formats are
        far from perfect:</p><ul><li>neither bibtex nor RIS use a web-friendly data
        interchange format such as XML or JSON, which makes it harder to work with
        these formats</li><li>bibtex - and to a lesser extend RIS - don\u2019t support
        all entry types that we need, e.g. datasets, or new standards such as ORCID
        author identifiers</li><li>bibtex stores all authors in a single field, which
        makes author names hard to parse</li></ul><h3 id=\"bibtex\">bibtex</h3><pre><code>@article{fenner2012a,\n
        \ title = {One-click science marketing},\n  volume = {11},\n  url = {http://dx.doi.org/10.1038/nmat3283},\n
        \ doi = {10.1038/nmat3283},\n  number = {4},\n  journal = {Nature Materials},\n
        \ publisher = {Nature Publishing Group},\n  author = {Fenner, Martin},\n  year
        = {2012},\n  month = {mar},\n  pages = {261-263}\n}</code></pre><p>One obvious
        solution would be to store bibliographic data in XML or JSON. These formats
        have very good support in all programming languages, and they are the formats
        used by APIs on the web. There have been some efforts to standardize these
        formats for bibliographic data, e.g. <a href=\"http://www.bibjson.org/\">BibJSON</a>,
        <a href=\"http://www.loc.gov/standards/mods/\">MODS</a>, <a href=\"http://bibtexml.sourceforge.net/\">BibTeX
        XML</a> or Endnote XML.</p><h3 id=\"bibtex-xml\">BibTeX XML</h3><pre><code>&lt;bibtex:entry
        id='fenner2012a'&gt;\n  &lt;bibtex:article&gt;\n    &lt;bibtex:title&gt;One-click
        science marketing&lt;/bibtex:title&gt;\n    &lt;bibtex:volume&gt;11&lt;/bibtex:volume&gt;\n
        \   &lt;bibtex:url&gt;http://dx.doi.org/10.1038/nmat3283&lt;/bibtex:url&gt;\n
        \   &lt;bibtex:doi&gt;10.1038/nmat3283&lt;/bibtex:doi&gt;\n    &lt;bibtex:number&gt;4&lt;/bibtex:number&gt;\n
        \   &lt;bibtex:journal&gt;Nature Materials&lt;/bibtex:journal&gt;\n    &lt;bibtex:publisher&gt;Nature
        Publishing Group&lt;/bibtex:publisher&gt;\n    &lt;bibtex:person&gt;\n      &lt;bibtex:first&gt;Martin&lt;/bibtex:first&gt;\n
        \     &lt;bibtex:last&gt;Fenner&lt;/bibtex:last&gt;\n    &lt;bibtex:person&gt;&lt;bibtex:author/&gt;\n
        \   &lt;bibtex:year&gt;2012&lt;/bibtex:year&gt;\n    &lt;bibtex:month&gt;mar&lt;/bibtex:month&gt;\n
        \   &lt;bibtex:pages&gt;261-263&lt;/bibtex:pages&gt;\n  &lt;/bibtex:article&gt;\n&lt;/bibtex:entry&gt;</code></pre><p>My
        problem with these formats is that they are made for computers talking to
        each other and not humans. I personally think that a file with bibliographic
        data should be human-readable, similar to why <a href=\"https://blog.front-matter.io/posts/a-call-for-scholarly-markdown/\">I
        like markdown</a> for writing scientific documents.</p><p>When you have too
        many standards and are not happy with any of them, you of course create a
        new standard.</p><p>My suggestion for a new bibliographic file format is twofold:
        a) use YAML for data serialization and b) use CSL as data format. <a href=\"http://www.yaml.org/spec/1.2/spec.html\">YAML</a>
        is a data format popular with Ruby Developers and is described on the <a href=\"http://yaml.org/\">YAML
        website</a> as</p><blockquote>YAML is a human friendly data serialization
        standard for all programming languages.</blockquote><p>Something that not
        may people seem to know is that YAML is a superset of JSON and that <a href=\"http://yaml.org/spec/1.2/spec.html#id2759572\">every
        JSON file is also a valid YAML file</a>. The main difference is the better
        human readability of YAML.</p><p><strong><strong>Citation Style Language</strong></strong>
        is described on the <a href=\"http://citationstyles.org/\">CSL website</a>
        as</p><blockquote>CSL is an open XML-based language to describe the formatting
        of citations and bibliographies.</blockquote><p>Although some commercial applications
        still use proprietary citation styles, CSL has become the de facto standard,
        and is used by the reference managers <strong><strong>Zotero</strong></strong>,
        <strong><strong>Mendeley</strong></strong>, <strong><strong>Papers</strong></strong>,
        and others. This blog uses CSL via Pandoc and the <a href=\"http://code.google.com/p/citeproc-hs/\">citeproc-hs</a>
        library. CSL processors need bibliographic data in a standard format. The
        popular <a href=\"https://bitbucket.org/fbennett/citeproc-js/wiki/Home\">Citeproc-js</a>
        Javascript CSL processor by Frank Bennett for example uses JSON, but we might
        as well use YAML:</p><h3 id=\"citeproc-yaml\">Citeproc YAML</h3><pre><code>-
        title: One-click science marketing\n  volume: '11'\n  URL: http://dx.doi.org/10.1038/nmat3283\n
        \ DOI: 10.1038/nmat3283\n  issue: '4'\n  container-title: Nature Materials\n
        \ publisher: Nature Publishing Group\n  author:\n  - family: Fenner\n    given:
        Martin\n    orcid: 0000-0003-1419-2405\n  page: 261-263\n  id: fenner2012a\n
        \ type: article-journal\n  issued:\n    date-parts:\n      - 2012\n      -
        3</code></pre><p>I hope you agree that this format is not only structured
        and can be understood by computers, but is also very readable by humans. You
        may have noticed that I have inserted my ORCID, something that is very difficult
        to do with bibtex where all authors are stored in one text string (see above).</p><p>Careful
        readers of this blog will of course remember that <a href=\"http://blog.front-mtter.io/posts/metadata-in-scholarly-markdown/\">I
        have written about</a> using YAML to store metadata about a blog post. We
        could now add bibliographic information to these metadata, either in the YAML
        frontmatter (if it is a Jekyll blog), or in a separate file. It should be
        straightforward to adapt the existing CSL processors to understand YAML since
        YAML and JSON are so similar. To get started with some Citeproc YAML, use
        the new (and still experimental) <strong><strong>ORCID Feed</strong></strong>
        Webservice with your ORCID and specify the <code>yml</code> format, e.g. <a
        href=\"http://feed.labs.orcid-eu.org/0000-0003-1419-2405.yml\">http://feed.labs.orcid-eu.org/0000-0003-1419-2405.yml</a>
        for my publications.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ RSS Feeds for Scholarly Authors ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/rss-feeds-for-scholarly-authors/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw13</id>\n        <published>2013-07-26T16:48:00.000+00:00</published>\n\t\t<updated>2022-07-31T11:01:47.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Open Researcher &amp; Contributor
        ID (<a href=\"https://speakerdeck.com/mfenner/orcid-connecting-research-and-researchers-1\">ORCID</a>)
        provides a persistent identifier for researchers and lets them claim their
        research outputs in the ORCID Registry. I have been involved with ORCID since
        early 2010 and I am happy to see that nine months after launch 200,000 researchers
        have signed up for the service, and the organization has more than <a href=\"http://orcid.org/about/community/members\">70
        member organizations</a>.</p><!--kg-card-begin: html--><iframe src=\"http://s3.datawrapper.de/BZBSQ/\"
        frameborder=\"0\" allowtransparency=\"true\" allowfullscreen=\"allowfullscreen\"
        webkitallowfullscreen=\"webkitallowfullscreen\" mozallowfullscreen=\"mozallowfullscreen\"
        oallowfullscreen=\"oallowfullscreen\" msallowfullscreen=\"msallowfullscreen\"
        width=\"600\" height=\"400\"></iframe><!--kg-card-end: html--><p><a href=\"https://orcid.org/register\">Registering
        for an ORCID identifier</a> is easy, and can be done in a few minutes. Claiming
        works in the profile is also straightforward, and works by integration with
        CrossRef Search, Scopus, Web of Science, DataCite Metadata Search, and other
        services. Even though about 1.5 million works have been claimed by now, many
        users have still not claimed any works or added profile information in other
        ways.</p><p>These numbers should go up as more academic institutions sign
        up for ORCID and help their researchers create ORCIDs and claim works. In
        the meantime we need more incentives for researchers to add publications to
        their ORCID profile. Publication lists are a very good reason to add your
        papers and other research outputs to your ORCID profile.</p><h3 id=\"publication-lists\">Publication
        Lists</h3><p>Every researcher maintains a list of his publications in some
        form. These publication lists are used for grant and job applications, for
        academic websites to attract collaborators and students, and more. Publication
        lists can be generated in many different ways, but I have never heard that
        someone finds this process fun or easy. The challenge is multiplied when the
        publication list is not generated for an individual, but for a research group,
        department or institution (my university goes through this process every year
        uisng RefWorks and produces an <a href=\"http://www.refworks.com/RefShare2?site=047931198213200000/RWWS6A619751/2013%20Hochschulbibliografie\">annual
        institutional bibliography</a>).</p><p>Although the library usually takes
        care of the larger publication lists and can help researchers setting up their
        own lists, there still is much that needs to be done by individual researchers,
        and the process needs to be easier. Some recommendations are:</p><ul><li>don\u2019t
        reinvent the wheel</li><li>use persistent identifiers</li><li>use standards</li><li>don\u2019t
        worry about citation styles</li><li>keep everything upstream, not locally</li></ul><p>Don\u2019t
        try to invent a new way of managing publication lists. Other people have worked
        on this problem before, and there are many tools available. This doesn\u2019t
        mean you shouldn\u2019t try something new, but please build it on top of all
        the infrastructure and services we have already.</p><p>Managing publication
        lists becomes much easier when you use persistent identifiers such as DOIs.
        They make it much easier to obtain metadata (e.g. authors, title, journal)
        and the full-text version. Some disciplines use other identifiers, but a local
        identifier such as a URL is usually a bad idea.</p><p>Use standard protocols,
        standard file formats and standard metadata. BibTex and RIS are file formats
        for references that almost every piece of software handling references understands.</p><p>Citation
        styles come from a time when publications were printed on paper. They make
        no real sense anymore, and as a researcher you shouldn\u2019t bother which
        one of 3000+ styles is the appropriate one.</p><p>The last recommendation
        is the most important one. Don\u2019t try to manage publication lists in your
        local system, or your department, but rather do this as much upstream as possible.
        ORCID is an ideal service for this. But don\u2019t try to manually add or
        edit publications in the ORCID registry, but rather claim them from CrossRef,
        DataCite or similar services, because these are the places that have authoritative
        information about publication. If you try to \u201Cfix\u201D information (because
        all metadata can contain mistakes), nobody will notice. If something is wrong
        with your works, notify the publisher so that the CrossRef metadata can be
        updated.</p><h3 id=\"orcid-profiles-as-rss-feeds\">ORCID Profiles as RSS Feeds</h3><p>ORCID
        is a good place to manage publication lists, but it is often not easy to get
        the information out of the system. The standard way is via a REST API (XML
        or JSON). This might work really well for a software developer who wants to
        connect his system to ORCID, but most researchers have other things to do.</p><p>RSS
        was invented to publish information about frequently updated works, and a
        good example are Tables of Content (TOC) for journals. RSS is also a great
        tool to manage publication lists, as it can be easily integrated into content
        management systems such as Wordpress or Drupal. There is a <a href=\"http://oxford.crossref.org/best_practice/rss/\">Recommendation
        on RSS Feeds for Scholarly Publishers</a>, and we can apply the same guidelines
        to <strong><strong>RSS Feeds for Scholarly Authors</strong></strong>. With
        <a href=\"http://en.wikipedia.org/wiki/OPML\">OPML</a> we also have a standard
        format to aggregate multiple RSS feeds, and this is true not only for journal
        RSS feeds, but also author RSS feeds.</p><p>Unfortunately there is one missing
        piece in this workflow: turning ORCID profiles into RSS feeds. At the <a href=\"http://occamstypewriter.org/trading-knowledge/2012/11/13/solo-hackday/\">SpotOn
        London hackathon</a> last November I worked with <a href=\"http://twitter.com/easternblot\">Eva
        Amsen</a> and <a href=\"http://twitter.com/graemedmoffat\">Graeme Moffat</a>
        to hack this workflow together using available tools. But we really need a
        more mature solution. Until RSS feeds are provided by the core ORCID service
        - and there is so much other stuff to do right now that this will take time
        - the best solution might be a web service that turns ORCID profiles into
        scholarly RSS as described above for journal articles.</p><p>Today I finally
        came around implementing a first version of this - hacking together a Ruby
        Sinatra application hosted on Amazon Web Services (<a href=\"http://hack4ac.com/\">#hack4ac</a>
        attendees know why). The application takes an ORCID ID (e.g. mine: <a href=\"http://feed.labs.orcid-eu.org/0000-0003-1419-2405.rss\">http://feed.labs.orcid-eu.org/0000-0003-1419-2405.rss</a>)
        and returns an RSS feed. The first version just returns just the name and
        biography from the profile, but I only started working on this today. ORCID
        Feed can be found at <a href=\"http://feed.labs.orcid-eu.org/\">http://feed.labs.orcid-eu.org</a>
        and the source code is available at <a href=\"https://github.com/mfenner/orcid-feed\">Github</a>.
        Please add suggestions and comments to the Github issue tracker <a href=\"https://github.com/mfenner/orcid-feed/issues\">here</a>.</p><p><strong><strong>Update
        7/28/13</strong></strong>: <em>I\u2019ve added publications to the output,
        and additional content types. Use them as extension (e.g. <code>.json</code>),
        as format parameter (e.g. <code>?format=rss</code>), or use an accept-header,
        e.g. <code>Accept: application/x-bibtex</code>. I\u2019ve also added basic
        error checking with cleanup of names and removal of duplicates.</em></p><ul><li>html
        (the default): forward to profile on the ORCID website</li><li>rss - RSS feed</li><li>bib
        - bibtex file</li><li>json - Citeproc JSON</li></ul> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ The trouble with keynotes ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/the-trouble-with-keynotes/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw14</id>\n
        \       <published>2013-07-23T16:50:00.000+00:00</published>\n\t\t<updated>2022-08-29T19:41:20.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/DALL-E-2022-08-29-21.40.47---a-garden-gnome-with-umbrella-in-front-of-Kensington-Palace-on-a-rainy-day-with-a-rainbow.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/DALL-E-2022-08-29-21.40.47---a-garden-gnome-with-umbrella-in-front-of-Kensington-Palace-on-a-rainy-day-with-a-rainbow.png\"></p><p>A
        keynote is a presentation typically given at a start of a conference that
        sets the central theme for the event. A keynote speaker usually has more time
        (45-60 min) than other presenters, and has the full attention of everyone
        attending the conference. The keynotes at the conferences I attended the last
        several years (mostly scholarly communication conferences) seem to work like
        this:</p><ul><li>find a prominent speaker, ideally not a core member of the
        community attending the conference</li><li>tell him to talk about something
        he knows a lot about, not necessarily a central theme of the conference</li><li>the
        keynote should be inspiring and eye-opening, instead of focussing on the conference</li></ul><p>The
        problem with this approach is that it focusses too much on the <em>prominent
        speaker</em> and it runs the risk of the keynote speaker talking about what
        he always talks about. Meaning that we don\u2019t learn much if we have heard
        the keynote speaker before. Which is too bad, because keynotes should contain
        things that are unexpected and exciting.</p><p>One of the best keynotes I
        had the pleasure of listening to in the last several years was the one given
        by <a href=\"http://michaelnielsen.org/blog/michael-a-nielsen/\">Michael Nielsen</a>
        at <a href=\"http://www.nature.com/spoton/\">Science Online London 2011</a>
        (disclaimer: I was one of the conference organizers). Not only is Michael
        an excellent speaker, but his presentation about <strong><strong>Open Science</strong></strong>
        fit perfectly into the conference, and it was clear that he had made the presentation
        specifically for this conference (with an audience that knows a lot about
        Open Science). One of the main themes of his presentation \u2013 the <em>collective
        action problem</em>, or to get started with something that benefits everyone,
        but where there is a cost doing the first step - is something I later picked
        up <a href=\"https://doi.org/10.1629/24277\">in a publication</a> about the
        Open Researcher &amp; Contributor ID (Fenner, Gomez, &amp; Thorisson, 2011).</p><figure
        class=\"kg-card kg-embed-card kg-card-hascaption\"><iframe src=\"http://player.vimeo.com/video/29784152\"
        width=\"720\" height=\"480\" frameborder=\"0\" webkitallowfullscreen=\"\"
        mozallowfullscreen=\"\" allowfullscreen=\"\" style=\"box-sizing: border-box;
        color: rgb(0, 0, 0); font-family: ff-tisa-web-pro, Georgia, serif; font-size:
        21px; font-style: normal; font-variant-ligatures: normal; font-variant-caps:
        normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align:
        start; text-indent: 0px; text-transform: none; white-space: normal; widows:
        2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255,
        255, 255); text-decoration-thickness: initial; text-decoration-style: initial;
        text-decoration-color: initial;\"></iframe><figcaption><em>Keynote by Michael
        Nielsen at the <a href=\"http://www.nature.com/spoton/\">Science Online London
        2011 Conference</a>, video recording and editing by <a href=\"http://river-valley.tv/keynote-solo2011/\">River
        Valley TV</a>.</em></figcaption></figure><p>Luckily we increasingly have video
        recordings of keynote presentations available online, making it easier to
        listen to good presentations. <a href=\"http://www.ted.com/tedx\">TED and
        TEDx</a> have of course made the format of recordings of carefully prepared
        talks popular. For large scholarly and academic conferences the best starting
        point is <a href=\"http://river-valley.tv/\">River Valley TV</a>. The <a href=\"http://www.mediatheque.lindau-nobel.org/\">Lindau
        Nobel Laureate Meeting</a> has hundreds of presentations by Nobel laureates.
        And as video recording and streaming has become easier technically (e.g. with
        <a href=\"http://googleblog.blogspot.de/2011/09/google-92-93-94-95-96-97-98-99-100.html\">Google
        Hangouts on Air</a>), recording good keynotes should become the norm and not
        the exception.</p><p><em>After several hundred blog posts here and elsewhere,
        this may well be my first blog post with an embedded video.</em></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Creating charts with Datawrapper ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/creating-charts-with-datawrapper/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw15</id>\n        <published>2013-07-19T16:54:00.000+00:00</published>\n\t\t<updated>2022-08-19T08:38:43.000+00:00</updated>\n\t\t<category
        term=\"Chart\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Figures are an important part
        of any scientific document. While the kind of figure commonly used obviously
        varies between disciplines, charts are an important part of many publications.
        There are two problems in how charts are currently used:</p><ul><li>the data
        used to draw the chart are not available or difficult to obtain</li><li>charts
        are drawn as static images with no interactivity, e.g. to see the values of
        individual data points</li></ul><p>Ross Mounce and others did a <strong><strong>Figures
        \u2192 Data</strong></strong> project at the recent <a href=\"http://hacka4ac.com/\">hack4ac</a>
        to extract data from figures, described in a <a href=\"http://rossmounce.co.uk/2013/07/09/hack4ac-recap/\">blog
        post</a>. The experience was painful, even though they started with a <em>really</em>
        simple chart.</p><p>While we should of course <a href=\"http://datadryad.org/\">publish
        all data associated with a paper</a>, the smarter strategy to overcome the
        two limitations above would be to embed the data used for a chart directly
        into the document. We have many tools that can accomplish this, and I have
        given an example using R in an <a href=\"https://blog.front-matter.io/posts/what-is-scholarly-markdown/\">earlier
        blog post</a>. The problem is the sometimes steep learning curve.</p><p>One
        approach is to build an easy-to use online tool, and <a href=\"http://datawrapper.de/\">Datawrapper</a>
        is exactly that:</p><blockquote>An open source tool helping anyone to create
        simple, correct and embeddable charts in minutes.</blockquote><p>Datawrapper
        uses the <strong><strong>d3.js</strong></strong> and <strong><strong>Highcharts</strong></strong>
        Javascript libraries for data visualizations, and the service is easy to use.
        It took me for example about 15 min to generate the chart below. The data
        used for the chart are embedded (click <strong><strong>Get the data</strong></strong>)
        and you can hover over the chart to see the actual numbers by month.</p><!--kg-card-begin:
        html--><iframe title=\"Monthly Article Views Over Time\" aria-label=\"Interactive
        line chart\" id=\"datawrapper-chart-6EQUJ\" src=\"https://datawrapper.dwcdn.net/6EQUJ/5/\"
        scrolling=\"no\" frameborder=\"0\" style=\"width: 0; min-width: 100% !important;
        border: none;\" height=\"400\"></iframe><script type=\"text/javascript\">!function(){\"use
        strict\";window.addEventListener(\"message\",(function(a){if(void 0!==a.data[\"datawrapper-height\"])for(var
        e in a.data[\"datawrapper-height\"]){var t=document.getElementById(\"datawrapper-chart-\"+e)||document.querySelector(\"iframe[src*='\"+e+\"']\");t&&(t.style.height=a.data[\"datawrapper-height\"][e]+\"px\")}}))}();\n</script><!--kg-card-end:
        html--><p>Most journal articles see the highest usage immediately after publication,
        and the light purple line shows this pattern for Darcy et al. (2009). The
        dark purple line for Moher et al. (2009) \u2013 published on the same day
        \u2013 on the other hand shows a highly unusual usage pattern, as the usage
        actually increases over time, starting about 1 1/2 years after publication.
        The article is a guideline for reporting systematic reviews and meta-analyses,
        and is now viewed more often than directly after publication four years ago.</p><p>Datawrapper
        does three things: it makes it easy to generate charts, it allows you to embed
        them directly into your webpage (using an <code>&lt;iframe&gt;</code> tag),
        and it is Open Source software (MIT license, Github repo <a href=\"https://github.com/datawrapper/datawrapper\">here</a>)
        so that you can help improve the code and host this service on your own. DataWrapper
        was written in Javascript and PHP by a group of German journalists, and the
        main focus is data journalism where the service has become really <a href=\"http://blog.datawrapper.de/2013/datawrapper-crosses-mark-of-10-million-visits/\">popular</a>
        with more than 3.5 million views of embedded charts in May 2013 alone.</p><p>Datawrapper
        is a perfect tool for science blogs and websites with scientific content,
        but it can also enhance the charts in scientific articles. We need a few additional
        chart types, error bars and more flexible labeling. And we might want to add
        a license picker, making it easy to add a Creative Commons license so that
        it is clear how the chart can be reused. Datawrapper is intended for online
        use, but the service can also save the charts as PNG or PDF. We would want
        to add saving to SVG (already used for online rendering) for easier embedding
        into the XML and ePub versions of articles.</p><h2 id=\"references\">References</h2><p>D\u2019Arcy,
        E., &amp; Moynihan, R. (2009). Can the relationship between doctors and drug
        companies ever be a healthy one? <em>PLoS Medicine</em>, <em>6</em>(7), e1000075.
        Retrieved from <a href=\"http://doi.org/10.1371/journal.pmed.1000075\">http://doi.org/10.1371/journal.pmed.1000075</a></p><p>Moher,
        D., Liberati, A., Tetzlaff, J., &amp; Altman, D. G. (2009). Preferred reporting
        items for systematic reviews and meta-analyses: The pRISMA statement. <em>PLoS
        Medicine</em>, <em>6</em>(7), e1000097. Retrieved from <a href=\"http://doi.org/10.1371/journal.pmed.1000097\">http://doi.org/10.1371/journal.pmed.1000097</a></p><hr>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Altmetrics: first we need the for what?
        and only then the how? OK? ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/altmetrics-first-we-need-the-for-what-and-only-then-the-how-ok/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw1s</id>\n        <published>2013-07-09T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-15T14:13:32.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/cute-500x132.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/cute-500x132.png\"></p><p>Altmetrics
        track the impact of scholarly works in the social web. Article-Level Metrics
        focuses on articles, but also looks at traditional citations and usage statistics.
        The <a href=\"https://web.archive.org/web/20170913082053/http://article-level-metrics.plos.org/\">PLOS
        Article-Level Metrics</a> project was started in 2008. The <a href=\"https://web.archive.org/web/20170913082053/http://altmetrics.org/manifesto/\">altmetrics
        manifesto</a> was published in October 2010 and described the fundamental
        ideas. By October 2011 we had a number of altmetrics tools, fueled by the
        Mendeley/PLOS API <a href=\"https://web.archive.org/web/20170913082053/http://blog.mendeley.com/design-research-tools/winners-of-the-first-binary-battle-apps-for-science-contest/\">programming
        contest</a>. In 2012 the focus shifted from the fact that we can provide these
        numbers to a discussion of the many open questions. We could see this at the
        <a href=\"https://web.archive.org/web/20170913082053/http://blogs.plos.org/mfenner/2012/06/25/random-notes-from-the-altmetrics12-conference/\">altmetrics12
        conference </a>in June, and even more so at the <a href=\"https://web.archive.org/web/20170913082053/https://sites.google.com/site/altmetricsworkshop/\">altmetrics
        workshop</a> hosted by PLOS last week in San Francisco.</p><p>Altmetrics can
        provide a large amount of information about the post-publication activity
        around an article (and other scholarly content), and this is exciting, but
        at the same time also somewhat overwhelming and scary. Some of the things
        that we as a community have to figure out include standards for collecting,
        aggregating and displaying altmetrics data, strategies to combat attempts
        to game these metrics, and finding appropriate ways for the different organizations
        providing altmetrics to work together as a community. These and other topics
        were discussed in great detail at the PLOS altmetrics workshop, and we made
        excellent progress not least thanks to the excellent moderation by <em>Cameron
        Neylon</em>. The third day of the workshop was a <a href=\"https://web.archive.org/web/20170913082053/https://sites.google.com/site/altmetricsworkshop/altmetrics-hackathon\">hackathon</a>,
        and we were able to translate some of the ideas into prototypes of new tools.</p><p>The
        most important conclusion from the workshop for me personally was that we
        should really should focus on use cases. Altmetrics should help answer questions
        that we can\u2019t answer today, and despite the promise, the various altmetrics
        tools still have a log way to go. A case in point is the promise that altmetrics
        can make it easier to find relevant scholarly content. We all use social media
        to help us find papers and other stuff, but integration of altmetrics into
        the traditional scholarly search tools is still missing. <a href=\"https://web.archive.org/web/20170913082053/http://rerank.it/\">ReRank</a>
        is a cool prototype developed during the hackathon last Saturday, but we are
        still a long way from having altmetrics feeding directly into the relevance
        sorting of search results.</p><p>With these thoughts in the back of mind,
        I look forward to the <a href=\"https://web.archive.org/web/20170913082053/http://www.nature.com/spoton/event/spoton-london-2012-altmetrics-beyond-the-numbers/\">altmetrics
        session</a> at the <a href=\"https://web.archive.org/web/20170913082053/http://www.nature.com/spoton/in/london/\">SpotOn
        London conference</a> this Sunday afternoon. <em>Sarah Venis</em> from <a
        href=\"https://web.archive.org/web/20170913082053/http://www.msf.org/\">M\xE9decins
        sans Fronti\xE8res</a> (MSF) will talk about the questions that she hopes
        altmetrics can answer for her organization. MSF is very interested to look
        beyond citations for the impact of their publications, as their primary target
        audience is not really the scholarly community, but rather people in need
        in various parts of the world. <em>Marie Boran</em> from the <a href=\"https://web.archive.org/web/20170913082053/http://www.deri.ie/about/team/member/marie_boran/\">Digital
        Research Enterprise Institute</a> (DERI) is interested in using altmetrics
        as a recommendation tool to find researchers with similar interests. <em>Euan
        Adie</em> from <a href=\"https://web.archive.org/web/20170913082053/http://altmetric.com/\">altmetric.com</a>
        and I (technical lead for the <a href=\"https://web.archive.org/web/20170913082053/http://article-level-metrics.plos.org/\">PLOS
        Article-Level Metrics project</a>) will use our respective tools to try to
        answer some of these questions. For me altmetrics are primarily tools to tell
        a good story, and that is one reason why we picked the title <em>Altmetrics
        beyond the Numbers</em> for this session. The focus of the session will then
        shift to an open discussion, and I hope we can get some good answers to this
        and other questions.</p><p>A clear focus on use cases should go a long way
        to reduce that feeling of being overwhelmed by all the numbers that altmetrics
        can provide. If we have specific goals for which we need altmetrics, it becomes
        much easier to decide what numbers work best for us, what standards we need
        and whom to ask to collect this information. <a href=\"https://web.archive.org/web/20170913082053/http://www.nature.com/spoton/2012/11/spoton-london-2012-altmetrics-everywhere-but-what-are-we-missing-solo12impact/\">AJ
        Cann</a> and <a href=\"https://web.archive.org/web/20170913082053/http://ukwebfocus.wordpress.com/2012/11/08/understanding-the-limits-of-altmetrics-slideshare-statistics/\">Brian
        Kelly </a>have written two excellent blog post about the confusion that too
        many altmetrics numbers can create, and the workshop <a href=\"https://web.archive.org/web/20170913082053/http://www.nature.com/spoton/event/spoton-london-2012-assessing-social-media-impact/\">Assessing
        Social Media Impact</a> during SpotOn London addresses some of these questions.
        Hackathons have played an important role in the history of altmetrics. I invite
        you to come to the <a href=\"https://web.archive.org/web/20170913082053/http://www.nature.com/spoton/event/spoton-london-2012-fringe-event-hackday/\">SpotOn
        London hackathon</a> this Saturday if you have some cool ideas and want to
        get started with the help of others.</p><h3 id=\"other-reports-from-the-plos-article-level-metrics-aka-altmetrics-workshop\">Other
        reports from the PLOS Article-Level Metrics (aka Altmetrics) Workshop</h3><ul><li><strong>Paul
        Groth</strong>: <a href=\"https://web.archive.org/web/20170913082053/http://thinklinks.wordpress.com/2012/11/05/trip-report-plos-article-level-metrics-workshop-and-hackathon/\">Trip
        Report: PLOS Article Level Metrics Workshop and Hackathon</a></li><li><strong>Karthik
        Ram</strong>: <a href=\"https://web.archive.org/web/20170913082053/http://inundata.org/2012/11/08/plos-altmetrics-workshop/\">PLOS
        Altmetrics workshop</a></li><li><strong>Carl Boettiger</strong>: <a href=\"https://web.archive.org/web/20170913082053/http://www.carlboettiger.info/2012/11/03/altmetrics-conference.html\">Altmetrics
        Conference</a></li><li><strong>Pedro Beltrao</strong>: <a href=\"https://web.archive.org/web/20170913082053/http://pbeltrao.blogspot.de/2012/11/scholarly-metrics-with-heart.html\">Scholarly
        metrics with a heart</a></li><li><strong>Ian Mulvany</strong>: <a href=\"https://web.archive.org/web/20170913082053/https://plus.google.com/u/0/photos/102755743034732738536/albums/5807181863066123265\">a
        photo post</a></li><li><strong>Euan Adie</strong> (who couldn\u2019t attend
        in person but followed remotely): <a href=\"https://web.archive.org/web/20170913082053/http://altmetric.com/blog/?p=316\">Want
        some hackathon friendly altmetrics data? arXiv tweets dataset now up on figshare</a></li></ul><p><em>Please
        let me know if you see other reports of the workshop that I have missed.</em></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Auto generating links to data and resources
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/auto-generating-links-to-data-and-resources/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw16</id>\n        <published>2013-07-02T16:58:00.000+00:00</published>\n\t\t<updated>2022-08-15T14:14:53.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/journal.pone.0063184.g003.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/journal.pone.0063184.g003.png\"></p><p>A
        few weeks ago Kafkas et al. (2013) published a paper looking at current patterns
        of how datasets o biological databases are cited in research articles, based
        on an analysis of the full text Open Access articles available from Europe
        PMC. They identified data citations by:</p><ol><li>Accession numbers available
        in articles as publisher-supplied, structured content;</li><li>Accession numbers
        identified in articles by text mining;</li><li>References to articles from
        the ENA, UniProt and PDBe records.</li></ol><p>They could show that text mining
        doubles the number of structured annotations available in journal articles
        (from 2.26% to 5.15%), and that these structured annotations should be extended
        beyond the ENA, UniProt and PDB identifiers that their analysis focused on.
        ENA identifiers (for nucleotide sequences in GenBank, EMBL or DDBJ) make up
        the largest group, with 160,112 identifiers found in the 410,364 articles
        that were analyzed.</p><p>Another result in the paper is that references to
        articles in these databases show little overlap with database links found
        in articles. One of the conclusions drawn by the author is that</p><blockquote>Text-mining
        can be used to extend structured data citation, and could be a basis for the
        development of services to help authors or editors to add structured content
        at the beginning of the publication process, rather than after the fact.</blockquote><p>Adding
        structured data citations during the authoring phase of a manuscript requires
        tools that make this process easier, providing auto-linking and verification
        without requiring extra input from the author. Scholarly Markdown is an ideal
        platform for these tools, as it is easier to extend than traditional word
        processors such as Microsoft Word. During a small workshop around persistent
        identifiers for data (<a href=\"http://datacite.org/\">DataCite</a>), people
        (<a href=\"http://orcid.org/\">ORCID</a>) and geological samples (<a href=\"http://www.geosamples.org/igsnabout\">IGSN</a>)
        that took place yesterday and today at the <a href=\"http://www.gfz-potsdam.de/portal/gfz/cegit\">GFZ
        Potsdam</a> I worked on a tool that does auto-linking for these identifiers:</p><ul><li>IGSN.
        <a href=\"http://www.geosamples.org/igsnabout\">International Geosample Number</a></li><li>MGI
        identifiers for genetically modified mouse strains in the <a href=\"http://www.findmice.org/about\">Internal
        Mouse Strain Resource</a></li><li>ENA. <a href=\"http://www.ebi.ac.uk/ena/about/about\">Genbank
        / ENA / DDBJ nucleotide sequences</a></li><li>UniProt protein sequences from
        the <a href=\"http://www.uniprot.org/help/about\">UniProt database</a></li><li>PDB.
        <a href=\"http://www.rcsb.org/pdb/static.do?p=home/faq.html\">Protein Data
        Bank protein structure information</a></li></ul><p>The list includes the IGSN,
        the database identifiers studied by Kafkas et al (2013), and the MGI identifier
        for genetically altered mice. In the life sciences there is a long tradition
        - and requirement by journals - to use database identifiers for data, but
        identifiers for resources such as genetically modified mice are unfortunately
        not in common use.</p><p>This blog uses the Pandoc markdown processor and
        the Jekyll static website generator. The easiest way to implement this functionality
        was by writing a filter for the liquid templating engine used by Jekyll, and
        provide this filter as a Jekyll plugin. The Jekyll plugin can be found at
        <a href=\"https://github.com/mfenner/jekyll-scholmd\">mfenner/jekyll-scholmd</a>.
        The plugin expects the name of the identifier, followed by a colon and optional
        space, followed by the identifier:</p><pre><code>GenBank:  M10090\nIGSN:  JRH964436\nMGI:
        \ 96922\nUniProt:  P02144\nPDB:  1mbn</code></pre><p>This input is automatically
        translated into <a href=\"http://www.ebi.ac.uk/ena/data/view/M10090\">GenBank:M10090</a>,
        <a href=\"http://hdl.handle.net/10273/JRH964436\">IGSN:JRH964436</a>, <a href=\"http://www.findmice.org/summary?gaccid/96922\">MGI:96922</a>,
        and information about the human myoglobin protein (<a href=\"http://www.uniprot.org/uniprot/P02144\">UniProt:P02144</a>,
        <a href=\"http://www.rcsb.org/pdb/explore/explore.do?structureId=1mbn\">PDB:1mbn</a>)
        is generated in a similar fashion.</p><p>The plugin was written in a few hours
        today, and is my first Jekyll plugin. There is room for improvement, e.g.
        support for more identifiers, better regex matching, validation of the resulting
        links, and automated tag generation if an identifier is found. Ideally the
        auto-linking should happen in the markdown and not the HTML output, so that
        these structured database links are also available in other markdown outputs
        such as PDF. But this is another example how Scholarly Markdown can make it
        easier for researchers to author documents without requiring a fancy web-based
        user interface.</p><h2 id=\"references\">References</h2><p>Kafkas, \u015E.,
        Kim, J.-H., &amp; McEntyre, J. R. (2013). Database Citation in Full Text Biomedical
        Articles. <em>PLoS ONE</em>. <a href=\"http://doi.org/10.1371/journal.pone.0063184\">doi:10.1371/journal.pone.0063184</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Metadata in Scholarly Markdown ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/metadata-in-scholarly-markdown/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw17</id>\n        <published>2013-06-29T17:01:00.000+00:00</published>\n\t\t<updated>2022-08-19T08:18:11.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Scholarly documents often
        need metadata that describe them: typically author(s), title and location
        (DOI or URL), but possibly many other things. For some metadata it makes sense
        to store them in the document text, e.g. as is typically done for citations.
        The problem is that this can make it hard to make the metadata machine-readable.
        The worst place for metadata is of course outside of the document, and unfortunately
        that it is the most common way of doing this. Two examples:</p><ul><li>Manuscript
        submission. Papers submitted to scholarly journals contain the metadata in
        the text, but authors are required to enter the information again into a webform.
        You can add metadata (<a href=\"http://office.microsoft.com/en-001/word-help/add-property-information-to-a-document-HA010163766.aspx\">property
        information</a>) to Microsoft Word documents, but it seems that nobody is
        doing it.</li><li>PDFs and image files. Even though we have at least one good
        standard with <a href=\"https://blog.front-matter.io/posts//just_doi_it/\">XMP</a>
        to store metadata in these documents, it is not a common practice. Information
        about these documents is therefore stored somewhere else and doesn\u2019t
        automatically travel with them.</li></ul><p>The best place for metadata is
        the document itself, and the metadata should be stored in machine-readable
        format. Another requirement is flexibility in what we can store, and we shouldn\u2019t
        limit ourselves to a predefined list. Pandoc for example allows only three
        attributes in the <a href=\"http://johnmacfarlane.net/pandoc/README.html\">title
        block</a>:</p><pre><code>% title\n% author(s) (separated by semicolons)\n%
        date</code></pre><p>For Scholarly Markdown we have another requirement: the
        metadata should be writeable and readable by humans. <a href=\"http://en.wikipedia.org/wiki/YAML\">YAML</a>
        is the perfect format for this. JSON is closely related to YAML (and is in
        fact a subset of YAML 1.2), but YAML can also be written with whitespace instead
        of curly braces. The static website generator Jekyll - which I use to parse
        the markdown for this blog into HTML - uses YAML at the beginning of markdown
        documents to store metadata, and we can easily extend this functionality.
        Carl Boettinger posted a comment yesterday saying that YAML support is on
        the Pandoc development roadmap.</p><p>Below is the YAML for (Ethan P. White,
        2013), where I reposted a paper written in markdown:</p><pre><code>---\nlayout:
        post\ntitle: \"Nine simple ways to make it easier to (re)use your data\"\ntags:
        [example, citation]\nauthors:\n - name: Ethan P. White\n   orcid: 0000-0001-6728-7745\n
        \  affiliation: Dept. of Biology and the Ecology Center, Utah State University,
        Logan, UT, USA, 84341\n - name: Elita Baldrige\n   orcid: 0000-0003-1639-5951\n
        \  affiliation: Dept. of Biology and the Ecology Center, Utah State University,
        Logan, UT, USA, 84341\n - name: Zachary T. Brym\n   affiliation: Dept. of
        Biology and the Ecology Center, Utah State University, Logan, UT, USA, 84341\n
        - name: Kenneth J. Locey\n   affiliation: Dept. of Biology, Utah State University,
        Logan, UT, USA, 84341\n - name: Daniel J. McGlinn\n   affiliation: Dept. of
        Biology and the Ecology Center, Utah State University, Logan, UT, USA, 84341\n
        - name: Sarah R. Supp\n   affiliation: Dept. of Biology and the Ecology Center,
        Utah State University, Logan, UT, USA, 84341\n---</code></pre><p>In JSON the
        same information would look like this (and Jekyll is able to parse it, since
        JSON is a subset of YAML 1.2):</p><pre><code>---\n{\n  \"layout\": \"post\",\n
        \ \"title\": \"Nine simple ways to make it easier to (re)use your data\",\n
        \ \"tags\": [\n    \"example\",\n    \"citation\"\n  ],\n  \"authors\": [\n
        \   {\n      \"name\": \"Ethan P. White\",\n      \"orcid\": \"0000-0001-6728-7745\",\n
        \     \"affiliation\": \"Dept. of Biology and the Ecology Center, Utah State
        University, Logan, UT, USA, 84341\"\n    },\n    {\n      \"name\": \"Elita
        Baldrige\",\n      \"orcid\": \"0000-0003-1639-5951\",\n      \"affiliation\":
        \"Dept. of Biology and the Ecology Center, Utah State University, Logan, UT,
        USA, 84341\"\n    },\n    {\n      \"name\": \"Zachary T. Brym\",\n      \"affiliation\":
        \"Dept. of Biology and the Ecology Center, Utah State University, Logan, UT,
        USA, 84341\"\n    },\n    {\n      \"name\": \"Kenneth J. Locey\",\n      \"affiliation\":
        \"Dept. of Biology, Utah State University, Logan, UT, USA, 84341\"\n    },\n
        \   {\n      \"name\": \"Daniel J. McGlinn\",\n      \"affiliation\": \"Dept.
        of Biology and the Ecology Center, Utah State University, Logan, UT, USA,
        84341\"\n    },\n    {\n      \"name\": \"Sarah R. Supp\",\n      \"affiliation\":
        \"Dept. of Biology and the Ecology Center, Utah State University, Logan, UT,
        USA, 84341\"\n    }\n  ]\n}\n---</code></pre><p>You can see that the author
        information required for manuscript submission can easily be written in YAML
        (email addresses were removed to protect privacy). JSON is also possible for
        people where this is a better fit into their workflow, but it is more difficult
        to write for humans because of the curly braces, and because all strings need
        to be in double quotes.</p><p>Once the ORCID Registry <a href=\"http://orcid.org/blog/2013/06/27/orcid-plans-launch-affiliation-module-using-isni-and-ringgold-organization\">adds
        affiliation</a> information, we no longer need to provide email and affiliation
        when submitting manuscripts. I have stored my own name, orcid, email and affiliation
        in my site configuration file so that I don\u2019t have to provide this info
        for every blog post.</p><p>In this blog markdown files are currently only
        processed to HTML, and I store the metadata in HTML <code>meta</code> tags
        in a <a href=\"http://www.monperrus.net/martin/accurate+bibliographic+metadata+and+google+scholar\">format</a>
        used by many sites and services, including Google Scholar - look at the source
        code of Ethan P. White et al. (2013) for an example. These metadata are also
        understood by the <a href=\"http://www.russet.org.uk/blog/2071\">Greycite
        service</a> built by Phil Lord and Lindsay Marshall that generates citation
        information for weblinks, adding important metadata such as title, authors
        and publication_date so that we can properly cite our blog post (Ethan P.
        White, 2013).</p><p>And I use the metadata to link the author names to their
        ORCID profile (if they have an ORCID) or email address, with the affiliation
        visible when you hover over the name. My own name is linked to the <a href=\"https://blog.front-matter.io/about\">About</a>
        page of this site, but with a little development effort I could automatically
        add all my publications (and other works) in my ORCID profile to that page.</p><p>Metadata
        are important, and Scholarly Markdown makes it easy to embed them.</p><p><em>Update
        06/30/13: added JSON example to demonstrate the differences to YAML, and to
        show that Jekyll also works with JSON (used in this blog post, and tested
        with the examples above which produce identical HTML output). Also added two
        references, using the embedded HTML metadata and the Greycite service to generate
        citations in bibtex.</em></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Nine simple ways to make it easier to (re)use
        your data ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/nine-simple-ways-to-make-it-easier-to-re-use-your-data/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw18</id>\n        <published>2013-06-25T17:04:00.000+00:00</published>\n\t\t<updated>2023-09-07T21:46:30.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><blockquote>This paper in markdown
        format was written by Ethan White et al. The markdown file and the associated
        bibliogaphy and figure files are available from the <a href=\"https://github.com/weecology/data-sharing-paper\">Github
        repository of the paper</a>.</blockquote>\n<blockquote>I used <a href=\"https://github.com/weecology/data-sharing-paper/commit/b5a73eb0942a18bb29810025a528aea48a8465e7\">this</a>
        version, an earlier version was published as <a href=\"https://doi.org/10.7287/peerj.preprints.7v1\"
        rel=\"noreferrer\">PeerJ Preprint</a>. Special thanks to Ethan White for allowing
        me to reuse this paper. The paper is used here as an example document to show
        how markdown can handle scholarly documents, in particular tables, figures
        and citations. The document was slightly modified from the orginal: added
        YAML frontmatter (needed by jekyll, author names are also stored there), and
        changed the anchor text for some links. This post is using the APA citation
        style. Please restrict your comments to issues related to Scholarly Markdown,
        for the content of the article contact Ethan directly.</blockquote>\n<h2 id=\"abstract\">Abstract</h2>\n<p>Sharing
        data is increasingly considered to be an important part of the scientific
        process. Making your data publicly available allows original results to be
        reproduced and new analyses to be conducted. While sharing your data is the
        first step in allowing reuse, it is also important that the data be easy to
        understand and use. We describe nine simple ways to make it easy to reuse
        the data that you share and also make it easier to work with it yourself.
        Our recommendations focus on making your data understandable, easy to analyze,
        and readily available to the wider community of scientists.</p>\n<h2 id=\"introduction\">Introduction</h2>\n<p>Sharing
        data is increasingly recognized as an important component of the scientific
        process (Whitlock, McPeek, Rausher, Rieseberg, &amp; Moore, 2010). The sharing
        of scientific data is beneficial because it allows replication of research
        results and reuse in meta-analyses and projects not originally intended by
        the data collectors (Poisot, Mounce, &amp; Gravel, 2013). In ecology and evolutionary
        biology, sharing occurs through a combination of formal data repositories
        like <a href=\"http://www.ncbi.nlm.nih.gov/genbank/\">GenBank</a> and <a href=\"http://datadryad.org/\">Dryad</a>,
        and through individual and institutional websites.</p>\n<p>While data sharing
        is increasingly common and straightforward, much of the shared data in ecology
        and evolutionary biology are not easily reused because they do not follow
        best practices in terms of data structure, metadata, and licensing (M. B.
        Jones, Schildhauer, Reichman, &amp; Bowers, 2006). This makes it more difficult
        to work with existing data and therefore makes the data less useful than it
        could be (M. B. Jones et al., 2006; O. J. Reichman, Jones, &amp; Schildhauer,
        2011). Here we provide a list of 9 simple ways to make it easier to reuse
        the data that you share.</p>\n<p>Our recommendations focus on making your
        data understandable, easy to work with, and available to the wider community
        of scientists. They are designed to be simple and straightforward to implement,
        and as such represent an introduction to good data practices rather than a
        comprehensive treatment. We contextualize our recommendations with examples
        from ecology and evolutionary biology, though many of the recommendations
        apply broadly across scientific disciplines. Following these recommendations
        makes it easier for anyone to reuse your data including other members of your
        lab and even yourself.</p>\n<h2 id=\"1-share-your-data\">1. Share your data</h2>\n<p>The
        first and most important step in sharing your data is to share your data.
        The recommendations below will help make your data more useful, but sharing
        it in any form is a big step forward. So, why should you share your data?</p>\n<p>Data
        sharing provides substantial benefits to the scientific community (Fienberg
        &amp; Martin, 1985). It allows</p>\n<ol><li>the results of existing analyses
        to be reproduced and improved upon (Fienberg &amp; Martin, 1985; Poisot et
        al., 2013),</li><li>data to be combined in meta-analyses to reach general
        conclusions (Fienberg &amp; Martin, 1985),</li><li>new approaches to be applied
        to the data and new questions asked using it (Fienberg &amp; Martin, 1985),
        and</li><li>approaches to scientific inquiry that couldn\u2019t even be considered
        without broad scale data sharing (Hampton et al., 2013).</li></ol>\n<p>As
        a result, data sharing is increasingly required by funding agencies (Poisot
        et al. (2013); e.g., <a href=\"http://www.nsf.gov/bfa/dias/policy/dmp.jsp\">NSF</a>,
        <a href=\"http://grants.nih.gov/grants/guide/notice-files/NOT-OD-03-032.html\">NIH</a>,
        <a href=\"http://www.nserc-crsng.gc.ca/Professors-Professeurs/FinancialAdminGuide-GuideAdminFinancier/Responsibilities-Responsabilites_eng.asp\">NSERC</a>,
        <a href=\"http://www.fwf.ac.at/en/public_relations/oai/index.html\">FWF</a>),
        journals (Whitlock et al., 2010), and potentially by law (e.g. <a href=\"http://doyle.house.gov/sites/doyle.house.gov/files/documents/2013%2002%2014%20DOYLE%20FASTR%20FINAL.pdf\">FASTR</a>).</p>\n<p>Despite
        these potential benefits to the community, many scientists are still reluctant
        to share data. This reluctance is largely due to perceived fears of 1) competition
        for publications based on the shared data, 2) technical barriers, and 3) a
        lack of recognition for sharing data (Hampton et al., 2013; Palmer et al.,
        2004). These concerns are often not as serious as they first appear, and the
        minimal costs associated with data sharing are frequently offset by individual
        benefits to the data sharer (Hampton et al., 2013; Parr &amp; Cummings, 2005).
        Many data sharing initiatives allow for data embargoes or limitations on direct
        competition that can last for several years while the authors develop their
        publications and thus avoid competition for deriving publications from the
        data. Also, logistical barriers to data sharing are diminishing as data archives
        become increasingly common and easy to use (Hampton et al., 2013; Parr &amp;
        Cummings, 2005). Datasets are now considered citable entities and data providers
        receive recognition in the form of increased citation metrics and credit on
        CVs and grant applications (Heather A Piwowar &amp; Vision, 2013; Heather
        A. Piwowar, Day, &amp; Fridsma, 2007; Poisot et al., 2013). In addition to
        increased citation rates, shared datasets that are documented and standardized
        are also more easily reused in the future by the original investigator. As
        a result, it is increasingly beneficial to the individual researcher to share
        data in the most useful manner possible.</p>\n<h2 id=\"2-provide-metadata\">2.
        Provide metadata</h2>\n<p>The first key to using data is understanding it.
        Metadata is information about the data including how it was collected, what
        the units of measurement are, and descriptions of how to best use the data.
        Clear metadata makes it easier to figure out if a dataset is appropriate for
        a project. It also makes data easier to use by both the original investigators
        and by other scientists by making it easy to figure out how to work with the
        data. Without clear metadata, datasets can be overlooked or not used due to
        the difficulty of understanding the data (Fraser &amp; Gluck, 1999; A. S.
        Zimmerman, 2003), and the data becomes less useful over time (Michener, Brunt,
        Helly, Kirchner, &amp; Stafford, 1997).</p>\n<p>Metadata can take several
        forms, including descriptive file and column names, a written description
        of the data, images (<em>i.e.,</em> maps, photographs), and specially structured
        information that can be read by computers. Good metadata should provide 1)
        the what, when, where, and how of data collection, 2) how to find and access
        the data, 3) suggestions on the suitability of the data for answering specific
        questions, 4) warnings about known problems or inconsistencies in the data,
        and 5) information to check that the data are properly imported, such as the
        number of rows and columns in the dataset and the total sum of numerical columns
        (Michener et al., 1997; Strasser, Cook, Michener, &amp; Budden, 2012; A. S.
        Zimmerman, 2003).</p>\n<p>Just like any other scientific publication, metadata
        should be logically organized, complete, and clear enough to enable interpretation
        and use of the data (A. Zimmerman, 2007). Specific metadata standards exist
        (<em>e.g.,</em> Ecological Metadata Language <a href=\"http://knb.ecoinformatics.org/software/eml/\">EML</a>,
        Directory Interchange Format <a href=\"http://gcmd.gsfc.nasa.gov/add/difguide/index.html\">DIF</a>,
        Darwin Core <a href=\"http://rs.tdwg.org/dwc/\">DWC</a> (Wieczorek et al.,
        2012), Dublin Core Metadata Initiative <a href=\"http://dublincore.org/metadata-basics/\">DCMI</a>,
        Federal Geographic Data Committee <a href=\"http://www.fgdc.gov/metadata/geospatial-metadata-standards\">FGDC</a>
        (O. J. Reichman et al., 2011; Whitlock, 2011). These standards are designed
        to provide consistency in metadata across different datasets and also to allow
        computers to interpret the metadata automatically. This allows broader and
        more efficient use of shared data (Brunt, McCartney, Baker, &amp; Stafford,
        2002; M. B. Jones et al., 2006). While following these standards is valuable,
        the most important thing is to have metadata at all.</p>\n<p>You don\u2019t
        need to spend a lot of extra time to write good metadata. The easiest way
        to develop metadata is to start describing your data during the planning and
        data collection stages. This will help you stay organized, make it easier
        to work with your data after it has been collected, and make eventual publication
        of the data easier. If you decide to take the extra step and follow metadata
        standards, there are tools designed to make this easier including: <a href=\"http://knb.ecoinformatics.org/morpho%20portal.jsp\">KNB
        Morpho</a>, <a href=\"http://geology.usgs.gov/tools/metadata/tools/doc/xtme.html\">USGS
        xtme</a>, and <a href=\"http://www.fgdc.gov/metadata/documents/workbook_0501_bmk.pdf\">FGDC
        workbook</a>.</p>\n<h2 id=\"3-provide-an-unprocessed-form-of-the-data\">3.
        Provide an unprocessed form of the data</h2>\n<p>Often, the data used in scientific
        analyses are modified in some way from the original form in which they were
        collected. This is done to address the questions of interest in the best manner
        possible and to address common limitations associated with the raw data. However,
        the best way to process data depends on the question being asked and corrections
        for common data limitations often change as better approaches are developed.
        It can also be very difficult to combine data from multiple sources that have
        each been processed in different ways. Therefore, to make your data as useful
        as possible it is best to share the data in as raw a form as possible.</p>\n<p>This
        is not to say that your data are best suited for analysis in the raw form,
        but providing it in the raw form gives data users the most flexibility. Of
        course, your work to develop and process the data is also very important and
        can be quite valuable for other scientists using your data. This is particularly
        true when correcting data for common limitations. Providing both the raw and
        processed forms of the data, and clearly explaining the differences between
        them in the metadata, is an easy way to include the benefits of both data
        forms. An alternate approach is to share the unprocessed data along with the
        code that process the data to the form you used for analysis. This allows
        other scientists to assess and potentially modify the process by which you
        arrived at the values used in your analysis.</p>\n<h2 id=\"4-use-standard-data-formats\">4.
        Use standard data formats</h2>\n<p>Everyone has their own favorite tools for
        storing and analyzing data. To make it easy to use your data it is best to
        store it in a standard format that can be used by many different kinds of
        software. Good standard formats include the type of file, the overall structure
        of the data, and the specific contents of the file.</p>\n<h3 id=\"use-standard-file-formats\">Use
        standard file formats</h3>\n<p>You should use file formats that are readable
        by most software and, when possible, are non-proprietary (Borer, Seabloom,
        Jones, &amp; Schildhauer, 2009; Strasser, Cook, Michener, Budden, &amp; Koskela,
        2011; Strasser et al., 2012). Certain kinds of data in ecology and evolution
        have well established standard formats such as <a href=\"http://zhanglab.ccmb.med.umich.edu/FASTA/\">FASTA</a>
        files for nucleotide or peptide sequences and the <a href=\"http://evolution.genetics.washington.edu/phylip/newicktree.html\">Newick
        files</a> for phylogenetic trees. Use these well defined formats when they
        exist, because that is what other scientists and most existing software will
        be able to work with most easily.</p>\n<p>Data that does not have a well defined
        standard format is often stored in tables. Tabular data should be stored in
        a format that can be opened by any type of software to increase reuseability
        of the data, i.e. text files. These text files use delimiters to indicate
        different columns. Commas are the most commonly used delimiter (i.e., comma-delimited
        text files with the .csv extension). Tabs can also be used as a delimiter,
        although problems can occur in displaying the data correctly when importing
        data from one program to another. In contrast to plain text files, proprietary
        formats such as those used by Microsoft Excel (e.g, .xls, .xlsx) can be difficult
        to load into other programs. In addition, these types of files can become
        obsolete, eventually making it difficult to open the data files at all if
        the newer versions of the software no longer support the original format (Borer
        et al., 2009; Strasser et al., 2011, 2012).</p>\n<p>When naming files you
        should use descriptive names so that it is easy to keep track of what data
        they contain (Borer et al., 2009; Strasser et al., 2011, 2012). If there are
        multiple files in a dataset, name them in a consistent manner to make it easier
        to automate working with them. You should also avoid spaces in file names,
        which can cause problems for some software (Borer et al., 2009). Spaces in
        file names can be avoided by using camel case (e.g, RainAvg) or by separating
        the words with underscores (e.g., rain_avg).</p>\n<h3 id=\"use-standard-table-formats\">Use
        standard table formats</h3>\n<p>Data tables are ubiquitous in ecology and
        evolution. Tabular data provides a great deal of flexibility in how to structure
        the data, which makes it easy to structure the data in a way that is difficult
        to (re)use. We provide three simple recommendations to help ensure that tabular
        data are properly structured to allow the data to be easily imported and analyzed
        by most data management systems and common analysis software, such as R and
        Python.</p>\n<ul><li>Each row should represent a single observation (i.e.,
        a record) and each column should represent a single variable or type of measurement
        (i.e., a field) (Borer et al., 2009; Strasser et al., 2011, 2012). This is
        the standard format for tables in the most commonly used database management
        systems and analysis packages and makes the data easy to work with in the
        most general way.</li><li>Every cell should contain only a single value (Strasser
        et al., 2012). For example, do not include units in the cell with the values
        (Figure 1) or include multiple measurements in a single cell, and break taxonomic
        information up into single components with one column each for family, genus,
        species, subspecies, etc. Violating this rule makes it difficult to process
        or analyze your data using standard tools, because there is no easy way for
        the software to treat the items within a cell as separate pieces of information.</li><li>There
        should only be one column for each type of information (Borer et al., 2009;
        Strasser et al., 2011, 2012). The most common violation of this rule is <a
        href=\"http://en.wikipedia.org/wiki/Cross_tabulation\">cross-tab structured
        data</a>, where different columns contain measurements of the same variable
        (e.g., in different sites, treatments, etc.; Figure 1).</li></ul>\n<figure
        class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"http://blog.martinfenner.org/images/Data_formatting.jpg\"
        class=\"kg-image\" alt=\"Figure 1. Examples of how to restructure two common
        issues with tabular data. (a) Each cell should only contain a single value.
        If more than one value is present then the data should be split into multiple
        columns. (b) There should be only one column for each type of information.
        If there are multiple columns then the column header should be stored in one
        column and the values from each column should be stored in a single column.\"
        loading=\"lazy\"><figcaption><b><strong>Figure 1. Examples of how to restructure
        two common issues with tabular data</strong></b><span>. (a) Each cell should
        only contain a single value. If more than one value is present then the data
        should be split into multiple columns. (b) There should be only one column
        for each type of information. If there are multiple columns then the column
        header should be stored in one column and the values from each column should
        be stored in a single column.</span></figcaption></figure>\n<p>While cross-tab
        data can be useful for its readability, and may be appropriate for data collection,
        this format makes it difficult to link the records with additional data (e.g.,
        the location and environmental conditions at a site) and it cannot be properly
        used by most common database management and analysis tools (e.g., relational
        databases, dataframes in R and Python, etc.). If tabular data are currently
        in a cross-tab structure, there are tools to help restructure the data including
        functions in Excel, R (e.g., melt() function in the R package reshape; Wickham
        (2007)), and Python (e.g., melt() function in the <a href=\"http://pandas.pydata.org/\">Pandas</a>
        Python module.</p>\n<p>In addition to following these basic rules you should
        also make sure to use descriptive column names (Borer et al., 2009). Descriptive
        column names make the data easier to understand and therefore make data interpretation
        errors less likely. As with file names, spaces can cause problems for some
        software and should be avoided.</p>\n<h3 id=\"use-standard-formats-within-cells\">Use
        standard formats within cells</h3>\n<p>In addition to using standard table
        structures it is also important to ensure that the contents of each cell don\u2019t
        cause problems for data management and analysis software. Specifically, we
        recommend:</p>\n<ul><li>Be consistent. For example, be consistent in your
        capitalization of words, choice of delimiters, and naming conventions for
        variables.</li><li>Avoid special characters. Most software for storing and
        analyzing data works best on plain text, and accents and other special characters
        can make it difficult to import your data (Borer et al., 2009; Strasser et
        al., 2012).</li><li>Avoid using your delimiter in the data itself (e.g., commas
        in the notes filed of a comma-delimited file). This can make it difficult
        to import your data properly. This means that if you are using commas as the
        decimal separator (as is often done in continental Europe) then you should
        use a non-comma delimiter (e.g., a tab).</li><li>When working with dates use
        the YYYY-MM-DD format (i.e., follow the <a href=\"http://www.iso.org/iso/support/faqs/faqs_widely_used_standards/widely_used_standards_other/iso8601\">ISO
        8601</a> data standard).</li></ul>\n<h2 id=\"5-use-good-null-values\">5. Use
        good null values</h2>\n<p>Most ecological and evolutionary datasets contain
        missing or empty data values. Working with this kind of \u201Cnull\u201D data
        can be difficult, especially when the null values are indicated in problematic
        ways. Unfortunately, there are many different ways to indicate a missing/empty
        value, and very little agreement on which approach to use.</p>\n<p>We recommend
        choosing a null value that is both compatible with most software and unlikely
        to cause errors in analyses (Table 1). The null value that is most compatible
        with the software commonly used by biologists is the blank (i.e., nothing;
        Table 1). Blanks are automatically treated as null values by R, Python, SQL,
        and Excel. They are also easily spotted in a visual examination of the data.
        Note that a blank involves entering nothing, it is not a space, so if you
        use this option make sure there aren\u2019t any hidden spaces. There are two
        potential issues with blanks that should be considered:</p>\n<ol><li>It can
        be difficult to know if a value is missing or was overlooked during data entry.</li><li>They
        can be confusing when spaces or tabs are used as delimiters in text files.</li></ol>\n<p>NA
        and NULL are reasonable null values, but they are only handled automatically
        by a subset of commonly used software (Table 1). NA can also be problematic
        if it is also used as an abbreviation (e.g., North America, Namibia, <em>Neotoma
        albigula</em>, sodium, etc.). We recommend against using numerical values
        to indicate nulls (e.g., 999, -999, etc.) because they typically require an
        extra step to remove from analyses and can be accidentally included in calculations.
        We also recommend against using non-standard text indications (e.g., No data,
        ND, missing, \u2014) because they can cause issues with software that requires
        consistent data types within columns). Whichever null value that you use,
        only use one, use it consistently throughout the data set, and indicate it
        clearly in the metadata.</p>\n<table style=\"box-sizing: border-box; border-collapse:
        collapse; border-spacing: 0px; max-width: 100%; background-color: rgb(255,
        255, 255); font-size: 19px; font-family: ff-tisa-sans-web-pro, Arial, sans-serif;
        width: 750px; margin-bottom: 21px; color: rgb(0, 0, 0); font-style: normal;
        font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400;
        letter-spacing: normal; orphans: 2; text-align: start; text-transform: none;
        white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width:
        0px; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color:
        initial;\"><caption style=\"box-sizing: border-box; text-align: left; vertical-align:
        top; font-size: 19px; font-style: italic; line-height: 1.33; margin-bottom:
        0.75em;\"><strong style=\"box-sizing: border-box; font-weight: bold;\">Tabel
        1. Commonly used null values, limitations, compatibility with common software
        and a recommendation regarding whether or not it is a good option</strong>.
        Null values are indicated as being a null value for specific software if they
        work consistently and correctly with that software. For example, the null
        value \u201CNULL\u201D works correctly for certain applications in R, but
        does not work in others, so it is not presented as part of the table.</caption><colgroup
        style=\"box-sizing: border-box;\"><col style=\"box-sizing: border-box; width:
        0px;\"><col style=\"box-sizing: border-box; width: 0px;\"><col style=\"box-sizing:
        border-box; width: 0px;\"><col style=\"box-sizing: border-box; width: 0px;\"></colgroup><thead
        style=\"box-sizing: border-box;\"><tr class=\"header\" style=\"box-sizing:
        border-box;\"><th style=\"box-sizing: border-box; padding: 8px; text-align:
        left; vertical-align: bottom; border-top: 0px; font-weight: bold;\">Null values</th><th
        style=\"box-sizing: border-box; padding: 8px; text-align: left; vertical-align:
        bottom; border-top: 0px; font-weight: bold;\">Problems</th><th style=\"box-sizing:
        border-box; padding: 8px; text-align: left; vertical-align: bottom; border-top:
        0px; font-weight: bold;\">Compatibility</th><th style=\"box-sizing: border-box;
        padding: 8px; text-align: left; vertical-align: bottom; border-top: 0px; font-weight:
        bold;\">Recommendation</th></tr></thead><tbody style=\"box-sizing: border-box;\"><tr
        class=\"odd\" style=\"box-sizing: border-box;\"><td style=\"box-sizing: border-box;
        padding: 8px; text-align: left; vertical-align: top; border-top: 1px solid
        rgb(221, 221, 221);\"><p style=\"box-sizing: border-box; margin: 0px 0px 21px;\">0</p></td><td
        style=\"box-sizing: border-box; padding: 8px; text-align: left; vertical-align:
        top; border-top: 1px solid rgb(221, 221, 221);\"><p style=\"box-sizing: border-box;
        margin: 0px 0px 21px;\">Indistinguishable from a true zero</p></td><td style=\"box-sizing:
        border-box; padding: 8px; text-align: left; vertical-align: top; border-top:
        1px solid rgb(221, 221, 221);\"></td><td style=\"box-sizing: border-box; padding:
        8px; text-align: left; vertical-align: top; border-top: 1px solid rgb(221,
        221, 221);\"><p style=\"box-sizing: border-box; margin: 0px 0px 21px;\">Never
        use</p></td></tr><tr class=\"even\" style=\"box-sizing: border-box;\"><td
        style=\"box-sizing: border-box; padding: 8px; text-align: left; vertical-align:
        top; border-top: 1px solid rgb(221, 221, 221);\"><p style=\"box-sizing: border-box;
        margin: 0px 0px 21px;\">blank</p></td><td style=\"box-sizing: border-box;
        padding: 8px; text-align: left; vertical-align: top; border-top: 1px solid
        rgb(221, 221, 221);\"><p style=\"box-sizing: border-box; margin: 0px 0px 21px;\">Hard
        to distinguish values that are missing from those overlooked on entry. Hard
        to distinguish blanks from spaces, which behave differently.</p></td><td style=\"box-sizing:
        border-box; padding: 8px; text-align: left; vertical-align: top; border-top:
        1px solid rgb(221, 221, 221);\"><p style=\"box-sizing: border-box; margin:
        0px 0px 21px;\">R, Python, SQL</p></td><td style=\"box-sizing: border-box;
        padding: 8px; text-align: left; vertical-align: top; border-top: 1px solid
        rgb(221, 221, 221);\"><p style=\"box-sizing: border-box; margin: 0px 0px 21px;\">Best
        option</p></td></tr><tr class=\"odd\" style=\"box-sizing: border-box;\"><td
        style=\"box-sizing: border-box; padding: 8px; text-align: left; vertical-align:
        top; border-top: 1px solid rgb(221, 221, 221);\"><p style=\"box-sizing: border-box;
        margin: 0px 0px 21px;\">999, -999</p></td><td style=\"box-sizing: border-box;
        padding: 8px; text-align: left; vertical-align: top; border-top: 1px solid
        rgb(221, 221, 221);\"><p style=\"box-sizing: border-box; margin: 0px 0px 21px;\">Not
        recognized as null by many programs without user input. Can be inadvertently
        entered into calculations.</p></td><td style=\"box-sizing: border-box; padding:
        8px; text-align: left; vertical-align: top; border-top: 1px solid rgb(221,
        221, 221);\"></td><td style=\"box-sizing: border-box; padding: 8px; text-align:
        left; vertical-align: top; border-top: 1px solid rgb(221, 221, 221);\"><p
        style=\"box-sizing: border-box; margin: 0px 0px 21px;\">Avoid</p></td></tr><tr
        class=\"even\" style=\"box-sizing: border-box;\"><td style=\"box-sizing: border-box;
        padding: 8px; text-align: left; vertical-align: top; border-top: 1px solid
        rgb(221, 221, 221);\"><p style=\"box-sizing: border-box; margin: 0px 0px 21px;\">NA,
        na</p></td><td style=\"box-sizing: border-box; padding: 8px; text-align: left;
        vertical-align: top; border-top: 1px solid rgb(221, 221, 221);\"><p style=\"box-sizing:
        border-box; margin: 0px 0px 21px;\">Can also be an abbreviation (e.g., North
        America), can cause problems with data type (turn a numerical column into
        a text column). NA is more commonly recognized than na.</p></td><td style=\"box-sizing:
        border-box; padding: 8px; text-align: left; vertical-align: top; border-top:
        1px solid rgb(221, 221, 221);\"><p style=\"box-sizing: border-box; margin:
        0px 0px 21px;\">R</p></td><td style=\"box-sizing: border-box; padding: 8px;
        text-align: left; vertical-align: top; border-top: 1px solid rgb(221, 221,
        221);\"><p style=\"box-sizing: border-box; margin: 0px 0px 21px;\">Good option</p></td></tr><tr
        class=\"odd\" style=\"box-sizing: border-box;\"><td style=\"box-sizing: border-box;
        padding: 8px; text-align: left; vertical-align: top; border-top: 1px solid
        rgb(221, 221, 221);\"><p style=\"box-sizing: border-box; margin: 0px 0px 21px;\">N/A</p></td><td
        style=\"box-sizing: border-box; padding: 8px; text-align: left; vertical-align:
        top; border-top: 1px solid rgb(221, 221, 221);\"><p style=\"box-sizing: border-box;
        margin: 0px 0px 21px;\">An alternate form of NA, but often not compatible
        with software</p></td><td style=\"box-sizing: border-box; padding: 8px; text-align:
        left; vertical-align: top; border-top: 1px solid rgb(221, 221, 221);\"></td><td
        style=\"box-sizing: border-box; padding: 8px; text-align: left; vertical-align:
        top; border-top: 1px solid rgb(221, 221, 221);\"><p style=\"box-sizing: border-box;
        margin: 0px 0px 21px;\">Avoid</p></td></tr><tr class=\"even\" style=\"box-sizing:
        border-box;\"><td style=\"box-sizing: border-box; padding: 8px; text-align:
        left; vertical-align: top; border-top: 1px solid rgb(221, 221, 221);\"><p
        style=\"box-sizing: border-box; margin: 0px 0px 21px;\">NULL</p></td><td style=\"box-sizing:
        border-box; padding: 8px; text-align: left; vertical-align: top; border-top:
        1px solid rgb(221, 221, 221);\"><p style=\"box-sizing: border-box; margin:
        0px 0px 21px;\">Can cause problems with data type</p></td><td style=\"box-sizing:
        border-box; padding: 8px; text-align: left; vertical-align: top; border-top:
        1px solid rgb(221, 221, 221);\"><p style=\"box-sizing: border-box; margin:
        0px 0px 21px;\">SQL</p></td><td style=\"box-sizing: border-box; padding: 8px;
        text-align: left; vertical-align: top; border-top: 1px solid rgb(221, 221,
        221);\"><p style=\"box-sizing: border-box; margin: 0px 0px 21px;\">Good option</p></td></tr><tr
        class=\"odd\" style=\"box-sizing: border-box;\"><td style=\"box-sizing: border-box;
        padding: 8px; text-align: left; vertical-align: top; border-top: 1px solid
        rgb(221, 221, 221);\"><p style=\"box-sizing: border-box; margin: 0px 0px 21px;\">None</p></td><td
        style=\"box-sizing: border-box; padding: 8px; text-align: left; vertical-align:
        top; border-top: 1px solid rgb(221, 221, 221);\"><p style=\"box-sizing: border-box;
        margin: 0px 0px 21px;\">Can cause problems with data type</p></td><td style=\"box-sizing:
        border-box; padding: 8px; text-align: left; vertical-align: top; border-top:
        1px solid rgb(221, 221, 221);\"><p style=\"box-sizing: border-box; margin:
        0px 0px 21px;\">Python</p></td><td style=\"box-sizing: border-box; padding:
        8px; text-align: left; vertical-align: top; border-top: 1px solid rgb(221,
        221, 221);\"><p style=\"box-sizing: border-box; margin: 0px 0px 21px;\">Avoid</p></td></tr><tr
        class=\"even\" style=\"box-sizing: border-box;\"><td style=\"box-sizing: border-box;
        padding: 8px; text-align: left; vertical-align: top; border-top: 1px solid
        rgb(221, 221, 221);\"><p style=\"box-sizing: border-box; margin: 0px 0px 21px;\">No
        data</p></td><td style=\"box-sizing: border-box; padding: 8px; text-align:
        left; vertical-align: top; border-top: 1px solid rgb(221, 221, 221);\"><p
        style=\"box-sizing: border-box; margin: 0px 0px 21px;\">Can cause problems
        with data type, contains a space</p></td><td style=\"box-sizing: border-box;
        padding: 8px; text-align: left; vertical-align: top; border-top: 1px solid
        rgb(221, 221, 221);\"></td><td style=\"box-sizing: border-box; padding: 8px;
        text-align: left; vertical-align: top; border-top: 1px solid rgb(221, 221,
        221);\"><p style=\"box-sizing: border-box; margin: 0px 0px 21px;\">Avoid</p></td></tr><tr
        class=\"odd\" style=\"box-sizing: border-box;\"><td style=\"box-sizing: border-box;
        padding: 8px; text-align: left; vertical-align: top; border-top: 1px solid
        rgb(221, 221, 221);\"><p style=\"box-sizing: border-box; margin: 0px 0px 21px;\">Missing</p></td><td
        style=\"box-sizing: border-box; padding: 8px; text-align: left; vertical-align:
        top; border-top: 1px solid rgb(221, 221, 221);\"><p style=\"box-sizing: border-box;
        margin: 0px 0px 21px;\">Can cause problems with data type</p></td><td style=\"box-sizing:
        border-box; padding: 8px; text-align: left; vertical-align: top; border-top:
        1px solid rgb(221, 221, 221);\"></td><td style=\"box-sizing: border-box; padding:
        8px; text-align: left; vertical-align: top; border-top: 1px solid rgb(221,
        221, 221);\"><p style=\"box-sizing: border-box; margin: 0px 0px 21px;\">Avoid</p></td></tr><tr
        class=\"even\" style=\"box-sizing: border-box;\"><td style=\"box-sizing: border-box;
        padding: 8px; text-align: left; vertical-align: top; border-top: 1px solid
        rgb(221, 221, 221);\"><p style=\"box-sizing: border-box; margin: 0px 0px 21px;\">-,+,.</p></td><td
        style=\"box-sizing: border-box; padding: 8px; text-align: left; vertical-align:
        top; border-top: 1px solid rgb(221, 221, 221);\"><p style=\"box-sizing: border-box;
        margin: 0px 0px 21px;\">Can cause problems with data type</p></td><td style=\"box-sizing:
        border-box; padding: 8px; text-align: left; vertical-align: top; border-top:
        1px solid rgb(221, 221, 221);\"></td><td style=\"box-sizing: border-box; padding:
        8px; text-align: left; vertical-align: top; border-top: 1px solid rgb(221,
        221, 221);\"><p style=\"box-sizing: border-box; margin: 0px 0px 21px;\">Avoid</p></td></tr></tbody></table>\n<h2
        id=\"6-make-it-easy-to-combine-your-data-with-other-datasets\">6. Make it
        easy to combine your data with other datasets</h2>\n<p>Ecological and evolutionary
        data are often most valuable when combined with other kinds of data (e.g.,
        taxonomic, environmental). You can make it easier to combine your data with
        other data sources by including the data that is common across many data sources
        (e.g., Latin binomials, latitudes and longitudes) It is common for data to
        include codes or abbreviations. For example, in ecology and evolution codes
        often appear in place of site locations or taxonomy. This is useful because
        it reduces data entry (e.g., DS instead of <em>Dipodomys spectabilis</em>)
        and redundancy (a single column for a species ID rather than separate columns
        for family, genus, and species). However, without clear definitions these
        codes can be difficult to understand and make it more difficult to connect
        your data with external sources. The easiest way to link your data to other
        datasets is to include additional tables that contain a column for the code
        and additional columns that describe the item in the standard way. For example,
        you might include a table with the species codes followed by their most current
        family, genus, and specific epithet. For site location, you could include
        a table with the site code followed by latitude and longitude. Linked tables
        can also be used to include additional information about your data, such as
        spatial extent, temporal duration, and other appropriate details.</p>\n<h2
        id=\"7-perform-basic-quality-control\">7. Perform basic quality control</h2>\n<p>Data,
        just like any other scientific product, should undergo some level of quality
        control (O. J. Reichman et al., 2011). This is true regardless of whether
        you plan to share the data because quality control will make it easier to
        analyze your own data and decrease the chance of making mistakes. However,
        it is particularly important for data that will be shared because scientists
        using the data won\u2019t be familiar with quirks in the data and how to work
        around them.</p>\n<p>At its most basic, quality control can consist of a few
        quick sanity checks of the data. More advanced quality control can include
        automated checks on data as it is entered and double-entry of data (Lampe
        &amp; Weiler, 1998; Paulsen, Overgaard, &amp; Lauritsen, 2012). This additional
        effort can be time consuming, but is valuable because it increases data accuracy
        by catching typographical errors, reader/recorder error, out-of-range values,
        and questionable data in general (Lampe &amp; Weiler, 1998; Paulsen et al.,
        2012).</p>\n<p>Before sharing your data we recommend performing a quick \u201Cdata
        review\u201D. Start by performing some basic sanity checks on your data. For
        example:</p>\n<ul><li>If a column should contain numeric values, check that
        there are no non-numeric values in the data.</li><li>Check that empty cells
        actually represent missing data, and not mistakes in data entry, and indicate
        that they are empty using the appropriate null values (see recommendation
        6).</li><li>Check for consistency in unit of measurement, data type (e.g.,
        numeric, character), naming scheme (e.g., taxonomy, location), etc.</li></ul>\n<p>These
        checks can be performed by carefully looking at the data or can be automated
        using common programming and analysis tools like R or Python.</p>\n<p>Then
        ask someone else to look over your metadata and data and provide you with
        feedback about anything they didn\u2019t understand. In the same way that
        friendly reviews of papers can help catch mistakes and identify confusing
        sections of papers, a friendly review of data can help identify problems and
        things that are unclear in the data and metadata.</p>\n<h2 id=\"8-use-an-established-repository\">8.
        Use an established repository</h2>\n<p>For data sharing to be effective, data
        should be easy to find, accessible, and stored where it will be preserved
        for a long time (Kowalczyk &amp; Shankar, 2011). To make your data (and associated
        code) visible and easily accessible, and to ensure a permanent link to a well
        maintained website, we suggest depositing your data in one of the major well-established
        repositories. This guarantees that the data will be available in the same
        location for a long time, in contrast to personal and institutional websites
        that do not guarantee the long-term persistence of the data. There are repositories
        available for sharing almost any type of biological or environmental data.
        Repositories that host specific data types, such as molecular sequences (e.g.,
        DDBJ, GenBank, MG-RAST), are often highly standardized in data type, format,
        and quality control approaches. Other repositories host a wide array of data
        types and are less standardized (e.g., Dryad, KNB, PANGAEA). In addition to
        the repositories focused on the natural sciences there are also all purpose
        repositories where data of any kind can be shared (e.g., figshare).</p>\n<p>When
        choosing a repository you should consider where other researchers in your
        discipline are sharing their data. This helps you quickly identify the community\u2019s
        standard approach to sharing and increases the likelihood that other scientists
        will discover your data. In particular, if there is a centralized repository
        for a specific kind of data (e.g., GenBank for sequence data) then you should
        use that repository.</p>\n<p>In cases where there is no <em>de facto</em>
        standard it is worth considering differences among repositories in terms of
        use, data rights, and licensing (Table 2) and whether your funding agency
        or journal has explicit requirements or restrictions related to repositories.
        We also recommend that you use a repository that allows your dataset to be
        easily cited. Most repositories will describe how this works, but an easy
        way to guarantee that your data are citable is to confirm that the repository
        associates it with a persistent identifier, the most popular of which is the
        digital object identifier (DOI). DOIs are permanent unique identifiers that
        are independent of physical location and site ownership. There are also online
        tools for finding good repositories for your data including <a href=\"http://databib.org/\">Databib</a>
        and <a href=\"http://re3data.org/\">re3data</a>.</p>\n<table style=\"box-sizing:
        border-box; border-collapse: collapse; border-spacing: 0px; max-width: 100%;
        background-color: rgb(255, 255, 255); font-size: 19px; font-family: ff-tisa-sans-web-pro,
        Arial, sans-serif; width: 750px; margin-bottom: 21px; color: rgb(0, 0, 0);
        font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal;
        font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-transform:
        none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width:
        0px; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color:
        initial;\"><caption style=\"box-sizing: border-box; text-align: left; vertical-align:
        top; font-size: 19px; font-style: italic; line-height: 1.33; margin-bottom:
        0.75em;\"><strong style=\"box-sizing: border-box; font-weight: bold;\">Table
        2. Popular repositories for scientific datasets</strong>. This table does
        not include well-known molecular repositories (e.g.\_GenBank, EMBL, MG-RAST)
        that have become<span>\_</span><em style=\"box-sizing: border-box;\">de facto</em><span>\_</span>standards
        in molecular and evolutionary biology. Consequently, several of these primarily
        serve the ecological community. These repositories are not exclusively used
        by members of specific institutions or museums, but accept data from the general
        scientific community.</caption><colgroup style=\"box-sizing: border-box;\"><col
        style=\"box-sizing: border-box; width: 0px;\"><col style=\"box-sizing: border-box;
        width: 0px;\"><col style=\"box-sizing: border-box; width: 0px;\"><col style=\"box-sizing:
        border-box; width: 0px;\"><col style=\"box-sizing: border-box; width: 0px;\"><col
        style=\"box-sizing: border-box; width: 0px;\"></colgroup><thead style=\"box-sizing:
        border-box;\"><tr class=\"header\" style=\"box-sizing: border-box;\"><th style=\"box-sizing:
        border-box; padding: 8px; text-align: left; vertical-align: bottom; border-top:
        0px; font-weight: bold;\">Repository</th><th style=\"box-sizing: border-box;
        padding: 8px; text-align: left; vertical-align: bottom; border-top: 0px; font-weight:
        bold;\">License</th><th style=\"box-sizing: border-box; padding: 8px; text-align:
        left; vertical-align: bottom; border-top: 0px; font-weight: bold;\">DOI</th><th
        style=\"box-sizing: border-box; padding: 8px; text-align: left; vertical-align:
        bottom; border-top: 0px; font-weight: bold;\">Metadata</th><th style=\"box-sizing:
        border-box; padding: 8px; text-align: left; vertical-align: bottom; border-top:
        0px; font-weight: bold;\">Access</th><th style=\"box-sizing: border-box; padding:
        8px; text-align: left; vertical-align: bottom; border-top: 0px; font-weight:
        bold;\">Notes</th></tr></thead><tbody style=\"box-sizing: border-box;\"><tr
        class=\"odd\" style=\"box-sizing: border-box;\"><td style=\"box-sizing: border-box;
        padding: 8px; text-align: left; vertical-align: top; border-top: 1px solid
        rgb(221, 221, 221);\"><p style=\"box-sizing: border-box; margin: 0px 0px 21px;\">Dryad</p></td><td
        style=\"box-sizing: border-box; padding: 8px; text-align: left; vertical-align:
        top; border-top: 1px solid rgb(221, 221, 221);\"><p style=\"box-sizing: border-box;
        margin: 0px 0px 21px;\">CC0</p></td><td style=\"box-sizing: border-box; padding:
        8px; text-align: left; vertical-align: top; border-top: 1px solid rgb(221,
        221, 221);\"><p style=\"box-sizing: border-box; margin: 0px 0px 21px;\">Yes</p></td><td
        style=\"box-sizing: border-box; padding: 8px; text-align: left; vertical-align:
        top; border-top: 1px solid rgb(221, 221, 221);\"><p style=\"box-sizing: border-box;
        margin: 0px 0px 21px;\">Suggested</p></td><td style=\"box-sizing: border-box;
        padding: 8px; text-align: left; vertical-align: top; border-top: 1px solid
        rgb(221, 221, 221);\"><p style=\"box-sizing: border-box; margin: 0px 0px 21px;\">Open</p></td><td
        style=\"box-sizing: border-box; padding: 8px; text-align: left; vertical-align:
        top; border-top: 1px solid rgb(221, 221, 221);\"><p style=\"box-sizing: border-box;
        margin: 0px 0px 21px;\">Ecology & evolution data associated with publications</p></td></tr><tr
        class=\"even\" style=\"box-sizing: border-box;\"><td style=\"box-sizing: border-box;
        padding: 8px; text-align: left; vertical-align: top; border-top: 1px solid
        rgb(221, 221, 221);\"><p style=\"box-sizing: border-box; margin: 0px 0px 21px;\">Ecological
        Archives</p></td><td style=\"box-sizing: border-box; padding: 8px; text-align:
        left; vertical-align: top; border-top: 1px solid rgb(221, 221, 221);\"><p
        style=\"box-sizing: border-box; margin: 0px 0px 21px;\">No</p></td><td style=\"box-sizing:
        border-box; padding: 8px; text-align: left; vertical-align: top; border-top:
        1px solid rgb(221, 221, 221);\"><p style=\"box-sizing: border-box; margin:
        0px 0px 21px;\">Yes</p></td><td style=\"box-sizing: border-box; padding: 8px;
        text-align: left; vertical-align: top; border-top: 1px solid rgb(221, 221,
        221);\"><p style=\"box-sizing: border-box; margin: 0px 0px 21px;\">Required</p></td><td
        style=\"box-sizing: border-box; padding: 8px; text-align: left; vertical-align:
        top; border-top: 1px solid rgb(221, 221, 221);\"><p style=\"box-sizing: border-box;
        margin: 0px 0px 21px;\">Open</p></td><td style=\"box-sizing: border-box; padding:
        8px; text-align: left; vertical-align: top; border-top: 1px solid rgb(221,
        221, 221);\"><p style=\"box-sizing: border-box; margin: 0px 0px 21px;\">Publishes
        supplemental data for ESA journals and stand alone data papers</p></td></tr><tr
        class=\"odd\" style=\"box-sizing: border-box;\"><td style=\"box-sizing: border-box;
        padding: 8px; text-align: left; vertical-align: top; border-top: 1px solid
        rgb(221, 221, 221);\"><p style=\"box-sizing: border-box; margin: 0px 0px 21px;\">Knowledge
        Network for Biocomplexity</p></td><td style=\"box-sizing: border-box; padding:
        8px; text-align: left; vertical-align: top; border-top: 1px solid rgb(221,
        221, 221);\"><p style=\"box-sizing: border-box; margin: 0px 0px 21px;\">No</p></td><td
        style=\"box-sizing: border-box; padding: 8px; text-align: left; vertical-align:
        top; border-top: 1px solid rgb(221, 221, 221);\"><p style=\"box-sizing: border-box;
        margin: 0px 0px 21px;\">Yes</p></td><td style=\"box-sizing: border-box; padding:
        8px; text-align: left; vertical-align: top; border-top: 1px solid rgb(221,
        221, 221);\"><p style=\"box-sizing: border-box; margin: 0px 0px 21px;\">Required</p></td><td
        style=\"box-sizing: border-box; padding: 8px; text-align: left; vertical-align:
        top; border-top: 1px solid rgb(221, 221, 221);\"><p style=\"box-sizing: border-box;
        margin: 0px 0px 21px;\">Variable</p></td><td style=\"box-sizing: border-box;
        padding: 8px; text-align: left; vertical-align: top; border-top: 1px solid
        rgb(221, 221, 221);\"><p style=\"box-sizing: border-box; margin: 0px 0px 21px;\">Partners
        with ESA, NCEAS, DataONE</p></td></tr><tr class=\"even\" style=\"box-sizing:
        border-box;\"><td style=\"box-sizing: border-box; padding: 8px; text-align:
        left; vertical-align: top; border-top: 1px solid rgb(221, 221, 221);\"><p
        style=\"box-sizing: border-box; margin: 0px 0px 21px;\">Paleobiology Database</p></td><td
        style=\"box-sizing: border-box; padding: 8px; text-align: left; vertical-align:
        top; border-top: 1px solid rgb(221, 221, 221);\"><p style=\"box-sizing: border-box;
        margin: 0px 0px 21px;\">Various CC</p></td><td style=\"box-sizing: border-box;
        padding: 8px; text-align: left; vertical-align: top; border-top: 1px solid
        rgb(221, 221, 221);\"><p style=\"box-sizing: border-box; margin: 0px 0px 21px;\">No</p></td><td
        style=\"box-sizing: border-box; padding: 8px; text-align: left; vertical-align:
        top; border-top: 1px solid rgb(221, 221, 221);\"><p style=\"box-sizing: border-box;
        margin: 0px 0px 21px;\">Optional</p></td><td style=\"box-sizing: border-box;
        padding: 8px; text-align: left; vertical-align: top; border-top: 1px solid
        rgb(221, 221, 221);\"><p style=\"box-sizing: border-box; margin: 0px 0px 21px;\">Variable</p></td><td
        style=\"box-sizing: border-box; padding: 8px; text-align: left; vertical-align:
        top; border-top: 1px solid rgb(221, 221, 221);\"><p style=\"box-sizing: border-box;
        margin: 0px 0px 21px;\">Paleontology specific</p></td></tr><tr class=\"odd\"
        style=\"box-sizing: border-box;\"><td style=\"box-sizing: border-box; padding:
        8px; text-align: left; vertical-align: top; border-top: 1px solid rgb(221,
        221, 221);\"><p style=\"box-sizing: border-box; margin: 0px 0px 21px;\">Data
        Basin</p></td><td style=\"box-sizing: border-box; padding: 8px; text-align:
        left; vertical-align: top; border-top: 1px solid rgb(221, 221, 221);\"><p
        style=\"box-sizing: border-box; margin: 0px 0px 21px;\">Various CC</p></td><td
        style=\"box-sizing: border-box; padding: 8px; text-align: left; vertical-align:
        top; border-top: 1px solid rgb(221, 221, 221);\"><p style=\"box-sizing: border-box;
        margin: 0px 0px 21px;\">No</p></td><td style=\"box-sizing: border-box; padding:
        8px; text-align: left; vertical-align: top; border-top: 1px solid rgb(221,
        221, 221);\"><p style=\"box-sizing: border-box; margin: 0px 0px 21px;\">Optional</p></td><td
        style=\"box-sizing: border-box; padding: 8px; text-align: left; vertical-align:
        top; border-top: 1px solid rgb(221, 221, 221);\"><p style=\"box-sizing: border-box;
        margin: 0px 0px 21px;\">Open</p></td><td style=\"box-sizing: border-box; padding:
        8px; text-align: left; vertical-align: top; border-top: 1px solid rgb(221,
        221, 221);\"><p style=\"box-sizing: border-box; margin: 0px 0px 21px;\">GIS
        data in ESRI files, limited free space</p></td></tr><tr class=\"even\" style=\"box-sizing:
        border-box;\"><td style=\"box-sizing: border-box; padding: 8px; text-align:
        left; vertical-align: top; border-top: 1px solid rgb(221, 221, 221);\"><p
        style=\"box-sizing: border-box; margin: 0px 0px 21px;\">Pangaea</p></td><td
        style=\"box-sizing: border-box; padding: 8px; text-align: left; vertical-align:
        top; border-top: 1px solid rgb(221, 221, 221);\"><p style=\"box-sizing: border-box;
        margin: 0px 0px 21px;\">Various CC</p></td><td style=\"box-sizing: border-box;
        padding: 8px; text-align: left; vertical-align: top; border-top: 1px solid
        rgb(221, 221, 221);\"><p style=\"box-sizing: border-box; margin: 0px 0px 21px;\">Yes</p></td><td
        style=\"box-sizing: border-box; padding: 8px; text-align: left; vertical-align:
        top; border-top: 1px solid rgb(221, 221, 221);\"><p style=\"box-sizing: border-box;
        margin: 0px 0px 21px;\">Required</p></td><td style=\"box-sizing: border-box;
        padding: 8px; text-align: left; vertical-align: top; border-top: 1px solid
        rgb(221, 221, 221);\"><p style=\"box-sizing: border-box; margin: 0px 0px 21px;\">Variable</p></td><td
        style=\"box-sizing: border-box; padding: 8px; text-align: left; vertical-align:
        top; border-top: 1px solid rgb(221, 221, 221);\"><p style=\"box-sizing: border-box;
        margin: 0px 0px 21px;\">Editors participate in QA/QC</p></td></tr><tr class=\"odd\"
        style=\"box-sizing: border-box;\"><td style=\"box-sizing: border-box; padding:
        8px; text-align: left; vertical-align: top; border-top: 1px solid rgb(221,
        221, 221);\"><p style=\"box-sizing: border-box; margin: 0px 0px 21px;\">figshare</p></td><td
        style=\"box-sizing: border-box; padding: 8px; text-align: left; vertical-align:
        top; border-top: 1px solid rgb(221, 221, 221);\"><p style=\"box-sizing: border-box;
        margin: 0px 0px 21px;\">CC0</p></td><td style=\"box-sizing: border-box; padding:
        8px; text-align: left; vertical-align: top; border-top: 1px solid rgb(221,
        221, 221);\"><p style=\"box-sizing: border-box; margin: 0px 0px 21px;\">Yes</p></td><td
        style=\"box-sizing: border-box; padding: 8px; text-align: left; vertical-align:
        top; border-top: 1px solid rgb(221, 221, 221);\"><p style=\"box-sizing: border-box;
        margin: 0px 0px 21px;\">Optional</p></td><td style=\"box-sizing: border-box;
        padding: 8px; text-align: left; vertical-align: top; border-top: 1px solid
        rgb(221, 221, 221);\"><p style=\"box-sizing: border-box; margin: 0px 0px 21px;\">Open</p></td><td
        style=\"box-sizing: border-box; padding: 8px; text-align: left; vertical-align:
        top; border-top: 1px solid rgb(221, 221, 221);\"><p style=\"box-sizing: border-box;
        margin: 0px 0px 21px;\">Also allows deposition of other research outputs and
        private datasets</p></td></tr></tbody></table>\n<h2 id=\"9-use-an-established-and-liberal-license\">9.
        Use an established and liberal license</h2>\n<p>Including an explicit license
        with your data is the best way to let others know exactly what they can and
        cannot do with the data you shared. Following the <a href=\"http://pantonprinciples.org/\">Panton
        Principles</a> we recommend:</p>\n<ol><li>Using well established licenses
        in order to clearly communicate the rights and responsibilities of both the
        people providing the data and the people using it.</li><li>Using the most
        open license possible, because even minor restrictions on data use can have
        unintended consequences for the reuse of the data (Poisot et al., 2013; Schofield
        et al., 2009).</li></ol>\n<p>The Creative Commons Zero license (CC0) places
        no restrictions on data use and is considered by many to be one of the best
        license for sharing data (e.g., (Poisot et al., 2013; Schofield et al., 2009),
        <a href=\"http://blog.datadryad.org/2011/10/05/why-does-dryad-use-cc0/\">Why
        does Dryad use CC0</a>). Having a clear and open license will increase the
        chance that other scientists will be comfortable using your data.</p>\n<h2
        id=\"concluding-remarks\">Concluding remarks</h2>\n<p>Data sharing has the
        potential to transform the way we conduct ecological and evolutionary research
        (Fienberg &amp; Martin, 1985; Poisot et al., 2013; Whitlock et al., 2010).
        As a result, there are an increasing number of initiatives at the federal,
        funding agency, and journal levels to encourage or require the sharing of
        the data associated with scientific research (Heather A Piwowar &amp; Chapman,
        2008; Poisot et al., 2013; Whitlock et al., 2010). However, making the data
        available is only the first step. To make data sharing as useful as possible
        it is necessary to make the data usable with as little effort as possible
        (M. B. Jones et al., 2006; O. J. Reichman et al., 2011). This allows scientists
        to spend their time doing science rather than cleaning up data.</p>\n<p>We
        have provided a list of 9 practices that require only a small additional time
        investment but substantially improve the usability of data. These practices
        can be broken down into three major groups.</p>\n<ol><li>Well documented data
        are easier to understand.</li><li>Properly formatted data are easier to use
        in a variety of software.</li><li>Data that is shared in established repositories
        with open licenses is easier for others to find and use.</li></ol>\n<p>Most
        of these recommendations are simply good practice for working with data regardless
        of whether that data are shared or not. This means that following these recommendations
        (2-7) make the data easier to work with for anyone, including you. This is
        particularly true when returning to your own data for further analysis months
        or years after you originally collected or analyzed it. In addition, data
        sharing often occurs within a lab or research group. Good data sharing practices
        make these in-house collaborations faster, easier, and less dependent on lab
        members who may have graduated or moved on to other things.</p>\n<p>By following
        these practices we can assure that the data collected in ecology and evolution
        can be used to its full potential to improve our understanding of biological
        systems.</p>\n<h2 id=\"acknowledgments\">Acknowledgments</h2>\n<p>Thanks to
        Karthik Ram for organizing this special section and inviting us to contribute.
        Carly Strasser and Kara Woo recommended important references and David Harris
        and Carly Strasser provided valuable feedback on null values, all via Twitter.
        Carl Boettiger, Matt Davis, Daniel Hocking, Heinz Pampel, Karthik Ram, Thiago
        Silva, Carly Strasser, Tom Webb, and beroe (Twitter handle) provided value
        comments on the manuscript. Many of these comments were part of the informal
        review process facilitated by posting this manuscript as a preprint. The writing
        of this paper was supported by a CAREER grant from the U.S. National Science
        Foundation (DEB 0953694) to EPW. A <a href=\"https://doi.org/10.4033/iee.2013.6b.6.f\"
        rel=\"noreferrer\">peer-reviewed version</a> of this preprint is available.</p>\n<h2
        id=\"references\">References</h2>\n<p>Borer, E. T., Seabloom, E. W., Jones,
        M. B., &amp; Schildhauer, M. (2009). Some simple guidelines for effective
        data management. <em>Bulletin of the Ecological Society of America</em>, <em>90</em>(2),
        205\u2013214. Retrieved from <a href=\"http://dx.doi.org/10.1890/0012-9623-90.2.205\">http://dx.doi.org/10.1890/0012-9623-90.2.205</a></p>\n<p>Brunt,
        J. W., McCartney, P., Baker, K., &amp; Stafford, S. G. (2002). The future
        of ecoinformatics in long term ecological research. In <em>Proceedings of
        the 6th world multiconference on systemics, cybernetics and informatics: SCI</em>
        (pp. 14\u201318).</p>\n<p>Fienberg, S. E., &amp; Martin, M. E. (1985). <em>Sharing
        research data</em>. Natl Academy Pr.</p>\n<p>Fraser, B., &amp; Gluck, M. (1999).
        Usability of geospatial metadata or space-time matters. <em>Bulletin of the
        American Society for Information Science and Technology</em>, <em>25</em>(6),
        24\u201328. Retrieved from <a href=\"http://dx.doi.org/10.1002/bult.134\">http://dx.doi.org/10.1002/bult.134</a></p>\n<p>Hampton,
        S. E., Strasser, C. A., Tewksbury, J. J., Gram, W. K., Budden, A. E., Batcheller,
        A. L., \u2026 Porter, J. H. (2013). Big data and the future of ecology. <em>Frontiers
        in Ecology and the Environment</em>, <em>11</em>(3), 156\u2013162. Retrieved
        from <a href=\"http://dx.doi.org/10.1890/120103\">http://dx.doi.org/10.1890/120103</a></p>\n<p>Jones,
        M. B., Schildhauer, M. P., Reichman, O., &amp; Bowers, S. (2006). The new
        bioinformatics: Integrating ecological data from the gene to the biosphere.
        <em>Annual Review of Ecology, Evolution, and Systematics</em>, <em>37</em>(1),
        519\u201354. Retrieved from <a href=\"http://dx.doi.org/10.1146/annurev.ecolsys.37.091305.110031\">http://dx.doi.org/10.1146/annurev.ecolsys.37.091305.110031</a></p>\n<p>Kowalczyk,
        S., &amp; Shankar, K. (2011). Data sharing in the sciences. <em>Annual Review
        of Information Science and Technology</em>, <em>45</em>(1), 247\u2013294.
        Retrieved from <a href=\"http://dx.doi.org/10.1002/aris.2011.1440450113\">http://dx.doi.org/10.1002/aris.2011.1440450113</a></p>\n<p>Lampe,
        A., &amp; Weiler, J. (1998). Data capture from the sponsors\u2019 and investigators\u2019
        perspectives: Balancing quality, speed, and cost. <em>Drug Information Journal</em>,
        <em>32</em>(4), 871\u2013886.</p>\n<p>Michener, W. K., Brunt, J. W., Helly,
        J. J., Kirchner, T. B., &amp; Stafford, S. G. (1997). Nongeospatial metadata
        for the ecological sciences. <em>Ecological Applications</em>, <em>7</em>(1),
        330\u2013342. Retrieved from <a href=\"http://dx.doi.org/10.1890/1051-0761(1997)007%5B0330:nmftes%5D2.0.co;2\">http://dx.doi.org/10.1890/1051-0761(1997)007[0330:nmftes]2.0.co;2</a></p>\n<p>Palmer,
        M. A., Bernhardt, E. S., Chornesky, E. A., Collins, S. L., Dobson, A. P.,
        Duke, C. S., \u2026 Turner, M. G. (2004). Ecological science and sustainability
        for a crowded planet. Retrieved from <a href=\"http://www.esa.org/ecovisions/ppfiles/EcologicalVisionsReport.pdf\">http://www.esa.org/ecovisions/ppfiles/EcologicalVisionsReport.pdf</a></p>\n<p>Parr,
        C., &amp; Cummings, M. (2005). Data sharing in ecology and evolution. <em>Trends
        in Ecology &amp; Evolution</em>, <em>20</em>(7), 362\u2013363. Retrieved from
        <a href=\"http://dx.doi.org/10.1016/j.tree.2005.04.023\">http://dx.doi.org/10.1016/j.tree.2005.04.023</a></p>\n<p>Paulsen,
        A., Overgaard, S., &amp; Lauritsen, J. M. (2012). Quality of data entry using
        single entry, double entry and automated forms processing\u2013An example
        based on a study of patient-reported outcomes. <em>PloS ONE</em>, <em>7</em>(4),
        e35087. Retrieved from <a href=\"http://dx.doi.org/10.1371/journal.pone.0035087\">http://dx.doi.org/10.1371/journal.pone.0035087</a></p>\n<p>Piwowar,
        H. A., &amp; Chapman, W. W. (2008). A review of journal policies for sharing
        research data. In <em>ELPUB2008</em>.</p>\n<p>Piwowar, H. A., &amp; Vision,
        T. J. (2013). Data reuse and the open data citation advantage. <em>PeerJ PrePrints</em>,
        <em>1</em>, e1. Retrieved from <a href=\"http://dx.doi.org/10.7287/peerj.preprints.1\">http://dx.doi.org/10.7287/peerj.preprints.1</a></p>\n<p>Piwowar,
        H. A., Day, R. S., &amp; Fridsma, D. B. (2007). Sharing detailed research
        data is associated with increased citation rate. <em>PLoS ONE</em>, <em>2</em>(3),
        e308. Retrieved from <a href=\"http://dx.doi.org/10.1371/journal.pone.0000308\">http://dx.doi.org/10.1371/journal.pone.0000308</a></p>\n<p>Poisot,
        T., Mounce, R., &amp; Gravel, D. (2013). Moving toward a sustainable ecological
        science: Don\u2019t let data go to waste! Retrieved from <a href=\"https://github.com/tpoisot/DataSharingPaper/blob/master/DataSharing-MS.md\">https://github.com/tpoisot/DataSharingPaper/blob/master/DataSharing-MS.md</a></p>\n<p>Reichman,
        O. J., Jones, M. B., &amp; Schildhauer, M. P. (2011). Challenges and opportunities
        of open data in ecology. <em>Science</em>, <em>331</em>(6018), 703\u2013705.
        Retrieved from <a href=\"http://dx.doi.org/10.1126/science.1197962\">http://dx.doi.org/10.1126/science.1197962</a></p>\n<p>Schofield,
        P. N., Bubela, T., Weaver, T., Portilla, L., Brown, S. D., Hancock, J. M.,
        \u2026 Rosenthal, N. (2009). Post-publication sharing of data and tools. <em>Nature</em>,
        <em>461</em>(7261), 171\u2013173. Retrieved from <a href=\"http://dx.doi.org/10.1038/461171a\">http://dx.doi.org/10.1038/461171a</a></p>\n<p>Strasser,
        C. A., Cook, R. B., Michener, W. K., Budden, A., &amp; Koskela, R. (2011).
        Promoting data stewardship through best practices. In <em>Proceedings of the
        environmental information management conference 2011 (eIM 2011)</em>. Oak
        Ridge National Laboratory (ORNL).</p>\n<p>Strasser, C. A., Cook, R., Michener,
        W. K., &amp; Budden, A. (2012). Primer on data management: What you always
        wanted to know. DataONE. Retrieved from <a href=\"http://dx.doi.org/10.5060/D2251G48\">http://dx.doi.org/10.5060/D2251G48</a></p>\n<p>Whitlock,
        M. C. (2011). Data archiving in ecology and evolution: Best practices. <em>Trends
        in Ecology &amp; Evolution</em>, <em>26</em>(2), 61\u201365. Retrieved from
        <a href=\"http://dx.doi.org/10.1016/j.tree.2010.11.006\">http://dx.doi.org/10.1016/j.tree.2010.11.006</a></p>\n<p>Whitlock,
        M. C., McPeek, M. A., Rausher, M. D., Rieseberg, L., &amp; Moore, A. J. (2010).
        Data archiving. <em>The American Naturalist</em>, <em>175</em>(2), 145\u2013146.
        <a href=\"http://doi.org/10.1086/650340\">doi:10.1086/650340</a></p>\n<p>Wickham,
        H. (2007). Reshaping data with the reshape package. <em>Journal of Statistical
        Software</em>, <em>21</em>(12). Retrieved from <a href=\"http://www.jstatsoft.org/v21/i12/paper\">http://www.jstatsoft.org/v21/i12/paper</a></p>\n<p>Wieczorek,
        J., Bloom, D., Guralnick, R., Blum, S., D\xF6ring, M., Giovanni, R., \u2026
        Vieglais, D. (2012). Darwin core: An evolving community-developed biodiversity
        data standard. <em>PLoS ONE</em>, <em>7</em>(1), e29715. <a href=\"http://doi.org/10.1371/journal.pone.0029715\">doi:10.1371/journal.pone.0029715</a></p>\n<p>Zimmerman,
        A. (2007). Not by metadata alone: The use of diverse forms of knowledge to
        locate data for reuse. <em>International Journal on Digital Libraries</em>,
        <em>7</em>(1-2), 5\u201316. <a href=\"http://doi.org/10.1007/s00799-007-0015-8\">doi:10.1007/s00799-007-0015-8</a></p>\n<p>Zimmerman,
        A. S. (2003). <em>Data sharing and secondary use of scientific data: Experiences
        of ecologists</em> (PhD thesis). The University of Michigan.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Citations in Markdown Part 3 ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/citations-in-markdown-part-3/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw19</id>\n        <published>2013-06-24T17:08:00.000+00:00</published>\n\t\t<updated>2022-08-19T08:41:07.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>After the <a href=\"https://blog.front-matter.io/posts/citations-in-scholarly-markdown/\">post
        last week</a> and the crazy discussion that followed I would understand that
        you feel you have heard enough about citations in markdown. But I had the
        feeling last week that something was still missing, and I have done some more
        thinking. What we have so far:</p><ul><li>Pandoc has nice support for citations,
        including Citation Style Language support (i.e. it is using the same 5000+
        citation styles as Zotero, Mendeley and Papers).</li><li>Pandoc requires a
        separate file to store the citations, typically in bibtex format. This is
        fine for some people, but can make the workflow complicated for short documents
        or when several people work on the bibliography at the same time.</li><li>Citations
        are similar to links, and we can use links for almost all the functionality
        we need, making it much easier to add citations to a text. The problem is
        a) citations that don\u2019t include a weblink, b) being able to do this offline,
        and c) where in the HTML to store the citation metadata.</li></ul><p>And I
        looked at how Wikipedia is <a href=\"http://en.wikipedia.org/wiki/Wikipedia:Citing_sources\">doing
        this</a>, and they use a) links, b) citations and c) footnotes. If Wikipedia
        thinks that it can\u2019t do without citations and do everything as links,
        then maybe we also shouldn\u2019t enforce this for scholarly texts.</p><p>I
        think what we need is the best of both worlds. We should use the Pandoc citation
        workflow, as it is similar to what we are used to from other authoring environments,
        and we get good citation style support, including more complex formatting
        of references. Some reference managers already support copy/paste of Pandoc
        citation keys. The inclusion of a bibtex file with a scholarly markdown text
        is also a bonus, as it allows the automated extraction of citations, e.g.
        by manuscript submission systems.</p><p>We also want to support a simpler
        solution for shorter texts or when people don\u2019t want to use a separate
        bibtex file. Here we would add the citations as links, ideally in a syntax
        very similar to Pandoc citation keys:</p><pre><code>Johnson [@Johnson2006]
        didn't agree with ...\n\n[@Johnson2006]: http://dx.doi.org/10.1002/aris.201
        \"Data sharing in the sciences\"</code></pre><p>We need to write a tool that
        parses the markdown before Pandoc, fetches the citation metadata for these
        links in bibtex format (e.g. using CrossRef Content Negotiation), and adds
        them to the existing bibtex file (or creates a new bibtex file). The next
        time the markdown is parsed, the citation is already \u201Ccached\u201D in
        the bibtex file. Those people who don\u2019t have such a tool would see the
        citation as link (<strong><strong>???</strong></strong>), with the essential
        information (DOI or URL) preserved so that a downstream tool can fetch the
        bibliographic information. Some people were worried about typos in DOIs and
        URLs. They can add additional information - e.g. the title of the paper -
        in double quotes to allow checking of the correct DOI.</p><p>This workflow
        now makes a lot of sense to me, as it uses existing solutions, but also allows
        for easy entering of citation information in a way similar to the <a href=\"http://carlboettiger.info/2012/05/30/knitcitations.html\">knitcitations</a>
        and <a href=\"http://wordpress.org/plugins/kcite/\">kcite</a> tools. As I
        use jekyll and am a Ruby developer, I will implement the citation parsing
        as a jekyll plugin.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ What Flavor is Scholarly Markdown? ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/what-flavor-is-scholarly-markdown/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw1a</id>\n        <published>2013-06-21T17:11:00.000+00:00</published>\n\t\t<updated>2022-08-19T08:42:31.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>One important
        outcome of the recent <a href=\"https://github.com/scholmd/scholmd/wiki/workshop\">Markdown
        for Science</a> workshop was an overall agreement that all the different implementations
        (or flavors) of markdown that currently exist are a big problem for the adoption
        of Scholarly Markdown and that we <a href=\"https://github.com/scholmd/scholmd/wiki/What-is-Markdown\">need</a>:</p><blockquote>A
        reference implementation with documentation and tests</blockquote><p>As described
        by Karthik Ram (<a href=\"https://github.com/scholmd/scholmd/wiki/workshop\">31
        flavors is great for ice cream but not markdown</a>), <a href=\"https://blog.front-matter.io/posts/what-flavor-is-scholarly-markdown/@flavor\">me</a>
        and <a href=\"http://www.codinghorror.com/blog/2012/10/the-future-of-markdown.html\">others</a>,
        there is really a large number of markdown implementations to choose from,
        including</p><ul><li>John Gruber\u2019s <a href=\"http://daringfireball.net/projects/markdown/\">original
        Markdown</a></li><li><a href=\"https://help.github.com/articles/github-flavored-markdown\">Github-flavored
        Markdown</a></li><li><a href=\"http://michelf.ca/projects/php-markdown/extra/\">PHP
        Markdown Extra</a></li><li><a href=\"http://johnmacfarlane.net/pandoc/\">Pandoc</a></li><li><a
        href=\"http://fletcherpenney.net/multimarkdown/\">MultiMarkdown</a></li></ul><p>These
        different flavors all serve their needs, but for Markdown to take off in the
        relatively small scholarly community it would be very helpful to come up with
        a reference implementation. But how do we get to that point?</p><ol><li>Think
        about the features we need for Scholarly Markdown and make this the reference
        implementation?</li><li>Organize a working group or committee that decides
        what is Scholarly Markdown?</li><li>Pick the Markdown flavor with the best
        developer support?</li><li>Figure out what markdown flavor has the widest
        support by tools relevant for scholars?</li><li>See what markdown flavor most
        scholars are currently using?</li></ol><p>I think as a starting point, and
        until we come up with something better, #5 makes the most sense. The number
        of markdown users among scholars is still small, but my guess would be that
        Pandoc is currently the most popular Markdown flavor among scholars. This
        blog uses Pandoc and the static site generator <a href=\"http://jekyllrb.com/\">Jekyll</a>,
        and is hosted on <a href=\"http://pages.github.com/\">Github Pages</a> - for
        the source code use the link in the footer. Please tell me in the comments
        what you are using (Markdown flavor and tools), and whether I am correct with
        my wild guess regarding Pandoc. And make sure your preferred tool is listed
        in the <a href=\"https://github.com/scholmd/scholmd/wiki/Tools-to-support-your-markdown-authoring\">Tools
        to support your markdown authoring</a> wiki page.</p><p>A reference Markdown
        document is also very helpful to move forward, as we can see what outputs
        in HTML, PDF (or other formats) our specific Markdown tools produce, and how
        they differ. This reference document should include citations, tables, figures,
        and other features typical for scholarly content. Ideally this is a paper
        written in Markdown and accepted for publication - proving the concept -,
        or it can be a published paper transformed into markdown, e.g. a paper by
        <a href=\"http://www.elifesciences.org/elife-now-supports-content-negotiation/\">eLife</a>.
        Feel free to suggest a paper in the comments.</p><p>The idea of tests that
        came up in the Markdown workshop is also great. Ideally we have a set of tests
        that we (or someone else, e.g. a publisher) can run to make sure that the
        markdown in the document conforms with the reference implementation. This
        could also include basic checks for required metadata (title, author, publication
        date, etc.), and could optionally validate the citations as well.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Citations in Scholarly Markdown ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/citations-in-scholarly-markdown/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw1b</id>\n        <published>2013-06-19T17:13:00.000+00:00</published>\n\t\t<updated>2022-07-31T10:58:16.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>In the comments on <a href=\"https://front-matter.io/mfenner/what-is-scholarly-markdown/\">Monday\u2019s
        blog post</a> about the Markdown for Science workshop, <a href=\"http://carlboettiger.info/\">Carl
        Boettiger</a> had some good arguments against the proposal for how to do <a
        href=\"https://github.com/scholmd/scholmd/wiki/citations\">citations</a> that
        we came up with during the workshop. As this is a complex topic, I decided
        to write this blog post.</p><p>Citations of the scholarly literature are an
        essential part of scholarly texts and therefore have to be supported by scholarly
        markdown. Both the <a href=\"http://johnmacfarlane.net/pandoc/README.html\">Pandoc</a>
        and <a href=\"https://github.com/fletcher/MultiMarkdown/wiki/MultiMarkdown-Syntax-Guide\">Multimarkdown</a>
        flavors of markdown support citations, using a bibtex file that contains citations,
        placeholders for citekeys \u2013 <code>[@smith04]</code> for Pandoc and <code>[#smith04]</code>
        for Multimarkdown \u2013 and the <a href=\"http://citationstyles.org/\">Citation
        Style Language</a> for citation formatting (Pandoc). A very reasonable approach
        would therefore be to use this functionality, with a preference for Pandoc
        because of the Citation Style Language support. All reference managers can
        export to the bibtex format, and some of them (e.g. <a href=\"http://www.papersapp.com/papers/\">Papers</a>)
        make it very easy to copy and paste citekeys.</p><p>Ten days after the workshop
        I\u2019m not so sure anymore this is the best approach. For four reasons:</p><ol><li><strong><strong>YFNS</strong></strong>.
        This approach failed the YFNS (your friendly neighborhood scientist) test.
        We came up with this term during the workshop and it means that our ideas
        about authoring should make sense to the workflow of the average scientist.
        I thought that using citekeys is a good idea, but my wife (my YFNS) tells
        me that she never uses citekeys because there are just too many <code>[@smith04]</code>,
        and it is too easy get out of sync with the reference manager. She therefore
        prefers to put the complete reference information into the text while writing.</li><li><strong><strong>Snippets</strong></strong>.
        As I said <a href=\"https://front-matter.io/mfenner/what-is-scholarly-markdown/\">previously</a>,
        I think that scholarly markdown has great potential not so much for writing
        full papers, but for all the little scientific documents we write on a daily
        basis. For this reason the citation information should ideally be embedded
        in the document if it is short, and that is difficult with bibtex (which is
        not human-readable).</li><li><strong><strong>Citations as links</strong></strong>.
        Carl Boettiger reminded me that I wrote a <a href=\"https://front-matter.io/mfenner/citations-are-links-so-where-is-the-problem/\">blog
        post in 2010</a> stating that citations are nothing else than links, and that
        we should treat them accordingly. He has written a tool (<a href=\"http://carlboettiger.info/2012/05/30/knitcitations.html\">knitcitations</a>)
        for R that does just that, and Phil Lord and colleagues have written a similar
        tool (<a href=\"http://wordpress.org/plugins/kcite/\">kcite</a>) for Wordpress.
        In 2010 I wrote a tool for Wordpress (<a href=\"http://wordpress.org/plugins/link-to-link/\">Link
        to Link</a>) that takes a different approach but also treats citations as
        links. All that we need is the DOI (or URL) for the article.</li><li><strong><strong>Vendor
        lock-in</strong></strong>. Although a number of excellent reference managers
        are available now, users are still limited in their choices because everyone
        has to use the same reference manager when multiple authors work on the same
        document. This has always annoyed me. It would no longer be the case if we
        embed the citation information in the document in a standard format.</li></ol><p>Part
        of the motivation for using scholarly markdown is that we can come up with
        best practices that make sense for digital content and don\u2019t need to
        support conventions from an era when articles were still printed on paper.
        Reference information in the form of volumes and pages, and 1000s of citation
        styles certainly have outlived their purpose. Citation styles are a particular
        pain point, as they are nothing more than a visual representation of a citation
        - we should care much more about the machine-readable metadata, in particular
        the DOI or other identifier.</p><p>The best practice for scholarly markdown
        could therefore be to treat citations as links, using DOIs or other standard
        identifiers (PMID, ArXiV, etc.) where possible. Because we typically want
        to list the citations as references at the end of the document, reference-style
        links should be preferred over inline links. From the <a href=\"http://daringfireball.net/projects/markdown/syntax#link\">markdown
        syntax documentation</a>:</p><pre><code>This is [an example][id] reference-style
        link.\n\nThis is [an example](http://example.com/ \"Title\") inline link.\n[id]:
        http://example.com/  \"Optional Title Here\"</code></pre><p>It might be tempting
        to use sequential numbers as id for the reference-style links, but the order
        of links can of course change during writing. It may make sense to think of
        the id in reference-style links as a citekey, and people should be free use
        that functionality of their reference manager. The citekey is used to link
        to the reference list at the bottom of the document, different from linking
        to the citekey in a separate bibtex file.</p><p>All of the above can be done
        in any text editor. This also includes the text editor that scholars spend
        most of their time with - their email program. Reference-style citations in
        an email are very readable, and also actionable since they are links and not
        text with bibliographic information.</p><p>One problem with this approach
        is of course that all links are inline in the resulting HTML, without a references
        section at the end of the document. This may be fine, as we can provide citation
        information in the title attribute, available upon hovering over the link
        (try hovering over <a href=\"https://doi.org/10.1371/journal.pmed.0020124\">this
        link</a>, the journal eLife is doing <a href=\"https://doi.org/10.7554/eLife.00633\">something
        similar</a>). The markdown could look like this (using the <em>Vancouver</em>
        citation style):</p><pre><code>[@Ioannidis2005]: http://dx.doi.org/10.1371/journal.pmed.0020124
        \"Ioannidis JPA. Why Most Published Research Findings Are False. PLoS Medicine.
        Public Library of Science; 2005;2(8):e124. Available from: http://dx.doi.org/10.1371/journal.pmed.0020124\"</code></pre><p>The
        title attribute now of course uses a citation style, but this is optional
        information and can easily be reformatted as we have the DOI.</p><p>Or we
        break away from standard markdown and display reference-style links at the
        end of the document - similar to <a href=\"http://rephrase.net/box/word/footnotes/syntax/\">footnotes</a>,
        which are also not part of standard markdown. But this is just a display issue
        that can be solved, and the solution might look different depending on whether
        the output is HTML, PDF or XML. This document for example contains 14 reference-style
        citations.</p><p>There is obviously a need for tools that make adding citations
        to scholarly markdown easier. This could be accomplished by relatively small
        changes to existing reference managers (enabling copy/paste of citations in
        reference-style markdown format), or by tools similar to the <a href=\"http://carlboettiger.info/2012/05/30/knitcitations.html\">knitcitations</a>
        and <a href=\"http://wordpress.org/plugins/kcite/\">kcite</a> mentioned above.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ What is Scholarly Markdown? ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/what-is-scholarly-markdown/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw1c</id>\n
        \       <published>2013-06-17T17:16:00.000+00:00</published>\n\t\t<updated>2022-08-29T09:57:43.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/DALL-E-2022-08-29-11.57.15---Edward-hopper-oil-painting-of-a-garden-gnome-with-an-umbrella-under-the-Golden-Gate-Bridge.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/DALL-E-2022-08-29-11.57.15---Edward-hopper-oil-painting-of-a-garden-gnome-with-an-umbrella-under-the-Golden-Gate-Bridge.png\"></p><p>One
        of the important discussions taking place at the <a href=\"https://github.com/scholmd/scholmd/wiki\">Markdown
        for Science</a> workshop last weekend was about the definition of Scholarly
        Markdown. We came up with <a href=\"https://github.com/scholmd/scholmd/wiki/What-is-Markdown\">this</a>:</p><ol><li>Markdown
        that supports the requirements of scientific texts</li><li>Markdown as format
        that glues open scientific text resources together</li><li>A reference implementation
        with documentation and tests</li><li>A community</li></ol><p>We also agreed
        that <strong><strong>Scholarly Markdown</strong></strong> is a better term
        than <strong><strong>Markdown for Science</strong></strong>, as it also includes
        the Social Sciences and Humanities. And we agreed on a hashtag, <a href=\"https://twitter.com/search?q=%23scholmd&amp;src=typd\">#scholmd</a>.</p><p>I
        like #3 and #4, and I was not surprised to see #1. #2 is one of the most important
        outcomes of the workshop for me personally, and was reflected in the discussion
        we had in the breakout session on <em>What is needed for Markdown to be adopted
        by the scientific community?</em> One important strategy is the following:</p><blockquote>We
        need an online tool that makes it easy for scholars to write scholarly markdown
        in a collaborative manner.</blockquote><p>We called this the <strong><strong>Google
        Docs for Scientists</strong></strong> (Google Docs is a good collaborative
        tool, but is lacking some important features required for scientific documents,
        e.g. integrated citation management). <a href=\"https://www.authorea.com/\">Authorea</a>
        was mentioned as a promising example of this concept. It was also noted that
        some previous efforts failed, because the tool looked too different from Microsoft
        Word. But building such a tool wouldn\u2019t really require markdown as a
        file format, and could for example also be done directly in HTML5. This would
        be a reasonable strategy, but in my mind is falling short because I think
        the problem we need to solve is more complicated than making collaboration
        easier with tools that look like Microsoft Word. We therefore also discussed
        a different strategy:</p><blockquote>We need multiple tools that make it easy
        for scholars to create scholarly markdown documents and openly share them.
        This collaborative work is not limited to authoring scholarly papers, but
        also includes shorter scholarly texts, e.g. experimental results, lab notebooks,
        lecture notes, blog posts and working papers. Ease of use is not only defined
        by the writing experience, but also how easy it is to share documents with
        others.</blockquote><p>This definition almost sounds like a definition for
        Open Science, and assumes that data - and increasingly software - are an integral
        part of reporting science. This makes <a href=\"https://www.scienceexchange.com/reproducibility\">reproducibility</a>
        of scientific results much easier, and one nice example how this can be done
        is the integration of markdown into the R statistical software, using the
        <a href=\"http://yihui.name/knitr/\">knitr package</a>. Using the <a href=\"http://article-level-metrics.plos.org/plos-alm-data/\">May
        2013 PLOS article-level metrics data</a> which are freely available for download,
        the R code below can be embedded into a markdown file and will produce the
        bar plot below when the markdown file is run in R (to try this yourself, download
        the ALM data and <a href=\"https://github.com/articlemetrics/plosOpenR/blob/master/barPlotSummary.Rmd\">markdown
        file for this article</a>).</p><pre><code># Load required libraries\nlibrary(reshape2)\n\n#
        Load the data from the bulk download, filter out DOIs that are not from PLoS
        journals\nalm &lt;- read.csv(\"data-alm/alm_report_2013-05-20.csv\", encoding
        = \"UTF8\", sep = \",\", stringsAsFactors=FALSE, na.strings=c(\"0\"))\nalm
        &lt;- subset(alm, (substr(alm$doi,1,15) == \"10.1371/journal\"))\nalm$publication_date
        &lt;- as.Date(alm$publication_date)\nalm$counter_html &lt;- as.numeric(alm$counter_html)\n\n#
        Options\nplos.start_date &lt;- NA\nplos.end_date &lt;- NA\nplos.colors &lt;-
        c(\"#304345\",\"#304345\",\"#789aa1\",\"#789aa1\",\"#789aa1\",\"#ad9a27\",\"#ad9a27\",\"#ad9a27\",\"#ad9a27\",\"#ad9a27\",\"#ad9a27\",\"#ad9a27\")\n\n#
        Aggregate notes and comments\nalm$comments &lt;- as.numeric(alm$comments)\n\n#
        Aggregate Mendeley\nalm$mendeley &lt;- rowSums(subset(alm, select=c(\"mendeley_readers\",\"mendeley_groups\")),
        na.rm=TRUE)\nalm$mendeley[alm$mendeley == 0] &lt;- NA\n\n# Use subset of columns\nalm
        &lt;- subset(alm, select=c(\"counter_html\",\"pmc_html\",\"crossref\",\"scopus\",\"pubmed\",\"mendeley\",\"citeulike\",\"comments\",\"researchblogging\",\"facebook\",\"twitter\",\"wikipedia\"))\n\n#
        Calculate percentage of values that are not missing (i.e. have a count of
        at least 1)\ncolSums &lt;- colSums(!is.na(alm)) * 100 / length(alm$counter_html)\nexactSums
        &lt;- sum(as.numeric(alm$pmc_html),na.rm =TRUE)\n\n# Plot the chart.\nopar
        &lt;- par(mar=c(1,7,2,1)+0.1,omi=c(1,0.3,1,1))\nplos.names &lt;- c(\"PLoS
        HTML Views\", \"PMC HTML Views\",\"CrossRef\",\"Scopus\",\"PubMed Citations\",
        \"Mendeley\",\"CiteULike\",\"PLoS Comments\",\"Research Blogging\",\"Facebook\",\"Twitter\",\"Wikipedia\")\ny
        &lt;- barplot(colSums,horiz=TRUE,col=plos.colors, border = NA, xlab=plos.names,
        xlim=c(0,120), axes=FALSE, names.arg=plos.names,las=1, adj=0)\ntext(colSums+6,y,labels=sprintf(\"%1.0f%%\",
        colSums))</code></pre><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"http://blog.martinfenner.org/images/barplot-2013-06-17.svg\" class=\"kg-image\"
        alt=\"Proportion of articles covered by source. Article-level metrics for
        all 80,602 PLOS journal articles published until May 20, 2013.\" loading=\"lazy\"><figcaption><strong
        style=\"box-sizing: border-box; font-weight: bold;\">Proportion of articles
        covered by source</strong>. Article-level metrics for all 80,602 PLOS journal
        articles published until May 20, 2013.</figcaption></figure><p>In a way this
        approach to scholarly markdown is much more difficult than building a nice
        online collaborative writing tool. But for me scholarly markdown is not about
        competing with Microsoft Word, it is about building something new that scholars
        want to use because it allows them to do something that is impossible with
        the existing tools. For the same reason my todo item at the end of the workshop
        was <em>think about document type where markdown shines</em>. The R example
        above is a great example where markdown shines. If you can think of additional
        examples, please add them to the comments.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Goodbye PLOS Blogs, Welcome Github Pages
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/goodbye-plos-blogs-welcome-github-pages/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw1d</id>\n        <published>2013-06-15T17:18:00.000+00:00</published>\n\t\t<updated>2023-09-07T08:08:12.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2023/09/octocat-1.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2023/09/octocat-1.png\"></p><p>This
        is the last <a href=\"http://blogs.plos.org/mfenner\">Gobbledygook</a> post
        on PLOS Blogs, and at the same time the first post at the <a href=\"http://blog.martinfenner.org/\">new
        Github blog location</a>. I have been blogging at PLOS Blogs since the <a
        href=\"http://blogs.plos.org/blogosphere/\">PLOS Blogs Network</a> was launched
        in September 2010, so this step wasn\u2019t easy. But I have two good reasons.</p><p>In
        May 2012 I started to work as technical lead for the <a href=\"http://article-level-metrics.plos.org/\">PLOS
        Article-Level Metrics</a> project. Although this is contract work, and I also
        do other things - including spending 5% of my time as clinical researcher
        at Hannover Medical School - this created the awkward situation that I was
        never quite sure whether I was blogging as Martin Fenner or as someone working
        for PLOS. This was all in my head, as I never had any restrictions in my blogging
        from PLOS. With the recent launch of the <a href=\"http://blogs.plos.org/tech/\">PLOS
        Tech Blog</a> there is now a good venue for the kind of topics I like to write
        about, and I have started to work on two posts for this new blog.</p><p>There
        will always be topics for which the PLOS Tech Blog is not a good fit, and
        for these posts I have launched the new personal blog at Github. But the main
        reason for this new blog is a technical one: I\u2019m moving away from blogging
        on Wordpress to writing my posts in <a href=\"http://daringfireball.net/projects/markdown/\">markdown</a>
        (a lightweight markup language), that are then transformed into static HTML
        pages using <a href=\"http://jekyllrb.com/\">Jekyll</a> and <a href=\"http://johnmacfarlane.net/pandoc/\">Pandoc</a>.
        Last weekend I co-organized the workshop <a href=\"https://github.com/scholmd/markdown_science/wiki\"><strong><strong>Scholarly
        Markdown</strong></strong></a> together with <a href=\"http://twitter.com/houshuang\">Stian
        H\xE5klev</a>. A full workshop report will follow in another post, but the
        discussions before, at and after the workshop convinced me that <strong><strong>Scholarly
        Markdown</strong></strong> has a bright future and that it is time to move
        more of my writing to markdown. At the end of the workshop each participant
        suggested a <a href=\"https://github.com/scholmd/markdown_science/wiki/Todo-list-from-workshop\">todo
        item</a> that he/she would be working on, and my todo item was \u201CThink
        about document type where MD shines\u201D. Markdown might be good for writing
        scientific papers, but I think it really shines in shorter scientific documents
        that can easily be shared with others. And blog posts are a perfect fit.</p><p>The
        new site is work in progress. Over time I will copy over all old blog posts
        from PLOS Blogs, and will work on the layout as well as additional features.
        Special thanks to <a href=\"http://carlboettiger.info/\">Carl Boettiger</a>
        for helping me to get started with Jekyll and Github pages.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ re3data.org: registry of research data repositories
        launched ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/re3data-org-registry-of-research-data-repositories-launched/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw1w</id>\n        <published>2013-06-01T00:00:00.000+00:00</published>\n\t\t<updated>2023-06-29T18:04:53.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/figure2.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/figure2.png\"></p><p>Earlier
        this week re3data.org \u2013 the Registry of Research Data Repositories \u2013
        <a href=\"https://web.archive.org/web/20171029050202/http://www.re3data.org/2013/05/re3data-org-launched/\">officially
        launched</a>. The registry is nicely described in a <a href=\"https://dx.org/10.7287/peerj.preprints.21v1\">preprint</a>
        also published this week.</p><p><em>re3data.org offers researchers, funding
        organizations, libraries and publishers and overview of the heterogeneous
        research data repository landscape. Information icons help researchers to
        identify an adequate repository for the storage and reuse of their data.</em></p><p>I
        really like re3data.org, and that is not because I personally know several
        of the people involved in this project, or because they <a href=\"https://front-matter.io/mfenner/figshare-interview-with-mark-hahnel/\">cited
        this blog</a> in their preprint. I think that we are just at the beginning
        of building the infrastructure needed for research data management, and re3data.org
        fills an important need. In my opinion it is not enough to provide lists of
        research data repositories, we need additional information that can help guide
        researchers in selecting an appropriate research data repository. re3data.org
        has addressed this nicely by providing a <a href=\"https://front-matter.io/mfenner/re3data-org-registry-of-research-data-repositories-launched/10.2312/re3.002\">vocabulary
        for the registration and description of research data repositories</a>, and
        by creating a simple icon system:</p><figure class=\"kg-card kg-image-card\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/figure2-1.png\"
        class=\"kg-image\" alt=\"The re3data icon system\" loading=\"lazy\" width=\"500\"
        height=\"569\"></figure><p><em>Possible values for each icon. From <a href=\"https://doi.org/10.7287/peerj.preprints.21v1\">https://doi.org/10.7287/peerj.preprints.21v1</a></em></p><p>Future
        directions I would like re3data.org to take include:</p><ul><li><strong>Training
        and education.</strong> Researchers probably pick research data repositories
        mainly based on the familiarity of the repository within their community rather
        than the criteria developed by re3data.org. A lot more training and education
        is needed before researchers understand the importance of persistent identifiers,
        licenses and other criteria.</li><li><strong>Integration.</strong> re3data.org
        can make it easier to integrate into existing scientific infrastructure, e.g.
        by using persistent identifiers such as DOIs for research data repositories,
        or by providing an API that makes it easier for other services to integrate
        re3data.org.</li><li><strong>Governance</strong>. Whether or not scientific
        infrastructure such as re3data.org is accepted and used by the community depends
        on many factors, and governance is one of the most important ones. re3data.org
        should seek the support of other organizations, in particular from outside
        Germany. A governing board, re3data.org as an independent organization, and
        strategies to coordinate with similar efforts such as <a href=\"https://web.archive.org/web/20171029050202/http://www.databib.org/\">Databib</a>
        are possible strategies.</li></ul><h3 id=\"references\">References</h3><p>Pampel
        H, Vierkant P, Scholze F, et al. <em>Making Research Data Repositories Visible:
        The Re3data.Org Registry</em>. PeerJ PrePrints; 2013. doi:<a href=\"https://doi.org/10.7287/peerj.preprints.21v1\">10.7287/peerj.preprints.21v1</a></p><p>Vierkant
        P, Spier S, Ruecknagel J, et al. Vocabulary for the Registration and Description
        of Research Data Repositories. <em>re3data.org</em>. Published online 2012:374
        kb, 23 pages. doi:<a href=\"https://doi.org/10.2312/RE3.002\">10.2312/RE3.002</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Metrics and attribution: my thoughts for
        the panel at the ORCID-Dryad symposium on research attribution ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/metrics-and-attribution-my-thoughts-for-the-panel-at-the-orcid-dryad-symposium-on-research-attribution/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw1x</id>\n        <published>2013-05-31T00:00:00.000+00:00</published>\n\t\t<updated>2023-07-10T16:18:33.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/A_Bicycle_in_Oxford-1.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/A_Bicycle_in_Oxford-1.jpeg\"></p><p>This
        Thursday I take part in a panel discussion at the <a href=\"http://orcid.org/orcid-outreach-meeting-symposium-and-codefest-may-2013\">Joint
        ORCID \u2013 Dryad Symposium on Research Attribution</a>. Together with <a
        href=\"http://www.bmj.com/about-bmj/editorial-staff/trish-groves\">Trish Groves</a>
        (BMJ) and <a href=\"http://polaris.gseis.ucla.edu/cborgman/Chriss_Site/Welcome.html\">Christine
        Borgman</a> (UCLA) I will discuss several aspects of attribution. Trish will
        speak about ethics, Christine will highlight problems, and I will add my perspective
        on metrics. This blog post summarizes the main points I want to make.</p><p>Scholarly
        metrics can be used in discovery tools, as business intelligence for funders,
        research organizations or publishers, and for research assessment. For all
        these scenarios \u2013 and in particular for research assessment \u2013 it
        is important to not only collect metrics for a particular journal publication,
        dataset or other research output, but to also link these metrics to the creators
        of that research output. \_That is why unique identifiers for researchers,
        and ORCID in particular, are so important for scholarly metrics, and this
        is also reflected in the ORCID membership of organizations such as Thomson
        Reuters, Elsevier/Scopus, Altmetric or F1000Prime who provide metrics in a
        variety of ways.</p><h2 id=\"dora\">DORA</h2><p>A good starting point for
        any discussion on metrics for research assessment is the San Francisco Declaration
        on Research Assessment (<a href=\"https://sfdora.org\">DORA</a>) that was
        published las week, together with a set of editorials in several journals,
        including the <em><a href=\"https://doi.org/10.1083/jcb.201304162\">Journal
        of Cell Biology</a></em>, <em><a href=\"https://doi.org/10.1091/mbc.e13-04-0193\">Molecular
        Biology of the Cell</a></em>, <em><a href=\"https://doi.org/10.1038/emboj.2013.126\">EMBO
        Journal</a></em>, <em><a href=\"https://doi.org/10.1126/science.1240319\">Science</a></em>,
        <em><a href=\"http://jcs.biologists.org/content/early/2013/05/09/jcs.134460.full.pdf+html\">Journal
        of Cell Science</a></em>, and <em><a href=\"http://elife.elifesciences.org/content/elife/2/e00855.full.pdf\">eLife</a></em>.
        The first three recommendations are a good starting point for the panel discussion:</p><ol><li><em>Do
        not use journal-based metrics, such as Journal Impact Factors, as a surrogate
        measure of the quality of individual research articles, to assess an individual
        scientist\u2019s contributions, or in hiring, promotion, or funding decisions.</em></li><li><em>Be
        explicit about the criteria used in evaluating the scientific productivity
        of grant applicants and clearly highlight, especially for early-stage investigators,
        that the scientific content of a paper is much more important than publication
        metrics or the identity of the journal in which it was published.</em></li><li><em>For
        the purposes of research assessment, consider the value and impact of all
        research outputs (including datasets and software) in addition to research
        publications, and consider a broad range of impact measures including qualitative
        indicators of research impact, such as influence on policy and practice.</em></li></ol><h2
        id=\"persistent-identifiers\">Persistent Identifiers</h2><p>Before we can
        collect any metrics, we need persistent identifiers for research outputs.
        Most journal articles now come with a DOI, but we should make it easier for
        smaller publishers to use DOIs, as cost unfortunately is still an issue.</p><p>Persistent
        identifiers for data are a much more complex issue, as there a number of persistent
        identifiers out there (including DOIs, handles, ARKs and purls), in addition
        to all the domain-specific identifiers, e.g. for nucleotide sequence or protein
        structures. DataCite DOIs are probably the first choice for attribution, as
        this is their main use case and they have features that make attribution easier
        (e.g. familiar to researchers, funders and publishers, global resolver). There
        are many other use cases for identifiers for data (e.g. to identify temporary
        datasets in an ongoing experiment), and is of course possible to use several
        identifiers for the same dataset. CrossRef is of course also issuing DOIs
        for datasets on behalf of their members, and the publisher PLOS is for example
        using CrossRef <a href=\"https://front-matter.io/mfenner/direct-links-to-figures-and-tables-using-component-dois/\">component
        DOIs</a> for figures and supplementary information associated with a journal
        article, and is <a href=\"http://blogs.plos.org/plos/2013/01/easier-access-to-plos-data/\">making
        them available via figshare</a>.</p><p>Particular challenges with persistent
        identifiers for research data include different versions of a dataset, and
        aggregation of datasets (e.g. whether we want to cite the aggregate dataset,
        or a particular subset). Persistent identifiers for other research outputs
        are an even bigger challenge, e.g. how to uniquely identify scientific software.</p><p>In
        addition to persistent identifiers for research outputs, we also need persistent
        identifiers for researchers. ORCID is obviously a good candidate, as it focusses
        on attribution (by allowing researchers to claim their research outputs and
        by integration in many researcher workflows). But it is clear that ORCID is
        not the only persistent identifiers for researchers, and that we need to link
        these identifiers, e.g. <a href=\"https://orcid.org/blog/2013/04/22/orcid-and-isni-issue-joint-statement-interoperation-april-2013\">ORCID
        and ISNI</a>.</p><p>Depending on how we want to aggregate the metrics we are
        interested in, we might also need persistent identifiers for institutions,
        for funding agencies and their grant IDs, and for resources such as particle
        accelerators or research vessels. Unfortunately much more work is needed in
        these areas.</p><h2 id=\"attribution\">Attribution</h2><p>Attribution is then
        the next step, linking persistent identifiers for research outputs to their
        creators. Attribution is therefore essential for research assessment. The
        <a href=\"https://www.force11.org/AmsterdamManifesto\">Amsterdam Manifesto
        on Data Citation Principles</a> that came out of the Beyond the PDF 2 workshop
        in March are an excellent document, but are unfortunately missing the important
        step of linking persistent identifiers for data to the persistent identifiers
        of their creators.</p><p>One important issue related to attribution is the
        provenance of the claims. Has a researcher claimed authorship for a particular
        paper, is a data center linking creators to research data, or is a funder
        doing this? The ORCID registry is built around the concept of self-claims
        by authors, but will allow the other stakeholders to confirm these claims.</p><h2
        id=\"metrics\">Metrics</h2><p>Metrics for scholarly content fall into one
        of three categories:</p><ul><li>Citations</li><li>Usage stats</li><li>Altmetrics</li></ul><p>Altmetrics
        is a mixed bag of many different things, from sharing on social media such
        as Twitter or Facebook to more scholarly activities such as Mendeley bookmarks
        or F1000Prime reviews. I therefore expect the altmetrics category to over
        time further evolve into 2-3 sub-categories.</p><p>We are all familiar with
        citation-based metrics for journal articles. We currently see the long-overdue
        shift from journal-based citation metrics to article-level metrics (see #1
        from the DORA statement above for the reasoning), and as the technical lead
        for the PLOS Article-Level Metrics project I of course welcome this shift
        in focus. We also see a trend towards opening up reference lists that will
        make citation-based metrics much more accessible, and the <a href=\"http://opencitations.net/\">JISC
        Open Citations</a> project by David Shotton and others is an important driver
        in this, as is the <a href=\"http://openbiblio.net/\">Open Bibliographic Data</a>
        project by OKFN. Until open bibliographic data become the norm, we have to
        deal with different citation counts from different sources. PLOS is collecting
        citations from Web of Science, Scopus, CrossRef and PubMed Central, and the
        citation counts are highly correlated overall (e.g. R2= 0.87 for CrossRef
        and Scopus citations for 2009 PLOS Biology papers), but for some papers differ
        substantially. Similar to persistent identifiers, reference lists of publications
        should become part of the open e-infrastructure for science and not depend
        on proprietary systems. This makes citation metrics more transparent and easier
        to compare, and fosters research and innovation, in particular by smaller
        organizations.</p><p>The data citation community has adopted the journal article
        citation model, and we are starting to see more citations to datasets. Even
        though data citations look similar to citations of journal articles, many
        essential tools and services still don\u2019t properly handle datasets. The
        <a href=\"http://wokinfo.com/products_tools/multidisciplinary/dci/\">Web of
        Knowledge Data Citation Index</a> is an important step in the right direction,
        as is the<a href=\"http://odin-project.eu/2013/05/13/new-orcid-integrated-data-citation-tool/\">
        new DataCite import tool for ORCID</a>. Something that we should pay closer
        attention to is the citation counts of the paper(s) associated with a dataset.
        Maybe the major scientific impact is in the data, but scientific practice
        still dictates to the cite the corresponding paper and not the dataset itself
        (one of the reasons we see data journals being launched). The DataCite metadata
        can contain the persistent identifier of the corresponding journal article,
        thus making it possible to associate the citation count of the corresponding
        paper with the dataset. This approach is particularly important for datasets
        that are always part of a paper, as is the case for Dryad. One important consideration
        is that contributor lists may differ between journal article and dataset,
        or between related datasets.</p><p>Another problem with data citation is that
        citation counts might not be the best way to reflect the scientific impact
        of a dataset. We are increasingly seeing usage stats for datasets, and DataCite
        for example has <a href=\"https://web.archive.org/web/20171029102820/http://www.datacite.org/node/76\">started
        in January</a> to publish monthly stats for the most popular datasets by number
        of DOI resolutions. The #1 dataset in March was the raw data to a figure in
        a F1000Research article, <a href=\"https://doi.org/10.6084/M9.FIGSHARE.154685\">hosted
        on figshare</a>.</p><p>Similar to citations we see a strong trend for usage
        stats to move from aggregate numbers for journals to article-level metrics.
        COUNTER has <a href=\"https://web.archive.org/web/20171029102820/http://www.projectcounter.org/pirus.html\">released</a>
        a draft code of practice for their PIRUS (Publisher and Institutional Repository
        Usage Statistics) standard in February, and increasing numbers of publishers
        and repository infrastructure providers such as <a href=\"https://web.archive.org/web/20171029102820/http://www.irus.mimas.ac.uk/\">IRUS-UK</a>
        and <a href=\"https://web.archive.org/web/20171029102820/http://www.dini.de/projekte/oa-statistik/english\">OA-Statistics</a>
        are providing usage stats for individual articles.</p><p>One challenge with
        usage stats, in particular with Open Access content, is that an article or
        other research output might be available in more than one place, e.g. publisher
        (or data center), disciplinary repository, and institutional repository. For
        PLOS articles we don\u2019t know the aggregated usage stats from institutional
        repositories, but we know that 17% of HTML page views and 33% of PDF downloads
        happen not at the PLOS website, but at PubMed Central.</p><p>Altmetrics provide
        new challenges, but they are also a more recent development compared to usage
        stats and citations. Similar to usage stats they are easier to game than citations,
        and for some altmetrics sources (e.g. Twitter) standardization is still difficult.
        Altmetrics do not necessarily measure impact, but sometimes rather reflect
        attention or self-promotion. We have just started to look into altmetrics
        beyond the numbers, e.g. who is tweeting, bookmarking, or discussing a paper
        or dataset. Altmetrics provide the opportunity to show the broader social
        impact (as Mike Taylor from Elsevier explains it) of research, e.g. changing
        clinical practice or policies.</p><h2 id=\"contributions\">Contributions</h2><p>One
        important aspect of attribution is contribution, i.e. what is the specific
        contribution by a researcher to a paper or other research output? An <a href=\"https://web.archive.org/web/20171029102820/http://projects.iq.harvard.edu/attribution_workshop\">International
        Workshop on Contributorship and Scholarly Attribution</a> was held together
        with the May 2012 ORCID Outreach Meeting to discuss this topic. Authorship
        position (e.g. first author, last author) is used in some metrics, but overall
        the contributor role is still poorly appreciated in most metrics. David Shotton
        has proposed a <a href=\"http://purl.org/spar/scoro/Shotton_SCoRO_and_SCoRF_Contributions-Workshop_Harvard_16May2012.pdf\">Scholarly
        Contributions and Roles Ontology</a> (ScoRO) and is suggesting splitting authorship
        credit into percentage points based on relative contributions, but I haven\u2019t
        seen these numbers used in the context of metrics.</p><h2 id=\"conclusions\">Conclusions</h2><p>Persistent
        identifiers for people, attribution, and metrics are closely interrelated
        and we have seen a lot of exciting developments in this area in the last two
        years. The widespread adoption of ORCID identifiers by the research community
        will have a huge impact on scholarly metrics. But with all the excitement
        we should never forget that a) there will never be a single metric that can
        be used for research assessment, and b) that scientific content will always
        be more important than any metric. I look forward to a great panel discussion
        on Thursday, and welcome any feedback via comments, Twitter, or email.</p><p><em>May
        23, 2013: Post updated with minor corrections and additions.</em></p><h3 id=\"references\">References</h3><p>Misteli
        T. Eliminating the impact of the Impact Factor. <em>Journal of Cell Biology</em>.
        2013;201(5):651-652. doi:<a href=\"https://doi.org/10.1083/jcb.201304162\">10.1083/jcb.201304162</a></p><p>Bertuzzi
        S, Drubin DG. No shortcuts for research assessment. <em>MBoC</em>. 2013;24(10):1505-1506.
        doi:<a href=\"https://doi.org/10.1091/mbc.e13-04-0193\">10.1091/mbc.e13-04-0193</a></p><p>Pulverer
        B. Impact fact-or fiction? <em>EMBO J</em>. 2013;32(12):1651-1652. doi:<a
        href=\"https://doi.org/10.1038/emboj.2013.126\">10.1038/emboj.2013.126</a></p><p>Alberts
        B. Impact Factor Distortions. <em>Science</em>. 2013;340(6134):787-787. doi:<a
        href=\"https://doi.org/10.1126/science.1240319\">10.1126/science.1240319</a></p><p>Way
        M, Ahmad SA. The San Francisco Declaration on Research Assessment. <em>Journal
        of Cell Science</em>. Published online January 1, 2013:jcs.134460. doi:<a
        href=\"https://doi.org/10.1242/jcs.134460\">10.1242/jcs.134460</a></p><p>Schekman
        R, Patterson M. Reforming research assessment. <em>eLife</em>. 2013;2:e00855.
        doi:<a href=\"https://doi.org/10.7554/eLife.00855\">10.7554/eLife.00855</a></p><p>Kamel
        S, Yee J. Figure 7 raw data: Effect of variable exposure to PTHrP (1-36) on
        bone nodules and AP activity in high plating density cultures. Published online
        2013:9991 Bytes. doi:<a href=\"https://doi.org/10.6084/M9.FIGSHARE.154685\">10.6084/M9.FIGSHARE.154685</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ New DataCite / ORCID Integration Tool ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/new-datacite-orcid-integration-tool/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw1y</id>\n        <published>2013-05-18T00:00:00.000+00:00</published>\n\t\t<updated>2023-09-07T12:55:04.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>A <a href=\"https://web.archive.org/web/20171029102032/http://datacite.labs.orcid-eu.org/\">new
        service</a> allows researchers to add research datasets \u2013 and other content
        with DataCite DOIs, including all <a href=\"https://web.archive.org/web/20171029102032/http://figshare.com/\">figshare</a>
        content \u2013 to their <a href=\"https://web.archive.org/web/20171029102032/http://about.orcid.org/\">ORCID</a>
        profile by integrating with the <a href=\"https://search.datacite.org\">DataCite
        Metadata Store</a>. The tool is an adaption (or fork) of the <a href=\"https://search.crossref.org/\"
        rel=\"noreferrer\">CrossRef Metadata Search</a> developed by <a href=\"https://web.archive.org/web/20171029102032/https://twitter.com/karlward\">Karl
        Ward</a>, and was developed by <a href=\"https://web.archive.org/web/20171029102032/https://twitter.com/gthorisson\">Gudmundur
        Thorisson</a> and myself as part of work in the EU-funded <a href=\"https://web.archive.org/web/20171029102032/http://odin-project.eu/\">ODIN
        project</a>. More details can be found <a href=\"https://web.archive.org/web/20171029102032/http://odin-project.eu/2013/05/13/new-orcid-integrated-data-citation-tool/\">here</a>.</p>\n<p>There
        are many things I like about this new DataCite/ORCID integration tool:</p>\n<ul><li>it
        makes it easier for researchers to get credit for their research outputs.</li><li>it
        shows the value of persistent identifiers for data, publications and people,
        and linking them together</li><li>it shows the Creative Commons licenses for
        DataCite content where this info is available, facilitating reuse of content</li><li>it
        demonstrates the power of open source (thanks CrossRef!), open collaboration,
        standard REST APIs, and lightweight programming (Sinatra/Ruby) and deployment
        (Vagrant, Amazon EC2, Rackspace) tools</li><li>it shows that we don\u2019t
        need a single \u2013 often closed \u2013 system, but open services that build
        on top of each other using accepted community standards. Tools using the ORCID
        API can immediately reuse the new DataCite content, altmetrics provided by
        <a href=\"https://impactstory.org/\">ImpactStory</a> are a good example</li></ul>\n<p>I
        want to explore some of these ideas in the panel <strong>Attribution: Managing
        Provenance, Ethics, and Metrics</strong> at the combined <a href=\"https://web.archive.org/web/20171029102032/http://orcid.org/orcid-outreach-meeting-symposium-and-codefest-may-2013\">ORCID/Dryad
        Meeting</a> in Oxford next Thursday.</p>\n<h2 id=\"acknowledgments\">Acknowledgments</h2>\n<p>This
        work was funded by the European Union\u2019s Horizon Seventh Framework programme
        under <a href=\"https://cordis.europa.eu/project/id/312788\" rel=\"noreferrer\">grant
        agreement No.&nbsp;312788</a>.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Announcing Markdown for Science Workshop
        on June 8th ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/announcing-markdown-for-science-workshop-on-june-8th/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw1e</id>\n        <published>2013-05-08T17:20:00.000+00:00</published>\n\t\t<updated>2022-08-19T09:04:19.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>On Saturday,
        June 8th \u2013 exactly a month from today \u2013 the PLOS San Francisco offices
        will host a workshop/hackathon about using markdown for science. A lot of
        people are experimenting with markdown for authoring scientific articles \u2013
        see blog posts <a href=\"http://blog.yoavram.com/markx/\">here</a>, <a href=\"http://inundata.org/2012/06/01/markdown-and-the-future-of-collaborative-manuscript-writing/\">here</a>
        or my post <a href=\"https://blog.front-matter.io/posts/a-call-for-scholarly-markdown/\">here</a>,
        and the scientific manuscript <a href=\"https://github.com/weecology/data-sharing-paper/\">here</a>.</p><p>Markdown
        is a simple markup language for text, and is primarily used for HTML content
        on the web, but can also be converted to PDF, LaTeX and others. One challenge
        with markdown is that there are a number of slightly different \u201Cflavors\u201D
        out there, from the original markdown to multimarkdown, github-flavored markdown
        and pandoc. Some of the advanced formatting of scientific documents \u2013
        tables, citations, math \u2013 is still a challenge for markdown.</p><p>Will
        markdown become our next authoring format for scientific content? Will there
        be yet another flavor, scholarly markdown? How will markdown writing tools
        be different from LaTeX tools or Microsoft Word? If you care about any of
        these questions and are in or near San Francisco, join us on for all full
        day on June 8th. Free registration is open at <a href=\"http://mdsci13.eventbrite.com/\">http://mdsci13.eventbrite.com</a>.
        We are collecting workshop ideas at <a href=\"https://github.com/karthikram/markdown_science/wiki/workshop\">https://github.com/karthikram/markdown_science/wiki/workshop</a>,
        the Twitter hashtag is #mdsci13.</p><p>This event is organized by <a href=\"http://twitter.com/houshuang\">Stian
        H\xE5klev</a> and myself, with generous support by a <a href=\"http://www.force11.org/node/4358\">1K
        Challenge prize from Force11</a>, and hosting provided by PLOS.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Baby steps toward better metrics ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/baby-steps-toward-better-metrics/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw21</id>\n        <published>2013-04-16T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-29T19:53:08.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/DALL-E-2022-08-29-21.52.35---a-garden-gnome-with-umbrella-doing-baby-steps-on-a-rope-between-buildings--digital-art.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/DALL-E-2022-08-29-21.52.35---a-garden-gnome-with-umbrella-doing-baby-steps-on-a-rope-between-buildings--digital-art.png\"></p><p><a
        href=\"https://web.archive.org/web/20171029102027/http://article-level-metrics.plos.org/\">Article-Level
        Metrics</a> provide new ways to look at the impact of scholarly research.
        Two important concepts are a) to track metrics for individual scholarly articles
        instead of using numbers aggregated by journal, and b) to go beyond citations
        and also include usage stats and altmetrics.</p><p>Article-Level Metrics is
        also doing something else: instead of tracking impact by year, it looks at
        usage, altmetrics and citations in real-time. There might have been technical
        reasons to do so 20 years ago, but there really is no longer any reason why
        scholarly impact should be tracked on a yearly basis in 2013. Unfortunately
        there is one big stumbling block:</p><blockquote><em><em>The publication date
        of a scholarly article is often difficult or impossible to obtain. Publication
        year may be the only available information.</em></em></blockquote><p>A good
        example is CrossRef. They provide a lot of interesting metadata about an article
        and make this information available in <a href=\"https://web.archive.org/web/20171029102027/http://search.crossref.org/\">a
        very nice search interface</a>. But they only require the publisher to provide
        the publication year, information about the publication month and day is optional.
        There are many other examples of journals and services that just can\u2019t
        tell you when exactly an article was published. This might have made sense
        when periodicals were printed on paper, but doesn\u2019t work for digital
        content.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ You should be able to install my software
        in less than one hour \u2013 or why DevOps is important ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/you-should-be-able-to-install-my-software-in-less-than-one-hour-or-why-devops-is-important/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw20</id>\n        <published>2013-04-14T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-13T14:53:10.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Cameron Neylon yesterday wrote
        a<a href=\"https://web.archive.org/web/20171029102958/http://cameronneylon.net/blog/whats-the-right-model-for-shared-scholarly-communications-infrastructure/\">
        great blog post</a> about appropriate business models for shared scholarly
        communications infrastructure. This is an area I have also been <a href=\"https://web.archive.org/web/20171029102958/http://blogs.plos.org/mfenner/2013/03/20/the-price-of-innovation-my-thoughts-for-beyond-the-pdf/\">thinking
        about a lot recently</a>, and in this post I want to add a technical perspective
        (and an announcement) to the discussion.</p><p><a href=\"https://web.archive.org/web/20171029102958/http://en.wikipedia.org/wiki/DevOps\">DevOps</a>
        is an important trend that brings software development and administration
        of IT infrastructure closer together. Agile software development, server virtualization,
        cloud infrastructure and software automation tools such as <a href=\"https://web.archive.org/web/20171029102958/http://www.opscode.com/chef/\">Chef</a>,
        <a href=\"https://web.archive.org/web/20171029102958/https://puppetlabs.com/\">Puppet</a>
        or <a href=\"https://web.archive.org/web/20171029102958/http://cfengine.com/\">CFEngine</a>
        are an important pars of DevOps, but it is really the collaborative aspect
        of IT administrators working much closer with software developers what defines
        DevOps. The end result is often <a href=\"https://web.archive.org/web/20171029102958/http://readwrite.com/2013/03/27/devops-booms-in-the-enterprise\">faster
        and more stable software releases</a>, and that is what is users and customers
        care about.</p><p>This makes DevOps particularly relevant for all areas where
        innovation is important, and that of course includes <a href=\"https://web.archive.org/web/20171029102958/http://science.okfn.org/tools-for-open-science/\">tools
        and services for Open Science</a>. We not only need infrastructure that facilitates
        software development (with services like Github, among many others), but we
        also have to streamline IT administration. The question is not whether you
        do your development in Java, Python, Ruby, PHP or Javascript, but how well
        you integrate your software development and IT administration. The shift towards
        web-based tools has centralized software installation and updates, but these
        web-based services are becoming increasingly complex and difficult to set
        up and administer. Running an institutional respository, research information
        system or a journal is a complex task. The software may be freely available
        as open source (e.g. <a href=\"https://web.archive.org/web/20171029102958/http://www.dspace.org/\">Dspace</a>,
        <a href=\"https://web.archive.org/web/20171029102958/http://vivoweb.org/\">VIVO</a>
        or <a href=\"https://web.archive.org/web/20171029102958/http://pkp.sfu.ca/?q=ojs\">Open
        Journal Systems</a>), but the resources required to run such a service still
        make this a big investment.</p><p>Two solutions to this dilemma are to pay
        either a vendor for installation and maintenance, or to use the software as
        a service (SaaS) that is hosted somewhere else. Why these two options are
        popular, they may not always be the best choices because they mean that you
        are locked in to a particular vendor or service provider, and that you may
        give expertise and direct access to your data away. I believe that these are
        helpful approaches for auxillary services, but that ideally the core services
        of a library, publisher or other provider of scientific infrastructure should
        not be outsourced. Developing software for scientific infrastructure that
        you want organizations to install locally should therefore always include
        work on integration with IT infrastructure, and just providing manual installation
        instructions isn\u2019t good enough anymore.</p><p><a href=\"https://web.archive.org/web/20171029102958/http://blogs.plos.org/mfenner/tag/article-level-metrics/\">Article-Level
        Metrics</a> (ALM) and the related altmetrics are becoming increasingly popular.
        The collection and display of this information is a complex process, as it
        requires the integration of information from several upstream APIs which may
        be temporarily unavailable, have changed their data format, or put up restrictions
        on how you can use the data. In turn this information has to be processed
        and aggregated, and then reliably be provided to downstream users. This kind
        of information gathering fits perfectly with a service provider model, and
        organizations such as <a href=\"https://web.archive.org/web/20171029102958/http://www.altmetric.com/\">Altmetric</a>,
        <a href=\"https://web.archive.org/web/20171029102958/http://impactstory.org/\">ImpactStory</a>
        and <a href=\"https://web.archive.org/web/20171029102958/http://www.plumanalytics.com/\">Plum
        Analytics</a>. PLOS is collecting and displaying this information with <a
        href=\"https://web.archive.org/web/20171029102958/https://github.com/articlemetrics/alm\">its
        own tool</a>. The simple reason is that PLOS started doing this several years
        before the services above became available, and none of them currently provide
        the same comprehensive set of information about citations, usage stats and
        altmetrics (although there are of course a lot of things they do better than
        the PLOS ALM application).</p><p>But there is also the question of whether
        Article-Level Metrics are a core service for every publisher and are best
        collected in-house. This not only makes it easier to collect information from
        some sources (e.g. usage stats or CrossRef citations), but also gives unrestricted
        access to the data in real-time. When I took over as technical lead for the
        PLOS Article-Level Metrics project last May, I therefore not only worked on
        improving the ALM application for PLOS, but we are also working hard on making
        it easier for other publishers to install and use the application. We want
        to provide an attractive alternative for organizations for which the service
        provider model is not the best option.</p><p>To that end I want to announce
        the latest feature which allows the automated installation of the PLOS ALM
        application on an Amazon Web Services (AWS) EC2 instance. This option is great
        not only for setting up an ALM production service, but because of the EC2
        pricing model by hour (about $1 a day for a small EC2 instance) without setup
        costs is a great way to test-drive the application for a publisher, to analyze
        a particular set of papers from different publishers for a research project,
        or to set up a PLOS ALM server for a hackathon or workshop.</p><figure class=\"kg-card
        kg-image-card\"><img src=\"https://web.archive.org/web/20171029102958im_/http://blogs.plos.org/mfenner/files/2013/04/vagrant_aws.png\"
        class=\"kg-image\" alt=\"vagrant_aws\" loading=\"lazy\"></figure><p>There
        are of course many options to automate software deployment on a production
        server, including the PaaS (platform as a service) providers <a href=\"https://web.archive.org/web/20171029102958/https://www.heroku.com/\">Heroku</a>,
        <a href=\"https://web.archive.org/web/20171029102958/http://www.cloudfoundry.com/\">CloudFoundry</a>
        and <a href=\"https://web.archive.org/web/20171029102958/https://www.openshift.com/\">OpenShift</a>,
        and the recently announced <a href=\"https://web.archive.org/web/20171029102958/http://aws.amazon.com/de/opsworks/\">Amazon
        OpsWorks</a>. I am a big fan of the <a href=\"https://web.archive.org/web/20171029102958/http://www.vagrantup.com/\">Vagrant</a>
        software development tool in combination with Chef for automation, and in
        March Vagrant added <a href=\"https://web.archive.org/web/20171029102958/http://www.hashicorp.com/blog/preview-vagrant-aws.html\">support
        for Amazon AWS</a>. This makes deployment of the PLOS ALM application to AWS
        really simple:</p><ol><li>Install Vagrant and the <a href=\"https://web.archive.org/web/20171029102958/https://github.com/mitchellh/vagrant-aws\">vagrant-aws
        plugin</a></li><li>Setup an Amazon Web Services Account</li><li>Check out
        the <a href=\"https://web.archive.org/web/20171029102958/https://github.com/articlemetrics/alm\">PLOS
        ALM source code</a> from Github</li><li>run the command <strong>vagrant up
        \u2013provider aws</strong></li></ol><p>Step #4 took 898 sec or about 15 min
        on my computer (see screenshot), and at the end I had a PLOS ALM server where
        I could access the admin dashboard via the web interface. If you are familiar
        with Amazon Web Services \u2013 you have to think about \_the right size for
        the EC2 instance, an appropriate AMI, security groups, elastic IPs, and DNS
        service \u2013 then the whole process should be done in well under an hour.
        I will use this instance to load and analyze some articles from a publisher
        for a presentation next week. When I\u2019m done, another command (<strong>vagrant
        destroy</strong>) will destroy this server and Amazon will stop billing me.
        During testing I have created and destroyed many servers, and the <a href=\"https://web.archive.org/web/20171029102958/http://www.hashicorp.com/blog/preview-vagrant-aws.html\">vagrant-aws
        video</a> shows you how easy this process is.</p><p>At this stage the installation
        process is working (and has been working for a local Virtualbox install for
        many months), but needs testing and documentation. I therefore invite everyone
        interested in testing this out to contact me so that we can make this well-documented
        and working reliably.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Mendeley and Elsevier ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/mendeley-and-elsevier/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw1z</id>\n
        \       <published>2013-04-11T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T17:22:10.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Earlier this week the rumors
        that started in January became official: <a href=\"https://web.archive.org/web/20170731044726/http://blog.mendeley.com/start-up-life/team-mendeley-is-joining-elsevier/\">Elsevier
        is buying Mendeley</a> (see also <a href=\"https://web.archive.org/web/20170731044726/http://elsevierconnect.com/elsevier-welcomes-mendeley/\">here</a>).
        A <a href=\"https://web.archive.org/web/20170731044726/http://enjoythedisruption.com/post/47527556151/my-thoughts-on-mendeley-elsevier-why-i-left-to-start\">lot
        has been written</a> about this announcement, in particular about the fear
        that Mendeley as a product and organization will turn into something not as
        open and collaborative as before.</p><p>I first met Victor and Jan from Mendeley
        in 2008 and did an <a href=\"https://web.archive.org/web/20170731044726/http://blogs.plos.org/mfenner/2008/09/05/interview_with_victor_henning_from_mendeley/\">interview
        with Victor</a> in September 2008. We worked together in the organization
        of two <a href=\"https://web.archive.org/web/20170731044726/http://www.scienceonlinelondon.org/\">Science
        Online London conferences</a> (2009 and 2010, together with Nature.com and
        others), and my current job started with an entry for an <a href=\"https://web.archive.org/web/20170731044726/http://blog.mendeley.com/design-research-tools/winners-of-the-first-binary-battle-apps-for-science-contest/\">API
        programming contest</a> co-organized by PLOS and Mendeley, with the <a href=\"https://web.archive.org/web/20170731044726/http://blogs.plos.org/mfenner/2011/09/28/announcing-sciencecard/\">first
        lines of code written</a> in the Mendeley offices during the Science Online
        London 2011 hackathon. I wish Mendeley all the best with their new parent.</p><p>What
        this acquisition signals to me is that commercial publishers are now moving
        into the software tools for scientists business at full speed. They have always
        done this, but with <a href=\"https://web.archive.org/web/20170731044726/http://www.readcube.com/\">ReadCube</a>
        by Digital Science (a Nature Publishing Group sister company) in 2011, the
        acquisition of <a href=\"https://web.archive.org/web/20170731044726/http://www.papersapp.com/\">Papers</a>
        by Springer last year and now Mendeley, reference management now often means
        using a tool owned by a publisher \u2013 this market used to be dominated
        academic software such as <a href=\"https://web.archive.org/web/20170731044726/http://www.zotero.org/\">Zotero</a>
        and commercial software vendors such as Thomson Reuters (<a href=\"https://web.archive.org/web/20170731044726/http://endnote.com/\">Endnote</a>)
        or ProQuest (<a href=\"https://web.archive.org/web/20170731044726/http://www.refworks.com/\">RefWorks</a>).</p><p>For
        me this trend signals that publishers have realized that we are moving into
        an Open Access publishing model, which in contrast to subscription publishing
        is not about owning the content, but about providing valuable services around
        content that is free to read and reuse.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Comment: the case for open preprints in
        biology ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/comment-the-case-for-open-preprints-in-biology/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw22</id>\n        <published>2013-03-30T00:00:00.000+00:00</published>\n\t\t<updated>2023-07-10T15:37:21.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/gentil-beccot-1.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/gentil-beccot-1.png\"></p><p>Last
        week Philippe Desjardins-Prouly et al. published the article <a href=\"https://doi.org/10.6084/M9.FIGSHARE.655710\">The
        case for open preprints in biology</a> \u2013 naturally as a preprint on figshare
        (later also published as full paper). The article sees preprint servers as
        a great opportunity for open science, and discusses the status of preprints
        in the biological sciences. In this blog post I want to add some comments
        to the text.</p><h2 id=\"e-biomed\">E-BIOMED</h2><p>What is now PubMed Central
        <a href=\"https://web.archive.org/web/20170731034700/http://www.nih.gov/about/director/pubmedcentral/ebiomedarch.htm\">started
        out as E-BIOMED in 1999</a> and initially was envisioned to include a repository
        for preprints. It is important to look back at what happened then, and why
        the preprint repository was dropped from what then became PubMed Central.
        Harold Varmus talks a bit about this in this <a href=\"https://web.archive.org/web/20170731034700/http://poynder.blogspot.de/2006/06/interview-with-harold-varmus.html\">interview</a>
        from 2006.</p><h2 id=\"nature-precedings\">Nature Precedings</h2><p>The article
        talks about why biologists have not developed a culture of sharing preprints.
        It would be good to mention <a href=\"https://web.archive.org/web/20170731034700/http://precedings.nature.com/\">Nature
        Precedings</a>, a preprint server for the life sciences started in 2007 that
        stopped taking new submissions in 2012. <a href=\"https://web.archive.org/web/20170731034700/http://retractionwatch.wordpress.com/2012/03/30/nature-precedings-to-stop-accepting-submissions-next-week-after-finding-model-unsustainable/\">This
        blog post</a> on RetractionWatch cites the announcement by Nature Publishing
        Group (which doesn\u2019t explain why the service was shut down), and there
        are a good number of interesting comments.</p><h2 id=\"ssrn\">SSRN</h2><p>Preprints
        in other disciplines are mentioned in the text, in particular ArXiv, but also
        RePEc. I would also include <strong>SSRN</strong> (<a href=\"https://web.archive.org/web/20170731034700/http://www.ssrn.com/\">Social
        Science Research Network</a>), which uses a different model, but is as important
        for the working paper and preprint culture in the social sciences as ArXiV
        is in physics/mathematics.</p><h2 id=\"google-scholar-metrics\">Google Scholar
        Metrics</h2><p>In April 2012 Google launched <a href=\"https://web.archive.org/web/20170731034700/http://scholar.google.com/citations?view_op=top_venues&amp;hl=en&amp;vq=en\">Google
        Scholar Metrics</a>, listing the top 100 publications (according to their
        h5-index) in several disciplines. Six out of the top 10 publications in physics/mathematics
        are ArXiV sections (arXiv Astrophysics (astro-ph) is #2), the <a href=\"https://web.archive.org/web/20170731034700/http://www.iza.org/en/webcontent/publications/papers\">IZA
        Discussion Papers</a> are #1 in Social Sciences, and the <a href=\"https://web.archive.org/web/20170731034700/http://www.nber.org/papers.html\">NBER
        Working Papers</a> are #1 in Economics, and arXiv Astrophysics (astro-ph)
        is #12 on the top 100 list for all disciplines (#1-5 are journals in biology
        and medicine: <em>Nature</em>, <em>New England Journal of Medicine</em>, <em>Science</em>,
        <em>Lancet</em>, <em>Cell</em>). All these metrics are a strong indicator
        that preprints can be highly cited.</p><h2 id=\"citation-advantage-of-preprints\">Citation
        Advantage of Preprints</h2><p>Anne Gentil-Beccot et al. have written a nice
        paper (of course <a href=\"https://doi.org/10.48550/ARXIV.0906.5418\">available
        as preprint</a>) that shows that publication as preprint now only increases
        the citation rate for the corresponding peer-reviewed article published later,
        but also leads to much faster citations, with a peak immediately after publication.</p><figure
        class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/gentil-beccot.png\"
        class=\"kg-image\" alt=\"gentil-beccot\" loading=\"lazy\" width=\"500\" height=\"319\"><figcaption>Average
        number of citations per article per month as a function of the time of the
        citation relative to the time of publication. From <a href=\"https://doi.org/10.48550/ARXIV.0906.5418\">http://arxiv.org/abs/0906.5418</a></figcaption></figure><h2
        id=\"scoap3\">SCOAP3</h2><p>The Sponsoring Consortium for Open Access Publications
        in High Energy Physics (<a href=\"https://scoap3.org/\">SCOAP3</a>) is working
        on turning the majority of peer-reviewed publications in high energy physics
        into gold open access. It is important to understand that the high energy
        physics community feels that they need peer-reviewed journal articles in addition
        to ArXiv.</p><h2 id=\"preprint-culture-in-clinical-medicine\">Preprint Culture
        in Clinical Medicine</h2><p>It is a little known fact that there is a strong
        preprint culture in clinical medicine. I have written about this topic in
        <a href=\"https://doi.org/10.53731/r294649-6f79289-8cw89\">October 2010</a>.
        Clinical trials have to be registered before starting the trial, and information
        about the trial is publicly available in <a href=\"https://web.archive.org/web/20170731034700/http://clinicaltrials.gov/\">clinicaltrials.gov</a>
        and other registries. Results are presented in conferences (as poster or oral
        presentation), at which stage it becomes public information. The peer-reviewed
        paper \u2013 with a few exceptions \u2013 follows much later, sometimes even
        after drug approval by the FDA (in the blog post I used the <a href=\"https://doi.org/10.1016/S0140-6736(10)61389-X\">TROPIC</a>
        trial as example). The problem is of course that information in oral presentations
        and posters is incomplete and difficult to find. But publication of a clinical
        trial in a peer-reviewed journal is more about giving credit to the researchers
        involved (similar to SCOAP3 in high energy physics) than about spreading the
        knowledge. Peer review is not an appropriate filter for whether or not a new
        drug or drug combination should be used to treat patients \u2013 the approval
        process by regulatory authorities is much more extensive than any peer review
        can ever be.</p><h2 id=\"preprint-culture-in-biology\">Preprint culture in
        Biology</h2><p>The paper mentions several reasons why the field of biology
        has essentially no preprint culture. One argument against preprints is that
        it would be easier to steal ideas. Although I agree with the authors that
        preprints are a great way to establish precedence, there is a big difference
        between research based on years of work using expensive equipment (as is often
        the case in high energy physics but also some other fields), and research
        that can be reproduced in a few weeks. In the latter case it is possible that
        someone else is faster in publishing the peer-reviewed paper. Another difference
        is the community: \u201Cstealing\u201D ideas from someone else is probably
        more difficult in smaller scientific communities, and some scientific communities
        are more competitive and less collaborative than others.</p><p>Another concern
        about preprints raised in the paper is the Ingelfinger rule, i.e. the uncertainty
        that a journal would accept a manuscript if already published as a preprint.
        This concern is fortunately unfounded regarding most publishers, and the paper
        includes a table listing the preprint policies of important publishers in
        biology.</p><p>I would like to add two other reasons why the preprint culture
        is probably not established in biology. Preprints are competition for the
        peer-reviewed journal article and scholarly publishers might not be particularly
        interested in encouraging a preprint culture. A lot has fortunately changed
        since E-BIOMED in 1999.</p><p>Finally, whereas some disciplines use preprints
        and working papers to communicate, in biology the preferred way to communicate
        research findings before publication of a peer-reviewed paper is the oral
        presentation. What we may need is a service that makes it easy to upload and
        share scientific presentations. We for example already have Slideshare, Speaker
        Deck as generic tools, and SciVee, figshare aimed at scientists. Speaker Deck
        <a href=\"https://blog.front-matter.io/posts/speaker-deck-for-sharing-presentations/\">is
        currently my favorite tool</a> and is a Github product (Github has been mentioned
        in the manuscript as an option for hosting preprints). Maybe what is missing
        is a killer combination of features in a new or existing service \u2013 persistent
        identifiers, uploading of background material (text, data, software, video)
        in addition to the slides, non-textual search, cooperation with conference
        organizers, etc. \u2013 for presentation sharing to take off as a way to establish
        a preprint culture in biology.</p><p><em>Update 4/4/13: Yesterday PeerJ launched
        a new preprint service for life sciences research. Read <a href=\"https://blogs.scientificamerican.com/guest-blog/2013/04/03/who-killed-the-preprint-and-could-it-make-a-return/\">this
        blog post</a> for details, and this <a href=\"https://web.archive.org/web/20170731034700/http://blog.mendeley.com/open-access/is-the-time-right-for-a-preprint-server-for-life-science/\">post</a>
        on the Mendeley blog.</em></p><h3 id=\"references\">References</h3><p>Desjardins-Proulx
        P, White EP, Adamson J, Ram K, Poisot T, Gravel D. The case for open preprints
        in biology. Published online 2013:532508 Bytes. doi:<a href=\"https://doi.org/10.6084/M9.FIGSHARE.655710\">10.6084/M9.FIGSHARE.655710</a></p><p>Desjardins-Proulx
        P, White EP, Adamson JJ, Ram K, Poisot T, Gravel D. The Case for Open Preprints
        in Biology. <em>PLoS Biol</em>. 2013;11(5):e1001563. doi:<a href=\"https://doi.org/10.1371/journal.pbio.1001563\">10.1371/journal.pbio.1001563</a></p><p>Gentil-Beccot
        A, Mele S, Brooks T. Citing and Reading Behaviours in High-Energy Physics.
        How a Community Stopped Worrying about Journals and Learned to Love Repositories.
        Published online 2009. doi:<a href=\"https://doi.org/10.48550/ARXIV.0906.5418\">10.48550/ARXIV.0906.5418</a></p><p>Fenner
        M. In which I suggest a preprint archive for clinical trials. Published online
        October 16, 2010. doi:<a href=\"https://doi.org/10.53731/r294649-6f79289-8cw89\">10.53731/r294649-6f79289-8cw89</a></p><p>De
        Bono JS, Oudard S, Ozguroglu M, et al. Prednisone plus cabazitaxel or mitoxantrone
        for metastatic castration-resistant prostate cancer progressing after docetaxel
        treatment: a randomised open-label trial. <em>The Lancet</em>. 2010;376(9747):1147-1154.
        doi:<a href=\"https://doi.org/10.1016/S0140-6736(10)61389-X\">10.1016/S0140-6736(10)61389-X</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Using d3.js to visualize Article-Level Metrics
        over time ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/using-d3-js-to-visualize-article-level-metrics-over-time/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw24</id>\n        <published>2013-03-26T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T08:27:40.000+00:00</updated>\n\t\t<category
        term=\"Chart\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/sparklines4-e1364338936408.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/sparklines4-e1364338936408.png\"></p><p>PLOS
        Article-Level Metrics (ALM) are a great set of data (available via API and
        as <a href=\"https://web.archive.org/web/20170731170128/http://article-level-metrics.plos.org/plos-alm-data/\">monthly
        data dump</a>) for some nice data visualizations. I have recently become a
        big fan of the <a href=\"https://web.archive.org/web/20170731170128/http://d3js.org/\">d3.js</a>
        javascript library, and have now used d3 to look at some ALM data over time.</p><p>I
        like simple visualizations without too many labels or axes, and wanted to
        do a visualization inspired by <a href=\"https://web.archive.org/web/20170731170128/http://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=0001OR\">sparklines</a>
        ever since we discussed this idea in our <em>altviz</em> breakout group at
        the <a href=\"https://web.archive.org/web/20170731170128/http://article-level-metrics.plos.org/alm-workshop-2012/hackathon/#altviz\">ALM
        workshop hackathon</a> in November 2012 (kudos in particular to Juan Alperin,
        Karthik Ram and Carl Boettiger). In the chart below every column represents
        the numbers for a given month, with alternating colors for the years (the
        article was published November 2009).</p><figure class=\"kg-card kg-image-card
        kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/sparklines4-e1364338936408-1.png\"
        class=\"kg-image\" alt=\"sparklines4\" loading=\"lazy\" width=\"300\" height=\"263\"><figcaption>CiteULike
        bookmarks, usage stats from PLOS website and blog posts for article <strong>Article-Level
        Metrics and the Evolution of Scientific Impact</strong> by month, available
        at <a href=\"https://web.archive.org/web/20170731170128/http://dx.doi.org/10.1371/journal.pbio.1000242\">http://dx.doi.org/10.1371/journal.pbio.1000242</a>.</figcaption></figure><p>You
        can see a pattern that is probably typical for many articles independent of
        the absolute numbers: most pageviews and downloads happen in the weeks after
        publication, as does academic bookmarking and science blogging.</p><p>The
        second example shows a very different pattern. This is not only the <a href=\"https://web.archive.org/web/20170731170128/http://alm.plos.org/sources/counter\">most-downloaded</a>
        PLOS article, but \_the distribution of downloads over time is very different,
        with the number of monthly downloads actually higher the last two years (this
        article was published in August 2005). We also see a few spikes in the usage
        stats, probably indicating events that triggered usage. Academic bookmarking
        was most active from 2009 to 2011 and not right after publication, although
        that might also have to do with the relative popularity of CiteULike over
        time.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/sparklines5-500x262.png\"
        class=\"kg-image\" alt=\"sparklines5\" loading=\"lazy\" width=\"500\" height=\"262\"><figcaption>CiteULike
        bookmarks, usage stats from PLOS website and blog posts for article <strong>Why
        Most Published Research Findings Are False</strong> by month, available at
        <a href=\"https://web.archive.org/web/20170731170128/http://dx.doi.org/10.1371/journal.pmed.0020124\">http://dx.doi.org/10.1371/journal.pmed.0020124</a>.</figcaption></figure><p>Citation
        data are unfortunately more difficult to get with exact publication dates
        (why is that so difficult?), but we can at least look at CrossRef numbers
        by year for the same article.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/sparklines31-e1364340861413.png\"
        class=\"kg-image\" alt=\"sparklines3\" loading=\"lazy\" width=\"200\" height=\"169\"><figcaption>CiteULike
        bookmarks, usage stats from PLOS website and blog posts for article <strong>Why
        Most Published Research Findings Are False</strong> by year, available at
        <a href=\"https://web.archive.org/web/20170731170128/http://dx.doi.org/10.1371/journal.pmed.0020124\">http://dx.doi.org/10.1371/journal.pmed.0020124</a>.</figcaption></figure><p>The
        citation numbers by year are still increasing (the last bar is for 2013),
        indicating that this article is still of general interest 8 years after publication.
        This would probably be unusual for a life sciences research article, but the
        article is an essay looking at common pitfalls in the statistical analysis
        of research data.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ New version of Article-Level Metrics app
        released ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/new-version-of-article-level-metrics-app-released/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw25</id>\n        <published>2013-03-21T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T17:21:03.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>On Tuesday we released the
        latest version of the <a href=\"https://web.archive.org/web/20170731155505/http://article-level-metrics.plos.org/\">PLOS
        Article-Level Metrics application</a>. As always, the source code is available
        at <a href=\"https://web.archive.org/web/20170731155505/https://github.com/articlemetrics\">Github</a>.
        The changes in this version focus on improving API performance, making it
        easier to install the application, and RSS feeds for the most popular articles
        by source and publication date (e.g. <a href=\"https://web.archive.org/web/20170731155505/http://alm.plos.org/sources/twitter.rss?days=7\">the
        most tweeted papers published in the last 7 days</a>). See the <a href=\"https://web.archive.org/web/20170731155505/https://github.com/articlemetrics/alm/wiki/2.6\">Github
        Wiki page</a>for more details, in the Wiki you also find the development <a
        href=\"https://web.archive.org/web/20170731155505/https://github.com/articlemetrics/alm/wiki/Roadmap\">roadmap</a>
        and the <a href=\"https://web.archive.org/web/20170731155505/https://github.com/articlemetrics/alm/issues\">issue
        tracker</a> for feature suggestions.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ The Price of Innovation \u2013 my Thoughts
        for Beyond the PDF ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/the-price-of-innovation-my-thoughts-for-beyond-the-pdf/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw26</id>\n        <published>2013-03-20T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T08:31:27.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/291798596_dbfcfc26d7_c-1.jpg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/291798596_dbfcfc26d7_c-1.jpg\"></p><p>The
        <a href=\"https://web.archive.org/web/20170731155123/http://www.force11.org/taxonomy/term/27\">Beyond
        the PDF Conference</a> is currently taking place in Amsterdam. Unfortunately,
        I am unable to attend in person this time (I took part in the first Beyond
        the PDF in January 2011), but I was watching the <a href=\"https://web.archive.org/web/20170731155123/http://www.force11.org/beyondthepdf2/live\">livestream</a>
        of the <a href=\"https://web.archive.org/web/20170731155123/http://blogs.plos.org/mfenner/2013/03/20/the-price-of-innovation-my-thoughts-for-beyond-the-pdf/ww.force11.org/Business_Case\">Business
        Case</a> panel discussion yesterday afternoon.</p><p>How to pay for the development
        of new scientific infrastructure and tools is something that I think a lot
        about science moving away from academia to become a developer of scientific
        software last year. I would assume three things:</p><ul><li>there are a lot
        of great ideas out there to improve scholarly communication</li><li>there
        is enough money out there to pay for improvements in scholarly communication</li><li>we
        are frustrated because progress is much slower than we anticipate</li></ul><p>If
        we have enough great ideas and enough money, but don\u2019t see the results
        we expect, something must be going wrong. A simple answer would be that it
        is different people and organizations that have the ideas from those that
        have the money, but I don\u2019t think that this is the reason. My suspicion
        is that there is a deeper problem, and that the approach we take to scholarly
        innovation is broken. Below is how innovation is approached by the major players:</p><ul><li>individual
        scientists and/or software developers come up with great ideas, but don\u2019t
        get past the prototype stage because of limited resources</li><li>academic
        tools and infrastructure are built as part of a funded project (anywhere from
        6 months to a few years), but there are no resources to turn this into a service
        that is persistent beyond the project</li><li>publishers and large academic
        institutions have the resources to build these tools. They are often less
        innovative because of their size</li><li>funders pay for projects (see above),
        but rarely for infrastructure, and they rarely get involved in innovative
        projects themselves</li><li>commercial organizations can quickly bring great
        ideas to market (in particular small startups), but it is often unclear how
        their services are paid for in the long run</li></ul><p>At the end of the
        day it seems that we have a lot of great ideas, but many of them never reach
        critical mass, and an even smaller number has long-term sustainability. I
        can think of a number of great projects that have never gained traction, and
        of a number of great tools and services where I have no idea how their development
        and service is paid for. The idea to get to a large number of users no matter
        what it costs, and figure out the business plan later is popular with internet
        startups, but dangerous when we care about tools we want to still use two
        years from now. Two projects that are not specific to science, but are important
        for science and have made this work are <strong>Wikipedia</strong> and <strong>Github</strong>.
        From the long list of tools for scientists I would not pick <strong>Mendeley</strong>
        or <strong>figshare</strong> (both great services, but still in search of
        sustainability), but <strong>ArXiV</strong> and <strong>Papers</strong>.It
        also doesn\u2019t help that most scientists are a conservative bunch when
        it comes to technology, and that the scientific market is fairly small compared
        to the overall number of users. Another big challenge is to innovate in an
        open environment, i.e. to make the innovation available to as many people
        as possible without barriers of access. Some of my personal conclusions from
        all this are the following:</p><ul><li>we should acknowledge that we have
        an innovation problem, and it is not simply solved by getting more money</li><li>we
        have a collaboration problem, too many people are doing similar things without
        talking to each other and working together</li><li>scientific infrastructure
        and tools cost money. We need the right people to pay (ideally not the individual
        researcher), fair prices and intelligent business models</li><li>funders should
        reconsider how they pay for scientific infrastructure, as the project-based
        approach is broken</li><li>large organizations (commercial, non-commercial
        and academic) should think about their approach to innovation, in particular
        how they support innovation outside of their organization</li></ul><p>You
        can follow the Beyond the PDF <a href=\"https://web.archive.org/web/20170731155123/http://www.force11.org/beyondthepdf2/live\">livestream</a>
        today or follow the Twitter hashtag <a href=\"https://web.archive.org/web/20170731155123/https://twitter.com/search?q=%23btpdf2&amp;src=hash\">#btpdf2</a>.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Some Thoughts on Beyond the Paper ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/some-thoughts-on-beyond-the-paper/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw23</id>\n        <published>2013-03-20T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-31T10:54:59.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Today the journal <em>Nature</em>
        has released a special on the <a href=\"https://web.archive.org/web/20170731155331/http://www.nature.com/news/specials/scipublishing/index.html\">Future
        of Publishing</a>. It includes a lot of interesting reading, but I want to
        focus on the comment <a href=\"https://web.archive.org/web/20170731155331/http://dx.doi.org/10.1038/495437a\">Beyond
        the Paper</a> by Jason Priem. In the comment Jason describes his vision of
        the future of scholarly communication, a future where many of today\u2019s
        roles for articles and journals will be replaced by the <em>decoupled journal</em>
        and online tools taking the lead in dissemination and filtering of scholarly
        content.</p><p>Jason makes a strong case for this vision, and takes his time
        to also discuss the concerns and challenges. He doesn\u2019t have the space
        to discuss in more detail how we get to that future, and in particular what
        the role of researchers, publishers, libraries and funders be in that transition.</p><p>Jason\u2019s
        vision will probably be overwhelming for many researchers, and might not directly
        address what is probably the biggest issue for most researchers: funding for
        grants and jobs is limited, and the processes we use to select for good science
        and good scientists are inefficient and often arbitrary. Most students entering
        graduate school will not be able to have a career in academia, and most academics
        will say that they spend far too much time with evaluations \u2013 of their
        own work and the work of others. It is unclear to me how we can get from the
        current system \u2013 where one misstep such as denied grant or submission
        to the wrong journal can mean the end of a career \u2013 to the system that
        Jason envisions. The current climate doesn\u2019t really foster experimentation
        by researchers and I am interested to understand how researchers can take
        part in this process of change.</p><p>The vision of the decoupled journal
        is very threatening for some of the stakeholders of the current scholarly
        communication ecosystem, in particular publishers and libraries. Every journal
        publisher and library knows that it has to reinvent itself to survive the
        digital transformation, but a vision that is build around a new ecosystem
        of service providers needs to be clear how publishers and libraries can be
        part of the transformation process.</p><p>Lastly, I disagree with the notion
        that <em>today\u2019s publication silos will be replaced by a set of decentralized,
        interoperable services that are built on a core infrastructure of open data
        and evolving standards \u2014 like the Web itself.</em> I would argue that
        both scholarly communication and the web in general have a tendency for centralization,
        and that scientific infrastructure needs to be interoperable first and decentralized
        second. Without a focus on interoperability the future of scholarly communication
        will not be open and in the hands of many, but will be a race to become one
        of the dominant players in this new ecosystem, and we might end up with not
        1000s of libraries and publishers but just a handful of technology companies
        holding the keys to our scientific infrastructure.</p><h2 id=\"references\">References</h2><p>Priem,
        J. (2013). Scholarship: Beyond the paper <em>Nature, 495</em> (7442), 437-440
        DOI: <a href=\"https://web.archive.org/web/20170731155331/http://dx.doi.org/10.1038/495437a\">10.1038/495437a</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Bye-bye Google Reader ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/bye-bye-google-reader/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw27</id>\n
        \       <published>2013-03-14T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T17:20:06.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Yesterday Google announced
        that they will <a href=\"https://web.archive.org/web/20170731151455/http://googleblog.blogspot.de/2013/03/a-second-spring-of-cleaning.html\">shut
        down Google Reader</a> July 1st. In a way this announcement didn\u2019t surprise
        me, as my own use of RSS readers has gone down in favor of news readers such
        as <a href=\"https://web.archive.org/web/20170731151455/http://blogs.plos.org/mfenner/2010/09/05/flipboard-plos-blogs-on-the-ipad/\">Flipboard</a>
        and using Twitter as a discovery tool. And built-in support for RSS had slowly
        been depreciated in web browsers such as Firefox (version 4, 2011) and Safari
        (version 6, 2012).</p><p>Although RSS (and the related Atom) may never have
        caught on with the typical web user, it is an essential tool for scholarly
        content. It is the best format to subscribe to journal table of contents,
        much more suitable than email alerts. <a href=\"https://web.archive.org/web/20170731151455/http://www.journaltocs.ac.uk/\">JournalTOCs</a>
        is a good place to get started, but most publishers prominently display the
        RSS icon. RSS is also great for searches you want to do regularly and is supported
        by PLOS, <a href=\"https://web.archive.org/web/20170731151455/http://www.nlm.nih.gov/bsd/disted/pubmedtutorial/040_060.html\">PubMed</a>,
        and others. Because it is a machine-readable format, it is also used by many
        websites to automatically read in article information. RSS feeds for journal
        table of contents differ in format, but CrossRef in 2009 has posted <a href=\"https://oxford.crossref.org/best_practice/rss/\">recommendations</a>
        for publishers.</p><p>Google Reader is of course only one of many RSS readers,
        so this announcement shouldn\u2019t have any immediate impact. Nevertheless
        it is probably another sign that the web is moving away from RSS, and that
        we should start to think about alternatives for distributing tables of content.
        Or that we should use different strategies for finding interesting articles
        that have recently been published, e.g. follow the article recommendations
        in your social network.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Additional Markdown we need in Scholarly
        Texts ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/additional-markdown-we-need-in-scholarly-texts/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw1f</id>\n        <published>2012-12-18T17:34:00.000+00:00</published>\n\t\t<updated>2022-08-19T07:48:23.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/set-operations-illustrated-with-venn-diagrams.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/set-operations-illustrated-with-venn-diagrams.png\"></p><p>Following
        up from <a href=\"https://blog.front-matter.io/posts/a-call-for-scholarly-markdown/\">my
        post last week</a>, below is a suggested list of features that should be supported
        in documents written in scholarly markdown. Please provide feedback via the
        comments, or by editing the Wiki version I have set up <a href=\"https://github.com/mfenner/scholarly-markdown/wiki\">here</a>.
        Listed are features that go beyond the <a href=\"http://daringfireball.net/projects/markdown/syntax\">standard
        markdown syntax</a>.</p><p>The goals of scholarly markdown are</p><ol><li>to
        support writing of complete scholarly articles,</li><li>don\u2019t make the
        syntax more complicated than it is today, and</li><li>don\u2019t rely on HTML
        as the fallback mechanism.</li></ol><p>In practice this means that scholarly
        markdown should support most, but not all scholarly texts \u2013 documents
        that are heavy in math formulas, have complicated tables, etc. may be better
        written with LaTeX or Microsoft Word. It also means that scholarly markdown
        will probably contain only limited semantic markup, as this is difficult to
        do with a lightweight markup language and much easier with XML or a binary
        file format.</p><h2 id=\"cover-page\">Cover Page</h2><p>Optional metadata
        about a document. Typically used for title, authors (including affiliation),
        and publication date, but should be flexible enough to handle any kind of
        metadata (keywords, copyright, etc.).</p><pre><code>---\nlayout: post\ntitle:
        \"Additional Markdown we need in Scholarly Texts\"\ntags: [markdown]\nauthors:\n
        - name: Martin Fenner\n   orcid: 0000-0003-1419-2405\ncopyright: http://creativecommons.org/licenses/by/3.0/deed.en\n---</code></pre><h2
        id=\"typography\">Typography</h2><p>Scholarly markdown should support superscript
        and subscript text, and should provide an easy way to enter greek \u03B6 letters.</p><h2
        id=\"tables\">Tables</h2><p>Tables should work as anchors (i.e. you can link
        to them) and table captions should support styled text. Unless the table is
        very simple, tables are probably better written as CSV files with another
        tool, and then imported into the scholarly markdown document similar to figures.</p><!--kg-card-begin:
        html--><table style=\"box-sizing: border-box; border-collapse: collapse; border-spacing:
        0px; max-width: 100%; background-color: rgb(255, 255, 255); font-size: 19px;
        font-family: ff-tisa-sans-web-pro, Arial, sans-serif; width: 750px; margin-bottom:
        21px; color: rgb(0, 0, 0); font-style: normal; font-variant-ligatures: normal;
        font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans:
        2; text-align: start; text-transform: none; white-space: normal; widows: 2;
        word-spacing: 0px; -webkit-text-stroke-width: 0px; text-decoration-thickness:
        initial; text-decoration-style: initial; text-decoration-color: initial;\"><caption
        style=\"box-sizing: border-box; text-align: left; vertical-align: top; font-size:
        19px; font-style: italic; line-height: 1.33; margin-bottom: 0.75em;\"><strong
        style=\"box-sizing: border-box; font-weight: bold;\">This is the table caption</strong>.
        We can explain the table here.</caption><colgroup style=\"box-sizing: border-box;\"><col
        style=\"box-sizing: border-box; width: 0px;\"><col style=\"box-sizing: border-box;
        width: 0px;\"><col style=\"box-sizing: border-box; width: 0px;\"></colgroup><thead
        style=\"box-sizing: border-box;\"><tr class=\"header\" style=\"box-sizing:
        border-box;\"><th style=\"box-sizing: border-box; padding: 8px; text-align:
        center; vertical-align: bottom; border-top: 0px; font-weight: bold;\">Centered
        Header</th><th style=\"box-sizing: border-box; padding: 8px; text-align: right;
        vertical-align: bottom; border-top: 0px; font-weight: bold;\">Right Aligned</th><th
        style=\"box-sizing: border-box; padding: 8px; text-align: left; vertical-align:
        bottom; border-top: 0px; font-weight: bold;\">Left Aligned</th></tr></thead><tbody
        style=\"box-sizing: border-box;\"><tr class=\"odd\" style=\"box-sizing: border-box;\"><td
        style=\"box-sizing: border-box; padding: 8px; text-align: center; vertical-align:
        top; border-top: 1px solid rgb(221, 221, 221);\">First</td><td style=\"box-sizing:
        border-box; padding: 8px; text-align: right; vertical-align: top; border-top:
        1px solid rgb(221, 221, 221);\">12.0</td><td style=\"box-sizing: border-box;
        padding: 8px; text-align: left; vertical-align: top; border-top: 1px solid
        rgb(221, 221, 221);\">Example of a row that spans multiple lines.</td></tr><tr
        class=\"even\" style=\"box-sizing: border-box;\"><td style=\"box-sizing: border-box;
        padding: 8px; text-align: center; vertical-align: top; border-top: 1px solid
        rgb(221, 221, 221);\">Second</td><td style=\"box-sizing: border-box; padding:
        8px; text-align: right; vertical-align: top; border-top: 1px solid rgb(221,
        221, 221);\">5.0</td><td style=\"box-sizing: border-box; padding: 8px; text-align:
        left; vertical-align: top; border-top: 1px solid rgb(221, 221, 221);\">Here\u2019s
        another one. Note the blank line between rows.</td></tr></tbody></table><!--kg-card-end:
        html--><h2 id=\"figures\">Figures</h2><p>Figures in scholarly works are separated
        from the text, and have a figure caption (which can contain styled text).
        Figures should work as anchors (i.e. you can link to them). Figures can be
        in different file formats, including TIFF and PDF, and those formats have
        to be converted into web-friendly formats when exporting to HTML (e.g. PNG
        and SVG).</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/set-operations-illustrated-with-venn-diagrams-1.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"500\" height=\"500\"><figcaption>Set
        operations illustrated with Venn diagrams. Example taken <a href=\"https://texample.net/tikz/examples/set-operations-illustrated-with-venn-diagrams/\">TeXample.net</a>.</figcaption></figure><h2
        id=\"citations-and-links\">Citations and Links</h2><p>Scholarly articles typically
        don\u2019t have inline links, but rather citations. The external links (both
        scholarly identifiers such as DOIs and regular web URLs) are collected in
        a bibliography at the end of the document, and the citations in the text link
        to this bibliography. This functionality is similar to footnotes.</p><p>Citations
        should include a citation key in the text, e.g. <code>[@kowalczyk2011]</code>,
        parsed as (Kowalczyk &amp; Shankar, 2011), and a separate bibliography file
        in BibTeX (or RIS) format that contains references for all citations. Inserting
        citations and creating the bibliography can best be done with a reference
        manager.</p><p>Cross-links \u2013 i.e. links within a document \u2013 are
        important for scholarly texts. It should be possible to link to section headers
        (e.g. the beginning of the discussion section), figures and tables.</p><h2
        id=\"math\">Math</h2><p>Complicated math is probably best done in a different
        authoring environment, but simple formulas, both inline 2\u203E\u221Ax and
        block elements</p><p>ddxarctan(sin(x2))=\u22122cos(x2)x\u22122+(cos(x2))2</p><p>should
        be supported by scholarly markdown.</p><h2 id=\"comments\">Comments</h2><p>Comments
        are important for multi-author documents and if reviewer feedback should be
        included. Comments should be linked to a particular part of a document to
        provide context, or attached at the end of a document for general comments.
        It would also be helpful to \u201Ccomment out\u201D parts of a document, e.g.
        to indicate parts that are incomplete and need more work. Revisions of a markdown
        document are best handled using a version control system such as git.</p><h2
        id=\"references\">References</h2><p>Kowalczyk, S., &amp; Shankar, K. (2011).
        Data sharing in the sciences. <em>Annual Review of Information Science and
        Technology</em>, <em>45</em>(1), 247\u2013294. Retrieved from <a href=\"http://doi.org/10.1002/aris.2011.1440450113\">http://doi.org/10.1002/aris.2011.1440450113</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ A Call for Scholarly Markdown ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/a-call-for-scholarly-markdown/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw1g</id>\n        <published>2012-12-13T17:37:00.000+00:00</published>\n\t\t<updated>2022-08-13T14:51:59.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Markdown is a lightweight
        markup language, originally created by John Gruber for writing content for
        the web. Other popular lightweight markup languages are Textile and Mediawiki.
        Whereas Mediawiki markup is of course popular thanks to the ubiquitous Wikipedia,
        Markdown seems to have gained momentum among scholars. Markdown really focuses
        on writing content, many of the features of today\u2019s word processors are
        just a distraction (e.g. fonts, line spacing or style sheets). Adding markup
        for document structure (e.g. title, authors or abstract) on the other hand
        is overly complicated with tools such as Microsft Word.</p><p>Fortunately
        or unfortunately there are several versions (or flavors) of Markdown. The
        original specification by John Gruber hasn\u2019t been updated for years.
        Github uses Markdown with some minor modifications. Multimarkdown and Pandoc
        provide features important for scholarly content, e.g. citations, superscript
        and tables.</p><ul><li>Markdown</li><li>Github-flavored Markdown</li><li>Multimarkdown</li><li>Pandoc</li></ul><p>The
        Pandoc flavor of Markdown probably comes closest to the requirements of a
        scholar, but still has limitations, e.g. support for metadata and tables isn\u2019t
        very flexible. I propose that we as a community create a new Scholarly Markdown
        flavor, which takes into account most of the use cases important for scholarly
        content.</p><p>One of the big advantages of Markdown is that the format can
        not only be translated to HTML, but also to other formats, and Pandoc is particularly
        good in translating to and from many different formats. We want to make sure
        that Scholarly Markdown not only translates into nice Scholarly HTML (with
        good support for HTML5 tags relevant for scholars), but also into Microsot
        Word, LaTeX and PDF, as these are the formats typically required by manuscript
        tracking systems.</p><p>Some of the features required for Scholarly Markdown
        include:</p><ul><li>Superscript and subscript</li><li>Highlighting text (supporting
        the HTML tag <code>&lt;mark&gt;</code>)</li><li>Captions for tables and figures
        (with support for the HTML tags <code>&lt;caption&gt;</code> and <code>&lt;figcaption&gt;</code>)</li><li>Support
        for document sections (the HTML5 tags <code>&lt;article&gt;</code>, <code>&lt;header&gt;</code>,
        <code>&lt;footer&gt;</code>, <code>&lt;section&gt;</code>)</li><li>Good table
        support</li><li>Math support</li><li>Good citation support</li><li>Support
        for comments and annotations</li></ul><p>Multimarkdown and Pandoc of course
        already support many of these features. Tables and citations are two examples
        where it is important to not only support them, but support them in a non-intrusive
        way that doesn\u2019t get in the way of the flow of writing.</p><p>BTW, this
        wouldn\u2019t be the first community flavor for Markdown. The screenwriting
        community has done this already with <a href=\"http://fountain.io/\">Fountain</a>.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ ORCID has launched. What\u2019s next? ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/orcid-has-launched-whats-next/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw28</id>\n        <published>2012-10-22T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T08:35:14.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/nametag-500x283.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/nametag-500x283.png\"></p><p>Last
        week has been busy. I went to Berlin for the launch of the <a href=\"https://web.archive.org/web/20170518120701/http://orcid.org/\">Open
        Researcher &amp; Contributor ID (ORCID)</a> service. ORCID allows researchers
        to obtain a persistent identifier that can be used to claim publications and
        other scholarly works. I\u2019m <a href=\"https://web.archive.org/web/20170518120701/http://orcid.org/0000-0003-1419-2405\">0000-0003-1419-2405</a>,
        and we put the ID (and the QR code linking to the profile on the ORCID website)
        on the name tags for the ORCID Outreach Meeting last Wednesday (Geek alert:
        I also have received a T-shirt with my name, ORCID and QR code).</p><p>I was
        invited to work with ORCID in early 2010 after writing about the initiative
        that was started in November 2009 on this blog (<a href=\"https://web.archive.org/web/20170518120701/http://blogs.plos.org/mfenner/2010/01/03/orcid_or_how_to_build_a_unique_identifier_for_scientists_in_10_easy_steps/\">ORCID
        or how to build a unique identifier for scientists in 10 easy steps</a>).
        And now, after three years and a lot of work by a lot of people, ORCID is
        real and everyone can use the system. As a researcher, you can go to the ORCID
        website and register.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/orcid-500x445-1.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"500\" height=\"445\"></figure><p>Obtaining
        a number is of course not very interesting in itself, few people get excited
        about the fact of having a 16-digit unique identifier. What ORCID is really
        about is claiming your publications and other scholarly works, and <strong>Connecting
        Research and Researchers</strong> is the slogan of the organization. In the
        ORCID system you can now claim publications found in the CrossRef database,
        and other work types will be added over time.</p><p>What I\u2019m particularly
        interested in is the claiming of research datasets. Everyone wants to give
        researchers better credit for the data they have produced, transformed and
        annotated, but data citation is still not a widespread practice. I am therefore
        very excited to be involved in the <a href=\"https://web.archive.org/web/20170518120701/http://www.odin-project.eu/\">ORCID
        and DataCite Interoperability Network</a> (ODIN), a EU-funded project that
        had its kickoff meeting last week in Berlin.</p><figure class=\"kg-card kg-image-card\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/odin-500x319.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"500\" height=\"319\"></figure><p>In
        the ODIN project we will work closely with <a href=\"https://web.archive.org/web/20170518120701/http://www.datacite.org/\">DataCite</a>,
        an organization that provides digital object identifiers (DOIs) for research
        data. One of the many things I like about ODIN is that social sciences is
        one of the disciplines where we will build a proof of concept (with the British
        Library, the other discipline is high-energy physics and CERN). We also want
        to understand how to best link researchers, data and publications. <a href=\"https://web.archive.org/web/20170518120701/http://datadryad.org/\">Dryad</a>
        is an ODIN project partner and obviously has a lot of experience linking biological
        datasets to publications, and we will discuss how to integrate ORCID identifiers
        into the workflow.</p><p>Unique identifiers for researchers are of course
        also an essential part of any work on article-level metrics. I <a href=\"https://web.archive.org/web/20170518120701/http://blogs.plos.org/mfenner/2012/06/25/random-notes-from-the-altmetrics12-conference/\">spoke
        about this</a> at the altmetrics12 conference in June, and I\u2019m excited
        that we can now finally start linking things together. <a href=\"https://web.archive.org/web/20170518120701/http://impactstory.org/\">ImpactStory</a>
        was one of the ORCID launch partners, and I demoed their ORCID integration
        last week in Berlin.</p><p><a href=\"https://web.archive.org/web/20170518120701/http://sciencecard.org/\">ScienceCard</a>
        is a fork of the open source <a href=\"https://web.archive.org/web/20170518120701/http://article-level-metrics.plos.org/\">PLOS
        Article-Level Metrics application</a>, and is a project I started <a href=\"https://web.archive.org/web/20170518120701/http://blogs.plos.org/mfenner/2011/11/20/sciencecard-named-finalist-in-mendeleyplos-api-binary-battle/\">about
        a year ago</a>. ScienceCard allows researchers to list all their publications,
        and the metrics associated with them. With the launch of ORCID I was able
        to finally add one important missing piece. Through automatic lookup of the
        ORCID identifier and retrieval of the publications claimed in the ORCID profile
        is has become much easier to create and maintain a ScienceCard profile \u2013
        it shouldn\u2019t take more than 5 min and a few mouse clicks (collecting
        all metrics takes longer because that happens in the background). I added
        ORCID integration to ScienceCard over the weekend, using the <a href=\"https://web.archive.org/web/20170518120701/http://dev.orcid.org/resources\">free
        public ORCID API</a>.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/sciencecard-500x438.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"500\" height=\"438\"></figure><p>ScienceCard
        is a great tool to explore how research impact can be collected and displayed,
        and I appreciate feedback in the form of feature requests and bug reports,
        ideally in the <a href=\"https://web.archive.org/web/20170518120701/https://github.com/mfenner/alm/issues\">GitHub
        issue tracker</a> of the project. This will also provide very valuable feedback
        to improve the PLOS Article-Level Metrics application, as they use almost
        the same code base. The API is for example completely the same, <a href=\"https://web.archive.org/web/20170518120701/https://github.com/ropensci/rplos\">rplos</a>
        and other tools using the PLOS ALM API can be used with ScienceCard by just
        changing the URL. Another example is the <a href=\"https://web.archive.org/web/20170518120701/http://wordpress.org/extend/plugins/plos-alm-widget/\">PLOS
        ALM WordPress Widget</a>, with minor modifications it can be also be used
        with ScienceCard, allowing a researcher to display the metrics for his publications
        from PLOS and other sources on his blog. The upcoming <a href=\"https://web.archive.org/web/20170518120701/https://sites.google.com/site/altmetricsworkshop/\">Altmetrics
        workshop and hackathon</a> (November 1-3 in San Francisco) will be a great
        opportunity to explore this further.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Announcing the ScienceCard Relaunch ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/announcing-the-sciencecard-relaunch/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw29</id>\n        <published>2012-09-19T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-19T07:40:46.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/sciencecard_new-500x312.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/sciencecard_new-500x312.png\"></p><p>Almost
        exactly a year ago (in the hackathon of the Science Online London 2011 conference)
        I <a href=\"https://blog.front-matter.io/posts/announcing-sciencecard/\">started
        the ScienceCard project</a>. ScienceCard is a fork of the Open Source PLOS
        Article-Level Metrics (ALM) code, personalizing the Article-Level Metrics.</p><p>A
        lot has happened in the last 12 months, most importantly that I started to
        work for PLOS as technical lead for the Article-Level Metrics project in May.
        In July, version 2.0 of the PLOS ALM application was released, and the code
        made <a href=\"https://web.archive.org/web/20160402053034/https://github.com/articlemetrics/alm\">available
        on Github</a>. This not only means that everyone can install his own ALM application
        (assuming some familiarity with the Ruby and Rails web framework), but that
        we can fork the code and modify it.</p><p>Although my focus is now clearly
        on improving the PLOS application, it didn\u2019t feel right to shut down
        the <a href=\"https://web.archive.org/web/20160402053034/http://sciencecard.org/\">ScienceCard</a>
        project. I really like the idea of personalized Article-Level Metrics (something
        I spoke about at the <a href=\"https://web.archive.org/web/20160402053034/http://blogs.plos.org/mfenner/2012/06/25/random-notes-from-the-altmetrics12-conference/\">altmetrics12</a>
        conference). So I sat down the last two weekends to upgrade ScienceCard to
        the PLOS ALM 2.0 code (the source code of my fork can be found <a href=\"https://github.com/mfenner/alm\">here</a>).
        With the <a href=\"https://web.archive.org/web/20160402053034/http://about.orcid.org/content/orcid-launch-plan-announced\">imminent
        launch</a> of the Open Researcher &amp; Contributor ID (ORCID) service next
        month I dropped the functionality to get all articles by a particular person
        from Microsoft Academic Search. For now you can add your articles by DOI or
        PubMed ID (currently only articles from PubMed), but you can now also add
        interesting articles not authored by you. This makes ScienceCard a nice tool
        to try out the PLOS ALM code without installing the software. Please remember
        that all metrics are collected in the background, so it can take a few hours
        until they show up for newly added articles.</p><p>ScienceCard also shows
        the power of open source software. Open source doesn\u2019t simply mean free
        software, it means that you can modify the code if your requirements are different.
        For ScienceCard I added authentication via Twitter (required to add articles,
        I don\u2019t want to deal with usernames and passwords), a simple lookup by
        DOI or PubMed ID (something not needed if you are publisher of the article
        and have that information), and comments and likes. Article-Level Metrics
        is not about collecting numbers, it is about capturing the <a href=\"https://web.archive.org/web/20160402053034/http://blogs.bmj.com/bmj/2011/04/06/richard-smith-what-is-post-publication-peer-review/\">activity
        surrounding an article post-publication</a>.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Bye bye Nature Network, welcome SciLogs.com
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/bye-bye-nature-network-welcome-scilogs-com/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw2a</id>\n        <published>2012-07-26T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T08:39:32.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/nature-network.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/nature-network.jpeg\"></p><p>The
        science blogging network Nature Network is <a href=\"http://blogs.nature.com/ofschemesandmemes/2012/07/26/a-new-era-for-the-nature-network-blogs\">moving
        to a new home</a>. Today <a href=\"http://www.scilogs.com/\">SciLogs.com</a>
        launched as a new home for Nature Network bloggers. I have been blogging at
        Nature Network for three years, starting with my first blog post (<a href=\"https://blog.front-matter.io/posts/open_access_may_become_mandatory_for_nih_funded_research/\">Open
        access may become mandatory for NIH-funded research</a>) almost exactly 5
        years ago to the day. My blog moved to PLOS BLOGS in September 2010 and all
        my old Nature Network content can be found here at PLOS BLOGS.</p><p>Blogging
        at Nature Network has changed my life in many ways. Thank you Matt and Corie
        (and later Lou) to make this possible.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ What Users do with PLOS ONE Papers ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/what-users-do-with-plos-one-papers/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw2b</id>\n        <published>2012-07-24T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T08:41:47.000+00:00</updated>\n\t\t<category
        term=\"Chart\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/PLoS-ONE-summary-466x500-1.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/PLoS-ONE-summary-466x500-1.png\"></p><p>Inspired
        by four recent blog posts and their comments (<a href=\"https://web.archive.org/web/20170423155530/http://nsaunders.wordpress.com/2012/07/13/comments-at-journals-websites-just-turn-them-off/\">Comments
        at journal websites: just turn them off</a>, <a href=\"https://web.archive.org/web/20170423155530/http://figshare.com/blog/Open_Access_and_The_Dramatic_Growth_of_PLoS_ONE/41\">Open
        Access and The Dramatic Growth of PLoS ONE</a>, <a href=\"https://web.archive.org/web/20170423155530/http://blogs.plos.org/everyone/2012/07/23/no-comment/\">No
        Comment?</a>, <a href=\"https://web.archive.org/web/20170423155530/http://perlsteinlab.com/round-table/if-you-email-it-they-will-comment\">If
        you email it, they will comment</a>), I created a graphic to show what users
        do with PLoS ONE papers. As always, the data behind the graphic are <a href=\"https://web.archive.org/web/20170423155530/http://www.plosone.org/static/almInfo.action\">openly
        available</a>. I think that the number of times a paper is informally discussed
        (comments, Facebook, science blogs, etc.) should be much larger compared to
        the number of formal citations. The challenge is of course to have technology
        that captures all these discussions \u2013 this is much more difficult than
        for bookmarks or citations, and is obviously what <a href=\"https://web.archive.org/web/20170423155530/http://altmetrics.org/manifesto/\">altmetrics</a>
        is all about. The blog posts I link to above also express another feeling:
        that there are still too many barriers for scientists to take part in the
        informal discussion of scholarly research on the web, in particular as comments
        on journal websites. Hat tip to <a href=\"https://web.archive.org/web/20170423155530/http://www.davidmccandless.com/\">David
        McCandless</a> for inspiration.</p><p><em>Update 08/02/12: The publication
        of the dataset used in this chart was delayed, but the data are now available
        at the <a href=\"https://web.archive.org/web/20170423155530/http://www.plosone.org/static/almInfo.action\">link</a>
        provided.</em></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Neelie Kroes talks Open Science ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/neelie-kroes-talks-open-science/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw2c</id>\n        <published>2012-07-21T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T17:16:45.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Earlier this week the European
        Commission <a href=\"https://blogs.ec.europa.eu/neelie-kroes/open-science/\">announced</a>
        new measures towards open science. As part of the announcement interviews
        of three scientists with European Commission Vice President Neelie Kroes were
        posted on YouTube. Here is a summary:</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ More fun with Visualizations ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/more-fun-with-visualizations/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw2d</id>\n        <published>2012-07-20T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T09:20:10.000+00:00</updated>\n\t\t<category
        term=\"Chart\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/dotchart2-500x386.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/dotchart2-500x386.png\"></p><p>This
        has been another week working on visualizations. I have summarised some of
        the results in a <a href=\"https://web.archive.org/web/20160528080207/http://api.plos.org/2012/07/20/example-visualizations-using-the-plos-search-and-alm-apis/\">blog
        post</a> over at the PLoS API website. One of my current favorites is the
        dot chart. PLoS Computational Biology publishes a <a href=\"https://web.archive.org/web/20160528080207/http://www.ploscollections.org/article/browseIssue.action?issue=info:doi/10.1371/issue.pcol.v03.i01\">collection
        of Ten Simple Rules</a>. The dot chart below summarizes the HTML pageviews,
        PDF downloads and Mendeley readers for this collection.</p><p>On Wednesday
        I gave a presentation about Article-Level Metrics, using many of the same
        visualizations. You can find the slides over at <a href=\"https://web.archive.org/web/20160528080207/https://speakerdeck.com/u/mfenner/p/article-level-metrics\">Speaker
        Deck</a> (my new favorite to upload presentation slides).</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Europe PubMed Central coming in November
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/europe-pubmed-central-coming-in-november/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw2e</id>\n        <published>2012-07-16T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T09:20:53.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/epmc.gif\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/epmc.gif\"></p><p>The
        <a href=\"https://web.archive.org/web/20160528080726/http://erc.europa.eu/\">European
        Research Council</a> on Friday <a href=\"https://web.archive.org/web/20160528080726/http://erc.europa.eu/sites/default/files/press_release/files/EuropePMC_press_release_WT_ERC_FINAL.pdf\">announced</a>
        that they will participate in the UK PubMed Central (UKPMC) open access repository
        service. They become the third European funder to join UKPMC, and the existing
        UKPMC funders have agreed to rebrand UKPMC as Europe PubMed Central (abbreviated
        to EPMC?) on November 1st.</p><p>More information about these changes can
        be found on the <a href=\"https://web.archive.org/web/20160528080726/http://ukpmc.blogspot.de/2012/07/european-research-council-renews-its.html\">UKPMC
        blog</a> and in the <a href=\"https://web.archive.org/web/20160528080726/http://www.wellcome.ac.uk/News/Media-office/Press-releases/2012/WTVM055890.htm\">Wellcome
        Trust press release</a>.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Visualizing tweets linking to a paper ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/visualizing-tweets-linking-to-a-paper/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw2f</id>\n        <published>2012-07-14T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T09:27:01.000+00:00</updated>\n\t\t<category
        term=\"Chart\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/calendarPlot.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/calendarPlot.png\"></p><p><a
        href=\"https://web.archive.org/web/20170216233248/http://dx.doi.org/10.1371/journal.pone.0037945\">DNA
        Barcoding the Native Flowering Plants and Conifers of Wales</a> has been one
        of the most popular new <em>PLoS ONE</em> papers in June. In the paper Natasha
        de Vere <em>et al.</em> describe a DNA barcode resource that covers the 1143
        native Welsh flowering plants and conifers.</p><p>My new job as technical
        lead for the <a href=\"https://web.archive.org/web/20170216233248/http://article-level-metrics.plos.org/\">PLoS
        Article Level Metrics (ALM) project</a> involves thinking about how we can
        best display the ALM collected for this and other papers. We want these ALM
        to tell us something important and/or interesting, and it doesn\u2019t hurt
        if the information is displayed in a visually appealing way. There are many
        different ways this can be done, but here I want to focus on <strong>Twitter</strong>
        and <strong>CiteULike</strong>, the only two data sources where PLoS is currently
        storing every single event (tweet or CiteULike bookmark) with a date. Usage
        data (HTML and XML views, PDF downloads) are aggregated on a monthly basis,
        and PLoS doesn\u2019t store the publication dates of citations.</p><p>We know
        from the <a href=\"https://web.archive.org/web/20170216233248/http://blogs.plos.org/mfenner/2011/12/20/crowdometer-or-trying-to-understand-tweets-about-journal-papers/\">work
        of Gunter Eysenbach</a> and others that most tweets linking to scholarly papers
        are written in the first few days after publication. It therefore makes sense
        to display this information on a timeline covering the first 30 days after
        publication, and the tweets about the de Vere paper follow the same pattern.</p><figure
        class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/sparklines.png\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"sparklines\" width=\"500\"
        height=\"375\"></figure><p>I like the simplicity of sparklines. It would be
        interesting to also map the 274 Facebook <strong>Likes, Comments,</strong>
        and <strong>Shares</strong>, but we don\u2019t have date information for them.
        The same is true for the 9 Mendeley readers and groups.</p><p>Another way
        to display the time course of tweets (or bookmarks) is to use a calendar heat
        map (the paper was published on June 6).</p><figure class=\"kg-card kg-image-card\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/calendarPlot-1.png\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"calendarPlot\" width=\"500\"
        height=\"320\"></figure><p>The chart looks a little bit empty, a calendar
        heat map probably works better for information with many daily data points.
        I would appreciate feedback on how these visualizations can be improved.</p><p>The
        charts were created with data from the <a href=\"https://web.archive.org/web/20170216233248/http://api.plos.org/\">PLoS
        ALM API</a> and the statistical computing package <a href=\"https://web.archive.org/web/20170216233248/http://www.r-project.org/\">R</a>,
        the source code is available <a href=\"https://web.archive.org/web/20170216233248/https://github.com/articlemetrics/plosOpenR/blob/master/sparkLines.R\">here</a>
        and <a href=\"https://web.archive.org/web/20170216233248/https://github.com/articlemetrics/plosOpenR/blob/master/calendarPlot.R\">here</a>.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Random notes from the altmetrics12 conference
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/random-notes-from-the-altmetrics12-conference/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw2g</id>\n        <published>2012-06-21T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T09:29:00.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/journal.pone.0004803.g005.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/journal.pone.0004803.g005.png\"></p><p>Last
        week I attended the <a href=\"https://web.archive.org/web/20160528073512/http://altmetrics.org/altmetrics12/\">altmetrics12</a>
        workshop in Chicago. You can read all 11 abstracts <a href=\"https://web.archive.org/web/20160528073512/http://altmetrics.org/altmetrics12/program/\">here</a>,
        and the conference had good Twitter coverage (using the hashtag <a href=\"https://web.archive.org/web/20160528073512/https://twitter.com/search/%23altmetrics12\">#altmetrics12</a>),
        at least until Twitter had a total blackout around 12 PM our time.</p><p>All
        but two presenters used slides \u2013 I have uploaded <a href=\"https://web.archive.org/web/20160528073512/https://speakerdeck.com/u/mfenner/p/altmetrics-will-be-taken-personally-at-plos\">my
        presentation</a> to Speaker Deck. Kelli Barr used the blackboard to explain
        that</p><ul><li>filtering (via altmetrics or any other means) by definition
        always selects out content and therefore runs against the democratization
        of science</li><li>peer review is a black box. altmetrics is also a black
        box, only much bigger</li></ul><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/barr.jpeg\" class=\"kg-image\"
        alt loading=\"lazy\" title=\"barr\" width=\"500\" height=\"373\"><figcaption>Kelli
        Barr used the blackboard for two important points in <a href=\"https://web.archive.org/web/20160528073512/http://altmetrics.org/altmetrics12/barr/\">her
        talk</a>.</figcaption></figure><p>altmetrics12 was one of the best conferences
        that I have attended recently. The intensity of the discussions was palpable.
        My only regrets are that there wasn\u2019t more time for discussions, but
        many of us convened in the bar afterwards.</p><p>We were off to a very strong
        start with two excellent keynote presentations by Johann Bollen ( Altmetrics:
        from usage data to social media) and Gregg Gordon (<a href=\"https://web.archive.org/web/20160528073512/http://ssrnblog.com/2012/05/18/alternative-is-the-new-grey/\">Alternative
        is the new Grey</a>). Johann emphasized why it is both important and fascinating
        to study how science is actually working. He stressed that science is a gift
        economy, where the currency is acknowledgement of influence in the form of
        citations. He sees two major problems with the present citation-based analysis
        of scientific impact: a) data and b) the metrics. Citation data are very domain
        specific (with very different citation practices in different disciplines),
        and delayed (several years after publication of the research they are citing).
        The problem with current citation-based metrics is that they ignore the network
        effect in science. Johann then went on to explain the <a href=\"https://web.archive.org/web/20160528073512/http://mesur.informatics.indiana.edu/\">MESUR</a>
        project, which studies the patterns of scientific activity on a very large
        scale (1 billion usage events, 500 million citations, 50 million papers).</p><figure
        class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/journal.pone.0004803.g005-1.png\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"Map of Science\" width=\"320\"
        height=\"305\"><figcaption>Map of science from <a href=\"https://web.archive.org/web/20160528073512/http://dx.doi.org/10.1371/journal.pone.0004803\">2009
        PLoS ONE paper</a>.</figcaption></figure><p>Johann then briefly explained
        the results of another <a href=\"https://web.archive.org/web/20160528073512/http://dx.doi.org/10.1371/journal.pone.0006022\">2009
        PLoS ONE paper</a> where he analyzed 39 metrics with principal component analysis.
        He found two major components in the metrics analysis: counting vs. social
        influence and fast vs. slow.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/journal.pone_.0006022.g002.jpg\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"PCA\" width=\"480\" height=\"340\"><figcaption>Correlation
        of 37 metrics mapped onto first two principal components in another <a href=\"https://web.archive.org/web/20160528073512/http://dx.doi.org/10.1371/journal.pone.0006022\">2009
        PLoS ONE paper</a>.</figcaption></figure><p>Johann then told the interesting
        story behind a <a href=\"https://web.archive.org/web/20160528073512/http://arxiv.org/abs/1010.3003\">2010
        paper</a> where he showed that <strong>Twitter mood can predict the stock
        market</strong>. The paper was rejected by all publishers and was finally
        published on ArXiV in October 2010. It immediately became very popular in
        terms of downloads and media attention (and was eventually <a href=\"https://web.archive.org/web/20160528073512/http://dx.doi.org/10.1016/j.jocs.2010.12.007\">published</a>
        in the <em>Journal of Computational Science</em> in March 2011).</p><p>Gregg
        Gordon has summarized his keynote in a May <a href=\"https://web.archive.org/web/20160528073512/http://ssrnblog.com/2012/05/18/alternative-is-the-new-grey/\">blogpost</a>,
        so I will focus on a few highlights. Gregg Gordon runs the Social Science
        Research Network (<a href=\"https://web.archive.org/web/20160528073512/http://ssrn.com/\">SSRN</a>),
        a leading resource for sharing social sciences research. Gregg thinks that
        altmetrics can provide the compass to navigate the map of science described
        earlier. He told us some very interesting anecdotes of users trying to game
        SSRN by inflating their download counts (e.g. \u201Cdownloads for donuts\u201D),
        and mentioned a <a href=\"https://web.archive.org/web/20160528073512/http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1346397\">research
        paper</a>analyzing gaming at SSRN. Download counts are apparently taken very
        seriously by SSRN authors and are also used for hiring decisions. SSRN not
        only has written software to protect against gaming, but also has a person
        constantly looking over these numbers (Gregg feels that computer algorithms
        alone are not enough).</p><p>The two keynotes were followed by 11 short (10-15
        minute) presentations, including two presentations about the PLoS <a href=\"https://web.archive.org/web/20160528073512/http://article-level-metrics.plos.org/\">Article-Level
        Metrics</a> project. Jennifer Lin spoke about <a href=\"https://web.archive.org/web/20160528073512/http://altmetrics.org/altmetrics12/lin/\">anti-gaming
        mechanisms</a> and I emphasized the importance of <a href=\"https://web.archive.org/web/20160528073512/http://altmetrics.org/altmetrics12/fenner/\">personalizing
        altmetrics</a> to fully understand the \u201Cnetwork of science\u201D. All
        presentation abstracts are available <a href=\"https://web.archive.org/web/20160528073512/http://altmetrics.org/altmetrics12/program/\">online</a>.</p><p>After
        the lunch break (and some interesting discussions) we continued with demos
        of various altmetrics applications and users, including <a href=\"https://web.archive.org/web/20160528073512/http://total-impact.org/\">Total
        Impact</a>, <a href=\"https://web.archive.org/web/20160528073512/http://www.plumanalytics.com/\">Plum
        Analytics</a>, <a href=\"https://web.archive.org/web/20160528073512/http://www.altmetric.com/\">altmetric.com</a>,
        the<a href=\"https://web.archive.org/web/20160528073512/http://alm.plos.org/\">
        PLoS Article-Level Metrics</a> application, <a href=\"https://web.archive.org/web/20160528073512/http://knodeinc.com/\">Knode</a>,
        <a href=\"https://web.archive.org/web/20160528073512/http://academia.edu/\">Academia.edu</a>,
        <a href=\"https://web.archive.org/web/20160528073512/http://www.biomedcentral.com/\">BioMed
        Central</a> and <a href=\"https://web.archive.org/web/20160528073512/http://www.ubiquitypress.com/\">Ubiquity
        Press</a> (example <a href=\"https://web.archive.org/web/20160528073512/http://openarchaeologydata.metajnl.com/article/intensive-survey-data-from-antikythera-greece/\">here</a>).</p><p>In
        the last our and a half we split up into several smaller group to discuss
        issues relevant for altmetrics. I was in the <strong>standards</strong> group
        and we all agreed that it is too early to sep up rigid standards for this
        evolving field, but not too early to start the discussion. The two standards
        experts in our group (Todd Carpenter from <a href=\"https://web.archive.org/web/20160528073512/http://www.niso.org/home/\">NISO</a>
        and David Baker from <a href=\"https://web.archive.org/web/20160528073512/http://casrai.org/\">CASRAI</a>)
        were of course very helpful with the discussion in our group. In the closing
        group discussion the breakout groups reported their major discussion points
        (which will hopefully be written up by someone). We also learned that the
        NIH is considering changing the Biosketch format for CVs and is looking for
        input via a <a href=\"https://web.archive.org/web/20160528073512/http://grants.nih.gov/grants/guide/notice-files/NOT-OD-12-115.html\">Request
        for Information</a> (RFI) until June 29.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Speaker Deck for Sharing Presentations ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/speaker-deck-for-sharing-presentations/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw2h</id>\n        <published>2012-05-29T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-12T07:49:24.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>It has become
        common practice to make presentation slides available for those unable to
        attend in person, or for more in-depth review later. The most popular service
        to do this is of course <a href=\"https://web.archive.org/web/20160404225654/http://www.slideshare.net/\">Slideshare</a>.
        Slideshare is a fine service, but the website has become fairly cluttered
        over the years, and visuals are of course important when it comes to presentations.<br><br><a
        href=\"https://web.archive.org/web/20160404225654/http://speakerdeck.com/\">Speaker
        Deck</a> is an alternative to Slideshare with a focus on \u201Csimplicity
        and beauty\u201D. The service has the features you would expect:</p><ul><li>upload
        presentations (currently in PDF only)</li><li>view presentations, including
        fullscreen mode</li><li>share presentations, including downloads and embedding</li></ul><figure
        class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://web.archive.org/web/20160404225654im_/http://blogs.plos.org/mfenner/files/2012/05/speakerdeck.png\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"speakerdeck\"><figcaption><a
        href=\"https://web.archive.org/web/20160404225654/https://speakerdeck.com/u/mfenner/p/future-formats-representing-the-next-generation-of-scholarly-articles?slide=51\">Slide
        51</a> from a presentation I did with Steve Pettifer at UKSG in March.</figcaption></figure><p>Speaker
        Deck was <a href=\"https://web.archive.org/web/20160404225654/http://orderedlist.com/blog/articles/share-presentations-without-the-mess/\">announced
        last September</a> and is free to use. It would be helpful if Speaker Deck
        allowed the upload of Powerpoint or Keynote files, making it easier to reuse
        the slides. But the big item on my wish list is an improvement of the social
        activities enabled around a presentation. I want to see download counts, comments,
        number of tweets and Facebook likes, and I want an API for them. Ordered List,
        the company behind Speakerdeck, was <a href=\"https://web.archive.org/web/20160404225654/http://orderedlist.com/blog/articles/ordered-list-acquired-by-github/\">acquired
        by Github</a> in December, turning Speaker Deck into a Github product. This
        makes me confident that we will see these Speaker Deck improvements rather
        sooner than later.</p><p>To see a few Speaker Deck presentations, go to <a
        href=\"https://web.archive.org/web/20160404225654/https://speakerdeck.com/u/mfenner\">my
        presentations</a> or the <a href=\"https://web.archive.org/web/20160404225654/https://speakerdeck.com/c/science\">Science
        category</a>.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ PLoS Article-Level Metrics: Interview with
        Martin Fenner ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/plos-article-level-metrics-interview-with-martin-fenner/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw2j</id>\n        <published>2012-04-23T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T09:30:24.000+00:00</updated>\n\t\t<category
        term=\"Interview\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/429781913_9524791cff_c-1.jpg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/429781913_9524791cff_c-1.jpg\"></p><p>This
        blog occasionally does interviews with people providing interesting tools
        for scholars. These <a href=\"https://front-matter.io/interviews\">interviews</a>
        have always been among my favorite blog posts. This now is obviously an interview
        with myself, but I felt this is the best format to explain some important
        news.</p><p>Starting May 16 I will be working full-time as technical lead
        for the PLoS <a href=\"https://web.archive.org/web/20161226124822/http://article-level-metrics.plos.org/\">Article
        Level Metrics</a> (ALM) project. I will help with development of the <a href=\"https://web.archive.org/web/20161226124822/http://code.google.com/p/alt-metrics/\">PLoS
        ALM application</a>, and will do community developer outreach for this project.</p><p>The
        PLoS ALM application is written in <a href=\"https://web.archive.org/web/20161226124822/http://rubyonrails.org/\">Ruby
        on Rails</a>, an open-source web framework I have been working with since
        2005. The ALM project was launched in 2009, and I first learned about ALM
        in a July 2009 presentation by Pete Binfield at <a href=\"https://web.archive.org/web/20161226124822/http://blogs.plos.org/mfenner/2009/07/10/i_was_at_scibarcamp_palo_alto/\">SciBarCamp
        Palo Alto</a>. A month later I did an <a href=\"https://web.archive.org/web/20161226124822/http://blogs.plos.org/mfenner/2009/07/10/i_was_at_scibarcamp_palo_alto/\">interview
        with Pete</a> about Article Level Metrics and PLoS ONE.</p><h3 id=\"what-is-article-level-metrics\">What
        is Article Level Metrics?</h3><p>Article Level Metrics <em>place transparent
        and \_comprehensive information about the usage and reach of published articles
        onto the articles themselves, so that the entire academic community can assess
        their value </em>(from the <a href=\"https://web.archive.org/web/20161226124822/http://article-level-metrics.plos.org/\">PLoS
        ALM website</a>). A <a href=\"https://web.archive.org/web/20161226124822/http://dx.doi.org/10.1371/journal.pbio.1000242\">November
        2009 paper</a> by Cameron Neylon and Shirley Wu gives a more detailed introduction.
        And a <a href=\"https://web.archive.org/web/20161226124822/http://www.slideshare.net/kristenratan/metrics-the-new-black\">recent
        presentation</a> by Kristen Ratan, PLoS Director of Product Management, given
        at the <a href=\"https://web.archive.org/web/20161226124822/http://www.nfais.org/page/361-program-2012-nfais-annual-conference\">2012
        NFAIS meeting</a>, provides an update for 2012.</p><p>Article Level Metrics
        is part of the larger <a href=\"https://web.archive.org/web/20161226124822/http://altmetrics.org/manifesto/\">altmetrics</a>
        movement, which also looks at metrics for other scholarly works besides journal
        articles.</p><h3 id=\"does-this-mean-that-you-will-be-moving-to-san-francisco\">Does
        this mean that you will be moving to San Francisco?</h3><p>For personal reasons
        I will continue to live in Hannover, Germany and work from home as a contractor
        with occasional trips to San Francisco.</p><h3 id=\"will-you-miss-treating-cancer-patients-and-doing-cancer-research\">Will
        you miss treating cancer patients and doing cancer research?</h3><p>Absolutely.
        This has not been an easy decision. To make the transition easier, I will
        continue to spend 10% of my time at Hannover Medical School. I will no longer
        be seeing patients, but this will allow me to conclude the RADIT <a href=\"https://web.archive.org/web/20161226124822/http://clinicaltrials.gov/ct2/show/NCT01242631\">clinical
        trial</a> for testicular cancer patients where I am the principal investigator.</p><p>I
        hope to continue doing research in the new position, but with a focus on information
        science. There are for example still a lot of things we don\u2019t know about
        altmetrics. A more detailed analysis of our recent <a href=\"https://web.archive.org/web/20161226124822/http://blogs.plos.org/mfenner/2012/02/19/crowdsourcing-the-analysis-of-scholarly-tweets/\">CrowdoMeter</a>
        project (a crowdsourced analysis of tweets linking to scholarly papers) would
        be a good start.</p><h3 id=\"what-will-happen-with-sciencecard\">What will
        happen with ScienceCard?</h3><p><a href=\"https://web.archive.org/web/20161226124822/http://sciencecard.org/\">ScienceCard</a>
        is a website that collects author level metrics and was my entry into the
        <a href=\"https://web.archive.org/web/20161226124822/http://blogs.plos.org/mfenner/2011/11/20/sciencecard-named-finalist-in-mendeleyplos-api-binary-battle/\">Mendeley/PLoS
        Binary Battle API contest</a> last fall. ScienceCard is based on the PLoS
        ALM code (which is open source and <a href=\"https://web.archive.org/web/20161226124822/http://code.google.com/p/alt-metrics/\">available
        via Google Code</a>). I will decide in the coming months what to do with ScienceCard.
        This depends mainly on how much author level metrics make sense in the PLoS
        ALM project.</p><h3 id=\"and-what-will-happen-to-your-other-scholarly-communication-activities\">And
        what will happen to your other scholarly communication activities?</h3><p>There
        is no reason not to continue my other activities, including involvement in
        the Open Researcher &amp; Contributor ID (<a href=\"https://web.archive.org/web/20161226124822/http://about.orcid.org/\">ORCID</a>)
        initiative, and using WordPress as a <a href=\"https://web.archive.org/web/20161226124822/http://blogs.plos.org/mfenner/tag/wordpress/\">tool
        to write and publish manuscripts</a>.</p><h3 id=\"what-are-your-future-plans-for-this-blog\">What
        are your future plans for this blog?</h3><p>I plan to continue this blog in
        a very similar format, and I will have more time for more in-depth articles.
        And of course I will indicate a conflict of interest when I write about Article
        Level Metrics.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Marketing for Scientists ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/marketing-for-scientists/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw2k</id>\n
        \       <published>2012-03-27T00:00:00.000+00:00</published>\n\t\t<updated>2023-07-05T18:15:52.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>The <a href=\"https://web.archive.org/web/20160528080410/http://www.nature.com/nmat/journal/v11/n4/index.html\">April
        issue</a> of <em>Nature Materials</em> contains three articles that discuss
        marketing strategies for scientists. The <a href=\"https://doi.org/10.1038/nmat3300\">Editorial</a>
        (\u201CThe scientific marketplace\u201D) introduces the topic and explains
        why scientists should consider marketing their work. The issue also contains
        an <a href=\"https://web.archive.org/web/20160528080410/http://dx.doi.org/10.1038/nmat3276\">interview</a>
        (\u201CThe m word\u201D) with astrophysicist Marc Kuchner who published a
        book titled <a href=\"https://web.archive.org/web/20160528080410/http://marketingforscientists.com/\"><em>Marketing
        for Scientists</em></a><em>. </em>Finally, there is a <a href=\"https://web.archive.org/web/20160528080410/http://dx.doi.org/10.1038/nmat3283\">commentary</a>
        (\u201COne-click science marketing\u201D) by me discussing strategies and
        tools that scientists can use to promote their work. The commentary also includes
        links to pages by <a href=\"https://web.archive.org/web/20160528080410/http://www.scivee.tv/user/4\">Phil
        Bourne</a> (SciVee), <a href=\"https://web.archive.org/web/20160528080410/http://www.mendeley.com/profiles/jonathan-eisen\">Jonathan
        Eisen</a> (Mendeley), <a href=\"https://web.archive.org/web/20160528080410/http://rrresearch.fieldofscience.com/\">Rosie
        Redfield</a> (blog), <a href=\"https://web.archive.org/web/20160528080410/http://johnhawks.net/weblog\">John
        Hawks</a> (blog), and <a href=\"https://web.archive.org/web/20160528080410/http://cameronneylon.net/\">Cameron
        Neylon</a> (personal webpage).</p><p>Scientists may feel uncomfortable about
        marketing their work, but we all are doing it already. We know that giving
        a presentation at a key meeting can be a boost for our career, and we know
        about the importance of maintaining an academic homepage listing our research
        interests and publications. And people reading this blog will understand that
        a science blog can be a powerful marketing tool.</p><p>Feel free to add your
        thoughts and suggestions in the comments.</p><h2 id=\"references\">References</h2><p>The
        scientific marketplace. <em>Nature Mater</em>. 2012;11(4):259-259. doi:<a
        href=\"https://doi.org/10.1038/nmat3300\">10.1038/nmat3300</a></p><p>Martin
        C. The m word. <em>Nature Mater</em>. 2012;11(4):264-265. doi:<a href=\"https://doi.org/10.1038/nmat3276\">10.1038/nmat3276</a></p><p>Fenner
        M. One-click science marketing. <em>Nature Mater</em>. 2012;11(4):261-263.
        doi:<a href=\"https://doi.org/10.1038/nmat3283\">10.1038/nmat3283</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Why I still like FriendFeed, why Twitter
        is important and other thoughts about Altmetrics ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/why-i-still-like-friendfeed-why-twitter-is-important-and-other-thoughts-about-altmetrics/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw2m</id>\n        <published>2012-03-05T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T09:31:51.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/activitystream-1.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/activitystream-1.png\"></p><p><a
        href=\"https://web.archive.org/web/20160528083343/http://altmetrics.org/\">Altmetrics</a>
        \u2013 tools to assess the impact of scholarly works based on alternative
        online measures such as bookmarks, links, blog posts, etc. \u2013have become
        a regular topic in this blog. The <a href=\"https://web.archive.org/web/20160528083343/http://altmetrics.org/manifesto/\">altmetrics
        manifesto</a> was published in October 2010, and in the last 18 months we
        have seen a <a href=\"https://web.archive.org/web/20160528083343/http://altmetrics.org/tools/\">number
        of interesting new altmetrics services</a>, including the <a href=\"https://web.archive.org/web/20160528083343/http://blogs.plos.org/blog/tag/sciencecard/\">ScienceCard</a>
        service that I started six months ago. ScienceCard has been a very interesting
        learning experience, because I not only had to write the software, but also
        think about my perspective on altmetrics. Some of my recent thoughts are listed
        below.</p><p><strong>FriendFeed still is a great model for a scholarly service</strong><br>I
        have stopped using FriendFeed a few months ago in favor of Twitter, but I
        still very much like the design of the service. I think that the concept should
        also work very well for altmetrics, and I have therefore continued work on
        an <a href=\"https://web.archive.org/web/20160528083343/http://en.wikipedia.org/wiki/Activity_stream\">activity
        stream</a> for ScienceCard. At <a href=\"https://web.archive.org/web/20160528083343/http://sciencecard.org/works\">http://sciencecard.org/works</a>
        you find a listing of all recent scholarly works of your ScienceCard friends,
        and now you can like/comment/share them. ScienceCard friends are the people
        you follow on Twitter who also have a ScienceCard account and sharing is possible
        via Mendeley and CiteULike. Comments are still in the testing stage, and Twitter
        integration is also in the works. I also want to add more scholarly content
        including Slideshare presentations and blog posts, although the latter are
        really hard to do in an automated way.</p><p>Altmetrics tools should not only
        present scholarly works and their metrics, but they should also allow users
        to interact with them via sharing, commenting, etc.</p><p><strong>Altmetrics
        is about search</strong><br>Altmetrics is really about two related concepts:
        reputation and discovery. ScienceCard tries to summarize the metrics available
        about a particular researcher, although much more work needs to be done to
        show that these numbers correlate with reputation. The discovery aspect of
        altmetrics is at least as important, and this means that these alternative
        metrics should help provide better search results. Some bibliographic databases
        let you sort your search results by number of citations \u2013 the problem
        is of course that citations can have a delay of several years. Download counts,
        social bookmarks, Twitter links, etc. on the other hand can give information
        about the impact of a paper within days of publication. The search results
        can be improved further by personalizing them based on what the friends in
        your social network are publishing, bookmarking or discussing.</p><p><strong>Altmetrics
        is expensive</strong><br>It is great to see so many altmetrics grassroots
        projects. Unfortunately it is resource-intensive and therefore costly to collect
        altmetrics, in particular if it is almost real-time numbers such as Twitter
        citations. I\u2019m afraid that many people (including myself) will have a
        hard time providing this service in a sustainable way. There are two possible
        solutions: providing altmetrics as a commercial service, and providing altmetrics
        as a collaborative effort. Although I understand the reasoning behind commercial
        services, I would very much prefer the open and collaborative approach. Collaboration
        could mean that several people and/or organizations join forces and run an
        altmetrics service together, but it could also mean that we break altmetrics
        into smaller services connected via programming interfaces. A typical altmetrics
        service has at least these functions:</p><ul><li>an interface to add journal
        articles and other scholarly objects, whether it is manual input by users
        or via an API</li><li>a searchable database with metadata about scholarly
        objects</li><li>a background service that collects metrics from other sources</li><li>a
        public interface that displays metrics for particular scholarly objects and
        collections</li><li>an interface for visualization and analysis of aggregate
        numbers</li></ul><p>I don\u2019t think that all five functions (and possibly
        more) necessarily have to be provided by the same service. I\u2019m sure that
        there are enough people that are only interested in providing interesting
        ways to add scholarly objects, or in visualization and analysis. The background
        service is probably the most boring and resource-intensive part.</p><p><strong>I
        want second-order metrics</strong><br>Second-order metrics means the metrics
        for the scholarly works citing a particular paper or for the person bookmarking
        or tweeting a scholarly work. This approach would add valuable information
        and is obviously similar to the PageRank algorithm for web links. Unfortunately
        this approach also creates a lot of extra work, as this means collecting the
        metrics (or at least some metrics) for all citing works. Again something that
        makes altmetrics expensive.</p><p><strong>Twitter is important</strong><br>Many
        of the <a href=\"https://web.archive.org/web/20160528083343/http://blogs.lse.ac.uk/impactofsocialsciences/2012/02/09/more-tweets-more-citations/\">recent
        altmetrics discussions</a> have really been about the role of Twitter in scholarly
        communication. A lot of people are excited about the potential of Twitter
        to help discover interesting scholarly works, and to allow this within days
        after publication. It is still too early to know for sure whether <a href=\"https://web.archive.org/web/20160528083343/http://blogs.plos.org/mfenner/2011/12/20/crowdometer-or-trying-to-understand-tweets-about-journal-papers/\">highly
        tweeted papers will be cited more often later on</a>. Better Twitter integration
        is high on my to do list for ScienceCard.</p><p><strong>Yet another bibliographic
        database</strong><br>The core function of altmetrics is to build a database
        with metadata about scholarly objects, including a variety of metrics. There
        are of course a large number of bibliographic databases already out there,
        so maybe existing databases can also be extended to include metrics. Ideally
        the existing database should not be restricted to particular kinds of scholarly
        works (e.g. journal articles) or disciplines, should be free to use and should
        allow reuse of the data with an appropriate license. There are several candidates
        that fit this description, including <a href=\"https://web.archive.org/web/20160528083343/http://bibsoup.net/\">BibSoup</a>
        run by the Open Knowledge Foundation and possibly also the <a href=\"https://web.archive.org/web/20160528083343/http://www.zotero.org/\">Zotero
        </a>database allowing synchronization with the desktop reference manager.
        Both services focus on bibliographic collections uploaded by users, whereas
        my idea of an altmetrics database relies on disambiguated authors and scholarly
        works.</p><p><strong>There are too many altmetrics</strong><br>It is great
        that altmetrics increases the variety of available metrics, but too many different
        metrics can be confusing to users. Although it is interesting that the number
        of citations for the same work vary widely between PubMed, Web of Science,
        Scopus, Microsoft Academic Search, Pubmed and Google Scholar, the typical
        user is probably only interested in one citation count. The same is true for
        usage metrics and number of social bookmarks. I think it would be helpful
        to consolidate the metrics about a scholarly work to maybe five numbers, including
        views/downloads, bookmarks, citations, comments, and tweets. This doesn\u2019t
        mean that the other information shouldn\u2019t be collected, just that the
        numbers will be consolidated for display.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ A Few Questions about Science Spam ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/a-few-questions-about-science-spam/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw2n</id>\n        <published>2012-02-24T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-31T10:52:34.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/07/519906069_de5953764a_m-1.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/07/519906069_de5953764a_m-1.jpeg\"></p><p>This
        was another week with a fair amount of spam in my email inbox. We all receive
        email <a href=\"https://web.archive.org/web/20161026234722/http://www.youtube.com/watch?v=anwy2MPT5RE\">spam</a>
        on a regular basis and most of us have probably also received science spam:
        invitations to scientific conferences about topics we are not working on,
        invitations to submit articles to journals not covering your field, and information
        about lab supplies we never had asked for. Although I\u2019m of course aware
        that spam is now a fact of online life, I don\u2019t quiet understand how
        this science spam works.</p><p><strong>1. How do science spammers get my email
        address?</strong><br>Most science spam is not really targeted toward my research
        interests. From this, I conclude that these spammers automatically harvest
        the email addresses of researchers, or they buy these lists. One potential
        source to harvest <a href=\"https://web.archive.org/web/20161026234722/http://blogs.plos.org/mfenner/2011/07/13/did-you-receive-spam-because-you-published-a-paper/\">email
        addresses is PubMed</a> and other bibliographic databases, but I don\u2019t
        know whether this is actually done.</p><p><strong>2. Is even a small percentage
        of researchers responding to this science spam?</strong><br>Science spam is
        as uninteresting to me as any other spam, and I can\u2019t really imagine
        a colleague submitting a manuscript to a journal marketed this way. But the
        idea behind spam is that there is a \u2013 admittedly very small \u2013 conversion
        rate.</p><p><strong>3. When will we start to see more social media science
        spam?</strong><br>I think it is only a question of time before we see more
        science spam on Twitter, Google+ and Facebook \u2013 I already receive a small
        amount of spam through these channels.</p><p><strong>4. Is there anything
        an individual researcher can other than using good spam filters in his email
        program?</strong><br>Would it for example help if we hide our email address
        as much as possible? Should we deny publishers the permission to post our
        email address in journal articles, and should places like PubMed hide them?
        Do publisher organizations such as OASPA (Open Access Scholarly Publishers
        Association) enforce their <strong><a href=\"https://web.archive.org/web/20161026234722/http://www.oaspa.org/conduct.php\">Member
        Code of Conduct</a>,</strong> which clearly state that a<em>ny direct marketing
        activities publishers engage in shall be appropriate and unobtrusive.</em></p><p><strong>5.
        Will it get worse?</strong><br>I know this answer. Yes. This blog has seen
        more than 60,000 spam comments already, most of the spam in my email is filtered
        out before I even see it, but I think it will get much worse \u2013 via email
        and other channels.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Crowdsourcing the analysis of scholarly
        tweets ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/crowdsourcing-the-analysis-of-scholarly-tweets/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw2p</id>\n        <published>2012-02-19T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T09:33:08.000+00:00</updated>\n\t\t<category
        term=\"Chart\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/authors.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/authors.png\"></p><p>In
        December Euan Adie and I <a href=\"https://web.archive.org/web/20161027000313/http://blogs.plos.org/mfenner/2011/12/20/crowdometer-or-trying-to-understand-tweets-about-journal-papers/\">started
        the CrowdoMeter projec</a>t, an analysis of the semantic content of tweets
        linking to scholarly papers. Because classifying almost 500 tweets is a lot
        of work, we turned this into a crowdsourcing project. We got help from 36
        people, who did 953 classifications, and we discussed the preliminary results
        (available <a href=\"https://web.archive.org/web/20161027000313/http://crowdometer.org/ratings\">here</a>)
        at the <a href=\"https://web.archive.org/web/20161027000313/http://scienceonline2012.com/\">ScienceOnline2012</a>
        conference.</p><p>There is no reason to stop the crowdsourcing here, so we
        have <a href=\"https://web.archive.org/web/20161027000313/http://hdl.handle.net/10779/01c28ce592291e7e294ed328208a5869\">uploaded
        the result set</a> to <a href=\"https://web.archive.org/web/20161027000313/http://blogs.plos.org/mfenner/2012/02/16/figshare-interview-with-mark-hahnel/\">figshare</a>
        and invite everybody to help us with the data analysis. For this purpose I
        have created a <a href=\"https://web.archive.org/web/20161027000313/https://github.com/mfenner/crowdometer\">public
        repository</a> on Github which contains not only the source code for the CrowdoMeter
        website, but also all data \u2013 the same dataset made available on figshare.
        I have written a <a href=\"https://web.archive.org/web/20161027000313/https://github.com/mfenner/crowdometer/blob/crowdometer/public/assets/shares_author.R\">first
        R script</a> that produces the following pie chart:</p><p>The figure doesn\u2019t
        look all that exciting, but there is some calculation involved. There are
        different numbers of classifications per tweet and sometimes there is disagreement:
        true means at least 50% of classifications were true. It would be great if
        we find people willing to help with data analysis, preferably using <a href=\"https://web.archive.org/web/20161027000313/http://rstudio.org/\">R</a>
        and contributing their scripts to the Github repository. Please send me an
        email or contact me <a href=\"https://web.archive.org/web/20161027000313/http://twitter.com/#!/mfenner\">via
        Twitter</a> if you need write access to the repository.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Reference Manager Papers now available for
        Windows ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/reference-manager-papers-now-available-for-windows/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw2q</id>\n        <published>2012-02-17T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T17:12:38.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Regular readers of this blog
        know that I\u2019m a big fan of the reference manager <a href=\"https://web.archive.org/web/20161026235642/http://www.mekentosj.com/papers/\">Papers
        </a>\u2013 three years ago we even had a <a href=\"https://web.archive.org/web/20161026235642/http://blogs.plos.org/mfenner/2009/02/19/papers_for_iphone_released_time_for_more_poetry\">poetry
        contest</a> when the iPhone version was first released. The strength of Papers
        has always been the very nice user interface, and Papers 2 <a href=\"https://web.archive.org/web/20161026235642/http://blogs.plos.org/mfenner/2011/03/08/papers-2-the-reference-manager-made-with-love/\">released
        last March</a> was a major update that added many more reference types, collaboration
        and a word processor plugin.</p><p>The first five years Papers has been only
        available for Mac and iPhone/iPad, but this week mekentosj.com released a
        pre-release version for Windows. Papers for Windows is a collaboration with
        <a href=\"https://web.archive.org/web/20161026235642/http://www.scimatic.com/node/386\">Scimatic
        Software</a>, and a <a href=\"https://web.archive.org/web/20161026235642/http://pfw.mekentosj.com/kb/roadmap/mac-vs-windows-comparison-compatibility\">comparison
        of the Mac and Windows </a>versions is here. A 30 day trial version is <a
        href=\"https://web.archive.org/web/20161026235642/http://www.mekentosj.com/papers/\">available
        for download</a> from mekentosj.com.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Figshare: Interview with Mark Hahnel ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/figshare-interview-with-mark-hahnel/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw2r</id>\n        <published>2012-02-16T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T10:24:32.000+00:00</updated>\n\t\t<category
        term=\"Interview\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/me1.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/me1.png\"></p><p>fig<strong>share</strong>
        <em>allows researchers to publish all of their research outputs in seconds
        in an easily citable, sharable and discoverable manner</em>. The service was
        started by Mark Hahnel last year while still a PhD student. Mark joined <a
        href=\"https://web.archive.org/web/20161023171633/http://www.digital-science.com/\">Digital
        Science</a> to work on fig<strong>share</strong> in September and last month
        relaunched a much improved version of the service. I asked Mark a few questions
        about fig<strong>share</strong> below. I also uploaded two datasetst to fig<strong>share</strong>
        and made them publicly available:</p><ul><li><a href=\"https://web.archive.org/web/20161023171633/http://hdl.handle.net/10779/1c48a305c08c717fea3f6fe1687b3eff\">CrowdoMeter
        Tweets</a> \u2013 all 467 tweets used in the CrowdoMeter project</li><li><a
        href=\"https://web.archive.org/web/20161023171633/http://hdl.handle.net/10779/01c28ce592291e7e294ed328208a5869\">CrowdoMeter
        Classifications</a> \u2013 all 953 classifications from the CrowdoMeter project.</li></ul><h2
        id=\"1-what-is-figshare\">1. What is figshare?</h2><p><a href=\"https://web.archive.org/web/20161023171633/http://figshare.com/\">figshare</a>
        is a repository where users can make all of their research outputs available
        in a citable, sharable and discoverable manner. figshare allows users to upload
        any file format so that figures, datasets and media can be disseminated in
        a way that the current scholarly publishing model does not allow.</p><figure
        class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/screenshot.png\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"screenshot\" width=\"500\"
        height=\"258\"></figure><h2 id=\"2-what-is-the-right-content-for-figshare-and-what-should-rather-go-somewhere-else\">2.
        What is the right content for figshare? And what should rather go somewhere
        else?</h2><p>Every experiment that is completed without error in the methods
        is valuable. Researchers investigate things because the question is interesting
        and supposedly unanswered. This means that other researchers will at some
        point ask that same question. Just because the hypothesis didn\u2019t turn
        out to be true, doesn\u2019t mean that this data should be thrown away.</p><p>With
        fig<strong>share</strong>, you can share your negative results or results
        that you were not planning to publish. You can make raw data available or
        supplementary material that journals cannot handle linked to from the published
        article. You can even make your papers and posters available and citable.
        People have uploaded whole chapters of their PhD thesis to share with the
        world and make sure that all of their hard work is not wasted.</p><p>Currently
        we are not focusing on handling massive datasets, whilst this is an aim for
        the future. These edge cases seem to be better handled by journals set up
        specifically for publishing these huge files, such as the excellent <a>GigaScience</a>.</p><h2
        id=\"3-you-relaunched-figshare-in-january-what-has-changed-to-the-previous-version\">3.
        You relaunched figshare in January. What has changed to the previous version?</h2><p>The
        old site was a proof of concept based on Mediawiki software. The new site
        has been completely built from scratch so that it is rapidly extendable in
        terms of features and scale. This means that we can adapt quickly and easily
        to the needs of researchers. As well as being much more intuitive, the biggest
        new feature for fig<strong>share</strong> is the private space.</p><p>Whilst
        we would like everyone to make all of their research objects available, we
        appreciate that some researchers would like to keep research private for many
        reasons. Because of this we set about giving users their own private repository
        to store their research objects. These objects can be uploaded in seconds
        and all objects are initially held in the private space, from where they can
        be made publicly available when the user decides. All research is easily tagged
        and categorizable, so that researchers can filter through their many files
        to find the one they were looking for in no time at all.</p><h2 id=\"4-how-important-is-the-user-interface-for-figshare-what-particular-features-do-you-like-the-most\">4.
        How important is the user interface for figshare? What particular features
        do you like the most?</h2><p>The user interface is essential, researchers
        are busy enough as it it. They haven\u2019t got the time to attend training
        course on how to use a repository. If this was the case with facebook, no
        one would use facebook. For this reason fig<strong>share</strong> is stupidly
        simple and allows users to get their research onto the site in seconds, even
        the PIs. At this point they can choose to make it publicly available and immediately
        citable, sharable and discoverable, or keep it private \u2013 securely hosted,
        taggable and accessible when they need it, from anywhere in the world.</p><p>This
        is something we are constantly aiming to improve and we not only welcome feedback,
        we are actively seeking the thoughts of researchers on how we can make this
        a seemless part of their research process.</p><h2 id=\"5-do-you-have-plans-for-a-desktop-version-of-figshare-e-g-to-watch-folders-for-new-figshare-content\">5.
        Do you have plans for a desktop version of figshare, e.g. to watch folders
        for new figshare content?</h2><p>We do! By creating a desktop uploader, the
        process becomes even more intuitive for researchers, allowing them to make
        backups of their research in the cloud with no effort expenditure. Research
        data management is something I personally was terrible at. My research was
        organised into folders based on the month and the year I did that work. I
        lost days trying to find files that \u2018I know I worked on sometime last
        summer\u2019. Hopefully a desktop uploader will add to the current simple
        management system so that researchers like me have no excuse when it comes
        to losing (often expensive) results files.</p><h2 id=\"6-how-is-figshare-different-from-data-repositories\">6.
        How is figshare different from data repositories?</h2><p>fig<strong>share</strong>
        is not limited as many repositories are. It caters for all research domains,
        no matter where your research is carried out. Institutional repositories are
        often limited to members of said institution. Also, the majority of institutional
        repositories are built specifically for papers. The Dryad repository has been
        doing some great work making the datasets behind published articles available
        under CC0. fig<strong>share</strong> is not limited by the normal constraints
        of publishing, data generated in the lab can be shared and made available
        to the world as a citable object the same day.</p><figure class=\"kg-card
        kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/usermetrics.png\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"usermetrics\" width=\"275\"
        height=\"115\"></figure><p>fig<strong>share</strong> also gives the researchers
        the credit for their research. By adding metrics to the public uploads, and
        putting the cumulative metrics of a researcher\u2019s uploads on their profile,
        users can see the true impact and reach of the hard work they put in.</p><h2
        id=\"7-you-currently-use-handles-for-figshare-content-what-are-your-thoughts-on-persistent-identifiers-are-the-plans-to-use-dois\">7.
        You currently use handles for figshare content. What are your thoughts on
        persistent identifiers? Are the plans to use DOIs?</h2><p>Persistent identifiers
        are essential for the long term availability of research outputs. One of the
        reasons I set up figshare was because I wanted to cite a video in my thesis.
        Research data on <a href=\"https://web.archive.org/web/20161023171633/http://figshare.com/blog/A%20YouTube%20%20for%20Scientists/11\">YouTube</a>
        is not easily citable, by adding persitent identifiers and an organised citation
        structure, videos as well as any other file format can be easily cited. All
        citations can be exported to <a href=\"https://web.archive.org/web/20161023171633/http://mendeley.com/\">Mendeley</a>,
        <a href=\"https://web.archive.org/web/20161023171633/http://www.endnote.com/\">Endnote</a>
        and <a href=\"https://web.archive.org/web/20161023171633/http://www.refman.com/\">RefMan</a>with
        one click. We use handles at the moment, but have noticed that researchers
        tend to be more familiar with DOI\u2019s and so will be making the move over
        to them shortly. We\u2019re currently working with <a href=\"https://web.archive.org/web/20161023171633/http://datacite.org/\">DataCite</a>
        through the British Library to get this set up.</p><h2 id=\"8-how-does-figshare-guarantee-long-term-preservation-of-uploaded-data\">8.
        How does figshare guarantee long-term preservation of uploaded data?</h2><p>The
        long term persistence of this research data is essential. The research is
        backed up locally as soon as it is uploaded. We are currently in talks with
        <a href=\"https://web.archive.org/web/20161023171633/http://www.portico.org/\">Portico</a>
        to back up all data and further guarantee this long term persistence.</p><h2
        id=\"9-what-are-your-responsibilities-at-figshare-what-did-you-do-before-figshare\">9.
        What are your responsibilities at figshare? What did you do before Figshare?</h2><p>I\u2019m
        basically responsible for making the platform as useful for researchers as
        possible. I also love going to talk at Universities and conferences to researchers
        directly, to hear their thoughts/opinions. As a former life science researcher
        (I finished my PhD in stem cell biology at Imperial College London in September),
        I understand that what makes sense in a rational world does not make sense
        in the scientific world. You just have to look at the established model of
        scientific research dissemination to understand that. fig<strong>share</strong>
        is useful whether you want to make all of your research outputs available
        or none. Science would just be a lot more efficient and dynamic if they did.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ The Personalized Journal ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/the-personalized-journal/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw2s</id>\n
        \       <published>2012-02-10T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-01T11:40:55.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Earlier this week I wrote
        a <a href=\"https://web.archive.org/web/20161026234447/http://blogs.lse.ac.uk/impactofsocialsciences/2012/02/09/more-tweets-more-citations/\">guest
        post</a> for the <strong>Impact of Social Sciences</strong> blog. In the post
        I talk about a recent paper correlating tweets and citations (<a href=\"https://web.archive.org/web/20161026234447/http://blogs.plos.org/mfenner/2011/12/20/crowdometer-or-trying-to-understand-tweets-about-journal-papers/\">also
        discussed on this blog</a>). But the main argument I try to make is that tweets
        are a powerful filter for personalized scholarly content:</p><blockquote><em><em>A
        few years from now the \u201Cpersonalized journal\u201D will have replaced
        the traditional journal as the primary means to discover new scholarly papers
        with impact to our work.</em></em></blockquote> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Zotero 3.0 Released ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/zotero-3-0-released/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw2t</id>\n
        \       <published>2012-01-31T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T09:37:15.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/zotero.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/zotero.png\"></p><p>Zotero
        3.0 was <a href=\"https://www.zotero.org/blog/zotero-3-0-is-here/\">officially
        released</a> today. The big change in version 3.0 of the reference manager
        is a standalone version that runs outside the Firefox browser. The <a href=\"https://blog.front-matter.io/posts/zotero-3-0-beta-released-works-with-chrome-and-safari/\">first
        beta</a> was released in August 2011.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Say Hello to F1000 Research ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/say-hello-to-f1000-research/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw2v</id>\n
        \       <published>2012-01-30T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T17:10:34.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Faculty 1000 today <a href=\"https://web.archive.org/web/20161010225753/http://f1000research.com/2012/01/30/f1000-research-join-us-and-shape-the-future-of-scholarly-communication-2/\">announced</a>
        <strong>F1000 Research</strong>, <em>a new fully Open Access publishing program
        across biology and medicine, that will start publishing later this year</em>.
        The default open access license is CC-BY, and CC0 for data.</p><p>Important
        features include:</p><ol><li>immediate publication</li><li>open, post-publication
        peer review</li><li>revisioning of work</li><li>raw data repository</li><li>article
        format and content is not predefined</li></ol><p>F1000 Research is a <em>publishing
        program</em> rather than a journal. The format for F1000 Research hasn\u2019t
        been finalized, and F1000 welcomes comments at the <a href=\"https://web.archive.org/web/20161010225753/http://f1000research.com/\">blog</a>
        or via the <a href=\"https://web.archive.org/web/20161010225753/https://twitter.com/#!/F1000Research\">Twitter</a>
        account.</p><p>My main question about F1000 Research: is this a preprint archive
        similar to <a href=\"https://web.archive.org/web/20161010225753/http://arxiv.org/\">ArXiv</a>
        and <a href=\"https://web.archive.org/web/20161010225753/http://precedings.nature.com/\">Nature
        Precedings</a>? I\u2019m a big fan of preprint archives, and I think that
        \u2013 contrary to what most people think \u2013 they <a href=\"https://web.archive.org/web/20161010225753/http://blogs.plos.org/mfenner/2010/10/16/in-which-i-suggest-a-preprint-archive-for-clinical-trials/\">should
        work particularly well</a> for clinical trial data.</p><p>Update (1/30/12):
        <a href=\"https://web.archive.org/web/20161010225753/http://retractionwatch.wordpress.com/2012/01/30/an-arxiv-for-all-of-science-f1000-launches-new-immediate-publication-journal/\">RetractionWatch</a>
        and <a href=\"https://web.archive.org/web/20161010225753/http://blogs.nature.com/news/2012/01/f1000-launches-fast-open-science-publishing-for-biology-and-medicine.html\">Nature
        News</a> also cover this story.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Altmetrics \u2013 Where Do We Go From Here?
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/altmetrics-where-do-we-go-from-here/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw2w</id>\n        <published>2012-01-24T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T09:38:56.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/6732330879_726113a81d.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/6732330879_726113a81d.jpeg\"></p><p>The
        <a href=\"https://web.archive.org/web/20161027000038/http://scienceonline2012.com/\">ScienceOnline2012</a>
        conference last week again was a wonderful experience. This was my third time
        in North Carolina, and I had many great conversations in the sessions, hallways
        \u2013 and bars. One of many highlights was a lunch meeting with fellow PLoS
        bloggers and staffers.</p><p>Together with <a href=\"https://web.archive.org/web/20161027000038/http://twitter.com/Stew\">Euan
        Adie</a> I moderated a session on Friday:</p><h2 id=\"using-altmetrics-tools-to-track-the-scholarly-impact-of-your-research-\">Using
        altmetrics tools to track the scholarly impact of your research.</h2><p>We
        started the session by asking several people in the audience to demonstrate
        their altmetrics tools: <a href=\"https://web.archive.org/web/20161027000038/http://altmetric.com/\">altmetric.com</a>
        (Euan Adie), <a href=\"https://web.archive.org/web/20161027000038/http://readermeter.org/\">ReaderMeter</a>
        (Dario Taraborelli), <a href=\"https://web.archive.org/web/20161027000038/http://total-impact.org/\">Total
        Impact</a> (Jason Priem), <a href=\"https://web.archive.org/web/20161027000038/http://article-level-metrics.plos.org/\">PLoS
        Article-Level Metrics</a> (Jennifer Lin), and <a href=\"https://web.archive.org/web/20161027000038/http://sciencecard.org/\">ScienceCard</a>
        (me). We briefly showed our <a href=\"https://web.archive.org/web/20161027000038/http://crowdometer.org/\">CrowdoMeter</a>
        project where we crowdsourced the meaning of tweets about scholarly papers.</p><p>The
        discussion covered many interesting aspects. I would like to focus on three
        of them.</p><h3 id=\"gaming\">Gaming</h3><p>Altmetrics are still fairly new,
        and therefore not many people try to the cheat yet (but almost 1% of tweets
        in the <a href=\"https://web.archive.org/web/20161027000038/http://crowdometer.org/ratings\">CrowdoMeter
        dataset</a> were already spam). I\u2019m sure that this will change over time,
        and some metrics will be more prone to gaming than others. Gaming is a particular
        problem for usage stats, as it is difficult to impossible to verify them.
        Metrics provided by the producer of a research object (author or publisher)
        will be more susceptible to gaming than metrics from an independent source.
        Anonymous metrics (e.g. Mendeley readers) are more susceptible to gaming than
        metrics that list the source of every citation (e.g. CiteULike bookmarks).</p><h3
        id=\"context\">Context</h3><p>Altmetrics is currently at a stage where we
        collect various metrics, but don\u2019t really know what these numbers mean.
        Does 1,000 downloads, 10 Mendeley bookmarks or 50 tweets mean that the paper
        has impact? And how do we compare altmetrics from different disciplines? Does
        it make a difference if a <a href=\"https://web.archive.org/web/20161027000038/http://www.mathunion.org/general/prizes/fields/details/\">Fields
        Medalist</a> blogs about your paper (an example given in the session)? I think
        that the most interesting metrics are those that take into account who is
        citing the work, being it a regular citation, a social bookmark or a social
        media comment. This is of course how Google <a href=\"https://web.archive.org/web/20161027000038/http://de.wikipedia.org/wiki/PageRank\">PageRank</a>
        works for webpages, and how <a href=\"https://web.archive.org/web/20161027000038/http://www.eigenfactor.org/\">Eigenfactor</a>
        ranks scholarly journals. The context can be further improved by including
        the social networks of the person looking for information, e.g. how many people
        I follow on Twitter have bookmarked this particular paper.</p><h3 id=\"scope\">Scope</h3><p>The
        tools discussed in the ScienceOnline session all have a particular approach
        for gathering altmetrics: altmetrics over a given time period (<em>altmetric.com</em>),
        altmetrics for content produced by a particular publisher (<em>PLoS ALM</em>),
        altmetrics for a given researcher (<em>ReaderMeter</em> and <em>ScienceCard</em>),
        and altmetrics produced for a given dataset on demand (<em>Total-Impact</em>).
        One obvious advantage of this approach is that it reduces the number of datasets
        needed to run the service. Unfortunately, this is an arbitrary distinction,
        and it falls apart when you use a PageRank approach and also look at the metrics
        of citing sources.</p><h3 id=\"conclusions\">Conclusions</h3><p>I think that
        altmetrics has made tremendous progress in 2011, but that there is a lot of
        work to do in 2012. I\u2019m very interested in altmetrics based on PageRank,
        but also want to take social networks into consideration. This is of course
        how finding information on the web works \u2013 scholarly communication is
        just a subset. Unfortunately, this approach requires a massive database of
        scholarly citations, something that is impossible to do for the small part-time
        altmetrics projects mentioned at the beginning of the post.</p><p>I\u2019m
        less interested in usage metrics because they are so prone to gaming and will
        probably become problematic in a few years, and I want to focus on a reasonable
        number of altmetrics. I hope that there will never be a single \u201Caltmetric\u201D,
        but I also don\u2019t think that we need 20 different altmetrics for every
        scholarly work. A lot of interesting work ahead for my ScienceCard project.</p><p>I\u2019m
        looking forward to the altmetrics session at ScienceOnline2013.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Sloan Foundation funds Columbia and Mendeley
        to develop a Citation-Style Language Editor ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/sloan-foundation-funds-columbia-and-mendeley-to-develop-a-citation-style-language-editor/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw2x</id>\n        <published>2012-01-19T00:00:00.000+00:00</published>\n\t\t<updated>2023-08-06T13:29:01.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2023/08/cropped-csl-logo-600-bordered.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2023/08/cropped-csl-logo-600-bordered.png\"></p><p>The
        Sloan Foundation has awarded a $125,000 grant to Columbia University and Mendeley
        to fund the development of a <a href=\"https://doi.org/10.53731/r294649-6f79289-8cw5y\">Citation-Style
        Language</a> (CSL) editor. CSL is a XML-based language to format citations
        and bibliographies, and is used by the reference managers Zotero, Mendeley
        and Papers, and in many other places. Even though more than 1000 citation
        styles are available at <a href=\"https://web.archive.org/web/20161026235632/http://citationstyles.org/\">CitationStyles.org</a>
        (and built into the tools using CSL), it has until now been fairly hard to
        create new citation styles \u2013 editing XML files is not everyones idea
        of having fun. The CSL editor will be made available as open source software.</p><p>Building
        a dedicated CSL editor will be a tremendous boost to the format. The press
        release is <a href=\"https://web.archive.org/web/20161026235632/http://www.prnewswire.com/news-releases/mendeley-teams-up-with-columbia-university-libraries-to-develop-a-citation-style-language-editor-through-125000-sloan-foundation-award-137669218.html\">here</a>.</p><p>In
        related news, Mekentosj is <a href=\"https://web.archive.org/web/20161026235632/http://news.mekentosj.com/2012/01/a-serial-for-a-style/\">giving
        away</a> a Papers 2 serial number for every citation style submitted to CitationStyles.org.</p><h3
        id=\"references\">References</h3><p>Fenner M. Citation Style Language: An
        Interview with Rintze Zelle and Ian Mulvany. Published online September 24,
        2010. doi:<a href=\"https://doi.org/10.53731/r294649-6f79289-8cw5y\">10.53731/r294649-6f79289-8cw5y</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Altmetrics to go \u2013 mobile version of
        ScienceCard available ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/altmetrics-to-go-mobile-version-of-sciencecard-available/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw2y</id>\n        <published>2012-01-08T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T10:26:27.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/sciencecard2.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/sciencecard2.png\"></p><p><a
        href=\"https://web.archive.org/web/20161027000751/http://sciencecard.org/\">ScienceCard</a>
        is a web service that collects all scientific articles published by an author
        and displays their aggregate article-level metrics. Yesterday I added a mobile
        version to ScienceCard, simply browse to ScienceCard with your mobile phone
        or go to <a href=\"https://web.archive.org/web/20161027000751/http://mobile.sciencecard.org/\">http://mobile.sciencecard.org</a>.
        This is a first version based on my work with jQuery Mobile on <a href=\"https://web.archive.org/web/20161027000751/http://blogs.plos.org/mfenner/2012/01/04/crowdometer-goes-mobile/\">CrowdoMeter</a>,
        but I think ScienceCard works really well on a small screen.My ScienceCard
        looks like <a href=\"https://web.archive.org/web/20161027000751/http://mobile.sciencecard.org/mfenner\">this</a>.
        Further down the screen are the articles I have published and the collective
        metrics of these papers.</p><p>Other ScienceCard users have much more impressive
        metrics, both in traditional citations, and in altmetrics such as PDF downloads
        of papers published with PLoS:</p><figure class=\"kg-card kg-image-card\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/sciencecard3.png\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"sciencecard3\" width=\"320\"
        height=\"480\"></figure><p>Metrics of an individual paper (<a href=\"https://web.archive.org/web/20161027000751/http://doi.org/dm9\">http://doi.org/dm9</a>),
        with links to the journal and metrics (e.g. CiteULike bookmarks) look like
        this:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/sciencecard.png\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"sciencecard\" width=\"320\"
        height=\"480\"></figure><p>One idea behind ScienceCard is to make the collection
        and display of this kind of information as simple as possible. I hope this
        is another small step in the right direction.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ CrowdoMeter goes Mobile ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/crowdometer-goes-mobile/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw2z</id>\n
        \       <published>2012-01-04T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T10:28:42.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/crowdometer1.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/crowdometer1.png\"></p><p>Two
        weeks ago Euan Adie from <a href=\"https://web.archive.org/web/20170107002621/http://altmetric.com/\">altmetric.com</a>
        and myself <a href=\"https://web.archive.org/web/20170107002621/http://blogs.plos.org/mfenner/2011/12/20/crowdometer-or-trying-to-understand-tweets-about-journal-papers/\">launched</a>
        the website <a href=\"https://web.archive.org/web/20170107002621/http://crowdometer.org/\">CrowdoMeter</a>,
        a crowdsourcing project that tries to classify tweets about scholarly articles
        using the Citation Typing Ontology (CiTO). Despite the holidays we have gotten
        off to a good start with currently 597 classifications by 56 different users,
        already covering 93% of the tweets we wanted to classify. We will discuss
        the results of this project at the <a href=\"https://web.archive.org/web/20170107002621/http://scienceonline2012.com/\">ScienceOnline2012</a>
        conference in two weeks, but the most important findings can also be watched
        in real-time <a href=\"https://web.archive.org/web/20170107002621/http://crowdometer.org/ratings\">here</a>.</p><p>To
        our knowledge this is the first time that CiTO has been used for the systematic
        classification of tweets, and the preliminary results seem to confirm what
        we and others had thought, i.e. that most tweets contain little semantic information
        and often only retweet the title of a paper. But not only do we now have numbers
        to confirm this, but we can also make some interesting additional observations.
        We find for example that only 1% of tweets disagree with the statements made
        in a paper \u2013 most Twitter users don\u2019t seem to care telling others
        about papers they dislike or disagree with.</p><p>This project is far from
        over, ideally we want 3-5 classifications per tweet or an additional 1,000
        classifications. It is a challenge to build a website so that enough people
        want to help with this project. One idea is to make the classifications as
        simple as possible, and to help further with this we today launched a mobile
        version of CrowdoMeter. Simply browse to <a href=\"https://web.archive.org/web/20170107002621/http://crowdometer.org/\">http://crowdometer.org</a>
        with your iPhone or Android phone, sign in via your Twitter account, and you
        should see something similar to this:</p><figure class=\"kg-card kg-image-card\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/crowdometer.png\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"crowdometer\" width=\"320\"
        height=\"480\"></figure><p>CrowdoMeter uses <a href=\"https://web.archive.org/web/20170107002621/http://jquerymobile.com/\">jQuery
        Mobile</a>, a touch-optimized Javascript framework for smartphones and tablets.
        There are still some minor issues, but in general jQuery Mobile is a great
        tool to optimize a website for mobile users. Users are presented with 10 random
        tweets they haven\u2019t classified yet, and see a simple classification screen
        when clicking (touching) a tweet:</p><figure class=\"kg-card kg-image-card\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/crowdometer1-1.png\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"crowdometer1\" width=\"320\"
        height=\"480\"></figure><p>It should not take longer than 15 minutes to classify
        15-25 tweets, and this would be a tremendous help for the project.</p><p>The
        CrowdoMeter results page displayed the same information as in the desktop
        version of the website, the charts are produced by the <a href=\"https://web.archive.org/web/20170107002621/http://www.highcharts.com/\">Highcharts</a>
        Javascript library (and again jQuery).</p><figure class=\"kg-card kg-image-card\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/crowdometer2.png\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"crowdometer2\" width=\"320\"
        height=\"480\"></figure><p>I\u2019m interested to see how well the crowdsourcing
        for CrowdoMeter will work in the coming weeks. We hope to finish the data
        gathering part in January. If this project generates enough interest I could
        imagine doing another crowdsourcing project, maybe again using the Citation
        Typing Ontology, but this time for blog posts about scholarly papers.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Introducing Annotum to WordPress Bloggers
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/introducing-annotum-to-wordpress-bloggers/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw61</id>\n        <published>2011-12-08T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T10:31:11.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/annotum4-406x500.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/annotum4-406x500.png\"></p><p>Version
        1.0 of <a href=\"https://web.archive.org/web/20120421012848/http://annotum.org/\">Annotum</a>,
        the free WordPress theme for writing scholarly articles, was <a href=\"https://web.archive.org/web/20120421012848/http://googleblog.blogspot.com/2011/11/more-spring-cleaning-out-of-season.html\">announced</a>
        in late November. Back in June I <a href=\"https://web.archive.org/web/20120421012848/http://blogs.plos.org/mfenner/2011/06/30/annotum-publishing-with-wordpress-soon-coming-to-a-journal-near-you/\">wrote
        about</a> the first public version of Annotum, but until now using Annotum
        was experimental. Annotum is available in the <a href=\"https://web.archive.org/web/20120421012848/http://wordpress.org/extend/themes/annotum-base\">WordPress
        Themes Directory</a> at WordPress.org (and has been downloaded more than 9,000
        times in the past three weeks), and is also available for users of WordPress.com.
        I have installed Annotum 1.0 <a href=\"https://web.archive.org/web/20120421012848/http://blogs.scienceonlinelondon.org/annotum/\">here</a>,
        please drop me a note if you want an account.</p><p>But how is an Annotum
        blog different from a regular WordPress blog?</p><h3 id=\"annotum-is-a-wordpress-theme\">Annotum
        is a WordPress Theme</h3><p>WordPress can be extended via Plugins and Themes.
        Whereas Plugins add functionality, themes usually change the look and feel
        of a WordPress site. Annotum is a theme that includes a lot of plugin functionality.
        This strategy makes it easier to get started with Annotum, as there is only
        one theme to install and not a set of plugins that has to work with a particular
        theme. Annotum can still be extended via <a href=\"https://web.archive.org/web/20120421012848/http://codex.wordpress.org/Child_Themes\">child
        themes</a>, e.g. if you want a different look for your blog. And of course
        you can still use other scholarly plugins.</p><h3 id=\"annotum-uses-articles-and-not-posts\">Annotum
        uses articles and not posts</h3><p>Annotum uses the custom post type <em><em>article</em></em>
        for scholarly content. This can be confusing in the beginning, but makes it
        easier to separate scholarly content from regular blog posts.</p><h3 id=\"the-annotum-editor-knows-about-document-structure\"><strong><strong>The
        Annotum editor knows about document structure</strong></strong></h3><p>Scholarly
        articles have more structure than blog posts, and you can add this structure
        with the Annotum editor (see below). This structure is enforced, and the WordPress
        HTML editor is disabled. This makes it easier to create content that conforms
        to the NLM-DTD XML format.</p><figure class=\"kg-card kg-image-card\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/annotum1.png\" class=\"kg-image\"
        alt loading=\"lazy\" title=\"annotum1\" width=\"487\" height=\"319\"></figure><h3
        id=\"annotum-can-import-and-export-in-the-nlm-dtd-format\">Annotum can import
        and export in the NLM-DTD format</h3><p>More specifically, Annotum supports
        the <a href=\"https://web.archive.org/web/20120421012848/http://dtd.nlm.nih.gov/ncbi/kipling/\">Kipling
        subset</a> of the NLM Journal Publishing DTD. NLM-DTD is the standard XML
        format for scholarly articles, and you can for example import published articles
        (with a license that allows reuse) into Annotum to get started. Unfortunately
        there aren\u2019t that many NLM-DTD tools for authors (I haven\u2019t tested
        the<a href=\"https://web.archive.org/web/20120421012848/http://blogs.nature.com/mfenner/2008/11/07/interview-with-pablo-fernicola\">Microsoft
        Word Article Authoring Add-In</a> with Annotum), but this is a great way to
        get content written somewhere else into Annotum.</p><h3 id=\"annotum-knows-that-articles-can-have-multiple-authors\">Annotum
        knows that articles can have multiple authors</h3><p>This is of course important
        for scholarly articles, and the <a href=\"https://web.archive.org/web/20120421012848/http://wordpress.org/extend/plugins/co-authors-plus/\">Co-Authors
        Plus Plugin</a> also adds this feature to any WordPress blog.</p><figure class=\"kg-card
        kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/annotum2.png\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"annotum2\" width=\"416\" height=\"166\"></figure><h3
        id=\"annotum-knows-about-tables-figures-equations-and-references\">Annotum
        knows about tables, figures, equations and references</h3><p>Scholarly articles
        have special formatting requirements for these content types, particularly
        references. Annotum adds visual editors for all of them. Annotum also has
        an editor for LaTeX equations.</p><figure class=\"kg-card kg-image-card\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/annotum4-406x500-1.png\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"annotum4\" width=\"406\" height=\"500\"></figure><p>Annotum
        currently does not integrate with reference managers (Endnote, Mendeley, Zotero,
        etc.) or other WordPress tools that insert citations into blog posts (e.g
        <a href=\"https://web.archive.org/web/20120421012848/http://wordpress.org/extend/plugins/kcite/\">kcite</a>
        or <a href=\"https://web.archive.org/web/20120421012848/http://wordpress.org/extend/plugins/link-to-link/\">Link
        to Link</a>), but you can look up references via DOI and PubMed ID.</p><h3
        id=\"annotum-knows-about-reviewers-and-editors\">Annotum knows about reviewers
        and editors</h3><p>Annotum has \_a built-in review system that knows about
        authors, reviewers and editors. Annotum allows comments only visible to authors
        and reviewers, and sends out notification emails. The <a href=\"https://web.archive.org/web/20120421012848/http://editflow.org/\">Edit
        Flow</a> plugin provides similar functionality.</p><figure class=\"kg-card
        kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/annotum3.png\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"annotum3\" width=\"298\" height=\"206\"></figure><h3
        id=\"annotum-can-export-to-pdf\">Annotum can export to PDF</h3><p>Annotum
        automatically creates a PDF version of your article (using the <a href=\"https://web.archive.org/web/20120421012848/http://code.google.com/p/dompdf/\">dompdf</a>
        HTML to PDF converter). \_Annotum also works with my <a href=\"https://web.archive.org/web/20120421012848/http://wordpress.org/extend/plugins/epub-export/\">ePub
        Export plugin</a>, using <a href=\"https://web.archive.org/web/20120421012848/https://gist.github.com/1046450\">this
        hack</a> to display the ePub link next to the PDF link:</p><figure class=\"kg-card
        kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/annotum5-500x148.png\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"annotum5\" width=\"500\" height=\"148\"></figure><h3
        id=\"summary\">Summary</h3><p>Annotum is a complete and free solution for
        starting a scholarly journal using WordPress. It has everything you need to
        write great scholarly content with WordPress and improves a regular WordPress
        blog in several important ways. Thanks to the support for the NLM-DTD format,
        Annotum can also be used as a writing tool for articles intended for submission
        somewhere else. One of the biggest strengths of WordPress is that it is really
        a writing <em><em>platform</em></em> that can be extended in many interesting
        ways. Maybe we will see WordPress plugins that enhance the equation editor
        or the reference management \u2013 or that connect Annotum to traditional
        journal submission systems.</p><p>Science bloggers will also be interested
        in many of the features of Annotum, but they don\u2019t need the review workflow
        and might find that the support for NLM-DTD restricts them in how they can
        write content. Annotum is at version 1.0, and it is therefore not surprising
        that it still has a few rough edges. My biggest wish for a future version
        is better support for revisions and inline comments \u2013 Google Docs and
        other collaborative writing tools do a much better job highlighting the changes
        made in a text.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ ScienceCard named Finalist in Mendeley/PLoS
        API Binary Battle ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/sciencecard-named-finalist-in-mendeley-plos-api-binary-battle/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw62</id>\n        <published>2011-11-20T00:00:00.000+00:00</published>\n\t\t<updated>2023-09-02T09:19:49.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2023/09/sciencecard.jpg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2023/09/sciencecard.jpg\"></p><p>I\u2019m
        very proud to report that <a href=\"https://web.archive.org/web/20120525033358/http://sciencecard.org/\">ScienceCard</a>
        last week has been <a href=\"https://web.archive.org/web/20120525033358/http://dev.mendeley.com/api-binary-battle\">named
        finalist</a> in the Mendeley/PLoS API Binary Battle. Not bad for a project
        that started only two months ago in a hackathon following the <a href=\"https://web.archive.org/web/20120525033358/http://www.scienceonlinelondon.org/\">Science
        Online London</a> conference and is done in my spare time. The winners of
        the contest will be named on November 30, but I\u2019m more than happy that
        the project has even gotten this far.</p><p>The idea of ScienceCard is threefold:</p><ul><li>make
        it as easy as possible to create a profile page with your publications</li><li>Automatically
        collect citations and other metrics for these publications</li><li>make it
        as easy as possible to reuse this information, e.g. in your personal blog
        or reference manager</li></ul><p>Registration with ScienceCard is easy. You
        create an account by logging in via Twitter (using the OAuth 2 protocol for
        the technically inclined), and then add your account name from one or more
        author identifier services. I added Google Scholar today, the other options
        are Microsoft Academic Search, AuthorClaim and Mendeley (I\u2019m working
        on Scopus Author ID). If you add an Microsoft Academic Search or AuthorClaim
        identifier, ScienceCard will import all your publications from these services.
        ScienceCard currently only understands publications with a DOI, other scholarly
        items could be added in the future. With Mendeley and Google Scholar you only
        link to these services, I\u2019m still having trouble with the Mendeley OAuth
        1 authentication and Google Scholar doesn\u2019t have an API.</p><p>ScienceCard
        is importing all the relevant bibliographic information using the CrossRef
        service. And ScienceCard is creating a <a href=\"https://web.archive.org/web/20120525033358/http://blogs.plos.org/mfenner/2011/10/17/serving-shortdois/\">shortDOI</a>
        for all papers. But more interestingly, ScienceCard is calculating <a href=\"https://web.archive.org/web/20120525033358/http://article-level-metrics.plos.org/\">article-level
        metrics</a> for all publications, and composite numbers for authors. For this
        ScienceCard is using the PLoS Article-Level Metrics API code, but I have added
        more sources, including Mendeley, Microsoft Academic Search and altmetric.com
        (but here only the number of blog posts citing a paper). ScienceCard links
        to most sources so that you can see the actual citations there, only CrossRef
        and altmetric.com don\u2019t offer that. A future update will show all citations
        directly in ScienceCard.</p><p>ScienceCard tries to display a nice profile
        page for each researcher, but also makes it easy to reuse the information
        somewhere else. Each author page is available in six different formats, simply
        add the extension after the (Twitter) username, e.g. <a href=\"https://web.archive.org/web/20120525033358/http://sciencecard.org/mfenner.json\">http://sciencecard.org/mfenner.json</a></p><ul><li>HTML
        \u2013 for regular viewing</li><li>XML \u2013 for reuse by another computer</li><li>JSON
        \u2013 for reuse by another computer</li><li>CSV \u2013 comma-separated values
        for import into a spreadsheet</li><li>RIS \u2013 for reuse by a reference
        manager</li><li>BIB \u2013 BibTeX, for reuse by a reference manager</li></ul><figure
        class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2023/09/annotum2.jpg\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"annotum2\" width=\"500\" height=\"475\"></figure><p>JSON
        is the most interesting format, because it makes it very easy to connect two
        different services. If you for example want to use ScienceCard data on your
        personal WordPress blog you can simply download my <a href=\"https://web.archive.org/web/20120525033358/http://wordpress.org/extend/plugins/contact-info-options/\">Contact
        Info Options WordPress</a> plugin, add your ScienceCard username in your WordPress
        settings, and do some hacking of the author template. The process is unfortunately
        different for every WordPress theme, but you can see an example WordPress
        profile that uses the <a href=\"https://web.archive.org/web/20120525033358/http://annotum.wordpress.com/\">Annotum</a>
        theme (and publishing platform) <a href=\"https://web.archive.org/web/20120525033358/http://blogs.scienceonlinelondon.org/annotum/author/mfenner/\">here</a>:</p><p>This
        WordPress author profile is generated on the fly using ScienceCard data, and
        will therefore automatically update.</p><p>The ScienceCard project is still
        at the beginning, and there are enough ideas to move this project forward
        in interesting ways. I\u2019m particularly interested in improving the user
        interface and display of information, adding datasets and other scholarly
        content, and in integrating with the ORCID unique author identifier service
        once the service launches in the spring of 2012. If you are interested in
        learning more about ScienceCard, please contact me via email or Twitter, or
        attend the altmetrics session at <a href=\"https://web.archive.org/web/20120525033358/http://scienceonline2012.com/\">ScienceOnline2012</a>,
        which I will do together with Euan Adie from altmetric.com and <a href=\"https://web.archive.org/web/20120525033358/http://altmetric.com/interface/plos.html\">PLoS
        Impact Explorer</a>, and Jason Priem from <a href=\"https://web.archive.org/web/20120525033358/http://total-impact.org/\">Total
        Impact</a> (two other Mendeley/PLoS API Binary Battle finalists).</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Why BibTeX, RIS and Endnote XML will soon
        be broken ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/why-bibtex-ris-and-endnote-xml-will-soon-be-broken/\"
        />\n\t\t<id>https://doi.org/10.53731/fhnh1qv-v9ga47e</id>\n        <published>2011-11-08T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-14T14:33:17.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p><a href=\"https://web.archive.org/web/20120610135415/http://www.bibtex.org/\">BibTeX</a>
        is one of the most popular file formats for bibliographies, and is therefore
        commonly used to transfer bibliographies from one reference manager to another,
        or to other applications that handle bibliographic references. <a href=\"https://web.archive.org/web/20120610135415/http://www.refman.com/support/risformat_intro.asp\">RIS</a>
        and <a href=\"https://web.archive.org/web/20120610135415/http://www.endnote.com/support/helpdocs/endnote.zip\">Endnote
        XML</a> are probably the other two bibliographic file formats most commonly
        used. Most reference managers support all three formats, making it easy to
        move references around.</p><p>All three formats have been around for a while,
        BibTeX for example since 1985. Reference management has of course gone through
        many changes during this time, and an important change will happen next year:
        <a href=\"https://web.archive.org/web/20120610135415/http://blogs.plos.org/mfenner/tag/orcid/\">unique
        identifiers for scholarly authors</a>. In 2012 the Open Researcher &amp; Contributor
        ID (<a href=\"https://web.archive.org/web/20120610135415/http://www.orcid.org/\">ORCID</a>)
        initiative will start issuing unique identifiers for researchers, and researchers,
        universities, funding organizations, publishers and hopefully everyone else
        will start using them. But ORCID will only be successful if as many bibliographic
        tools as possible can handle ORCID identifiers, and if these tools can exchange
        these author identifiers.</p><p>None of the three bibliographic file formats
        mentioned above can handle unique author identifiers. If we take for example
        <a href=\"https://web.archive.org/web/20120610135415/http://sciencecard.org/articles/d6n\">this
        paper</a> from ScienceCard, then the authors would look like this in BibTeX:</p><pre><code>author
        = {Kirstein, Janine and Dougan, David and Gerth, Ulf and Hecker, Michael and
        Turgay, K\xFCr\u015Fad}</code></pre><p>And like this in RIS:</p><pre><code>AU
        \ - Kirstein, Janine \nAU  - Dougan, David \nAU  - Gerth, Ulf \nAU  - Hecker,
        Michael \nAU  - Turgay, K\xFCr\u015Fad</code></pre><p>I suggest we extend
        the BibTeX \_format to understand author identifiers like this:</p><pre><code>orcid
        = {1274643, 8474644, 847412, 9183414, 7461414}</code></pre><p>And RIS:</p><pre><code>AI
        \ - 1274643 \nAI  - 8474644 \nAI  - 847412 \nAI  - 9183414 \nAI  - 7461414</code></pre><p>This
        would look similar in Endnote XML. Will we see these changes to BibTeX, RIS
        and Endnote XML in 2012? I don\u2019t know, but I very much hope so. Imagine
        what your Zotero, Mendeley or Endnote could do if the application knew about
        unique author identifiers, e.g. find all papers by a particular author, alert
        me when a particular author publishes something new, or organize your reference
        library by author.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Wikis, Q&amp;As and Cookbooks ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/wikis-q-as-and-cookbooks/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw64</id>\n
        \       <published>2011-10-31T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-29T19:31:46.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n\t\t<category term=\"Science Hack\"/>\n        <media:content
        url=\"https://blog.front-matter.io/content/images/2022/08/16FA8A88-7E03-4237-B6B2-E0CDA03AABF4.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/16FA8A88-7E03-4237-B6B2-E0CDA03AABF4.jpeg\"></p><p>Last
        week I attended the <a href=\"https://web.archive.org/web/20120610120856/http://research.microsoft.com/en-US/events/escience2011-scholarly-communications/default.aspx\">Transforming
        Scholarly Communication</a> workshop in Cambridge, Massachusetts. The main
        goal of the workshop was to come up with practical recommendations for the
        topics <a href=\"https://web.archive.org/web/20120610120856/http://msrworkshop.tumblr.com/tagged/resources\">#resources</a>
        <a href=\"https://web.archive.org/web/20120610120856/http://msrworkshop.tumblr.com/tagged/review\">#review</a>
        <a href=\"https://web.archive.org/web/20120610120856/http://msrworkshop.tumblr.com/tagged/literature\">#literature</a>
        <a href=\"https://web.archive.org/web/20120610120856/http://msrworkshop.tumblr.com/tagged/media\">#media</a>
        <a href=\"https://web.archive.org/web/20120610120856/http://msrworkshop.tumblr.com/tagged/recognition\">#recognition</a>
        and <a href=\"https://web.archive.org/web/20120610120856/http://msrworkshop.tumblr.com/tagged/platforms\">#platforms</a>:</p><blockquote>This
        workshop strives to be different in one important way\u2014rather than focusing
        on utopian visions for their own sake, we will focus on the existing and newly
        developed technologies designed to enhance scholarship and scholarly communication
        in order to determine factors for their success and their potential.</blockquote><p>The
        workshop started with product demos (18 demos in a little over three hours!),
        we then spent two half days working in smaller groups on one of the six topics
        above. I was assigned to the <strong><strong>#recognition</strong></strong>
        group, and we started with a very open discussion about recognition, reputation,
        altmetrics and related topics. The work was much more focussed on the second
        day, where we produced a <a href=\"https://web.archive.org/web/20120610120856/http://msrworkshop.tumblr.com/tagged/recognition\">draft
        text</a> with practical recommendations.</p><p>We all reported back to the
        whole group in the plenary discussion the second day, but unfortunately didn\u2019t
        have much time (and energy) left to discuss the reports of the other topic
        groups in more detail. It was suggested that we create a Wikipedia page summarizing
        our reports, so that researchers interested in new scholarly communication
        tools would have a starting point.</p><p>I personally felt that most reports
        (including our own) had too much detail information \u2013 they are great
        resources of information, but are probably overwhelming for the average researcher.
        I therefore thought that a good alternative to a wiki page would be a Question
        &amp; Answer site similar to the hugely popular <a href=\"https://web.archive.org/web/20120610120856/http://stackoverflow.com/\">Stack
        Overflow</a> and <a href=\"https://web.archive.org/web/20120610120856/http://www.quora.com/\">Quora</a>.
        Even simpler would be a book in the <a href=\"https://web.archive.org/web/20120610120856/http://shop.oreilly.com/category/series/cookbooks.do\">Cookbook</a>
        or <a href=\"https://web.archive.org/web/20120610120856/http://pragprog.com/book/fr_arr/advanced-rails-recipes\">Recipes</a>
        format so popular with programmers. The book would be a collection of solutions
        for many of the small problems we face in scholarly communication today. We
        probably need hundreds of recipes, to start this off I today wrote a <a href=\"https://web.archive.org/web/20120610120856/http://blogs.plos.org/mfenner/scholarly-communication-cookbook-create-a-researcher-profile-page/\">recipe
        for creating a researcher profile page</a> (very much based on our topic report).</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Book Review: Reinventing Discovery by Michael
        Nielsen ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/book-review-reinventing-discovery-by-michael-nielsen/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw65</id>\n        <published>2011-10-22T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T10:33:07.000+00:00</updated>\n\t\t<category
        term=\"Book Review\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/Reinventing_Discovery.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/Reinventing_Discovery.jpeg\"></p><p>Reinventing
        Discovery, the book by Michael Nielsen we all have been waiting for, has finally
        been published on Friday. Today I flew to Boston for the Microsoft Research
        eScience Workshop: Transforming Scholarly Communication, and reading the book
        on the plane was the perfect preparation for the workshop.</p><p>Michael says
        in the book:</p><blockquote><em><em>I wrote this book with the goal of lightning
        an almighty fire under the scientific community. \u2026 We have an opportunity
        to change the way knowledge is constructed.</em></em></blockquote><p>You can
        <a href=\"https://press.princeton.edu/chapters/s9517.pdf\">download the chapter
        1 as PDF</a>, and you can also watch the videos of two of his recent presentations:
        <a href=\"https://www.youtube.com/watch?v=DnWocYKqvhw\">TEDx Waterloo</a>
        in March and <a href=\"https://web.archive.org/web/20120525040623/http://river-valley.tv/keynote-solo2011/\">Science
        Online London</a> in September.</p><p>The book uses examples from science
        and related disciplines \u2013 e.g. programming or chess \u2013 to examine
        both the opportunities and challenges of doing Open Science. The book is good
        reading, because Michael is aware of the many challenges that we face before
        science can be done differently. One example for this is the peer-reviewed
        journal article as the main currency to evaluate researchers. Until scientists
        are also rewarded for producing or curating data, programming scientific software,
        etc., we will not be able to start a new era of networked science.</p><p>Highly
        recommended reading.</p><p>Timo Hannay has also written a <a href=\"https://doi.org/10.1038/nphys2109\">review
        of the book</a> for Nature Physics, and I\u2019m sure we will soon see many
        more.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Data citation how-to guide released by Digital
        Curation Centre ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/data-citation-how-to-guide-released-by-digital-curation-centre/\"
        />\n\t\t<id>https://doi.org/10.53731/ddkjr75-55ff0rf</id>\n        <published>2011-10-19T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-14T14:34:48.000+00:00</updated>\n
        \       <media:content url=\"\" medium=\"image\"/>\n        <content type=\"html\"><![CDATA[
        <p><img src=\"\"></p><p>Earlier this week <strong><strong>Alex Ball</strong></strong>
        and <strong><strong>Monica Duke</strong></strong> from the Digital Curation
        Centre released the how-to guide <a href=\"https://web.archive.org/web/20120525040549/http://www.dcc.ac.uk/resources/how-guides/cite-datasets\">Cite
        Datasets and Link to Publications</a>. The guide is highly recommended reading
        for everyone interested in data citation. The guide was released under a <a
        href=\"https://web.archive.org/web/20120525040549/http://creativecommons.org/licenses/by/2.5/scotland/\">Creative
        Commons Attribution license</a>, allowing me to post the summary for researchers
        below:</p><h2 id=\"summary-for-researchers\">Summary for researchers</h2><p><em>If
        you have generated/collected data to be used as evidence in an academic publication,
        you should deposit them with a suitable data archive or repository as soon
        as you are able. If they do not provide you with a persistent identifier or
        URL for your data, encourage them to do so.</em></p><p><em><em>When citing
        a dataset in a paper, use the citation style required by the editor/publisher.
        If no form is suggested for datasets, take a standard data citation style
        (e.g. DataCite\u2019s) and adapt it to match the style for textual publications.</em></em></p><p><em><em>Give
        dataset identifiers in the form of a URL wherever possible, unless otherwise
        directed.</em></em></p><p><em><em>Include data citations alongside those for
        textual publications. Some reference management packages now include support
        for datasets, which should make this easier.</em></em></p><p><em><em>Cite
        datasets at the finest-grained level available that meets your need. If that
        is not fine enough, provide details of the subset of data you are using at
        the point in the text where you make the citation.</em></em></p><p><em><em>If
        a dataset exists in several versions, be sure to cite the exact version you
        used.</em></em></p><p><em><em>When you publish a paper that cites a dataset,
        notify the repository that holds the dataset, so it can add a link from that
        dataset to your paper.</em></em></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Serving shortDOIs ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/serving-shortdois/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw67</id>\n
        \       <published>2011-10-17T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T10:34:30.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>The shortDOI service was launched
        by the International DOI Foundation (IDF) in May 2010. The service creates
        short versions of the often long DOIs, e.g. <strong><strong>10/dvq</strong></strong>
        instead of <strong><strong>10.1093/hmg/ddp202</strong></strong> \u2013 written
        as URL this would be <a href=\"https://web.archive.org/web/20120531234808/http://doi.org/dvq\">http://doi.org/dvq</a>
        instead of <a href=\"https://doi.org/10.1093/hmg/ddp202\">http://doi.org/10.1093/hmg/ddp202</a>.
        shortDOIs started as a <a href=\"https://web.archive.org/web/20120531234808/http://labs.crossref.org/site/toi_dois.html\">CrossRef
        Labs project</a> in 2009 and were originally named TOI DOI \u2013 TOI stands
        for tiny object identifier. For a good introduction I recommend <a href=\"https://web.archive.org/web/20120531234808/http://go-to-hellman.blogspot.com/2010/05/long-handle-on-shortened-digital-object.html\">Eric
        Hellman\u2019s blog post</a> written in May 2010 when the shortDOI service
        was launched.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/2093290327_0803f40005.jpeg\"
        class=\"kg-image\" alt=\"The long and the short of it\" loading=\"lazy\" width=\"320\"
        height=\"480\"></figure><p>shortDOIs provide exactly the same service as normal
        DOIs, i.e. they redirect the user to the digital resource. They are convenient,
        particularly for email and Twitter where space is limited. Links to journal
        articles created by URL shorteners such as bit.ly or goo.gl look similar,
        but require two redirects (first to dx.doi.org, then to the journal article).
        But URL shorteners provide additional services to users, e.g. customized links
        and usage statistics.</p><p>As far as I can tell shortDOIs have not become
        popular since the service started more than a year ago. One important reason
        is certainly that publishers are not really using them for their journal articles.
        I don\u2019t think many users will go through the <a href=\"https://web.archive.org/web/20120531234808/http://shortdoi.org/\">extra
        steps creating a shortDOI</a> just to use a DOI with Twitter \u2013 the Twitter
        URL shortener t.co will do this automatically for them. Michael Kuhn has created
        a <a href=\"https://web.archive.org/web/20120531234808/http://blog.mckuhn.de/2011/02/bookmarklet-for-shortdoiorg.html\">bookmarklet</a>
        that makes it a little bit easier to create shortDOIs. If we want shortDOIs
        to ever become popular, then we should ask journal publishers, bibliographic
        databases, reference managers and other places that currently use DOIs to
        enable them.</p><p>Starting yesterday <a href=\"https://web.archive.org/web/20120531234808/http://sciencecard.org/\">ScienceCard</a>
        is using shortDOIs instead of DOIs, and is also using the shortDOI to link
        to individual articles on ScienceCard, e.g. <a href=\"https://web.archive.org/web/20120531234808/http://sciencecard.org/articles/dvq\">http://sciencecard.org/articles/dvq</a>.
        Yesterday I\u2019ve created about 750 shortDOIs for ScienceCard, and \_this
        probably already makes ScienceCard one of the larger shortDOI users. I will
        decide in the coming months whether shortDOIs have improved the ScienceCard
        service. A nice feature would for example be the announcement of newly published
        papers via Twitter.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Two reviews of new reference manager ReadCube
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/two-reviews-of-new-reference-manager-readcube/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw68</id>\n        <published>2011-10-11T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T10:36:09.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/readcube-500x275.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/readcube-500x275.jpeg\"></p><figure
        class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/readcube3.jpeg\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"readcube3\" width=\"220\"
        height=\"49\"></figure><p>Today, <a href=\"https://web.archive.org/web/20120610121628/http://www.digital-science.com/\">Digital
        Science</a> announced an investment in startup <a href=\"https://web.archive.org/web/20120610121628/http://www.labtiva.com/\">Labtiva</a>.
        And Labtiva released a \u201Ccommunity preview\u201D of their reference manager
        <a href=\"https://web.archive.org/web/20120610121628/http://www.readcube.com/\">ReadCube</a>.
        The community preview is a free download for Windows and Mac, and this is
        the summary of my first impressions.</p><p>You could write two different reviews
        about ReadCube. The first version would mention the really slick interface,
        and the fun you have using the program. ReadCube is doing a good job importing
        the PDFs on your hard drive and adding bibliographic information to them.
        In addition to PDF import you can also search PubMed and Google Scholar. ReadCube
        helps you find related papers by listing the references and citing papers
        of the paper you imported. ReaderCube also gives recommendations based on
        the papers in your library.</p><figure class=\"kg-card kg-image-card\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/readcube1-500x276.jpg\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"readcube\" width=\"500\" height=\"276\"></figure><p>ReadCube
        includes an integrated PDF viewer that also allows text highlighting and note
        taking.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/readcube-500x275-1.jpeg\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"readcube\" width=\"500\" height=\"275\"></figure><p>The
        community preview is free, so please download ReadCube to find out whether
        you like it.</p><p>The second review would take a different approach. It would
        ask what problem ReadCube tries to solve, and why researchers should start
        using ReadCube rather than the tools they already use, maybe for many years.
        ReadCube is a reference manager with a particular focus on organizing the
        PDFs of scholarly papers. There a number of programs out there that can do
        the same. <a href=\"https://web.archive.org/web/20120610121628/http://www.mekentosj.com/papers/\">Papers</a>
        for Macintosh for example is a very similar program, but the first version
        of it has been released four years ago. Even more traditional reference managers
        now include inline PDF readers with annotation support, including the <a href=\"https://web.archive.org/web/20120610121628/http://www.endnote.com/enx5info.asp\">latest
        version of Endnote</a>. Mendeley and Zotero are two other alternatives, and
        they are both free and available for Windows, Mac and Linux. It\u2019s difficult
        to see what is unique in ReadCube, and on the other hand some important features
        are missing (e.g. no bookmarklet to import from other sources, no reference
        type other than journal articles, no group sharing feature, no integration
        with Microsoft Word). And ReadCube is based on Adobe Air, a cross-platform
        development environment that you either love or hate.</p><p>It will be interesting
        to watch what direction ReadCube development will take. They started a few
        years later than their competitors, and it will be a lot of work to catch
        up. I wish the Labtiva team good luck.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ The trouble with DOIs ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/the-trouble-with-dois/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw69</id>\n
        \       <published>2011-10-09T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T10:37:37.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/4632436148_7795a0127c.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/4632436148_7795a0127c.jpeg\"></p><p><a
        href=\"https://web.archive.org/web/20120610120821/http://sciencecard.org/\">ScienceCard</a>
        is a new service that I started last month with the simple idea to automatically
        track all journal articles of a given author, and to collect the article-level
        metrics (citations, bookmarks, etc.) for these papers. ScienceCard requires
        unique identifiers for articles and authors to work. Unique identifiers for
        authors is a difficult topic <a href=\"https://web.archive.org/web/20120610120821/http://blogs.plos.org/mfenner/tag/orcid/\">regularly
        discussed</a> in this blog. But I thought that using digital object identifiers
        (DOI) for journal articles would be easy. The system managed by CrossRef was
        started 10 years ago, and almost all journal publishers now use DOIs \u2013
        there were 49,350,542 registered CrossRef DOI links as of today.</p><p>The
        first problem I encountered is that many bibliographic databases don\u2019t
        fully support DOIs. Most of them store DOIs, but not all of them allow queries
        using DOIs, and very few services allow linking to them using DOIs. In the
        end I had to store various other article identifiers in ScienceCard (currently
        PubMed ID, PubMed Central ID, Microsoft Academic Search ID, Mendeley UUID,
        Scopus ID). One side effect of this proliferation of identifiers is that (in
        very rare cases) DOIs are not unique in these bibliographic services. And
        it makes it more complicated than necessary to build tools based on DOIs.
        The members of CrossRef are publishers, the other service providers (whether
        public or private) seem to be reluctant to fully support a service where they
        have no direct influence.</p><p>The second problem with DOIs is that they
        are often not web-friendly. DOIs are really permanent URLs, and CrossRef has
        recently changed the <a href=\"https://web.archive.org/web/20120610120821/http://www.crossref.org/help/Content/02_Getting_started/Displaying_DOIs_in_print_and_online.htm\">display
        guidelines for DOIs</a> to reflect this. Instead of <strong><strong><a href=\"https://web.archive.org/web/20120610120821/http://dx.doi.org/10.1371/journal.pcbi.0010057\">doi:
        10.1371/journal.pcbi.0010057</a> </strong></strong>we are supposed to show
        DOIs as <strong><strong><a href=\"https://web.archive.org/web/20120610120821/http://dx.doi.org/10.1371/journal.pcbi.0010057\">http://doi.org/10.1371/journal.pcbi.0010057</a></strong></strong>.
        The problem is that DOIs can contain characters such as \u201C+\u201D, \u201C(\u201C,
        \u201C.\u201D or \u201C/\u201D that need to be escaped when used as URLs.
        Some ScienceCard examples include the following:</p><ol><li><a href=\"https://web.archive.org/web/20120610120821/http://dx.doi.org/10.1016/S0959-8049(05)80357-0\">http://doi.org/10.1016/S0959-8049(05)80357-0</a></li><li><a
        href=\"https://web.archive.org/web/20120610120821/http://dx.doi.org/10.1093/bioinformatics/12.4.357\">http://doi.org/10.1093/bioinformatics/12.4.357</a></li><li><a
        href=\"https://web.archive.org/web/20120610120821/http://dx.doi.org/10.1021/bi980175+\">http://doi.org/10.1021/bi980175+</a></li><li><a
        href=\"https://web.archive.org/web/20120610120821/http://dx.doi.org/10.1642/0004-8038(2002)119[0088:SSCPEO]2.0.CO;2\">http://doi.org/10.1642/0004-8038(2002)119[0088:SSCPEO]2.0.CO;2</a></li></ol><p>These
        special characters can create problems when DOIs are used in software programs.
        ScienceCard for example wants to create links to articles in the format <strong><strong>http://sciencecard.org/10.1642/0004-8038(2002)119[0088:SSCPEO]2.0.CO;2.xml</strong></strong>,
        but this function is currently broken.</p><p>One possible solution are <a
        href=\"https://web.archive.org/web/20120610120821/http://shortdoi.org/\">shortDOIs</a>.
        Article (3) would for example become <a href=\"https://web.archive.org/web/20120610120821/http://doi.org/dcp\">http://doi.org/dcp</a>,
        whereas article (4) is rejected as invalid DOI. I would love to use shortDOIs
        in ScienceCard and other places (e.g. Twitter), but haven\u2019t found an
        API yet that automatically returns shortDOIs for DOIs.</p><p><a href=\"https://web.archive.org/web/20120610120821/http://blogs.plos.org/mfenner/2011/03/26/direct-links-to-figures-and-tables-using-component-dois/\">Component
        DOIs</a> directly link to a figure or table of a paper. This is an underused,
        but very useful feature, and is for example provided by the <em><em>PLoS</em></em>
        journals. Unfortunately component DOIs can confuse bibliographic databases
        and make it more difficult to track all the links to a given article. I had
        to write a little routine to detect component DOIs imported into ScienceCard.</p><p>Articles
        are sometimes updated or corrected, and many publishers will use a different
        DOI for the updated article. This is a problem when you want to track all
        references to this particular article. <a href=\"https://doi.org/10.1371/journal.pcbi.0020121\">http://doi.org/10.1371/journal.pcbi.0020121</a>
        and <a href=\"https://web.archive.org/web/20120610120821/http://dx.doi.org/10.1371/journal.pcbi.0020181\">http://doi.org/10.1371/journal.pcbi.0020181</a>
        are for example DOIs for the same <em><em>PLoS Computational Biology</em></em>
        article (the latter is the corrected version). <em><em>Nature Precedings</em></em>
        uses a format that is easier to understand for computers - <a href=\"https://web.archive.org/web/20120610120821/http://dx.doi.org/10.1038/npre.2011.4479.3\">http://doi.org/10.1038/npre.2011.4479.3</a>
        is for example a link to the third version of this particular manuscript.
        <a href=\"https://web.archive.org/web/20120610120821/http://www.crossref.org/crossmark/index.html\">CrossMark</a>
        is a new CrossRef service that will make it easier to track the different
        versions of a manuscript, including retractions.</p><p>ScienceCard should
        of course not be limited to journal articles. I\u2019m also interested in
        other scholarly content, e.g. preprints from <strong><strong>ArXiV</strong></strong>
        or research datasets from <strong><strong>DataCite</strong></strong>. But
        I want to first solve the problems with DOIs for journal articles, before
        I tackle the much bigger problems with uniquely identifying and tracking other
        scholarly contributions. Science blog posts are a good example. It would be
        wonderful to track them in ScienceCard, but I don\u2019t see how we can do
        that before we have a system in place that assigns unique and persistent identifiers
        to blog posts. For this and other reasons I really want unique identifiers
        for science blog posts, and we should also think about using DOIs for this
        purpose.</p><p><strong><strong>Update October 9</strong></strong>: A ScienceCard
        <a href=\"https://web.archive.org/web/20120610120821/http://sciencecard.org/articles/804\">example</a>
        of multiple identifiers for the same paper:</p><ul><li>DOI: 10.1007/s10654-011-9572-7</li><li>PubMed
        ID: 21461943</li><li>PubMed Central ID: 3115050</li><li>Microsoft Academic
        Search: 48849734</li><li>Mendeley: 5b0023f0-609e-11e0-8f54-0024e8453de6</li><li>Mendeley
        URL: http://www.mendeley.com/research/informativeness-indices-blood-pressure-obesity-serum-lipids-relation-ischaemic-heart-disease-mortality-huntii-study/</li><li>Scopus:
        79959714408</li></ul> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Announcing ScienceCard ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/announcing-sciencecard/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw6a</id>\n
        \       <published>2011-09-28T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T10:38:44.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/sciencecard-500x345.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/sciencecard-500x345.jpeg\"></p><p>Metrics
        for scholarly works are used for evaluation and discovery. The Journal Impact
        Factor is widely used, but is not the best tool to look at the metrics of
        an individual article. In the past few years we finally started to have the
        technology to do article-level metrics (citations, downloads, etc.) and PLoS
        has <a href=\"https://web.archive.org/web/20120610140041/http://article-level-metrics.plos.org/\">pushed
        this concept</a> since at least 2009. I first heard about the PLoS Article-Level
        Metrics project in a presentation given by Pete Binfield in July 2009, and
        a month later I <a href=\"https://web.archive.org/web/20120610140041/http://blogs.plos.org/mfenner/2009/08/15/plos_one_interview_with_peter_binfield/\">interviewed
        him</a> about this project.</p><p>Article-level metrics are a major step forward
        from journal-level metrics, but I always wanted to extend this concept to
        authors. Three events in the past few weeks worked nicely together and made
        me start an author-level metrics project myself: <a href=\"https://web.archive.org/web/20120610140041/http://dev.mendeley.com/api-binary-battle\">programming
        contest by Mendeley and PLoS</a> with a September 30 deadline, a hackfest
        following the <a href=\"https://web.archive.org/web/20120610140041/http://www.scienceonlinelondon.org/\">Science
        Online London Conference</a> in early September, and two conferences (in <a
        href=\"https://web.archive.org/web/20120610140041/http://irisc-workshop.org/irisc2011-helsinki/\">Helsinki</a>
        and <a href=\"https://web.archive.org/web/20120610140041/http://www.orcid.org/civicrm/event/info?id=2&amp;reset=1\">Geneva</a>)
        in mid-September discussing the value of unique author identifiers for researchers.</p><p>I\u2019ve
        taken the <a href=\"https://web.archive.org/web/20120610140041/http://code.google.com/p/alt-metrics/\">Open
        Source Article-Level Metrics API Server</a> from PLoS and added a few important
        features: metrics by author, additional metrics from Mendeley and Microsoft
        Academic Search, and a web-based interface that less authors register via
        their Twitter account. The result is <a href=\"https://web.archive.org/web/20120610140041/http://sciencecard.org/\">ScienceCard</a>,
        a website I launched this weekend and today entered for the Mendeley/PLoS
        Binary Battle contest. ScienceCard currently uses <a href=\"https://web.archive.org/web/20120610140041/http://code.google.com/p/alt-metrics/\">Microsoft
        Academic Search</a> to find all papers of a particular author, the next version
        will allow users to retrieve info about their personal papers from Mendeley.</p><p>Working
        on ScienceCard has already taught me a lot about the problems we face when
        doing metrics for scholarly works. Most problems are social and not technical.
        Digital object identifiers (DOIs) for example have been the standard identifier
        for journal articles for ten years, but many places (including PubMed, Microsoft
        Academic Search and Mendeley) want users to use their own identifiers for
        journal articles. This makes it unnecessarily difficult to find articles and
        collect metrics. Identifiers for authors are even more complicated. ScienceCard
        will of course use <a href=\"https://web.archive.org/web/20120610140041/http://orcid.org/\">ORCID</a>
        identifiers when they become available in 2012, and I hope that I can make
        the transition to ORCID easier for ScienceCard users.</p><p>Let me know what
        you think.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Hacking the PLoS Article-Level Metrics API
        Server ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/hacking-the-plos-article-level-metrics-api-server/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw6b</id>\n        <published>2011-09-05T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-29T10:04:03.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/DALL-E-2022-08-29-12.03.20---Thomas-Gainsborough-oil-painting-of-a-garden-gnome-with-an-umbrella-in-front-of-the-london-tower.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/DALL-E-2022-08-29-12.03.20---Thomas-Gainsborough-oil-painting-of-a-garden-gnome-with-an-umbrella-in-front-of-the-london-tower.png\"></p><p>The
        <a href=\"https://web.archive.org/web/20120610134729/http://www.scienceonlinelondon.org/\">Science
        Online London 2011 Conference</a> was a great event that took place last Friday
        and Saturday. I was able to celebrate the first <em><em>PLoS Blogs</em></em>
        anniversary together with community manager <strong><strong>Brian Mossop</strong></strong>,
        but a detailed conference post will follow later. The blog posts covering
        the event are <a href=\"https://web.archive.org/web/20120610134729/http://scienceonlinelondon.wikidot.com/coverage\">here</a>,
        and the list is growing by the hour.</p><p>On Sunday a few brave souls met
        at the <a href=\"https://web.archive.org/web/20120610134729/http://www.mendeley.com/\">Mendeley</a>
        offices for the Science Online London hackathon to spend some time on a cool
        programming project. We were greeted by <strong><strong>Victor Henning</strong></strong>
        and <strong><strong>Jason Hoyt</strong></strong> and quickly came up with
        a few good ideas. Jason finished work on <a href=\"https://web.archive.org/web/20120610134729/http://twendeley.ologeez.org/\">Twendeley</a>,
        a cool Twitter/Mendeley mashup that looks for papers mentioned in your Twitter
        stream and finds relevant articles in Mendeley. I wanted to do some work on
        the PLoS <a href=\"https://web.archive.org/web/20120610134729/http://code.google.com/p/alt-metrics/\">Article-Level
        Metrics API</a>.</p><p><a href=\"https://web.archive.org/web/20120610134729/http://article-level-metrics.plos.org/\">Article-Level
        Metrics</a> looks at the usage and reach of an individual article instead
        of using the <strong><strong>Journal Impact Factor</strong></strong> as a
        proxy for the impact of a paper. The PLoS Article-Level Metrics API provides
        access to some interesting numbers: not only citations, HTML pageviews and
        PDF downloads, but also social metrics such as number of bookmarks in CiteULike
        or number of readers in Mendeley.</p><p>But for the hackathon I was not interested
        in building a tool that talks to the Article-Metrics API. On Sunday morning
        I had discovered that the PLoS Article-Level Metrics server software is not
        only available as Open Source software, but is built with <strong><strong>Ruby
        on Rails</strong></strong>, a programming framework that I\u2019m familiar
        with. So I thought it would be fun to start improving the software by adding
        metrics on the author level. And by building your own Article-Level Metrics
        server, you are not limited to papers published in PLoS journals, or to the
        kinds of metrics provided by PLoS. Wouldn\u2019t it for example be nice to
        also include download counts for <a href=\"https://web.archive.org/web/20120610134729/http://datadryad.org/\">Dryad</a>
        datasets?</p><figure class=\"kg-card kg-image-card\"><img src=\"https://web.archive.org/web/20120610134729im_/http://blogs.plos.org/mfenner/files/2011/09/alm2-500x355.png\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"alm2\"></figure><p>With the
        help of <strong><strong>Kristi Holmes</strong></strong> and <strong><strong>Cameron
        Neylon</strong></strong> we quickly got the API server up and running, added
        a few papers and retrieved citation counts from PubMed Central and the number
        of bookmarks from CiteULike (see above). A few hours later we could add authors,
        and today I was able to automatically import the first papers by author.</p><figure
        class=\"kg-card kg-image-card\"><img src=\"https://web.archive.org/web/20120610134729im_/http://blogs.plos.org/mfenner/files/2011/09/alm-500x274.png\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"alm\"></figure><p>For author-level
        metrics we of course need a widely used unique author identifier, and an API
        we can talk to. Otherwise author disambiguation quickly becomes frustrating.
        Until <a href=\"https://web.archive.org/web/20120610134729/http://www.orcid.org/\">ORCID</a>
        comes along next year, the <a href=\"https://web.archive.org/web/20120610134729/http://social.microsoft.com/Forums/en-US/mas/thread/9a23b2d6-6599-4853-acf5-c1692a64365e\">Microsoft
        Academic Search API</a> looks like one of the best ways to retrieve DOIs for
        papers published by a particular author.</p><p>The code for this project is
        available at <a href=\"https://web.archive.org/web/20120610134729/http://github.com/mfenner/plos-alt-metrics\">Github</a>.
        This obviously needs a lot more work, but it shouldn\u2019t take more than
        a few months to have the author part working properly and to find a host for
        a server. And because this is an API server based on the PLoS code, all tools
        that interact with the PLoS Article-Metrics server can use this system immediately.</p><p>This
        service should make it a little bit easier to build a <a href=\"https://web.archive.org/web/20120610134729/http://www.phdcomics.com/comics.php?f=1417\">professional
        trading card for scientists</a>, or a dashboard of the <a href=\"https://web.archive.org/web/20120610134729/http://total-impact.org/\">total
        impact</a> of your research.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ On Microattribution ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/on-microattribution/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw6c</id>\n
        \       <published>2011-08-28T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-12T07:41:48.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>At the <a
        href=\"https://web.archive.org/web/20120610133410/http://www.scienceonlinelondon.org/\">Science
        Online London Conference</a> later this week I will moderate a session on
        <strong><strong>microattribution</strong></strong>, together with <a href=\"https://web.archive.org/web/20120610133410/http://www.mikepeel.net/blog/\">Mike
        Peel</a>, <a href=\"https://web.archive.org/web/20120610133410/http://blogs.scientificamerican.com/a-blog-around-the-clock/\">Bora
        Zivkovic</a> and <a href=\"https://web.archive.org/web/20120610133410/http://blogs.openaccesscentral.com/blogs/gigablog/\">Scott
        Edmunds</a>. I thought that microattribution would be an established concept,
        so I was surprised to find so little information about it. Wikipedia <a href=\"https://web.archive.org/web/20120610133410/http://en.wikipedia.org/w/index.php?title=Microattribution&amp;action=edit&amp;redlink=1\">doesn\u2019t
        know</a> about microattribution. A search in PubMed retrieves only two hits
        (the 2011 <em><em>Nature Genetics</em></em> paper mentioned below and an editorial
        in the same issue). One of the first mentions of the term appears to be an
        August 2007 Editorial in <em><em>Nature Genetics</em></em> (<strong><strong><a
        href=\"https://web.archive.org/web/20120610133410/http://dx.doi.org/10.1038/ng0807-931\">Compete,
        collaborate, compel</a></strong></strong>), but at the time the term also
        included what we today would call data citation. It therefore might be a good
        idea to try a definition:</p><blockquote>Microattribution ascribes a small
        scholarly contribution to a particular author.</blockquote><p>Important for
        this definition is the <strong><strong>small scholarly contribution</strong></strong>,
        which until now we have been unable to appropriately associate with its contributor.
        This scholarly contribution is too small to merit a scholarly paper or publication
        as dataset. And in most cases we have not bothered to provide unique identifiers
        for the scholarly contribution and/or the author.</p><p>A very good example
        for where microattribution can be valuable is the description of genetic variation.
        A March 2011 <em><em>Nature Genetics</em></em> paper (<strong><strong><a href=\"https://web.archive.org/web/20120610133410/http://dx.doi.org/10.1038/ng.785\">Systematic
        documentation and analysis of human genetic variation in hemoglobinopathies
        using the microattribution approach</a>) </strong></strong>concluded that
        microattribution <em><em>demonstrably increased the reporting of human variants,
        leading to a comprehensive online resource for systematically describing human
        genetic variation</em></em>. One example described in the paper is the genetic
        variation in the promoter of the KLF1 erythroid transcription factor, explaining
        differences in the level of fetal hemoglobin (HbF). Most of these variants
        were never published in a paper (the blue squares in the figure).</p><figure
        class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://web.archive.org/web/20120610133410im_/http://blogs.plos.org/mfenner/files/2011/08/ng.785-F3-500x305.jpg\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"ng.785-F3\"><figcaption><strong><strong>Figure
        3</strong></strong> <em><em>from Giardine B et al. Nature Genetics 2011. </em>https://<em><a
        href=\"https://doi.org/10.1038/ng.785\">doi.org/10.1038/ng.785</a>.</em></em></figcaption></figure><p>For
        the first time we now seem to have both the technology and willingness to
        enable microattributions on a large scale. There will be ample time for discussion
        in the microattribution session on Friday, but I\u2019m personally most interested
        in the next practical steps to move microattribution forward. My background
        is unique author identifiers (ORCID) and my co-moderators bring in their experience
        with Wikipedia (Mike Peel), science blog aggregation (Bora Zivkovic) and crowdsourcing
        of sequencing efforts (Scott Edmunds). Some of the questions that I would
        like to address in the session are:</p><ol><li>Should all microattribution
        information be collected in one, several or many places?</li><li>Do we need
        one, several or many identifier schemes for contributions and authors?</li><li>What
        level of detail should we allow for microattributions?</li><li>Should microattributions
        use persistent identifiers?</li><li>Can and should we keep our scholarly contributions
        separate from other contributions?</li></ol><figure class=\"kg-card kg-image-card\"><img
        src=\"https://web.archive.org/web/20120610133410im_/http://blogs.plos.org/mfenner/files/2011/08/Scientific-Attribution-v.2.jpg\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"Scientific Attribution v.2\"></figure><p><em><em>My
        simplified view of the scholarly record, updated</em></em></p><p>I <a href=\"https://web.archive.org/web/20120610133410/http://blogs.plos.org/mfenner/scientific-attribution-principles/\">have
        said before</a> that I think that attribution should be separated from evaluation,
        and I think is also true for microattribution. The main reason is that evaluation
        is something we still know very little about, and a scholarly record available
        to everybody will make it much easier to make progress here. I don\u2019t
        think anybody knows yet what distinguishes a good from a bad microattribution,
        or whether it is possible to compare the scientific impact of 10 or 100 microattributions
        to one scholarly paper.</p><p><em><em>Disclaimer: I sit on the Board of Directors
        of the Open Researcher &amp; Contributor ID (ORCID) initiative which aims
        to help solve this and related problems.</em></em></p><h2 id=\"references\">References</h2>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Zotero 3.0 Beta released, works with Chrome
        and Safari ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/zotero-3-0-beta-released-works-with-chrome-and-safari/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw6d</id>\n        <published>2011-08-23T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T10:40:16.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/zotero-500x328-1.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/zotero-500x328-1.png\"></p><p>The
        first beta of the reference manager Zotero 3.0 was <a href=\"https://web.archive.org/web/20120525045252/http://www.zotero.org/blog/announcing-zotero-3-0-beta-release/\">released</a>
        yesterday. The big news is that Zotero 3.0 no longer only runs within the
        Firefox browser, but is now also available as a standalone version similar
        to other reference managers.</p><p>Zotero Connectors integrate with the Chrome
        and Safari browser. They also allow saving directly to your Zotero library
        at zotero.org. Zotero does not support Internet Explorer. Users of this blog
        are not representative of all internet users, and Zotero 3.0 would offer browser
        support for more than 80% of them.</p><figure class=\"kg-card kg-image-card\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/YNgML-web-browsers-used-by-gobbledygook-readers-august-2011.png\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"analytics\" width=\"1240\"
        height=\"1096\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/YNgML-web-browsers-used-by-gobbledygook-readers-august-2011.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/08/YNgML-web-browsers-used-by-gobbledygook-readers-august-2011.png
        1000w, https://blog.front-matter.io/content/images/2022/08/YNgML-web-browsers-used-by-gobbledygook-readers-august-2011.png
        1240w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Zotero 3.0 is beta
        software and you should expect bugs. One small problem I discovered is that
        the German translation is incomplete, e.g. in the menus. But overall Zotero
        looks and feels very similar to the familiar Zotero 2.1 \u2013 just as a standalone
        version. One new feature I like is duplicate detection, an experimental feature
        of earlier versions.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Personal names around the world ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/personal-names-around-the-world/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw6e</id>\n        <published>2011-08-14T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T10:42:36.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/noname.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/noname.jpeg\"></p><p>Yesterday
        I discovered (via a tweet by <a href=\"https://web.archive.org/web/20120610133741/https://twitter.com/#!/ostephens\">Owen
        Stephens</a>) a very interesting document <a href=\"https://web.archive.org/web/20120610133741/http://www.w3.org/International/questions/qa-personal-names\">Personal
        names around the world</a> that discusses the following question:</p><blockquote>How
        do people\u2019s names differ around the world, and what are the implications
        of those differences on the design of forms, databases, ontologies, etc. for
        the Web?</blockquote><p>The document was written by <a href=\"https://web.archive.org/web/20120610133741/http://rishida.net/\">Richard
        Ishida</a>, Internationalization Activity Lead at the <a href=\"https://web.archive.org/web/20120610133741/http://www.w3.org/International/\">W3C</a>
        (World Wide Web Consortium). The document was published on July 26, and Richard
        was seeking comments until August 7 before finalizing the document.</p><p>The
        document is a good summary how names for people differ around the world, e.g.
        multiple family names (Spain, Latin America), no family name (Iceland), different
        ordering of names (China, Korea, Japan), non-latin characters in names (many
        countries), and other issues.</p><p>The second part of the document makes
        a few suggestions of how these variations in names could be handled on the
        web. The text should be required reading for anybody who is designing databases
        that handle international names \u2013 and there are a lot of them. A form
        that asks for <strong><strong>first name</strong></strong>, <strong><strong>middle
        initial</strong></strong> and <strong><strong>last name</strong></strong>
        will just not be appropriate for a lot of people.</p><p>I am lucky that my
        German name doesn\u2019t contain any German umlauts (\xE4, \xF6, \xFC) or
        the letter \xDF, so I haven\u2019t had any bad (or funny) experiences with
        my name. But I know that it can be a big problem for a lot of people. The
        result is that people end up having several spellings for their name, or write
        their name in ways that were not intended, e.g. a hyphen between the two family
        names in Spain. The name is something very personal, and I think the least
        we can do is to allow people to use their name appropriately.</p><p>Science
        is probably no better or worse in this regard than other domains. If we are
        lucky, we find a journal that prints our name correctly, or have a database
        that understands that \xFC should be sorted as ue. But for the most part,
        this seems to be an unresolved issue. And I don\u2019t want everybody to start
        using a first name and last name in that order and only with ASCII or latin
        characters. That would be boring. So please start thinking about this issue
        when you design systems that use personal names, and use the W3C document
        by Richard Ishida as a starting point.</p><p><em><em>Disclaimer: I sit on
        the Board of Directors of the Open Researcher &amp; Contributor ID (ORCID)
        initiative which aims to help solve this and related problems.</em></em></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Book Review: Visualize This by Nathan Yau
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/book-review-visualize-this-by-nathan-yau/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw6f</id>\n        <published>2011-08-13T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T10:45:08.000+00:00</updated>\n\t\t<category
        term=\"Book Review\"/>\n\t\t<category term=\"Chart\"/>\n        <media:content
        url=\"https://blog.front-matter.io/content/images/2022/08/visualize-this-drop.jpg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/visualize-this-drop.jpg\"></p><p>In
        July Wiley published the book <strong><strong><a href=\"https://web.archive.org/web/20120611111645/http://book.flowingdata.com/\">Visualize
        This \u2013 The Flowing Data Guide to Design, Visualization and Statistics</a></strong></strong>.
        The book is written by <em><em>Nathan Yau</em></em>, and he is of course also
        behind the popular <a href=\"https://web.archive.org/web/20120611111645/http://flowingdata.com/\">FlowingData</a>
        blog about the same topic. This is a short review of the book.</p><p>Please
        keep in mind that I\u2019m no expert in data visualization. The book is written
        for people like me, an expert in the topic will probably look at the book
        differently.</p><p>And the book is intended as an introduction to important
        concepts. It is probably the wrong book if you are interested in using a particular
        tool \u2013 e.g. Adobe Illustrator, R or Flash \u2013 for Data Visualization.</p><p>The
        examples in the book are about topics similar to those used in the FlowingData
        blog, most of them are about data journalism. This is not a book about visualization
        of scientific experiments.</p><p>The first chapter of the book talks about
        how to tell stories with data. This is a very important chapter, as learning
        how to tell a good story is more important than knowing all the details on
        how to use a tool for visualization.</p><p>Nathan continues with a chapter
        on how to find and format data for data visualization. We are then introduced
        to a number of important visualization tools, and their particular strengths.
        Nathan uses a large number of tools in the book, but seems to particularly
        like Python for formatting data, R for for calculation and visualization,
        and Adobe Illustrator for perfecting the result for publication. This is one
        of the take-home messages of the book for me: instead of perfecting the use
        of one particular tool, learn to decide what works best for a particular problem.
        R and Illustrator are a good start for most problems.</p><p>The next few chapters
        look at visualizations in different contexts: patterns over time, proportions,
        relationships, differences and spatial relationships. All chapters are written
        with examples that you can follow along, and with enough basic information
        that you can start solving similar problems on your own. Below is a chart
        I tried myself after reading the book. It looks at the number of member organizations
        of the non-profit ORCID over time (more info <a href=\"https://web.archive.org/web/20120611111645/http://www.orcid.org/news/250-participating-organizations-have-joined-orcid\">here</a>).</p><figure
        class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/orcid-500x400.png\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"orcid\" width=\"500\" height=\"400\"></figure><p>I
        can highly recommend <strong><strong>Visualize This</strong></strong> to anybody
        interested in learning about data visualization. I found only two things I
        didn\u2019t like. I wish Nathan had spent more time explaining how a data
        graph can be improved visually. In many examples he shows how small changes
        in color or font size can make a big difference in presentation, but I would
        prefer to see a more systematic approach to this important topic. I wouldn\u2019t
        mind if he would drop the chapter on <a href=\"https://en.wikipedia.org/wiki/Chernoff_face\">Chernoff
        faces</a> instead \u2013 fun stuff, but not really important in an introductory
        text.</p><p>My other problem is with the publisher. I read the book as ePub
        on my iPad. It is nice to have web links you can click in the text, but it
        would have been even nicer if the ePub had ben prepared with a little bit
        more care. Most images in the text (there are many) are too small \u2013 in
        an ePub you expect figures to enlarge and show more detail when you click
        on them. And figure headings were regularly orphaned (on a different page
        than the figure itself). ePub is an evolving standard, but a little bit of
        consideration for typography and layout would go a long way.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Google Scholar Citations, Researcher Profiles,
        and why we need an Open Bibliography ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/google-scholar-citations-researcher-profiles-and-why-we-need-an-open-bibliography/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw6h</id>\n        <published>2011-07-27T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T10:48:11.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/SafariSnapshot001-500x306.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/SafariSnapshot001-500x306.jpeg\"></p><p>Last
        week Google Scholar <a href=\"https://web.archive.org/web/20120610140256/http://googlescholar.blogspot.com/2011/07/google-scholar-citations.html\">announced
        a new feature</a> on the Google Scholar Blog: <strong><strong>Google Scholar
        Citations</strong></strong>. The stated purpose of this tool is to allow researchers
        to calculate their citation metrics, e.g. their <a href=\"https://web.archive.org/web/20120610140256/http://blogs.plos.org/mfenner/2007/08/17/do_you_know_your_hirsch_number/\">Hirsch
        index</a> (H-index).</p><p>This is an interesting new service, that not only
        helps with calculating citation metrics, but also shows you who is citing
        your papers \u2013 a great discovery tool. Signup to Google Scholar Citations
        is currently limited, but I was able to create a profile <a href=\"https://web.archive.org/web/20120610140256/http://scholar.google.com/citations?user=N05QljgAAAAJ&amp;hl=en\">here</a>.</p><p>The
        problem? We have this service already. <strong><strong>Scopus</strong></strong>,
        <strong><strong>Researcher ID</strong></strong> and others have provided this
        information for some time, and Google Scholar Citations looks very much like
        a response to the recently launched Microsoft Academic Search:</p><figure
        class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/SafariSnapshot002-500x349.jpeg\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"SafariSnapshot002\" width=\"500\"
        height=\"349\"></figure><p>Will we soon see a similar offering from <strong><strong>Mendeley</strong></strong>
        or <strong><strong>ResearchGate</strong></strong>? There is of course nothing
        wrong with competition, and there is no reason why we can\u2019t have more
        than one place that provides researcher profiles. But as I have <a href=\"https://web.archive.org/web/20120610140256/http://blogs.plos.org/mfenner/scientific-attribution-principles/\">argued
        before</a>,</p><p><strong><strong>Systems that measure and evaluate scientific
        contributions can and should be separate from the databases that hold the
        scholarly record.</strong></strong></p><p>It is not only a waste of resources
        (both Google Scholar\u2019s and the individual researchers\u2019 who maintain
        their profiles) to many many different bibliographic databases, but it also
        makes it impossible to compare citation metrics. In the examples above Alonzo
        Church has a H-index of 19 at Google Scholar, but only 11 at Microsoft Academic
        Search (and probably again a different one somewhere else). This means that
        we can only use an H-index when we mention where (and when) it was calculated.</p><p>The
        better solution is a common <a href=\"https://web.archive.org/web/20120610140256/http://3lib.org/\">open
        bibliography</a>, and the difference between the various service would be
        how they calculate the citation metric or present the bibliographic data \u2013
        you can see the different approaches taken by Google Scholar and Microsoft
        Academic Search in the screenshots above. This is a difficult task, but not
        impossible to do. The first step would be to realize that having a common
        open bibliography would create tremendous value for everybody as we can start
        building tools on top this bibliography without requiring to collect all the
        bibliographic data ourselves. We see something like this happening in smaller
        domains, and the <a href=\"https://web.archive.org/web/20120610140256/http://blogs.plos.org/mfenner/2011/04/29/web-tools-for-searching-the-biomedical-literature-part-i/\">tools
        using the PubMed database</a> are a good example.</p><p>From a researcher
        perspective it makes little sense to have many different places where you
        can maintain your publications. It makes much more sense to do this once and
        then see the information reused in different services. This is the approach
        the Open Researcher &amp; Contributor ID initiative is <a href=\"https://web.archive.org/web/20120610140256/http://www.orcid.org/principles\">taking</a>:</p><p><strong><strong>All
        profile data contributed to ORCID by researchers or claimed by them will be
        available in standard formats for free download (subject to the researchers\u2019
        own privacy settings) that is updated once a year and released under the CC0
        waiver.</strong></strong></p><p><em><em>Disclaimer: I sit on the Board of
        Directors of the Open Researcher &amp; Contributor ID (ORCID) initiative which
        aims to help solve this and related problems.</em></em></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Mendeley 1.0 released Today ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/mendeley-1-0-released-today/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw6g</id>\n
        \       <published>2011-07-27T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T13:43:32.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Version 1.0 of the reference
        manager Mendeley was <a href=\"https://web.archive.org/web/20120525041606/http://www.prnewswire.com/news-releases/mendeley-rips-beta-label-off-award-winning-research-collaboration-software-with-v10-release-126244103.html\">released</a>
        today. In good Web 2.0 tradition it took three years from the first Beta release
        to the first \u201Cfinished\u201D product. I <a href=\"https://web.archive.org/web/20120525041606/http://blogs.plos.org/mfenner/2008/09/05/interview_with_victor_henning_from_mendeley/\">interviewed</a>
        co-founder Victor Henning back in September 2008, and both the software and
        the company have gone a long way since then. Congratulations.</p><figure class=\"kg-card
        kg-image-card kg-card-hascaption\"><img src=\"https://web.archive.org/web/20120525041606im_/http://farm4.static.flickr.com/3212/2822759480_c330822084_o.jpg\"
        class=\"kg-image\" alt loading=\"lazy\"><figcaption><em><em>Mendeley in 2008.
        Picture taken from <a href=\"https://web.archive.org/web/20120525041606/http://blogs.plos.org/mfenner/2008/09/05/interview_with_victor_henning_from_mendeley/\">my
        interview</a> with Victor.</em></em></figcaption></figure><p>Mendeley has
        changed reference management in many ways. Most importantly it has added another
        choice for users, and their constant push for new features has benefitted
        everybody, including the competition.</p><p>The Mendeley software has been
        downloaded one million times and 100 million papers have been uploaded to
        the service. Mendeley is no longer the new kid on the blog. With their popularity
        and size also comes an increased responsibility for the community. On top
        of my wish list: a decent <a href=\"https://web.archive.org/web/20120525041606/http://blogs.plos.org/mfenner/2010/09/24/citation-style-language-an-interview-with-rintze-zelle-and-ian-mulvany/\">Citation
        Style</a> Editor that would also benefit <strong><strong>Zotero</strong></strong>
        and <strong><strong>Papers 2 </strong></strong>users (<a href=\"https://web.archive.org/web/20120525041606/http://www.mendeley.com/blog/research-tutorials/howto-edit-citation-styles-for-use-in-mendeley/\">hacking
        the XML files</a> is not an option for most people).</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ How to formally cite a blog post ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/how-to-formally-cite-a-blog-post/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw1v</id>\n        <published>2011-07-21T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-19T07:48:53.000+00:00</updated>\n\t\t<category
        term=\"Science Hack\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/4534468843_176c790812.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/4534468843_176c790812.jpeg\"></p><p>Other
        blog posts often provide important background material for your own posts,
        and they are typically cited by <a href=\"https://blog.front-matter.io/posts/beyond-the-pdf-is-epub/\">inline
        links</a> in the text. But sometimes we need more formal citations, e.g. when
        citing blog posts in a journal article or when providing a bibliography. But
        how do you properly cite a blog post?</p><p>The <a href=\"https://web.archive.org/web/20170913072431/http://www.apastyle.org/\">APA
        Style</a> \u2013 from the Publication Manual of the American Psychological
        Association \u2013 suggests the following format:</p><p><strong>Fenner, M.H.</strong>
        (2011, January 23). Beyond the PDF \u2026 is ePub [Web log post]. Retrieved
        from <a href=\"https://blog.front-matter.io/posts/beyond-the-pdf-is-epub/\">https://blog.front-matter.io/posts/beyond-the-pdf-is-epub/</a></p><p>This
        is a good start, but I think the citation should include the name of the blog.
        The <a href=\"https://web.archive.org/web/20170913072431/http://www.chicagomanualofstyle.org/tools_citationguide.html\">Chicago
        Manual of Style</a> does this:</p><p><strong>Fenner, M.H., </strong>\u201CBeyond
        the PDF \u2026 is ePub,\u201D Gobbledygook, January 23, 2011, <a href=\"https://blog.front-matter.io/posts/beyond-the-pdf-is-epub/\">https://blog.front-matter.io/posts/beyond-the-pdf-is-epub/</a></p><p>The
        <a href=\"https://web.archive.org/web/20170913072431/http://www.library.illinois.edu/learn/tutorials/mla.html\">MLA
        Style</a> also mentions the Publisher, and the date the blog post was accessed
        (in addition to the publication date):</p><p><strong>Fenner, M.H.</strong>
        \u201CBeyond the PDF \u2026 is ePub\u201D. <em>Gobbledygook</em>. PLoS Blogs.
        January 23, 2011. Web. July 21, 2011. <a href=\"https://blog.front-matter.io/posts/beyond-the-pdf-is-epub/\">https://blog.front-matter.io/posts/beyond-the-pdf-is-epub/</a></p><p>This
        is a little bit too much for me. There is an argument to use the accession
        date for web content, but having two dates can be confusing and the publication
        date is more important. I personally prefer a citation format that looks very
        similar to a journal article citation (and comes closest to the Chicago Manual
        of Style):</p><p><strong>Fenner, M.H. </strong>Beyond the PDF \u2026 is ePub.
        <em>Gobbledygook</em>, January 23, 2011. <a href=\"https://blog.front-matter.io/posts/beyond-the-pdf-is-epub/\">https://blog.front-matter.io/posts/beyond-the-pdf-is-epub/</a></p><p>If
        we want to include blog posts in a reference list, we also have to think about
        the formatting. In <strong>BibTeX</strong>a blog entry would look like this:</p><!--kg-card-begin:
        html--><pre>\n    @misc{ author = {Fenner, Martin}, \n    title = {Beyond
        the PDF \u2026 is ePub}, \n    journal = {Gobbledygook}, \n    type = {Blog},
        \n    number = {January 23}, \n    year = {2011}, \n    howpublished = {\\url{https://blog.front-matter.io/posts/beyond-the-pdf-is-epub/}}\n</pre><!--kg-card-end:
        html--><p><strong>BibTeX</strong> doesn\u2019t have an entry type for blog
        posts, so we have to use @misc and use the type field. @unpublished is an
        alternative, but that is a strange name. We have to put the URL into the howpublished
        field, which is also awkward.</p><p><a href=\"https://web.archive.org/web/20170913072431/http://www.refman.com/support/risformat_intro.asp\">RIS</a>
        is another popular format, and knows about blogs and URLs:</p><!--kg-card-begin:
        html--><pre>\nTY  - BLOG \nAU  - Fenner, Martin \nTI  - Beyond the PDF \u2026
        is ePub \nJF  - Gobbledygook \nPY  - 2011/01/23 \nUR  - https://blog.front-matter.io/posts/beyond-the-pdf-is-epub/
        \nER  -\n</pre><!--kg-card-end: html--><p><strong>BibTeX</strong> and <strong>RIS</strong>
        both predate the web. A modern reference format should use HTML or XML so
        that it can be embedded directly in the blog post. The recently announced
        <a href=\"https://web.archive.org/web/20170913072431/http://blogs.plos.org/mfenner/2011/06/07/schema-org-for-scholarly-html/\">Schema.org</a>
        micro data format is a strong candidate for this <a href=\"https://web.archive.org/web/20170913072431/http://scholarlyhtml.org/\">Scholarly
        HTML</a>, and it has a <a href=\"https://web.archive.org/web/20170913072431/http://schema.org/BlogPosting\">BlogPosting</a>
        format:</p><p>&lt;div itemscope itemtype=\"http://schema.org/BlogPosting\"&gt;
        &lt;span itemprop=\"author\" itemscope itemtype=\"http://schema.org/Person\"&gt;
        &lt;span itemprop=\"name\"&gt;Fenner, Martin&lt;/span&gt; &lt;/span&gt; &lt;span
        itemprop=\"name\"&gt;Beyond the PDF \u2026 is ePub&lt;/span&gt; &lt;span itemprop=\"publisher\"&gt;Gobbledygook&lt;/span&gt;
        &lt;time datetime=\"2011-01-23\"&gt;01/23/11&lt;/time&gt; &lt;a href=\"<a
        href=\"https://blog.front-matter.io/posts/beyond-the-pdf-is-epub/\">https://blog.front-matter.io/posts/beyond-the-pdf-is-epub/</a>\"
        itemprop=\"url\"&gt;<a href=\"https://blog.front-matter.io/posts/beyond-the-pdf-is-epub/\">https://blog.front-matter.io/posts/beyond-the-pdf-is-epub/</a>&lt;/a&gt;
        &lt;/div&gt;</p><p>There are other ways to describe this blog post with <strong>Schema.org</strong>,
        but the best practices are still evolving. How this BlogPosting above looks
        in a blog obviously depends on the CSS styling used, without any styling it
        looks like this:</p><p>Fenner, Martin<br>Beyond the PDF \u2026 is ePub<br>Gobbledygook<br>01/23/11<br><a
        href=\"https://blog.front-matter.io/posts/beyond-the-pdf-is-epub/\">https://blog.front-matter.io/posts/beyond-the-pdf-is-epub/</a></p><p>With
        a little work on the CSS for this blog, the citation could look exactly as
        shown above, but with added semantic information that is understood by search
        engines and other tools. It is clear to me that HTML-based standards such
        as Schema.org are the future for embedding citation information in blog posts.
        We need better tools to make this process as painless as possible.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Did you receive spam because you published
        a paper? ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/did-you-receive-spam-because-you-published-a-paper/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw6j</id>\n        <published>2011-07-13T00:00:00.000+00:00</published>\n\t\t<updated>2023-07-05T18:21:08.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Brendan Thomas has <a href=\"https://doi.org/10.4065/mcp.2010.0817\">published
        an interesting paper</a> that looks at author email addresses in the PubMed
        database of biomedical literature. Email addresses of first authors have been
        added to PubMed since 1996, and they can be retrieved via the standard web
        interface or automated software. This makes PubMed an excellent place to find
        the email address of an academic author, but also shows that PubMed is very
        vulnerable to email address harvesting.</p><p>The problem is not limited to
        PubMed; this is also an issue with many scholarly journals. Email addresses
        are used as contact information in scholarly papers, and they are commonly
        displayed on journal webpages. You can harvest email addresses from <em><em>NEJM</em></em>,
        <em><em>Science</em></em> or <em><em>PLoS</em></em> webpages, and you don\u2019t
        even need a subscription. <em><em>JAMA</em></em> is hiding the email address,
        and <em><em>Nature</em></em> is providing an author contact form. Both journals
        provide the email address in the PDF.</p><p>Most journals provide the postal
        address of corresponding authors. Journals added email addresses in the 1990s,
        and this of course has become the preferred method of communication among
        scientists \u2013 when was the last time you received a postcard for a reprint
        request? Unfortunately we have long learned that it is no longer safe to make
        email addresses publicly available \u2013 more than 90% of email traffic is
        <a href=\"https://web.archive.org/web/20120611043917/http://www.ftc.gov/bcp/edu/microsites/spam/\">spam</a>.</p><p>Journal
        publishers have to rethink their policies regarding contact information of
        their authors. And authors should demand from journals that their email addresses
        are treated with more respect for privacy. There are better ways to provide
        contact information for corresponding authors, and I don\u2019t mean a link
        to their Twitter account or LinkedIn profile. Journal publishers should create
        author profile pages that not only list all publications of a particular author,
        but also the relevant contact information. There should be contact forms instead
        of plain email addresses, and authors should be able to control what information
        is displayed in their author profile. Author profiles of course can be further
        extended in many ways, from links to publications with other publishers to
        author-level metrics.</p><p><em><em>Disclaimer: I sit on the Board of Directors
        of the Open Researcher &amp; Contributor ID (ORCID) initiative which aims
        to help solve this and related problems.</em></em></p><h2 id=\"references\">References</h2><p>Thomas
        B. E-mail Address Harvesting on PubMed\u2014A Call for Responsible Handling
        of E-mail Addresses. <em>Mayo Clinic Proceedings</em>. 2011;86(4):362. doi:<a
        href=\"https://doi.org/10.4065/mcp.2010.0817\">10.4065/mcp.2010.0817</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Conference microblogging: FriendFeed, Twitter
        and now Google+ ? ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/conference-microblogging-friendfeed-twitter-and-now-google/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw6k</id>\n        <published>2011-07-04T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-19T08:45:48.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Blogging
        is a <a href=\"https://blog.front-matter.io/posts/conference_blogging_interview_with_alex_knoll/\">great
        format </a>to report from conferences. The regular blog format works best
        for posts written at the end of the day \u2013 unless you are typing really
        fast. Microblogging, i.e. a number of short or very short posts by a group
        of people, works better for live blogging of an event and has become very
        popular.</p><p><a href=\"https://web.archive.org/web/20120611100409/http://www.friendfeed.com/\">FriendFeed</a>
        was probably the first widely used microblogging tool for scientific conferences
        starting in 2008, and a <a href=\"https://doi.org/10.1371/journal.pcbi.1000263\">January
        2009 paper </a>describes the experience at 2008 ISMB conference in Toronto.
        By late 2009 Twitter had surpassed FriendFeed in popularity, and at some point
        in 2010 most people seemed to have switched from FriendFeed to Twitter for
        conference microblogging.</p><p>Twitter is a great tool in many ways, but
        is far from perfect for conferences. The biggest problem is that the tweets
        about a particular topic aren\u2019t really connected. Hashtags help to find
        tweets about a particular conference, but hashtags for a particular session
        have never cught on. This makes it very difficult to have a real discussion,
        or to find related messages later on.</p><p>Facebook is not only extremely
        popular, but has also taken many of the features of FriendFeed. But for some
        reason it has not become a popular conference microblogging tool for scientists.
        I think this is because many people use Facebook primarily for their social
        interactions, and keep those separate from their professional discussions.</p><p><a
        href=\"https://plus.google.com/\">Google+</a> was released last week, and
        the services has many of the features of FriendFeed and Facebook (who bought
        FriendFeed in August 2009, one of the reasons the service has never become
        that popular). Google+ allows discussions around a particular message (post,
        tweet?). It doesn\u2019t have groups about a particular topic (e.g. conference),
        and doesn\u2019t yet understand a concept similar to hashtags. The service
        looks very nice from a desktop computer, but the mobile version for iPhone
        and iPad isn\u2019t very polished (I haven\u2019t tested the Android app).</p><p>The
        experience from Twitter tells me that the most important feature for a great
        conference microblogging tool is popularity, and this is only partly related
        to the technology behind the service. There are already a good number of science
        bloggers and other Science 2.0 folks on Google+ and we have seen some good
        discussions (e.g. a <a href=\"https://plus.google.com/106537123721037364937/posts/buxDWrvq8vU#106537123721037364937/posts/buxDWrvq8vU\">discussion
        about conference microblogging</a>), so that is a very good sign. But the
        experience with Google Wave (<a href=\"https://blog.front-matter.io/posts/what_comes_after_google_wave/\">discontinued</a>)
        and Google Buzz (not that many people seem to use it) makes me a bit cautious,
        and I will wait how Google+ evolves in the coming months before I get too
        excited.</p><p>Update: Added a paragraph about Facebook.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Annotum: Publishing with WordPress soon
        coming to a journal near you ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/annotum-publishing-with-wordpress-soon-coming-to-a-journal-near-you/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw6m</id>\n        <published>2011-06-30T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T13:42:01.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Last week the first <a href=\"http://annotum.wordpress.com/2011/06/23/alpha-release/\">Alpha</a>
        version of <strong><strong>Annotum</strong></strong> was released. <a href=\"http://annotum.wordpress.com/about/\">Annotum</a>
        is \u201Ca\_scholarly authoring and publishing platform based on WordPress\u201D.
        I <a href=\"http://river-valley.tv/annotem-an-open-source-journal-authoring-and-publishing-platform-based-on-wordpress/\">first
        learned</a> about Annotum at the <a href=\"https://sites.google.com/site/beyondthepdf/\">Beyond
        the PDF</a> workshop in January. One of the themes of the workshop was that
        we need better tools for authoring, reviewing and publishing of scholarly
        articles. For many at the workshop it was obvious that these tools should
        be web-based, use HTML as the file format, and should use readily available
        tools whenever possible.</p><p>WordPress is a perfect candidate for such a
        tool, but needs to be extended with functions required for scholarly articles:
        better handling of citations, figures and tables, support of standard document
        formats such as <a href=\"http://dtd.nlm.nih.gov/\">NLM-DTD</a>, and support
        of \_a review workflow with co-authors, editors and reviewers. WordPress can
        easily be extended with <a href=\"https://web.archive.org/web/20120611092155/http://wordpress.org/extend/plugins/\">plugins</a>,
        and a good number of plugins have been released for scholars. A good starting
        point are plugins tagged <a href=\"http://wordpress.org/extend/plugins/tags/res-comms\">res-comms</a>
        and the <a href=\"https://groups.google.com/forum/#!forum/wordpress-for-scientists\">WordPress
        for Scientists</a> Google Group.</p><p>There is one problem with these scholarly
        plugins: none of them offers a complete solution, and it is sometimes tricky
        to make them work with other required plugins or with each other (a particular
        problem are plugins that use Javascript). This means that there is currently
        no out-of-the-box solution to create, review and publish scholarly content
        with WordPress.</p><p><strong><strong>Annotum</strong></strong> is an ambitious
        project that wants to change this. It helps that Annotum seems to have sufficient
        funding and commitment to launch a production version later this year \u2013
        rather than being the part-time effort of a single developer. Technically
        it is a WordPress theme, and not a plugin. Themes normally are responsible
        for the look of a WordPress site, but they can also contain functions normally
        found in plugins. Installing a single theme is much easier for the average
        WordPress user than installing a number of plugins plus a theme that works
        with all plugins. BTW, themes can have child themes, so this doesn\u2019t
        mean that all Annotum sites will look the same.</p><p>Annotum of course can\u2019t
        do everything by itself and has to work with existing plugins (it took me
        only one hour to <a href=\"https://web.archive.org/web/20120611092155/http://blogs.xartrials.org/annotum/article/the-mycobacterium-tuberculosis-drugome-and-its-polypharmacological-implications/\">make
        it work</a> with my <a href=\"https://web.archive.org/web/20120611092155/http://wordpress.org/extend/plugins/epub-export/\">ePub
        Export</a> plugin). Annotum\u2019s Carl Leubsdorf is part of the WordPress
        for Scientists community and I think he will make sure that Annotum will work
        well with the plugins already out there.</p><p>I hope that Annotum will not
        only become a nice out-of-the-box solution to create a WordPress-based journal
        or science blog, but will also be a big stimulus for the budding community
        of scholarly WordPress users and developers.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Three funding organizations will launch
        new open access journal ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/three-funding-organizations-will-launch-new-open-access-journal/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw6n</id>\n        <published>2011-06-23T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T13:40:23.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Three leading funding organizations
        today made this important <a href=\"https://web.archive.org/web/20120611031434/http://www.wellcome.ac.uk/News/Media-office/Press-releases/2011/WTVM051897.htm\">announcement</a>:</p><blockquote>The
        Howard Hughes Medical Institute, the Max Planck Society and the Wellcome Trust
        announced today that they are to support a new, top-tier, open access journal
        for biomedical and life sciences research.</blockquote><p>Some features of
        the new journal:</p><ul><li>open access</li><li>name of journal to be decided</li><li>aims
        to attract and define the very best research publications</li><li>papers will
        be accepted or rejected as rapidly as possible</li><li>first issue expected
        for summer of 2012</li><li>editor-in-chief and editorial team will be active
        scientists</li><li>journal will enable improved data presentation</li><li>long-term
        business model to be developed, the three organisations made a commitment
        to cover initial costs</li></ul><p>This is an important announcement, as the
        journal has the potential to have a major impact on publishing biomedical
        research. Two aspects of the announcement surprise me: many details about
        the new journal have not been decided, I would have expected at least a decision
        about the journal name and Editor-in-Chief. And from the few details in the
        announcement the new journal appears to take a fairly conservative approach
        to publishing. You could for example compare today\u2019s press release with
        the editorial explaining the launch of PLoS Biology from October 2003 (<a
        href=\"https://web.archive.org/web/20120611031434/http://dx.doi.org/doi:10.1371/journal.pbio.0000036\">Why
        PLoS became a Publisher</a>). This approach is understandable as most scientists
        are conservative and don\u2019t care much about new publishing technologies
        or even open access; they only care about having their research accepted in
        a journal with high impact. Publishing this kind of journal \u2013 which usually
        means high rejection rates and time-consuming editorial work \u2013 is difficult
        with with an author-pays business model. The deep pockets of the three funding
        organizations change this equation.</p><p>Earlier this year we saw the the
        announcements of <a href=\"https://web.archive.org/web/20120611031434/http://blogs.plos.org/mfenner/2011/01/06/new-journal-nature-one-launched-today/\">Scientific
        Reports</a>, <a href=\"https://web.archive.org/web/20120611031434/http://dx.doi.org/10.1136/bmj.d1190\">BMJ
        Open</a> and similar high volume open access journals that follow the success
        of PLoS ONE (<a href=\"https://web.archive.org/web/20120611031434/http://www.slideshare.net/PBinfield/ssp-presentation4\">PLoS
        ONE and the Rise of the Open Access Mega Journal</a>). The new journal announced
        today takes a very different approach to open access publishing.</p><p>This
        announcement has of course also been discussed elsewhere, including:</p><ul><li><a
        href=\"https://web.archive.org/web/20120611031434/http://phylogenomics.blogspot.com/2011/06/new-openaccess-journals-welcome.html\">The
        Tree of Life</a></li><li><a href=\"https://web.archive.org/web/20120611031434/http://cameronneylon.net/default/a-new-sustainability-model-major-funders-to-support-oa-journal/\">Science
        in the Open</a></li><li><a href=\"https://web.archive.org/web/20120611031434/http://bytesizebio.net/index.php/2011/06/27/suggest-a-name-for-the-next-big-journal/\">Byte
        Size Biology</a></li><li><a href=\"https://web.archive.org/web/20120611031434/http://scholarlykitchen.sspnet.org/2011/06/27/top-tiered-open-access-journal-arrives-with-fanfare-few-details/\">Scholarly
        Kitchen</a></li></ul> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Is Schema.org about a technical standard
        or about something else? ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/is-schema-org-about-a-technical-standard-or-about-something-else/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw6p</id>\n        <published>2011-06-19T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-13T14:09:46.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>At the beginning of the month
        Google, Bing and Yahoo <a href=\"https://web.archive.org/web/20120525041721/http://blogs.plos.org/mfenner/2011/06/07/schema-org-for-scholarly-html/\">announced</a>
        schema.org, a new initiative for structured markup on the web. Richard MacManus
        responded with a critical piece at ReadWriteWeb (<a href=\"https://web.archive.org/web/20120525041721/http://www.readwriteweb.com/archives/is_schemaorg_really_a_google_land_grab.php\">Is
        Schema.org really a Google Land Grab?</a>), mainly criticizing that the initiative
        didn\u2019t use RDFa and didn\u2019t seem to have consulted with the web standards
        body W3C. The best discussion about schema.org that I found so far (via Eric
        Hellman\u2019s <a href=\"https://web.archive.org/web/20120525041721/http://go-to-hellman.blogspot.com/2011/06/our-metadata-overlords-and-that.html\">post</a>)
        is by Henri Sivonen (<a href=\"https://web.archive.org/web/20120525041721/http://hsivonen.iki.fi/schema-org-and-communities/\">Schema.org
        and Pre-Existing Communities</a>). He explains why he thinks it makes sense
        that schema.org picked microdata over RDFa or microformats as markup standard.
        And he discusses how the web community has developed standards in the past
        and what characterizes the successful efforts. I personally believe that schema.org
        will bring us closer to the semantic web, and the discussion reminds me a
        little bit of the discussion around HTML 5 vs. XHTML 2 (where the pragmatic
        solution supported by the major browser vendors won over the ideal but dogmatic
        solution discussed for many years in standards bodies). Schema.org is will
        certainly be discussed at the <a href=\"https://web.archive.org/web/20120525041721/http://scienceonlinelondon.wikidot.com/start\">Science
        Online London Conference</a> in September.</p><p>Whether schema.org becomes
        a success depends in large part on the adoption by the community. Schema.org
        is backed by the three largest search engines (Google, Bing, Yahoo), so everybody
        who wants to be found by them will take a close look at the standard. Scholarly
        content is for the most part collected and curated in specialized databases.
        This makes it not only a technical decision whether or not to adopt schema.org
        for markup (we need more and better defined scholarly data types in the standard),
        but also a business decision. If scholarly publishers start marking up their
        journal articles, they will be easier to find via Google, Bing, etc. But will
        this mean that institutions would start re-evaluating their subscriptions
        to commercial services like Scopus or Web of Science? And will schema.org
        help or hinder the very large market of discovery tools for scholarly content?</p><p>At
        this point this is very much a theoretical discussion. We first need better
        scholarly data types in the schema.org standard. The Association of Educational
        Publishers and Creative Commons <a href=\"https://web.archive.org/web/20120525041721/http://www.aepweb.org/mediacenter/AEP-CC-Schema_6-7-11.htm\">has
        announced</a> an initiative to create a metadata framework for educational
        resources based on schema.org. And we hopefully see a similar initiative from
        scholarly publishers. I hope that the group behind schema.org is open to this
        input.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Please join us for the Science Online London
        Conference in September ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/please-join-us-for-the-science-online-london-conference-in-september/\"
        />\n\t\t<id>https://doi.org/10.53731/fceexy7-7f3je4z</id>\n        <published>2011-06-13T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-14T14:36:27.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>The <a href=\"https://web.archive.org/web/20120611105557/http://www.scienceonlinelondon.org/\">Science
        Online London 2011 Conference</a> takes place September 2-3 at the British
        Library. I am again one of the organizers (together with <em><em>Lou Woodley</em></em>
        from Nature.com and <em><em>Kaitlin Thaney</em></em> from Digital Science),
        and I\u2019m getting both excited and nervous the closer we get to September.</p><figure
        class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://web.archive.org/web/20120611105557im_/http://www.scienceonlinelondon.org/images/solo11.jpg\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"Science Online London 2011\"><figcaption>Photo
        by Mendeley.com (if you look really hard, you can find me in this picture
        from the 2010 conference).</figcaption></figure><p>We have recently posted
        a first draft of the <a href=\"https://web.archive.org/web/20120611105557/http://www.scienceonlinelondon.org/programme.html\">conference
        program</a>, and you can see that we are trying something new. In addition
        to the keynotes, panel discussions and breakout sessions we had the last few
        years we have also scheduled four workshops for the second day of the conference.
        I\u2019m doing a workshop called <strong><strong>Beyond scholarly publication</strong></strong>
        together with <em><em>Eva Amsen</em></em> (The Node) and <em><em>Mark Hahnel</em></em>
        (FigShare). The idea is to really have a hands-on experience, and in this
        workshop we will focus on blogs and related tools. We will try to do something
        interesting both for someone who wants to start a science blog, but also for
        more experienced writers (e.g. <a href=\"https://web.archive.org/web/20120611105557/http://scholarlyhtml.org/\">Scholarly
        HTML</a> or <a href=\"https://web.archive.org/web/20120611105557/http://blogs.plos.org/mfenner/2011/01/23/beyond-the-pdf-%E2%80%A6-is-epub/\">ePub</a>).
        We haven\u2019t work out the details, so please drop us a note if there is
        a particular topic that you want to see covered. All workshops will focus
        on <strong><strong>Spinal Muscular Atrophy</strong></strong> as a theme, and
        we hope that everybody has learned a few tricks by the end of the day.</p><p>We
        are still looking for breakout session suggestions for the first day of the
        conference. If you have a good idea, please add it to the <a href=\"https://web.archive.org/web/20120611105557/http://scienceonlinelondon.wikidot.com/\">wiki</a>,
        as we hope to have a program that is (close to) final by July.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Schema.org for Scholarly HTML? ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/schema-org-for-scholarly-html/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw6r</id>\n        <published>2011-06-07T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T10:51:15.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/schema-500x456.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/schema-500x456.jpeg\"></p><p>Last
        Thursday the search engines Google, Bing and Yahoo <a href=\"https://web.archive.org/web/20120525041638/http://googleblog.blogspot.com/2011/06/introducing-schemaorg-search-engines.html\">announced</a>
        <a href=\"https://web.archive.org/web/20120525041638/http://schema.org/\">schema.org</a>,
        a new initiative for structured data markup on the web. Websites that use
        this schema to markup their data (more than 100 data types are supported)
        will make it easier for the three largest web search engines to find their
        content. Schema.org uses microdata, not microformats or RDFa, according to
        the <a href=\"https://web.archive.org/web/20120525041638/http://schema.org/docs/faq.html#15\">FAQ</a>
        this was a pragmatic decision.</p><p>Schema.org also defines the <a href=\"https://web.archive.org/web/20120525041638/http://schema.org/ScholarlyArticle\">ScholarlyArticle</a>,
        but unfortunately this data type doesn\u2019t add any properties beyond those
        of the parent <a href=\"https://web.archive.org/web/20120525041638/http://schema.org/Article\">Article</a>
        (e.g. the Digital Object Identifier). The <a href=\"https://web.archive.org/web/20120525041638/http://www.schema.org/Person\">Person</a>
        data type is also interesting (and uses a professor as an example), but for
        example doesn\u2019t include an <strong><strong>isAuthor</strong></strong>
        relationship.</p><p>It will be interesting to see whether future versions
        of the schema.org standard will have better support for scholarly content,
        and how well this microformat can be integrated into our efforts to create
        <a href=\"https://web.archive.org/web/20120525041638/http://scholarlyhtml.org/\">Scholarly
        HTML</a>. And how quickly scholarly publishers and other providers of scholarly
        content will adopt this new standard., which in its current form already is
        a big improvement over plain HTML.</p><p><em>Update (6/7/11): Google today
        <a href=\"https://web.archive.org/web/20120525041638/http://insidesearch.blogspot.com/2011/06/authorship-markup-and-web-search.html\">announced</a>
        support for authorship markup, either via the schema.org format or using the
        <strong><strong>rel</strong></strong> attribute.</em></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Web Tools for Searching the Biomedical Literature
        \u2013 part II ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/web-tools-for-searching-the-biomedical-literature-part-ii/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw6s</id>\n        <published>2011-05-09T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T12:47:09.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/pubmed-500x177.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/pubmed-500x177.png\"></p><p>Ten
        days ago I <a href=\"https://web.archive.org/web/20120610114233/http://blogs.plos.org/mfenner/2011/04/29/web-tools-for-searching-the-biomedical-literature-part-i/\">mentioned
        </a>a paper by Zhiyong Lu that gives an overview over the available web tools
        to search the biomedical literature. Most of these tools enhance the PubMed
        service, and Zhiyong Lu in fact works for the NCBI, the developer of PubMed.
        In this post I want to take a more detailed look at the available tools.</p><p>A
        good starting point is the <a href=\"https://web.archive.org/web/20120610114233/http://www.ncbi.nlm.nih.gov/CBBresearch/Lu/search/\">companion
        webpage</a> to the paper, listing 28 services. One of the most painful shortcomings
        of PubMed is the sorting of results by date. Zhiyong lists 8 tools that can
        present search results sorted by relevance. Semantic search, seeking relevant
        concepts, and visualization of search results are all offered by several tools.
        Three tools will identify similar publications, and three tools will find
        potential experts, reviewers or collaborators. It is a good sign that there
        are so many tools that integrate with PubMed \u2013 in addition to the reference
        managers (e.g. Endnote, Papers) that do the same.</p><p>The analysis has one
        important shortcoming: only tools that specifically cover the biomedical literature
        are discussed. General purpose search tools such as <strong><strong>Web of
        Science</strong></strong>, <strong><strong>Scopus</strong></strong>, <strong><strong>Google
        Scholar</strong></strong> or <strong><strong>Microsoft Academic Search</strong></strong>
        are therefore not covered, neither are online bibliographic tools such as
        <strong><strong>Mendeley</strong></strong> and <strong><strong>CiteULike</strong></strong>.
        All of them also include biomedical literature \u2013 although the coverage
        at the fairly new Microsoft Academic Search is still limited. They all offer
        unique features not found in Pubmed or the 28 tools discussed in the paper.</p><p>When
        I think about how I find interesting articles, then it is increasingly through
        my social networks - including this paper by Zhiyong Lu. His paper unfortunatel
        fails to discuss this important search strategy. Twitter, FriendFeed, science
        blogs, etc. are strange places to find interesting literature, but they work
        for me. <a href=\"https://web.archive.org/web/20120610114233/http://www.massgenomics.org/2011/04/whole-genome-sequencing-for-cancer-patients.html\">This
        April 22 post</a> on the wonderful <strong><strong>Massgenomics</strong></strong>
        blog alerted me to two interesting papers published in JAMA on April 20 that
        describe the use of whole-genome sequencing in the care of two patients with
        acute leukemia. I presented the paper by Welch et al. in a journal club last
        Friday and we had a very interesting discussion.</p><p>The paper has also
        been discussed in the following places: <a href=\"https://web.archive.org/web/20120610114233/http://nnlm.gov/pnr/dragonfly/2011/02/15/beyondpubmed/\">Dragonfly</a>,
        <a href=\"https://web.archive.org/web/20120610114233/http://cmch.typepad.com/cmch/2011/03/res.html\">Center
        on Media and Child Health</a>, <a href=\"https://web.archive.org/web/20120610114233/http://beckerinfo.net/scp/2011/04/29/pubmed-and-beyond-a-survey-of-web-tools-for-searching-biomedical-literature/\">Bernard
        Becker Medical Library</a>, <a href=\"https://web.archive.org/web/20120610114233/http://laikaspoetnik.wordpress.com/2011/05/08/3rd-call-for-submissions-for-medical-information-matters-tools-for-searching-the-biomedical-literature/\">Medical
        Information Matters</a>, <a href=\"https://web.archive.org/web/20120610114233/http://autoimmunbuch.de/?p=447\">Friendly
        Fire</a> (German), <a href=\"https://web.archive.org/web/20120610114233/http://usalbiomedica.wordpress.com/2011/05/05/pubmed-and-beyond-a-survey-of-web-tools-for-searching-biomedical-literature/\">Usalbiomedica
        </a>(Spanish). This post is my much-delayed contribution to the <a href=\"https://web.archive.org/web/20120610114233/http://blogcarnival.com/bc/cprof_6092.html\">medlib\u2019s
        round</a> blog carnival. Unfortunately I haven\u2019t received any submissions
        since my call on April 29, but I probably didn\u2019t do enough advertising.</p><h2
        id=\"references\">References</h2><p><strong><strong>Lu Z.</strong></strong>
        PubMed and beyond: a survey of web tools for searching biomedical literature.
        <em><em>Database</em></em>. 2011 Jan;2011. doi: <a href=\"https://doi.org/10.1093/database/baq036\">http://doi.org/10.1093/database/baq036</a>.</p><p><strong><strong>Welch
        JS, Westervelt P, Ding L, Larson DE, Klco JM, Kulkarni S, et al</strong></strong>.
        Use of whole-genome sequencing to diagnose a cryptic fusion oncogene. <em><em>JAMA
        : the journal of the American Medical Association</em></em>. 2011 Apr;305(15):1577-1584.
        doi: \_<a href=\"https://doi.org/10.1001/jama.2011.497\">http://doi.org/10.1001/jama.2011.497</a>.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Web Tools for Searching the Biomedical Literature
        \u2013 part I ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/web-tools-for-searching-the-biomedical-literature-part-i/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw6t</id>\n        <published>2011-04-29T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-31T08:30:20.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Zhiyong Lu recently published
        an excellent overview of the web tools that are currently available to search
        the biomedical literature. The article has also a <a href=\"https://web.archive.org/web/20120610131235/http://www.ncbi.nlm.nih.gov/CBBresearch/Lu/search/\">companion
        web page</a> that allows user to filter for the features they are interested
        in, and to report new tools.</p><p>The author describes 28 tools developed
        specifically for the biomedical domain. The tools are grouped based on their
        most important features into</p><ol><li>Ranking search results</li><li>Clustering
        results into topics</li><li>Extracting and displaying semantics and relations</li><li>Improving
        search interface and retrieval experience</li></ol><p>Zhiyong Lu works for
        the National Center for Biotechnology Information (NCBI). NCBI developed and
        maintains PubMed, and this is obviously the database to which the other tools
        are compared. Or looked at this differently, the proliferation of tools in
        the four areas listed above is an indication of the areas where PubMed is
        not very good at (e.g. it returns search results not by relevance, but in
        chronological order).</p><p>Instead of reviewing the article, I decided to
        do this in two parts. I will write about my thoughts on the various tools
        next week to give everybody time to look at this themselves. This is my delayed
        contribution to the <a href=\"https://web.archive.org/web/20120610131235/http://blogcarnival.com/bc/cprof_6092.html\">medlib\u2019s
        round</a> blog carnival. Feel free to write a comment, or submit directly
        to the blog carnival using <a href=\"https://web.archive.org/web/20120610131235/http://blogcarnival.com/bc/cprof_6092.html\">this
        link</a>. The post with my own thoughts and the feedback I have received will
        go up Saturday next week.</p><p><strong><strong>Lu Z.</strong></strong> PubMed
        and beyond: a survey of web tools for searching biomedical literature. <em><em>Database</em></em>.
        2011 Jan;2011. <a href=\"https://doi.org/10.1093/database/baq036\">https://doi.org/10.1093/database/baq036</a>.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Explaining the ORCID Principles ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/explaining-the-orcid-principles/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw6v</id>\n        <published>2011-04-13T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-01T11:40:02.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>On Monday
        I gave a presentation about ORCID, based on the <a href=\"https://web.archive.org/web/20120610125808/http://www.orcid.org/principles\">ORCID
        Principles</a>. The slides are hopefully a good introduction to ORCID and
        the current status of the initiative.</p><figure class=\"kg-card kg-embed-card\"><iframe
        src=\"https://web.archive.org/web/20120610125808if_/http://www.slideshare.net/slideshow/embed_code/7606016\"
        width=\"425\" height=\"355\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\"
        scrolling=\"no\" style=\"background: transparent; border: 0px; margin: 0px;
        padding: 0px; vertical-align: baseline;\"></iframe></figure><p>A good in-person
        update of the ORCID initiative is the next ORCID Participant Meeting that
        takes place May 18 in Boston. Registration is free and everybody interested
        in unique identifiers for scholarly authors is invited to attend. More information
        <a href=\"https://web.archive.org/web/20120610125808/http://www.orcid.org/civicrm/event/info?reset=1&amp;id=1\">at
        the ORCID website</a>.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Please help the Nippon Science Support Network
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/please-help-the-nippon-science-support-network/\"
        />\n\t\t<id>https://doi.org/10.53731/90ctgyp-ph7eq2a</id>\n        <published>2011-04-06T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-14T14:37:47.000+00:00</updated>\n
        \       <media:content url=\"\" medium=\"image\"/>\n        <content type=\"html\"><![CDATA[
        <p><img src=\"\"></p><p>The recent tragic events in Japan have made it difficult
        or impossible for many Japanese scientists to continue their work. The newly
        launched <a href=\"https://web.archive.org/web/20120610130607/http://nipponsciencesupport.net/\">Nippon
        Science Support Network</a> has therefore established a database of positions
        and stipends in other countries for Japanese students, research fellows and
        scientific personnel. The network has started as a cooperation between German
        and Japanese researchers, but because of overwhelming demand today turned
        into a global initiative, allowing researchers from all countries help to
        support Japanese scientists.</p><p>Behind this initiative are a lot of people,
        but most importantly Phil Selenko \u2013 a group leader from the Leibniz Institute
        of Molecular Pharmacology in Berlin. Longtime readers of this blog will remember
        that Phil helped organize a <a href=\"https://web.archive.org/web/20120610130607/http://blogs.nature.com/mfenner/2008/05/24/why-local-hubs-in-nature-network-are-important\">great
        effort in 2008</a> to bring Nobel Laureates and other senior scientists together
        with graduate students, and <em><em>to give them the same kind of networking
        opportunities that are usually restricted to seasoned faculty (and often happens
        behind closed doors).</em></em> I wish him the best of luck with this initiative.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Direct links to figures and tables using
        component DOIs ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/direct-links-to-figures-and-tables-using-component-dois/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw6x</id>\n        <published>2011-03-26T00:00:00.000+00:00</published>\n\t\t<updated>2023-07-12T09:15:45.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/journal.pone_.0006022.g002-1.jpg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/journal.pone_.0006022.g002-1.jpg\"></p><p>We
        are all familiar with digital object identifiers (DOIs) provided by <a href=\"https://web.archive.org/web/20120610122411/http://www.crossref.org/\">CrossRef</a>
        to identify (and link to) journal articles. Some of us are familiar with the
        DOIs issued by <a href=\"https://web.archive.org/web/20120610122411/http://datacite.org/whatisdoi.html\">DataCite</a>
        to link to datasets. But most of us don\u2019t know that CrossRef is also
        providing <a href=\"https://web.archive.org/web/20120610122411/http://www.crossref.org/help/Content/Components.htm\">component
        DOIs</a> that can provide persistent links to a particular table or figure
        in a paper. The <em><em>PLoS</em></em> journals use component DOIs, for example
        for this figure:</p><p>Linking to component DOIs is straightforward, table
        1 of the paper above is <a href=\"https://web.archive.org/web/20120610122411/http://dx.doi.org/10.1371/journal.pone.0006022.t001\">10.1371/journal.pone.0006022.t001</a>.
        Unfortunately, <a href=\"https://web.archive.org/web/20120610122411/http://www.niso.org/publications/isq/free/Feeney_DOIs_for_Journals_ISQ_v22no3.pdf\">only
        about 300,000</a> of the more than 40 million CrossRef DOIs are compontent
        DOIs. There are many good reasons to use a direct (and persistent) link to
        a specific part of a scholarly journal article. And this becomes an even more
        important issue once DOIs for datasets are more commonly cited.</p><h3 id=\"references\">References</h3><p>Bollen
        J, Van De Sompel H, Hagberg A, Chute R. A Principal Component Analysis of
        39 Scientific Impact Measures. Mailund T, ed. <em>PLoS ONE</em>. 2009;4(6):e6022.
        doi:<a href=\"https://doi.org/10.1371/journal.pone.0006022\">10.1371/journal.pone.0006022</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Zotero 2.1 released with support for CSL
        1.0 ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/zotero-2-1-released-with-support-for-csl-1-0/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw6y</id>\n        <published>2011-03-22T00:00:00.000+00:00</published>\n\t\t<updated>2023-07-13T12:02:52.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Version 2.1 of the reference
        manager Zotero was <a href=\"https://web.archive.org/web/20120610122458/http://www.zotero.org/blog/new-release-zotero-2-1/\">released
        last Friday</a>. The biggest change for me is the support of Citation Style
        Language (CSL) 1.0. <a href=\"https://web.archive.org/web/20120610122458/http://citationstyles.org/\">CSL
        </a>is an open XML-based standard for citations and bibliographies. Older
        versions of Zotero used CSL 0.8.1, but the improved CSL 1.0 was <a href=\"https://web.archive.org/web/20120610122458/http://citationstyles.org/2011/03/18/csl-1-0-first-anniversary/\">released
        </a>a year ago.</p><p>With Zotero 2.1, Papers 2 (both released in March),
        and Mendeley we now have three major reference managers supporting the current
        version of CSL. Which reference manager will be the next one? And why aren\u2019t
        more journals providing downloadable citation styles in CSL format in their
        <a href=\"https://web.archive.org/web/20120610122458/http://blogs.plos.org/mfenner/2010/09/24/citation-style-language-an-interview-with-rintze-zelle-and-ian-mulvany/\">author
        guidelines</a>?</p><h3 id=\"references\">References</h3><p>Zelle RM. CSL 1.0
        First Anniversary. Published online March 18, 2011. doi:<a href=\"https://doi.org/10.59350/hm6cs-ehp54\">10.59350/hm6cs-ehp54</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ A very brief history of Scholarly HTML ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/a-very-brief-history-of-scholarly-html/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw6z</id>\n        <published>2011-03-19T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T12:50:57.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/4268841912_c2b34ca43c.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/4268841912_c2b34ca43c.jpeg\"></p><p>The
        history of HTML begins 1989 at <a href=\"https://web.archive.org/web/20120610122136/http://info.cern.ch/\">CERN</a>,
        the European Laboratory for Particle Physics in Geneva. <strong><strong>Tim
        Berners-Lee</strong></strong>, <strong><strong>Robert Cailliau</strong></strong>
        and colleagues invented HTML (as well as the transport protocol HTTP and the
        web browser) to facilitate collaboration between CERN physicists.</p><p>HTML
        was originally invented for scholarly communication, but of course by the
        mid-1990s was also used by everybody else. But when electronic distribution
        of scholarly journal articles became possible, most publishers switched to
        PDF instead of HTML as the electronic document format of choice.</p><p>In
        April 2003 Inera, Mulberry Technologies and the NCBI published the <a href=\"https://web.archive.org/web/20120610122136/http://www.inera.com/nlmresources.shtml\">NLM
        Journal Archiving and Interchange DTD Suite</a> (NLM-DTD, read <a href=\"https://web.archive.org/web/20120610122136/http://old.diglib.org/preserve/hadtdfs.pdf\">here
        </a>about the history of this DTD Suite). The NLM-DTD has become the de facto
        XML standard for scholarly publishing and archiving. Although some tools for
        authors can write articles in this format (including Microsoft Word with the
        <a href=\"https://web.archive.org/web/20120610122136/http://blogs.plos.org/mfenner/2008/11/07/interview_with_pablo_fernicola/\">Article
        Authoring Add-In</a>), the NLM-DTD has never caught on as an authoring format
        for scholars and I\u2019m not aware of any publisher accepting manuscripts
        written in this format.</p><p>In April 2009 \_<em><em>Learned Publishing</em></em>
        published a paper by <strong><strong>David Shotton</strong></strong> titled
        <a href=\"https://web.archive.org/web/20120610122136/http://dx.doi.org/10.1087/2009202\"
        rel=\"cito:discusses\">Semantic publishing: the coming revolution in scientific
        journal publishing</a>. David listed six rules for semantic publishers:</p><ol><li>Start
        simply and improve functionality incrementally.</li><li>Expect greater things
        of your authors.</li><li>Exploit your existing in-house skills fully.</li><li>Use
        established standards wherever possible.</li><li>Publish raw datasets to the
        Web.</li><li>Release article metadata, particularly reference lists, in machine-readable
        form.</li></ol><p>Although the paper focuses on scholarly publishers, these
        rules also very much apply to what we could call Scholarly HTML today.</p><p>At
        about the same time (March 31, 2009) <strong><strong>Peter Sefton</strong></strong>
        for the first time used the term <em><em>Scholarly HTML</em></em> in a <a
        href=\"https://web.archive.org/web/20120610122136/http://ptsefton.com/2009/03/31/scholarly-html.htm\">blog
        post</a>. He thinks that Scholarly HTML should allow the following:</p><ol><li>Documents
        should definitely have headings.</li><li>Protocols for representing things
        like examples.</li><li>Metadata, using a linked data approach.</li><li>Links
        from terms mentioned in the text to ontologies that describe them.</li><li>Linkable
        paragraphs.</li><li>Dead simple reference management via links to trusted
        sources.</li></ol><p>In January 2011 <strong><strong>Phil Bourne</strong></strong>
        organized the <a href=\"https://web.archive.org/web/20120610122136/http://blogs.plos.org/mfenner/2010/11/06/beyond-the-pdf-it-is-time-for-a-workshop/\">Beyond
        the PDF</a> workshop, and I was lucky to attend. We had a number of <a href=\"https://web.archive.org/web/20120610122136/http://river-valley.tv/conferences/beyondthepdf-2011\">interesting
        sessions </a>about how to improve the current scholarly paper published as
        PDF. I was involved in the working group thinking about better authoring tools,
        and one of my personal conclusions was that <a href=\"https://web.archive.org/web/20120610122136/http://blogs.plos.org/mfenner/2011/01/23/beyond-the-pdf-%E2%80%A6-is-epub/\">ePub</a>
        is a very interesting alternative to PDF if we need a packing format for HTML,
        e.g. for journal submission or archiving.</p><p><strong><strong>Peter Murray-Rust</strong></strong>
        was able to capture the ideas of the authoring working group with a <a href=\"https://web.archive.org/web/20120610122136/http://blogs.ch.cam.ac.uk/pmr/2011/02/09/scholarly-html-hackfest-cambridge-uk-march/\">drawing</a>,
        and he picked the term <em><em>Scholarly HTML</em></em> as the best description
        of what we want to achieve. He subsequently invited Peter Sefton, Brian McMahon
        and me (and a number of other people interested in Scholarly HTML) to a workshop
        that took place last weekend in Cambridge. Some of the thoughts of Peter Murray-Rust
        and Peter Sefton are summarized <a href=\"https://web.archive.org/web/20120610122136/http://blogs.ch.cam.ac.uk/pmr/2011/03/14/scholarly-html-%e2%80%93-major-progress/\">here
        </a>and <a href=\"https://web.archive.org/web/20120610122136/http://ptsefton.com/2011/03/18/scholarly-html-fraglets-of-progress.htm\">here</a>.
        Two outcomes of the workshop are Scholarly HTML <a href=\"https://web.archive.org/web/20120610122136/http://okfnpad.org/schtml-principles\">Principles
        </a>and a <a href=\"https://web.archive.org/web/20120610122136/http://okfnpad.org/schtml-faqs\">FAQ</a>.</p><p>My
        approach to Scholarly HTML is through developing WordPress plugins. The future
        will hopefully bring of a number of Scholarly HTML authoring tools, and WordPress
        will be just one of them. But Wordpress is a great platform to test ideas
        and improve them over time, or to quote David Shotton: <em><em>start simply
        and improve functionality incrementally</em></em>. One starting point has
        been citations in Scholarly HTML and we have already made <a href=\"https://web.archive.org/web/20120610122136/http://okfnpad.org/schtml-citations\">good
        progress</a>.</p><p>The idea behind Scholarly HTML is not to build alternatives
        for Microsoft Word or LaTeX for authoring, but instead to build tools that
        will allow us to do something new and exciting with scholarly content. The
        trick here is to improve the scholarly document \u2013 and the author should
        see the immediate benefit - without putting too much extra burden on the author.
        And this might in fact be the big challenge for Scholarly HTML.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Discussing science with microformats ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/discussing-science-with-microformats/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw70</id>\n        <published>2011-03-15T00:00:00.000+00:00</published>\n\t\t<updated>2023-07-13T13:56:58.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>The best and quickest discussions
        of a scientific paper now sometimes happen in science blogs rather than in
        the peer-reviewed literature. Whereas we have a number of scholarly databases
        that track citations between papers, we don\u2019t have the same tools for
        science blogs. Following all science blogs manually has simply become impossible
        (unless your first name is <a href=\"https://web.archive.org/web/20120525235200/http://coturnix.org/\">Bora</a>).
        This makes it difficult to find all blog posts about a particular paper \_-
        either for <a href=\"https://doi.org/10.53731/r294649-6f79289-8cw59\">proper
        discussion</a> of an article or for doing automated <a href=\"https://doi.org/10.53731/r294649-6f79289-8cw36\">article-level
        metrics</a>.</p><h3 id=\"aggregation\">Aggregation</h3><p>Aggregation can
        help solve this problem. <a href=\"https://web.archive.org/web/20120525235200/http://www.researchblogging.org/\">ResearchBlogging</a>
        aggregates blog posts about peer-reviewed research. <a href=\"https://web.archive.org/web/20120525235200/http://scienceseeker.org/\">ScienceSeeker</a>
        aggregates all science blog posts (currently aggregating over 400 blogs) and
        was <a href=\"https://web.archive.org/web/20120525235200/http://scienceblogging.org/2011/01/15/introducing-scienceseeker/\">announced</a>
        in February. <a href=\"https://web.archive.org/web/20120525235200/http://blogs.nature.com/\">Nature
        Blogs</a> also aggregates science blogs but doesn\u2019t seem to be up-to-date.</p><h3
        id=\"microformats\">Microformats</h3><p>Microformats are an alternative \u2013
        but of course complimentary \u2013 strategy. Microformats are small snippets
        of HTML that represent commonly published things. A good example is <a href=\"https://web.archive.org/web/20120525235200/http://microformats.org/wiki/rel-license\">Rel-License</a>,
        a microformat indicating licensed content:</p><pre><code>&lt;a href=\"http://creativecommons.org/licenses/by/2.0/\"
        rel=\"license\"&gt;cc by 2.0&lt;/a&gt;</code></pre><p>In February Google <a
        href=\"https://web.archive.org/web/20120525235200/http://microformats.org/2011/02/24/google-launches-microformat-powered-recipe-search\">launched</a>
        a new Recipe view feature based on the <a href=\"https://web.archive.org/web/20120525235200/http://microformats.org/wiki/hrecipe\">hRecipe</a>
        microformat, demonstrating how microformats can help discover content. There
        is currently no <a href=\"https://web.archive.org/web/20120525235200/http://blogs.ch.cam.ac.uk/pmr/2011/03/14/scholarly-html-%E2%80%93-major-progress/\">standard
        microformat for scholarly citations</a>. The simplest format would again use
        the <strong><strong>rel</strong></strong> tag \u2013 together with the Citation
        Typing Ontology (<a href=\"https://web.archive.org/web/20120525235200/http://blogs.plos.org/mfenner/2011/02/14/how-to-use-citation-typing-ontology-cito-in-your-blog-posts/\">CiTO</a>):</p><pre><code>&lt;a
        href=\"http://dx.doi.org/10.1126/science.1197258\" rel=\"cito:discusses\"&gt;this
        paper&lt;/a&gt;</code></pre><p>There are <a href=\"https://doi.org/10.1186/2041-1480-1-S1-S6\">more
        than 20</a> CiTO tags for describing what we think about a particular paper
        or science blog post \u2013 many science bloggers would probably have used
        <em><em>cito:critiques</em></em> for the above paper. I suggest <em><em>cito:discusses</em></em>
        as the standard CiTO relationship for most papers and blog posts. You can
        add this tag manually, or use a tool such as the <a href=\"https://web.archive.org/web/20120525235200/http://wordpress.org/extend/plugins/link-to-link/\">Link
        to Link</a> WordPress plugin (I added <em><em>cito:discusses</em></em> to
        version 1.1.2).</p><h3 id=\"references\">References</h3><p>Fenner M. Supplementary
        Information: should I stay or should I go? Published online August 27, 2010.
        doi:<a href=\"https://doi.org/10.53731/r294649-6f79289-8cw59\">10.53731/r294649-6f79289-8cw59</a></p><p>Fenner
        M. PLoS One: Interview with Peter Binfield. Published online August 15, 2009.
        doi:<a href=\"https://doi.org/10.53731/r294649-6f79289-8cw36\">10.53731/r294649-6f79289-8cw36</a></p><p>Shotton
        D. CiTO, the Citation Typing Ontology. <em>J Biomed Sem</em>. 2010;1(Suppl
        1):S6. doi:<a href=\"https://doi.org/10.1186/2041-1480-1-S1-S6\">10.1186/2041-1480-1-S1-S6</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Papers 2: the reference manager made with
        love ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/papers-2-the-reference-manager-made-with-love/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw71</id>\n        <published>2011-03-08T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T12:53:10.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/papers2-500x475.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/papers2-500x475.jpeg\"></p><p>The
        reference management software <a href=\"https://web.archive.org/web/20120525044214/http://www.mekentosj.com/papers/\">Papers</a>
        has been a regular topic on this blog. I wrote about Papers in one of my first
        blog posts in May 2008, <a href=\"https://web.archive.org/web/20120525044214/http://blogs.plos.org/mfenner/2008/10/03/interview_with_alexander_griekspoor/\">interviewed</a>
        main developer Alex Griekspoor in October 2008, and held a <a href=\"https://web.archive.org/web/20120525044214/http://blogs.plos.org/mfenner/2009/02/19/papers_for_iphone_released_time_for_more_poetry/\">poetry
        contest</a> when Papers for iPhone was released in February 2009 (Stephen
        Curry won the first price for <a href=\"https://web.archive.org/web/20120525044214/http://blogs.plos.org/mfenner/2009/02/19/papers_for_iphone_released_time_for_more_poetry/#comment-898\">this
        poem</a>).</p><figure class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/Papers-2c.jpg\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"Papers 2c\" width=\"185\"
        height=\"263\"></figure><p>Today Papers 2 <a href=\"https://web.archive.org/web/20120525044214/http://news.mekentosj.com/\">was
        released</a>, and with this major update Papers has grown into a full-fledged
        reference manager for the Macintosh (there is no Windows or Linux version).
        Papers 1 was released in 2007 as a tool to manage the PDF files of scholarly
        papers on your hard drive. Papers 1 did this job very well, but it was not
        a reference manager in the strict sense, because you couldn\u2019t use Papers
        to insert citations into the manuscripts you were writing.</p><p>In order
        to add this feature, Papers first had to be completely rewritten to not only
        handle journal articles and the associated PDF files, but also all the other
        common reference formats \u2013 conference proceeding, book chapter, website,
        etc. A nice side effect that I haven\u2019t fully explored yet is that Papers
        can now also store all your Powerpoint or Keynote presentations (but fulltext
        search in these presentations doesn\u2019t seem to work yet).</p><p>Inserting
        references into manuscripts is done using a floating window activated from
        the menu bar or with a shortcut:</p><figure class=\"kg-card kg-image-card\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/papers2-500x475-1.jpeg\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"papers2\" width=\"500\" height=\"475\"></figure><p>This
        feature works similar to the plugins used by Endnote, Mendeley, Zotero, etc.,
        but in typical Papers fashion the implementation is much nicer. The plugin
        is available to all applications, e.g. other word processors besides Microsoft
        Word, your blogging software or your email program.</p><p>The other big limitation
        of Papers 1 wasn\u2019t so obvious when Papers originally launched in 2007.
        But today most major reference managers allow users to <a href=\"https://web.archive.org/web/20120525044214/http://blogs.plos.org/mfenner/reference-manager-overview/\">share
        their references</a> in private and/or public groups, as most research is
        done in groups and most manuscripts are written by multiple authors.</p><p>The
        sharing feature of Papers 2 is called <strong><strong>Livfe</strong></strong>.
        It is not as complete as the sharing features of some other reference managers
        (e.g. CiteULike or Mendeley). It is for example not yet possible to upload
        a complete Papers library to Livfe. And Livfe doesn\u2019t have a web interface,
        but only works through Papers.</p><figure class=\"kg-card kg-image-card\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/Papers-2a-500x243.jpg\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"Papers 2a\" width=\"500\"
        height=\"243\"></figure><p>The difference between Papers 2 and other reference
        managers is not so much the feature set. What sets Papers really apart is
        the love that went into the design of the program. Papers doesn\u2019t just
        get the job done, it allows you to have fun searching for references or reading
        \u2013 and now also writing \u2013 a paper. This makes Papers 2 a strong competitor
        against some of the other established programs that for example have more
        than 25 years of experience with reference management (Endnote), think that
        reference management should be done as Open Source software (Zotero), do everything
        in the browser (Refworks), or see reference management primarily as a social
        application (Mendeley).<br></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ The Trouble with Bibliographies ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/the-trouble-with-bibliographies/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw72</id>\n        <published>2011-03-07T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T12:54:16.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/5124103273_968a3c50cc.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/5124103273_968a3c50cc.jpeg\"></p><p>The
        bibliography of a scholarly paper is interesting and important reading material.
        You can see whether the authors have cited the relevant literature, and you
        often find references to interesting papers you didn\u2019t know about. Bibliographies
        are obviously also needed to count citations, and then do all kinds of useful
        and not so useful things with them.</p><p>Unfortunately almost all bibliographies
        are in the wrong format. What you want is at least a direct link to the cited
        work using the DOI (if available), and a lot of journals do that. You don\u2019t
        want to have a link to PubMed using the PubMed ID as the only option (as in
        PubMed Central), as this requires a few more mouse clicks to get to the full-text
        article. And you don\u2019t want to go to an extra page, then use a link to
        search the PubMed database, and then use a few more mouse clicks to get to
        the full-text article (something that could happen to you with a PLoS journal).</p><p>A
        bibliography should really be made available in a downloadable format such
        as BibTeX. Unfortunately journal publishers \u2013 including Open Access publishers
        \u2013 in most cases don\u2019t see that they can provide a lot of value here
        without too much extra work. One of the few publishers offering this service
        is BioMed Central \u2013 feel free to mention other journals that do the same
        in the comments.</p><p>This weekend <a href=\"https://web.archive.org/web/20120610124417/http://blogs.ch.cam.ac.uk/pmr/2011/03/04/scholarly-html-hackfest-and-visit-of-peter-sefton-and-martin-fenner/\">Peter
        Murray-Rust invited Peter Sefton and me to Cambridge </a>(UK) for a very interesting
        workshop about <strong><strong>Scholarly HTML</strong></strong>. Our goal
        is to discuss how we can define standards and build tools to make HTML the
        best platform for scholars and scholarly works. The event is in fact a hackfest,
        and we hope to have something to show by Sunday evening.</p><p>My idea for
        the hackfest is a tool that extracts all links (references and weblinks) out
        of a HTML document (or URL) and creates a bibliography. The generated bibliography
        should be both in HTML (using the <a href=\"https://web.archive.org/web/20120610124417/http://blogs.plos.org/mfenner/2010/09/24/citation-style-language-an-interview-with-rintze-zelle-and-ian-mulvany/\">Citation
        Style Language</a> ) and BibTex formats, and should ideally also support the
        Citation Typing Ontology (<a href=\"https://web.archive.org/web/20120610124417/http://blogs.plos.org/mfenner/2011/02/14/how-to-use-citation-typing-ontology-cito-in-your-blog-posts/\">CiTO</a>)
        and <a href=\"https://web.archive.org/web/20120610124417/http://ocoins.info/\">COinS
        </a>- \_a standard to embed bibliographic metadata in HTML. I will use PHP
        as a programming language and will try to build both a generic tool and something
        that can work as a WordPress plugin. Obviously I will not start from scratch,
        but will reuse several already existing libraries. Any feedback or help for
        this project is much appreciated.</p><p>If I had a tool with which I could
        create my own bibliographies (and in the formats I want), I would no longer
        care so much about journals not offering this service. One big problem would
        still persist, and that is that most subscription journals wouldn\u2019t allow
        the redistribution of the bibliographies to their papers. A single citation
        can\u2019t have a copyright, but a compilation of citations can. I\u2019m
        sure we will also discuss this topic at the workshop, as Peter Murray-Rust
        is one of the biggest proponents of <a href=\"https://web.archive.org/web/20120610124417/http://openbiblio.net/principles/\">Open
        Bibliographic Data</a>.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ How to use Citation Typing Ontology (CiTO)
        in your blog posts ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/how-to-use-citation-typing-ontology-cito-in-your-blog-posts/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw73</id>\n        <published>2011-02-14T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T12:55:11.000+00:00</updated>\n\t\t<category
        term=\"Science Hack\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/cito-500x433-1.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/cito-500x433-1.jpeg\"></p><p>One
        of the annoyances with bibliographies as we use them for scholarly papers
        is that is usually unclear why a particular paper was cited. It is often possible
        for readers to gather this information by looking at the citation in the context
        of the surrounding text, but this is very difficult to automate. A highly
        cited paper might contain a method that everybody uses, might be a review,
        or it might contain information that everybody disagrees with. David Shotton
        has thought a lot about this problem and has come up with <a href=\"https://web.archive.org/web/20120611093455/http://dx.doi.org/10.1186/2041-1480-1-S1-S6\">CiTO</a>,
        the Citation Typing Ontology:</p><blockquote>CiTO, the Citation Typing Ontology,
        is an ontology for describing the nature of reference citations in scientific
        research articles and other scholarly works, both to other such publications
        and also to Web information resources, and for publishing these descriptions
        on the Semantic Web.</blockquote><p>Using CiTO obviously means extra work
        for the author, so for widespread use it is very important that CiTO is as
        easy to use as possible. The first step would be to reduce the number of possible
        relationships to a manageable number, e.g. not more than ten (CiTO defines
        more than 20 relationships). Following a dinner discussion at the <a href=\"https://web.archive.org/web/20120611093455/http://blogs.plos.org/mfenner/2010/11/06/beyond-the-pdf-it-is-time-for-a-workshop/\">Beyond
        the PDF</a> workshop, David Shotton kindly provided 10 popular CiTO relationships
        to Alex Wade from Microsoft Research and me. I made three little changes to
        the list: added \u201Ccites\u201D as the default generic relationship, dropped
        \u201Cshares authors with\u201D, as this can be done better with <a href=\"https://web.archive.org/web/20120611093455/http://blogs.plos.org/mfenner/2010/09/07/orcid-as-unique-author-identifier-what-is-it-good-for-and-should-we-worry-or-be-happy/\">unique
        author identifiers</a>, and added \u201Cdisagrees with\u201D to have at least
        one relationship that expresses disagreement.</p><p>In the next step I added
        these relationships to my <a href=\"https://web.archive.org/web/20120611093455/http://blogs.plos.org/mfenner/2011/01/11/having-fun-with-citations-at-scienceonline2011/\">Link
        to Link</a> WordPress plugin, and I released the updated version (1.1) today.
        Using CiTO is an option that can be turned off, but the plugin makes it very
        easy to use CiTO relationships when inserting references into a blog post.</p><p>The
        CiTO relationship is stored in the <strong><strong>rel</strong></strong> attribute
        of the link that is created \u2013 currently as free-form text, but this can
        be changed to the <strong><strong>cito:DisagreesWith</strong></strong> format.
        This information can easily be extracted by computers, or made available in
        the bibliography to readers. The Reference Manager CiteULike is <a href=\"https://web.archive.org/web/20120611093455/http://opencitations.wordpress.com/2010/10/21/use-of-cito-in-citeulike/\">also
        supporting CiTO</a>, but we need many more CiTO tools for authors.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ OPDS: RSS for ePub or how to distribute
        ePub files ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/opds-rss-for-epub-or-how-to-distribute-epub-files/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw74</id>\n        <published>2011-02-06T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T12:55:54.000+00:00</updated>\n\t\t<category
        term=\"Science Hack\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/OPDS-500x371.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/OPDS-500x371.jpeg\"></p><p>ePub
        is a great <a href=\"https://web.archive.org/web/20120611043846/http://blogs.plos.org/mfenner/2011/01/23/beyond-the-pdf-%E2%80%A6-is-epub/\">format
        for scholarly content</a>, and there are a <a href=\"https://web.archive.org/web/20120611043846/http://blogs.plos.org/mfenner/2011/02/01/epub-wordpress-plugin-released-today/\">number
        of tools</a> to create ePub files. But creating content is only half the story,
        at least as important is an easy mechanism for distribution. This is particularly
        true if your ePub files are not books, but shorter pieces of content: journal
        articles, blog posts or even output from your ongoing research. <a href=\"https://web.archive.org/web/20120611043846/http://en.wikipedia.org/wiki/RSS\">RSS</a>
        or the related Atom protocol has of course become the standard mechanism to
        publish frequently updated works.</p><p>Open Publication Syndication System
        (<a href=\"https://web.archive.org/web/20120611043846/http://code.google.com/p/openpub/wiki/CatalogSpecDraft#Introduction\">OPDS</a>)
        is a syndication format for electronic publications based on Atom. OPDS is
        a relatively new format, but is supported by a growing number of (book) publishers,
        ePub tools and readers. If you want to try OPDS for yourself, pick one the
        feeds listed <a href=\"https://web.archive.org/web/20120611043846/http://code.google.com/p/openpub/wiki/AvailableFeeds\">here</a>
        and add the feed as a Book source in the Stanza reader (in the <strong><strong>Shared</strong></strong>
        section). Alternatively, install the <a href=\"https://web.archive.org/web/20120611043846/http://www.epubread.com/de/manual.php\">EPUBReader
        plugin</a> for Firefox. As you can see, OPDS does more than just list titles
        with a summary and image, you can also categorize the content by author (or
        tag), and provide a search interface.</p><p>I\u2019m looking forward to the
        first scholarly publisher that not only provides ePub files of his journal
        articles, but also makes them available via OPDS. Although OPDS is currently
        used mostly for electronic books, I think that this is a very interesting
        protocol for scholarly publishers. Did I mention that OPDS also provides facilities
        for buying or lending content? And that you probably shouldn\u2019t expect
        OPDS support in the Apple iBooks application for iPhone and iPad anytime soon
        as they don\u2019t seem to like distributed content delivery? I would like
        to see scholarly publishers providing their journal content via ePub and OPDS
        that can be consumed with one of the many available readers, rather than everybody
        creating his own little app that only works with a single publisher on a single
        platform.</p><p>OPDS is a relatively simple protocol and similar to RSS should
        make it easy for everybody to provide his content in catalog form. It should
        be straightforward to add OPDS support to the WordPress <a href=\"https://web.archive.org/web/20120611043846/http://wordpress.org/extend/plugins/epub-export/\">ePub
        plugin</a> that I released last week, thus making a blog (or blog network)
        available directly in the ePub reader. While I expect that we will continue
        to read most blogs via the Web or RSS reader, ePub might be the better format
        for longer posts and the posts you want to store on your computer.</p><p>ePub
        is a very interesting format for packaging research objects, e.g. the description
        and data files from an experiment. OPDS would be very helpful as a distribution
        mechanism for these ePubs, and also works on the small scale of a research
        group. You can for example use the Calibre eBook management tool \u2013 which
        can create not only ePub files but also OPDS catalogs \u2013 together with
        Dropbox to <a href=\"https://web.archive.org/web/20120611043846/http://dearauthor.com/wordpress/2010/02/14/create-your-own-cloud-of-ebooks-with-calibre-calibre-opds-dropbox/\">share
        your content</a>. The <a href=\"https://web.archive.org/web/20120611043846/http://wiki.mobileread.com/wiki/Calibre2opds\">calibre2opds</a>
        tool also creates an OPDS catalog from the Calibre metadata database but doesn\u2019t
        require Calibre to run in order to use the OPDS catalog. And the <a href=\"https://web.archive.org/web/20120611043846/http://www.pincette.biz/index.xhtml\">Pincette</a>
        document management system automatically creates an OPDS catalog for the ePub
        files dropped into a Pincette folder. I hope that more tools for researchers
        start to support not only ePub but also OPDS. An OPDS interface to the data
        produced by your favorite piece of lab equipment (gel documentation system,
        microarray reader, etc.) would be an interesting sight.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Discussing WordPress for Scientists ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/discussing-wordpress-for-scientists/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw75</id>\n        <published>2011-02-04T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-31T08:26:35.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Regular readers of this blog
        know about <a href=\"https://web.archive.org/web/20120628134839/http://blogs.plos.org/mfenner/tag/wordpress/\">my
        current interest in WordPress </a>as a tool to create scholarly content. In
        the last few weeks I have released several WordPress plugins for <a href=\"https://web.archive.org/web/20120628134839/http://wordpress.org/extend/plugins/bibtex-importer/\">reference
        management</a> and to <a href=\"https://web.archive.org/web/20120628134839/http://wordpress.org/extend/plugins/epub-export/\">create
        ePub </a>files. Obviously I\u2019m not the only person having this idea. Some
        interesting projects are:</p><ul><li><a href=\"https://web.archive.org/web/20120628134839/http://knowledgeblog.org/\">Knowledge
        Blog</a> \u2013 a JISC-funded project for light-weight scientific publishing</li><li><a
        href=\"https://web.archive.org/web/20120628134839/http://wiki.code4lib.org/index.php/Code4Lib_Journal_WordPress_Input_Guidelines\">Code4Lib</a>
        \u2013 a journal that provides practical solutions for technologists working
        in libraries, using WordPress as publishing platform</li><li><a href=\"https://web.archive.org/web/20120628134839/http://ptsefton.com/2010/03/30/my-obsession-with-wordpress.htm\">My
        obsession with WordPress</a> \u2013 Peter Sefton\u2019s thoughts on WordPress
        as a scholarly publishing platform</li><li><a href=\"https://web.archive.org/web/20120628134839/http://wordpress.org/extend/plugins/mendeley-related-research/\">Mendeley
        Related Research</a> \u2013 a plugin that finds academic research related
        to your blog posts</li><li><a href=\"https://web.archive.org/web/20120628134839/http://www.youtube.com/watch?v=twxSOGGQV84&amp;feature=player_embedded\">Annotem</a>
        \u2013 an open-source journal authoring and publishing platform based on WordPress</li></ul><p>WordPress
        is by far the most popular blogging platform, and many science bloggers (including
        us here at PLoS Blogs) use WordPress. And science bloggers have some specific
        requirements, e.g. easy to use tools for linking to scholarly papers or aggregators
        of blog posts about a particular paper (<a href=\"https://web.archive.org/web/20120628134839/http://www.researchblogging.org/\">ResearchBlogging</a>)
        or science blogging in general (<a href=\"https://web.archive.org/web/20120628134839/http://scienceblogging.org/2011/01/15/introducing-scienceseeker/\">ScienceSeeker</a>).
        A number of people use WordPress as a lab notebook (e.g. <a href=\"https://web.archive.org/web/20120628134839/http://www.carlboettiger.info/\">Carl
        Boettinger</a>). There is no clear difference between WordPress as a scholarly
        writing tool and WordPress as a blogging tool, and I expect that the amount
        of scholarly writing done with WordPress will only increase.</p><p>Two days
        ago Ed Yong <a href=\"https://web.archive.org/web/20120628134839/http://blogs.discovermagazine.com/notrocketscience/2011/02/02/research-into-reprogrammed-stem-cells-an-interactive-timeline/\">published
        an interactive timeline</a> of research into reprogrammed stem cells. John
        Rennie yesterday cited Ed Yong and this post as a wonderful example of the
        <a href=\"https://web.archive.org/web/20120628134839/http://blogs.plos.org/retort/2011/02/03/why-ed-yong-is-the-future-of-science-news-and-you-could-be-too/\">future
        of science news</a>. The future of science news depends on many things (not
        least brilliant writers such as Ed and John), but I think we also need better
        tools to make science writing fun and exciting.</p><p>In the hope that this
        will improve WordPress as a science writing platform, Mark Hahnel from the
        <a href=\"https://web.archive.org/web/20120628134839/http://www.science3point0.com/\">Science
        3.0</a> blogging network and me today created the <a href=\"https://web.archive.org/web/20120628134839/https://groups.google.com/forum/?hl=en#!forum/wordpress-for-scientists\">WordPress
        for Scientists</a> Google Group. We invite developers who are working on scholarly
        plugins and themes for WordPress to join this group, but also researchers
        that need specific WordPress tools (e.g. to hook up their lab equiment to
        WordPress), and science bloggers that have cool ideas on how to improve WordPress
        for their needs.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ ePub WordPress plugin released today ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/epub-wordpress-plugin-released-today/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw76</id>\n        <published>2011-02-01T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T12:57:59.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/5406202716_43d1b632e0.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/5406202716_43d1b632e0.jpeg\"></p><p>The
        <a href=\"https://web.archive.org/web/20120628132920/https://sites.google.com/site/beyondthepdf/\">Beyond
        the PDF</a> workshop took place a little over a week ago. One take-home message
        for me was that <a href=\"https://web.archive.org/web/20120628132920/http://blogs.plos.org/mfenner/2011/01/23/beyond-the-pdf-%E2%80%A6-is-epub\">ePub
        is a very interesting</a> document format for scholarly publishing and has
        several advantages over PDF. The workshop had a wonderful spirit <em><em>to
        do something</em></em>, and in this spirit I wrote a WordPress plugin that
        automatically creates ePub files from blog posts. The plugin was <a href=\"https://web.archive.org/web/20120628132920/http://wordpress.org/extend/plugins/epub-export\">released
        today</a>, and can be installed directly from your WordPress installation.
        A sample ePub can be downloaded from <a href=\"https://web.archive.org/web/20120628132920/http://blogs.xartrials.org/2011/01/09/embedding-adobe-illustrator-charts-in-wordpress-using-html5/\">this
        blog post</a>, using the link at the bottom.</p><figure class=\"kg-card kg-image-card
        kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/5406202716_43d1b632e0.jpg\"
        class=\"kg-image\" alt=\"Wordpress as ePub\" loading=\"lazy\" width=\"500\"
        height=\"375\"><figcaption><em><em>The workshop example paper from PLoS Comp
        Biol, as seen on the iPad.</em></em></figcaption></figure><p>This is version
        1.0 of the plugin, and there are a still a number of small bugs, mainly because
        ePub is a complex format. A big problem is page breaks, and <a href=\"https://web.archive.org/web/20120628132920/http://en.wikipedia.org/wiki/Widows_and_orphans\">widows
        and orphans</a> can currently only be avoided by workarounds. You can also
        see in the screenshot that the shortcode wasn\u2019t parsed for the ePub.</p><p>But
        these are minor issues that can be solved in the coming weeks. More interesting
        for version 1.1 is the inclusion of attachments (other than images) in the
        ePub. I have to do some more thinking on how to do this, especially how to
        handle all the possible mime types.</p><p>I like reading science blogs in
        ePub format, using either Adobe Digital Editions on the Mac or iBooks on iPad
        and iPhone. This works particularly well for longer posts, e.g. those lovely
        posts from my science writer colleagues here on PLoS Blogs. If you have access
        to WordPress, then this plugin is one of the easiest ways to produce content
        in ePub format.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Nature.com iPad app released today ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/nature-com-ipad-app-released-today/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw77</id>\n        <published>2011-01-24T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-19T08:46:58.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/IMG_0039-500x375.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/IMG_0039-500x375.jpeg\"></p><p>Today
        nature.com <a href=\"https://web.archive.org/web/20120628132319/http://www.nature.com/press_releases/ipad.html\">released</a>
        their iPad reader application. The app gives users access to<em><em> Nature
        News</em></em> and abstracts from <em><em>Nature</em></em>, <em><em>Nature
        Genetics</em></em>, <em><em>Nature Medicine</em></em>, <em><em>Nature Biotechnology</em></em>,
        <em><em>Nature Physics</em></em>, <em><em>Nature Reviews Microbiology, Nature
        Reviews Genetics</em></em> and <em><em>Nature Communications</em></em>. Full
        text access to these journals can be purchased for $69.99 per year (<em><em>Nature</em></em>
        costs $79.99 per year with free access to full-text articles until February
        28).</p><p>The iPad app is in many ways similar to the nature.com iPhone app
        <a href=\"https://blog.front-matter.io/posts/nature_com_iphone_app_in_pictures/\">released
        last February</a>, but takes advantage of the larger screen. A <em><em>Nature
        News</em></em> article looks like this on the website:</p><figure class=\"kg-card
        kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/IMG_0038-500x375.jpg\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"IMG_0038\" width=\"500\" height=\"375\"></figure><p>\u2026
        and like this in the nature.com reader:</p><figure class=\"kg-card kg-image-card\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/IMG_0037-500x375.jpg\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"IMG_0037\" width=\"500\" height=\"375\"></figure><p>Much
        nicer. The <strong><strong>Add to Connotea</strong></strong> button is interesting.
        Connotea is a social bookmarking service by nature.com, but less popular than
        CiteULike and Mendeley. So why is there no choice?</p><p>The home screen lists
        all sources and articles. Users can search nature.com, PubMed and arXiv, but
        the latter two sources are hidden behind the <strong><strong>Advanced</strong></strong>
        button (in the upper right corner).</p><figure class=\"kg-card kg-image-card\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/IMG_0039-500x375.jpg\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"IMG_0039\" width=\"500\" height=\"375\"></figure><p>The
        saved searches and bookmarks are stored on nature.com and can be shared with
        the website and iPhone app. The home screen doesn\u2019t follow iPad conventions
        \u2013 the sources don\u2019t appear in a floating window when holding the
        iPad vertical. Journals can be added here:</p><figure class=\"kg-card kg-image-card\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/IMG_0040-500x375.jpg\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"IMG_0040\" width=\"500\" height=\"375\"></figure><p>Journal
        articles look similar to <em><em>Nature News</em></em>. References open in
        a popup window:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/IMG_0042-500x375.jpg\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"IMG_0042\" width=\"500\" height=\"375\"></figure><p>Figures
        open not in a popup, but in a separate window, and they can be resized. It
        is unfortunately not possible to scroll through the figures of a paper.</p><figure
        class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/IMG_0041-500x375.jpg\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"IMG_0041\" width=\"500\" height=\"375\"></figure><p>The
        nature.com reader doesn\u2019t reflow content when you hold the iPad vertically,
        just shows less white margin on both sides. Author names are not links, and
        for some content the app switches to web browser mode.</p><figure class=\"kg-card
        kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/IMG_0043-375x500.jpg\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"IMG_0043\" width=\"375\" height=\"500\"></figure><p>Reading
        papers on the iPad is much more fun than on the iPhone. And it was a smart
        move <a href=\"https://web.archive.org/web/20120628132319/http://blogs.nature.com/wp/nascent/2010/02/new_naturecom_iphone_app.html\">to
        use ePub</a> for these mobile apps instead of PDF, I think that ePub<a href=\"https://web.archive.org/web/20120628132319/http://blogs.plos.org/mfenner/2011/01/23/beyond-the-pdf-%E2%80%A6-is-epub/\">
        has a bright future</a> for scholarly content. This is version 1.0, I\u2019m
        sure future versions will do further improve the reading experience thanks
        to HTML5. The prices for a personal subscription sounds reasonable, especially
        for the weekly <em><em>Nature</em></em>.</p><p>I have one problem with the
        application: the papers I read are not all published by Nature Publishing
        Group. I would very much prefer an ePub reader for all journal content, similar
        to the iPad PDF readers <strong><strong>Sente</strong></strong>, <strong><strong>Papers</strong></strong>
        and <strong><strong>Mendeley</strong></strong>. We already have several ePub
        readers for the iPad (e.g. Stanza and iBooks), but we need more journal publishers
        that offer their content in this format. The <a href=\"https://web.archive.org/web/20120628132319/http://www.nature.com/press_releases/iphone.html\">press
        release last February</a> hinted that Nature Publishing Group will provide
        content in ePub format for other e-readers. Subscription journals such as
        the <em><em>Nature</em></em> journals have another problem, they want to charge
        the iPad user for reading content. This makes it more difficult for them than
        for open access publishers to distribute content in innovative ways, and that
        is probably one reason the nature.com iPad app is a closed system that can\u2019t
        import, export or print articles.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Beyond the PDF \u2026 is ePub ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/beyond-the-pdf-is-epub/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw78</id>\n
        \       <published>2011-01-23T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-19T08:48:48.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/5376544624_9914bebffa.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/5376544624_9914bebffa.jpeg\"></p><p>Having
        breakfast at the end of a conference is a good way to recap what was discussed
        and can help to generate new ideas. Two years ago at <a href=\"https://web.archive.org/web/20120628140912/http://scienceonline09.com/\">ScienceOnline09</a>
        a conversation with Cameron Neylon that followed up on the session <a href=\"https://web.archive.org/web/20120628140912/http://precedings.nature.com/documents/2801/version/1/html\">Reputation,
        authority and incentives. Or: How to get rid of the Impact Factor</a> (moderated
        by Bj\xF6rn Brembs and Pete Binfield) was started my interest in unique author
        identifiers for researchers. An <a href=\"https://blog.front-matter.io/posts/nterview_with_geoffrey_bilder/\">interview
        with Geoff Bilder</a> about author identifiers and the CrossRef Contributor
        ID project followed a month later \u2013 still one of my favorite blog posts.
        I have since become deeply involved with author identifiers and have joined
        the Board of the Open Researcher &amp; Contributor ID (<a href=\"https://web.archive.org/web/20120628140912/http://www.orcid.org/\">ORCID</a>)
        initiative last September.</p><p>Wednesday to Friday I attended the <a href=\"https://web.archive.org/web/20120628140912/https://sites.google.com/site/beyondthepdf/\">Beyond
        the PDF</a> workshop in San Diego to discuss how we can do better in scholarly
        publishing. The limitations of the PDF format were just one topic, the main
        themes were annotation, data, provenance, new models, writing and reviewing
        and impact. This is my presentation:</p><p>We had two very productive breakout
        sessions about writing and reading tools, and we agreed that we should <a
        href=\"https://web.archive.org/web/20120628140912/https://sites.google.com/site/beyondthepdf/home/program-draft/notes-from-the-breakout\">build
        something that makes it much easier to describe and distribute our research
        data</a>. Most people in the group took a very pragmatic approach and want
        to build simple tools appropriate for small research groups in the next few
        months. We thought that graduate students would be good early adopters, and
        we already have three principal investigators willing to test these tools
        in their labs.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/BTPDFdiagram-500x373.jpg\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"BTPDFdiagram\" width=\"500\"
        height=\"373\"><figcaption><em><em>Our first prototype, as drawn by Peter
        Murray Rust</em></em></figcaption></figure><p>Peter Sefton demonstrated his
        <a href=\"https://web.archive.org/web/20120628140912/http://fascinator-demo.com/portal/default/search\">Fascinator</a>
        tool that already has a lot of the required functionality. But it was the
        breakfast discussion before departing \u2013 again with Cameron Neylon, but
        this time also including Peter Murray Rust, Peter Sefton and Ana Nelson \u2013
        that helped me to put all my thoughts into place.</p><blockquote>ePub should
        become the standard document format for authoring, distributing and reading
        scholarly content.</blockquote><p>The <a href=\"https://web.archive.org/web/20120628140912/http://www.idpf.org/\">ePub
        format</a> uses a collection of files held together in a zip archive. Content
        is displayed using a combination of XHTML and CSS \u2013 not different from
        web pages \u2013 and the ePub can also contain other files. Journal publishers
        use XML internally, and it is therefore easy to distribute journal articles
        in ePub format \u2013 <a href=\"https://web.archive.org/web/20120628140912/http://www.hindawi.com/epub.html\">some
        of them</a> are already doing this routinely. ePub has several advantages
        over PDF, including:</p><ul><li>ePub can be used for all steps in the creation
        of a scholarly document, including data collection, authoring, annotating
        and peer review. There is no need for time-consuming and expensive format
        conversions. Currently most manuscripts are submitted in Microsoft Word or
        LateX formats, and then converted first to XML and then to HTML and PDF. Metadata
        such as author identifiers, digital object identifiers and semantic information
        can be added early on and don\u2019t get lost in a format conversion.</li><li>ePub
        makes it easy to include supplementary material, e.g. video and other multimedia
        content, the datasets used in the publication (particularly the data used
        for tables and figures), all cited references in BibTeX format, etc.</li><li>ePub
        is much better suited for reading on mobile devices, as the format allows
        reflowing of content. Most articles today are printed from the PDF and then
        read, but this behavior is <a href=\"https://web.archive.org/web/20120628140912/http://blogs.plos.org/mfenner/2010/01/10/how_do_you_read_papers_2010_will_be_different/\">rapidly
        changing</a>.</li></ul><p>ePub is relatively new, and not many applications
        for scientists already support this format. We want lab equipment that stores
        its data in ePub, lab notebooks that write all files from an experiment into
        an ePub file, reference managers that store and display papers in ePub format,
        authoring tools that import all these ePub files and thus make it much easier
        to write, annotate and submit a manuscript, and journal submission systems
        that take ePub files. I have <a href=\"https://web.archive.org/web/20120628140912/http://blogs.plos.org/mfenner/2010/12/28/wordpress-for-reference-management/\">written
        a lot about WordPress</a> recently and this is of course a platform that would
        play nicely with ePub. At least two WordPress plugins <a href=\"https://web.archive.org/web/20120628140912/http://wordpress.org/extend/plugins/tags/epub\">support
        ePub</a>, and it should be possible to modify them to the requirements of
        the scholarly paper.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/epub-500x199.jpg\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"epub\" width=\"500\" height=\"199\"></figure><p>Almost
        as important as the document format is the distribution mechanism of these
        ePub files. We need a system that makes it easy to collaborate on a document,
        and that includes version control. The simplest solution would of course be
        centralized and web-based, but I\u2019m not sure that this is a realistic
        scenario. We talked a lot about <a href=\"https://web.archive.org/web/20120628140912/http://www.dropbox.com/\">Dropbox</a>
        during the meeting, but a solution using git (and <a href=\"https://web.archive.org/web/20120628140912/https://github.com/\">github</a>),
        Amazon <a href=\"https://web.archive.org/web/20120628140912/http://aws.amazon.com/s3/\">Simple
        Storage Service</a>, <a href=\"https://web.archive.org/web/20120628140912/http://explore.live.com/windows-live-skydrive\">Windows
        Live SkyDrive</a> or the repository software ePrints or DSpace is also possible.
        As an ePub document can contain all required documents, the submission of
        a manuscript to a journal or institutional repository could become as simple
        as uploading a single file, and all the peer review (including reviewer comments
        and revisions) could be done with that file. Submissions of datasets to databases
        such as <a href=\"https://web.archive.org/web/20120628140912/http://datadryad.org/about\">Dryad</a>
        could of course also be done using ePub files. A versioned distribution system
        should also make it easier to automatically get information about corrections
        or retractions (e.g. using the <a href=\"https://web.archive.org/web/20120628140912/http://www.crossref.org/crossmark.html\">CrossMark</a>
        system that will launch in 2011) and to receive regular updates of article-level
        metrics, including new citations of the article or dataset.</p><p>Several
        of us attending the meeting will continue the discussion in the coming weeks,
        and I hope I can convince them of the advantages of ePub. It shouldn\u2019t
        take us more than a month or two to produce a nice ePub of the <a href=\"https://web.archive.org/web/20120628140912/http://dx.doi.org/10.1371/journal.pcbi.1000976\">sample
        PLoS Computational Biology article</a> provided for the Beyond the PDF workshop.
        The next <strong><strong>Science Online London Conference</strong></strong>
        will be September 2-3 at the British Library. This is a good opportunity to
        discuss the progress of this project, ideally including reports about new
        ePub tools for scientists, more journals using ePub for their articles, and
        practical feedback from the first users.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ DataCite: visit their new blog ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/datacite-visit-their-new-blog/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw79</id>\n        <published>2011-01-14T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T13:05:56.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/datacite-screen-225.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/datacite-screen-225.jpeg\"></p><p><a
        href=\"https://web.archive.org/web/20120611041541/http://datacite.org/whatisdc.html\">DataCite</a>
        is an international consortium for data citation. DataCite originally started
        as a <a href=\"https://web.archive.org/web/20120611041541/http://www.std-doi.de/front_content.php\">project</a>
        at the <a href=\"https://web.archive.org/web/20120611041541/http://www.tib-hannover.de/\">German
        National Library of Science and Technology (TIB)</a>.</p><p>Since 2005 the
        TIB was providing digital object identifiers (DOIs) to research datasets.
        In December 2009 research libraries and technical information centres from
        6 countries founded the DataCite initiative. In December 2010 DataCite reach
        an important milestone by registering the 1,000,000th DOI name.</p><p>Many
        people are familiar with <a href=\"https://web.archive.org/web/20120611041541/http://www.crossref.org/\">CrossRef</a>
        which is providing DOIs for research papers. CrossRef is operated by Publishers
        International Linking Association (PILA), a non-profit organization formed
        by scholarly publishers in 2000. Think of DataCite as the counterpart that
        is providing DOIs for research data. And as research data are typically stored
        in data centers associated with technical information centers \_- e.g. the
        British Library or the \_Canada Institute for Scientific and Technical Information
        (CISTI) - and large research libraries (e.g. California Digital Library),
        DataCite members come from the academic community.</p><p>The TIB is located
        in Hannover, just a few miles away from Hannover Medical School where I work.
        In December I sat down with Jan Brase from the TIB, one of the driving forces
        behind DataCite and on its Board of Directors. We talked not only about DataCite,
        but also how DataCite could interoperate with <a href=\"https://web.archive.org/web/20120611041541/http://www.orcid.org/\">ORCID</a>,
        the unique author identifier initiative (where I am a member of the Board).
        One of the <a href=\"https://web.archive.org/web/20120611041541/http://www.orcid.org/principles\">aims</a>
        of ORCID is to create a <em><em>permanent, clear and unambiguous record of
        scholarly communication,</em></em> and this of course includes not only publications,
        but also the contribution of research datasets. Gudmundur Thorisson gave a
        <a href=\"https://web.archive.org/web/20120611041541/http://blogs.plos.org/mfenner/2010/09/07/orcid-as-unique-author-identifier-what-is-it-good-for-and-should-we-worry-or-be-happy/\">nice
        presentation</a> about the possible integration of DataCite and ORCID in September.</p><p>Earlier
        this week, Jan presented about DataCite at the <a href=\"https://web.archive.org/web/20120611041541/http://www.ape2011.eu/\">Academic
        Publishing in Europe</a> conference in Berlin. His slides are available on
        SlideShare, the video of his talk (like all the other presentations) will
        soon be available <a href=\"https://web.archive.org/web/20120611041541/http://river-valley.tv/\">here</a>.</p><p>Also
        this week Jan started the <a href=\"https://web.archive.org/web/20120611041541/http://datacite.wordpress.com/\">DataCite
        blog</a>. In his <a href=\"https://web.archive.org/web/20120611041541/http://datacite.wordpress.com/2011/01/13/some-more-details-on-2011/\">first
        post</a> (after the obligatory welcome post) Jan talks about the plans DataCite
        has for 2011. I am particularly excited about the central metadata repository
        that should be up and running by June. DataCite has allowed Thomson Reuters
        to crawl the repository so that the metadata will also appear in the <a href=\"https://web.archive.org/web/20120611041541/http://thomsonreuters.com/products_services/science/science_products/a-z/web_of_science/\">Web
        of Science</a>. A lot of interesting stuff is going to happen in 2011 around
        unique identifiers for researchers and their scholarly works.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Having fun with citations at ScienceOnline2011
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/having-fun-with-citations-at-scienceonline2011/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw7a</id>\n        <published>2011-01-11T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T13:08:48.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/screenshot-1-500x432.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/screenshot-1-500x432.png\"></p><p><a
        href=\"https://web.archive.org/web/20120611072611/http://scienceonline2011.com/\">ScienceOnline2011</a>,
        the fifth annual international meeting on Science and the Web, is only two
        days away. I am very excited for many reasons, most importantly because it
        gives me the chance to meet many online friends in person \u2013 again or
        for the first time.</p><p>On Saturday I will help moderate two (related) sessions:
        <strong><strong>How is the Web changing the way we identify scientific impact</strong></strong>
        and <strong><strong>Having fun with citations</strong></strong>. The first
        session will be about alternative ways to measure scientific impact, and about
        the alternative types of publications we can measure. The second session is
        all about citations. We use them all the time in scholarly communications,
        but we don\u2019t really think about them. To give a couple of examples: why
        are there so many different citation styles, why is it so difficult to find
        open bibliographic data, how can we describe why we decided to cite something,
        or how can we cite things that are not publications?</p><p>Since I suggested
        this session a few months ago, my thinking about citations has changed. Citations
        should be easy to use, wherever we need them. Even though he have a number
        of clever <a href=\"https://web.archive.org/web/20120611072611/http://blogs.plos.org/mfenner/reference-manager-overview/\">reference
        management tools</a>, the process is still too complicated. What would really
        help is an easier format for references, and the best format I can think of
        is the ubiquitous internet link. I have <a href=\"https://web.archive.org/web/20120611072611/http://blogs.plos.org/mfenner/2010/12/11/citations-are-links-so-where-is-the-problem/\">written
        about links</a> before, and I have spent the last few weeks to work on WordPress
        plugins to better handle links for scholarly works. Today I released the <a
        href=\"https://web.archive.org/web/20120611072611/http://wordpress.org/extend/plugins/link-to-link/\">Link
        to Link</a> plugin:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/screenshot-1-500x432-1.png\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"screenshot-1\" width=\"500\"
        height=\"432\"><figcaption><em><em>Some science-related references in my WordPress
        Links Manager.</em></em></figcaption></figure><p>The Link to Link window in
        the WordPress editor should look familiar to users of traditional reference
        managers. You search for references and then insert them into the text. The
        references are stored in the WordPress Links Manager, and you can get them
        in there using the <a href=\"https://web.archive.org/web/20120611072611/http://wordpress.org/extend/plugins/bibtex-importer/\">BibTeX
        Importer</a> plugin I wrote two weeks ago. Both plugins are available from
        the WordPress plugins directory and can be installed directly from WordPress.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Now in your DeepDyve store: Nature papers
        to rent ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/now-in-your-deepdyve-store-nature-papers-to-rent/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw7c</id>\n        <published>2011-01-06T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T13:28:56.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Articles published in <em><em>Nature</em></em>,
        <em><em>Nature Biotechnology</em></em>, <em><em>Nature Cell Biology</em></em>,
        <em><em>Nature Medicine</em></em> or <em><em>Nature Chemical Biology</em></em>
        are now available for renting from <a href=\"https://web.archive.org/web/20120611024706/http://www.deepdyve.com/nature\">DeepDyve</a>.
        Downloading or printing is not possible, and the $3.99 rental is for 24 hours.</p><p>Later
        this month, Nature plans to release the nature.com reader for the iPad. Monthy
        access to Nature (again read-only) will cost $9.99. For more information see
        <a href=\"https://web.archive.org/web/20120611024706/http://www.nature.com/press_releases/rental.html\">yesterday\u2019s
        press release</a>.</p><p>In the discussion of subscriptions vs. author-pays
        for scholarly papers we sometimes forget that it\u2019s really a question
        of how much we are willing to pay. I\u2019m looking forward to the nature.com
        app for the iPad, and $9.99 per month seems reasonable. I would not rent a
        single article for $3.99 \u2013 this should either be $0.99 or give me the
        PDF that I can download and print, something that subscription journals typically
        charge $10-$30.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ New journal \u201CNature ONE\u201D launched
        today ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/new-journal-nature-one-launched-today/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw7b</id>\n        <published>2011-01-06T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-26T13:12:44.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>It\u2019s very unusual for
        me to post two blog posts in a single day, and even more so when both posts
        are based on press releases by the same organization. But this is important
        news for everybody interested in scholarly publishing.</p><p>In a <a href=\"https://web.archive.org/web/20120628140907/http://www.nature.com/press_releases/scientificreports.html\">press
        release</a> earlier today, the Nature Publishing Group announced a new journal
        that</p><ul><li>is covering biology, chemistry, earth sciences and physics,</li><li>is
        an open access journal, giving the authors the choice of two Creative Commons
        non-commercial licenses,</li><li>will publish all papers that are judged to
        be technically valid and original, and</li><li>uses article-level metrics
        to put the emphasis on the individual article rather than the journal as a
        whole.</li></ul><p>The new journal is called <a href=\"https://web.archive.org/web/20120628140907/http://www.nature.com/srep/marketing/index.html\"><em><em>Scientific
        Reports</em></em></a>, and obviously resembles <a href=\"https://web.archive.org/web/20120628140907/http://www.plosone.org/\"><em><em>PLoS
        ONE</em></em></a> in many ways, down to the article-processing charges which
        are $1350 for both journals (but will go up to $1700 for <em><em>Scientific
        Reports</em></em> in 2012). The journal is open for submissions and will publish
        the first papers this summer. With <em><em>Nature</em></em>, <em><em>Nature
        Communications</em></em> (also see my <a href=\"https://web.archive.org/web/20120628140907/http://blogs.plos.org/mfenner/2009/11/26/nature_communications_interview_with_lesley_anson/\">interview</a>
        with Chief Editor Lesley Anson) and <em><em>Scientific Reports</em></em> the
        Nature Publishing Group now publishes three journals covering all areas of
        the natural sciences.</p><p>The launch of <em><em>Scientific Reports</em></em>
        is a good sign that <em><em>PLoS ONE</em></em> is doing something right. It
        will be interesting to watch whether the two journals will only be competitive
        \u2013 they are aiming for the same manuscript submissions \u2013 or will
        also collaborate on projects such as article-level metrics.</p><blockquote>\u201CScholarly
        communication has always, will always, and should always be served by a mix
        of models.\u201D</blockquote><p>In another <a href=\"https://web.archive.org/web/20120628140907/http://www.nature.com/press_releases/statement.html\">press
        release</a> today, David Hoole explains the position of the Nature Publishing
        Group on open access publishing. He argues that journals such as <em><em>Nature</em></em>
        with a 90% rejection rates are better served by a subscription model, and
        that he feels that journal submission fees (as discussed in a <a href=\"https://web.archive.org/web/20120628140907/http://blogs.plos.org/mfenner/2010/12/12/submission-fees-for-open-access-journals/\">recent
        report</a>) are not an attractive option. The press release also mentions
        that 40% of the content of the hybrid journal <a href=\"https://web.archive.org/web/20120628140907/http://blogs.plos.org/mfenner/2010/12/12/submission-fees-for-open-access-journals/\">Nature
        Communications</a> is currently open access.</p><p>Although I can follow the
        arguments made in the press release, I disagree that we need different \u201Ctiers\u201D
        of journals. The <em><em>Scientific Reports</em></em> FAQ makes it clear that
        the journal doesn\u2019t expect authors to submit their best works, but rather
        papers that require \u201Cspeed of publication\u201D, promise \u201Cno conceptual
        advance in the field\u201D and show \u201Cnegative results\u201D. Let\u2019s
        see how authors will respond to this and whether it will be possible 10 years
        from now to distinguish papers published in <em><em>Nature,</em></em> <em><em>Nature
        Communications</em></em> and <em><em>Scientific Reports</em></em>.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ HTML5 or messages from beyond the PDF ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/html5-or-messages-from-beyond-the-pdf/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw7d</id>\n        <published>2011-01-05T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T13:10:14.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/2429771653_68e45ff431.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/2429771653_68e45ff431.jpeg\"></p><p>In
        1990 Tim Berners-Lee and others started HTML and the world wide web to facilitate
        scientific communications at CERN, the world\u2019s largest particle physics
        laboratory.</p><p>Although the world wide web profoundly changed scholarly
        publishing (and of course many other things), HTML did not become the standard
        document format for scientific papers. In fact, there is no standard document
        format. We have document formats for authors, for the internal workflow of
        publishers, and for the distribution and reading of papers.</p><p>There are
        of course many good reasons to use LaTeX for writing, XML for workflows, PDF
        to print papers or ePub for mobile devices. But reformatting a manuscript
        into different formats several times is both expensive (in terms of time and
        costs) and means that the formatting options used will be a compromise of
        what is available in all formats.</p><figure class=\"kg-card kg-image-card\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/5327592909_f00585d28e.jpeg\"
        class=\"kg-image\" alt=\"Scholarly Publishing Workflow\" loading=\"lazy\"
        width=\"500\" height=\"350\"></figure><p>All this would be much easier if
        we just used HTML. With HTML, authors, publishers and readers can all use
        the same document format. And they will have an endless number of tools at
        their hands, including of course <a href=\"https://web.archive.org/web/20120611084546/http://blogs.plos.org/mfenner/2010/12/05/blogging-beyond-the-pdf/\">WordPress</a>
        for writing and the web browser of choice for reading. HTML in 2010 is very
        different from HTML in 1990. HTML5 supports new semantic elements such as
        &lt;article&gt;, microdata, embedding of video without plugins, geolocation,
        and offline web applications.</p><p>An HTML-based scholarly publishing workflow
        will make it</p><ul><li>faster and cheaper to publish a paper,</li><li>easier
        to create rich interactive documents,</li><li>easier to add additional steps,
        such as integration of data from <a href=\"https://web.archive.org/web/20120611084546/http://www.axiope.com/\">lab
        notebooks</a>, <a href=\"https://web.archive.org/web/20120611084546/http://www.arxiv.org/\">publishing
        of pre-prints</a>, etc.</li><li>easier to integrate additional services, from
        <a href=\"https://web.archive.org/web/20120611084546/http://cran.r-project.org/web/packages/googleVis/vignettes/googleVis.pdf\">data
        visualization</a> to <a href=\"https://web.archive.org/web/20120611084546/http://languageediting.nature.com/editing-services\">language
        editing</a>.</li></ul> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Author Identifier Overview ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/author-identifier-overview/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw7e</id>\n
        \       <published>2011-01-02T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-31T08:25:16.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Today I <a href=\"https://web.archive.org/web/20120611042244/http://blogs.plos.org/mfenner/author-identifier-overview/\">posted
        the pre-print</a> of a paper titled <strong><strong>Author Identifier Overview</strong></strong>
        that I submitted to the journal <a href=\"https://web.archive.org/web/20120611042244/http://edoc.hu-berlin.de/browsing/libreas/index.php\">Libreas</a>.
        This is the abstract:</p><blockquote>Unique identifiers for scholarly authors
        are still not commonly used, but provide a number of benefits to authors,
        institutions, publishers, funding organizations and scholarly societies. This
        report gives an overview about some of the popular author identifier systems,
        and their characteristics. The report also discusses several important issues
        that need to be addressed by author identifier systems, namely identity, reputation
        and trust.</blockquote><p>The paper was of course written with WordPress.
        I wish you all a Happy New Year.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ WordPress for Reference Management ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/wordpress-for-reference-management/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw7f</id>\n        <published>2010-12-28T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-31T08:24:05.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>One of the more complicated
        aspects of scientific writing is <a href=\"https://web.archive.org/web/20120611082245/http://blogs.plos.org/mfenner/tag/reference-management/\">reference
        management</a> \u2013 an important limitation of online collaborative tools
        such as <em><em>Google Docs</em></em>. I have <a href=\"https://web.archive.org/web/20120611082245/http://blogs.plos.org/mfenner/2010/12/05/blogging-beyond-the-pdf/\">argued
        before</a> that WordPress has the potential to become a great scientific writing
        tool. Wordpress can\u2019t do reference management out of the box, and the
        <a href=\"https://web.archive.org/web/20120611082245/http://wordpress.org/extend/plugins/search.php?q=bibtex\">available
        plugins</a> are somewhat limited. But WordPress is a good platform to add
        reference management functions: it is not only extremely popular (meaning
        a lot of people have expertise and many tools are available), but also already
        knows a lot about links, and has a wonderful plugin architecture.</p><h3 id=\"reference-database\">Reference
        database</h3><p>The first question with reference management in WordPress
        is where to store the references. Should they not be stored at all and be
        directly imported from the source (journal website or bibliographic database
        such as PubMed)? This is what most of us are currently doing when writing
        blog posts, but this approach has obvious limitations on more ambitious writing
        projects. Or should references be inserted from an online reference manager
        such as CiteULike, Mendeley, Refworks or Endnote Web? This is how we use these
        reference managers with Microsoft Word and similar word processors.</p><p>Instead
        I prefer a third approach: store the references in the built-in Links Manager
        in WordPress. References are nothing more than <a href=\"https://web.archive.org/web/20120611082245/http://blogs.plos.org/mfenner/2010/12/11/citations-are-links-so-where-is-the-problem/\">specialized
        links</a> after all. We loose functionality compared to reference manager
        databases, but we get some very interesting features for free, including <a
        href=\"https://web.archive.org/web/20120611082245/http://wordpress.org/extend/plugins/broken-link-checker/\">automatic
        checking of broken links</a>, <a href=\"https://web.archive.org/web/20120611082245/http://wordpress.org/extend/plugins/blogrollsync/\">automatic
        link synchronization</a> with other WordPress installations, and all the other
        cool things for links that people have come up with. And this makes it much
        easier for authors to collaborate if they use different reference managers,
        as all required references are stored in a common database.</p><h3 id=\"bibtex-importer\">BibTeX
        Importer</h3><p>There is currently no good solution to important references
        into the Links Manager, so I wrote a WordPress plugin to do just that. It
        took me two days, which says less about my skills, but more about the WordPress
        plugin architecture. Like all plugins hosted at WordPress.org, my <a href=\"https://web.archive.org/web/20120611082245/http://wordpress.org/extend/plugins/bibtex-importer/\">BibTeX
        Importer</a> plugin can be installed directly from within your WordPress installation
        in less than 5 minutes.</p><p>The plugin takes any BibTeX file (BibTeX is
        one of the more common file formats for references, all good reference managers
        can export into that format) and imports it into the WordPress Links Manager.
        The plugin can also import a BibTex file via URL (e.g. <a href=\"https://web.archive.org/web/20120611082245/http://www.citeulike.org/bibtex/user/mfenner\">http://www.citeulike.org/bibtex/user/mfenner</a>).</p><figure
        class=\"kg-card kg-image-card\"><img src=\"https://web.archive.org/web/20120611082245im_/http://blogs.plos.org/mfenner/files/2010/12/screenshot-2-500x198.jpg\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"BibTeX Importer\"></figure><p>The
        plugin creates WordPress links where the link name is in the format<strong><strong>
        first author \u2013 year \u2013 title</strong></strong>. The original BibTeX
        entry is stored in the link notes. The plugin does some extra work, e.g. checks
        for duplicates before importing and picks the DOI if several URLs are available
        for the link. The plugin also checks the BibTex entry type (article, PhD thesis,
        book chapter, etc.) and automatically assigns a link category with that name.
        The next step would be a solution that automatically synchronizes your WordPress
        Links Manager with a reference manager.</p><h3 id=\"inserting-references\">Inserting
        references</h3><p>Once the references are in the Links Manager, we can use
        them in the articles we write. Unfortunately WordPress doesn\u2019t provide
        an easy way to do that. I personally like the WordPress TinyMCE editor, so
        I made some changes to the wonderful <a href=\"https://web.archive.org/web/20120611082245/http://wordpress.org/extend/plugins/link-to-post/\">Link
        to Post</a> plugin. The plugin provides a searchable interface to link to
        the posts, pages, categories and tags of your own WordPress blog. It took
        me half a day to add a link section, so now I can search for links and insert
        them into a post in a way not that different from how we use reference managers
        with Microsoft Word. The plugin also searches for co-authors, journal names
        and words in abstracts, as all this information is stored in the Link notes
        as BibTeX entry. I will make the updated Link to Post plugin available for
        download (I have contacted the plugin author), for the time being please contact
        me if you are interested.</p><figure class=\"kg-card kg-image-card\"><img
        src=\"https://web.archive.org/web/20120611082245im_/http://blogs.plos.org/mfenner/files/2010/12/link2post-500x377.jpg\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"Link to Post\"></figure><h3
        id=\"providing-a-bibliography\">Providing a bibliography</h3><p>This is the
        last feature that I need for reference management with WordPress, and that
        should also be feasible to do. Ideally the bibliography should be created
        automatically from the links in the text, using the BibTeX info stored in
        the links database. In fact, this is something that a publisher could also
        do after manuscript submission, as the required information is all there.
        The bibliography should use the <a href=\"https://web.archive.org/web/20120611082245/http://blogs.plos.org/mfenner/2010/09/24/citation-style-language-an-interview-with-rintze-zelle-and-ian-mulvany/\">Citation
        Style Language,</a> and <a href=\"https://web.archive.org/web/20120611082245/http://ocoins.info/\">COinS</a>
        (a standard for publishing machine-readable reference information in HTML),
        and should check for duplicate references, broken links, etc.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Paperpile: an open source reference manager
        for Mac and Linux ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/paperpile-an-open-source-reference-manager-for-mac-and-linux/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw7h</id>\n        <published>2010-12-23T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T13:14:31.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/paperpile.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/paperpile.jpeg\"></p><p>Last
        week the first public beta (version 0.5) of <a href=\"https://web.archive.org/web/20120612092613/http://paperpile.com/\">Paperpile</a>
        was released (available for Mac and Linux). Paperpile is a desktop reference
        manager with typical features: search in PubMed, Google Scholar or ArXiv,
        import PDF files, support for BibTex and other standard file formates, etc.
        Paperpile currently doesn\u2019t sync with a web-based version, and Paperpile
        doesn\u2019t insert citations into manuscripts.</p><p>What is interesting
        about Paperpile is that the source code is available at <a href=\"https://web.archive.org/web/20120612092613/https://github.com/wash/paperpile\">github</a>
        (using the <a href=\"https://web.archive.org/web/20120612092613/http://www.gnu.org/licenses/\">GNU
        Affero General Public License</a>). Other reference managers that make their
        source code available include <a href=\"https://web.archive.org/web/20120612092613/https://www.zotero.org/trac\">Zotero</a>,
        <a href=\"https://web.archive.org/web/20120612092613/http://sourceforge.net/apps/mediawiki/jabref/index.php?title=Developing_and_extending_JabRef\">JabRef</a>
        and <a href=\"https://web.archive.org/web/20120612092613/http://www.connotea.org/code\">Connotea</a>.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ New and emerging technologies for reference
        software ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/new-and-emerging-technologies-for-reference-software/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw7g</id>\n        <published>2010-12-23T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-19T08:49:58.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Jason Rollins
        gave a presentation with that topic at the recent <a href=\"https://web.archive.org/web/20120612114551/http://www.stm-assoc.org/event.php?event_id=58\">STM
        Innovations Seminar</a> in London. The video of his presentation <a href=\"https://web.archive.org/web/20120612114551/http://river-valley.tv/new-and-emerging-technologies-for-reference-software/\">has
        now been made available</a> by River Valley TV, and his slides are <a href=\"https://web.archive.org/web/20120612114551/http://www.stm-assoc.org/2010_12_03_Innovations_Rollins_Bibliographic_Management_Software.pdf\">here</a>.</p><p>Jason
        talks about some recent trends in reference management software. For him one
        important new trend is APIs/extensions. I fully agree with him, but we haven\u2019t
        really seen many tools based on these APIs. Reference managers that provide
        APIs include <a href=\"https://web.archive.org/web/20120612114551/http://dev.mendeley.com/\">Mendeley</a>,
        <a href=\"https://web.archive.org/web/20120612114551/http://www.endnote.com/api/\">Endnote</a>,
        Refworks, <a href=\"https://web.archive.org/web/20120612114551/http://developer.mekentosj.com/\">Papers</a>,
        <a href=\"https://web.archive.org/web/20120612114551/http://www.zotero.org/blog/zoteros-next-big-step/\">Zotero</a>
        and <a href=\"https://web.archive.org/web/20120612114551/http://www.connotea.org/wiki/WebAPI\">Connotea</a>.
        The availability of an API has done a lot for the success of Web 2.0 tools
        such as Twitter and Flickr.</p><p>Another interesting topic was brought up
        in the discussion: should reference managers track difference versions of
        an article (e.g. pre-print, post-print, publisher PDF)? According to Jason
        many Endnote users request this feature. Jason is leading the <a href=\"https://web.archive.org/web/20120612114551/http://www.endnote.com/\">Endnote</a>
        development team, but also mentions Mendeley, CiteULike and Papers in his
        presentation. I <a href=\"https://blog.front-matter.io/posts/endnote_interview_with_jason_rollins/\">interviewed</a>
        Jason about Endnote back in August.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Digital Science launched: closing the gap
        between science and technology? ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/digital-science-launched-closing-the-gap-between-science-and-technology/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw7j</id>\n        <published>2010-12-18T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T13:16:18.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/3877930229_a84a550d0e.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/3877930229_a84a550d0e.jpeg\"></p><p>Two
        weeks ago <strong><strong>Eva Amsen</strong></strong> wrote in a thoughtful
        <a href=\"https://web.archive.org/web/20120612094223/http://blogs.nature.com/eva/2010/12/05/a-metaphor-for-science-and-technology\">blog
        post</a>:</p><blockquote>There\u2019s a gap between science and technology,
        and it\u2019s growing.</blockquote><p>Eva argues that \u2013 contrary to popular
        belief \u2013 there is actually a divide between science and technology. Scientists
        are on average not really comfortable using technology, and many computing
        tools aimed for scientists really miss the point of what scientists really
        care about.</p><p>Two days later, on December 7, <a href=\"https://web.archive.org/web/20120612094223/http://www.digital-science.com/\">Digital
        Science</a>, a new division of Macmillan Publishing launched. From the <a
        href=\"https://web.archive.org/web/20120612094223/http://international.macmillan.com/MediaArticle.aspx?id=2598\">press
        release</a>:</p><blockquote>Digital Science will focus on providing world-class
        software tools and services to scientists, managers and funders with the ultimate
        aim of making research more productive through the use of technology.</blockquote><p>Initial
        products include the chemical text-mining tool <a href=\"https://web.archive.org/web/20120612094223/http://www.surechem.org/\">SureChem
        Portal</a>, the laboratory research management system <a href=\"https://web.archive.org/web/20120612094223/http://www.biodata.com/\">BioData</a>
        and the research information system <a href=\"https://web.archive.org/web/20120612094223/http://www.symplectic.co.uk/products/publications.html\">Symplectic
        Elements</a>. You might see some familiar faces when you look at the Digital
        Science <a href=\"https://web.archive.org/web/20120612094223/http://www.digital-science.com/meet-the-team/\">team
        pictures</a>.</p><p>As a big fan of using technology for science I am looking
        forward to what Digital Science will do in the coming months. I am particularly
        interested in their answer to the questions asked by Eva. Have they found
        a better way to understand what technologies scientists really want? Or are
        tools for digital science something that the majority of scientists don\u2019t
        really care about?</p><p>Related posts:</p><ul><li>Cameron Neylon: <a href=\"https://web.archive.org/web/20120612094223/http://cameronneylon.net/blog/macmillan-do-interesting-stuff/\">Macmillan
        do interesting stuff</a></li><li>Benjamin Good: <a href=\"https://web.archive.org/web/20120612094223/http://i9606.blogspot.com/2010/12/digital-science-launches.html\">Digital
        Science launches</a></li><li>John Dupuis: <a href=\"https://web.archive.org/web/20120612094223/http://scienceblogs.com/confessions/2010/12/open_digital_research_science.php\">Open
        Science Digital Computation Research</a></li></ul> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Occam\u2019s Typewriter: please welcome
        a new science blogging network ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/occams-typewriter-please-welcome-a-new-science-blogging-network/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw7k</id>\n        <published>2010-12-13T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T13:17:46.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/occam.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/occam.png\"></p><p>Last
        Friday the latest science blogging network officially launched: <a href=\"https://web.archive.org/web/20120612092936/http://occamstypewriter.org/\">Occam\u2019s
        Typewriter</a>. The independent blogging network started out with eight bloggers
        and one guest blog, <a href=\"https://web.archive.org/web/20120612092936/http://scientopia.org/blogs/thisscientificlife/2010/12/12/occams-typewriter-here-at-last/\">all
        of them well characterized</a> by Bob O\u2019Hara. Most of the bloggers have
        moved their blogs from <a href=\"https://web.archive.org/web/20120612092936/http://network.nature.com/\">Nature
        Network</a>, where I wrote next to them from 2007 until September this year.</p><p>Richard,
        Jenny, Stephen, Austin, Frank, Erika, Cath and Henry, I wish you all good
        luck with the new blogging network.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Citations are links, so where is the problem?
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/citations-are-links-so-where-is-the-problem/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw7n</id>\n        <published>2010-12-11T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T13:18:52.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/4363633528_5026a5ce8b.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/4363633528_5026a5ce8b.jpeg\"></p><p>Citations
        are a fundamental concept of scholarly works. Unfortunately they are also
        difficult to do. Traditional writing tools such as Microsoft Word can\u2019t
        really handle them in a way that is appropriate for a scientific manuscript,
        and that is why we have reference managers such as Endnote, Zotero or Mendeley.
        And the lack of this functionality is a major reason that Google Docs and
        other online collaborative writing tools haven\u2019t become popular for writing
        scholarly works.</p><p>Using citations is hard for paper authors. The process
        is still complicated when using a reference manager, and it remains one of
        the more time consuming aspects of writing a manuscript. The main reason is
        that something always seems to go wrong with the formatting of the bibliography,
        but there are also issues of wrong or duplicate citations (including <a href=\"https://web.archive.org/web/20120611074314/http://www.the-scientist.com/news/display/57698/\">citation
        mutations</a>), correct citation styles, etc. I can\u2019t comment on how
        well BibTeX integrates citation management into LaTeX, but the main issue
        seems to be that citations usually are not one of the core functions of the
        writing tool.</p><h3 id=\"wordpress-and-reference-managers\">WordPress and
        reference managers</h3><p>The blogging platform <strong><strong>WordPress</strong></strong>
        could <a href=\"https://web.archive.org/web/20120611074314/http://blogs.plos.org/mfenner/2010/12/05/blogging-beyond-the-pdf/\">become
        an excellent authoring platform</a> for scientific papers. But to become successful,
        WordPress has to handle scholarly citations, and not just with copy and paste.
        Carl Boettinger <a href=\"https://web.archive.org/web/20120611074314/http://www.carlboettiger.info/archives/570\">has
        written about doing citations in WordPress</a> ealier this week and there
        is also an <a href=\"https://web.archive.org/web/20120611074314/http://friendfeed.com/science-2-0/deef8494/how-do-you-manage-citations-when-writing-on-web\">ongoing
        FriendFeed discussion</a>. I have also looked at the available plugins, in
        particular <a href=\"https://web.archive.org/web/20120611074314/http://wordpress.org/extend/plugins/papercite/\">papercite</a>
        (based on <a href=\"https://web.archive.org/web/20120611074314/http://wordpress.org/extend/plugins/bib2html/\">bib2html</a>)
        which uses the BibTex format and is giving me some problems. I can\u2019t
        get the <a href=\"https://web.archive.org/web/20120611074314/http://labs.crossref.org/site/blog_plugins.html\">CrossRef
        Citation plugin</a> to work (SyntaxError: Parse error) and the <a href=\"https://web.archive.org/web/20120611074314/http://wordpress.org/extend/plugins/mendeleyplugin/\">Mendeley
        Plugin</a> is displaying bibliographies, rather than inserting citations.
        There is currently probably no easy solution to cite scholarly works in WordPress
        and I don\u2019t think that creating a WordPress Plugin for one of the reference
        managers is the right approach.</p><h3 id=\"citations-are-links\">Citations
        are links</h3><p>If we think about it, citations are nothing more than specialized
        links that contain additional information and formatting. And the references
        section is a list of footnotes. Links are a genuine part of WordPress, and
        this system should therefore also be used when writing scholarly works with
        WordPress. A Citation Plugin should extend this system, and solve these issues:</p><ul><li>WordPress
        isn\u2019t very smart about footnotes. I use the <a href=\"https://web.archive.org/web/20120611074314/http://www.elvery.net/drzax/wordpress-footnotes-plugin\">WP-Footnotes</a>
        Plugin, but we need additional functionality: avoid duplicates, formatting
        options of in-text citations (e.g. range of citations or author-year) and
        sorting of footnotes by occurence or name.</li><li>The tool to create links
        in articles is not really integrated with the WordPress Links system (in contrast
        to images, where you have access to the media gallery when inserting an image).</li></ul><p>Both
        of \_these issues can be solved, especially since they are not specific to
        scholarly works and could be tackled by thousands of WordPress developers
        out there.</p><p>We don\u2019t want to use WordPress as a reference manager,
        as there are already many tools out there that can do this job much better.
        We rather want reference manager integration with WordPress, and the easiest
        way to do this would be an automatic synchronization with the WordPress Links
        database. We can already do this with the social bookmarking tool <strong><strong>delicious</strong></strong>
        (I use <a href=\"https://web.archive.org/web/20120611074314/http://wordpress.org/extend/plugins/wp-deliciouslinks/\">DeliciousLinkSync</a>),
        so it shouldn\u2019t be difficult to do this with the social bookmarking tools
        for scientists such as <strong><strong>CiteULike </strong></strong>(you can
        <a href=\"https://web.archive.org/web/20120611074314/http://blog.citeulike.org/?p=174\">sync
        CiteULike with delicious</a>, a workaround I currently use), <strong><strong>Connotea</strong></strong>
        or <strong><strong>BibSonomy</strong></strong>.</p><h3 id=\"links-are-powerful\">Links
        are powerful</h3><p>Using the WordPress Links system makes it very easy to
        extend the core functionality, and many interesting tools are already out
        there. A good example is the <a href=\"https://web.archive.org/web/20120611074314/http://wordpress.org/extend/plugins/broken-link-checker/\">Broken
        Link Checker</a>. The Plugin can regularly check the links in your blog posts,
        but could also be used to check DOIs for references in a semi-automated way.
        The Broken Link Checker found 30 broken links in the <a href=\"https://web.archive.org/web/20120611074314/http://blogs.xartrials.org/2010/12/05/the-mycobacterium-tuberculosis-drugome-and-its-polypharmacological-implications-2/\">Blogging
        Beyond the PDF sample article</a> (all my fault), and automatically changed
        the display style for them.</p><p>And there is so much more that can be done
        with links. I am particularly interested in adding meaning to links using
        the Citation Typing Ontology (<a href=\"https://web.archive.org/web/20120611074314/http://dx.doi.org/10.1186/2041-1480-1-S1-S6\">CiTO</a>).
        And I want to be able to cite specific parts of an article. Dave Winer has
        <a href=\"https://web.archive.org/web/20120611074314/http://scripting.com/stories/2010/10/21/newBloggingTechniques.html\">introduced</a>
        paragraph-level permalinks to blogs, and I can do this on WordPress using
        the <a href=\"https://web.archive.org/web/20120611074314/http://danielbachhuber.com/2010/10/27/winerlinks-v0-2-released/\">WinerLinks
        Plugin</a>. The broken links in my Blogging Beyond the PDF sample article
        are all internal links, and I can now use WinerLinks to fix them. An example
        where I have already done this is the reference to Table S8 in <a href=\"https://web.archive.org/web/20120611074314/http://blogs.xartrials.org/2010/12/05/the-mycobacterium-tuberculosis-drugome-and-its-polypharmacological-implications-2/#p16\">this
        paragraph</a>.</p><p><em><em>Update on 12/11/10: I\u2019ve installed the <a
        href=\"https://web.archive.org/web/20120611074314/http://ptsefton.com/2010/12/09/beyond-the-pdf-proposed-session-bring-the-web-to-the-researcher-mainly-on-authoring-tools.htm\">Anotar
        Plugin</a> by Peter Sefton that adds paragraph-level commenting.</em></em></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Submission Fees for Open Access Journals?
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/submission-fees-for-open-access-journals/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw7m</id>\n        <published>2010-12-10T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T13:21:24.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/2800029836_f351e8c826-1.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/2800029836_f351e8c826-1.jpeg\"></p><p>In
        early December <a href=\"https://web.archive.org/web/20120611025454/http://www.knowledge-exchange.info/\">Knowledge
        Exchange</a>, a partnership of JISC (United Kingdom), SURF (Netherlands),
        DEFF (Denmark), and DFG (Germany)<a href=\"https://web.archive.org/web/20120611025454/http://www.knowledge-exchange.info/Default.aspx?ID=413\">
        released a report</a> on submission fees that they had commissioned to <a
        href=\"https://web.archive.org/web/20120611025454/http://mrkwr.wordpress.com/mark-ware-consulting/\">Mark
        Ware Consulting</a>. The report was also discussed by Robert Kiley on the
        <a href=\"https://web.archive.org/web/20120611025454/http://ukpmc.blogspot.com/2010/12/submission-fees-viable-business-model.html\">UK
        PubMed Central blog</a> and by Phil Davis on the<a href=\"https://web.archive.org/web/20120611025454/http://scholarlykitchen.sspnet.org/2010/12/09/open-access-submission-fees/\">
        Scholarly Kitchen blog</a>.</p><p>Submission fees are more common than I thought,
        particularly in economics and the life sciences. The American Physiological
        Society journals, <em><em>Cancer Research</em></em>, <em><em>FASEB Journal</em></em>,
        <em><em>Journal of Clinical Investigation</em></em>, <em><em>Journal of Immunology</em></em>
        and <em><em>Journal of Neuroscience</em></em> all charge submission fees between
        $50 and $100, the <em><em>Journal of Biological Chemistry</em></em> dropped
        the $60 submission fee in 2010. Most journals that charge submission fees
        are society journals.</p><p>The report finds that submission fees would be
        particularly interesting for Open Access journals with high rejection rates
        (70% and more), as this would greatly reduce the article-processing charges
        for accepted manuscripts. A journal that accepts 10% of submitted papers could
        use a $150 submission fee to reduce the fee for accepted manuscripts from
        $2500 to $1150. There wouldn\u2019t really be a price reduction for journals
        that accept 50% of submitted papers.</p><p>Mark Ware reports that the Open
        Access publishers he talked to weren\u2019t really interested in starting
        submission fees for their journals, mainly because of the risks involved in
        changing their business model. I personally believe that submission fees may
        be the only option for journals with high rejection rates to become Open Access
        journals (unless you want to cross-subsidize those journals). I like submission
        fees because they help to cover the actual costs involved, instead of the
        costs of handling manuscripts that are ultimately rejected being paid either
        by journal subscribers or the authors of accepted manuscripts.</p><p>The full
        13-page report can be downloaded <a href=\"https://web.archive.org/web/20120611025454/http://www.knowledge-exchange.info/Files/Filer/downloads/Open%20Access/KE_Submission_fees_Short_Report_2010-11-25.pdf\">here</a>.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Blogging Beyond the PDF ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/blogging-beyond-the-pdf/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw7p</id>\n
        \       <published>2010-12-05T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-01T06:33:36.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Four weeks
        ago I <a href=\"https://web.archive.org/web/20120611081800/http://blogs.plos.org/mfenner/2010/11/06/beyond-the-pdf-it-is-time-for-a-workshop/\">wrote
        about</a> the <a href=\"https://web.archive.org/web/20120611081800/https://sites.google.com/site/beyondthepdf/\">Beyond
        the PDF</a> workshop that is planned for January in San Diego. The goal of
        the workshop is to identify a set of requirements, and a group of willing
        participants to develop open source code to accelerate scientific knowledge
        sharing. The <a href=\"https://web.archive.org/web/20120611081800/http://groups.google.com/group/beyond-the-pdf?pli=1\">Google
        Group</a> for the workshop has already seen a lot of interesting discussions.
        I have since had more time to think about my contribution and decided to propose
        the following:</p><p><em><em>Evaluate the blogging software </em></em><strong><strong><em><em>WordPress</em></em></strong></strong><em><em>
        as a platform to author, review and publish scientific manuscripts. Extend
        the <strong><strong>WordPress</strong></strong> functionality for authors
        and citations.</em></em></p><h3 id=\"blogging-beyond-the-pdf\">Blogging Beyond
        the PDF</h3><p>Wordpress is a very interesting candidate for this because
        of the following features:</p><ol><li>WordPress is Open Source and can be
        easily modified and extended by Themes, Plugins, etc.</li><li>WordPress is
        used by millions of users, a market much larger than the scientific software
        market. Many requirements for a scientific writing platform are not specific
        for scientific software.</li><li>WordPress treats article writing as a workflow
        that includes collaborative writing, version control, and a document status.</li></ol><p>Of
        course I\u2019m not the first to think about WordPress in this context, the
        <a href=\"https://web.archive.org/web/20120611081800/http://journal.code4lib.org/\">Code4Lib
        journal</a> and <a href=\"https://web.archive.org/web/20120611081800/http://knowledgeblog.org/\">Knowledge
        Blog</a> are just two examples. To get started, I installed WordPress and
        a number of interesting Plugins at a new<a href=\"https://web.archive.org/web/20120611081800/http://blogs.xartrials.org/\">
        Blogging Beyond the PDF</a> website. Phil Bourne has kindly provided material
        from a recent<em><em> PLoS Computational Biology</em></em> <a href=\"https://web.archive.org/web/20120611081800/http://dx.doi.org/10.1371/journal.pcbi.1000976\">paper</a>
        for the workshop. I formatted a first version of this paper using WordPress
        and the result can be seen <a href=\"https://web.archive.org/web/20120611081800/http://blogs.xartrials.org/2010/12/05/the-mycobacterium-tuberculosis-drugome-and-its-polypharmacological-implications-2/\">here</a>.
        There are a lot of rough edges (several tables and most references are still
        missing), but to me this looks good enough considering this is the result
        of maybe 10 hours of the work. In the next six weeks I will continue to work
        on this example manuscript to get a better idea of the strengths and weaknesses
        of the WordPress platform. I also hope to learn more from the experience of
        others. My first impressions are below.</p><h3 id=\"authors\">Authors</h3><p>The
        <a href=\"https://web.archive.org/web/20120611081800/http://wordpress.org/extend/plugins/co-authors-plus/\">Co-Authors
        Plus</a> Plugin enables multiple authors per article. Each author can be linked
        to an author page for displaying biographical info. WordPress could be extended
        to include additional info such as institution or past publications. Linking
        the WordPress user account to the unique author identifier <a href=\"https://web.archive.org/web/20120611081800/http://www.orcid.org/\">ORCID</a>,
        and describing the role of the author in the paper (e.g. <em><em>conceived
        and designed the experiments</em></em> or <em><em>analyzed the data</em></em>)
        would be particularly interesting. Plugins such as <a href=\"https://web.archive.org/web/20120611081800/http://www.editflow.org/\">Edit
        Flow</a> can extend the workflow by adding custom status messages (e.g. <em><em>resubmission</em></em>),
        reviewer comments, and email notifications.</p><h3 id=\"figures\">Figures</h3><p>Wordpress
        has good functionality to add figures to articles, including the option to
        add a caption or resize the figure. In addition, there is a good number of
        Plugins that help with the resizing, other manipulations and display of images.</p><h3
        id=\"tables\">Tables</h3><p>Wordpress doesn\u2019t do tables, but several
        Plugins add that functionality, including <a href=\"https://web.archive.org/web/20120611081800/http://tobias.baethge.com/wordpress-plugins/wp-table-reloaded-english/\">WP-Table
        Reloaded</a>. This Plugin adds some very interesting functions, including
        the option to export table data as CSV or XLS files. This makes it much easier
        to reuse these data, something that I <a href=\"https://web.archive.org/web/20120611081800/http://blogs.plos.org/mfenner/2010/09/30/why-cant-i-reuse-these-tables-and-figures/\">find
        very useful</a>.</p><h3 id=\"citations\">Citations</h3><p>The <a href=\"https://web.archive.org/web/20120611081800/http://www.elvery.net/drzax/wordpress-footnotes-plugin\">WP-Footnotes</a>
        Plugin is one of several plugins that adds footnotes to articles. Several
        Plugins integrate with reference managers such as CiteULike, but the functionality
        is still very limited compared to how most reference managers are integrated
        with Microsoft Word or LaTeX.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Medical Information Matters ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/medical-information-matters/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw7q</id>\n
        \       <published>2010-12-03T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T13:21:46.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>In December I am hosting the
        blog carnival <a href=\"https://web.archive.org/web/20120612112930/http://laikaspoetnik.wordpress.com/2010/09/30/may-i-introduce-to-you-a-new-name-for-the-medlibs-round/\">Medical
        Information Matters</a>, a blog carnival about \u2013 <strong><strong>medical
        information</strong></strong>. The deadline for submissions is next Tuesday,
        and I have already received a number of interesting posts. As Christmas is
        right around the corner, I thought that a good theme for the carnival would
        be a<strong><strong> wish list for better medical information</strong></strong>.
        This could mean many different things, e.g. a database that covers a specific
        area, better access to full-text papers or clinical trial results, etc. Please
        submit your posts <a href=\"https://web.archive.org/web/20120612112930/http://blogcarnival.com/bc/submit_6092.html\">here</a>.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Repositories: Researcher Perspective ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/repositories-researcher-perspective/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw7r</id>\n        <published>2010-11-30T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-29T10:14:33.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/DALL-E-2022-08-29-12.14.04---garden-gnome-with-an-umbrella-in-front-of-brandenburg-gate-as-a-painting-from-van-gogh.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/DALL-E-2022-08-29-12.14.04---garden-gnome-with-an-umbrella-in-front-of-brandenburg-gate-as-a-painting-from-van-gogh.png\"></p><p>Earlier
        today I gave this presentation at the<a href=\"https://web.archive.org/web/20120611031918/http://www.dini.de/veranstaltungen/workshops/dinihelmholtz-workshop-repositorien-praxis-und-vision/\">
        DINI/Helmholtz Repositories Workshop</a> in Berlin. I\u2019m looking forward
        to the second day tomorrow.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Researchers\u2019 reasons for publishing
        their work ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/researchers-reasons-for-publishing-their-work/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw7s</id>\n        <published>2010-11-28T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T13:22:19.000+00:00</updated>\n\t\t<category
        term=\"Chart\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/swan-1.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/swan-1.jpeg\"></p><p>When
        we want to change something, we have to look at the incentives for those involved.</p><h2
        id=\"references\">References</h2><p>Swan, A. (2006) The culture of Open Access:
        researchers\u2019 views and responses. In: <em><em>Open Access: Key Strategic,
        Technical and Economic Aspects</em></em>, Chandos. <a href=\"https://web.archive.org/web/20120611024948/http://eprints.ecs.soton.ac.uk/12428\">http://eprints.ecs.soton.ac.uk/12428</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Making your study public before you start
        can be fun ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/making-your-study-public-before-you-start-can-be-fun/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw7v</id>\n        <published>2010-11-27T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-31T08:22:12.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>On Monday I was finally able
        to start the clinical trial <strong><strong>Everolimus for patients with relapsed/refractory
        germ cell cancer</strong></strong> (<a href=\"https://web.archive.org/web/20101124185406/http://www.mh-hannover.de/studien/en/protocols/191.html\">RADIT</a>),
        and I\u2019m now looking forward to recruit the first patient. We aim to treat
        25 patients with cancer of the testis with the mTOR inhibitor everolimus in
        this phase II trial, and eight German hospitals are participating.</p><p>The
        International Committee of Medical Journal Editors (ICMJE) <a href=\"https://web.archive.org/web/20101124185406/http://www.icmje.org/publishing_10register.html\">requires</a>,
        as a condition of consideration for publication in their journals, registration
        in a public trials registry. I registered my trial with Clinicaltrials.gov
        as <a href=\"https://web.archive.org/web/20101124185406/http://clinicaltrials.gov/ct2/show/NCT01242631\">NCT01242631</a>.
        The registration process was straightforward, especially compared to all the
        other paperwork required for this trial.</p><p>The requirement for registration
        of clinical trials helps to prevent publication bias \u2013 meaning that negative
        results are likely to never be \_published. Clinical trial registries make
        it unlikely that you will be \u201Cscooped\u201D, as you know about the other
        studies addressing the same questions years before they finish.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Evolving English at the British Library
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/evolving-english-at-the-british-library/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw7t</id>\n        <published>2010-11-24T00:00:00.000+00:00</published>\n\t\t<updated>2023-07-05T19:11:18.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>On Saturday
        I went to see the exhibition <a href=\"https://web.archive.org/web/20120611032112/http://www.bl.uk/evolvingenglish/\">Evolving
        English</a> at the British Library in London. The exhibition explores the
        English language in all its diversity and was recommended to me by Matt Brown,
        an expert on all things London (his review for the Londonist is <a href=\"https://web.archive.org/web/20120611032112/http://londonist.com/2010/11/review_evolving_english_british_lib.php\">here</a>).
        <strong><strong>Evolving English</strong></strong> is interesting in many
        different ways, but here I want to focus on English as the language of science
        \u2013 used in two examples in the exhibition.</p><p>The book <em><em>Micrographia</em></em>
        from 1665 by Robert Hooke is the first major scientific work devoted to exploration
        using the microscope. It is also an important step in the development of scientific
        English. The book was praised for the clarity of the language at the time,
        but from today\u2019s science writing perspective contains sentences that
        are too long and convoluted, uses conversational English, and frequently an
        active voice. The National Library of Medicine provides a beautiful <a href=\"https://web.archive.org/web/20120611032112/http://archive.nlm.nih.gov/proj/ttp/flash/hooke/hooke.html\">online
        version</a> of the book, where observation XXV starts with:</p><blockquote><em><em>A
        nettle is a plant so well known to every one, as to what the appearance of
        it is to the naked eye, that it needs no description; and there are very few
        that have not felt as well as seen it; and therefore it will be no news to
        tell that a gentle and slight touch of the skin by a nettle, does oftentime,
        not onely create very sensible and acute pain, much like that of a burn or
        scald, but often also very angry and hard swellings and inflammations of the
        parts, such as will presently rise and continue swoln divers hours.</em></em></blockquote><p>As
        an example of current scientific English, the exhibitors picked the paper
        describing the cloning of Dolly (Wilmut 1997). The text is described in the
        exhibition as:</p><blockquote><em><em>The language is punctual throughout
        and technical terms are mostly used without explanation. The main text is
        supported by illustrations (here called figures), tables of data and \u2013
        over the page \u2013 bibliographic references to other scientific research.
        The purpose is to to maximize accuracy, remove any chance of ambiguity and
        provide writers with every opportunity to give detailed evidence.</em></em></blockquote><p>The
        exhibition makes it very clear that the English language is constantly evolving,
        and scientific English is no exception. Papers written in 10, 20, or 100 years
        might use a very different language. One important influence today is of course
        science writing in blogs and other social media. And with electronic publishing,
        open access, citizen science, and other trends, scientific papers have become
        available to a much larger audience.</p><h2 id=\"references\">References</h2><p>Wilmut
        I, Schnieke AE, McWhir J, Kind AJ, Campbell KHS. Viable offspring derived
        from fetal and adult mammalian cells. <em>Nature</em>. 1997;385(6619):810-813.
        doi:<a href=\"https://doi.org/10.1038/385810a0\">10.1038/385810a0</a><br></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ UK PubMed Central explained in Nucleic Acids
        Research Paper ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/uk-pubmed-central-explained-in-nucleic-acids-research-paper/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw7w</id>\n        <published>2010-11-14T00:00:00.000+00:00</published>\n\t\t<updated>2023-07-05T18:25:54.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/F3.medium-1.gif\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/F3.medium-1.gif\"></p><p>Last
        Tuesday <em><em>Nucleic Acids Research</em></em> published a nice paper describing
        the<a href=\"https://web.archive.org/web/20101124185412/http://ukpmc.ac.uk/\">
        UK PubMed Central</a> (UKPMC) database (McEntyre 2010). UKPMC was started
        in 2007, the enhanced version described in the paper was <a href=\"https://web.archive.org/web/20101124185412/http://blogit.realwire.com/?ReleaseID=14754\">launched
        January 2010</a>. In November 2009 I published an <a href=\"https://doi.org/10.53731/dzr4d0a-anr8e6y\">interview
        with Phil Vaughan</a>, the senior author of the paper. The paper talks about
        the specific enhancements done to PubMed Central, including an integrated
        search of PubMed and PubMed Central, \u201CCited by information\u201D and
        semantically enriched content generated by text mining.</p><p>Thanks to Duncan
        Hull we know that PubMed currently contains information about 20 million papers
        (<a href=\"https://web.archive.org/web/20101124185412/http://duncan.hull.name/2010/07/27/pubmed-20-million/\">Twenty
        million papers in PubMed: a triumph or a tragedy?</a>). About 10% of these
        papers are available as full-text from PubMed Central. What wasn\u2019t clear
        to me and what I learned from the paper is that only 194,000 papers, or 1%
        of PubMed content, are from the <a href=\"https://web.archive.org/web/20101124185412/http://www.ncbi.nlm.nih.gov/pmc/about/openftlist.html\">PMC
        Open Access Subset</a> (and that includes papers with a non-commercial OA
        license). All these papers are available as <a href=\"https://web.archive.org/web/20101124185412/http://www.ncbi.nlm.nih.gov/pmc/about/ftp.html\">download</a>
        or via <a href=\"https://web.archive.org/web/20101124185412/http://www.ncbi.nlm.nih.gov/pmc/about/oai.html\">PMC-OAI
        service</a>. Although 1.8 million papers (the majority digitized back issues)
        can be freely downloaded as full-text from PubMed Central, they carry a publisher
        copyright and can\u2019t be reused for research purposes (e.g. full-text mining)
        without explicit permission from the publisher.</p><h2 id=\"references\">References</h2><p>McEntyre
        JR, Ananiadou S, Andrews S, et al. UKPMC: a full text article resource for
        the life sciences. <em>Nucleic Acids Research</em>. 2011;39(Database):D58-D65.
        doi:<a href=\"https://doi.org/10.1093/nar/gkq1063\">10.1093/nar/gkq1063</a></p><p>Fenner
        M. UK PubMed Central: Interview with Phil Vaughan. Published online November
        4, 2009. doi:<a href=\"https://doi.org/10.53731/dzr4d0a-anr8e6y\">10.53731/dzr4d0a-anr8e6y</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Scientific Attribution Presentation ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/scientific-attribution-presentation/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw7x</id>\n        <published>2010-11-12T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-19T08:51:52.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Earlier today I gave a short
        presentation about the <a href=\"https://blog.front-matter.io/posts/scientific-attribution-principles/\">Scientific
        Attribution Principles</a> I posted here two weeks ago.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ More Gobbledygook at PLoS Blogs ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/more-gobbledygook-at-plos-blogs/\"
        />\n\t\t<id>https://doi.org/10.53731/9xpwtq8-84qkgwd</id>\n        <published>2010-11-03T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-14T14:39:26.000+00:00</updated>\n
        \       <media:content url=\"\" medium=\"image\"/>\n        <content type=\"html\"><![CDATA[
        <p><img src=\"\"></p><p>Thanks to a lot of hard work both at <strong><strong>Nature
        Network</strong></strong> and here at <strong><strong>PLoS Blogs</strong></strong>,
        all blog posts and comments from my <a href=\"https://web.archive.org/web/20101124185441/http://blogs.nature.com/mfenner/\">former
        blog at Nature Network</a> (August 2007 to August 2010) are now also available
        here. Special thanks go to Lou Woudley and Brian Mossop who made all this
        happen. There are of course a few formatting glitches here and there, but
        I will try to fix them over time.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ An ORCID discussion group for researchers
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/an-orcid-discussion-group-for-researchers/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw81</id>\n        <published>2010-11-02T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T13:18:50.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>The Open Researcher &amp;
        Contributor ID (<a href=\"https://web.archive.org/web/20101124191013/http://www.orcid.org/\">ORCID</a>)
        initiative is working on a unique researcher identifier for the creation of
        a clear and unambiguous scholarly record. The initiative is supported by <a
        href=\"https://web.archive.org/web/20101124191013/http://www.orcid.org/directory\">more
        than 140</a> universities, research institutes, funding organizations, publishers
        and other organizations interested in scholarly communication. The ORCID system
        will become publicly available in the first half of 2011.</p><p>Individual
        researchers will benefit from a unique researcher identifier because this
        identifier facilitates the manuscript submission process, and the creation
        of CVs and publication lists for institutional websites. Unique researcher
        identifiers will also help discover scholarly works and will make it easier
        to attribute scientific contributions other than papers \u2013 \_e.g. research
        datasets \u2013 to individual researchers.</p><p>Researchers have a lot to
        gain from unique researcher identifiers, and they might also have genuine
        concerns. Because of my interest in scholarly communication, and<a href=\"https://web.archive.org/web/20101124191013/http://blogs.nature.com/mfenner/2010/01/03/orcid-or-how-to-build-a-unique-identifier-for-scientists-in-10-easy-steps\">
        unique researcher identifiers in particular</a>, I became involved with the
        ORCID initiative in early 2010. When ORCID became a non-profit organization
        in August, I was asked to sit on the <a href=\"https://web.archive.org/web/20101124191013/http://www.orcid.org/board-directors\">Board
        of Directors</a> \u2013 one of many interesting things that have happened
        to me as the result of my science blogging. But although ORCID is certainly
        open to all individuals and organizations interested in author disambiguation,
        most researchers simply want to be informed about the progress of the initiative,
        ask specific questions and start using their identifier at some point.</p><p>The
        <a href=\"https://web.archive.org/web/20101124191013/http://www.orcid.org/\">ORCID
        website</a> is a good starting for this information, but to get individual
        answers to specific researcher questions about ORCID, <a href=\"https://web.archive.org/web/20101124191013/http://twitter.com/kristiholmes\">Kristi
        Holmes</a>, <a href=\"https://web.archive.org/web/20101124191013/http://twitter.com/gthorisson\">Gudmundur
        Thorisson</a>, <a href=\"https://web.archive.org/web/20101124191013/http://twitter.com/CameronNeylon\">Cameron
        Neylon</a> and <a href=\"https://web.archive.org/web/20101124191013/http://twitter.com/mfenner\">myself</a>
        today started the <a href=\"https://web.archive.org/web/20101124191013/http://groups.google.com/group/orcid-researchers\">ORCID
        Researchers</a> Google Group. Feel free to ask your ORCID-related researcher
        questions there, or contact us via email or Twitter.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ NCBI adds searchable images database ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/ncbi-adds-searchable-images-database/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw82</id>\n        <published>2010-10-29T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T13:25:35.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/images.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/images.jpeg\"></p><p>On
        Wednesday the NCBI released an <a href=\"https://web.archive.org/web/20101124191025/http://www.ncbi.nlm.nih.gov/images\">Images
        database</a>, compiled from full text resources at the NCBI \u2013 initially
        PubMed Central articles. The images can be searched by several parameters,
        e.g. figure caption or author.</p><p>Using this database, images are now displayed
        together with the PubMed abstract for PubMed Central articles. More info about
        these changes can be found in the <a href=\"https://web.archive.org/web/20101124191025/http://www.nlm.nih.gov/pubs/techbull/so10/so10_pm_display_ncbi_images.html\">NLM
        Bulletin</a>.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Some thoughts on principles for scientific
        attribution ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/some-thoughts-on-principles-for-scientific-attribution/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw83</id>\n        <published>2010-10-28T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-01T11:43:39.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://images.unsplash.com/photo-1562412692-26406e1bf600?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDF8fGF0dHJpYnV0aW9ufGVufDB8fHx8MTYxODY0MDYzOA&amp;ixlib&#x3D;rb-1.2.1&amp;q&#x3D;80&amp;w&#x3D;2000\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://images.unsplash.com/photo-1562412692-26406e1bf600?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDF8fGF0dHJpYnV0aW9ufGVufDB8fHx8MTYxODY0MDYzOA&amp;ixlib&#x3D;rb-1.2.1&amp;q&#x3D;80&amp;w&#x3D;2000\"></p><p>Today
        <a href=\"https://web.archive.org/web/20101124191031/http://blogs.plos.org/mfenner/scientific-attribution-principles/\">I
        posted a document</a> that should help define a set of principles for scientific
        attribution. These principles will be presented and discussed at the National
        Science Foundation workshop <strong><strong>Changing the Conduct of Science
        in the Information Age</strong></strong> on November 12. Many people helped
        me with this document (<a href=\"https://web.archive.org/web/20101124191031/http://cameronneylon.net/\">Cameron
        Neylon</a> in particular), and I welcome comments and suggestions.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Self-motivated vs. mandated archiving ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/self-motivated-vs-mandated-archiving/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw84</id>\n        <published>2010-10-26T00:00:00.000+00:00</published>\n\t\t<updated>2023-09-07T21:03:29.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/4088667379_880b0a796a.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/4088667379_880b0a796a.jpeg\"></p><p>My
        post last week about <a href=\"https://doi.org/10.53731/r294649-6f79289-8cw87\"
        rel=\"noreferrer\">citation rates of mandated vs. self-selected Open Access</a>fulfills
        resulted in an interesting discussion thanks to some good arguments made by
        Stevan Harnad. One personal conclusion for me: mandates for self-archiving
        are not a good idea. I would very much prefer researchers to be highly motivated
        to self-archive thanks to a repository that both fulfills important functions
        and is fun to use.</p>\n<p>What follows is a short list of ideas \u2013 many
        of them obvious and some of them already implemented \u2013 that for me would
        make repositories more attractive to use.</p>\n<h3 id=\"hosting-of-research-datasets\">Hosting
        of research datasets</h3>\n<p>Disciplinary and institutional repositories
        are good places to make primary research data publicly available. Particularly
        if no standard database exists, such as <a href=\"https://web.archive.org/web/20101124191039/http://www.ncbi.nlm.nih.gov/genbank/\">GenBank</a>
        for genetic sequence data. Whereas everybody nowadays talks about <a href=\"https://web.archive.org/web/20101124191039/http://www.jisc.ac.uk/whatwedo/programmes/~/link.aspx?_id=28A2778937C74EB285F05E38BFBD5DEE&amp;_z=z\">making
        research data available</a>, the threshold to do so is often too high for
        more specialized datasets. An institutional repository is a good place for
        a simple grassroots solution.</p>\n<h3 id=\"a-disciplinary-repository-for-biomedical-research\">A
        disciplinary repository for biomedical research</h3>\n<p><a href=\"https://web.archive.org/web/20101124191039/http://www.ncbi.nlm.nih.gov/pmc/\">PubMed
        Central</a> and <a href=\"https://web.archive.org/web/20101124191039/http://ukpmc.ac.uk/\">UK
        PubMed Central</a> are popular disciplinary repositories for the biomedical
        and life sciences. Unfortunately, I can only submit manuscripts to them if
        the research was funded by one of a few funders (including the NIH, but none
        of the major German funders).</p>\n<h3 id=\"a-preprint-archive-for-clinical-trials\">A
        preprint archive for clinical trials</h3>\n<p>Deposition of manuscripts prior
        to peer review <a href=\"https://doi.org/10.53731/r294649-6f79289-8cw8d\"
        rel=\"noreferrer\">has a long tradition</a> in high-energy physics and related
        disciplines. Preprint archives probably don\u2019t work in all disciplines,
        but I have <a href=\"https://doi.org/10.53731/r294649-6f79289-8cw89\" rel=\"noreferrer\">argued
        before</a> that they could be a very good idea for clinical trials.</p>\n<h3
        id=\"journal-publishers-that-allow-self-archiving\">Journal publishers that
        allow self-archiving</h3>\n<p>While most publishers allow some form of self-archiving
        by authors (pre-print, post-print and/or publisher\u2019s PDF version), there
        are unfortunately still exceptions. The American Chemical Society (ACS) has
        a <a href=\"https://web.archive.org/web/20101124191039/http://scientopia.org/blogs/bookoftrogool/2010/10/05/acs-the-perfect-storm/\">particularly
        unwelcoming policy</a>.</p>\n<h3 id=\"integration-with-the-journal-submission-process\">Integration
        with the journal submission process</h3>\n<p>An institutional repository can
        host pre-prints of submitted papers. But the repository could also enable
        a tighter integration with the journal submission process. The German <a href=\"https://web.archive.org/web/20101124191039/https://www.escidoc.org/JSPWiki/en/Overview\">eSciDoc</a>
        project uses that approach. Most researchers would probably welcome technical
        and financial assistance in the submission process.</p>\n<h3 id=\"integration-with-institutional-bibliography\">Integration
        with institutional bibliography</h3>\n<p>The institutional bibliography showcases
        the scholarly work done by a particular researcher, research group, department,
        or institution. Many researchers like to see up-to-date profiles (including
        publication lists) on their institutional web pages. Bibliographies are also
        collected for evaluation purposes. We have started to use <a href=\"https://web.archive.org/web/20101124191039/http://www.bibapp.org/\">BibApp</a>
        at our institution. Repositories can facilitate full-text access to PhD theses
        and other publications in the bibliography.</p>\n<h3 id=\"repositories-that-use-unique-author-identifiers\">Repositories
        that use unique author identifiers</h3>\n<p>Regular readers of this blog know
        about <a href=\"https://doi.org/10.53731/r294649-6f79289-8cw5j\" rel=\"noreferrer\">my
        involvement</a>fulfills in the Open Researcher &amp; Contributor ID (ORCID)
        initiative. All scholarly contributions, including repository content, should
        be unambiguously connected to their creators as this will greatly facilitate
        the discovery process. I look forward to ORCID support in repository software
        such as <a href=\"https://web.archive.org/web/20101124191039/http://www.dspace.org/\">DSpace</a>
        and <a href=\"https://web.archive.org/web/20101124191039/http://www.eprints.org/\">EPrints</a>.</p>\n<h3
        id=\"references\">References</h3>\n<p>Fenner, M. (2010). <em>New in PLoS ONE:
        Citation rates of self-selected vs. mandated Open Access</em>. <a href=\"https://doi.org/10.53731/r294649-6f79289-8cw87\">https://doi.org/10.53731/r294649-6f79289-8cw87</a></p>\n<p>Fenner,
        M. (2010). <em>New on Arxiv: First report of SOAP open access publishing project</em>.
        <a href=\"https://doi.org/10.53731/r294649-6f79289-8cw8d\">https://doi.org/10.53731/r294649-6f79289-8cw8d</a></p>\n<p>Fenner,
        M. (2010). <em>In which I suggest a preprint archive for clinical trials</em>.
        <a href=\"https://doi.org/10.53731/r294649-6f79289-8cw89\">https://doi.org/10.53731/r294649-6f79289-8cw89</a></p>\n<p>Fenner,
        M. (2010). <em>ORCID as unique author identifier: What is it good for and
        should we worry or be happy?</em> <a href=\"https://doi.org/10.53731/r294649-6f79289-8cw5j\">https://doi.org/10.53731/r294649-6f79289-8cw5j</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Having an impact (factor) and other stories
        from Gregory Petsko ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/having-an-impact-factor-and-other-stories-from-gregory-petsko/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw85</id>\n        <published>2010-10-24T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T13:16:07.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Biologist <a href=\"https://web.archive.org/web/20101124191225/http://www.bio.brandeis.edu/faculty/petsko.html\">Gregory
        Petsko</a> has written a <a href=\"https://web.archive.org/web/20101124191225/http://genomebiology.com/search/results?drpField1=&amp;txtSearch1=&amp;drpPhrase1=and&amp;drpField2=[TI]&amp;txtSearch2=&amp;drpPhrase2=and&amp;drpField3=[AU]&amp;txtSearch3=petsko_g&amp;drpPhrase3=and&amp;drpField4=&amp;txtSearch4=&amp;drpPhrase4=and&amp;excludeField1=&amp;excludeSearchText1=&amp;excludePhrase1=and&amp;articleType=Comment&amp;drpOrderBy=by+date&amp;itemsPerPage=25&amp;search-button=Search\">monthly
        column</a> for the journal <em><em>Genome Biology</em></em> since the journal
        launched in 2000. To mark the 10th anniversary of the column and the journal,
        <em><em>Genome Biology</em></em> <a href=\"https://web.archive.org/web/20101124191225/http://blogs.openaccesscentral.com/blogs/bmcblog/entry/gregory_petsko_in_genome_biology\">created
        an eBook</a> (<a href=\"https://web.archive.org/web/20101124191225/http://ax.itunes.apple.com/gb/book/gregory-petsko-in-genome-biology/id397541470\">iPad/iPhone</a>:
        free, <a href=\"https://web.archive.org/web/20101124191225/http://www.amazon.com/gp/product/B0046W6TD0?ie=UTF8&amp;tag=wwwbiomedcent-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=B0046W6TD0\">Kindle</a>:
        99 c) containing all columns up to August 2010.</p><p>I downloaded the iBooks
        version for iPad/iPhone. The columns read nicely on the iPad display (almost
        all of them are text-only, a few contain images and/or links), and the texts
        are of course thoughtful and entertaining. Here are a few teasers:</p><ul><li>Petsko
        G (2009a). Nation of twits. https://doi.org/<a href=\"https://web.archive.org/web/20101124191225/http://dx.doi.org/10.1186/gb-2009-10-8-110\">10.1186/gb-2009-10-8-110</a>.</li><li>Petsko
        G (2009b). What my genome told me \u2013 and what it didn\u2019t. https://doi.org/<a
        href=\"https://web.archive.org/web/20101124191225/http://dx.doi.org/10.1186/gb-2009-10-6-108\">10.1186/gb-2009-10-6-108</a>.</li><li>Petsko
        G (2008). Having an impact (factor).<br>https://doi.org/<a href=\"https://web.archive.org/web/20101124191225/http://dx.doi.org/10.1186/gb-2008-9-7-107\">10.1186/gb-2008-9-7-107</a>.</li></ul><p>Suggestion
        for <em><em>Genome Biology</em></em>: if you want more people to read the
        column, create an RSS feed for it. Or even better, turn it into a blog.</p><p>Suggestion
        for <em><em>EMBO Reports</em></em>: pick up the idea and create an eBook with
        the editorials by <strong><strong>Frank Gannon</strong></strong>, who wrote
        a similarly thoughtful column for them <a href=\"https://web.archive.org/web/20101124191225/http://blogs.nature.com/nautilus/2009/04/frank_gannon_says_farewell_to.html\">until
        April 2009</a>.</p><h2 id=\"references\">References</h2><p><strong><strong>Petsko
        G</strong></strong>. Nation of twits. <em><em>Genome Biology</em></em>. 2009;10(8):110+.
        Available from: https://doi.org/<a href=\"https://web.archive.org/web/20101124191225/http://dx.doi.org/10.1186/gb-2009-10-8-110\">10.1186/gb-2009-10-8-110</a>.</p><p><strong><strong>Petsko
        G</strong></strong>. What my genome told me \u2013 and what it didn\u2019t.
        <em><em>Genome Biology</em></em>. 2009;10(6):108+. https://doi.org/<a href=\"https://web.archive.org/web/20101124191225/http://dx.doi.org/10.1186/gb-2009-10-6-108\">10.1186/gb-2009-10-6-108</a>.</p><p><strong><strong>Petsko
        G</strong></strong>. Having an impact (factor). <em><em>Genome Biology</em></em>.
        2008;9(7):107+.<br>https://doi.org/<a href=\"https://web.archive.org/web/20101124191225/http://dx.doi.org/10.1186/gb-2008-9-7-107\">10.1186/gb-2008-9-7-107</a>.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Helping researchers create scholarly content
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/helping-researchers-create-scholarly-content/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw86</id>\n        <published>2010-10-20T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-01T06:30:31.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Two weeks
        ago I gave a presentation at the <a href=\"https://web.archive.org/web/20101114043831/http://www.stm-assoc.org/event.php?event_id=56\">STM
        Annual Conference 2010</a> in Frankfurt (STM is the International Association
        of Scientific, Technical and Medical Publishers). I told the audience that
        publishers could do a much better job helping researchers create digital content
        \u2013 both by providing better tools and by reconsidering licenses for content
        reuse.</p><p>A video of my presentation is available <a href=\"https://web.archive.org/web/20101114043831/http://river-valley.tv/helping-researchers-create-scholarly-content/\">here</a>.
        The other presentations of the event can be viewed <a href=\"https://web.archive.org/web/20101114043831/http://www.stm-assoc.org/event_presentations.php?event_id=56\">here</a>
        \u2013 unfortunately not (yet) the keynote by <a href=\"https://web.archive.org/web/20101114043831/http://www.guardian.co.uk/profile/stephendunn\">Stephen
        Dunn</a> from the Guardian (Beyond Publishing: how we open up to our users).</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Start Open Access Week with Kick-Off Video
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/start-open-access-week-with-kick-off-video/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw88</id>\n        <published>2010-10-18T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T12:56:34.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><figure class=\"kg-card kg-embed-card
        kg-card-hascaption\"><iframe src=\"https://player.vimeo.com/video/15881200?app_id=122963\"
        width=\"480\" height=\"272\" frameborder=\"0\" allow=\"autoplay; fullscreen;
        picture-in-picture\" allowfullscreen title=\"Open Access Week 2010\"></iframe><figcaption><a
        href=\"https://vimeo.com/15881200\">Open Access Week 2010</a> from <a href=\"https://web.archive.org/web/20101114043744/http://vimeo.com/sparcdc\">SPARC</a>
        on <a href=\"https://vimeo.com/\">Vimeo</a>.</figcaption></figure><p>Find
        out more at the <a href=\"https://web.archive.org/web/20101114043744/http://www.openaccessweek.org/\">Open
        Access Week website</a>. And watch this blog for another Open Access story
        later today.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ New in PLoS ONE: Citation rates of self-selected
        vs. mandated Open Access ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/new-in-plos-one-citation-rates-of-self-selected-vs-mandated-open-access/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw87</id>\n        <published>2010-10-18T00:00:00.000+00:00</published>\n\t\t<updated>2023-07-05T18:10:43.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p><em><em>PLoS ONE</em></em>
        today published a paper very relevant to <a href=\"https://web.archive.org/web/20101114042817/http://www.openaccessweek.org/\">Open
        Access Week</a> (which started today):</p><p><strong><strong>Gargouri Y, Hajjem
        C, Larivi\xE8re V, Gingras Y, Carr L, Brody T, Harnad S</strong></strong>.
        Self-Selected or Mandated, Open Access Increases Citation Impact for Higher
        Quality Research. <em><em>PLoS ONE</em></em>. 2010;5(10):e13636+. doi:<a href=\"https://web.archive.org/web/20101114042817/http://dx.doi.org/10.1371/journal.pone.0013636\">10.1371/journal.pone.0013636</a>.</p><p>The
        paper studied the citation rates of papers from four institutions with the
        longest-standing self-archiving mandate: <a href=\"https://web.archive.org/web/20101114042817/http://www.soton.ac.uk/\">Southampton
        University</a>, <a href=\"https://web.archive.org/web/20101114042817/http://public.web.cern.ch/public/\">CERN</a>,
        <a href=\"https://web.archive.org/web/20101114042817/http://www.qut.edu.au/\">Queensland
        University of Technology</a> and <a href=\"https://web.archive.org/web/20101114042817/http://www.uminho.pt/Default.aspx?lang=en-US\">Minho
        University</a>. The mandates (instituted between 2002 and 2004) increased
        the rate of self-archiving in the respective institutional repositories from
        around 15% to 60%:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://web.archive.org/web/20101114042817im_/http://blogs.plos.org/mfenner/files/2010/10/journal.pone_.0013636.g001.png\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"journal.pone.0013636.g001\"><figcaption><em><em>Fig
        1. Open Access Self-archiving percentages for institutions with self-archiving
        mandates compared to non-mandated, self-selected controls. doi:<a href=\"https://web.archive.org/web/20101114042817/http://blogs.plos.org/mfenner/2010/10/18/new-in-plos-one-citation-rates-of-self-selected-vs-mandated-open-access/10.1371/journal.pone.00136363.g001\">10.1371/journal.pone.00136363.g001</a></em></em></figcaption></figure><p>The
        authors then compared the citation rates of self-archived papers from the
        four institutions published in non-Open Access (OA) journals (<a href=\"https://web.archive.org/web/20101114042817/http://www.sherpa.ac.uk/romeoinfo.html\">mandated
        OA</a>) to matched papers from the same non-OA journal, volume and year (non-OA).
        15% of the latter papers were also available from repositories (self-selected
        OA). Overall the study examined the citations of 27,197 papers from 1,984
        non-OA journals. The study also looked at the influence of other factors that
        affect citation rates, e.g. article age, journal impact factor or number of
        references.</p><p>The main results of the study are that OA articles are cited
        more frequently than non-OA articles and that there is no difference in citation
        rates between mandated and self-archived articles. The authors conclude that
        OA articles are cited more often not because of self-selection (articles with
        higher impact more likely become OA), but because of readers cite OA articles
        more often.</p><p>The study is an effort to better understand if and why OA
        papers are cited more often, the so-called OA Advantage. Unfortunately I feel
        that the paper comes a little short. Yes, they did a very detailed analysis
        of the citation behavior, and take into account important cofactors. But the
        reader is left with the impression that mandatory self-archiving of post-prints
        in institutional repositories is the only reasonable Open Access strategy,
        and the introduction and discussion accordingly leave out some important arguments.</p><p>The
        authors fail to mention that not all studies show a citation advantage for
        OA articles (e.g. the randomized controlled trial by <a href=\"https://web.archive.org/web/20101114042817/http://dx.doi.org/10.1136/bmj.a568\">Davis
        PM et al. 2008</a>), and they only look at self-archiving in institutional
        repositories (green OA). Not only are there important disclipline-specific
        repositories such as PubMed Central and ArXiv, but of course also OA journals
        such as <em><em>PLoS ONE</em></em> that published the study (gold OA). And
        the study only discussed archiving of articles after peer review, even though
        archiving of preprints is a popular strategy in high-energy physics and related
        disciplines (and here the self-archiving rate is close to 100%). I also don\u2019t
        see a discussion of why the self-archiving rate of post-prints in institutions
        with a mandate is 60% and not close to 100%. And what is wrong if archiving
        rates are only around 15% if it is left to the researchers to decide? Finally,
        there are many reasons other than citation rates that make OA worthwhile,
        including access to the literature for those not working in academic institutions
        (and maybe never citing a paper), and work that uses the OA literature in
        new and exciting ways that go beyond citations. For me personally, the OA
        advantage is much more in these two aspects than in the citation rates of
        papers.</p><p>For me Open Access week is an opportunity to celebrate what
        has been achieved over the years. But it is equally important to look at the
        road ahead. There is no \u201Cone size fits all\u201D solution for Open Access,
        and we shouldn\u2019t look away from the things that aren\u2019t working,
        and the solutions that haven\u2019t been found yet.</p><h2 id=\"references\">References</h2><p>Gargouri
        Y, Hajjem C, Larivi\xE8re V, et al. Self-Selected or Mandated, Open Access
        Increases Citation Impact for Higher Quality Research. Futrelle RP, ed. <em>PLoS
        ONE</em>. 2010;5(10):e13636. doi:<a href=\"https://doi.org/10.1371/journal.pone.0013636\">10.1371/journal.pone.0013636</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ In which I suggest a preprint archive for
        clinical trials ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/in-which-i-suggest-a-preprint-archive-for-clinical-trials/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw89</id>\n        <published>2010-10-16T00:00:00.000+00:00</published>\n\t\t<updated>2023-07-10T15:42:52.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/4861245046_54d92ddfa9.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/4861245046_54d92ddfa9.jpeg\"></p><p>The
        <a href=\"https://web.archive.org/web/20101105203901/http://arxiv.org/\">ArXiv</a>
        preprint archive for research articles in physics, mathematics, computer science
        and related disciplines <a href=\"https://web.archive.org/web/20101105203901/http://people.ccmr.cornell.edu/~ginsparg/blurb/pg02pr.html\">was
        initiated</a> by Paul Ginsparg in 1991. ArXiv enables the rapid dissemination
        of research articles prior to peer review, and it quickly became very successful
        in this. ArXiv has not made the peer-reviewed journal obsolete, but rather
        provides a service that traditional journals \u2013 and that also includes
        Open Access journals \u2013 can\u2019t provide. By 1998, more than 90% of
        all peer-reviewed papers published in high-energy physics <a href=\"https://web.archive.org/web/20101105203901/http://arxiv.org/abs/0906.5418\">first
        appeared on ArXiv</a>. <a href=\"https://web.archive.org/web/20101105203901/http://precedings.nature.com/\">Nature
        Precedings</a> was started in 2007 to provide similar services for research
        in biology, medicine (except clinical trials), chemistry and earth sciences.
        In addition, many preprints are also hosted in institutional repositories.</p><p>The
        research that I am doing is clinical research, trying to improve the treatment
        of patients with cancer. Most clinical trials are drug trials, but there are
        also surgical interventions, trials with medical devices, etc. Clinical trials
        are a special kind of research, and I have talked about some aspects <a href=\"https://web.archive.org/web/20101105203901/http://blogs.nature.com/mfenner/2010/03/15/chances-and-problems-of-doing-science-online\">in
        a previous post</a>. Registration of clinical trials before the first patient
        is treated \u2013 providing <a href=\"https://web.archive.org/web/20101105203901/http://www.who.int/ictrp/network/trds/en/index.html\">key
        information</a> from the trial protocol \u2013 is now required in many countries,
        including the United States and the European Union. The U.S. database of registered
        clinical trials (<a href=\"https://web.archive.org/web/20101105203901/http://clinicaltrials.gov/\">Clinicaltrials.gov</a>)
        is publicly available, and the EU is working on doing the same with their
        <a href=\"https://web.archive.org/web/20101105203901/https://eudract.ema.europa.eu/\">EudraCT</a>
        database. The International Committee of Medical Journal Editors (ICMJE),
        and in consequence many medical journals, also <a href=\"https://web.archive.org/web/20101105203901/http://www.icmje.org/publishing_10register.html\">requires
        clinical trial registration</a>. Since September 2008 the U.S. Food and Drug
        Administration (FDA) also <a href=\"https://web.archive.org/web/20101105203901/http://blogs.nature.com/mfenner/2008/08/02/fdaaa-push-to-open-data-in-clinical-medicine\">requires</a>
        all clinical trials registered at Clinicaltrials.gov to provide key results
        within 12 months after the last patient has finished treatment.</p><p>The
        results of clinical trials are rarely first reported in a peer-reviewed journal,
        but rather are usually first presented at a conference \u2013 in the case
        of important practice-changing clinical trials often before an audience of
        thousands of people. The conference abstracts are also an important source
        of information, even though they don\u2019t provide the space for more detailed
        information, including tables and figures. Many societies publish conference
        abstract in their society journals, but bibliographic databases such as PubMed
        probably don\u2019t cover all conference abstracts reporting clinical trial
        results.</p><p>The peer-reviewed paper is usually published months or even
        years after the conference presentation. This not only allows for more mature
        data \u2013 e.g. survival information \u2013 but also critical review and
        discussion of the data. The publication of the peer-reviewed paper is <strong><strong>not</strong></strong>
        the first time the medical community learns about the results of a clinical
        trial, or draws conclusions for their own research or clinical practice. To
        take a recent example from a clinical trial in cancer: the results of the
        TROPIC trial of cabazitaxel chemotherapy in hormone-refractory metastatic
        prostate cancer (Clinicaltrials.gov <a href=\"https://web.archive.org/web/20101105203901/http://clinicaltrials.gov/ct2/show/NCT00417079\">NCT00417079</a>)
        were <a href=\"https://web.archive.org/web/20101105203901/http://www.asco.org/ASCOv2/Meetings/Abstracts?&amp;vmview=abst_detail_view&amp;confID=73&amp;abstractID=30560\">first
        reported</a> at the ASCO Genitourinary Cancers Symposium March 5 (and there
        was a <a href=\"https://web.archive.org/web/20101105203901/http://en.sanofi-aventis.com/binaries/20100304_Asco_GU_en_tcm28-27547.pdf\">press
        release</a> a day earlier). Capazitaxel <a href=\"https://web.archive.org/web/20101105203901/http://www.fda.gov/AboutFDA/CentersOffices/CDER/ucm216214.htm\">was
        approved</a> by the FDA on June 17, and I treated the first patient with the
        drug in September. The peer-reviewed paper <a href=\"https://doi.org/10.1016/S0140-6736(10)61389-X\">was
        published</a> in <em><em>The Lancet</em></em> October 2.</p><p>I would like
        to suggest that we need a preprint archive for clinical trial research papers.
        The preprints should be uploaded at the time of journal submission, or shortly
        after the conference presentation. The preprint server should add some structure
        to the preprints, e.g. linking to both the clinical trials registry (Clinicaltrials.gov,
        EudraCT, and others) and the published paper. The preprint should fulfill
        the requirement for reporting results set by the FDA. Articles in the preprint
        archive should be freely available, and should ideally provide the main results
        as downloadable datasets. The preprint server will only work if medical journals
        \u2013 and ideally the <a href=\"https://www.icmje.org/\">ICMJE</a> \u2013
        have a clear policy allowing prior publication as preprint.</p><p><em><em>This
        post was inspired by discussions with Salvatore Mele and Ivan Oransky. And
        it is my first contribution to the </em></em><a href=\"https://web.archive.org/web/20101105203901/http://www.openaccessweek.org/\"><em><em>Open
        Access Week</em></em></a><em><em> that starts on Monday.</em></em></p><h3
        id=\"references\">References</h3><p>Chances and problems of doing science
        online. Published online March 15, 2010. doi:<a href=\"https://doi.org/10.53731/r294649-6f79289-8cw4s\">10.53731/r294649-6f79289-8cw4s</a></p><p>De
        Bono JS, Oudard S, Ozguroglu M, et al. Prednisone plus cabazitaxel or mitoxantrone
        for metastatic castration-resistant prostate cancer progressing after docetaxel
        treatment: a randomised open-label trial. <em>The Lancet</em>. 2010;376(9747):1147-1154.
        doi:<a href=\"https://doi.org/10.1016/S0140-6736(10)61389-X\">10.1016/S0140-6736(10)61389-X</a></p><figure
        class=\"kg-card kg-image-card\"><img src=\"https://web.archive.org/web/20101105203901im_/http://www.linkwithin.com/pixel.png\"
        class=\"kg-image\" alt=\"Related Posts Plugin for WordPress, Blogger...\"
        loading=\"lazy\"></figure> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Today I started a new blogging network ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/today-i-started-a-new-blogging-network/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw8a</id>\n        <published>2010-10-15T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T13:31:51.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/5001818922_f30d953f07.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/5001818922_f30d953f07.jpeg\"></p><p>In
        the last few weeks I haven\u2019t seen any announcement for a new science
        blogging network (the last one was probably <a href=\"https://web.archive.org/web/20101105204155/http://blog.coturnix.org/2010/09/15/alert-some-big-and-important-and-exciting-news/\">Scientific
        American</a> in September). So I thought today would be a good day to start
        a new one. Earlier today I wrote <a href=\"https://web.archive.org/web/20101105204155/http://blogs.mh-hannover.de/tumorzentrum/2010/10/15/herzlich-willkommen/\">the
        first post</a> on the first blog hosted by <a href=\"https://web.archive.org/web/20101105204155/http://www.mh-hannover.de/index.php?id=2&amp;L=1\">my
        institution</a>. The blog runs on a WordPress 3.0 installation that I hope
        will see more blogs in the future \u2013 our library will probably be next
        (they are currently <a href=\"https://web.archive.org/web/20101105204155/http://mhhbibliothek.wordpress.com/\">hosted
        on WordPress.com</a>).</p><p>The new blog is the official blog of our Comprehensive
        Cancer Center (my day job). I will write about various aspects of the work
        there \u2013 something I wanted to do for a while. This is also the first
        time that I write in German, which will be much easier, but at the same time
        will reach a smaller audience. Writing for my institution will also be an
        interesting experience. Although I don\u2019t think that this will start something
        big at our institution, institutions are in fact a good place for blogging
        networks. Special thanks go to Stefan Zorn in our PR department for encouraging
        words, and to <a href=\"https://web.archive.org/web/20101105204155/http://scienceblog.cancerresearchuk.org/about-the-authors/\">Henry
        Scowcroft</a> from Cancer Research UK for many good tips about blogging for
        an institution.</p><p>The new blog of course doesn\u2019t mean that I stop
        writing here. I\u2019m too deep into this.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Nature.com iPhone app updated ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/nature-com-iphone-app-updated/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw8b</id>\n        <published>2010-10-13T00:00:00.000+00:00</published>\n\t\t<updated>2023-07-13T14:10:37.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Earlier this year I <a href=\"https://doi.org/10.53731/r294649-6f79289-8cw4n\">wrote
        about</a> the Nature.com iPhone application that was released in February.
        Two weeks ago the app was updated with the following changes:</p><ul><li>Access
        to abstracts from additional journals: <em><em>Nature Genetics</em></em>,
        <em><em>Nature Medicine</em></em>, <em><em>Nature Biotechnology</em></em>,
        <em><em>Nature Reviews Microbiology</em></em>, <em><em>Nature Reviews Genetics,
        Nature Physics,</em></em> and <em><em>Nature Communications.</em></em></li><li><em><em>Access
        to full-text articles for a monthly subscription fee ($9.99 for Nature, $8.99
        for the other journals). Access to Nature News and Nature Communications is
        free.</em></em></li></ul><p>The updated app doesn\u2019t work with the iPad,
        and the Android version that was announced in February has not been released
        yet. Users that don\u2019t update to the newest version of the app don\u2019t
        get access to additional journals, but can still read full-text articles from
        Nature.</p><p>Reading papers on the iPad for me is a lot of fun. The reading
        experience on the iPhone/iPod touch is very different, and not something I
        would spend $9.99 a month for. But it is obvious where this is heading: many
        users (including myself) would probably spend $9.99/month for a nicely done
        iPad version of Nature. Especially if the content is free/cheaper with an
        institutional subscription. And we can already read PLoS content for free
        with the <a href=\"https://web.archive.org/web/20101105204928/http://blogs.plos.org/everyone/2010/09/16/plos-reader-2-0/\">PLoS
        Reader</a>.</p><h3 id=\"references\">References</h3><p>Fenner M. Nature.com
        iPhone app in pictures. Published online February 8, 2010. doi:<a href=\"https://doi.org/10.53731/r294649-6f79289-8cw4n\">10.53731/r294649-6f79289-8cw4n</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Survey asks for feedback about ORCID unique
        researcher identifier ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/survey-asks-for-feedback-about-orcid-unique-researcher-identifier/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw8c</id>\n        <published>2010-10-12T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T13:35:57.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/215910967_7ede5cc61a.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/215910967_7ede5cc61a.jpeg\"></p><p>The
        <a href=\"https://web.archive.org/web/20101013051207/http://www.orcid.org/\">ORCID</a>
        initiative for unique researcher identifiers yesterday started a <a href=\"https://web.archive.org/web/20101013051207/http://survey.euro.confirmit.com/wix/p501806648.aspx\">survey</a>
        that everybody interested in ORCID should fill out.</p><p>The survey asks
        questions about the main services that users expect from ORCID, and how the
        ORCID service should be paid for (e.g. membership fees or fee-for service).</p><p>In
        quick response to the announcement of the survey on Twitter, an <a href=\"https://web.archive.org/web/20101013051207/http://friendfeed.com/researchremix/d5611278/rt-orcid_org-please-help-us-move-orcid-forward\">interesting
        discussion</a> started on <strong><strong>FriendFeed</strong></strong>. Several
        commenters were worried that ORCID tries to be too much. Their thoughts were
        nicely summarized in <a href=\"https://web.archive.org/web/20101013051207/http://twitter.com/#!/CameronNeylon/status/27158241887\">this
        tweet</a> by <strong><strong>Cameron Neylon</strong></strong>:</p><figure
        class=\"kg-card kg-embed-card\"><blockquote class=\"twitter-tweet\"><p lang=\"en\"
        dir=\"ltr\">.<a href=\"https://twitter.com/mfenner?ref_src=twsrc%5Etfw\">@mfenner</a>
        Agree with <a href=\"https://twitter.com/ReaderMeter?ref_src=twsrc%5Etfw\">@ReaderMeter</a>
        + <a href=\"https://twitter.com/mrgunn?ref_src=twsrc%5Etfw\">@mrgunn</a>:
        <a href=\"https://twitter.com/ORCID_Org?ref_src=twsrc%5Etfw\">@ORCID_Org</a>
        will be a success when it does amazing things for me and I barely notice it&#39;s
        there</p>&mdash; C\u24D0meronNeylon (@CameronNeylon) <a href=\"https://twitter.com/CameronNeylon/status/27158241887?ref_src=twsrc%5Etfw\">October
        12, 2010</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\"
        charset=\"utf-8\"></script>\n</figure><p>The survey is open until October
        28, the results will be reported in November.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Registration for ScienceOnline2011 starts
        today ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/registration-for-scienceonline2011-starts-today/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw7y</id>\n        <published>2010-10-10T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T13:43:08.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/Scionline2011-100.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/Scionline2011-100.png\"></p><p>Registration
        for the <a href=\"https://web.archive.org/web/20101124185427/http://scienceonline2011.com/\">ScienceOnline2011</a>
        conference starts today at 12 noon EST. This is the fifth annual conference
        on science and the web, and will be held January 13-15, 2011 in Research Triangle
        Park, North Carolina.</p><p>This is the second time I will go to the conference
        \u2013 I had a wonderful time in 2009. The discussion around the 2009 session<a
        href=\"https://web.archive.org/web/20101124185427/http://jdupuis.blogspot.com/2009/01/scienceonline-09-sunday-summary-and.html\">
        Reputation, Authority and Incentives</a> (moderated by Bj\xF6rn Brembs and
        Pete Binfield) was really the starting point for my interest in unique researcher
        identifiers. The conference was also the first time that I met PLoS Blogs
        partner <a href=\"https://web.archive.org/web/20101124185427/http://blogs.plos.org/takeasdirected/\">David
        Kroll</a> and many other great people.</p><p>You will find my name on the
        <a href=\"https://web.archive.org/web/20101124185427/http://scio11.wikispaces.com/Program+Finalization\">preliminary
        program</a> in a session<strong><strong> Having Fun with Citations</strong></strong>
        (together with Melody Dye)<strong><strong>:</strong></strong></p><blockquote><em><em>Citations
        play a central role in science communication, but their role in the traditional
        scientific publication is often rather boring. We love to count citations
        for measures of scientific impact, but we spend little time thinking about
        the context and meaning of citations. In this session I would like to talk
        about topics ranging from semantic meaning of citations (using CiTO, the Citation
        Typing Ontology by David Shotton), citations of retracted papers, citations
        of datasets (using Datacite), the importance of an Open Bibliography, formatting
        of citations using CSL (Citation Style Language), citations in Twitter and
        other unusual places, citation mutations and the integration of unique researcher
        identifiers (using ORCID). There is some interesting work on how citation
        rates follow Zipfian-like distributions; it would be interested to discuss
        the background and implications.</em></em></blockquote><p>The exact session
        format and the other session moderators have not been finalized. There are
        also at least two related session proposals: <strong>How is the Web changing
        the way we identify scientific impact?</strong> (Jason Priem, Paul Groth)<strong><strong>
        </strong></strong>and <strong><strong>The Digital Toolbox: What\u2019s Needed?
        </strong></strong>(Kaitlin Thaney) \u2013 we might combine some of our ideas.
        And of course, I am also looking forward to again meeting all these wonderful
        people that are interested in science and the web.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ New on Arxiv: first report of SOAP open
        access publishing project ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/new-on-arxiv-first-report-of-soap-open-access-publishing-project/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw8d</id>\n        <published>2010-10-09T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-31T08:18:33.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Practically all papers in
        high-energy physics (&gt; 90% since the late 1990s) are first published on
        the <a href=\"https://web.archive.org/web/20101013051257/http://arxiv.org/\">ArXiv</a>
        preprint server. Several related disciplines also have a long ArXiv tradition.
        But ArXiv is also an excellent source of interesting papers about scientific
        publishing, including this one from last Monday:</p><p><strong><strong>Dallmeier-Tiessen
        S, Darby R, Goerner B, Hyppoelae J, Igo-Kemenes P, Kahn D, et al.</strong></strong>
        First results of the SOAP project. Open access publishing in 2010. 2010 Oct;
        Available from: <a href=\"https://web.archive.org/web/20101013051257/http://arxiv.org/abs/1010.0506\">http://arxiv.org/abs/1010.0506</a>.</p><p>The
        paper is a comprehensive report on the current state of open access publishing
        \u2013 and deserves a separate blog post. <strong><strong>Salvatore Mele</strong></strong>
        (one of the coauthors) pointed me to this paper in a very interesting dinner
        conversation last night. Follow the <a href=\"https://web.archive.org/web/20101013051257/http://www.citeulike.org/group/13987/library\">Gobbledygook
        reading list</a> for more interesting ArXiv papers, including a <a href=\"https://web.archive.org/web/20101013051257/http://arxiv.org/abs/0906.5418\">gem</a>
        from 2009 on the citation behavior in high-energy physics.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Paper published: Reference Management meets
        Web 2.0 ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/paper-published-reference-management-meets-web-2-0/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw8e</id>\n        <published>2010-10-08T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T07:53:00.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p><em><em>Cellular Therapy and
        Transplantation</em></em> today published my paper <a href=\"https://web.archive.org/web/20101016090740/http://dx.doi.org/10.3205/ctt-2010-en-000087.01\">Reference
        Management meets Web 2.0</a>. Regular readers of this blog probably know about
        most of the things I talk about in the paper, but I hope it is a good introduction
        for those new to reference management.</p><p>The paper wouldn\u2019t be possible
        without FriendFeed, because Claudia Koltzenburg \u2013 the Managing Editor
        of the journal and regular contributor to FriendFeed \u2013 contacted me after
        one of our discussions there.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Reference Management with the iPad ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/reference-management-with-the-ipad/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw8f</id>\n        <published>2010-10-06T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-31T08:17:39.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>The iPad was released six
        months ago, and we already have several reference managers available for the
        platform. Reading the PDF of a scientific paper on an iPad is a positive experience,
        and to me very different from reading the PDF on a regular computer. While
        this could also be done with generic iPad PDF readers such as <strong><strong>iBooks</strong></strong>
        or <strong><strong>Goodreader</strong></strong>, reference managers make it
        much easier to organize a large collection of PDF files.</p><h3 id=\"citeulike\">CiteULike</h3><p>CiteULike
        is a browser-based reference manager and works on the iPad as expected \u2013
        and this includes the bookmarklet. CiteULike is a good tool to collect references
        when browsing with the iPad. CiteULike doesn\u2019t allow offline reading
        of PDF files. While you can read the HTML versions of papers with the iPad
        web browser, this requires not only online access, but often also access through
        a paywall.<br><a href=\"https://web.archive.org/web/20101016090748/http://www.citeulike.org/\">More
        Info</a></p><h3 id=\"papers-for-ipad\">Papers for iPad</h3><p>This was the
        first reference manager specifically designed for the iPad. Papers for Mac
        owners can synchronize all their references and fulltext PDF files. The functionality
        is similar to the Mac version and also includes a good PDF reader and searching
        for references in PubMed and other online databases. This makes Papers a good
        stand-alone solution that doesn\u2019t depend on syncing to another applications.<br><a
        href=\"https://web.archive.org/web/20101016090748/http://mekentosj.com/papers/ipad/\">More
        Info</a> \u2013 <a href=\"https://web.archive.org/web/20101016090748/http://itunes.apple.com/app/papers/id304655618?mt=8\">iTunes</a></p><h3
        id=\"mendeley-lite\">Mendeley Lite</h3><p>Mendeley Lite syncs with all references
        you store in your Mendeley web account. I personally prefer this approach
        as I don\u2019t particularly like syncing between iPad and desktop computer.
        Just like Papers, this application works both on iPad and iPhone. You can\u2019t
        directly add references to Mendeley Lite. Mendeley is currently the only application
        that has both a web-based and an iPad version. This increases the options,
        but probably also adds to user confusion. Add reference with the web-based
        version, sync, then read PDF in Mendeley Lite?<br><a href=\"https://web.archive.org/web/20101016090748/http://itunes.apple.com/de/app/mendeley-reference-manager/id380669300?mt=8\">iTunes</a></p><h3
        id=\"sente-viewer-for-ipad\">Sente Viewer for iPad</h3><p>Last Friday <strong><strong>Sente
        Viewer for iPad</strong></strong> was released. Similar to Papers and Mendeley,
        Sente Viewer for iPad synchronizes with the desktop version of the application.
        The application allows browsing of all synchronized references and reading
        of the associated fulltext PDF papers. The <strong><strong>Sente for iPad</strong></strong>
        application will be released later and will also allow adding and editing
        of references. I\u2019m looking forward to \u201Ctargeted browsing\u201D which
        will capture both reference information and fulltext PDF files using a built-in
        web browser \u2013 another variation of reference manager integration with
        the web browser.<br><a href=\"https://web.archive.org/web/20101016090748/http://www.thirdstreetsoftware.com/site/iPadSente.html\">More
        Info</a> \u2013 <a href=\"https://web.archive.org/web/20101016090748/http://itunes.apple.com/us/app/sente-viewer/id392355663?mt=8\">iTunes</a></p><h3
        id=\"further-reading\">Further Reading</h3><p>Roderic Page has done <a href=\"https://web.archive.org/web/20101016090748/http://iphylo.blogspot.com/2010/09/viewing-scientific-articles-on-ipad.html\">a
        lot of writing</a> about reading scientific papers on the iPad, including
        reviews for <a href=\"https://web.archive.org/web/20101016090748/http://iphylo.blogspot.com/2010/08/viewing-scientific-articles-on-ipad_31.html\">Papers
        for iPad</a> and <a href=\"https://web.archive.org/web/20101016090748/http://iphylo.blogspot.com/2010/08/viewing-scientific-articles-on-ipad_3052.html\">Mendeley
        Lite</a>. Wizfolio is another web-based reference manager that <a href=\"https://web.archive.org/web/20101016090748/http://blog.wizfolio.com/index.php/2010/07/2-thumb-power-surfing-on-the-ipad/\">works
        on the iPad</a>.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Beyond the PDF \u2013 it is time for a workshop
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/beyond-the-pdf-it-is-time-for-a-workshop/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw7z</id>\n        <published>2010-10-06T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-19T07:52:45.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/3367901850_5b137da197.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/3367901850_5b137da197.jpeg\"></p><p>PDF
        has become the standard way we consume scientific papers, but in fact is not
        a good format for this purpose at all. Or as <a href=\"https://web.archive.org/web/20101124185433/http://www.mjrobbins.net/\">Martin
        Robbins</a> <a href=\"https://web.archive.org/web/20101124185433/http://blogs.nature.com/franknorman/2010/09/10/my-science-online-london-2010-impressions\">said
        at the recent Science Online London conference</a>: <em><em>PDF is an insult
        to science</em></em>. The problem was nicely illustrated by <a href=\"https://web.archive.org/web/20101124185433/http://wwmm.ch.cam.ac.uk/blogs/murrayrust/\">Duncan
        Hull</a>, using a quote from <a href=\"https://web.archive.org/web/20101124185433/http://wwmm.ch.cam.ac.uk/blogs/murrayrust/\">Peter
        Murray-Rust</a> from a <a href=\"https://web.archive.org/web/20101124185433/http://wwmm.ch.cam.ac.uk/blogs/murrayrust/?p=1069\">May
        2008</a> article:</p><p>There are of course ways journal publishers can add
        metadata to PDF files, e.g. using <a href=\"https://web.archive.org/web/20101124185433/http://blogs.plos.org/mfenner/2008/12/22/just_doi_it/\">XMP</a>
        markup. But that is only a workaround \u2013 what we really want is journal
        papers in a format that is all about document structure and not about looking
        good in print. XML is obviously that format with the <a href=\"https://web.archive.org/web/20101124185433/http://www.inera.com/nlmresources.shtml\">NLM-DTD</a>
        as the de facto standard for scholarly publications. Many journal publishers
        use that format internally, as does <a href=\"https://web.archive.org/web/20101124185433/http://www.ncbi.nlm.nih.gov/pmc/\">PubMed
        Central</a> for displaying full-text papers, as well as archiving projects
        such as <a href=\"https://web.archive.org/web/20101124185433/http://www.portico.org/digital-preservation/\">Portico</a>.</p><p>But
        there are two problems with how NLM-DTD is used now. The first problem is
        that most scientific papers still are ultimately read as printouts of PDF
        files, even though most journals now are online only. I wrote in January that
        this reading behavior is starting to change (<a href=\"https://blog.front-matter.io/posts/how_do_you_read_papers_2010_will_be_different/\">How
        do you read papers? 2010 will be different</a>), and new article formats \u2013
        such as the <a href=\"https://web.archive.org/web/20101124185433/http://blogs.plos.org/mfenner/2009/07/26/how_does_the_article_of_the_future_look_like/\">Article
        of the Future</a> by Cell Press \u2013 and the success of the iPad are two
        major reasons for that.</p><p>The second problem is that there are no good
        NLM-DTD tools for authors. <a href=\"https://blog.front-matter.io/posts/lemon8_xml_interview_with_mj_suhonos/\">Lemon8-XML</a>
        and the <a href=\"https://blog.front-matter.io/posts/interview_with_pablo_fernicola/\">Microsoft
        Word Article Authoring Add-In</a> are two examples that I have written about
        before. Publishers spend a significant amount of time and money (and using
        tools such as <a href=\"https://blog.front-matter.io/posts/extyles_interview_with_elizabeth_blake_and_bruce_rosenblum/\">eXtyles</a>)
        to convert submitted manuscripts from Microsoft Word, Open Office, or LaTeX
        formats into NLM-DTD. I wrote about my <a href=\"https://blog.front-matter.io/posts/my_paper_writing_dream_machine_1_0/\">paper
        writing dream machine</a> that would use the NLM-DTD more than two years ago.
        I still believe that the ideal authoring tool should be web-based, but in
        2010 this should be done in HTML5 and not Adobe Flash or Microsoft Silverlight.</p><p>The
        two problems are obviously related. When more people are reading papers in
        other formats than PDF and see the advantages, it changes the idea of a scientific
        paper that most people have from a static document do a document that is enriched
        with primary research data, visualizations that use 3D and video, links to
        related resources, the possibility to comment, and has more than one document
        version. In other words, what HTML and the WWW <a href=\"https://web.archive.org/web/20101124185433/http://www.w3.org/History/19921103-hypertext/hypertext/WWW/TheProject.html\">were
        invented for</a> by Tim Berners-Lee when working at CERN. At this point the
        incentives to create better authoring tools will be much greater, and the
        second problem should solve itself. And HTML and related technologies have
        now evolved to the point where they allow the building of some very attractive
        authoring tools.</p><p><a href=\"https://web.archive.org/web/20101124185433/http://www.sdsc.edu/~bourne/\">Phil
        Bourne</a> has written and talked a lot about this problem, including a recent
        editorial in <em><em>PLoS Computational Biology</em></em> (<a href=\"https://web.archive.org/web/20101124185433/http://dx.doi.org/10.1371/journal.pcbi.1000787\">What
        do I want from the publisher of the future?</a>) and a related <a href=\"https://web.archive.org/web/20101124185433/http://www.scivee.tv/node/18299\">SciVee
        video</a>. He has also been working very hard to organize the <strong><strong>Beyond
        the PDF</strong></strong> workshop, to be held in San Diego January 19-21.
        The workshop <a href=\"https://web.archive.org/web/20101124185433/https://sites.google.com/site/beyondthepdf/\">website</a>
        went live last week and is a very good source of information. The goal of
        the workshop is to identify a set of requirements and to start developing
        open source code that accelerates moving beyond PDF for scientific papers.</p><p>I
        will of course do everything possible to attend this workshop, but haven\u2019t
        yet secured funding for the trip. What I hope to contribute to the <strong><strong>Beyond
        the PDF</strong></strong> project is a more intelligent use of citations (the
        following was also posted to the Beyond the PDF <a href=\"https://web.archive.org/web/20101124185433/http://groups.google.com/group/beyond-the-pdf\">discussion
        group</a>):</p><h3 id=\"unique-author-identifiers\">Unique Author Identifiers</h3><p>Unique
        author identifiers such as <a href=\"https://www.orcid.org/\">ORCID</a> not
        only are a big help in knowledge discovery (finding other interesting papers,
        datasets, etc. by the same person), but they can also help to better define
        the contributions of a researcher to a particular paper. This could mean a
        general description of the contribution (had idea for project, collected data,
        helped write manuscript, etc.), or could also describe a very specific contribution
        (researcher X did experiment Y).</p><h3 id=\"citation-styles\">Citation styles</h3><p>We
        already have far too many citation styles, but the styles we use<br>have several
        important shortcomings. I suggest the following changes:</p><ul><li>Use the
        <a href=\"https://www.doi.org/\">DOI</a> instead of volume and page numbers
        whenever possible</li><li>Use <strong><strong>ORCID</strong></strong> to link
        to the authors of the citations</li><li>Use the Citation Typing Ontology (<a
        href=\"https://web.archive.org/web/20101124185433/http://www.crossref.org/CrossTech/2009/03/citation_typing_ontology.html\">CiTO</a>)
        to describe the meaning of the citation</li><li>Use a note field to explain
        why the citation was used</li></ul><p>Any authoring tool should obviously
        use the Citation Style Language (<a href=\"https://web.archive.org/web/20101124185433/http://blogs.plos.org/mfenner/2010/09/24/citation-style-language-an-interview-with-rintze-zelle-and-ian-mulvany/\">CSL</a>)
        to format citations. And the citations should be provided with a <a href=\"https://creativecommons.org/publicdomain/zero/1.0/\">CC
        Zero</a> or similar license to allow reuse.</p><h3 id=\"cited-by\">Cited by</h3><p>At
        least as important as the citations by a particular paper are the incoming
        citations, the works that cite a paper. We need much better mechanisms to
        automate these \u201Ctrackbacks\u201D, and this should go beyond other papers
        and also include datasets, blog posts, etc. The incoming citations are of
        course very helpful for discovery, and the basis for <a href=\"https://altmetrics.org/manifesto/\">alternative
        metrics</a>.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ ReaderMeter: researcher-level metrics based
        on readership ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/readermeter-researcher-level-metrics-based-on-readership/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw8g</id>\n        <published>2010-10-03T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-19T07:54:05.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>In a <a href=\"https://web.archive.org/web/20101016090754/http://www.academicproductivity.com/2010/readermeter-crowdsourcing-research-impact/\">blog
        post last week</a>, Dario Taraborelli officially announced <a href=\"https://web.archive.org/web/20101016090754/http://readermeter.org/\">ReaderMeter</a>.
        ReaderMeter takes the usage data from reference managers (starting with <a
        href=\"https://www.mendeley.com/\">Mendeley</a>) to analyze the impact of
        publications by a particular author.</p><p>ReaderMeter is a welcome addition
        to other metrics of researcher impact, most of which are citation-based. And
        ReaderMeter was hacked together in a few nights, so the service should improve
        over time. Dario mentions some of the current limitations in his blog post:</p><ul><li><strong><strong>Usage
        data only from Mendeley</strong></strong>. We don\u2019t know whether the
        reading patterns of users from other reference managers (e.g. CiteULike, Zotero,
        Endnote Web and Refworks) differ. Dario is working on adding more services.</li><li><strong><strong>Author
        disambiguation</strong></strong>. This is a critical component, and the <a
        href=\"https://blog.front-matter.io/posts/orcid-as-unique-author-identifier-what-is-it-good-for-and-should-we-worry-or-be-happy/\">ORCID</a>
        initiative is probably the best tool to overcome this limitation, especially
        when data from several reference managers have to be integrated.</li><li><strong><strong>Article
        disambiguation</strong></strong>. Multiple copies of the same reference are
        common in reference manager databases. The <a href=\"https://doi.org/\">DOI</a>
        can solve this problem for those publications that have a DOI, but consequent
        use of the DOI by journals, citation databases and reference managers has
        yet to become standard practice.</li></ul><p>ReaderMeter is visually pleasing
        and fun to use. And the data are also provided in JSON format, which allows
        integration into other web pages, e.g. the researcher\u2019s home page.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Advice for scientists who want to become
        Wikipedia editors ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/advice-for-scientists-who-want-to-become-wikipedia-editors/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw8h</id>\n        <published>2010-10-02T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-31T08:16:40.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>This week <em><em>PLoS Computational
        Biology</em></em> published another helpful editorial in their <a href=\"https://web.archive.org/web/20101016090759/http://www.ploscollections.org/article/browseIssue.action?issue=info%3Adoi%2F10.1371%2Fissue.pcol.v03.i01\">10
        Simple Rules</a> collection (https://doi.org/<a href=\"https://doi.org/10.1371/journal.pcbi.1000941\">10.1371/journal.pcbi.1000941</a>):
        <em>Ten Simple Rules for Editing Wikipedia. </em></p><p>I have very rarely
        edited Wikipedia articles myself, and I suspect this behavior is the rule
        and not the exception among science bloggers. And this always puzzled me,
        as editing Wikipedia articles should be a natural thing to do for those familiar
        with blogs and other online tools.</p><p>The editorial not only gives good
        advice for the beginning Wikipedia editor, there are many other places where
        you can also find this information. But the editorial is written with the
        scientist as Wikipedia editor in mind and clarifies some of the issues that
        can arise.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Why can\u2019t I reuse these tables and
        figures? ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/why-cant-i-reuse-these-tables-and-figures/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw60</id>\n        <published>2010-09-30T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T13:46:58.000+00:00</updated>\n\t\t<category
        term=\"Chart\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/bmccancer-e1285879074865--1-.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/bmccancer-e1285879074865--1-.jpeg\"></p><p>Tables
        and figures contain the data of a scientific paper in condensed (and often
        visually appealing) form. This is why they are among the first thing we look
        at, and why they are often reused when we discuss the paper in a presentation
        or blog post.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/ppat.v06.i08.jpg\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"PLoS Pathogens\" width=\"251\"
        height=\"251\"><figcaption><em><em>From </em>https://doi.org/<em><a href=\"https://web.archive.org/web/20120525130956/http://dx.doi.org/10.1371/journal.ppat.1001042\">10.1371/journal.ppat.1001042</a>.
        Image credit: Thomas J. Hannan, Washington University.</em></em></figcaption></figure><p>Electronic
        publication has dramatically simplified the reuse of tables and figures, and
        therefore reuse has become very common \u2013 you probably find reused material
        in most presentations given in academic institutions or at conferences.</p><p>Most
        authors will probably be happy that their results are disseminated, and reuse
        is likely to lead to more people reading the full paper and citing the work.</p><p>But
        this reuse has two problems. The first problem is copyright. Many journals
        own the copyright of the papers they publish and don\u2019t allow reuse without
        prior permission. Unfortunately, copyright is a complicated issue, and also
        differs between countries. Most researchers assume \u201C<a href=\"https://web.archive.org/web/20120525130956/http://www.copyright.gov/fls/fl102.html\">Fair
        use</a>\u201C when they reuse material, but this might not apply to all situations,
        e.g. presentations at conferences. And many researchers don\u2019t understand
        that they have often given away the copyright to their own works so that they
        can\u2019t show a figure from one of their papers without permission.</p><p>Many
        publishers have automated the process of obtaining permissions for copyrighted
        work, e.g. using the <a href=\"http://www.copyright.com/viewPage.do?pageCode=pu4-n\">Rightslink</a>
        system of the Copyright Clearance Center. But it still requires a considerable
        investment in time (and often money) to obtain all permissions, especially
        since these are usually one-time permissions only. This combination of unawareness
        of the details of copyright law and the required extra work means that many
        researchers probably don\u2019t obtain permission prior to reuse.</p><p>The
        solution to the copyright problems is obviously to use material with a <a
        href=\"https://creativecommons.org/\">Creative Commons</a> license whenever
        possible, as I have done in this blog post. And most Open Access papers are
        published under this license, so there is plenty of material to choose from.</p><p>But
        there is also a second problem with reusing tables and figures. They were
        designed to be part of a paper and often look terrible in a presentation,
        particularly tables.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/plosone-e1285879245843.png\"
        class=\"kg-image\" alt loading=\"lazy\" title=\"plosone\" width=\"500\" height=\"402\"><figcaption><em><em>From
        </em>https://doi.org/</em><a href=\"https://web.archive.org/web/20120525130956/http://dx.doi.org/10.1371/journal.pone.0006022\"><em><em>10.1371/journal.pone.0006022</em></em></a>.</figcaption></figure><p>The
        solution to this problem is to provide the data behind the table or figure,
        so that the information can be displayed in a way that makes sense in a presentation.
        Here we usually have to reduce the amount of information, but it could also
        mean that we remix the content with other sources. The Creative Commons licenses
        discussed above are<a href=\"http://pantonprinciples.org/\"> not appropriate</a>
        for data. Whenever possible, scientific data should be placed in the public
        domain.</p><p>It is important to distinguish the publication of table and
        figure data from the publication of the <a href=\"https://web.archive.org/web/20120525130956/http://blogs.openaccesscentral.com/blogs/bmcblog/entry/bmc_research_notes_wants_your\">whole
        research dataset</a>. The open questions with the latter (e.g. standard data
        formats, appropriate repositories, archiving) don\u2019t apply to the former.
        This means that publishers could start providing these data immediately. I\u2019m
        confident that they would see an increase in paper downloads and citations.
        But more importantly, I hope this would lead to better presentations in seminars
        and at conferences.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Paper retractions do not induce citation
        mutations ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/paper-retractions-do-not-induce-citation-mutations/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw5z</id>\n        <published>2010-09-26T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-31T08:15:49.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Dear Christian Specht,</p><p>Thank
        you very much for <a href=\"https://web.archive.org/web/20120525055229/http://www.the-scientist.com/news/display/57698/\">your
        detailed response</a> in <em><em>The Scientist</em></em> to <a href=\"https://web.archive.org/web/20120525055229/http://blogs.plos.org/mfenner/2010/09/20/letter-to-the-scientist/\">our
        previous letter</a> regarding citation mutations. You clarified several issues
        that were raised in <a href=\"https://web.archive.org/web/20120525055229/http://www.the-scientist.com/news/display/57689/\">your
        original study</a>, particularly that citation mutation rates have dropped
        significantly in the last 10 years (probably due to the more widespread use
        of reference management software), and that some citation mutations (e.g.
        680\u2192685 in Laemmli 1970) might be introduced not by citing authors, but
        by the citation database.</p><p>You rightfully point out that citation mutations
        indicate a much bigger problem: <em><em>authors often do not read the publications
        cited in their work</em></em>. I am not aware of any available direct data,
        but in an ongoing study Richard Grant is looking at this question (<a href=\"https://web.archive.org/web/20120525055229/http://blog.the-scientist.com/2010/09/23/mutatis-citandi/\">Do
        you read the papers you cite?</a>). The preliminary data that Richard kindly
        made available indicate that more than 85% of authors indeed read the papers
        they cite.</p><p>In another study made aware to us by <a href=\"https://web.archive.org/web/20120525055229/http://twitter.com/noahWG/status/25410352261\">Noah
        Gray</a>, Neale et al. (Neale 2009) used an elegant experimental design to
        address the same question. They studied lethal acquired mutations \u2013 retracted
        papers that in theory should no longer be cited \u2013 as an estimate of how
        diligent authors were reading the papers they cite.</p><p>The authors compared
        the number of citations of 102 retracted papers (starting 12 months after
        the retraction) to a control group of papers and found no difference in the
        average number of citations (26 vs. 27). Content analysis of a subset of citing
        papers indicated that more than 50% of citations used the retracted paper
        to support their own findings and less than 5% of citing papers mentioned
        the retraction.</p><p>These findings not only seem to contradict the preliminary
        findings by Richard Grant, but also indicate that journal publishers and citation
        databases may not be properly communicating paper retractions.</p><h3 id=\"references\">References</h3><p><strong><strong>Laemmli
        UK</strong></strong>. Cleavage of Structural Proteins during the Assembly
        of the Head of Bacteriophage T4. <em><em>Nature</em></em>. 1970;227:680-685.
        https://doi.org/<a href=\"https://web.archive.org/web/20120525055229/http://dx.doi.org/10.1038/227680a0\">10.1038/227680a0</a></p><p><strong><strong>Neale
        AVV, Dailey RK, Abrams J</strong></strong>. Analysis of citations to biomedical
        articles affected by scientific misconduct. <em><em>Science and Engineering
        Ethics</em></em>. 2010;16(2):251-261. https://doi.org/<a href=\"https://web.archive.org/web/20120525055229/http://dx.doi.org/10.1007/s11948-009-9151-4\">10.1007/s11948-009-9151-4</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Citation Style Language: Interview with
        Rintze Zelle and Ian Mulvany ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/citation-style-language-an-interview-with-rintze-zelle-and-ian-mulvany/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw5y</id>\n        <published>2010-09-24T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-14T15:12:11.000+00:00</updated>\n\t\t<category
        term=\"Interview\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Citation
        styles are one of the greater mysteries for the novice manuscript writer.
        There are numerous ways that authors, title, journal, etc. can be arranged
        and formatted (see examples below), and in bibliographies citations can be
        ordered either alphabetically or by order of appearance in the text.</p><p><strong><strong>Laemmli
        UK</strong></strong>. Cleavage of Structural Proteins during the Assembly
        of the Head of Bacteriophage T4. <em><em>Nature</em></em>. 1970;227:680-685.</p><p><strong><strong>U.
        K. Laemmli</strong></strong> (1970). \u2018Cleavage of Structural Proteins
        during the Assembly of the Head of Bacteriophage T4\u2032. <em><em>Nature</em></em>
        <strong><strong>227</strong></strong>(5259):680-685.</p><p><strong><strong>U.
        K. Laemmli</strong></strong>, <em><em>Nature </em></em><strong><strong>227</strong></strong>,
        680 (1970).</p><p>Because of this complexity, it has long become impractical
        to format citations manually, and formatting of citations and bibliographies
        is one of the main reasons for using reference management software. I interviewed
        Rintze Zelle (scientist and open source contributor) and Ian Mulvany (vice
        president of new product development at Mendeley) to better understand citation
        styles in general and the open source Citation Style Language (CSL) in particular.
        CSL co-developers Bruce D\u2019Arcus and Frank Bennett provided important
        feedback.</p><h3 id=\"1-what-is-the-citation-style-language\"><strong><strong>1.
        What is the Citation Style Language?</strong></strong></h3><p>Rintze Zelle:
        Scientific literature depends heavily on proper referencing. However, when
        writing a manuscript, manually editing citations and bibliographies is time
        consuming and error prone. Citation styles also differ between scientific
        journals, so authors often have to switch citation styles when they submit
        their manuscript to a different journal than originally anticipated.</p><p>The
        <a href=\"https://web.archive.org/web/20120525124720/http://citationstyles.org/\">Citation
        Style Language</a> (CSL) is an open XML based language meant to automate the
        formatting of citations and bibliographies. When provided with the metadata
        (title, year, authors, etc.) of the cited items (journal articles, books,
        etc.), and a CSL style, a CSL processor can automatically generate the bibliography
        and in-text citations. CSL is currently used by <a href=\"https://web.archive.org/web/20120525124720/http://www.zotero.org/\">Zotero</a>
        and <a href=\"https://web.archive.org/web/20120525124720/http://www.mendeley.com/\">Mendeley</a>,
        and both programs offer word processor plug-ins for <a href=\"https://web.archive.org/web/20120525124720/http://office.microsoft.com/en-us/word/\">Microsoft
        Word</a> and <a href=\"https://web.archive.org/web/20120525124720/http://www.openoffice.org/\">OpenOffice.org</a>.
        Several other projects are working on or exploring CSL support.</p><h3 id=\"2-do-we-really-need-hundreds-of-citation-styles\">2.
        Do we really need hundreds of citation styles?</h3><p><strong><strong>Rintze
        Zelle</strong></strong>: We have asked ourselves this question many times
        over. Some variability is certainly warranted: numeric, author-date and footnote
        styles are very different, and each type has its own advantages and disadvantages.
        However, small variations in citation styles result in a situation where almost
        every journal or publisher has its unique style. We think that even with the
        use of automated tools like CSL, reducing the number of citation styles in
        use could result in significant cost and time savings in scientific publishing.
        But this is a problem beyond the scope of CSL, so our goal is simply to support
        all the variability that currently exists in citation styles.</p><p><strong><strong>Ian
        Mulvany</strong></strong>: After working for many years at Springer, and then
        Nature, I was well aware that most large publishers just push submitted manuscripts
        out to companies in India where the formatting of the paper happens. The input
        format and citation formatting really doesn\u2019t matter to most publishers.
        They just tear the submitted manuscript to pieces and rebuild it in their
        chosen XML schema.</p><p>However, most people using citations are not actually
        submitting manuscripts for publication, but rather are writing term papers,
        or theses, or reports. So the weird thing is that citations started off as
        a required identifier for the literature. Google Scholar and HTTP URIs such
        as the DOI have almost totally made formatted citations redundant as identifiers,
        and yet there is still a huge user need to be able to format citations according
        to a huge variety of styles, and since that need is going to continue for
        quite a long time, it\u2019s a need that we have to support.</p><h3 id=\"3-what-is-the-difference-between-csl-and-other-citation-style-systems\"><strong><strong>3.
        What is the difference between CSL and other citation style systems?</strong></strong></h3><p>Rintze
        Zelle: Our main \u201Ccompetition\u201D arguably comes from <a href=\"https://web.archive.org/web/20120525124720/http://www.bibtex.org/\">BibTeX</a>
        and <a href=\"https://web.archive.org/web/20120525124720/http://www.endnote.com/\">EndNote</a>/<a
        href=\"https://web.archive.org/web/20120525124720/http://www.refman.com/\">Reference
        Manager</a>. BibTeX is a popular choice for those working with the <a href=\"https://web.archive.org/web/20120525124720/http://www.latex-project.org/\">LaTeX</a>
        typesetting system, but the user base of LaTeX is relatively small and mostly
        limited to the sciences. EndNote and Reference Manager are commercial tools
        offered by Thomson Reuters. While large collections of citation styles are
        available for each program, the use of these styles is limited to licensed
        users.</p><p>CSL was designed with three main goals:</p><ol><li>to create
        an open system that is independent of the operating system, application or
        document format,</li><li>to cover the full range of citation formatting rules
        in use, extending from the sciences to fields in the humanities as well as
        law,</li><li>to free end users from the complex task of formatting citations.</li></ol><p>Citation
        styles should be freely available, up to date, and complete. Switching between
        styles should be easy, and citation output should automatically localize to
        the desired language.</p><p>We think we\u2019ve come quite far toward reaching
        these goals with our most recent release, CSL 1.0. The <a href=\"https://web.archive.org/web/20120525124720/http://citationstyles.org/downloads/specification.html\">CSL
        1.0 specification</a> covers a wide range of citation rules, and offers advanced
        features like automatic localization of date formats, terms and punctuation,
        support for in-field rich text and extensive support for the rendering and
        disambiguation of names. The first standalone CSL 1.0 processor (the JavaScript
        <a href=\"https://web.archive.org/web/20120525124720/http://bitbucket.org/fbennett/citeproc-js/\">citeproc-js</a>)
        is currently being integrated into both Zotero and Mendeley, and is receiving
        attention for deployment on both the client and the server.</p><h3 id=\"4-can-you-tell-me-how-csl-was-developed\">4.
        Can you tell me how CSL was developed?</h3><p><strong><strong>Rintze Zelle</strong></strong>:
        CSL is the brainchild of Bruce D\u2019Arcus, an associate professor of Geography
        at Miami University of Ohio. The language was initially implemented for integration
        into OpenOffice.org, but only became popular in 2006 when Zotero, the first
        reference manager to use CSL, was released. In these early days major contributions
        were made to CSL by Zotero developer Simon Kornblith. Subsequently, the Zotero
        project successfully fostered an active user community, with many users contributing
        styles to a growing repository of CSL styles.</p><p>The year 2008 was a watershed
        of new developments. Mendeley was released, the second reference manager to
        use CSL for its citation formatting. Andrea Rossato released the first standalone
        CSL processor (<a href=\"https://web.archive.org/web/20120525124720/http://code.haskell.org/citeproc-hs/\">citeproc-hs</a>)
        for use with the <a href=\"https://web.archive.org/web/20120525124720/http://johnmacfarlane.net/pandoc/\">Pandoc</a>
        text processing system. Also in 2008, two Zotero users who enjoyed the program
        but felt that CSL could be further improved joined Bruce in CSL development:
        myself, at that time a PhD researcher in biotechnology at Delft University
        of Technology in the Netherlands, and Frank Bennett, Jr., an associate law
        professor at Nagoya University in Japan. Together with Andrea, our different
        academic and geographic backgrounds proved very useful in CSL development.
        In preparation for major backward-incompatible changes, CSL 0.8 was released
        in 2009, and in Spring 2010 CSL 1.0 saw the light of day. The <a href=\"https://web.archive.org/web/20120525124720/http://citationstyles.org/2010/03/22/citation-style-language-1-0/\">1.0
        release</a> was accompanied by a move to a new website at <a href=\"https://web.archive.org/web/20120525124720/http://citationstyles.org/\">citationstyles.org</a>,
        and included improved documentation in the form of a full language specification.
        CSL development has now calmed down a bit as we await the integration of CSL
        1.0 by Zotero and Mendeley.</p><p><strong><strong>Ian Mulvany</strong></strong>:
        We at Mendeley have been using the Citation Style Language for quite a while
        now. We think it is an amazing project and we are very strongly committed
        to working with the CSL community in encouraging uptake. We get a lot of feedback
        from our users and one area that they constantly run into problems with is
        the need to be able to format a citation in just such a manner. The CSL project
        is the best way for us to be able to support the needs of our users with these
        kinds of requests. Our developers have been pushing patches upstream to the
        <a href=\"https://web.archive.org/web/20120525124720/http://bitbucket.org/fbennett/citeproc-js/wiki/Home\">citeproc-js</a>
        project, particularly <a href=\"https://web.archive.org/web/20120525124720/http://www.mendeley.com/profiles/carles-pina/\">Carles
        Pina</a>.</p><p>We have added a cut and paste stylebox on our article pages.
        If you have a look at a <a href=\"https://web.archive.org/web/20120525124720/http://www.mendeley.com/research/karhunenloeve-eigenvalue-problems-cosmology-we-tackle-large-data-sets/\">sample
        paper</a> you will now see a little citeproc-js driven \u201CCite this document\u201D
        box that lets you copy and paste formatted citations in several popular citation
        styles. We have also been supporting the creation of a <a href=\"https://web.archive.org/web/20120525124720/http://bitbucket.org/csledit/csl-wysiwyg-editor\">WISYWIG
        citation style editor</a>. The status of the project is that most of the code
        is complete and we just need to work on getting it integrated into our client,
        and figuring out the best way to manage the creation of more styles, and how
        that will work with the CSL community.</p><p>One of the things that we have
        been discussing with Bruce D\u2019Arcus is how to manage the redistribution
        of new styles, and how to make sure that corrupt styles don\u2019t propagate,
        and that people get the style that they are looking for. If people want to
        contribute there is a lot of activity on the <a href=\"https://web.archive.org/web/20120525124720/https://lists.sourceforge.net/lists/listinfo/xbiblio-devel\">mailing
        list</a> of the CSL project. One thing we think we hope Mendeley can help
        with is reporting usage statistics on specific style files, so at least people
        can find the most popular version of a CSL file for a given style.</p><h3
        id=\"5-where-can-a-user-find-more-csl-citation-styles-is-it-easy-to-modify-a-csl-style\">5.
        Where can a user find (more) CSL citation styles? Is it easy to modify a CSL
        style?</h3><p><strong><strong>Rintze Zelle</strong></strong>: While anyone
        is free to write and host their own CSL styles, most CSL styles that are in
        use are available through the <a href=\"https://web.archive.org/web/20120525124720/http://www.zotero.org/styles\">Zotero
        Style Repository</a> (many of these styles are licensed under a <a href=\"https://web.archive.org/web/20120525124720/http://creativecommons.org/licenses/by-sa/3.0/\">Creative
        Commons license</a>). We have to admit that editing CSL styles currently requires
        some technical skill and knowledge of XML. This hasn\u2019t kept members of
        the Zotero user community from creating over a thousand CSL styles, but we
        do recognize that user friendly editing of styles is a very important feature.
        We therefore applaud Mendeley\u2019s effort to create an online CSL editor.</p><h3
        id=\"6-should-publishers-care-about-csl\">6. Should publishers care about
        CSL?</h3><p><strong><strong>Ian Mulvany</strong></strong>: As I pointed out
        the big publishers don\u2019t care about the submission format, but they have
        not really done a good job of communicating that to their editorial boards.
        Smaller publishers don\u2019t have the resources to totally reformat submissions,
        and beyond academic publishing there are a huge number of people who just
        need to format citations. There is a huge waste of people\u2019s time in reformatting
        papers for submissions, in fixing styles according to changing requirements
        from departments, when what should matter is the content. I\u2019d love to
        get to a point where every publisher accepted the same type of XML input,
        and our authoring tools all created content conforming to that input format.
        Citations should be a DOI or other HTTP URI that can be rendered into the
        appropriate format using CSL and an API.</p><p><em><em>Martin Fenner: The
        Open Access publishers BioMed Central and PLoS plan to add a CSL style download
        link to their author instruction pages. I hope that more publishers follow
        this example.</em></em></p><h3 id=\"7-do-you-want-to-talk-about-future-plans-for-csl\">7.
        Do you want to talk about future plans for CSL?</h3><p><strong><strong>Rintze
        Zelle</strong></strong>: We\u2019re very excited about the work Zotero and
        Mendeley developers are doing to update their programs to support CSL 1.0.
        The update path should be relatively smooth for users as styles can be automatically
        updated to the CSL 1.0 format, although styles will often need to be edited
        to take full advantage of all the new features. Zotero Everywhere <a href=\"https://web.archive.org/web/20120525124720/http://www.zotero.org/blog/zoteros-next-big-step/\">was
        announced</a> earlier this week and will include a web citation formatting
        service based on citeproc-js.</p><p>There are two things we consider crucial
        to the further development of CSL: one, we still lack an easy way for users
        to modify existing styles, although we\u2019re hopeful that <a href=\"https://web.archive.org/web/20120525124720/http://bitbucket.org/csledit/csl-wysiwyg-editor/\">Mendeley\u2019s
        CSL editor</a> will soon fill this gap. Secondly, we feel there is a need
        for a more full-featured online style repository which allows users to find
        their style of choice, to add comments, and to propose style changes.</p><p>The
        goal of CSL is to make citing formatting easier at a general level, across
        all fields and in all languages. This can only be achieved through a collaborative
        endeavor, and here we think publishers also share some responsibility. By
        providing high quality item metadata through robust standards (like <a href=\"https://web.archive.org/web/20120525124720/http://unapi.info/\">unAPI</a>
        or <a href=\"https://web.archive.org/web/20120525124720/http://ocoins.info/\">COinS</a>),
        by freely providing clear, correct and complete style guidelines or opting
        for a standard citation style (like APA, Chicago or <a href=\"https://web.archive.org/web/20120525124720/http://www.mhra.org.uk/Publications/Books/StyleGuide/download.shtml\">MHRA</a>),
        and perhaps even by creating and hosting their own CSL styles, publishers
        can make our work, and that of authors, so much easier.</p><p>With broad participation
        and support, we believe that CSL can benefit all fields of scholarship in
        a similar way Oren Patashnik\u2019s BibTeX helped the sciences, by (further)
        streamlining the publication process, improving access to metadata of materials
        of all kinds, and by allowing scholars to spend more of their time on the
        core of their research.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Zotero soon is Everywhere ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/zotero-soon-is-everywhere/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw5x</id>\n
        \       <published>2010-09-22T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T07:50:25.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Whereas most reference managers
        are either standalone applications and/or web-based, Zotero works as a Firefox
        plugin. This approach has many advantages, but is not for everybody. So today
        Zotero announced <a href=\"https://web.archive.org/web/20120603054912/http://www.zotero.org/blog/zoteros-next-big-step/\">Zotero
        Everywhere</a>:</p><ul><li>A browser pluging for Microsoft Internet Explorer,
        Apple Safari and Google Chrome, and standalone desktop version for Windows,
        Mac and Linux</li><li>An expanded Zotero web API that gives developers full
        read and write access to all of Zotero\u2019s features.</li></ul><p>Zotero
        Everywhere goes beyond allowing users to use Zotero with other browsers. The
        enhanced API will give developers the chance to build an infrastructure around
        Zotero, from mobile applications to integration with other services. No dates
        were given about the availability of Zotero Everywhere. The project is funded
        by the Andrew W. Mellon Foundation.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Letter to The Scientist ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/letter-to-the-scientist/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw5w</id>\n
        \       <published>2010-09-20T00:00:00.000+00:00</published>\n\t\t<updated>2023-07-05T18:06:18.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Dear Scientist,</p><p>last
        week you published an interesting article by <strong><strong>Christian Specht</strong></strong>
        about <a href=\"https://web.archive.org/web/20120525054056/http://www.the-scientist.com/news/display/57689/\">Mutations
        of citations</a>. Dr. Specht found more than 600 wrong citations for the paper
        by Laemmli (Laemmli 1970), which has been cited at least 88633 times according
        to Scopus.</p><p><strong><strong>Laemmli UK</strong></strong>. Cleavage of
        Structural Proteins during the Assembly of the Head of Bacteriophage T4. <em><em>Nature</em></em>.
        1970;227:680-685. https://doi.org/<a href=\"https://web.archive.org/web/20120525054056/http://dx.doi.org/10.1038/227680a0\">10.1038/227680a0</a></p><p>I
        was intrigued by the \u201Csequence alignment\u201D in Fig. 1a which clearly
        demonstrated that point mutations at 2<strong><strong>2</strong></strong>7
        and 68<strong><strong>0</strong></strong> are particularly common, and that
        some mutations are inherited between overlapping groups of scientists. Of
        particular interest is the \u201Ccomplete nonsense mutation\u201D that attributes
        the citation to the journal <em><em>Science</em></em>.</p><p>However, the
        author failed to demonstrate whether the citation mutations had a paper-not-found
        phenotype or whether they were simply silent mutations. Missing is also an
        analysis of whether the mutations</p><ul><li>originated with the paper authors
        (who by now should all be using reference managers that automatically import
        citations),</li><li>were introduced by the publisher during manuscript production
        (many journals use tools such as <a href=\"https://web.archive.org/web/20120525054056/http://blogs.nature.com/mfenner/2009/05/01/extyles-interview-with-elizabeth-blake-and-bruce-rosenblum\">eXtyles</a>
        to check and fix citations in manuscripts), or</li><li>first appeared in the
        scientific databases that stored the citations (Specht used Web of Science).</li></ul><p>Of
        particular interest would be whether there is a decrease in mutation rate
        over time, as automated tools have increased the fidelity of the citation
        process, and whether any citation style was particularly prone to mutations
        (no citation style uses checksums). As a researcher I suggest that the burden
        of proofreading should rest not with paper authors, and that journal and database
        publishers invest in appropriate citation repair mechanisms. And please use
        the DOI, even the paper by Laemmli (Laemmli 1970) has one.</p><h3 id=\"references\">References</h3><p>Laemmli
        UK. Cleavage of Structural Proteins during the Assembly of the Head of Bacteriophage
        T4. <em>Nature</em>. 1970;227(5259):680-685. doi:<a href=\"https://doi.org/10.1038/227680a0\">10.1038/227680a0</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Update of Reference Manager Overview Chart
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/update-of-reference-manager-overview-chart/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw5v</id>\n        <published>2010-09-19T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T07:49:17.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>In <a href=\"https://web.archive.org/web/20120603140937/http://blogs.nature.com/mfenner/2009/03/15/reference-manager-overview\">March
        2009</a> I posted an overview chart of how popular reference managers have
        implemented some important features. I\u2019ve since updated this chart several
        times, and the chart probably has outgrown the format of a blog post. For
        that reason I now made the chart available</p><ul><li>on a dedicated page
        with an easy to remember URL (<a href=\"https://web.archive.org/web/20120603140937/http://bit.ly/refman\">http://bit.ly/refman</a>),</li><li>as
        PDF file for downloading and printing,</li><li>under a <a href=\"https://web.archive.org/web/20120603140937/http://creativecommons.org/licenses/by/3.0/\">Creative
        Commons Attribution</a> license (like all content here on PLoS Blogs) for
        redistribution and reuse.</li></ul> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ And who are you? ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/and-who-are-you/\" />\n\t\t<id>https://doi.org/10.53731/bph94jk-kxvr00s</id>\n
        \       <published>2010-09-17T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-21T09:37:45.000+00:00</updated>\n
        \       <media:content url=\"https://blog.front-matter.io/content/images/2022/08/1_SiDVkJPVQr-ANEozSzF4ag-1.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/1_SiDVkJPVQr-ANEozSzF4ag-1.jpeg\"></p><p>Dear
        reader,</p><p>two weeks ago I moved this blog from <a href=\"https://web.archive.org/web/20120525131414/http://blogs.nature.com/mfenner\">Nature
        Network</a> to <strong><strong>PLoS Blogs</strong></strong>. I hope that most
        of my old readers have followed me here, and that I might even have a few
        new readers.</p><p><a href=\"https://www.nationalgeographic.com/science/article/not-exactly-rocket-science-blog-ends\">Ed
        Yong</a> recently <a href=\"https://web.archive.org/web/20120525131414/http://www.onemanandhisblog.com/archives/2010/09/science_online_bloggers_commenters_and_t.html\">talked
        about how he interacts with his many, many blog readers</a>. One important
        strategy he uses is to ask his readers for feedback in regular intervals \u2013
        he calls it delurking. AJ Cann has picked up the idea, and <a href=\"https://web.archive.org/web/20120525131414/http://www.microbiologybytes.com/blog/2010/09/15/you-like/\">on
        Wednesday asked the readers of his blog MicrobiologyBytes</a> a few questions.
        I like them and have blatantly reused most of them:</p><ul><li>Who are you
        and what\u2019s your background?</li><li>How long have you been reading Gobbledygook?</li><li>Where
        do you read Gobbledygook \u2013 website or RSS?</li><li>What do you like best
        about Gobbledygook?</li><li>How could I make Gobbledygook better for you?</li></ul><p>It
        would be kind if you could provide some feedback in the comments section below.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Starting a reading list for Gobbledygook
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/starting-a-reading-list-for-goobledygook/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw5s</id>\n        <published>2010-09-16T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T13:48:52.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/1252522330_78b53d7e16.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/1252522330_78b53d7e16.jpeg\"></p><p>All
        science bloggers do a lot of reading for background information, or write
        blog posts based on a (newly published) paper, blog post or news item. So
        I thought that it would be a good idea to collect those references in a single
        place.</p><p>Reading lists are perfect for this, and they are easy to create
        and maintain with web-based reference managers. Reading lists are used in
        teaching, e.g. to provide a list of required reading material for a class.
        But I can also see a number of benefits for science blogs:</p><ul><li>they
        help the blogger to organize his background material for writing</li><li>they
        help the reader find and keep referenced material</li><li>they can provide
        additional reading not mentioned in the blog post</li></ul><p>There are several
        good tools for reading lists. I decided to use <a href=\"https://web.archive.org/web/20120604134625/http://www.citeulike.org/\">CiteULike</a>,
        because what I really want here is a social bookmarking tool that understands
        references. My Goobledygook reading list is <a href=\"https://web.archive.org/web/20120604134625/http://www.citeulike.org/group/13987/library\">here</a>,
        the RSS feed is <a href=\"https://web.archive.org/web/20120604134625/http://www.citeulike.org/rss/group/13987/library\">here</a>,
        and the most recent items in the reading list are also shown in a new sidebar
        to the right. I started with references to papers, but plan to also include
        blog posts and other web resources.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Peer Review at the Scholarly Kitchen ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/peer-review-at-the-scholarly-kitchen/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw5r</id>\n        <published>2010-09-14T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-31T08:07:05.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p><a href=\"https://web.archive.org/web/20120525093945/http://scholarlykitchen.sspnet.org/\">The
        Scholarly Kitchen</a> is a group blog started by the <a href=\"https://web.archive.org/web/20120525093945/http://www.sspnet.org/\">Society
        for Scholarly Publishing</a> in 2008. The blog posts by authors Kent Anderson,
        Phil Davis, David Crotty, Michael Clarke, etc. are an always interesting \u2013
        and often thought-provoking \u2013 read about scholarly publishing. Two recent
        posts looked at peer review.</p><p><a href=\"https://web.archive.org/web/20120525093945/http://scholarlykitchen.sspnet.org/2010/08/31/the-burden-of-peer-review/\">The
        \u201CBurden\u201D of Peer Review</a><br>In this blog post <strong><strong>David
        Crotty</strong></strong> argues that we overestimate the amount of time the
        typical researcher spends doing peer review. In his informal survey most researchers
        review 1-3 papers per month, and those reviewing many more often do so voluntarily
        (e.g. because they sit on an editorial board). I haven\u2019t yet checked
        whether there are any formal surveys on the workload of peer review.</p><p><a
        href=\"https://web.archive.org/web/20120525093945/http://scholarlykitchen.sspnet.org/2010/09/10/post-publication-review-when-the-dialog-of-science-has-become-a-monologue/\">Post-publication
        Review: Is the Dialog of Science Really a Monologue?</a><br>In August the
        BMJ <a href=\"https://web.archive.org/web/20120525093945/http://dx.doi.org/10.1136/bmj.c3926\">published
        a paper</a> that looked at the adequacy of author replies to electronic letters
        to the editor. The cohort study found that authors are reluctant to respond
        to criticism to their work. In a <a href=\"https://web.archive.org/web/20120525093945/http://dx.doi.org/10.1136/bmj.c3803\">companion
        editorial</a>, David Schriger and Douglas Altman write about the possible
        reasons for this inadequate uptake of post-publication peer review, and that
        we need a change in culture to value public discussion<em><em><em><em><em><em>.
        </em></em></em></em></em></em><strong><strong>Philip David</strong></strong>
        summarized the two papers and concluded that <em><em>post-publication review
        may continue to be spotty and unreliable</em></em>.</p><p>I would disagree
        with Philip Davis about the conclusions that can be drawn from the cohort
        study. We all know that many papers receive few if any online comments. But
        we should rather think about where we could be 3-5 years from now, and how
        to get there. A recent editorial by Thomas Liesegang in the <em><em>Journal
        of Ophtalmology </em></em>is very relevant to this discussion (<a href=\"https://web.archive.org/web/20120525093945/http://dx.doi.org/10.1016/j.ajo.2009.11.015\">Peer
        review should continue after publication</a>, link via <a href=\"https://web.archive.org/web/20120525093945/http://ese-bookshelf.blogspot.com/2010/09/b-peer-review-should-continue-after.html\">EASE
        Journal Blog</a>). And Richard Smith gives a wonderful and much broader definition
        of post-publication peer review in a <a href=\"https://web.archive.org/web/20120525093945/http://www.bmj.com/content/341/bmj.c3803.full/reply#bmj_el_240798\">response</a>
        to the BMJ editorial:</p><blockquote>I would define post-publication review
        as the process whereby scientists and others decide whether a piece of work
        matters or not. I suggest that this doesn\u2019t happen much through debate
        in the correspondence pages of journals, but rather through scientists and
        other consumers of research recommending others to pay attention to a piece
        of research, conducting other studies off the back of it, absorbing it into
        systematic reviews, beginning to act on its conclusions, throwing it in the
        bin, and taking a thousand other actions that constitute the \u201Cmarket
        of ideas.\u201D</blockquote> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Data is the new soil ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/data-is-the-new-soil/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw5q</id>\n
        \       <published>2010-09-13T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-01T06:27:19.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>One of the
        main themes at the <a href=\"https://web.archive.org/web/20120525101008/http://www.scienceonlinelondon.org/programme.php\">Science
        Online London Conference</a> last weekend was <strong><strong>data</strong></strong>,
        with several sessions devoted to publishing primary research data, connecting
        scientific data from various resources, and a scientific experiment taking
        place before and during the conference (<a href=\"https://web.archive.org/web/20120525101008/http://scienceonlinelondon.wikidot.com/topics:green-chain-reaction\">Green
        Chain reaction</a>).</p><p><a href=\"https://web.archive.org/web/20120525101008/http://www.informationisbeautiful.net/visualizations/\">David
        McCandless</a> talked about Data Visualization, a fascinating way to filter
        and make sense of the enormous amounts of data that we produce. This is of
        course also very relevant to science. Those that couldn\u2019t attend the
        conference, or were in one of the parallel sessions like myself (<a href=\"https://web.archive.org/web/20120525101008/http://blogs.plos.org/mfenner/2010/09/07/orcid-as-unique-author-identifier-what-is-it-good-for-and-should-we-worry-or-be-happy/\">speaking
        about author identifiers</a>), can watch this video of a <a href=\"https://web.archive.org/web/20120525101008/http://www.ted.com/talks/david_mccandless_the_beauty_of_data_visualization.html\">TED
        talk</a> that David gave in July:</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Lanyrd: a new Twitter mashup for conferences
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/lanyrd-a-new-twitter-mashup-for-conferences/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw5p</id>\n        <published>2010-09-12T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-01T06:26:21.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p><a href=\"https://web.archive.org/web/20120525041249/http://lanyrd.com/\">Lanyrd</a>
        is a new social directory for conferences launched just a few days ago. It
        integrates with Twitter to allow you to list conferences you are organizing,
        speaking at, attending, or just following. It is a social directory in the
        sense that everyone can edit this information (I don\u2019t know who started
        the <a href=\"https://web.archive.org/web/20120525041249/http://lanyrd.com/2010/science-online-london/\">Science
        Online London 2010</a> page), and that you can see the conferences of your
        Twitter contacts. Future versions of Lanyrd will do a lot more (you can see
        some of the upcoming features at the <a href=\"https://web.archive.org/web/20120525041249/http://lanyrd.com/2010/dconstruct/\">dConstruct
        2010</a> page), but the site is already useful and just looks gorgeous.</p><figure
        class=\"kg-card kg-image-card\"><img src=\"https://web.archive.org/web/20120525041249im_/http://lanyrd.com/static/img/logo/lanyrd-158x158.png\"
        class=\"kg-image\" alt=\"Lanyrd Logo\" loading=\"lazy\"></figure><p>The Lanyrd
        blog launched yesterday and <a href=\"https://web.archive.org/web/20120525041249/http://lanyrd.com/blog/2010/welcome/\">the
        first post</a> contains some interesting background information. Lanyrd is
        a joint project by web developers and newly-weds Simon Willison and Natalie
        Downe. They launched Lanyrd from Morocco while on an extended honeymoon and
        don\u2019t plan to be back to England before the end of next year.</p><p>Sites
        such as <strong><strong>Eventbrite</strong></strong>, <strong><strong>Upcoming</strong></strong>
        or <strong><strong>Slideshare</strong></strong> have been around for a while.
        Twitter is becoming an increasingly useful tool for conferences (<a href=\"https://web.archive.org/web/20120525041249/http://blogs.plos.org/mfenner/2010/09/12/lanyrd-a-new-twitter-mashup-for-conferences/The%20Great%20Science%20Online%20London%20Tweetup\">The
        Great Science Online London Tweetup</a>). And Lanyrd is one of the nicest
        examples that I have seen so far that integrates Twitter into a service targeted
        at conference attendees.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Peer review is not a piece of cake ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/peer-review-is-not-a-piece-of-cake/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw5m</id>\n        <published>2010-09-09T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-03T05:01:16.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>On Monday <strong><strong>Jenny
        Rohn</strong></strong> published a blog post <a href=\"https://web.archive.org/web/20120525040917/http://www.guardian.co.uk/science/blog/2010/sep/06/peer-review\">Peer
        review is no picnic</a> that concludes:</p><blockquote><em><em><em><em><em><em><em><em>So
        the next time you hear someone asserting that scientists aren\u2019t critical,
        of their own work or that of their colleagues, remember that if a finding
        has made its way into a reputable journal, it\u2019s most likely despite every
        last objection that the researcher and all of his lab-mates could come up
        with \u2013 to say nothing of those nasty peer reviewers.</em></em></em></em></em></em></em></em></blockquote><p>As
        always with Jenny\u2019s blog posts, the discussion is as interesting as the
        blog post itself. Joe Dunckley, Maxine Clarke, Austin Elliott, David Colquhoun,
        and others wrote thoughtful comments about peer review (the comments are now
        closed). Peer review is an important topic that I want to write more about
        on this blog (I wrote <a href=\"https://web.archive.org/web/20120525040917/http://blogs.nature.com/mfenner/2009/07/13/the-value-of-peer-review\">The
        Value of Peer Review</a> after attending SciFoo 2009).</p><p>Jenny normally
        writes at Nature Network (<a href=\"https://web.archive.org/web/20120525040917/http://blogs.nature.com/ue19877e8/\">Mind
        the Gap</a>), but for this post was invited as guest blogger for the <a href=\"https://web.archive.org/web/20120525040917/http://www.guardian.co.uk/science/series/blog-festival\">Guardian
        science blogs</a>. They launched just last week and for the <a href=\"https://web.archive.org/web/20120525040917/http://www.guardian.co.uk/science/series/blog-festival\">Blog
        Festival</a> blog have started to invite guest bloggers such as <a href=\"https://web.archive.org/web/20120525040917/http://www.guardian.co.uk/science/blog/2010/sep/03/amateur-astronomy-telescope-night-sky\">Stephen
        Curry</a> (Nature Network) and <a href=\"https://web.archive.org/web/20120525040917/http://www.guardian.co.uk/science/blog/2010/sep/01/psychedelic-drugs-mental-illness\">Mo
        Costandi</a> (scienceblogs.com).</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ BioMed Central drafts position statement
        on open data ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/biomed-central-drafts-position-statement-on-open-data/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw5k</id>\n        <published>2010-09-08T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T07:47:31.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Last week <strong><strong>BioMed
        Central</strong></strong> published a draft position statement on open data
        (<a href=\"https://blogs.openaccesscentral.com/blogs/bmcblog/resource/opendatastatementdraft.pdf\">PDF</a>).
        <strong><strong>Iain Hrynaszkiewicz</strong></strong> <a href=\"https://web.archive.org/web/20120525103921/http://blogs.openaccesscentral.com/blogs/bmcblog/entry/join_the_data_debate_draft\">explained
        the statement</a> on the BioMed Central Blog, including the five Ws of open
        data:</p><ol><li>Why make data more open?</li><li>What data to make more open?</li><li>Where
        to make data more open?</li><li>When to make data more open?</li><li>How to
        make data more open?</li></ol><p>Please comment on the statement.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ ORCID as unique author identifier: what
        is it good for and should we worry or be happy? ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/orcid-as-unique-author-identifier-what-is-it-good-for-and-should-we-worry-or-be-happy/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw5j</id>\n        <published>2010-09-07T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T13:53:12.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/bilder.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/bilder.jpeg\"></p><p>This
        was the title of the session with <strong><strong>Geoff Bilder</strong></strong>,
        <strong><strong>Gudmundur Thorisson</strong></strong> and myself at the <a
        href=\"https://web.archive.org/web/20120525074318/http://www.scienceonlinelondon.org/programme.php?tab=abstracts#breakout12\">Science
        Online London Conference</a> last Saturday. Geoff first introduced the ORCID
        initiative, including several \_principles.</p><p>We then talked about two
        use cases for ORCID. I started with the manuscript submission scenario (<a
        href=\"https://web.archive.org/web/20120525074318/http://www.slideshare.net/mfenner/orcid-as-unique-author-identifier-what-is-it-good-for-and-should-we-worry-or-be-happy\">my
        Slideshare presentation</a>), and I suggested that a critical mass of journals
        using ORCID would have these benefits to researchers:</p><ol><li>Reduced submission
        work</li><li>Automated CVs and publication lists</li><li>Find related works
        by author</li><li>Semantic meaning of authorship</li></ol><p>Semantic meaning
        of authorship (\u201Ccorresponding author\u201D or \u201Canalyzed microarray
        data\u201D) is not a goal for the first ORCID release, but an interesting
        future perspective.</p><p>Gudmundur followed with a similar presentation about
        the research dataset submission scenario (<a href=\"https://web.archive.org/web/20120525074318/http://www.slideshare.net/gthorisson/thorisson-science-online-london-sep2010\">his
        Slideshare presentation</a>).</p><p>The process is similar to journal submission
        but interacts with repositories instead of journals. Gudmundur showed how
        this workflow could integrate the submission of a manuscript and the corresponding
        research data. He also demonstrated how datasets in repositories associated
        with a particular author could be discovered with the help of ORCID.</p><p>But
        most of the session was dedicated to discussion. As open data was one of the
        main themes of the conference, the meaning of \u201Copen\u201D in ORCID was
        one of the topics. We talked about how the identifier ORCID could be combined
        with authentication such as the OAuth system. Phil Lord wanted a modification
        of the journal submission use case, in that the ORCIDs of authors should be
        provided with the manuscript, and not entered in the journal submission system.
        And we talked about whether ORCID should also be used for blog posts, Wikipedia
        submissions, Slideshare presentations, etc. \u2013 I argued that not everything
        needs to be attributed and measured (see my <a href=\"https://blog.front-matter.io/posts/unmeasurable-science/\">previous
        blog post</a>).</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/4953236107_349c7d7b02_m.jpeg\"
        class=\"kg-image\" alt=\"Konferensp\xE5se\" loading=\"lazy\" width=\"180\"
        height=\"240\"><figcaption>Flickr photo by malin_c.</figcaption></figure><p>Today
        the ORCID initiative reached another important milestone. ORCID is<a href=\"https://web.archive.org/web/20120525074318/http://orcid.org/node/166\">
        now an official non-profit organization</a> with a first board of directors.
        I am looking forward to serving on this board of directors.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ The Great Science Online London Tweetup
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/the-great-science-online-london-tweetup/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw5g</id>\n        <published>2010-09-06T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-01T06:24:06.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>The 3rd Annual
        <a href=\"https://web.archive.org/web/20120524054709/http://www.scienceonlinelondon.org/\">Science
        Online London Conference</a> took place last Friday and Saturday. For me it
        was again a fantastic event. Matt Brown is collecting all blog posts, pictures,
        videos, etc. over at <a href=\"https://web.archive.org/web/20120524054709/http://blogs.nature.com/u6e5b2ce1/2010/09/05/science-online-london-2010-index-of-blog-posts-videos-photos-and-stuff\">this
        Nature Network post</a>. As one of the organizers of the conference (mainly
        helping with the program) I was pretty nervous, and I have to admit that I
        didn\u2019t sleep well Thursday and Friday. And much better Saturday.</p><figure
        class=\"kg-card kg-image-card\"><img src=\"https://web.archive.org/web/20120524054709im_/http://farm5.static.flickr.com/4133/4964420222_41f382e41c.jpg\"
        class=\"kg-image\" alt=\"IMG_0087\" loading=\"lazy\"></figure><p><em><em>Flickr
        photo by Mendeley.com with me on far left.</em></em></p><p>One important reason
        to go to a conference is of course to meet the members of your community in
        real life. It was great to talk to many old friends again, and to meet for
        the first time in person people I knew from online interactions (Alex Knoll,
        Brian Mossop, David Dobbs, Matt Cockerill, Jen Mellinn, William Gunn and Jim
        Caryl and many others not mentioned here). Of course I also missed several
        friends that came to the first two conferences.</p><p>Of the many impressions
        of the conference I want to focus on one: <strong><strong>Twitter</strong></strong>.</p><p>Twitter
        has of course become a mainstream tool to follow conferences. Microblogging
        for the 2008 conference happened mainly on FriendFeed (the much better tool
        for conference microblogging and described in this <em><em><a href=\"https://web.archive.org/web/20120524054709/http://dx.doi.org/10.1371/journal.pcbi.1000263\">PLoS
        Comp Biol</a></em></em> paper). Every year has seen an increase in Twitter
        use, and both <a href=\"https://web.archive.org/web/20120524054709/http://summarizr.labs.eduserv.org.uk/?hashtag=scio10\">ScienceOnline2010</a>
        (#scio10) in January and <a href=\"https://web.archive.org/web/20120524054709/http://summarizr.labs.eduserv.org.uk/?hashtag=solo10\">last
        week\u2019s conference</a> produced more than 6000 tweets. Towards the end
        of the conference on Saturday the #solo10 hashtag was the <a href=\"https://web.archive.org/web/20120524054709/http://twitter.com/scottkeir/status/22986296735\">#2
        trend</a> for London, right before #happbirthdaybeyonce. People not attending
        the conference were starting to drop in the conversation. We easily beat mainstream
        science conferences such as the American Society of Clinical Oncology Meeting
        (#asco10) that I <a href=\"https://web.archive.org/web/20120524054709/http://blogs.nature.com/mfenner/2010/06/15/using-twitter-at-the-asco-conference\">attended
        earlier this year</a> (almost 5000 tweets, but more than 30.000 attendees).
        Also interesting: more than 700 people used the #solo10 hashtag in their tweets,
        even though the conference had only 250 attendees (at least 140 of them with
        Twitter accounts, listed <a href=\"https://web.archive.org/web/20120524054709/http://twitter.com/LouWoodley/solo10-attendees\">here</a>).
        And some of those not attending were very active twitterers, particularly
        Bora Zivkovic (@BoraZ).</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://web.archive.org/web/20120524054709im_/http://farm5.static.flickr.com/4113/4963334783_dcb3fb6163.jpg\"
        class=\"kg-image\" alt=\"#solo10 Word Cloud\" loading=\"lazy\"><figcaption>Flickr
        image by Simon Cockell.</figcaption></figure><p>Simon Cockell has <a href=\"https://web.archive.org/web/20120524054709/http://blog.fuzzierlogic.com/archives/365\">created</a>
        a Wordle with the conference tweets, which gives a good idea of the topics
        discussed. The word PDF is a good example. <a href=\"https://web.archive.org/web/20120524054709/http://www.mjrobbins.net/\">Martin
        Robbins</a> said in the <strong><strong>Rebooting Science Journalism</strong></strong>
        panel discussion that \u201CThe PDF is an insult to science\u2026\u201D (rightfully
        so), and this resulted in a longer discussion in the Twitter backchannel.</p><p>That
        <a href=\"https://web.archive.org/web/20120524054709/http://alicerosebell.wordpress.com/2010/09/03/taking-science-journalism-upstream/\">same
        panel discussion</a> also made the best use of Twitter as integral part of
        a session. <a href=\"https://web.archive.org/web/20120524054709/https://twitter.com/christineottery\">Christine
        Ottery</a> was monitoring the Twitter feed and provided feedback for the panelists.
        We used Twitterwalls for most sessions, but the speakers often did not use
        information.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://web.archive.org/web/20120524054709im_/http://farm5.static.flickr.com/4090/4963802359_790df7b240.jpg\"
        class=\"kg-image\" alt=\"IMG_0066\" loading=\"lazy\"></figure><p><em><em>Flickr
        photo by Mendeley.com</em></em></p><p>Twitter several times was also mentioned
        as an important discovery tool, and I agree that it has become of the best
        tools to discover interesting stuff, blog posts, papers, etc. I couldn\u2019t
        attend the <strong><strong>Recommendation Tools for Scientists</strong></strong>
        session (with Kevin Emamy and Jason Hoyt), so I don\u2019t know whether Twitter
        as recommendation tool was discussed there.</p><p>It would be interesting
        to do a more detailed analysis of the #solo10 tweets, e.g. by analyzing which
        sessions were the most tweeted, what were the most popular keywords and links,
        or by categorizing tweets into different categories. This could make an interesting
        session at the <a href=\"https://web.archive.org/web/20120524054709/http://www.scienceonline2010.com/index.php/wiki/2011_Program_Suggestions\">ScienceOnline2011</a>
        Conference next January \u2013 of course using some of the cool data visualization
        tricks that <a href=\"https://web.archive.org/web/20120524054709/http://www.davidmccandless.com/\">David
        McCandless</a> showed us in his session.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Flipboard: PLoS BLOGs on the iPad ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/flipboard-plos-blogs-on-the-ipad/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw5h</id>\n        <published>2010-09-05T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-13T15:19:19.000+00:00</updated>\n\t\t<category
        term=\"Science Hack\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>The iPad
        owners among the PLoS BLOGs readers can use the free Flipboard application
        to read all the great content that is written by my fellow ploggers PLoGsters
        (as suggested by <a href=\"https://web.archive.org/web/20120604164119/http://blogs.plos.org/takeasdirected/2010/09/03/latest-from-the-plogsters\">David
        Kroll</a>). In Flipboard simply create a new section and then add content
        to it by following the @plosblogs Twitter account.</p><figure class=\"kg-card
        kg-image-card\"><img src=\"https://web.archive.org/web/20120604164119im_/http://farm5.static.flickr.com/4103/4959511883_06a51c32ce.jpg\"
        class=\"kg-image\" alt=\"PLoS Blogs on Flipboard\" loading=\"lazy\"></figure><p>There
        are of course many other ways Flipboard can be used to follow science blogs,
        e.g. by following the @researchblogs Twitter account. More info can be found
        in <a href=\"https://web.archive.org/web/20120604164119/http://blogs.nature.com/mfenner/2010/08/01/flipboard-changes-the-way-we-use-twitter\">this
        blog</a> posts I wrote last month.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Unmeasurable Science ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/unmeasurable-science/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw5f</id>\n
        \       <published>2010-09-04T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-13T14:01:19.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>On Wednesday PLoS BLOGs launched
        with a splash. We (both PLoS BLOGs as a whole and me individually) got a lot
        of positive feedback and words of encouragement \u2013 so we are off to a
        good start. As both our community manager Brian Mossop and myself are currently
        in London for the Science Online London Conference, we could celebrate the
        launch in person. With a good pint of British ale Thursday evening.</p><p>Today
        I want to talk about something that is sticking in my head since a conversation
        a few weeks ago with some friends (all esteemed professors in biology or medicine)
        over another beer. And this has of course been discussed before, both on this
        blog and elsewhere. Doing science is not only about doing exciting research,
        and communicating the results to your peers and the public. Measuring scientific
        output \u2013 of funded research projects, a particular researcher, or an
        institution \u2013 seems to be equally important. I would argue that in recent
        years this has even become the most important aspect of doing science. The
        successful researcher of today is not necessarily a brilliant mind, skillful
        experimenter or successful communicator, but a good manager of science. Grants
        need to be written, collaborations and networks built and maintained, and
        papers published.</p><p>This is all good and well in the sense that researchers
        should be held accountable for how they are using their funding, often from
        public sources. And we want to fund the right projects, i.e. those that have
        the highest likelihood of achieving something new and exciting. But there
        are two very big problems with this:</p><h3 id=\"we-don-t-really-know-how-to-evaluate-science-particularly-in-numbers-that-can-be-used-to-compare-research-projects-\">We
        don\u2019t really know how to evaluate science, particularly in numbers that
        can be used to compare research projects. </h3><p>This problem is aggravated
        by the fact that funding (and hiring) decisions are predictions based on past
        performance. Excellent science by definition is new and groundbreaking, and
        predicting scientific progress is really hard to do. The past performance
        of a researcher, the research environment he is working in (colleagues, scientific
        equipment, etc.), and of course the project outline written down in the proposal
        are all very helpful. But can we really \_predict the next Nature or Cell
        paper before a project has even started? And the evaluation of scientific
        output is also extremely difficult. Do you just look at published papers?
        And if so, how do you evaluate the scientific impact of those papers? Through
        peer review? By the number of times they were cited? Citation counts have
        several problems, one of them is the fact that they take a few years to accumulate.
        The journal a paper is published in? How good an indicator of the impact of
        the individual paper is that? Should you rather look at download counts or
        other article-level metrics? We need to think much more about these important
        issues, as our funding (and hiring) decisions depend on it. I am very happy
        that I was invited to a workshop by the National Science Foundation this November
        that will talk about some of these issues. Unique digital author identifiers
        will play an increasing role in our efforts to tackle the technical aspects
        of this problem, and I will say something about the ORCID initiative.</p><h3
        id=\"the-evaluation-of-science-is-taking-up-more-and-more-of-our-time-that-is-then-missing-time-for-doing-research-\">The
        evaluation of science is taking up more and more of our time that is then
        missing time for doing research. </h3><p>Before the first experiment is even
        started, a project has taken months or sometimes even years of grant writing
        and grant reviewing. The regulatory requirements are also increasing, and
        in the case of clinical research involving patients (something I do) can be
        overwhelming. After a research project is finished, paper writing and reviewing
        (and writing a report for the funding agency) again takes many months. In
        the end it might have taken us two years to do the experiments, but five years
        from beginning to end of the project.</p><p>If we want researchers to do more
        research \u2013 and less grant writing, manuscript writing and peer reviewing
        (because all this output has to be evaluated by someone), we have to ask funding
        organizations and institutions to do something about this. There are many
        possible solutions, and some of them have already been realized:</p><ul><li>Grants
        can be given for longer periods of time, e.g. 5 years instead of 3 years</li><li>The
        review of grants could just look at the researcher, and doesn\u2019t try to
        predict scientific discoveries based on the proposed work</li><li>Smaller
        grants, e.g. less than $50.000 don\u2019t need to have a concluding report,
        a link to a paper published with the results should be enough. Similarly we
        might need fewer progress reports in larger grants.</li><li>Many aspects of
        grant and paper writing could be made less time-consuming by standardization
        and automation.</li></ul><p>There is a lot of potential in the last point,
        and the workflow is broken at many points. Why do researchers have to list
        their publications in their CV, this information is publicly available? Why
        does every funding organization want a slightly different format for their
        grant proposals, can\u2019t we standardize this? Why don\u2019t we have better
        paper writing tools? Microsoft Word doesn\u2019t really now about the different
        required sections for a manuscript and is far from perfect for collaborative
        writing.</p><p>But I have to stop writing now, the second day of the Science
        Online London Conference is about to begin. I\u2019m wearing my new PLoS BLOGs
        T-shirt and look forward to another great conference day. I will write about
        the conference in a separate post in the next fews, but for now let\u2019s
        just say this conference is even better than in 2009.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Welcome to Gobbledygook ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/welcome-to-gobbledygook/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw5n</id>\n
        \       <published>2010-09-01T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-18T07:53:16.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/2187485704_a598c84739.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/2187485704_a598c84739.jpeg\"></p><p>In
        his <a href=\"https://web.archive.org/web/20120506093643/http://blogs.plos.org/blog/2010/08/31/the-niche-blog-network-lessons-from-the-past-visions-for-the-future/\">introductory
        post</a>, PLoS community manager Brian Mossop talks about how PLoS Blogs came
        to life, and the lessons learned from other blogging networks. For me personally
        it all started a few weeks ago with a phone call one Friday evening from <a
        href=\"https://web.archive.org/web/20120506093643/http://www.plos.org/about/people/one.php#pbinfield\">Pete
        Binfield</a>, Publisher of PLoS ONE and the PLoS Community Journals.</p><p>Since
        August 2007 and until today I was blogging over at <a href=\"https://web.archive.org/web/20120506093643/http://blogs.nature.com/mfenner\">Nature
        Network</a>. The focus of that blog was how the internet is changing scientific
        publishing. This is obviously a very broad topic. A lot of my blog posts looked
        at rather technical aspects, including new products and services (the <a href=\"https://web.archive.org/web/20120506093643/http://blogs.nature.com/mfenner/2010/08/29/elsevier-launches-sciverse-integrates-sciencedirect-scopus-more\">last
        post</a> was about Elsevier\u2019s SciVerse that launched last weekend).</p><p>I
        will continue to write about the same topics. I particularly like to continue
        <a href=\"https://web.archive.org/web/20120506093643/http://blogs.nature.com/mfenner/2010/08/31/bye-bye-nature-network\">interviews</a>,
        and I want to write more recipes (<a href=\"https://web.archive.org/web/20120506093643/http://blogs.nature.com/mfenner/2009/08/08/recipe-distributing-papers-for-a-journal-club\">Recipe:
        Distributing papers for a journal club</a>). Of course I also want to try
        different things, e.g. shorter blog posts of interesting stuff I find (something
        I currently post on Twitter). Please contact me if you have something related
        to scientific publishing that you want me to write about.</p><p>PLoS Blogs
        is not the only new science blogging network. <a href=\"https://web.archive.org/web/20120506093643/http://www.guardian.co.uk/science/blog/2010/aug/31/blogging-digital-media\">Guardian
        Science Blogs</a> launched just yesterday, and <a href=\"https://web.archive.org/web/20120506093643/http://scientopia.org/blogs/\">Scientopia</a>
        and <a href=\"https://web.archive.org/web/20120506093643/http://www.science3point0.com/blogs/\">Science
        3.0</a> in the last few weeks. And <a href=\"https://web.archive.org/web/20120506093643/http://scienceblogging.org/2010/08/19/some-thoughts-about-science-blog-aggregation/\">Scienceblogging.org</a>,
        an aggregator of science blogs (to keep track of all those great blog posts),
        was launched by Anton Zuiker, Bora Zivkovic and Dave Munger two weeks ago.</p><p>This
        is a good week for science blogging for another reason. The <a href=\"https://web.archive.org/web/20120506093643/http://www.scienceonlinelondon.org/\">Science
        Online London Conference</a> takes place this Friday and Saturday. Most relevant
        to the launch of PLoS Blogs is the panel discussion Friday afternoon <a href=\"https://web.archive.org/web/20120506093643/http://www.scienceonlinelondon.org/programme.php?tab=abstracts#panel2\">The
        state of science blogging?</a></p><figure class=\"kg-card kg-image-card\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/logo.png\" class=\"kg-image\"
        alt=\"Science Online London\" loading=\"lazy\" width=\"271\" height=\"208\"></figure><p>There
        will of course be other exciting sessions. The panel <a href=\"https://web.archive.org/web/20120506093643/http://www.scienceonlinelondon.org/programme.php?tab=abstracts#panel1\">\u201CRebooting\u201D
        (aka the future of) science journalism</a> with David Dobbs, Ed Yong, Martin
        Robbins, and Alice Bell should be a lot of fun. The closing panel discussion
        on Saturday <a href=\"https://web.archive.org/web/20120506093643/http://www.scienceonlinelondon.org/programme.php?tab=abstracts#panel3\">If
        you build it, will they come?</a> will look at the adoption (or lack thereof)
        of \_Web 2.0 tools for scholarly communication, based on a <a href=\"https://web.archive.org/web/20120506093643/http://www.rin.ac.uk/our-work/communicating-and-disseminating-research/use-and-relevance-web-20-researchers\">recent
        report</a> by the Research Information Network. And a number of sessions focus
        on open data, a trending topic I\u2019m personally very interested in. Together
        with Geoff Bilder and Gudmundur Thorisson I will moderate a session <a href=\"https://web.archive.org/web/20120506093643/http://www.scienceonlinelondon.org/programme.php?tab=abstracts#breakout11\">ORCID
        as unique author identifier: what is it good for and should we worry or be
        happy?</a></p><p>Most importantly, Science Online London is a great opportunity
        to meet many of my fellow science bloggers in person, including Brian Mossop,
        the PLoS Blogs community manager. Expect more reports from Science Online
        London in the next few days, for more up-to-date information please follow
        me on Twitter (<a href=\"https://web.archive.org/web/20120506093643/http://twitter.com/mfenner\">@mfenner</a>,
        conference hashtag <a href=\"https://web.archive.org/web/20120506093643/http://twitter.com/#search?q=%23solo10\">#solo10</a>)
        or try the <a href=\"https://web.archive.org/web/20120506093643/http://www.science3point0.com/solo10-2/\">video
        stream</a> put together by Graham Steel.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Bye-Bye Nature Network ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/bye-bye-nature-network/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw5e</id>\n
        \       <published>2010-09-01T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-18T07:50:34.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/3378007233_f8d5e5a539.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/3378007233_f8d5e5a539.jpeg\"></p><p>This
        is my last post for this Nature Network blog. Later today, I will start a
        new blog somewhere else \u2013 also called Gobbledygook and covering the same
        topics.</p><p>Writing this blog here on Nature Network since August 2007 has
        been an incredible experience, something that can't be covered in a single
        blog post. I simply want to say thank you to all the people I interacted with
        over the years \u2013 both online and in person. And a particular thanks for
        Matt, Corie, Anna and Lou from Nature Network who made all this possible.</p><p>There
        are several of my posts I particularly like \u2013 and some I like a little
        less. Something I really enjoyed doing \u2013 and something that I think works
        very well in the blog format \u2013 is interviews. I did around 20 interviews
        in the last two years (the last two on the <a href=\"https://web.archive.org/web/20120525055619/http://lindau.nature.com/\">Lindau
        Laureate Meeting</a> blog), and I've listed them all below.</p><ul><li><a
        href=\"https://web.archive.org/web/20120525055619/http://blogs.nature.com/mfenner/2008/09/05/interview-with-victor-henning-from-mendeley\">Victor
        Henning about Mendeley</a></li><li><a href=\"https://web.archive.org/web/20120525055619/http://blogs.nature.com/mfenner/2008/10/03/interview-with-alexander-griekspoor\">Alex
        Griekspoor about Papers</a></li><li><a href=\"https://web.archive.org/web/20120525055619/http://blogs.nature.com/mfenner/2008/11/07/interview-with-pablo-fernicola\">Pablo
        Fernicola about the Microsoft Word Article Authoring Add-In</a></li><li><a
        href=\"https://web.archive.org/web/20120525055619/http://blogs.nature.com/mfenner/2009/01/24/interview-with-moshe-pritsker\">Moshe
        Pritsker about JOVE</a></li><li><a href=\"https://web.archive.org/web/20120525055619/http://blogs.nature.com/mfenner/2009/01/30/interview-with-kevin-emamy\">Kevin
        Emamy about CiteULike</a></li><li><a href=\"https://web.archive.org/web/20120525055619/http://blogs.nature.com/mfenner/2009/02/17/interview-with-geoffrey-bilder\">Geoff
        Bilder about CrossRef and author identifiers</a></li><li><a href=\"https://web.archive.org/web/20120525055619/http://blogs.nature.com/mfenner/2009/02/27/lemon8-xml-interview-with-mj-suhonos\">MJ
        Suhonos about Lemon8-XML</a></li><li><a href=\"https://web.archive.org/web/20120525055619/http://blogs.nature.com/mfenner/2009/03/04/zotero-interview-with-trevor-owens\">Trevor
        Owens about Zotero</a></li><li><a href=\"https://web.archive.org/web/20120525055619/http://blogs.nature.com/mfenner/2009/03/25/editorial-manager-interview-with-richard-wynne\">Richard
        Wynne about Editorial Manager</a></li><li><a href=\"https://web.archive.org/web/20120525055619/http://blogs.nature.com/mfenner/2009/04/28/faculty-of-1000-interview-with-richard-grant\">Richard
        Grant about Faculty of 1000</a></li><li><a href=\"https://web.archive.org/web/20120525055619/http://blogs.nature.com/mfenner/2009/05/01/extyles-interview-with-elizabeth-blake-and-bruce-rosenblum\">Elizabeth
        Blake and Bruce Rosenblum about eXtyles</a></li><li><a href=\"https://web.archive.org/web/20120525055619/http://blogs.nature.com/mfenner/2009/05/25/oai-pmh-interview-with-tony-hammond\">Tony
        Hammond about OAI-PMH</a></li><li><a href=\"https://web.archive.org/web/20120525055619/http://blogs.nature.com/mfenner/2009/08/15/plos-one-interview-with-peter-binfield\">Peter
        Binfield about PLoS ONE and article level metrics</a></li><li><a href=\"https://web.archive.org/web/20120525055619/http://blogs.nature.com/mfenner/2009/08/20/streamosphere-interview-with-euan-adie\">Euan
        Adie about Streamosphere</a></li><li><a href=\"https://web.archive.org/web/20120525055619/http://blogs.nature.com/mfenner/2009/10/01/conference-blogging-interview-with-alex-knoll\">Alex
        Knoll about Conference Blogging</a></li><li><a href=\"https://web.archive.org/web/20120525055619/http://blogs.nature.com/mfenner/2009/11/04/uk-pubmed-central-interview-with-phil-vaughan\">Phil
        Vaughan about UK PubMed Central</a></li><li><a href=\"https://web.archive.org/web/20120525055619/http://blogs.nature.com/mfenner/2009/11/26/nature-communications-interview-with-lesley-anson\">Lesley
        Anson about Nature Communications</a></li><li><a href=\"https://web.archive.org/web/20120525055619/http://blogs.nature.com/mfenner/2010/02/15/sciencefeed-interview-with-ijad-madisch\">Ijad
        Madisch about ScienceFeed</a></li><li><a href=\"https://web.archive.org/web/20120525055619/http://blogs.nature.com/mfenner/2010/04/26/researcherid-interview-with-renny-guida\">Renny
        Guida about Researcher ID</a></li><li><a href=\"https://web.archive.org/web/20120525055619/http://blogs.nature.com/mfenner/2010/08/03/endnote-interview-with-jason-rollins\">Jason
        Rollins about Endnote</a></li><li><a href=\"https://web.archive.org/web/20120525055619/http://www.scilogs.eu/en/blog/lindaunobel/2010-07-13/interview-with-edmond-fischer\">Nobel
        Laureate Edmond Fischer</a></li><li><a href=\"https://web.archive.org/web/20120525055619/http://www.scilogs.eu/en/blog/lindaunobel/2010-07-14/an-interview-francoise-barre-sinoussi\">Nobel
        Laureate Francoise Barr\xE9-Sinoussi \u2013 together with Lou Woodley</a></li></ul><p>Please
        stay in touch. And if possible, come around to the <a href=\"https://web.archive.org/web/20120525055619/http://www.scienceonlinelondon.org/\">Science
        Online London Conference</a> this weekend.</p><p>Update: Gobbledygook has
        moved to <a href=\"https://web.archive.org/web/20120525055619/http://blogs.plos.org/mfenner\">PLoS
        Blogs</a>.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Elsevier launches SciVerse, integrates ScienceDirect
        + Scopus + More ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/elsevier-launches-sciverse-integrates-sciencedirect-scopus-more/\"
        />\n\t\t<id>https://doi.org/10.53731/c6913yb-bwqqcty</id>\n        <published>2010-08-29T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-14T14:41:18.000+00:00</updated>\n
        \       <media:content url=\"\" medium=\"image\"/>\n        <content type=\"html\"><![CDATA[
        <p><img src=\"\"></p><p>Elsevier on Saturday launched <a href=\"https://web.archive.org/web/20120524201220/http://info.sciverse.com/\">SciVerse</a>,
        the new Elsevier platform that combines <em><em>ScienceDirect</em></em> (full-text
        journal articles) and <em><em>Scopus</em></em> (abstract and citation database
        of peer-reviewed literature). In 2011 <em><em>SciTopics</em></em> (research
        summaries) will also be integrated and outside developers will be able to
        build SciVerse <em><em>applications</em></em> (Elsevier and 3rd party tools
        that integrate with ScienceDirect and Scopus). Current users of Scopus and
        ScienceDirect can continue to use these services or access them from the SciVerse
        platform.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://web.archive.org/web/20120524201220im_/http://blogs.plos.org/mfenner/files/2010/11/sciverse.jpg\"
        class=\"kg-image\" alt loading=\"lazy\"></figure><p>Both the ScienceDirect
        and Scopus service are not available this evening, put the new SciVerse functionality
        should be available in a few hours. As I had no access to SciVerse prior to
        the launch today, I will need a few days to have a closer look at both the
        integration of existing products, and the new features. But obviously missing
        from the announcement is <a href=\"https://web.archive.org/web/20120524201220/http://www.2collab.com/\">2collab</a>,
        Elsevier's social bookmarking service that integrates with Scopus and ScienceDirect.</p><p>Reference
        managers a few years ago started to store the PDFs of fulltext articles associated
        with a citation. It is no surprise to see the same trend from developers of
        abstracts databases. The integration of Scopus with ScienceDirect almost looks
        like Elsevier's answer to PubMed/PubMed Central. The recently launched <a
        href=\"https://web.archive.org/web/20120524201220/http://ukpmc.ac.uk/\">UK
        PubMed Central</a> is doing a particularly nice job integrating abstracts
        and fulltext articles.</p><p>The most interesting aspect of SciVerse is the
        possibility for 3rd party developers to access the service via APIs and to
        develop both free and commercial applications. We will see whether SciVerse
        develops into an open platform that works with other publishers, funders and
        institutions, or whether SciVerse will become a very large data silo. Elsevier's
        Rafael Sidi <a href=\"https://web.archive.org/web/20120524201220/http://www.researchinformation.info/features/feature.php?feature_id=255\">writes</a>
        that <em><em>Open data and open APIs offer huge opportunities for research
        and innovation</em></em>, and earlier this week Mendeley's Jason Hoyt <a href=\"https://web.archive.org/web/20120524201220/http://www.mendeley.com/blog/open-access/researcher-which-side-of-history/\">wrote</a>
        something similar. Data is also at the heart of the business models of many
        web-based companies \u2013 let's hope that these two interests don't collide.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Supplementary Information: should I stay
        or should I go? ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/supplementary-information-should-i-stay-or-should-i-go/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw59</id>\n        <published>2010-08-27T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T07:45:15.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>On August 11, the <em><em>Journal
        of Neuroscience</em></em> published an <a href=\"https://web.archive.org/web/20120524201522/http://www.jneurosci.org/cgi/content/full/30/32/10599\">Announcement
        Regarding Supplemental Material</a> by Editor-in-Chief John Maunsell. In it
        John Maunsell announces that the journal in November will stop accepting supplementary
        material in article submissions. The announcement has lead to an extensive
        discussion in the science blogosphere with a number of relevant posts listed
        below[^1]:</p><ul><li><em>Drugmonkey</em>: <a href=\"https://web.archive.org/web/20120524201522/http://scientopia.org/blogs/drugmonkey/2010/08/11/yay-j-neuroscience-agrees-with-me-that-supplementary-materials-is-bs-and-ruining-science/\">Yay!
        J. Neuroscience Agrees with Me that \"Supplementary Material\" is BS and Ruining
        Science!</a></li><li><em>Juniorprof</em>: <a href=\"https://web.archive.org/web/20120524201522/http://juniorprof.wordpress.com/2010/08/11/journal-of-neuroscience-is-getting-rid-of-supplemental-data/\">Journal
        of Neuroscience is getting rid of supplemental data</a></li><li><em>Stanford
        Neuroblog</em>: <a href=\"https://web.archive.org/web/20120524201522/http://www.stanford.edu/group/neurostudents/cgi-bin/neuroblog/wanted-primary-figures-for-publication-auxiliary-material-need-not-apply/\">Wanted:
        Primary Figures for Publication. Auxiliary Material Need Not Apply.</a></li><li><em>john
        hawks weblog</em>: <a href=\"https://web.archive.org/web/20120524201522/http://johnhawks.net/weblog/topics/metascience/supplementary-info-neuroscience-2010.html\">Down
        with supplements</a></li><li><em>Christina\u2019s LIS Rant</em>: <a href=\"https://web.archive.org/web/20120524201522/http://scientopia.org/blogs/christinaslisrant/2010/08/12/supplemental-materials-or-no/\">Supplemental
        materials or no?</a></li><li><em>Christina\u2019s LIS Rant</em>: <a href=\"https://web.archive.org/web/20120524201522/http://scientopia.org/blogs/christinaslisrant/2010/08/12/more-questions-about-supplemental-materials/\">More
        questions about supplemental materials</a></li><li><em>Book of Trogool</em>:
        <a href=\"https://web.archive.org/web/20120524201522/http://scientopia.org/blogs/bookoftrogool/2010/08/12/disrupting-with-data/\">Disrupting
        with data</a></li><li><em>petermr's blog</em>: <a href=\"https://web.archive.org/web/20120524201522/http://wwmm.ch.cam.ac.uk/blogs/murrayrust/?p=2540\">Supplementary
        Data must be published somewhere to validate the science</a></li><li><em>Micro
        World</em>: <a href=\"https://web.archive.org/web/20120524201522/http://bioenergyrus.blogspot.com/2010/08/where-i-disagree-with-drugmonkey.html\">Where
        I disagree with Drugmonkey \u2026</a></li><li><em>The Scholarly Kitchen</em>:
        <a href=\"https://web.archive.org/web/20120524201522/http://scholarlykitchen.sspnet.org/2010/08/16/ending-the-supplemental-data-arms-race/\">Ending
        the Supplemental Data \"Arms Race</a>\"</li><li><em>Research Remix</em>: <a
        href=\"https://web.archive.org/web/20120524201522/http://researchremix.wordpress.com/2010/08/13/supplementary-materials-is-a-stopgap-for-data-archiving/\">Supplementary
        Materials Is A Stopgap For Data Archiving</a></li></ul><p>The main arguments
        against supplementary information are that it overburdens reviewers (and in
        turn authors), and it counteracts the concept of a self-contained research
        report. The main argument for supplementary information is that sometimes
        essential information can\u2019t be provided within the context of a journal
        article (e.g. video, large datasets), especially in those journals that still
        have print editions. Several blog posts emphasized that supplementary information
        is particularly important to provide the research data with the article. I
        think that Heather Piwowar\u2019s <a href=\"https://web.archive.org/web/20120524201522/http://researchremix.wordpress.com/2010/08/13/supplementary-materials-is-a-stopgap-for-data-archiving/\">post</a>
        is the best discussion of the relevant issues.</p><p>I\u2019m obviously two
        weeks late with this blog posts, but I have been on vacation, and I\u2019m
        only slowly catching up with all the interesting discussions that have happened
        while I was away. I think the discussion of supplementary information is very
        important, because it really is a discussion of our concept of a scientific
        paper. And this concept is <a href=\"https://web.archive.org/web/20120524201522/http://blogs.nature.com/mfenner/2009/07/26/how-does-the-article-of-the-future-look-like\">changing
        rapidly</a> for many reasons, including the push to mobile platforms, and
        the wish by many to publish multimedia files (e.g. 3D structures) and research
        data with a paper.</p><p><em>Phil Bourne: Beyond the PDF.</em></p><p>It appears
        to me that we haven\u2019t talked much about supplementary information, and
        it really has been something everybody was doing out of necessity, without
        too much thinking about many of the issues, including standard formats, problems
        for users finding and storing this supplementary information, and copyright
        issues.</p><p>Most journals have (often similar) instructions regarding supplementary
        information, e.g.:</p><ul><li><em>Supplementary Information is peer-reviewed
        material directly relevant to the conclusion of a paper that cannot be included
        in the printed version for reasons of space or medium. \u2013 </em><a href=\"https://web.archive.org/web/20120524201522/http://www.nature.com/nature/authors/submissions/final/suppinfo.html\">Nature</a></li><li><em>Although
        BMC Medicine does not restrict the length and quantity of data in a paper,
        there may still be occasions where an author wishes to provide data sets,
        tables, movie files, or other information as additional information.</em>
        \u2013 <a href=\"https://web.archive.org/web/20120524201522/http://www.biomedcentral.com/bmcmed/ifora/\">BMC
        Medicine</a></li><li><em>Supplemental Information may include additional control
        data, validation of methods and reagents, primary data, nonprintable media
        files, or large data sets. It can also include detailed information regarding
        Experimental Procedures, including materials (oligonucleotides, plasmids,
        strains, etc.).</em> \u2013 <a href=\"https://web.archive.org/web/20120524201522/http://www.cell.com/supplemental_information_guide\">Cell</a></li><li><em>We
        strongly encourage authors to include such things as videos, 3-D structures/images,
        sequence alignments and data sets that are very large, such as those obtained
        with microarray hybridization experiments. \u2013 </em><a href=\"https://web.archive.org/web/20120524201522/http://www.jbc.org/site/misc/ifora.xhtml#supplemental_data\">J
        Biol Chem</a></li><li><em>We encourage authors to submit essential supporting
        files and multimedia files along with their manuscripts. All supporting material
        will be subject to peer review. \u2013 </em><a href=\"https://web.archive.org/web/20120524201522/http://www.plosone.org/static/guidelines.action\">PLoS
        ONE</a></li><li><em>Science does not accept as supporting online material
        HTML files including JavaScript or other scripting languages or Cascading
        Style Sheets, PowerPoint presentations, and TeX or LaTeX files.</em> \u2013
        <a href=\"https://web.archive.org/web/20120524201522/http://www.sciencemag.org/about/authors/prep/prep_online.dtl#submit\">Science</a></li><li><em>Instead
        of appearing in the printed version of the journal, supporting information
        is posted on the PNAS Web site at the time of publication. SI is referred
        to in the text and cannot be altered by authors after acceptance. \u2013 </em><a
        href=\"https://web.archive.org/web/20120524201522/http://www.pnas.org/site/misc/iforc.shtml#x\">PNAS</a></li><li><em>The
        amount of online-only material should be limited and justified. Online-only
        material should be original and not previously published. \u2013 </em><a href=\"https://web.archive.org/web/20120524201522/http://jama.ama-assn.org/misc/ifora.dtl#OnlineOnlyMaterial\">JAMA</a></li></ul><p>The
        announcement of the <em><em>Journal of Neuroscience</em></em> will hopefully
        initiate a broader discussion of the usefulness and best format of supplementary
        information. The most interesting aspect for me and several of the bloggers
        discussing the announcement is the publication of the research data associated
        with a paper. For now supplementary information is often the only place these
        data can be published, but there are <a href=\"https://web.archive.org/web/20120524201522/http://researchremix.wordpress.com/2010/08/13/supplementary-materials-is-a-stopgap-for-data-archiving/\">many
        reasons</a> why this is not the best idea in the long run.</p><p>[^1]: This
        is a perfect example for why we need better systems to track blog posts relating
        to an article. We have <a href=\"https://web.archive.org/web/20120524201522/http://blogs.nature.com/\">Nature
        Blogs</a>, <a href=\"https://web.archive.org/web/20120524201522/http://streamosphere.nature.com/\">Streamosphere</a>
        or <a href=\"https://web.archive.org/web/20120524201522/http://www.ubervu.com/conversations/www.jneurosci.org/cgi/content/full/30/32/10599\">UberVu</a>
        (and probably others) but they are far from perfect.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Book Review: Cognitive Surplus by Clay Shirky
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/book-review-cognitive-surplus-by-clay-shirky/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw5a</id>\n        <published>2010-08-14T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-18T07:54:32.000+00:00</updated>\n\t\t<category
        term=\"Book Review\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/1594202532.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/1594202532.jpeg\"></p><p>In
        his new book <em><em>Cognitive Surplus</em></em> Clay Shirky argues that in
        the last 50 years many of those living in industrialized countries have seen
        a dramatic increase in free time, paired with better education and a higher
        standard of living. But a very large part of that free time or cognitive surplus
        is now routinely used to watch television, a passive activity that makes us
        a consumer rather than a participant. In a trend that is also true for other
        media (eg. music), we have seen a shift away from participation (usually on
        an amateur level) towards consuming professionally produced media content.</p><p>In
        the last few years we have seen a dramatic change in Internet technologies
        that now make it extremely easy for everybody to produce content and distribute
        it on the Internet (e.g. Wikipedia, blogs, photos on Flickr, or YouTube videos)
        something we usually call Web 2.0 or social media. Clay Shirky contrasts the
        time that users spend editing <em><em>Wikipedia</em></em> (or other social
        media activities) with the hours we typically watch television to kill the
        argument that most of us would have no time for social media.</p><p>The combination
        of increased free time and social media is creating a lot of interesting collaborative
        projects, and the book is full of interesting examples. Clay Shirky stresses
        that social media only enable new uses of the cognitive surplus, it is how
        they are used that decides whether we create personal, communal, public or
        civic values. He uses <a href=\"https://web.archive.org/web/20120524201437/http://www.icanhazcheeseburger.com/\">ICanHazCheeseburger</a>
        (a popular website that shows cute pictures of cats with cute captions) as
        an example for communal value, the <a href=\"https://web.archive.org/web/20120524201437/http://www.apache.org/\">Apache
        Webserver</a> Open Source software project as an example of public value,
        and <a href=\"https://web.archive.org/web/20120524201437/http://www.ushahidi.com/\">Ushahidi.com</a>
        (a site started to allow citizens to track outbreaks of ethnic violence in
        Kenya) as an example of civic value.</p><p>Social media in the context of
        science and medicine are discussed briefly in the book. Clay Shirky describes
        the <em><em>Invisible College</em></em>, a group formed around 1645 in London
        by Robert Boyle, Robert Hooke and others that established many of the principles
        of conducting science that are still valid today (test every hypothesis with
        experiments, describe experiments detailed enough so that they could be reproduced,
        etc.). The group formed the core of what a little later became the <em><em>Royal
        Society</em></em>. Clay Shirky argues that the collaborative nature of how
        science was conducted by the Invisible College lead to a dramatic increase
        in our scientific knowledge and contrasts this with how alchemy was performed
        at the time (reclusive and secretive).</p><p>Clay Shirky also talks about
        <a href=\"https://web.archive.org/web/20120524201437/http://www.patientslikeme.com/\">PatientsLikeMe.com</a>,
        a site that allows patients with chronic diseases to share their health information,
        both for personal advice, but also as participants in clinical trials. Patients
        Like Me only works because patients are willing to share their personal healthcare
        information, and that is a cultural shift from the strict privacy that usually
        surrounds information about your personal health. Patients participating in
        Patients Like Me obviously think that the benefits from sharing their personal
        healthcare information outweigh the risks.</p><p>Cognitive Surplus is very
        entertaining reading, and on almost every page Clay Shirky gives us food for
        thought that will keep us busy for days or weeks. The book is required reading
        for everybody who is interested in how social media are changing the way we
        consume, communicate, and conduct science. After finishing the book, you will
        no longer think that the scientific article of the future is primarily about
        integration of video or other multimedia, intelligent navigation, or display
        on mobile devices. The successful journals of the future will be those that
        work hardest in facilitating collaboration among scientists, and this requires
        cultural changes as much as it requires technological changes.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ What comes after Google Wave? ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/what-comes-after-google-wave/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw5b</id>\n        <published>2010-08-09T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-29T10:19:23.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/DALL-E-2022-08-29-12.18.48---Photo-of-a-garden-gnome-with-an-umbrella-on-a-surfboard-surfing-on-a-large-wave.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/DALL-E-2022-08-29-12.18.48---Photo-of-a-garden-gnome-with-an-umbrella-on-a-surfboard-surfing-on-a-large-wave.png\"></p><p>Google
        <a href=\"https://web.archive.org/web/20120524201336/http://googleblog.blogspot.com/2010/08/update-on-google-wave.html\">announced
        last week</a> that they will stop further development of Google Wave, and
        essentially shut down the service by the end of the year. Some of the more
        exciting parts of Wave will be reused in other Google products or \u2013 since
        many parts of Google Wave have been made available under an Open Source license,
        in products by other companies. But the announcement is an admission that
        the adoption by users and developers had not been what Google had hoped for
        with this very ambitious project.</p><p>Google Wave was first announced at
        Google I/O in May 2009, and <a href=\"https://web.archive.org/web/20120524201336/http://blogs.nature.com/mfenner/2009/07/18/using-google-wave-for-a-week-its-still-great\">I
        had a Google Wave account</a> since July 2009 thanks to being invited to the
        SciFoo conference (where every attendee got one of those then still rare Wave
        invites). Like <a href=\"https://web.archive.org/web/20120524201336/http://cameronneylon.net/blog/the-triumph-of-document-layout-and-the-demise-of-google-wave/\">others</a>,
        I saw the tremendous potential to improve on existing tools for researchers
        to collaborate. But after 12 months, Google Wave hasn't replaced email as
        communication tool in at least some of my collaborations. Many people have
        pointed out the reasons for the lack of user adoption of Google Wave. I want
        to focus on something else: Google Wave tried to solve a problem that is very
        relevant to scientists, and we still don't have a solution for that problem.</p><p>Email
        has become the primary tool for many scientists to collaborate with colleagues
        both within the same institution, and between different institutions. Despite
        this popularity, email and the typical workflow around it has several significant
        shortcomings:</p><p><em><em>Email is not good in tracking longer conversations
        between more than two people.</em></em> Even though email messages can be
        grouped together, it quickly becomes difficult to follow the discussion. And
        it is even more complicated for those joining the discussion later.</p><p><em><em>Email
        is not good in sharing documents.</em></em> Sending large documents repeatedly
        back and forth is not only a waste of network bandwidth and limited email
        storage capacities, but is also not a very productive way to collaboratively
        work on a longer document, as it quickly becomes difficult to merge the different
        document versions together.</p><p><em><em>Word processors are not good tools
        to write scientific documents.</em></em> Traditional word processors such
        as Microsoft Word or LaTeX care too much about document formatting, and still
        approach a document primarily as something an individual user edits on a single
        computer.</p><p>Maybe user uptake for Google Wave was low because the approach
        to tackle these problems was too radical. Many other, less radical tools try
        to solve the same problems, including mailing lists, wikis, social bookmarking
        sites such as CiteULike, collaborative writing tools such as Google Docs,
        and project management tools such as Basecamp.</p><p>Where do we go from here?
        Because most of the technology behind Google Wave has been made available,
        we could continue to use and develop Google Wave and Wave extensions for scientists.
        But that is a very risky strategy that not many people would follow. We can
        also wait for new tools that help scientists collaborate, and there interesting
        products announced every few months. For the time being I will continue trying
        to convince my colleagues to use some of the existing tools instead of email
        where appropriate, something that is surprisingly difficult.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Endnote: Interview with Jason Rollins ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/endnote-interview-with-jason-rollins/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw5c</id>\n        <published>2010-08-03T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-13T15:40:49.000+00:00</updated>\n\t\t<category
        term=\"Interview\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Reference
        management is a frequent topic on this blog. The last few years we have seen
        both a large increase in the number of <a href=\"https://web.archive.org/web/20120524201927/http://blogs.nature.com/mfenner/2009/03/15/reference-manager-overview\">available
        tools</a>, but also big changes in <a href=\"https://web.archive.org/web/20120524201927/http://blogs.nature.com/mfenner/2010/05/19/post\">how
        we use reference management software</a>. But for many of us the first reference
        management software was Endnote.</p><p>I first used Endnote as a medical student
        in 1990 (Endnote Plus at that time, published by Niles Software), and I\u2019m
        still a regular user. I can\u2019t say that for many other programs (probably
        also Microsoft Word, Excel and Powerpoint, Adobe Photoshop, SPSS and until
        recently Freehand). The latest version \u2013 Endnote X4 \u2013 was just released/is
        about to be released (Windows in June, Macintosh in August). This is a good
        opportunity to look at how Endnote has changed over the years and why it is
        still such a popular application. For this I interviewed <em><em>Jason Rollins</em></em>,
        who is leading the Endnote development team.</p><figure class=\"kg-card kg-image-card\"><img
        src=\"https://web.archive.org/web/20120524201927im_/http://blogs.plos.org/mfenner/files/2010/11/endnote_group.jpg\"
        class=\"kg-image\" alt loading=\"lazy\"></figure><p><em><em>Members of the
        EndNote development team: Jason Rollins, Jiaquan Ma, David Pedrick, Rachel
        Hubbard, Mayra Aguas, Paul Patanella, Lisa Epps, Lynette Grabow, Howard Harrison,
        Jennifer Melinn, Bill Colsher, Tilla Edmunds, Gandalf Sollenberger (with the
        Philadelphia in the background).</em></em></p><h3 id=\"1-what-is-endnote\">1.
        What is EndNote?</h3><p>Researchers around the world depend on EndNote to
        simplify collaboration, reference collection, and bibliography formatting.
        It is these researchers who have molded the EndNote you see today, allowing
        us to address the pain points as technology evolves. While EndNote originated
        on the Macintosh and Windows desktops, users now have the added combination
        of the Web where they can transfer reference groups and share them with colleagues
        easily. EndNote connects to many parts of the research landscape including
        online resources for both basic bibliographic information and full text, word
        processors, <a href=\"https://web.archive.org/web/20120524201927/http://www.researcherid.com/\">ResearcherID</a>
        for uniquely identifying personal works that will dovetail into the <a href=\"https://web.archive.org/web/20120524201927/http://www.orcid.org/\">ORCID</a>
        initiative as well as decreasing time to publish when submitting EndNote formatted
        documents into publishing systems.</p><h3 id=\"2-how-is-endnote-different-from-other-reference-managers\">2.
        How is EndNote different from other reference managers?</h3><p>EndNote defined
        reference management software for generations of researchers and continues
        to offer the highest quality formatting available in any tool. Today some
        variation of the core functionality \u2013 searching, organizing, sharing,
        and citing of scholarly reference material \u2013 is available in many competing
        tools.</p><p>Two key differences between EndNote and other reference management
        tools include gathering and formatting references. First, EndNote is far more
        accurate and flexible when it comes to the variety of publishing styles it
        supports. EndNote not only provides <a href=\"https://web.archive.org/web/20120524201927/http://www.endnote.com/support/enstyles.asp\">over
        4,500 formatting styles</a> but it also allows for the most control and customization
        of this formatting. Our EndNote team works closely with leading publishers
        and editors across many academic disciplines to ensure that EndNote offers
        the formatting control our users need to meet exacting publisher specifications.
        Most of the power of this formatting is built-in and achieved automatically
        by EndNote \u2013 without the user having to think about it. Of course there
        are many customization options too; these allow users to easily make changes
        and tweaks to the way EndNote formats citations, footnotes, and bibliographies.</p><p>Second,
        EndNote offers the best options for easy import and export of user data. The
        Online Search, Find Full Text, importing, and Web capture options are all
        features that make it easy to obtain accurate bibliographic information and
        manage full text data in EndNote. The \u201CRIS Tagged Data\u201D format has
        become a de facto standard for hundreds of databases and software tools. Plus,
        the EndNote XML specification is something that is openly shared with partners
        and competitors alike in hopes of making it easier for our customers to move
        their data into and out of any system they may need to use.</p><h3 id=\"3-what-is-new-in-endnote-x4\">3.
        What is new in EndNote X4?</h3><p>There\u2019s a <a href=\"https://web.archive.org/web/20120524201927/http://www.endnote.com/enx4wnvid/Whats_New-SD.asp\">longer
        list of new and improved features</a>, but a few of the key features are new
        PDF functions, better support for collaborative writing and more robust footnote
        handling.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://web.archive.org/web/20120524201927im_/http://blogs.plos.org/mfenner/files/2010/11/endnote_screenshot.jpg\"
        class=\"kg-image\" alt loading=\"lazy\"></figure><p>EndNote X4 can create
        records from PDFs using metadata and a DOI, attaching the original file to
        the newly created reference. Then, PDFs are further incorporated into users\u2019
        libraries by indexing the attached files and making them searchable along
        with the reference data.</p><p>The connection between EndNote and a word processor
        is more visible by incorporating cited references from documents right into
        the EndNote interface. This way, users can work with their references in a
        word processor, and focus on the references in a particular paper while managing
        things in EndNote. Editing and managing individual citations in Word now combines
        all the functionality in one place which is a big help for people working
        on large projects, or collaboratively. The \u201CTraveling Library\u201D sharing
        feature in Word has also been significantly improved to help people work together.
        The APA 6th style is fully supported and EndNote X4 offers much more customization
        and intelligence to the way footnote formatting styles are handled.</p><p>The
        full list of features, online videos, and a free trial version of EndNote
        X4 are available at <a href=\"https://web.archive.org/web/20120524201927/http://www.endnote.com/\">www.endnote.com</a>.
        EndNote version X4 was released in June for Windows with the Macintosh version
        available by the end of this summer.</p><h3 id=\"4-how-does-endnote-handle-pdf-management-can-you-share-pdf-files-with-other-users\">4.
        How does EndNote handle PDF management? Can you share PDF files with other
        users?</h3><p>With version X4, we have added more PDF-related functionality
        to EndNote. Now, you can import PDF meta-data and search the full text of
        attached PDF files. You can share EndNote library files that contain PDF attachments
        easily \u2013 or any other file type. EndNote Web does not currently support
        direct file attachments but this is something we are currently working on.</p><h3
        id=\"5-what-is-endnote-web-how-does-it-relate-to-endnote\">5. What is EndNote
        Web, how does it relate to EndNote?</h3><p>EndNote provides <a href=\"https://web.archive.org/web/20120524201927/http://www.endnoteweb.com/\">EndNote
        Web</a> to users for easy sharing and collaboration features. Transferring
        references up to the web provides extra flexibility to work with EndNote references
        anywhere. There\u2019s a browser plug-in available with EndNote Web, that
        captures and saves references from web pages and allows users to send references
        to a desktop or web-based library. The web version has some features that
        the desktop doesn\u2019t, and vice versa; each is complimentary to the other.
        EndNote Web is also integrated into the Web of Knowledge database platform
        and a limited version of EndNote Web is provided to ResearcherID users for
        managing their personal publication list.</p><h3 id=\"6-can-i-use-endnote-with-collaborative-writing-tools-such-as-google-docs-or-microsoft-office-live\">6.
        Can I use EndNote with collaborative writing tools such as Google Docs or
        Microsoft Office Live?</h3><p>While we do not have any custom built plug-ins
        or similar tools for Google Docs or Microsoft Office Live, as always, it\u2019s
        easy to drag-and-drop or copy-and-paste in EndNote citations. If you look
        closely at other products that claim to be compatible, you\u2019ll see that
        they are offering a simple copy and paste function as well. Based on our research
        thus far, these writing tools do not yet offer the right APIs to build more
        robust integration. This is something we hear from customers quite often so
        we will keep an eye on developments and hope to offer something more once
        the APIs are available.</p><h3 id=\"7-how-does-endnote-help-with-reference-management-beyond-writing-manuscripts-e-g-reading-lists-for-students-writing-blog-posts-etc-\">7.
        How does EndNote help with reference management beyond writing manuscripts,
        e.g reading lists for students, writing blog posts, etc.?</h3><p>You can easily
        use EndNote to include citations, hyperlinks, or any other reference data
        into nearly any type of document in almost any format and customize the output
        for your specific needs. You can share groups of references with both read
        only and read-write access; this supports sharing reading lists and more involved
        collaboration. But, reference management has evolved into so much more than
        just finding things to insert into a document. With the grouping, searching,
        and file attachment options, EndNote is a way to organize the majority of
        your research. These features make EndNote robust and flexible at handling
        a huge volume of items. Plus, you\u2019ve always been able to store files
        of any type with EndNote, therefore making it possible to utilize much of
        the organizational capabilities for non-traditional sources like video clips
        or datasets.</p><h3 id=\"8-endnote-has-seen-many-updates-since-its-initial-release-more-than-20-years-ago-what-do-you-see-as-some-of-the-most-significant-changes-during-that-time\">8.
        EndNote has seen many updates since its initial release more than 20 years
        ago. What do you see as some of the most significant changes during that time?</h3><p>EndNote
        started out for the Mac Plus and DOS; so clearly a lot has changed along with
        many of the major developments in personal software technology since the late
        1980\u2032s. EndNote introduced online searching and direct export to simplify
        the movement of references from discovery to a personal collection for citing
        in papers. Cite While You Write is often imitated but never duplicated for
        ease of use when citing references in Apple Pages, Microsoft Word, and OpenOffice.org
        Writer. The fundamental problem that EndNote has been solving for our customers
        has morphed over the years. While keeping up with changes in formatting rules
        and reference types, which have always been the core strength of EndNote,
        we have also evolved EndNote into a more complete reference management solution.
        Where at one time the majority of our users worked alone on a single computer
        writing a static manuscript, today most customers interact with a global network
        of collaborators on multiple projects that might be delivered in several formats.
        Now with EndNote Web and ResearcherID, EndNote users can easily promote their
        work and connect with others. Another area that has significantly changed
        over the last twenty years is the means by which users access research material,
        and as our user\u2019s focus has shifted from basic reference data and description
        to inclusion of the full text of sources and supporting documentation, EndNote
        has too. EndNote supports this with OpenURL linking, proxy and open source
        authentication, browser plug-ins, and other functions.</p><p>Many of the developments
        we currently have underway will further support online sharing and connectivity
        and should prove to be some of the most valuable including mobile functionality
        and more.</p><h3 id=\"9-what-are-your-responsibilities-at-thomson-reuters\">9.
        What are your responsibilities at Thomson Reuters?</h3><p>My team is responsible
        for the development of bibliographic management tools. This involves leading
        the development teams for EndNote and Reference Manager, listening to customer
        input, and coordinating partnerships.</p><h3 id=\"10-what-did-you-do-before-working-at-thomson-reuters\">10.
        What did you do before working at Thomson Reuters?</h3><p>I joined the EndNote
        team in 2001. Before that, I was completing a PhD in Educational Technology
        from Drexel University and working for two different consulting firms and
        a small web start-up.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Flipboard changes the way we use Twitter
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/flipboard-changes-the-way-we-use-twitter/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw5d</id>\n        <published>2010-08-01T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-18T08:01:26.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/flipboard7.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/flipboard7.jpeg\"></p><p><a
        href=\"https://web.archive.org/web/20120628140034/http://www.flipboard.com/\">Flipboard</a>
        is a <em><em>personalized social magazine</em></em> for the iPad. The free
        application was released on July 22, and instantly created a lot of buzz.
        Because of the overwhelming interest, they had to create a waitlist for the
        personal features and I could only sign up for and start using them a few
        days ago. Flipboard is a true iPad application, it would not work the same
        on a laptop computer or mobile phone.</p><p>Flipboard allows you to set up
        nine sections for different content. You can select them from a predefined
        list, but the really interesting part is to create your own sections from
        Twitter users or Twitter lists.</p><p>You can also create a section with all
        the Twitter accounts you follow. Flipboard will display Tweets in a visually
        pleasing way. Flipboard doesn't display all Tweets in your Twitter timeline
        but filters the most popular and interesting tweets.</p><p>But Flipboard does
        something else. Rather than just displaying tweets, it follows the links provided
        in your Twitter stream and displays that information (photos, YouTube videos,
        blog posts, etc.). It can't handle all the links and for example has problems
        with links to FriendFeed (very common in my Twitter feed).</p><p>To filter
        the information, you can also create sections from Twitter lists (or individual
        users). I had created lists with Science Journals (<a href=\"https://web.archive.org/web/20120628140034/https://twitter.com/mfenner/science-journals\">@mfenner/science-journals</a>)
        and Nature Network (<a href=\"https://web.archive.org/web/20120628140034/https://twitter.com/mfenner/nature-network\">@mfenner/nature-network</a>)
        bloggers in the past.</p><p>Twitter lists are great for following meetings
        (e.g. <a href=\"https://web.archive.org/web/20120628140034/https://twitter.com/BoraZ/scienceonline2010\">@BoraZ/scienceonline2010</a>),
        but unfortunately Flipboard doesn't yet allow to create sections from Twitter
        hashtags (e.g. <a href=\"https://web.archive.org/web/20120628140034/https://twitter.com/#search?q=%23scifoo\">#scifoo</a>).</p><p>When
        you click on an individual entry, you will see a longer text, and also Tweets
        referring to that time as well as a link to the full-text article.</p><figure
        class=\"kg-card kg-image-card\"><img src=\"https://web.archive.org/web/20120628140034im_/http://blogs.plos.org/mfenner/files/2010/11/flipboard7.jpg\"
        class=\"kg-image\" alt loading=\"lazy\"></figure><p>Flipboard does something
        similar with your Facebook News Feed. It is important to understand that Flipboard
        is not an RSS reader, but rather a visually pleasing aggregator from News
        in your Twitter and Facebook networks. Flipboard doesn't present all the information
        in these networks, but rather filters the most popular and \u201Cinteresting\u201D
        stuff.</p><p>How is Flipboard relevant to reading scholarly papers? It can
        be used out of the box for journals that tweet their table of contents or
        at least the most interesting papers. And everybody can create a Twitter account
        that retweets interesting papers in a particular subject area or from a particular
        institution (ideally this should be integrated with a bookmarking tool such
        as CiteULike). Scientific publishers could also work with Flipboard to integrate
        their content (you see in the example above that the scraping used by flipboard
        sometimes isn't perfect). Almost all scientific papers have an abstract. The
        abstract would display well in Flipboard, and could then link to the full
        text at the journal site.</p><p><em><em>To get started reading science blogs
        on Flipboard, add a ResearchBlogging.org section by subscribing to the @ResearchBlogs
        Twitter account.</em></em></p><p>Flipboard is of course also a great tool
        to follow science blogs. It probably works best if a new Twitter account is
        set up just for that purpose. This account could announce all new posts from
        a particular blog, or about a particular topic. Twitter lists could then be
        used for blogging networks such as <em><em>Nature Network</em></em> or <em><em>Scienceblogs.com</em></em>.
        Flipboard would also work very well to cover the blogging and tweeting of
        scientific conferences. With all these activities we will very soon need more
        than the nine sections that Flipboard supports.</p><p><em><em>Update 08/01/10:
        Added ResearchBlogging.org screenshot.</em></em></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Yet another look at blogging networks ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/yet-another-look-at-blogging-networks/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw56</id>\n        <published>2010-07-26T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-18T08:03:12.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/3849275338_d77a382643.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/3849275338_d77a382643.jpeg\"></p><p>The
        last few days we have seen a number of blog posts reflecting on the pros and
        cons of science blogging networks. Bora Zivkovic last week announced his departure
        from scienceblogs.com, and in his must-read post reflected on the history
        of science blogging (<a href=\"https://web.archive.org/web/20120611102940/http://scienceblogs.com/clock/2010/07/scienceblogs_and_me_and_the_ch.php\">A
        Farewell to Scienceblogs: the Changing Science Blogging Ecosystem</a>). Richard
        Grant on Saturday wrote down his thoughts <a href=\"https://web.archive.org/web/20120611102940/http://blogs.nature.com/rpg/2010/07/24/on-nature-network\">On
        Nature Network</a>. Cameron Neylon draws an interesting parallel between science
        networks and scientific journals (<a href=\"https://web.archive.org/web/20120611102940/http://cameronneylon.net/blog/the-nature-of-science-blog-networks/\">The
        Nature of Science Blog Networks</a>). And Katherine Haxton compared her experience
        blogging on Nature Network vs. blogging on her own blog (<a href=\"https://web.archive.org/web/20120611102940/http://www.possibilitiesendless.com/?p=270\">Science
        Blogging Networks</a>).</p><p>My thoughts on this: it's complicated. I don't
        see how blogging networks (or any particular network) can be inherently better
        or worse than setting up your own blog. It's an individual decision. Right
        now I like to write as part of a blogging network. But I may change my mind
        and write for a different network, or on an individually hosted blog. I would
        like to add three considerations to the discussion.</p><h3 id=\"consider-institutional-blogs\">Consider
        institutional blogs</h3><p>We shouldn't forget that there is also a third
        alternative to blogging networks and individually hosted blogs: a blog hosted
        by your institution. An institutional blog has a different set of advantages
        and disadvantages and is therefore not the right choice for everybody. But
        I will soon start an official blog for the cancer center of my medical school
        (I've gotten the green light from administration and the PR department, the
        WordPress 3.0 test system is set up, but it probably will be a few weeks before
        the first post). I have no intentions stopping the Gobbledygook blog \u2013
        the new blog will have a different focus, and it will be in German. <a href=\"https://web.archive.org/web/20120611102940/http://network.nature.com/profile/rpg\">Richard</a>
        have written institutional blogs for years, but this will be new for me \u2013
        and will also be the first official blog at our university.</p><h3 id=\"we-need-a-better-aggregator-for-science-blogs\">We
        need a better aggregator for science blogs</h3><p>Most of us probably have
        subscribed to a good number of science blogs with an RSS reader. The best
        way to find interesting new posts is probably through links in blogs we read
        regularly. In addition, we stumble upon interesting posts via links in blog
        networks, blog rolls, <em><em>Twitter</em></em>, <em><em>FriendFeed</em></em>,
        or shared items in <em><em>Google Reader</em></em>.</p><p>In addition, we
        also need a good aggregator of science blogs. I have to admit that I have
        stopped using <em><em>Technorati</em></em> a while ago. <a href=\"https://web.archive.org/web/20120611102940/http://blogs.nature.com/\">Nature.com
        Blogs</a> was a good start, and <a href=\"https://web.archive.org/web/20120611102940/http://www.researchblogging.org/\">ResearchBlogging</a>
        does a good job of covering blog posts about peer-reviewed literature. But
        we probably can do much better. Whether the best strategy would be to put
        more resources into one of the existing services (see also Lou's <a href=\"https://web.archive.org/web/20120611102940/http://blogs.nature.com/rpg/2010/07/24/on-nature-network#comment-61864\">comment</a>
        from earlier today), or whether to start building something new, I don't know.
        But there is a lot of potential for building a better discovery service that
        at the same time will become an interesting archive of what the science blogosphere
        is talking about. <a href=\"https://web.archive.org/web/20120611102940/http://blogs.nature.com/mfenner/2009/08/20/streamosphere-interview-with-euan-adie\">Streamosphere</a>
        is already a good step in the right direction.</p><h3 id=\"personal-interactions-are-important\">Personal
        interactions are important</h3><p>It is usually much more rewarding to interact
        with someone online whom you have also met in person. This is true not only
        for scientific collaborations, but of course also for social media. This is
        obviously much easier if you live in places like London, but even Hannover
        (where I live) has a really nice <a href=\"https://web.archive.org/web/20120611102940/http://blogs.nature.com/mfenner/2010/05/11/action-points\">Science
        2.0 community</a>. And this is why science blogging conferences such as <a
        href=\"https://web.archive.org/web/20120611102940/http://www.scienceonline2010.com/index.php/wiki/\">ScienceOnline2010</a>
        or <a href=\"https://web.archive.org/web/20120611102940/http://www.scienceonlinelondon.org/\">Science
        Online London 2010</a> are so important. Science Online London is only six
        weeks away (September 3-4 at the British Library), and I'm really excited
        not only about the program, but also because of all the people I will for
        the first time or again meet in person.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Discuss Papers with JournalFire ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/discuss-papers-with-journalfire/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw57</id>\n        <published>2010-07-05T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T07:44:23.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>About a year ago I wrote a
        blog post about how to use Web 2.0 tools for a journal club (<a href=\"https://web.archive.org/web/20120611103044/http://blogs.nature.com/mfenner/2009/08/08/recipe-distributing-papers-for-a-journal-club\">Recipe:
        Distributing papers for a journal club</a>). Although reference management
        tools such as <em><em>CiteULike</em></em> and <em><em>Mendeley</em></em> can
        be used for journal clubs, discussion features are often more of an afterthought.
        At the time I therefore recommended FriendFeed. In February of this year,
        ScienceFeed was released (<a href=\"https://web.archive.org/web/20120611103044/http://blogs.nature.com/mfenner/2010/02/15/sciencefeed-interview-with-ijad-madisch\">ScienceFeed:
        Interview with Ijad Madisch</a>). It is very similar to FriendFeed, but is
        smarter about finding and storing references to scientific literature. Unfortunately
        ScienceFeed integrates very tightly with ResearchGate. You have to sign up
        for both services to use the reference management features.</p><p>Last week
        a new web-based tool specifically for Journal Clubs was released. <a href=\"https://web.archive.org/web/20120611103044/http://journalfire.com/\">JournalFire</a>
        was created by <a href=\"https://web.archive.org/web/20120611103044/http://journalfire.com/johnmdelacruz\">John
        Delacruz</a>, <a href=\"https://web.archive.org/web/20120611103044/http://journalfire.com/riccardoschmid\">Riccardo
        Schmid</a> and <a href=\"https://web.archive.org/web/20120611103044/http://journalfire.com/timhill\">Tim
        Hill</a>. JournalFire is free for public discussion groups, but costs money
        for private groups with more than 4 members.</p><figure class=\"kg-card kg-image-card\"><img
        src=\"https://web.archive.org/web/20120611103044im_/http://blogs.plos.org/mfenner/files/2010/11/journalfire.jpg\"
        class=\"kg-image\" alt loading=\"lazy\"></figure><p>Feel free to participate
        in the discussion about this article <a href=\"https://web.archive.org/web/20120611103044/http://journalfire.com/node/70269107\">here</a>.
        I've picked a paper that is not only freely available and nicely written,
        but also in a very hot field.</p><h3 id=\"what-i-like\">What I like</h3><p>JournalFire
        really focuses on discussion around a paper. Journal Clubs are used to organize
        the discussion, similar to groups in other tools. The interface is uncluttered,
        and almost everything is available as RSS feed.</p><h3 id=\"what-i-would-like\">What
        I would like</h3><p>JournalFire was just released publicly, so it obviously
        doesn't have all the features of a more mature product. More importantly,
        JournalFire covers a fairly specific reference management niche, it is therefore
        important that data exchange with other reference management tools is as easy
        as possible.<br>JournalFire has a bookmarklet similar to what other reference
        managers offer, and you can export one or more references in Endnote or BibTex
        format. <a href=\"https://web.archive.org/web/20120611103044/http://ocoins.info/\">COinS</a>
        support should be an obvious addition, and an API would allow tighter integration
        with other tools, e.g. to add Journal Club features to your CiteULike, Mendeley
        or Zotero library.</p><p>The Journal Club concept of JournalFire fills a very
        interesting niche. But in the end, social tools for scientists are about critical
        mass. It will be interesting to see whether JournalFire can attract enough
        users in this very crowded market.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Innovations in Reference Management ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/innovations-in-reference-management/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw54</id>\n        <published>2010-06-22T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-01T06:22:04.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Earlier today
        I attended the fabulous <a href=\"https://web.archive.org/web/20120611100639/http://www.open.ac.uk/telstar/event\">Innovations
        in Reference Management</a> workshop in Birmingham organized by <a href=\"https://web.archive.org/web/20120611100639/http://www.twitter.com/ostephens\">Owen
        Stephens</a> from Open University. Owen has written <a href=\"https://web.archive.org/web/20120611100639/http://www.open.ac.uk/blogs/telstar/tag/irm10/\">some
        blog posts</a> summarizing the sessions almost in real time. You also find
        a good number of interesting tweets under the hashtag <a href=\"https://web.archive.org/web/20120611100639/http://twitter.com/#search?q=%23irm10\">#irm10</a>.
        My presentation was called <em><em>Trends in Reference Management</em></em>:</p><p>I
        started my presentation by giving a brief historical perspective on how reference
        management has evolved during the past 25 years. It seems as if many users
        today use reference managers the same way as users did in 1992 (when <a href=\"https://web.archive.org/web/20120611100639/http://dx.doi.org/10.1021/ci00010a601\">this
        review of Endnote</a> was written): a database of (mostly) journal articles
        installed on your desktop computer that can fetch references directly from
        online databases (in 1992 we had Endlink and the Z39.50 protocol for that)
        and that inserts bibliographies into Microsoft Word. It is odd that many seemingly
        old problems still exist today:</p><ul><li>Digital Object Identifiers (<a
        href=\"https://web.archive.org/web/20120611100639/http://www.doi.org/\">DOIs</a>)
        were introduced in 2000, and many journals not only are using them, but also
        exist only as electronic versions. Nevertheless most citation styles still
        use volumes, issues and page numbers instead of the DOI. And some journals
        and online databases (e.g. PubMed) still don\u2019t display the DOI prominently,
        but rather use their own numbering scheme.</li><li>Most reference managers
        allow sharing of reference in private or public groups. We have collaborative
        writing tools (Google Docs, Zoho Writer, Adobe Buzzword, and now even <a href=\"https://web.archive.org/web/20120611100639/http://workspace.officelive.com/\">Microsoft
        Office Live Workspace</a>) since at least 2006, but I think that no reference
        manager supports them beyond a simple copy and past function.</li><li>Almost
        all journal articles can be downloaded as PDF files, but users are still confused
        what they are allowed to do with these PDFs. Many publishers don\u2019t even
        allow redistribution of these PDFs within an institution (e.g. for a journal
        club), something that is probably often ignored. These problems obviously
        don\u2019t exist for Open Access publications, but it again gets complicated
        with those publishers that use a <a href=\"https://web.archive.org/web/20120611100639/http://creativecommons.org/licenses/by-nc/3.0/\">Creative
        Commons Noncommercial license</a>. And to the best of my knowledge, no reference
        manager is providing copyright information for its references.</li></ul><h3
        id=\"mobile-applications-for-reference-management\">Mobile Applications for
        Reference Management</h3><p>In the next part of my presentation I briefly
        talked about some of the mobile applications handling scientific journal articles
        (<a href=\"https://web.archive.org/web/20120611100639/http://www.nature.com/mobileapps/\">Nature</a>,
        <a href=\"https://web.archive.org/web/20120611100639/http://speakingofmedicine.plos.org/2010/03/22/introducing-the-plos-medicine-iphone-application/\">PLoS
        Medicine</a>, <a href=\"https://web.archive.org/web/20120611100639/http://blogs.nejm.org/now/index.php/introducing-the-nejm-this-week-iphone-app/2010/06/18/\">NEJM</a>
        and <a href=\"https://web.archive.org/web/20120611100639/http://info.scopus.com/mobile\">Scopus</a>
        for iPhone and <a href=\"https://web.archive.org/web/20120611100639/http://itunes.apple.com/us/app/plos-reader/id370880976\">PLoS
        Reader</a> and <a href=\"https://web.archive.org/web/20120611100639/http://mekentosj.com/papers/ipad/\">Papers
        for iPad</a>) that have been released in the last few months. The small screen
        of mobile phones makes it difficult to read scientific papers (especially
        the tables and figures). The best use case is probably the scanning of journal
        table of contents or search alerts with bookmarking of interesting papers
        for later reading. In other words, a perfect job for a RSS reader synchronized
        with the desktop.</p><p>The iPad is a very different story, as for me it is
        a very good device for reading a scientific paper \u2013 better than a desktop
        computer and even better than a printout if you don\u2019t have a color printer.
        And <a href=\"https://web.archive.org/web/20120611100639/http://mekentosj.com/papers/ipad/\">Papers
        for iPad</a> is the perfect software for this use case, especially if you
        also own Papers for Mac and can simply transfer all your PDF files complete
        with reference information to the iPad.</p><h3 id=\"orcid\">ORCID</h3><p>I
        then moved on to give a brief introduction to the <a href=\"https://web.archive.org/web/20120611100639/http://www.orcid.org/\">ORCID</a>
        initiative (most of my slides were kindly provided my <a href=\"https://web.archive.org/web/20120611100639/http://www.slideshare.net/CrossRef/crossref-contributor-id\">Geoff
        Bilder</a> and <a href=\"https://web.archive.org/web/20120611100639/http://www.slideshare.net/hratner/introduction-to-orcid-stm-spring-2010\">Howard
        Ratner</a>). Open Researcher &amp; Contributor ID aims to provide a universal
        unique identifier for researchers. Past approaches have not gained universal
        acceptance because they were restricted to a particular discipline (e.g. <a
        href=\"https://web.archive.org/web/20120611100639/http://www.repec.org/\">RePEec</a>),
        country (e.g. <a href=\"https://web.archive.org/web/20120611100639/http://www.slideshare.net/amandahill/names-project-update\">Names
        Project</a>) or were started by a single private company (e.g. <a href=\"https://web.archive.org/web/20120611100639/http://info.scopus.com/scopus-in-detail/tools/authoridentifier/\">Scopus
        Author Identifier</a>). ORCID is a broad initiative with already more than
        100 <a href=\"https://web.archive.org/web/20120611100639/http://www.orcid.org/gallery.php\">participating
        organizations</a>. ORCID <a href=\"https://web.archive.org/web/20120611100639/http://dx.doi.org/10.1038/462825a\">was
        announced</a> in December 2009, and the initiative is currently working hard
        to first incorporate as a non-profit organization and then launch a first
        public prototype (based on the <a href=\"https://web.archive.org/web/20120611100639/http://www.researcherid.com:80/Home.action\">ResearcherID</a>
        software). Both milestones are planned for later this year.</p><p>Reference
        managers will of course benefit from a widely accepted author identifier,
        e.g. by making it much easier to find all publications from a particular author.
        ORCID can also be used to track other scientific contributions, e.g. peer
        review, blog posts, presentations or primary research datasets. Reference
        managers could also track (some of) these contributions by researchers.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Using Twitter at the ASCO Conference ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/using-twitter-at-the-asco-conference/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw55</id>\n        <published>2010-06-15T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-01T06:21:00.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Last week
        I attended the annual meeting of the <a href=\"https://web.archive.org/web/20120630144308/http://www.asco.org/\">American
        Society of Clinical Oncology</a> (ASCO) in Chicago. For my work it is the
        most important scientific meeting of the year, and it is also by far the biggest
        with more than 30.000 participants.</p><figure class=\"kg-card kg-image-card
        kg-card-hascaption\"><img src=\"https://web.archive.org/web/20120630144308im_/http://farm5.static.flickr.com/4010/4691440146_bcaea61ee0.jpg\"
        class=\"kg-image\" alt loading=\"lazy\"><figcaption>Chicago last Thursday.
        Flickr image by ifmuth.</figcaption></figure><p>Blogging is a great way to
        <a href=\"https://web.archive.org/web/20120630144308/http://blogs.nature.com/mfenner/2010/01/17/scienceonline2010-i-wish-i-was-there\">report
        from conferences</a>, and for me <em><em>FriendFeed</em></em> is the best
        microblogging tool to do that. Its use at the 2008 ISMB conference was nicely
        described in a <em><em>PLoS Comp Biol</em></em> paper (<a href=\"https://web.archive.org/web/20120630144308/http://dx.doi.org/10.1371/journal.pcbi.1000263\">doi:10.1371/journal.pcbi.1000263</a>)
        by Neil Saunders et al. Unfortunately it seems as if the use of FriendFeed
        is declining at every online science conference I go to, as everybody seems
        to be switching to <em><em>Twitter</em></em>. At the <a href=\"https://web.archive.org/web/20120630144308/http://bibcamp.wordpress.com/\">BibCamp</a>
        that we organized in May we didn't even bother trying FriendFeed (or similar
        microbloging tools such as Google Buzz, ScienceFeed, <a href=\"https://web.archive.org/web/20120630144308/http://hotpotato.com/\">Hot
        Potato</a>, <a href=\"https://web.archive.org/web/20120630144308/http://www.snapgroups.com/\">Snapgroups</a>
        or Google Wave).</p><p>My main problem with using Twitter at conferences is
        that it is difficult to connect all tweets talking about a particular session
        together. General hashtags like <em><em>#asco10</em></em> are not a solution
        for conferences with several thousand tweets. The ASCO conference organizers
        asked us to use two <a href=\"https://web.archive.org/web/20120630144308/http://www.asco.org/ascov2/MyASCO/Twitter\">special
        hash tags</a> for some sessions, but it seemed as if almost nobody was using
        them. I would not be surprised if someone invents (or has already done so)
        a nice service that connects tweets to conference sessions.</p><p>Another
        shortcoming of Twitter is the lack of automatic long-term archiving. Therefore
        <a href=\"https://web.archive.org/web/20120630144308/http://www.twitter.com/RMEOncology\">@RMEOncology</a>
        created a Twapper Keeper that was <a href=\"https://web.archive.org/web/20120630144308/http://twapperkeeper.com/hashtag/asco10\">used
        to archive</a> the about 4500 tweets with the <em><em>#asco10</em></em> hashtag.
        You can do interesting things with such an archive, Cornelius Puschmann did
        an <a href=\"https://web.archive.org/web/20120630144308/http://wisspub.net/2010/05/11/bibcamp-auswertung/\">analysis</a>
        of the Twitter activity at our recent <a href=\"https://web.archive.org/web/20120630144308/http://blogs.nature.com/mfenner/2010/05/11/action-points\">BibCamp</a>
        using the R statistical software.</p><p>On the second conference day we were
        invited by the ASCO organizers to a tweetup. We were twice as many people
        compared to the tweetup at last year's ASCO (including one familiar face,
        <a href=\"https://web.archive.org/web/20120630144308/http://www.twitter.com/MaverickNY\">@MaverickNY</a>).
        We had an interesting discussion for about an hour. The most important message
        for me: we were encouraged to freely tweet about the sessions, restricted
        only by common sense and not a particular policy. A large meeting like ASCO
        with a lot of press coverage and videotaping of most sessions obviously has
        it easier to allow widespread Twitter use than a smaller meeting like the
        Cold Spring Harbor Biology of Genomes meeting. The discussions at that meeting
        in May were nicely covered by <a href=\"https://web.archive.org/web/20120630144308/http://scienceblogs.com/geneticfuture/2010/05/what_a_difference_a_year_makes.php\">Daniel
        MacArthur</a> and <a href=\"https://web.archive.org/web/20120630144308/http://embargowatch.wordpress.com/2010/05/24/can-you-tweet-from-cold-spring-harbor-laboratory-meetings/\">Ivan
        Oransky</a>.</p><p>ASCO was also the first conference that I attended with
        an iPad. We had free WiFi (that worked in most places) and the iPad was great
        to write Tweets, look through the PDF of the sessions and posters I wanted
        to see (created back home), and to keep in touch via email and Skype. The
        only caveat: adding links to Tweets was difficult without multitasking \u2013
        although this should become easier with the soon to be released iOS 4.</p><p>I
        did not like all Tweets about the conference. Twitter was obviously also used
        as a marketing tool. Although there is nothing wrong with that, some pharma
        companies felt it necessary to tweet exactly the same message again and again.
        I would have like more tweets reporting key findings from the sessions and/or
        adding comments or interesting links (e.g. with background information). But
        I'm optimistic that Twitter coverage at ASCO11 will be even better, and that
        by ASCO12 Twitter will be as mainstream and popular as email was at ASCO10.</p><p><em><em>Starting
        tomorrow, I will also write for the <a href=\"https://web.archive.org/web/20120630144308/http://lindau.nature.com/\">Lindau
        Nobel Laureate Meeting</a> blog (the meeting itself will start June 27). The
        Nature Network blog has <a href=\"https://web.archive.org/web/20120630144308/http://blogs.nature.com/u6e5b2ce1/2010/06/15/nature-at-the-lindau-nobel-laureates-meeting-2010\">more
        info</a> about the event.</em></em></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ On Privacy ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/on-privacy/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw53</id>\n        <published>2010-05-24T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-18T08:04:57.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/2404940312_e759c4030d.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/2404940312_e759c4030d.jpeg\"></p><p>Social
        media and privacy have a complicated relationship, as using social media implies
        giving up at least some privacy. And the value of a social networking site
        is directly related not only to the number of users, but also the extend of
        personal data that the site has collected. All this is of course not unique
        to social networking tools for scientists, but conducting science using online
        tools is different from connecting to friends or people with similar personal
        interests with these tools. One area where privacy issues are particularly
        prominent is the creation of unique identifiers for scientists, and here I'm
        involved in the <a href=\"https://web.archive.org/web/20120611031846/http://www.orcid.org/\">ORCID</a>
        initiative. We need a discussion about required privacy standards, and about
        the limitations of privacy that we accept in order to increase our scientific
        productivity.</p><p>I've collected a couple of thoughts below. They are of
        course only starting points for a discussion, and I welcome any comments and
        suggestions.</p><h3 id=\"1-the-service-allows-anonymous-access\">1. The service
        allows anonymous access</h3><p>Social networking sites for scientists can
        be quite useful for anonymous users, e.g. for reading of blog or forum posts.
        Users should not be required to sign up for a service just for reading a public
        message or looking at the public part of a user profile. Many social networking
        sites unfortunately require a user account these activities, and they often
        nag users to \u201Ccomplete their personal profiles\u201D, i.e. to provide
        as much personal information as possible.</p><h3 id=\"2-the-service-has-a-privacy-policy\">2.
        The service has a privacy policy</h3><p>I've randomly checked five social
        networking sites for scientists, and they all provide a privacy policy:</p><ul><li><a
        href=\"https://web.archive.org/web/20120611031846/http://www.academia.edu/privacy\">Academia.edu</a></li><li><a
        href=\"https://web.archive.org/web/20120611031846/http://www.citeulike.org/privacy\">CiteULike</a></li><li><a
        href=\"https://web.archive.org/web/20120611031846/http://www.mendeley.com/privacy/\">Mendeley</a></li><li><a
        href=\"https://web.archive.org/web/20120611031846/http://network.nature.com/site/privacy\">Nature
        Network</a></li><li><a href=\"https://web.archive.org/web/20120611031846/http://www.researchgate.net/application.PrivacyPolicy.html\">ResearchGate</a></li></ul><p>The
        privacy policy should make clear what user data the service is collecting,
        whether the service is providing these user data to third parties, and should
        provide an email address for further privacy questions.</p><h3 id=\"3-personal-data-are-owned-by-the-user\">3.
        Personal data are owned by the user</h3><p>All personal data that a user uploads
        should be owned by the user, and the privacy policy should make this clear.
        This implies that a user should be allowed to cancel an account and delete
        all personal information (surprisingly difficult with most social networking
        sites), and that the user decides which part of the personal data is shared
        with others, and with whom.</p><p>To give users control over their privacy
        settings, these settings should default to not being public for everything
        beyond the most basic information, and they should not change over time (<a
        href=\"https://web.archive.org/web/20120611031846/http://mattmckeon.com/facebook-privacy/\">The
        Evolution of privacy on Facebook</a>).</p><p>Obviously, there is a large grey
        area. If I comment on a blog post by someone else, who owns this comment,
        and who should be allowed to delete this comment \u2013 me, the author of
        the blog post, and/or the provider of the social networking site? And who
        owns my usage data of a service, how often I logged in, my activity in the
        service, etc.?</p><h3 id=\"4-the-service-protects-the-user-data\">4. The service
        protects the user data</h3><p>The social networking site should make all efforts
        necessary to protect the personal data of a user. There are examples where
        this has gone wrong, and this includes examples involving scientists (<a href=\"https://web.archive.org/web/20120611031846/http://www.nature.com/news/2009/090423/full/news.2009.398.html\">Fake
        Facebook pages spin web of deceit</a>).</p><p><em><em>Update 5/25/10: I didn't
        see it when I wrote the post, but last week the Electronic Frontier Foundation
        published a <a href=\"https://web.archive.org/web/20120611031846/http://www.eff.org/deeplinks/2010/05/bill-privacy-rights-social-network-users\">Bill
        of Privacy Rights for Social Network Users</a> (thanks to Renny Guida for
        the link).</em></em></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ What is a reference manager? ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/what-is-a-reference-manager/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw52</id>\n
        \       <published>2010-05-19T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-01T06:20:11.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Next month
        I will participate in the <a href=\"https://web.archive.org/web/20120611032215/http://www.open.ac.uk/telstar/event/programmet\">Innovations
        in Reference Management</a> event organized by <a href=\"https://web.archive.org/web/20120611032215/http://twitter.com/ostephens\">Owen
        Stevens</a> from the Open University. My own presentation has the title <em><em>Trends
        in Reference Management</em></em>, where I will try to focus on three emerging
        areas:</p><ul><li>Use of mobile devices for reference management (e.g. <a
        href=\"https://web.archive.org/web/20120611032215/http://blogs.nature.com/mfenner/2010/02/08/nature-com-iphone-app-in-pictures\">Nature.com
        iPhone App</a>, <a href=\"https://web.archive.org/web/20120611032215/http://mekentosj.com/papers/ipad/\">Papers
        for iPad</a>, <a href=\"https://web.archive.org/web/20120611032215/http://info.scopus.com/mobile/\">Scopus
        Alerts for iPhone</a>)</li><li>Social networks as discovery tools (using CiteULike,
        Twitter, FriendFeed, ResearchBlogging.org, etc. for finding relevant references
        instead of keyword searches in databases)</li><li>Integration of unique author
        identifiers (specifically <a href=\"https://web.archive.org/web/20120611032215/http://blogs.nature.com/mfenner/2010/01/03/orcid-or-how-to-build-a-unique-identifier-for-scientists-in-10-easy-steps\">ORCID</a>)
        into reference management tools. This will allow many interesting uses of
        reference lists (e.g. for automated researcher profiles or evaluation)</li></ul><p>Reference
        management has obviously come a long way from the desktop applications <a
        href=\"https://web.archive.org/web/20120611032215/http://dx.doi.org/10.1021/ci00010a601\">created
        25 years ago</a>. In 2010 it is difficult to give a good description of the
        typical functions of reference managers. My 8 answers are below.</p><figure
        class=\"kg-card kg-image-card\"><img src=\"https://web.archive.org/web/20120611032215im_/http://blogs.plos.org/mfenner/files/2010/11/refman1.jpg\"
        class=\"kg-image\" alt=\"refman1.jpg\" loading=\"lazy\"></figure><p>At their
        core all reference managers are databases that store references. They should
        allow the user to create or import all required reference types, find duplicate
        records, and connect references by the same author or published in the same
        journal. I don't think any reference manager completely supports even this
        small feature set (most of them don't do author disambiguation). And we rarely
        use reference managers in a much broader sense, e.g. for storing important
        blog posts or references to research datasets (as <a href=\"https://web.archive.org/web/20120611032215/http://bit.ly/do6Ujj\">suggested
        by Cameron Neylon</a>).</p><figure class=\"kg-card kg-image-card\"><img src=\"https://web.archive.org/web/20120611032215im_/http://blogs.plos.org/mfenner/files/2010/11/refman2.jpg\"
        class=\"kg-image\" alt=\"refman2.jpg\" loading=\"lazy\"></figure><p>Reference
        managers should put references into manuscripts, allowing a variety of citation
        styles. Only a few reference managers allow the user to edit citation styles,
        an important feature if an obscure style is required. Surprisingly, the functionality
        for reference management is usually not built into most word processors, but
        rather provided by the reference management software.</p><figure class=\"kg-card
        kg-image-card\"><img src=\"https://web.archive.org/web/20120611032215im_/http://blogs.plos.org/mfenner/files/2010/11/refman3.jpg\"
        class=\"kg-image\" alt=\"refman3.jpg\" loading=\"lazy\"></figure><p>All reference
        managers can import references directly from bibliographic databases, either
        by direct database connections, or via bookmarklets.</p><figure class=\"kg-card
        kg-image-card\"><img src=\"https://web.archive.org/web/20120611032215im_/http://blogs.plos.org/mfenner/files/2010/11/refman4.jpg\"
        class=\"kg-image\" alt=\"refman4.jpg\" loading=\"lazy\"></figure><p>Some reference
        managers (most notably <a href=\"https://web.archive.org/web/20120611032215/http://mekentosj.com/papers/\">Papers</a>)
        not only manage references, but also organize the full-text PDF files associated
        with them. There are many good reasons to keep the assets (such as scientific
        papers) and their metadata (the references) connected, e.g. to allow full-text
        searches in your reference manager. Scientific journals have started to embed
        reference metadata in full-text PDF files (<a href=\"https://web.archive.org/web/20120611032215/http://blogs.nature.com/wp/nascent/2008/12/xmp_labelling_for_nature.html\">XMP
        Labelling for Nature</a>), making it easier to connect reference and PDF file.</p><figure
        class=\"kg-card kg-image-card\"><img src=\"https://web.archive.org/web/20120611032215im_/http://blogs.plos.org/mfenner/files/2010/11/refman5.jpg\"
        class=\"kg-image\" alt=\"refman5.jpg\" loading=\"lazy\"></figure><p>Many reference
        managers now offer a web-based version. This allows using the same reference
        database with more than one computer and sharing of references with others.
        Some reference managers (e.g. CiteULike, RefWorks) only provide a web-based
        version.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://web.archive.org/web/20120611032215im_/http://blogs.plos.org/mfenner/files/2010/11/refman6.jpg\"
        class=\"kg-image\" alt=\"refman6.jpg\" loading=\"lazy\"></figure><p>Many bibliographic
        databases (e.g. PubMed or Scopus) now allow user accounts with storing of
        search strategies, interesting references, etc. Does that make them reference
        managers?</p><figure class=\"kg-card kg-image-card\"><img src=\"https://web.archive.org/web/20120611032215im_/http://blogs.plos.org/mfenner/files/2010/11/refman7.jpg\"
        class=\"kg-image\" alt=\"refman7.jpg\" loading=\"lazy\"></figure><p>The flow
        of reference information has become much more complicated than simply from
        online database to reference manager to manuscript. <a href=\"https://web.archive.org/web/20120611032215/http://blogs.nature.com/mfenner/2010/05/03/bibapp-mashups-for-universities\">Institutional
        bibliographies</a> are a good example.</p><figure class=\"kg-card kg-image-card\"><img
        src=\"https://web.archive.org/web/20120611032215im_/http://blogs.plos.org/mfenner/files/2010/11/refman8.jpg\"
        class=\"kg-image\" alt=\"refman8.jpg\" loading=\"lazy\"></figure><p>More and
        more we find interesting references not via keyword searches in databases,
        but rather through our social networks. This could be via <a href=\"https://web.archive.org/web/20120611032215/http://blog.citeulike.org/?p=136\">CiteULike
        recommendations</a>, blog posts discussing a paper on ResearchBlogging.org,
        or one of your contacts talking about an interesting paper on Twitter, FriendFeed
        or Facebook. Current reference managers don't provide good functionality to
        handle this user behavior.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Action points ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/action-points/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw51</id>\n        <published>2010-05-11T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-19T07:56:29.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/p1060059.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/p1060059.jpeg\"></p><p>Last
        weekend was <em><em>BibCamp Hannover</em></em>, a \u201CBarCamp for librarians
        and other hackers\u201D. If you understand German, you can read about the
        sessions, discussions and people in the <a href=\"https://bibcamp.wordpress.com/\">Blog</a>,
        <a href=\"http://bibcamp.pbworks.com/browse/#view=ViewFolder&amp;param=BibCamp%202010\">Wiki</a>,
        and <a href=\"https://web.archive.org/web/20120611033833/http://friendfeed.com/bibcamp\">FriendFeed
        Room</a>. And Steffi Suhr wrote a nice post about <a href=\"http://blogs.nature.com/stuffysour/2010/05/09/the-most-beautiful-library-in-the-world\">The
        most beautiful library in the world</a> in her <em><em>Nature Network</em></em>
        blog.</p><p>The BarCamp format worked very well for us \u2013 we used traditional
        pen and paper for session planning:</p><figure class=\"kg-card kg-image-card
        kg-card-hascaption\"><img src=\"https://blog.front-matter.io/content/images/2022/08/p1060059-1.jpeg\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"500\" height=\"375\"><figcaption>Me,
        helping with session planning last Friday. Picture by <a href=\"http://edlf.wordpress.com/2010/05/07/bibcamp-2010-tag-1/\">Martin
        Kramer</a> .</figcaption></figure><p>I had suggested a session about <a href=\"https://blog.front-matter.io/posts/bibapp-mashups-for-universities\">Institutional
        Bibliographies</a>. We combined this with two related suggestions and had
        a very interesting session about the communication of scientists with librarians.
        One interesting theme in the discussion was the notion that the scientific
        workflow seems to be broken at some specific steps, for example:</p><h3 id=\"deposition-of-post-prints-in-institutional-repositories\">Deposition
        of post-prints in institutional repositories</h3><p>Most journals allow authors
        to make the final version of an accepted manuscript (i.e. after peer review)
        <a href=\"http://www.sherpa.ac.uk/romeoinfo.html#prepostprints\">publicly
        available</a> via an institutional repository. Most librarians would be happy
        to help their authors with this step, but unfortunately have no good tools
        to track the papers published at their institution, and never see the final
        version of the accepted manuscript (many journals don't allow publisher-generated
        PDFs in repositories).</p><h3 id=\"re-submission-of-rejected-manuscripts\">Re-submission
        of rejected manuscripts</h3><p>Rejected manuscripts are usually resubmitted
        to a different journal (most manuscripts will eventually be published <a href=\"https://doi.org/10.1097/01.ede.0000254668.63378.32\">somewhere</a>).
        Unfortunately the next journal will most likely use a different manuscript
        format, different citation styles and a different manuscript submission system.
        Some journals provide a <a href=\"https://www.nature.com/authors/author_services/transfer_manuscripts.html\">manuscript
        transfer service</a>, but the comments made in the peer review are usually
        not available to the editors and reviewers of the next journal.</p><h3 id=\"connecting-scientists-to-publications\">Connecting
        scientists to publications</h3><p>This is a topic that I have written about
        before (<a href=\"https://blog.front-matter.io/posts/orcid-or-how-to-build-a-unique-identifier-for-scientists-in-10-easy-steps\">ORCID
        or how to build a unique identifier for scientists in 10 easy steps</a>).
        Until we have unique author identifiers, it is difficult or impossible to
        reliably find the papers published by a particular person (a good number of
        papers by <em><em>Fenner M</em></em> in <em><em>PubMed</em></em> are not written
        by me).</p><h3 id=\"distributing-papers-for-a-journal-club\">Distributing
        papers for a journal club</h3><p>Another topic I have written about before
        (<a href=\"https://blog.front-matter.io/posts/recipe-distributing-papers-for-a-journal-club\">Recipe:
        Distributing papers for a journal club</a>). The problem is not only that
        email is really bad for sending PDF files to a group of people, but that most
        journals don't allow redistribution of their content, even within an institution
        with an institutional subscription.</p><h3 id=\"citation-counts\">Citation
        counts</h3><p>The number of times a paper is cited is often used as a proxy
        to the importance of the science in that paper. Citation counts (e.g. in the
        form of Impact Factor or H-Index) are often used to evaluate researchers.
        There are many problems with this approach, because citation counts are influenced
        by many other factors (e.g. time, popularity of the subject area, self-citations).
        But the biggest problem is the fact that there is no general agreement on
        how to count citations, and no database that makes this information freely
        available.</p><p>It might make sense to make a list of these broken steps,
        and then estimate the effort that would be required to fix each of them. Some
        broken steps are more important, and some fixes easier than others, so this
        exercise would give a good list of action points.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ BibApp: Mashups for Universities ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/bibapp-mashups-for-universities/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw50</id>\n        <published>2010-05-03T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-18T08:08:50.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/4572784486_52fff91a71.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/4572784486_52fff91a71.jpeg\"></p><p>Friday
        afternoon discussions can be dangerous. Last Friday I talked with <a href=\"https://web.archive.org/web/20120611032822/http://network.nature.com/people/UC0402CE6/profile\">Heinz
        Pampel</a> from the <a href=\"https://web.archive.org/web/20120611032822/http://oa.helmholtz.de/index.php?id=137\">Helmholtz
        Open Access Initiative</a> via email about the upcoming <a href=\"https://web.archive.org/web/20120611032822/http://bibcamp.wordpress.com/\">BibCamp
        Hannover</a> (a barcamp for librarians and others interested in online science
        that will take place this weekend). I said that I was looking for a solution
        to make the list of publications from our institution more accessible \u2013
        we currently store them in a regularly updated <a href=\"https://web.archive.org/web/20120611032822/http://www.refworks.com/refshare/?site=047931198224000000%2F\">RefWorks
        database</a>. Heinz not only told me that there is actually a name for this
        kind of tool (Current Research Information System or <a href=\"https://web.archive.org/web/20120611032822/http://www.cris2010.org/\">CIRS</a>),
        but also gave me some good links. <a href=\"https://web.archive.org/web/20120611032822/http://espace.library.uq.edu.au/eserv/UQ:152805/Simon_Porter.pdf\">This
        talk</a> by Simon Porter from the University of Melbourne is for example a
        very good introduction to the topic.</p><p>Heinz also suggested <a href=\"https://web.archive.org/web/20120611032822/http://bibapp.org/\">BibApp</a>,
        a nice web-based tool for exactly this purpose written in the <em><em>Ruby
        on Rails</em></em> programming language. Because I am a <a href=\"https://web.archive.org/web/20120611032822/http://www.mh-hannover.de/studien/en/\">very
        familiar with Ruby on Rails</a>, I took a closer look.</p><p><a href=\"https://web.archive.org/web/20120611032822/http://vimeo.com/2104723\">Bibapp
        \u2013 Find Campus Experts</a> from <a href=\"https://web.archive.org/web/20120611032822/http://vimeo.com/user885968\">Eric
        Larson</a> on <a href=\"https://web.archive.org/web/20120611032822/http://vimeo.com/\">Vimeo</a>.</p><p>In
        the end I spent a good deal of this weekend setting up <em><em>BibApp</em></em>,
        importing all publications from our institution since 2008 via <em><em>Refworks</em></em>,
        starting to add researchers and research groups and adjusting <em><em>BibApp</em></em>
        to our needs (mainly changing the layout to our institution style and starting
        to translate the templates into German). <em><em>BibApp</em></em> is already
        a fully working system and is telling me some interesting things. This includes
        many interesting papers from our institution that I didn't know about, but
        also that two researchers each have published more than 150 papers in two
        years, and that my colleagues have published 6 papers in <a href=\"https://web.archive.org/web/20120611032822/http://www.timeshighereducation.co.uk/story.asp?storycode=411168\">Medical
        Hypotheses</a> since 2008. The technical aspects of setting up <em><em>BibApp</em></em>
        are almost solved (it helps that I run two other <em><em>Ruby on Rails</em></em>
        applications at my institution), so now I have to convince our library and
        administration that it's worth having (and maintaining) such a CRIS tool.</p><p><a
        href=\"https://web.archive.org/web/20120611032822/http://blogs.nature.com/mfenner/2010/04/17/improving-the-conduct-of-science\">Two
        weeks ago I wrote about the upper part of the figure</a> (for a <em><em>NSF</em></em>
        workshop that got postponed to September because of the Volcano ash). As far
        as I can see, there is no standard between funding agencies for grant reporting,
        and both DataCite and ORCID are fairly new initiatives.</p><p>The CRIS can
        be used to facilitate access to institutional repositories or primary research
        datasets. <em><em>BibApp</em></em> supports the <a href=\"https://web.archive.org/web/20120611032822/http://www.ariadne.ac.uk/issue54/allinson-et-al/\">SWORD</a>
        protocol for article deposition, and it automatically checks all papers against
        the <a href=\"https://web.archive.org/web/20120611032822/http://www.sherpa.ac.uk/romeo/\">ROMEO</a>
        database of publisher copyright policies. A CRIS is a great discovery tool
        and it can be further enhanced by integration with social networking tools
        (e.g. with the <a href=\"https://web.archive.org/web/20120611032822/http://blogs.nature.com/u6e5b2ce1/2010/04/28/coming-soon-all-new-nature-network\">new
        Nature Network</a> or the <a href=\"https://web.archive.org/web/20120611032822/http://www.mendeley.com/blog/press-release/announcing-mendeley-open-api/\">Mendeley
        API</a> both announced a few days ago).</p><p>The main interest of administrations
        if of course evaluation of research output. A CRIS can be used to do exactly
        that, and it has two advantages: a) it can automate some of the processes
        that are currently done manually by researchers (regularly collecting and
        reporting information about grants and publications), and b) it is a great
        platform to develop new tools for the evaluation of scientific output. My
        institution currently evaluates using the <em><em>Impact Factor</em></em>
        of the published papers, and takes first and last authorship (and female authors)
        into consideration. A CRIS would allow an institution to use similar tools
        as the <a href=\"https://web.archive.org/web/20120611032822/http://www.plosone.org/static/almInfo.action\">PLoS
        Article-Level Metrics</a> (usage data, citation data, usage by social networking
        tools) instead of the <em><em>Impact Factor</em></em>, and several projects
        are already trying some of that, e.g. the German <a href=\"https://web.archive.org/web/20120611032822/http://www.dini.de/projekte/oa-statistik/english/\">Open
        Access Statistics</a> project.</p><p>But the best thing about CRIS tools in
        general, and <em><em>BibApp</em></em> in particular, is that they add a lot
        of value for relatively little effort. Universities don't want to (and can't)
        compete with large institutions or companies such as scientific publishers.
        Because they basically just integrate the data that are already available
        in an intelligent way (Mashup in Web 2.0 language), they require a reasonable
        effort to maintain. This will be particularly true once the <a href=\"https://web.archive.org/web/20120611032822/http://www.orcid.org/\">ORCID</a>
        system of unique author identifiers is in place, because author disambiguation
        is currently one of the most time-consuming aspects (even though <em><em>BibApp</em></em>
        is pretty smart about this). I'm looking forward to adapt <em><em>BibApp</em></em>
        to the <em><em>ORCID</em></em> prototype system that is planned for this summer.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ ResearcherID: Interview with Renny Guida
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/researcherid-interview-with-renny-guida/\"
        />\n\t\t<id>https://doi.org/10.53731/9r1jv8a-aa2ka4w</id>\n        <published>2010-04-26T00:00:00.000+00:00</published>\n\t\t<updated>2023-09-02T09:23:28.000+00:00</updated>\n\t\t<category
        term=\"Interview\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Open Researcher
        and Contributor ID or <a href=\"https://web.archive.org/web/20120611094015/http://blogs.nature.com/mfenner/2010/01/03/orcid-or-how-to-build-a-unique-identifier-for-scientists-in-10-easy-steps\">ORCID</a>
        is a community effort to standardize researcher identification. The initiative
        was first announced last December, and is supported by a <a href=\"https://web.archive.org/web/20120611094015/http://www.orcid.org/gallery.php\">growing
        number</a> of publishers, scholarly societies and academic institutions. <a
        href=\"https://web.archive.org/web/20120611094015/http://science.thomsonreuters.com/\">Thomson
        Reuters</a> is not only one of the founding members of the initiative, but
        will also provide the <a href=\"https://web.archive.org/web/20120611094015/http://www.researcherid.com/\">ResearcherID</a>
        technology as a starting point for building the <em><em>ORCID</em></em> platform.</p><p>I
        asked <em><em>Renny Guida</em></em> from Thomson Reuters a few questions about
        his thoughts on unique author identifiers in general, and <em><em>ResearcherID</em></em>
        and <em><em>ORCID</em></em> in particular.</p><h3 id=\"1-what-is-researcherid\">1.
        What is ResearcherID?</h3><p><em><em>ResearcherID</em></em> is a freely available
        system that helps the research community overcome the issues of individual
        name ambiguity and attribution. The system is available to everyone and allows
        a researcher to establish, maintain and control a biographic and bibliographic
        profile.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2023/09/rid_logo-1.gif\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"358\" height=\"77\"></figure><p>The
        system is the result of research that found that individual identity touches
        many parts of scholarly communications and that researcher\u2019s and academic
        institutions were ready to take some ownership of the issue to ensure proper
        attribution of scholarship.</p><p>The Registry is composed of biographical
        and bibliographic components which are accessible at the <a href=\"https://web.archive.org/web/20120611094015/http://www.researcherid.com/\">researcherid.com</a>
        web site. A web services API makes it possible for an institution or organization
        to create and use this information in their systems.</p><p>The biographical
        component of the registry creates a unique identifier and persistent web location
        for each user. The system is designed to allow a researcher to control privacy
        and access to the information in their profile, even if the information was
        uploaded by the researcher\u2019s institution. Researchers can enter and manage
        information about themselves, their work and their affiliations (<a href=\"https://web.archive.org/web/20120611094015/http://www.researcherid.com/rid/C-3246-2009\">example
        record</a>).</p><p>The bibliographic component of <em><em>ResearcherID</em></em>
        allows researchers to connect articles, patents and other scholarly items
        to their profile. Items can be loaded from <a href=\"https://web.archive.org/web/20120611094015/http://www.endnote.com/\">EndNote</a>,
        the <a href=\"https://web.archive.org/web/20120611094015/http://www.isiwebofknowledge.com/\">Web
        of Science</a> or in a text format into one of three lists.</p><p>As I mentioned,
        a web service makes it possible for organizations to create and manage both
        biographic and bibliographic information for their faculty and researchers.
        Upload, download and search services make this possible. For example, David
        Palmer at the University of Hong Kong uses ResearcherID to create <a href=\"https://web.archive.org/web/20120611094015/http://hub.hku.hk/rp/rp00023\">identifiers
        for HKU researchers</a>.</p><h3 id=\"2-what-is-orcid-and-how-does-it-relate-to-researcherid\"><em><em>2.
        What is ORCID, and how does it relate to ResearcherID?</em></em></h3><p>Open
        Researcher Contributor ID (ORCID) is an initiative to better understand how
        the issue of individual name ambiguity can be solved. Currently a cross section
        of the research community is discussing ways to overcome the issue with the
        hopes of establishing an open registry that will be used by the global research
        community.</p><p>One of the lessons learned from Thomson Reuters\u2019 development
        of <em><em>ResearcherID</em></em> is that issues of name ambiguity and attribution
        are problems bigger than any one organization can address. And, having multiple
        solutions to the problem will not meet the needs of researchers or the scholarly
        community. Based on <em><em>ResearcherID\u2019s</em></em> innovation and success
        in addressing these issues, Thomson Reuters plans to offer <em><em>ORCID</em></em>
        the technology and infrastructure for managing the biographic registry.</p><p>The
        initiative has grown from early 2009 conversations between <em><em>Thomson
        Reuters</em></em> and <em><em>Nature Publishing Group</em></em> into a global
        collaboration of academic institutions, research centers, funding agencies,
        scholarly societies and publishers. To date, everyone involved in the effort
        is volunteering their time and work is focused on the business and technical
        implications of creating an independent organization to manage an identity
        registry system. More information on the initiative can be found at the <a
        href=\"https://web.archive.org/web/20120611094015/http://www.orcid.org/\">ORCID</a>
        web site.</p><h3 id=\"3-there-are-numerous-other-initiatives-for-unique-researcher-identifiers-what-is-unique-about-researcherid\">3.There
        are numerous other initiatives for unique researcher identifiers. What is
        unique about ResearcherID?</h3><p>What is unique about <em><em>ResearcherID</em></em>
        is that it is a global initiative and not focused on any one organization,
        consortia, country or application. The system also ensures privacy and allows
        researchers to control their information. The <em><em>ResearcherID</em></em>
        is portable and can be included in authored works and used as a dynamic link
        on the researcher\u2019s website.</p><h3 id=\"4-how-does-researcherid-integrate-with-other-thomson-reuters-products-and-outside-tools\">4.
        How does ResearcherID integrate with other Thomson Reuters products and outside
        tools?</h3><p>The system was designed to allow all users, independent of any
        Thomson Reuters subscriptions, to benefit from the application. All users
        have the ability to establish an identifier, create and manage a biographical
        profile, and manage a list of scholarly works.</p><p>The <em><em>ResearcherID</em></em>
        system is closely coupled with EndNote and by May 2010, all ResearcherID users,
        independent of any Thomson Reuters subscriptions, will have access to the
        <a href=\"https://web.archive.org/web/20120611094015/http://www.endnoteweb.com/\">web
        version of EndNote</a>.</p><p>For users having access to the <em><em>Web of
        Knowledge</em></em> there are a number of additional integration points:</p><ul><li>Researchers
        can claim items from the <em><em>Web of Science</em></em> by either performing
        a search or using the <a href=\"https://web.archive.org/web/20120611094015/http://images.isiknowledge.com/WOK46/help/WOS/h_da_sets.html\">Distinct
        Author Sets</a> feature that automatically clusters articles believed to be
        authored by the same person.</li><li>Researchers can claim items from any
        <em><em>Web of Knowledge</em></em> database.</li><li>The ResearcherID system
        uses the <em><em>Web of Science</em></em> to automatically update the ResearcherID
        system with the times cited count.</li><li><em><em>Web of Science</em></em>
        times cited information is used to generate personal citation reports and
        the citation visualizations (currently being tested in <a href=\"https://web.archive.org/web/20120611094015/http://wokinfo.com/researcherid/ridlabs/\">ResearcherID
        labs</a> environment) to visualize collaboration and citation networks.</li></ul><h3
        id=\"5-do-you-plan-to-continue-with-researcherid-once-orcid-is-fully-working\">5.
        Do you plan to continue with ResearcherID once ORCID is fully working?</h3><p>Our
        plans are to adapt and enhance <em><em>ResearcherID</em></em> to support <em><em>ORCID</em></em>
        and allow users access to personal citation functionality and services on
        our <em><em>Web of Knowledge</em></em> platform. Thomson Reuters is one of
        the catalysts of the <em><em>ORCID</em></em> initiative and is working with
        our colleagues to help <em><em>ORCID</em></em> succeed. We will fully support
        <em><em>ORCID</em></em> from the enhanced <em><em>ResearcherID</em></em> platform
        and other Thomson Reuters applications.</p><h3 id=\"6-what-would-be-the-benefits-of-using-a-unique-author-identifier-for-a-researcher\">6.
        What would be the benefits of using a unique author identifier for a researcher?</h3><p>The
        unique author identifier not only addresses the issues of name ambiguity and
        attribution but benefits the scholarly communication process by maintaining
        the link between the researchers and their scholarship. This link is critical
        given the proliferation of information available on the Web and the demand
        to find information in less time and with greater accuracy.</p><p>The real
        benefit comes when all involved in the scholarly communications can leveraged
        the identifier to improve the process. Easier tenure review, better assessment
        of research output, more intelligent discovery tools, enhanced peer review
        systems and tools to maintain scholarly networks are some of the benefits
        of using a unique author identifier.</p><h3 id=\"7-where-do-you-see-the-biggest-obstacles-in-launching-a-universally-accepted-unique-identifier-for-researchers-technical-or-social\">7.
        Where do you see the biggest obstacles in launching a universally accepted
        unique identifier for researchers? Technical or social?</h3><p>I see two large
        obstacles. The first, and I believe most important, is the researchers perception
        of security and ownership. The system must allow researchers to control and
        manage their data.</p><p>The second biggest obstacle is the sustainability
        of an organization that would provide the identity service. <em><em>ORCID</em></em>
        is proving that the community can work together to address the technicalities
        of a global identity system. And, while there are significant technical, privacy
        and other challenges, the initiative is making great progress. However, such
        a service requires resources and the system must be supported financially
        by the community.</p><h3 id=\"8-what-is-your-thinking-with-regards-to-automatically-assigning-unique-author-identifiers-to-papers-vs-authors-claiming-their-publications\">8.
        What is your thinking with regards to automatically assigning unique author
        identifiers to papers vs. authors claiming their publications?</h3><p>I see
        these as being two complementary and important services. Algorithmic clustering
        of papers is a common feature in many applications including the <em><em>Web
        of Science</em></em> and other bibliographic databases. For the most part,
        these clustering systems do a good job identifying a high percentage of papers
        for a particular author. However, because none of the industry\u2019s algorithms
        are perfect, a claiming system that enables the researcher to associate all
        of their papers is an ideal complement and helps to complete a career profile
        of a researcher\u2019s works.</p><h3 id=\"9-what-are-your-responsibilities-at-thomson-reuters\">9.
        What are your responsibilities at Thomson Reuters?</h3><p>My title is Director
        of eResearch Services. Some of my responsibilities include individual identity
        initiatives (ResearcherID and the Web of Science Distinct Author Sets clustering
        system), Web of Knowledge web services, inbound and outbound linking, current
        awareness and alerting systems, and <a href=\"https://web.archive.org/web/20120611094015/http://www.projectcounter.org/about.html\">COUNTER</a>
        compliant usage reporting systems.</p><h3 id=\"10-what-did-you-do-before-working-at-thomson-reuters\">10.
        What did you do before working at Thomson Reuters?</h3><p>Prior to joining
        Thomson Reuters in 1997 I worked for the Datapro division of McGraw Hill in
        product development and for Xerox selling document management systems.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Standards for the Conduct of Science in
        the Information Age ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/standards-for-the-conduct-of-science-in-the-information-age/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw4x</id>\n        <published>2010-04-17T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-18T08:10:46.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/3429599200_2f54dbd5cd.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/3429599200_2f54dbd5cd.jpeg\"></p><p>Assuming
        our airports are again open next weekend, I will be attending a meeting organized
        by the <a href=\"https://web.archive.org/web/20120611093752/http://www.nsf.gov/\">NSF</a>
        (National Science Foundation) and <a href=\"https://web.archive.org/web/20120611093752/http://www.eurohorcs.org/E/Pages/home.aspx\">EuroHORCS</a>
        (European Heads of Research Councils) on <em><em>Changing the Conduct of Science
        in the Information Age</em></em> in Washington on April 26. We have been asked
        to submit a one page white paper in advance of the meeting.<sup><a href=\"https://web.archive.org/web/20120611093752/http://blogs.plos.org/mfenner/2010/04/17/improving_the_conduct_of_science/#fn1\">1</a></sup>
        I decided to focus on the importance of standards, obviously leaving out many
        other important technological and social aspects. But defining and adhering
        to standards will enable or enhance a number of very interesting ways to conduct
        and report science in the information age.</p><p>Improving the conduct of
        science through digital technology requires standards for linking to and formatting
        scholarly resources. These standards should be coordinated by independent
        organizations that are not restricted to geographic areas or particular research
        domains.</p><h3 id=\"data-access\">Data access</h3><p>Digital Object Identifiers
        (<a href=\"https://web.archive.org/web/20120611093752/http://www.doi.org/\">DOIs</a>)
        are the primary system to link to digital content. The International <a href=\"https://web.archive.org/web/20120611093752/http://www.datacite.org/\">DataCite</a>
        initiative is the DOI registration agency for scientific primary data. Although
        there are many uses of DOIs for primary research data (e.g. <a href=\"https://web.archive.org/web/20120611093752/http://www.pangaea.de/\">PANGAEA</a>,
        earth system research), many systems still use different identifiers.<br>Research
        funders and journals working in specific domains should collaborate on standards
        and best practices for primary research datasets, and journal publishers should
        encourage or even require linking to research datasets from publications.
        Successful examples include <a href=\"https://web.archive.org/web/20120611093752/http://www.ncbi.nlm.nih.gov/genbank/\">GenBank</a>
        (genetic sequences) and <a href=\"https://web.archive.org/web/20120611093752/http://www.mged.org/Workgroups/MIAME/miame.html\">MIAME</a>
        (microarray gene expression).</p><h3 id=\"knowledge-access\">Knowledge access</h3><p>DOIs
        have become the standard identifier for electronic scholarly publications
        and are managed by the <a href=\"https://web.archive.org/web/20120611093752/http://www.crossref.org/\">CrossRef</a>
        registration agency. Journal articles, databases and websites linking to scholarly
        publications should use DOIs whenever possible instead of internal identifiers
        such as the PubMed ID or direct links to publisher webpages. Publishers should
        implement citation styles that use the DOI instead of volume, issue and page
        numbers.<br>The <a href=\"https://web.archive.org/web/20120611093752/http://dtd.nlm.nih.gov/\">NLM
        DTD</a> is the standard format used by PubMed Central and many scholarly publishers
        to produce content for reading in the HTML, PDF or ePub formats. The <a href=\"https://web.archive.org/web/20120611093752/http://www.microsoft.com/mscorp/tc/scholarly_communication.mspx\">Article
        Authoring Add-in for Microsoft Office Word</a> and <a href=\"https://web.archive.org/web/20120611093752/http://pkp.sfu.ca/lemon8\">Lemon8-XML</a>
        allow researchers to produce content in the NLM DTD format. The workflow of
        writing, reviewing and publishing scientific papers should be based completely
        on the NLM DTD and tools for collaborative writing, journal submission and
        peer review should be build around that format.</p><h3 id=\"attribution\">Attribution</h3><p>The
        recently announced<a href=\"https://web.archive.org/web/20120611093752/http://blogs.plos.org/mfenner/2010/04/17/improving_the_conduct_of_science/#fn2\">2</a>
        Open Researcher and Contributor ID (<a href=\"https://web.archive.org/web/20120611093752/http://www.orcid.org/\">ORCID</a>)
        is one of many initiatives for a unique researcher identifier, but has probably
        the broadest support among institutions, publishers and research organizations.
        ORCID will be managed by an independent non-profit organization, and will
        allow the exchange of profiles with other researcher identifier systems such
        as those used by <a href=\"https://web.archive.org/web/20120611093752/http://www.scopus.com/\">Scopus</a>,
        <a href=\"https://web.archive.org/web/20120611093752/http://repec.org/\">RePEc</a>,
        or <a href=\"https://web.archive.org/web/20120611093752/https://twiki.cern.ch/twiki/bin/view/Inspire/WebHome\">Inspire</a>.<br>The
        information in the author profile may be initially provided by an institution,
        society or publisher, but should eventually be claimed by the individual researcher
        because of privacy concerns and because automated author disambiguation is
        never 100% accurate. Attribution should include all aspects of scholarly activity,
        including curation of primary research datasets and peer review.<br>The Public
        Library of Science (PLoS) <a href=\"https://web.archive.org/web/20120611093752/http://article-level-metrics.plos.org/\">article-level
        metrics</a> make available comprehensive information (citations, downloads,
        social bookmarks, comments, etc.) with every published article. This system
        should be linked to author identifiers and developed into a standard for scholarly
        resources. Other scholarly publishers and databases for primary research data
        should then adopt these metrics.</p><p>fn1. Cameron Neylon's draft white paper
        is <a href=\"https://web.archive.org/web/20120611093752/http://cameronneylon.net/blog/draft-white-paper-researcher-identifiers/\">here</a>.</p><p>fn2.
        Interestingly both DataCite and ORCID were first announced December 1, 2009
        at two independent events in London (press releases <a href=\"https://web.archive.org/web/20120611093752/http://www.tib-hannover.de/en/the-tib/news/news/id/133/\">here</a>
        and <a href=\"https://web.archive.org/web/20120611093752/http://orcid.org/media/pdf/ORCID_Announcement.pdf\">here</a>).</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Editorial Peer Reviewers\u2019 Recommendations
        at a General Medical Journal: Are They Reliable and Do Editors Care? ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/editorial-peer-reviewers-recommendations-at-a-general-medical-journal-are-they-reliable-and-do-editors-care/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw4y</id>\n        <published>2010-04-12T00:00:00.000+00:00</published>\n\t\t<updated>2023-07-05T17:56:27.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/3157621454_902378aa2f-1.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/3157621454_902378aa2f-1.jpeg\"></p><p>Peer
        review is central to how we evaluate science and therefore how journal papers,
        grants, and jobs are awarded. Peer review is done in many different ways,
        and has dramatically changed in the last 25 years. But the purpose of peer
        review is still to improve the quality of research by providing feedback and
        to evaluate the quality of research. The evaluation serves as a filter both
        for limited resources (e.g. grants or jobs; publication in a journal is no
        longer a limited resource), and for other researchers to focus on the most
        relevant work in their field.</p><p>It is therefore surprising that relatively
        little research on peer review itself has been done. Most discussions focus
        on the shortcomings of peer review, and the arguments are often based on personal
        experience and/or interests. Good research on peer review can help to improve
        the peer review process. Last week such a paper was published in <em><em>PLoS
        ONE.</em></em></p><p><strong><strong>Richard Kravitz</strong></strong> and
        colleagues looked at the recommendations of peer reviewers, and how they influenced
        the editorial decision to publish or reject a paper. The study looked at 6213
        manuscripts received from 2004 to 2008 at the <em><em>Journal of General Internal
        Medicine (JGIM)</em></em> where four of the authors were either current or
        former editors in chief.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/pone.0010072.g001.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"2706\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/pone.0010072.g001.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/08/pone.0010072.g001.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2022/08/pone.0010072.g001.png
        1600w, https://blog.front-matter.io/content/images/2022/08/pone.0010072.g001.png
        2292w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Figure 1. Flow chart
        showing the outcome of reviews pertaining to 2264 manuscripts undergoing external
        peer review at the <em><em>Journal of General Internal Medicine</em></em>.</figcaption></figure><p>At
        <em><em>JGIM</em></em> submitted manuscripts were first screened by an editor-in-chief
        and a deputy editor. Most manuscripts were rejected at this step, 2264 manuscripts
        (36%) were sent out for peer review. 2916 reviewers wrote a total of 5581
        reviews (1-4 per manuscript) which included comments and a recommendation.
        Eventually, 43% of the manuscripts were accepted for publication.</p><p>Overall,
        there was an agreement between all reviewers in just over half of the manuscripts
        (54.6% ), furthermore, editors did not follow these recommendations in another
        10% of manuscripts:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/pone.0010072.t001.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"386\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/pone.0010072.t001.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/08/pone.0010072.t001.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2022/08/pone.0010072.t001.png
        1600w, https://blog.front-matter.io/content/images/size/w2400/2022/08/pone.0010072.t001.png
        2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><strong>Table 1. </strong>Likelihood
        of Initial Decision to Reject in Relation to Reviewer Agreement.</figcaption></figure><p>The
        inter-reviewer agreement was slightly higher than what would have been expected
        by chance and was lower than the agreement between recommendations for several
        manuscripts by the same reviewer. In contrast, there was little correlation
        between editorial decisions for different manuscripts handled by the same
        editor.</p><p>The authors write in the discussion:</p><p><em><em>If reviewers
        cannot regularly agree on whether to recommend rejection or further consideration,
        the marginal contribution of such summative recommendations may be small,
        and worse, they may distract from reviewers' primary contribution, which is
        to improve the reporting \u2013 and ultimately the performance \u2013 of science.</em></em></p><p>The
        paper authors consider the following to improve reviewer recommendations:
        using more reviewers per manuscript, providing better training for reviewers,
        or recommendations could be dropped altogether and reviewers asked to focus
        instead on evaluating the strengths and weaknesses of manuscripts. Some journals
        are obviously using this latter approach.</p><p>Several studies <a href=\"https://doi.org/10.1097/01.ede.0000254668.63378.32\">have
        shown</a> that most rejected manuscripts will eventually be published somewhere
        else. One important reason is that publication space in journals is no longer
        a scarcity as it was before electronic publishing became widespread. This
        means that the ultimate decision on whether or not something will be published
        in a peer-reviewed journal rests with the authors and not the editors or reviewers.
        Reviewers should keep this in mind.</p><p><strong><strong>Further reading:</strong></strong><br>*
        <a href=\"https://web.archive.org/web/20120611094155/http://www.nasw.org/users/mslong/2010/2010_04/PeerReview.htm\">Questioning
        the Value of Recommendations in Peer Review</a> (Michael Long)<br>* <a href=\"https://web.archive.org/web/20120611094155/http://bit.ly/9YUs0q\">Scrap
        peer review and beware of top journals</a> (Richard Smith)<br>* <a href=\"https://web.archive.org/web/20120611094155/http://cameronneylon.net/blog/peer-review-what-is-it-good-for/\">Peer
        review: What is it good for?</a> (Cameron Neylon)<br>* <a href=\"https://web.archive.org/web/20120611094155/http://backreaction.blogspot.com/2010/04/peer-review-vi.html\">Peer
        Review VI</a> (Sabine Hossenfelder)<br>* <a href=\"https://web.archive.org/web/20120611094155/http://blogs.nature.com/mfenner/2009/07/13/the-value-of-peer-review\">The
        value of peer review</a> (me)</p><h3 id=\"references\">References</h3><p>Kravitz
        RL, Franks P, Feldman MD, Gerrity M, Byrne C, Tierney WM. Editorial Peer Reviewers\u2019
        Recommendations at a General Medical Journal: Are They Reliable and Do Editors
        Care? Sampson M, ed. <em>PLoS ONE</em>. 2010;5(4):e10072. doi:<a href=\"https://doi.org/10.1371/journal.pone.0010072\">10.1371/journal.pone.0010072</a></p><p>Hall
        SA, Wilcox AJ. The Fate of Epidemiologic Manuscripts: A Study of Papers Submitted
        to Epidemiology. <em>Epidemiology</em>. 2007;18(2):262-265. doi:<a href=\"https://doi.org/10.1097/01.ede.0000254668.63378.32\">10.1097/01.ede.0000254668.63378.32</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Lst wk I had g8t fun @ #hcsmeucamp ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/lst-wk-i-had-g8t-fun-hcsmeucamp/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw4z</id>\n        <published>2010-04-05T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-01T06:17:10.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Last Wednesday
        I attended the <a href=\"https://web.archive.org/web/20120611095039/http://www.hcsmeucamp.com/\">Health
        Care Social Media Camp</a> in Berlin. Healthcare Social Media in Europe \u2013
        <em><em>#hcsmeu</em></em> for short \u2013 is a community of healthcare twitterers
        and social media users from Europe, started in August 2009 by <a href=\"https://web.archive.org/web/20120611095039/http://www.whydotpharma.com/about/\">Silja
        Chouquet</a> and <a href=\"https://web.archive.org/web/20120611095039/http://stwem.com/\">Andrew
        Spong</a>. I am interested in <em><em>#hcsmeu</em></em> not only because I
        am a physician treating cancer patients, but also because there is a lot of
        overlap to many other things that interest me in doing and communicating science
        online, e.g. <a href=\"https://web.archive.org/web/20120611095039/http://blogs.nature.com/mfenner/2010/03/15/chances-and-problems-of-doing-science-online\">doing
        clinical research with online tools</a>, <a href=\"https://web.archive.org/web/20120611095039/http://blogs.nature.com/mfenner/2010/03/22/cancer-and-the-media\">reporting
        about cancer in the media</a>, or <a href=\"https://web.archive.org/web/20120611095039/http://blogs.nature.com/mfenner/2009/01/16/scienceonline09-providing-public-health-and-medical-information-to-all\">better
        access to public health and medical information</a>.</p><figure class=\"kg-card
        kg-image-card\"><img src=\"https://web.archive.org/web/20120611095039im_/http://farm5.static.flickr.com/4034/4482350267_c1105c6103.jpg\"
        class=\"kg-image\" alt loading=\"lazy\"></figure><p><em><em>Me listening to
        Andrew starting off the meeting. #hcsmeucamp Twitter feed in background. Flickr
        photo by dikomci.</em></em></p><p>The meeting was a small gathering of about
        45 people in the <a href=\"https://web.archive.org/web/20120611095039/http://blogs.nature.com/mfenner/2009/07/10/i-was-at-scibarcamp-palo-alto\">unconference</a>
        format, so we started with collecting questions we wanted to discuss during
        the day. For each of the four sessions (patient perspective, health care professional
        perspective, pharma perspective and <em><em>#hcsmeu</em></em> mission and
        goals) we first split up in 3-4 smaller groups to talk about some of the questions,
        and in the second half summarized and discussed this as the whole group. Some
        participants demonstrated excellent skills with the whiteboard.</p><p><em><em>How
        do we get scientists interested in social media?</em></em> is something we
        have talked about many times, e.g. <a href=\"https://web.archive.org/web/20120611095039/http://scholarlykitchen.sspnet.org/2009/10/19/scientists-still-not-joining-social-networks/\">Scientists
        Still Not Joining Social Networks</a>. Healthcare professionals are also reluctant
        to use social media, and we come up with some interesting suggestions to do
        something about this:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://web.archive.org/web/20120611095039im_/http://farm5.static.flickr.com/4017/4483005134_dfea7e66ba_d.jpg\"
        class=\"kg-image\" alt loading=\"lazy\"></figure><p><em><em>Flickr photo by
        dikomci.</em></em></p><p>We also talked about the dangers of getting involved
        with social media. The doctor-patient communication is something that is difficult
        to translate from personal communication to social media (lawyers and some
        other professions have similar problems), but otherwise the dangers look familiar
        to many scientists:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://web.archive.org/web/20120611095039im_/http://farm5.static.flickr.com/4027/4483004296_b2ba2d7482_d.jpg\"
        class=\"kg-image\" alt loading=\"lazy\"></figure><p><em><em>Flickr photo by
        dikomci.</em></em></p><p>The last part of the meeting was about <em><em>#hcsmeu</em></em>,
        and what next steps to take. <em><em>#hcsmeu</em></em> is very focused on
        moving the agenda forward, and that spirit penetrated the whole meeting. After
        a very productive discussion we come up with some good action items:</p><figure
        class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://web.archive.org/web/20120611095039im_/http://farm3.static.flickr.com/2715/4482357507_121d7b3c86.jpg\"
        class=\"kg-image\" alt loading=\"lazy\"><figcaption>Flickr photo by dikomci.</figcaption></figure><p><em><em>#hcsmeu</em></em>
        is very much built around Twitter, including regular Tweetups every Friday,
        and <a href=\"https://web.archive.org/web/20120611095039/http://twitter.com/#search?q=%23hcsmeucamp\">heavy
        use</a> during the meeting. I am a big <a href=\"https://web.archive.org/web/20120611095039/http://www.twitter.com/mfenner\">Twitter
        fan</a>, but have <a href=\"https://web.archive.org/web/20120611095039/http://blogs.nature.com/mfenner/2010/01/17/scienceonline2010-i-wish-i-was-there\">argued
        before</a> that Twitter is not the best tool for conference microblogging,
        as it is difficult to have connected discussions around a topic, and archieving
        is complicated. And pictures, documents and links are better collected in
        places like <em><em>Flickr</em></em>, <em><em>Slideshare</em></em> and <em><em>delicious</em></em>.
        <a href=\"https://web.archive.org/web/20120611095039/http://mfenner.posterous.com/best-practices-for-hcsmeu-social-media-use\">My
        suggestions</a> for the <em><em>#hcsmeu</em></em> knowledge hub therefore
        include more use of other social media tools, plus <em><em>FriendFeed</em></em>
        or a similar aggregation/microblogging tool to connect all the social media
        in one place. <em><em>Facebook</em></em> is actually a perfect tool to do
        all this, but unfortunately is still perceived by many as a tool for <em><em>private</em></em>
        social networking. I met many very smart and friendly people during the meeting
        and hope to hear more about <em><em>#hcsmeu</em></em> at <em><em>Science Online
        London 2010</em></em> in September or the <a href=\"https://web.archive.org/web/20120611095039/http://www.medicine20congress.com/ocs/index.php/med/med2010\">Medicine
        2.0 conference</a> in November.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Let\u2019s make science metrics more scientific
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/lets-make-science-metrics-more-scientific/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw4q</id>\n        <published>2010-03-29T00:00:00.000+00:00</published>\n\t\t<updated>2023-07-05T17:51:02.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/3592693331_ae8822f91d-1.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/3592693331_ae8822f91d-1.jpeg\"></p><p>In
        the March 25 edition of <em><em>Nature</em></em>, <a href=\"https://web.archive.org/web/20120611101936/http://client.norc.org/jole/SOLEweb/JLHome.html\">Julia
        Lane</a>, Program Director of the <a href=\"https://web.archive.org/web/20120611101936/http://www.nsf.gov/funding/pgm_summ.jsp?pims_id=501084&amp;org=NSF&amp;from_org=NSF\">Science
        of Science and Innovation Policy Program</a> at the National Science Foundation,
        wrote an interesting opinion piece about the assessment of scientific performance.
        She argues that the current systems of measurement are inadequate, as they
        have several inherent problems and do not capture the full spectrum of scientific
        activities. Good scientific metrics are difficult, but without them, we risk
        making the wrong decisions about funding and academic positions.</p><p>Julia
        Lane suggests that we develop and use standard identifiers both for researchers
        and their scientific output (examples given include the <a href=\"https://web.archive.org/web/20120611101936/http://www.doi.org/\">DOI</a>
        for publications and <a href=\"https://web.archive.org/web/20120611101936/http://www.orcid.org/\">ORCID</a>
        as unique author identifier), that we develop standards for reporting scientific
        achievements (e.g. using the <a href=\"https://web.archive.org/web/20120611101936/http://www.nsf.gov/bfa/dias/policy/rppr/\">Research
        Performance Progress Report</a> format), and that we open up and connect the
        various tools and databases that collect scientific output. She cites the
        <a href=\"https://web.archive.org/web/20120611101936/http://lattes.cnpq.br/english/index.htm\">Lattes</a>
        database for Brazilian researchers as a successful example of systematically
        collecting scientific output. Another example given is the ongoing <a href=\"https://web.archive.org/web/20120611101936/http://nrc59.nas.edu/star_info2.cfm\">STAR
        METRICS</a> project which measures the impact of federally funded research
        on economic, scientific, and social outcomes.</p><p>The article emphasizes
        that is not enough to think about how to best collect and report scientific
        output, but that it is equally important to understand what these data mean
        and how to use them, and this may differ from field to field. Knowledge creation
        is complex and measuring this can not be reduced to counting scientific papers
        and the number of times they are cited. Social scientists and economists should
        be involved in this step. Julia Lane suggests an international platform supported
        by funding agencies in which ideas and potential solutions for science metrics
        can be discussed.</p><p>The article contains a lot of food for thought and
        has already collected some insightful <a href=\"https://web.archive.org/web/20120611101936/http://www.nature.com/nature/journal/v464/n7288/full/464488a.html#comments\">comments</a>.
        In perfect timing, <em><em>Nature</em></em> this week not only made <a href=\"https://web.archive.org/web/20120611101936/http://www.nature.com/press_releases/naturenews.html\">Nature
        News available without a subscription</a>, but also <a href=\"https://web.archive.org/web/20120611101936/http://dx.doi.org/10.1038/464466a\">added
        commenting to all their articles</a>. I would like to add some thoughts on
        topics that were not covered because of space constraints and different perspectives.</p><h3
        id=\"what-are-the-standard-identifiers-for-research-output\"><strong><strong>What
        are the standard identifiers for research output?</strong></strong></h3><p>Using
        standard identifiers for research output is an essential first step, and the
        standard identifier for scientific papers is the DOI. So why is it that PubMed
        (the most important database for biomedical articles, published by the U.S.
        National Institutes of Health) still uses their own PMID and doesn't display
        the DOI in their abstract and summary views? And where is the DOI in abstracts,
        full-text HTML, or PDF of articles published in the New England Journal of
        Medicine, to take just one popular medical journal as an example? Both PubMed
        and the NEJM obviously use the DOI, but why do they make it so difficult for
        others?</p><p>The unique author identifier <a href=\"https://www.orcid.org/\">ORCID</a>
        was mentioned in the article (disclaimer: I am a member of the ORCID technical
        working group). There are many other initiatives for uniquely identifying
        researchers, most of them older than <strong><strong>ORCID</strong></strong>
        which was started in November 2009. But is very important that we can agree
        on a single author identifier that is supported by researchers, institutions,
        journals, and funding organizations. <strong><strong>ORCID</strong></strong>
        already has support from a growing list of <a href=\"https://web.archive.org/web/20120611101936/http://www.orcid.org/gallery.php\">ORCID
        members</a> and is our best chance for a widely supported and open unique
        author identifier. But this list of <strong><strong>ORCID</strong></strong>
        members is very short on funding organizations (with notable exceptions such
        as the <strong><strong>Wellcome Trust</strong></strong> and <strong><strong>EMBO</strong></strong>).
        What is holding them back, and that includes the <strong><strong>National
        Science Foundation</strong></strong> (where Julia Lane works) and the U.S.
        <strong><strong>National Institutes of Health (NIH)</strong></strong>?</p><p>Persistent
        identifiers are essential to attribute, cite and share primary research data
        sets. We have a long tradition for this with <a href=\"https://https://www.ncbi.nlm.nih.gov/Genbank/\">sequence
        data</a>, and there is growing demand in other research areas, especially
        when huge amounts of data are collected (one example is <a href=\"htthttps://www.pangaea.de/about/\">PANGAEA</a>
        for earth system research). <a href=\"https://www.datacite.org/\">DataCite</a>
        is a new initiative that aims to improve the scholarly infrastructure around
        datasets and to <em><em>increase the acceptance of research data as legitimate,
        citable contributions to the scientific record</em></em>.</p><p>With the focus
        on research papers, we forget that we do not have standard identifiers for
        many aspects of scientific activity, including</p><ul><li>research grants</li><li>principal
        investigator in clinical trials</li><li>scientific prizes and awards</li><li>invited
        lectures</li><li>curation of scientific databases</li><li>mentoring of students</li></ul><h3
        id=\"how-do-we-measure-scientific-output\">How do we measure scientific output?</h3><p>Citations
        are the traditional way to measure the impact of a scientific paper. Some
        of the problems with this approach are well-known and were for example highlighted
        in a 2007 editorial in the <em><em>Journal of Cell Biology</em></em> (<a href=\"https://doi.org/10.1083/jcb.200711140\">Show
        me the data</a>). We need a metric that is open and not proprietary, and that
        measures the citations of an individual paper and not the journal as a whole.
        We should also not forget that the number of citations can't be compared between
        different fields.</p><p>A 2009 analysis by the <a href=\"https://web.archive.org/web/20120611101936/http://www.mesur.org/\">MESUR</a>
        project indicates that scientific impact of a paper can not be measured by
        any single indicator (<a href=\"https://doi.org/10.1371/journal.pone.0006022\">A
        Principal Component Analysis of 39 Scientific Impact Measures</a>). Alternatives
        to citations are usage statistics such as HTML page views and PDF downloads,
        popularity in social bookmarking sites, coverage in blog posts, and comments
        to articles. The <em><em>PLoS</em></em> <a href=\"https://web.archive.org/web/20120611101936/http://article-level-metrics.plos.org/\">article
        level metrics</a> introduced in September 2009 combine these different metrics,
        and make the data openly available.</p><p>How best to measure the other aspects
        of scientific output is largely unknown. It is possible to count the number
        of research grants or the total amount of money awarded, but should we simply
        count the number of submitted research datasets, invited lectures, science
        blog posts, etc., or do we need some quality indicator similar to citations?</p><h3
        id=\"why-do-we-need-all-this\"><strong><strong>Why do we need all this?</strong></strong></h3><p>Julia
        Lane emphasizes that we need science metrics to make the right decisions about
        funding and academic positions. And I fully agree with her that we need more
        research by social scientists and economists to better understand what these
        data mean and how best to use them. There is a lot of anecdotal evidence that
        suggests that science metrics alone may be poor indicators of future scientific
        achievements, simply because there are too many confounding factors. Maybe
        we also need to find a better term, as metric implies that scientific output
        can be reduced to <a href=\"https://web.archive.org/web/20120611101936/http://friendfeed.com/jcbradley/18e76233/binfield-article-level-metrics-should-be\">one
        or more numbers</a>.</p><p>Another important motivation for improving science
        metrics, and not mentioned in the article, is to reduce the burden on researchers
        and administrators in evaluating research. The proportion of time spent doing
        research vs. time spent applying for funding, submitting manuscripts, filling
        out evaluation forms, doing peer review, etc. has become ridiculous for many
        active scientists. Initiatives such as the standardized <strong><strong>Research
        Performance Progress Report</strong></strong> format mentioned in the paper
        or automated tools to created a publication list or CV can reduce this burden.
        Funding organizations are also trying to reduce the burden of evaluating research
        , e.g. by increasing the time of funding from 3 to 5 years, reducing the number
        of papers that can be listed in grant applications (<a href=\"https://web.archive.org/web/20120611101936/http://blogs.nature.com/mfenner/2010/03/01/german-research-foundation-says-that-numbers-arent-everything\">German
        Research Foundation says that numbers aren't everything</a>), or funding <a
        href=\"https://web.archive.org/web/20120611101936/http://www.wellcome.ac.uk/Funding/investigator-awards/Implementation/index.htm\">investigators
        and not projects</a>.</p><p>Science metrics are not only important for evaluating
        scientific output, they are also great discovery tools, and this may indeed
        be their more important use. Traditional ways of discovering science (e.g.
        keyword searches in bibliographic databases) are increasingly superseded by
        <a href=\"https://web.archive.org/web/20120611101936/http://blogs.nature.com/mfenner/2010/02/22/there-is-still-so-much-to-learn-in-reference-management\">non-traditional
        approaches</a> that use social networking tools for awareness, evaluations
        and popularity measurements of research findings.</p><h2 id=\"references\">References</h2><p>Lane
        J. Let\u2019s make science metrics more scientific. <em>Nature</em>. 2010;464(7288):488-489.
        doi:<a href=\"https://doi.org/10.1038/464488a\">10.1038/464488a</a></p><p>Rossner
        M, Van Epps H, Hill E. Show me the data. <em>Journal of Cell Biology</em>.
        2007;179(6):1091-1092. doi:<a href=\"https://doi.org/10.1083/jcb.200711140\">10.1083/jcb.200711140</a></p><p>Bollen
        J, Van De Sompel H, Hagberg A, Chute R. A Principal Component Analysis of
        39 Scientific Impact Measures. Mailund T, ed. <em>PLoS ONE</em>. 2009;4(6):e6022.
        doi:<a href=\"https://doi.org/10.1371/journal.pone.0006022\">10.1371/journal.pone.0006022</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Cancer and the media ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/cancer-and-the-media/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw4r</id>\n
        \       <published>2010-03-22T00:00:00.000+00:00</published>\n\t\t<updated>2023-07-05T18:09:20.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2023/07/7942175_28dd6be677.jpg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2023/07/7942175_28dd6be677.jpg\"></p><p>Last
        Tuesday the <em><em>Archives of Internal Medicine</em></em> released a study
        that analyzed the news reporting about cancer in 8 large-readership newspapers
        and 5 national magazines in the United States. The authors identified 2228
        cancer-focused articles published between 2005-2007 and did a more detailed
        analysis on a random sample of 436 (20%) articles.</p><p>20% of articles discussed
        cancer in general, 35% focused on breast cancer, and 15% focused on prostate
        cancer. 32% of the articles focused on survival and 8% focused on death and
        dying. 57% of articles discussed aggressive treatments, but only two articles
        exclusively discussed end-of-life palliative care. Only 13% of articles reported
        that aggressive treatment might fail to cure or extend life, and only 30%
        of articles mentioned that cancer treatments can result in (sometimes serious)
        adverse events.</p><p>Cancer is the second most common cause of death in the
        United States and therefore cancer news coverage is relevant to many people.
        One important finding of the study is the relative under-reporting of death
        and dying and palliative care, despite the well-documented benefits for patients
        and their families. The <strong><strong>Pallimed</strong></strong> blog <a
        href=\"https://web.archive.org/web/20120611100654/http://www.pallimed.org/2010/03/cancer-reporting-in-media-guess-what.html\">discusses
        this</a> in more detail. The article was also discussed at <a href=\"https://web.archive.org/web/20120611100654/http://www.scientificblogging.com/news_articles/media_exaggerates_progress_cancer_research\">Scientific
        Blogging</a> and at <a href=\"https://web.archive.org/web/20120611100654/http://blog.syracuse.com/cny/2010/03/media_paint_overly_optimistic_view_of_cancer_medical_study_says.html\">syracuse.com</a>.</p><p>I
        am not surprised by these findings, as they seem to reflect the expectations
        of most cancer patients and their families towards treatment. In my personal
        experience as a doctor treating cancer patients, most patients, relatives
        and their treating physicians (including myself) are overly optimistic about
        the potential benefits of an aggressive cancer treatment (especially if part
        of a clinical trial), and talk much less about the possibility of the treatment
        not working, side effects, or death and dying. The scientific literature <a
        href=\"https://web.archive.org/web/20120611100654/http://dx.doi.org/10.1200/JCO.2008.17.2221\">supports
        this personal experience</a>.</p><p>The study raises a number of additional
        questions:</p><ul><li>What scientific information was used as background information
        for the news reports? Conference reports vs. published papers, case reports
        vs. large randomized trials, research in animal models vs. clinical research?
        Was a source for the research provided in the news reports?</li><li>What is
        the cancer news coverage by science/medical bloggers? Is there a similar bias
        towards aggressive treatment approaches and an under-reporting of treatment
        failures and adverse events?</li><li>Are there geographical differences (U.S.
        vs. Europe, urban vs. rural areas) in cancer news reporting and changes over
        time?</li><li>How are other areas of science covered in the media, e.g. other
        common diseases such as Alzheimer\u2019s disease or malaria, climate research
        or other reasearch areas with large public interest, or basic science research?</li></ul><p><em><em>Thanks
        to <strong><strong>Ivan Oransky</strong></strong> and his <strong><strong>Embargo
        Watch</strong></strong> blog to <a href=\"https://web.archive.org/web/20120611100654/http://embargowatch.wordpress.com/2010/03/19/are-these-embargo-breaks/\">alert</a>
        me to this paper.</em></em></p><h2 id=\"references\">References</h2><p>Fishman
        J. Cancer and the Media: How Does the News Report on Treatment and Outcomes?
        <em>Arch Intern Med</em>. 2010;170(6):515. doi:<a href=\"https://doi.org/10.1001/archinternmed.2010.11\">10.1001/archinternmed.2010.11</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Chances and problems of doing science online
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/chances-and-problems-of-doing-science-online/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw4s</id>\n        <published>2010-03-15T00:00:00.000+00:00</published>\n\t\t<updated>2023-07-10T13:02:06.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/3655816702_769a47f34d.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/3655816702_769a47f34d.jpeg\"></p><p>Last
        month (shortly after <a href=\"https://web.archive.org/web/20120611095611/http://go2.wordpress.com/?id=725X1342&amp;site=scholarlykitchen.wordpress.com&amp;url=http%3A%2F%2Fscienceonline2010.com%2Findex.php%2Fwiki\">ScienceOnline2010</a>)
        <em><em>David Crotty</em></em> wrote in a blog post <a href=\"https://web.archive.org/web/20120611095611/http://scholarlykitchen.sspnet.org/2010/02/08/science-and-web-2-0-talking-about-science-versus-doing-science/\">Science
        and Web 2.0: Talking About Science vs. Doing Science</a>:</p><blockquote><em><em>Nearly
        all of the more visible attempts (of science and Web 2.0) so far have focused
        on talking about science, rather than tools for actually doing science.</em></em></blockquote><p>The
        blog post is required reading for everybody interested in science and Web
        2.0 and has attracted a lot of thoughtful comments (on the blog and <a href=\"https://web.archive.org/web/20120611095611/http://friendfeed.com/the-life-scientists/9bdff1e4/science-and-web-2-0-talking-about-vs-doing\">on
        FriendFeed</a>). In another discussion <em><em>Thomas S</em>\xF6<em>derquist</em></em>
        from the <a href=\"https://web.archive.org/web/20120611095611/http://www.corporeality.net/museion/\">Medical
        Museion in Copenhagen</a> reminded me that there are limitations of what can
        be done online. My blog focusses on talking about science rather than doing
        science, but this post is about doing science online. My research focusses
        on clinical cancer research, and in this field the advantages and limitations
        of doing science online are obviously different from other subject areas (bioinformatics
        for example obviously looks very different). It probably makes sense to ask
        yourself the following questions:</p><ul><li>Are your research data collected
        in (or easily converted into) digital form?</li><li>Are standard data formats
        and standard tools (preferably as open source software) available?</li><li>Do
        you regularly collaborate with scientists in other locations?</li><li>Is information
        about ongoing research projects publicly available?</li><li>Do journals have
        policies regarding the publication of your primary research data?</li><li>Are
        there objections to make the research data freely available?</li></ul><h3
        id=\"are-your-research-data-collected-in-or-easily-converted-into-digital-form\">Are
        your research data collected in (or easily converted into) digital form</h3><p>Electronic
        medical records (<a href=\"https://web.archive.org/web/20120611095611/http://en.wikipedia.org/wiki/Electronic_health_record\">EMR</a>)
        have the potential to <a href=\"https://web.archive.org/web/20120611095611/http://www.nytimes.com/2009/03/01/business/01unbox.html\">improve
        patient care and reduce costs</a>. But for now, often only some clinical information
        (particularly lab and radiology results) is available electronically and paper-based
        patient records are still commonly used. And both electronic and paper-based
        records have to be adapted to be useful for clinical research, e.g. by allowing
        a detailed documentation of adverse events.</p><p>The raw clinical data of
        a patient in a trial (called <em><em>source data</em></em> in clinical research)
        are entered into a case-report form (<a href=\"https://web.archive.org/web/20120611095611/http://en.wikipedia.org/wiki/Case_report_form\">CRF</a>).
        The purpose of this two-step process is to make sure that all required data
        are collected and that they are entered correctly. Many clinical trials now
        use electronic CRFs or electronic data capture (EDC). But these tools are
        still surprisingly difficult to use and more expensive than paper-based solutions,
        so that many trials stick to paper CRFs and enter the data into a computer
        at a later stage. It also doesn't help that the EDC market is very fragmented,
        so that institutions have to learn to use several different tools.</p><h3
        id=\"are-standard-data-formats-and-standard-tools-preferably-as-open-source-software-available\">Are
        standard data formats and standard tools (preferably as open source software)
        available?</h3><p>Clinical Data Interchange Standard (<a href=\"https://web.archive.org/web/20120611095611/http://www.cdisc.org/\">CDISC</a>)
        is the standard format for clinical research data. <a href=\"https://web.archive.org/web/20120611095611/http://www.openclinica.org/\">OpenClinica</a>
        and <a href=\"https://web.archive.org/web/20120611095611/https://cabig.nci.nih.gov/workspaces/CTMS/?pid=primary.2006-10-24.9768040952&amp;sid=ctmsws&amp;status=True\">Clinical
        Trials Management System of CaBIG</a> are two examples of Open Source tools
        for clinical research.</p><h3 id=\"do-you-regularly-collaborate-with-scientists-in-other-locations\">Do
        you regularly collaborate with scientists in other locations?</h3><p>Most
        clinical trials are multi-center trials that are conducted in different locations,
        often even in different countries or continents. The coordination of the different
        trial locations uses email and web conferencing, but often relies more on
        human resources than on modern Web 2.0 tools.</p><h3 id=\"is-information-about-ongoing-research-projects-publicly-available\">Is
        information about ongoing research projects publicly available?</h3><p>Clinical
        research is one of only a few research areas where information about (almost)
        all ongoing research project is publicly available. Clinical trial registries
        serve two purposes. They make it much easier for patients and their treating
        physicians to find relevant clinical trials. And they allow clinical researchers
        to understand what clinical research is going on in their field, and to avoid
        publication bias. <a href=\"https://web.archive.org/web/20120611095611/http://clinicaltrials.gov/\">ClinicalTrials.gov</a>
        at the US National Institutes of Health is the largest clinical trial registry.
        For reasons that are difficult to understand, the European Clinical Trials
        database (<a href=\"https://web.archive.org/web/20120611095611/https://eudract.emea.europa.eu/\">EudraCT</a>)
        is not available to the public, but work is in progress to <a href=\"https://web.archive.org/web/20120611095611/http://www.ecpc-online.org/component/docman/doc_download/68-ecpc-comments-on-qconsultation-for-data-fields-from-eudract-made-available-on-eudrapharmq.html?ItemId=127\">change</a>
        that.</p><h3 id=\"do-journals-have-policies-regarding-the-publication-of-your-primary-research-data\">Do
        journals have policies regarding the publication of your primary research
        data?</h3><p>An article in the <em><em>BMJ</em></em> last month by Iain Hrynaszkiewicz
        and colleagues<sup><a href=\"https://web.archive.org/web/20120611095611/http://blogs.plos.org/mfenner/2010/03/15/chances_and_problems_of_doing_science_online/#fn1\">1</a></sup>
        tries to provide guidance on how to provide raw clinical data for publication.
        The main focus of the paper is patient privacy. Publication of raw clinical
        data either as dataset or as part of a research paper is still very uncommon.
        The meta-analysis of individual patient data<sup><a href=\"https://web.archive.org/web/20120611095611/http://blogs.plos.org/mfenner/2010/03/15/chances_and_problems_of_doing_science_online/#fn2\">2</a></sup>
        requires the raw clinical data of several clinical trials, and because of
        the required effort is probably underused.</p><h3 id=\"are-there-objections-to-make-the-research-data-freely-available\">Are
        there objections to make the research data freely available?</h3><p>Patient
        privacy is a major concern when publishing raw clinical data, and it's therefore
        critical to remove all identifying information from the dataset. This not
        only includes <em><em>direct identifiers</em></em> such as patient names,
        birthdates, unique identifying numbers or facial photographs, but also <em><em>indirect
        identifers</em></em> such as place of treatment, rare disease or treatment,
        occupation or place of work, etc. It is the consensus of the authors of the
        <em><em>BMJ</em></em> paper that datasets with three or more indirect identifiers
        should be evaluated for the risk that individuals might be identifiable before
        they are made available,</p><p>In contrast to <a href=\"https://web.archive.org/web/20120611095611/http://usefulchem.wikispaces.com/\">Open
        Notebook Science</a>, it is impossible to make the results of a clinical trial
        publicly available before the trial is completed. The statistical design of
        the clinical trial is based on the number of patients needed to show a significant
        difference \u2013 looking at interim data could influence patient recruitment.
        Double-blind designs (where neither patient nor treating physician now which
        treatment arm the patient is in) are based on the same principle.</p><p>In
        clinical research there is often more at stake than the well-being of patients
        and the careers of the scientists involved. <em><em>Pfizer</em></em> and <em><em>Roche</em></em>
        last week each lost $1 billion in <a href=\"https://web.archive.org/web/20120611095611/http://www.marketwatch.com/story/abbott-pfizer-lead-drug-stocks-lower-2010-03-12\">stock
        market value</a> after they both announced <a href=\"https://web.archive.org/web/20120611095611/http://www.pharmastrategyblog.com/2010/03/more-phase-iii-cancer-trials-flop-pfizer-sutent-and-roche-avastin.html\">negative
        results of large phase III cancer trials</a>. Drug companies therefore have
        a great interest in whether and when research findings are published, and
        that includes the raw clinical data. The selective publication of positive
        research findings is called <a href=\"https://web.archive.org/web/20120611095611/http://blogs.nature.com/mfenner/2009/11/18/publication-bias-in-clinical-trials\">publication
        bias</a> and the <a href=\"https://web.archive.org/web/20120611095611/http://blogs.nature.com/mfenner/2008/08/02/fdaaa-push-to-open-data-in-clinical-medicine\">mandatory
        reporting of clinical trial results in ClinicalTrials.gov</a> was introduced
        by the FDA to reduce publication bias.</p><h3 id=\"summary\">Summary</h3><p>Online
        tools can help with doing clinical research and there is probably a lot of
        untapped potential. From the perspective of an individual researcher or a
        small research group, it probably makes the most sense to develop and/or use
        tools that solve specific problems. I use the online project management tool
        <a href=\"https://web.archive.org/web/20120611095611/http://basecamphq.com/\">Basecamp</a>
        to coordinate one clinical research project. And I have created a web-based
        <a href=\"https://web.archive.org/web/20120611095611/http://www.mh-hannover.de/studien/\">clinical
        trials registry</a> for our university hospital. The internet version of this
        registry helps patients and referring physicians to find clinical trials at
        our institution. The intranet version helps us manage our clinical trials,
        e.g. by keeping all required documents in one place, keeping track of the
        patients registered in clinical trials, and serious adverse event reporting.
        And I don't see why clinical researchers can't adopt the <a href=\"https://web.archive.org/web/20120611095611/http://pantonprinciples.org/\">Panton
        Principles</a> \u2013 which endorse that data related to published science
        should be explicitly placed in the public domain \u2013 whenever possible.</p><h2
        id=\"references\">References</h2><p>Hrynaszkiewicz I, Norton ML, Vickers AJ,
        Altman DG. Preparing raw clinical data for publication: guidance for journal
        editors, authors, and peer reviewers. <em>BMJ</em>. 2010;340(jan28 1):c181-c181.
        doi:<a href=\"https://doi.org/10.1136/bmj.c181\">10.1136/bmj.c181</a></p><p>Simmonds
        MC, Higginsa JPT, Stewartb LA, Tierneyb JF, Clarke MJ, Thompson SG. Meta-analysis
        of individual patient data from randomized trials: a review of methods used
        in practice. <em>Clinical Trials</em>. 2005;2(3):209-217. doi:<a href=\"https://doi.org/10.1191/1740774505cn087oa\">10.1191/1740774505cn087oa</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ How do researchers use online journals?
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/how-do-researchers-use-online-journals/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw4t</id>\n        <published>2010-03-08T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-18T08:25:36.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/17071467_11820b826c.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/17071467_11820b826c.jpeg\"></p><figure
        class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/rb2_large_gray-3.png\"
        class=\"kg-image\" alt=\"ResearchBlogging.org\" loading=\"lazy\" width=\"70\"
        height=\"85\"></figure><p>Last Monday I was listening to a very interesting
        presentation by <a href=\"https://web.archive.org/web/20120611102310/http://www.ucl.ac.uk/infostudies/ian-rowlands/\">Ian
        Rowlands</a>, reader in scholarly communication in the <a href=\"https://web.archive.org/web/20120611102310/http://www.infostudies.ucl.ac.uk/\">Department
        of Information Studies</a> at University College London. He and his colleagues
        are interested in how researchers find and use information, and how this has
        changed with the internet, especially for the <a href=\"https://web.archive.org/web/20120611102310/http://www.jisc.ac.uk/whatwedo/programmes/resourcediscovery/googlegen.aspx\">Google
        Generation</a> (people born after 1993). If you want to be part in this research
        (and have some fun), you can take part in the <a href=\"https://www.bbc.co.uk/labuk/experiments/webbehaviour\">BBC
        Web Behaviour Test</a>. The test will help you discover which species of web
        animal you are (I'm a <strong><strong>fox</strong></strong>).</p><p>In another
        project, funded by the Research Information Network (<a href=\"https://web.archive.org/web/20120611102310/http://www.rin.ac.uk/\">RIN</a>),
        Ian and his colleagues are studying how researchers are using electronic journals.
        The findings of the first part of the project were presented and discussed
        in a <a href=\"https://web.archive.org/web/20120611102310/http://www.rin.ac.uk/news/events/e-journals-revolution-how-use-scholarly-journals-shaping-research\">workshop
        last July</a>. The presentations are available as PDF download, and as <a
        href=\"https://web.archive.org/web/20120611102310/http://www.rin.ac.uk/resources/rin-publications/podcasts/e-journals-revolution-podcast\">podcast</a>
        with interviews of the speakers. The findings were summarized in a paper also
        published last July: <strong><strong>Online use and information seeking behaviour:
        institutional and subject comparisons of UK researchers</strong></strong>.</p><p>In
        the paper, the use of <a href=\"https://web.archive.org/web/20120611102310/http://www.oxfordjournals.org/\">Oxford
        Journals</a> by 10 major UK research institutions was analyzed in the fields
        of life sciences, economics and history, using the server logs for the full
        year 2007. Some of the key findings of the study include:</p><h3 id=\"one-third-of-users-access-oxford-journals-outside-business-hours\">One
        third of users access Oxford Journals outside business hours</h3><p>9.7% of
        uses happened on a Saturday/Sunday and 30.1% between 6 PM and 9 AM. This means
        that about one third of users accessed Oxford Journals outside typical business
        hours, either working late or from home (the study didn't distinguish between
        these two). These numbers indicate that remote access (from home, but probably
        also when traveling) is important for many users. This is obviously not an
        issue for Open Access journals, but institutions need to provide practical
        solutions (<a href=\"https://web.archive.org/web/20120611102310/http://en.wikipedia.org/wiki/Virtual_private_network\">VPN</a>,
        etc.) for subscription journals. From personal experience this remote access
        is still overly complicated. And these numbers also mean that librarians will
        not be available for support questions one third of the time.</p><h3 id=\"around-40-of-sessions-originated-from-a-google-search\">Around
        40% of sessions originated from a Google Search</h3><p>In 2004 Oxford Journals
        opened up to Google for indexing. I didn't expect this important role that
        Google seems to play in finding scholarly papers, and I would be very interested
        in feedback from blog readers. Only 4% of sessions originated from Google
        Scholar (22% in economics). These results probably explain why Google Scholar
        hasn't seen that much development since it was launched. The search function
        at Oxford Journals was rarely used.</p><p>43% of users of history journals,
        but only 16% of users of life sciences journals used navigational tools (table
        of contents, etc.) provided by the journal. This statistic obviously doesn't
        look at users getting the table of contents via email or RSS, but it again
        shows that access via search now probably is more common than via browsing.<sup><a
        href=\"https://web.archive.org/web/20120611102310/http://blogs.plos.org/mfenner/2010/03/08/evaluating_usage_patterns_of_online_journals/#fn1\">1</a></sup></p><h3
        id=\"most-users-spend-little-time-on-journal-webpages-but-return-often\">Most
        users spend little time on journal webpages, but return often</h3><p>The average
        number of articles viewed per session was 1.1, and the average session time
        was just over 4 minutes. Users rather return often, usually via a search.
        These numbers indicate that journal webpages are not a place where users spend
        a lot of time. Unless journals change this (e.g. by more active involvement
        of users via comments and other social networking features, etc.), they probably
        can't expect to generate significant revenue from online advertising. The
        internet has not only dramatically changed the role of <a href=\"https://web.archive.org/web/20120611102310/http://blogs.nature.com/mfenner/2010/01/24/scientists-and-librarians-friend-or-foe\">libraries</a>,
        but also for journals, as users are mostly interested in single articles,
        rather than the journal as a whole.</p><h3 id=\"the-median-age-of-articles-was-48-months-life-sciences-73-months-economics-and-90-months-history-\">The
        median age of articles was 48 months (life sciences), 73 months (economics),
        and 90 months (history)</h3><p>In the life sciences only 25% of the articles
        were no more than 16 months old, but another 25% were over 104 months old.
        I would have expected that the median age of articles would be much lower
        in the life sciences (it was two years in a similar study with ScienceDirect<a
        href=\"https://web.archive.org/web/20120611102310/http://blogs.plos.org/mfenner/2010/03/08/evaluating_usage_patterns_of_online_journals/#fn2\">2</a>).
        It seems as if most papers are not accessed when they are published (in the
        first few months after publication), but rather as the result of a search
        strategy, e.g. when writing a paper.</p><h3 id=\"life-sciences-users-rarely-read-abstracts-on-publisher-platforms\">Life
        sciences users rarely read abstracts on publisher platforms</h3><p>This should
        not come as a surprise, as life sciences users typically read abstracts in
        specialized databases, particularly <strong><strong>PubMed</strong></strong>.
        But maybe Journal publishers should stop displaying papers in an abstract
        view, saving users and themselves some effort. <em><em>PLoS</em></em> journals
        don't have an abstract view, but the <em><em>Biomed Central</em></em> journals
        (which are also Open Access) do. Subscription journals (including <em><em>Nature</em></em>)
        typically display the abstract instead of full-text to users without subscription
        access, so there is also no need for a separate abstract view for them.</p><p>The
        number of PDF views was higher than the number of full-text HTML views (178,152
        vs. 106,582). This difference was much more pronounced in economics and history
        journals, probably indicating that here most papers were printed out and <a
        href=\"https://web.archive.org/web/20120611102310/http://blogs.nature.com/mfenner/2010/01/10/how-do-you-read-papers-2010-will-be-different\">not
        read on the computer</a>.</p><h2 id=\"references\">References</h2><p>Nicholas,
        D., Clark, D., Rowlands, I., &amp; Jamali, H. (2009). Online use and information
        seeking behaviour: institutional and subject comparisons of UK researchers
        <em>Journal of Information Science, 35</em> (6), 660-676 https://doi.org/<a
        href=\"https://web.archive.org/web/20120611102310/http://dx.doi.org/10.1177/0165551509338341\">10.1177/0165551509338341</a></p><p><sup>1</sup>
        My July 2008 blog post <a href=\"https://front-matter.io/mfenner/do-online-journals-narrow-science-and-scholarship\">Do
        online journals narrow science and scholarship?</a> discussed potential consequences.</p><p><sup>2</sup>
        CIBER, Evaluating the usage and impact of e-journals in the UK. Working paper
        5. Available at <a href=\"https://web.archive.org/web/20120611102310/http://www.ucl.ac.uk/infostudies/research/ciber/\">http://www.ucl.ac.uk/infostudies/research/ciber/</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ German Research Foundation says that numbers
        aren\u2019t everything ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/german-research-foundation-says-that-numbers-arent-everything/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw4v</id>\n        <published>2010-03-01T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-18T08:27:43.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/76463757_24a1858d2e_m.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/76463757_24a1858d2e_m.jpeg\"></p><p>Last
        Tuesday the <em><em>German Research Foundation</em></em> (DFG) <a href=\"https://web.archive.org/web/20120611102053/http://www.dfg.de/en/service/press/press_releases/2010/pressemitteilung_nr_07/index.html\">announced</a>
        changes to the grant application process, going in effect in July. Researchers
        are no longer allowed to list all their publications in their grant proposals.
        The number of publications is limited to five per researcher and to two per
        year of planned funding (e.g. 6 papers for a 3-year grant). Publications submitted
        but not yet accepted for publication will no longer be allowed.</p><p>Some
        of the reasoning behind this change was explained in the press conference
        where the policy change was announced. The DFG wants to put more emphasis
        on quality instead of quantity, in other words counteract the trend to publish
        several small pieces of incremental research findings (the <a href=\"https://web.archive.org/web/20120611102053/http://scienceblogs.com/drugmonkey/2009/01/repost_thoughts_on_the_least_p.php\">least
        publishable unit</a> or <em><em>LPU</em></em>). The DFG didn't say so, but
        this might also reduce the practice of \u201Chonorary coauthorship\u201D with
        some researchers being coauthors of 20 or even 50 papers per year. And the
        DFG is not happy with the increasing use of the Journal Impact Factor and
        other metrics as a token measure for the quality of research output. And as
        a reaction to problems with publication lists in <a href=\"https://web.archive.org/web/20120611102053/http://www.spiegel.de/unispiegel/studium/0,1518,622474,00.html\">G&amp;Atilde;\xB6ttingen</a>
        they want to stop the practice of including unpublished work in reference
        lists for grant applications.</p><p>These changes will decrease the administrative
        workload of the applicant, reviewer and the DFG. With much shorter reference
        lists in grant applications, reviewers will have it much easier to take a
        closer look at the research output of the applicant, instead of relying on
        an unfortunate proxy such as the <em><em>Journal Impact Factor</em></em>.
        Researchers seeking funding from the DFG will now probably be more likely
        to write fewer but more substantial papers. And research that doesn't have
        the potential for a substantial paper, but is nevertheless worth publishing,
        can be quickly published in a reasonable journal instead of going through
        several rounds of submissions to a number of journals.</p><p>But how do you
        select your five best publications (assuming you have written more than five)?
        Choices include:</p><ul><li>publication date, e.g. a list of the five most
        recent publications</li><li>Journal Impact Factor</li><li>citation counts,
        page views, downloads or other article-level metrics</li><li>personal preference</li></ul><p>Using
        my personal preference (and not too much thought), I picked four papers and
        one correspondence:</p><ul><li><em><em>Shioda T, Fenner MH, Isselbacher KJ</em></em>
        Msg1, a novel melanocyte-specific gene, encodes a nuclear protein and is associated
        with pigmentation. <em><em>PNAS</em></em> 1996 <a href=\"https://web.archive.org/web/20120611102053/http://www.ncbi.nlm.nih.gov/pmc/articles/PMC37985/?tool=pubmed\">PubMed
        Central</a><br>The first paper from my postdoctoral research project. We identified
        and cloned a new gene thought to be involved in cancer metastasis, using a
        technology called differential display to compare the gene expression profile
        of two melanoma cell lines. This was before the mouse and human genomes were
        sequenced, and before microarrays became available. What took us two years
        of work 15 years ago can now probably be done in a few weeks.</li><li><em><em>Sado
        T, Fenner MH, Tan SS Tam P, Shioda T, Li E</em></em> X Inactivation in the
        Mouse Embryo Deficient for Dnmt1: Distinct Effect of Hypomethylation on Imprinted
        and Random X Inactivation. <em><em>Dev Biol</em></em> 2000 <a href=\"https://web.archive.org/web/20120611102053/http://dx.doi.org/10.1006/dbio.2000.9823\">doi:10.1006/dbio.2000.9823</a><br>I
        spent most of my time as a post-doc generating a knockout mouse for the gene
        identified in the previous paper. As the knockout mouse had no obvious phenotype,
        it took another post-doc (the first author) to finish the project.</li><li><em><em>Krege
        S et al.</em></em> European consensus conference on diagnosis and treatment
        of germ cell cancer: a report of the second meeting of the European Germ Cell
        Cancer Consensus group (EGCCCG): part I. <em><em>Eur Urol</em></em> 2008 <a
        href=\"https://web.archive.org/web/20120611102053/http://dx.doi.org/10.1016/j.eururo.2007.12.024\">doi:10.1016/j.eururo.2007.12.024</a><br>This
        paper summarizes the conclusions of a consensus conference on the diagnosis
        and treatment of testicular cancer, and is the best review on the subject.
        I am one of over 80 coauthors, something I haven't done before or since. The
        journal published this as two papers because of length. This would have been
        a perfect paper for an Open Access journal, I hope I can convince the coauthors
        to do so when we update this in 2011.</li><li><em><em>Fenner MH, Beutel G,
        Gruenwald V.</em></em> Targeted therapies for patients with germ cell tumors.
        <em><em>Expert Opin Investig Drugs</em></em> 2008 <a href=\"https://web.archive.org/web/20120611102053/http://dx.doi.org/10.1517/13543784.17.4.511\">doi:10.1517/13543784.17.4.511</a><br>Testicular
        cancer is one of the few chemotherapy success stories, as most patients with
        advanced metastatic disease can be cured. Targeted therapies have become important
        treatment options in many cancers. This is the first review to look at the
        evidence for the use of targeted therapies in testicular cancer.</li><li><em><em>Fenner
        MH.</em></em> Duplication: stop favouring applicant with longest list. <em><em>Nature</em></em>
        2008 <a href=\"https://web.archive.org/web/20120611102053/http://dx.doi.org/10.1038/452029a\">doi:10.1038/452029a</a><br>This
        is a <em><em>Nature</em></em> correspondence, included here only to show that
        comments made in a Nature Network forum can end up in <em><em>Nature</em></em>.
        And because it is relevant to this blog post, as I suggested to <em><em>ask
        applicants to select their best three, five or ten papers</em></em> instead
        of giving grants or jobs to those with the longest publication list.</li></ul><p>The
        Wellcome Trust last year <a href=\"https://web.archive.org/web/20120611102053/http://www.wellcome.ac.uk/Funding/investigator-awards/Implementation/index.htm\">announced</a>
        a different change to they grant application process. Starting later this
        year, they will stop accepting proposals for project grants, and rather evaluate
        the reaseach output of the scientist asking for funding (<em><em>Investigator
        Awards</em></em>). They argue that researchers that alrady have shown excellence
        in the past shoudn't be burdened with the administrative overhead and restrictions
        of writing a detailed project proposal every three years.</p><p>It will be
        interesting to see how institutions and other research funders in Germany
        (e.g. <a href=\"https://web.archive.org/web/20120611102053/http://www.helmholtz.de/en/\">Helmholtz</a>
        or <a href=\"https://web.archive.org/web/20120611102053/http://www.wgl.de/\">Leibniz</a>)
        or elsewhere react to this DFG policy change. I would be happy if this is
        a step towards more reasonable publication policies. And I hope that the upcoming
        unique author identifier <a href=\"https://web.archive.org/web/20120611102053/http://www.orcid.org/\">ORCID</a>
        will not be used for even more complicated bibliometric calculations, but
        rather as a tool for researchers to showcase their most interesting work.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ There is still so much to learn in reference
        management ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/there-is-still-so-much-to-learn-in-reference-management/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw4j</id>\n        <published>2010-02-22T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-18T08:30:25.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/2587796561_36fea74569-1.jpg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/2587796561_36fea74569-1.jpg\"></p><p>Last
        week <a href=\"https://web.archive.org/web/20120611033209/http://wikify.org/\">Lambert
        Heller</a> and myself did a two-day workshop <em><em>Reference Management
        in Times of Web 2.0</em></em> for a group of German librarians. We introduced
        and tested the following five programs:</p><ul><li><a href=\"https://web.archive.org/web/20120611033209/http://www.refworks.com/\">RefWorks</a></li><li><a
        href=\"https://web.archive.org/web/20120611033209/http://www.zotero.org/\">Zotero</a></li><li><a
        href=\"https://web.archive.org/web/20120611033209/http://www.citeulike.org/\">CiteULike</a></li><li><a
        href=\"https://web.archive.org/web/20120611033209/http://www.mendeley.com/\">Mendeley</a></li><li><a
        href=\"https://web.archive.org/web/20120611033209/http://www.endnote.com/\">Endnote</a></li></ul><p>The
        goal of the workshop was to introduce the participants to the Web 2.0 aspects
        of these reference managers. We briefly talked about <a href=\"https://web.archive.org/web/20120611033209/http://www.mekentosj.com/papers\">Papers</a>
        and <a href=\"https://web.archive.org/web/20120611033209/http://www.citavi.com/\">Citavi</a>,
        but neither of them offers any Web 2.0 functionality. The goal of the workshop
        was <em><em>not</em></em> to pick the best reference manager. With the exception
        of <em><em>CiteULike</em></em> (which is more of a social bookmarking service
        and can't be used to directly put references into manuscripts), all of them
        are probably good choices for most users. For some of the minor differences,
        please check my reference manager chart that I have updated for the workshop
        (PDF <a href=\"https://web.archive.org/web/20120611033209/http://www.slideshare.net/mfenner/reference-manager-overview-2-1-3250074\">here</a>):</p><figure
        class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/Reference-Manager-Overview-1.jpg\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"472\" height=\"643\"></figure><p>We
        had used FriendFeed for the slides, links and comments in a <a href=\"https://web.archive.org/web/20120611033209/http://friendfeed.com/bibman2\">similar
        workshop last July</a>. This time we picked <a href=\"https://web.archive.org/web/20120611033209/http://www.sciencefeed.com/\">ScienceFeed</a>,
        both because ScienceFeed can be used for reference management, and to test
        the service that launched just three days earlier. The ScienceFeed group can
        be found <a href=\"https://web.archive.org/web/20120611033209/http://www.sciencefeed.com/zblit2\">here</a>,
        but is in German. FriendFeed and ScienceFeed are not only great for conference
        microblogging, but are also excellent teaching tools, especially in a workshop
        where every participant has an internet-connected computer. We also had a
        few people listening in and putting up comments.</p><p>The workshop did help
        me understand what could become one of the most important features of reference
        managers. (I would exclude <em><em>Endnote</em></em> because it doesn't allow
        public groups or sharing of full-text files). Libraries used to be places
        where you could find, store and read literature. A library would hold a subset
        of all the available literature, but still, far more texts than an individual
        could keep at his home. A library serves as an intermediary that helps the
        user get access to the literature he is interested in.</p><p>A reference manager
        that stores all references and the associated full-text PDF files in an accessible
        (public or password-protected) place can fullfill exactly the same role. It
        is not necessary that an individual user stores every reference and fulltext
        paper on his own computer. And he doesn't have to find all references for
        himself. Librarians could help with this, e.g. by not only handling a users
        search request but also filing the associated PDF files in a group folder.
        Other group folders would have the table of contents of your favorite journals
        (e.g. <a href=\"https://web.archive.org/web/20120611033209/http://www.citeulike.org/journals\">CiteULike
        Journals</a>). We used to go to the library for exactly these things. And
        now we do this all on our own, often not asking for help from our local library.</p><p>In
        the last session I talked about non-traditional ways to find scientific literature.
        Traditional would mean one of the following search strategies, summarized
        by Duncan Hull et al.<sup><a href=\"https://web.archive.org/web/20120611033209/http://blogs.plos.org/mfenner/2010/02/22/there_is_still_so_much_to_learn_in_reference_management/#fn1\">1</a></sup>:</p><ul><li><em><em>Search</em></em>
        \u2013 Search bibliographic databases</li><li><em><em>Browse</em></em> \u2013
        Scan tables of contents</li><li>Recommend \u2013 Recommendations by colleagues</li></ul><p><em><em>Twitter</em></em>
        is just a modern tool for strategies <em><em>#2</em></em> (check the Twitter
        list <a href=\"https://web.archive.org/web/20120611033209/http://twitter.com/mfenner/science-journals\">@mfenner/science-journals</a>
        for some science journals using Twitter to announce interesting articles)
        and <em><em>#3</em></em> (papers recommended by friends you talk to via Twitter).</p><p>The
        non-traditional approach basically lets other people do the work for you.
        Some examples include:</p><ul><li>Experts pick noteworthy papers in your field
        \u2013 <a href=\"https://web.archive.org/web/20120611033209/http://www.f1000.com/\">Faculty
        of 1000</a> and <a href=\"https://web.archive.org/web/20120611033209/http://www.researchblogging.org/\">Research
        Blogging</a>.</li><li>You follow what people with similar interests are reading
        \u2013 <em><em>CiteULike</em></em> and <em><em>Mendeley</em></em></li><li>Recommendations
        based on what is in your library \u2013 <a href=\"https://web.archive.org/web/20120611033209/http://blog.citeulike.org/?p=136\">CiteULike
        recommendations</a></li><li>Most popular articles in your research field of
        interest \u2013 <em><em>CiteULike</em></em> and <em><em>Mendeley</em></em>.
        The <em><em>PLoS</em></em> <a href=\"https://web.archive.org/web/20120611033209/http://www.plos.org/cms/node/485\">article-level
        metrics</a> have the potential to do the same.</li></ul><h3 id=\"references\">References</h3><p><em><em>Hull
        D, Pettifer SR, Kell DB.</em></em> Defrosting the digital library: bibliographic
        tools for the next generation web. <em><em>PLoS Computational Biology</em></em>.
        2008 https://doi.org/<a href=\"https://web.archive.org/web/20120611033209/http://dx.doi.org/10.1371/journal.pcbi.1000204\">10.1371/journal.pcbi.1000204</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ ScienceFeed: Interview with Ijad Madisch
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/sciencefeed-interview-with-ijad-madisch/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw4k</id>\n        <published>2010-02-15T00:00:00.000+00:00</published>\n\t\t<updated>2023-07-05T18:02:30.000+00:00</updated>\n\t\t<category
        term=\"Interview\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Microblogging
        is blogging of short text messages, photos or other media and is best exemplified
        by <em><em>Twitter</em></em>. Twitter use has grown tremendously in 2009,
        and this also includes many scientists.<sup><a href=\"https://web.archive.org/web/20120611032951/http://blogs.plos.org/mfenner/2010/02/15/sciencefeed_interview_with_ijad_madisch/#fn1\">1</a></sup>
        <em><em>FriendFeed</em></em> is a another microblogging tool that not only
        allows sending of short text messages, but connects them together in groups
        and discussions threads similar to what you can do in online forums. FriendFeed,
        especially <a href=\"https://web.archive.org/web/20120611032951/http://friendfeed.com/the-life-scientists\">The
        Life Scientists</a> group has been a popular place for many scientists for
        the last 18 months or so. <a href=\"https://web.archive.org/web/20120611032951/http://network.nature.com/people/U42E63119/profile\">Cameron
        Neylon</a> wrote a good introduction to the service back in June 2008: <a
        href=\"https://web.archive.org/web/20120611032951/http://blog.openwetware.org/scienceintheopen/2008/06/12/friendfeed-for-scientists-what-why-and-how/\">FriendFeed
        for scientists: what, why, and how?</a>. FriendFeed is a great tool for conference
        blogging, and the ISBM 2008 conference was probably the first scientific conference
        where it was used extensively, resulting in a <em><em>PLoS Computational Biology</em></em>
        paper.<sup><a href=\"https://web.archive.org/web/20120611032951/http://blogs.plos.org/mfenner/2010/02/15/sciencefeed_interview_with_ijad_madisch/#fn2\">2</a></sup>
        FriendFeed is also often used to comment on blog posts, and here it is competing
        for attention with comments that are put directly on a blog. FriendFeed is
        a good example for a generic Web 2.0 tool that is much more useful to scientists
        than many Web 2.0 tools targeted specifically at scientists (the <a href=\"https://web.archive.org/web/20120611032951/http://fcw.com/Articles/2009/10/26/NIH-grant-creates-Facebook-for-Scientists.aspx\">Facebooks
        for scientists</a>).</p><p>FriendFeed <a href=\"https://web.archive.org/web/20120611032951/http://www.facebook.com/press/releases.php?p=116581\">was
        acquired by Facebook</a> in August 2009, and users started to worry about
        the long-term future of FriendFeed. An Open Source version of the FriendFeed
        web server was recently released as <a href=\"https://web.archive.org/web/20120611032951/http://bret.appspot.com/entry/tornado-web-server\">Tornado</a>
        (source code on <a href=\"https://web.archive.org/web/20120611032951/http://github.com/facebook/tornado\">GitHub</a>).
        Although other services (including <em><em>Facebook</em></em>) offer similar
        functionality, no service has (yet) emerged as an alternative popular with
        scientists. FriendFeed use seemed to be declining at the two recent <em><em>Science
        Online London 2009</em></em> and <em><em>ScienceOnline2010</em></em> conferences,
        as more and more people were using Twitter.</p><p>Last Tuesday <a href=\"https://web.archive.org/web/20120611032951/http://www.google.com/buzz\">Google
        Buzz</a> was released. <em><em>Buzz</em></em> is also a microblogging service,
        tightly integrated with <em><em>Google Mail</em></em> and <em><em>Google Reader</em></em>.
        If offers many of the same features as <em><em>FriendFeed</em></em>, and because
        it integrates with Google Mail, it has a large number of potential users from
        the start \u2013 including a large number of people involved in the Science
        Bloggosphere. <em><em>Buzz</em></em> will certainly get some of the features
        that are still missing, e.g. an easy way to import content from other sources,
        including a bookmarklet. And <em><em>Buzz</em></em> works very well on iPhone
        and Android phones and there also uses location information \u2013 e.g. all
        the <em><em>Buzz</em></em> discussions near you. But at the moment many people
        wonder how best to integrate <em><em>Buzz</em></em> with <em><em>FriendFeed</em></em>
        and <em><em>Twitter</em></em>, and all the other online tools they use \u2013
        it doesn't make sense to read the same content again and again on all these
        services.</p><p>In this context it is very interesting to see <a href=\"https://web.archive.org/web/20120611032951/http://www.sciencefeed.com/\">ScienceFeed</a>
        launching as a new microblogging service this week. <em><em>ScienceFeed</em></em>
        in many ways is similar to <em><em>FriendFeed</em></em>, but tries to add
        features of particular interest to scientists. I spoke with <em><em>Ijad Madisch</em></em>
        about ScienceFeed.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://web.archive.org/web/20120611032951im_/http://gallery.me.com/mfenner/100079/ijad_madisch/web.jpg\"
        class=\"kg-image\" alt loading=\"lazy\"></figure><h3 id=\"1-what-is-sciencefeed\">1.
        What is ScienceFeed?</h3><p>ScienceFeed is science as it happens, communicated
        through a microblogging platform. Conceptualized and designed by scientists,
        it is a bridge between online scientific networking platforms, scientific
        databases, and the wider online science community. The ScienceFeed platform
        allows users to post microblogs, sometimes just a few sentences, on scientific
        headlines, new findings, controversy, conferences and ideas related to science.
        Community members can follow the feeds of fellow members and comment on topics
        in which they are interested, allowing real-time communication and transfer
        of ideas.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://web.archive.org/web/20120611032951im_/http://gallery.me.com/mfenner/100079/sciencefeed_screenshot/web.jpg\"
        class=\"kg-image\" alt loading=\"lazy\"></figure><p>ScienceFeed is an interactive
        and dynamic platform \u2013 like science itself. Here, scientists, journalists,
        librarians, students, and those with an interest in science, will be able
        to communicate in a way that has no borders. Individuals from all over the
        world are able to participate and observe, helping to make science accessible
        to all. Integral to the concept of Science 2.0 is having online resources
        that are archivable and searchable \u2013 ScienceFeed will do just this. Science
        is not limited to the laboratory: it happens through interactions of communities.
        ScienceFeed is excited to build such a community.</p><h3 id=\"2-how-is-sciencefeed-different-from-friendfeed\">2.
        How is ScienceFeed different from FriendFeed?</h3><p>In basic functionality,
        ScienceFeed isn't much different to <a href=\"https://web.archive.org/web/20120611032951/http://friendfeed.com/the-life-scientists\">FriendFeed</a>.
        However, I think with the help of the community we will develop and add applications
        to the platform that could make it very efficient for scientific communication.
        There are two differences from FriendFeed which we have already implemented:
        1) Specific scientific publications can easily be searched for and then entered
        as a linked-in reference within a feed, and, 2) Groups can be marked as an
        event (e.g. a conference). My vision is to have event streams in ScienceFeed,
        which then can be visualized and presented in a much better way. However,
        the most important part is that we listen to the feedback of the community
        and develop specific applications based on their ideas and feedback.</p><h3
        id=\"3-what-special-features-does-sciencefeed-provide-for-conference-microblogging\">3.
        What special features does ScienceFeed provide for conference microblogging</h3><p>An
        important feature from ScienceFeed is that groups can be marked as a specific
        event, such as a conference. Administrators of these groups will be able to
        import hashtags from Twitter, so all tweets will be aggregated and displayed
        within this group. A possibility for future growth is the integration of an
        entire conference program (sessions, panels, etc.) into the group, which then
        can be commented on by group members. It is important to us that the scientific
        community has an input into the development of this feature so that we can
        build a stronger, more efficient platform based on the needs of our users.</p><h3
        id=\"4-can-you-import-references-into-sciencefeed-only-via-your-reference-database-or-also-via-citeulike-or-other-bookmarking-service\">4.
        Can you import references into ScienceFeed only via your reference database,
        or also via CiteULike or other bookmarking service?</h3><p>Martin, thank you
        so much for this great idea. Based on your feedback we worked hard to make
        this happen before launch. Yes, now ScienceFeed can import from other bookmarking
        services such as <a href=\"https://web.archive.org/web/20120611032951/http://www.citeulike.org/\">CiteUlike</a>
        or <a href=\"https://web.archive.org/web/20120611032951/http://www.connotea.org/\">Connotea</a>.
        Furthermore ScienceFeed supports <a href=\"https://web.archive.org/web/20120611032951/http://www.oclc.org/productworks/coins.htm\">CoiNS</a>,
        which identifies automatically based on a weblink whether or not bibliographic
        data is in the specified URL.</p><h3 id=\"5-how-is-sciencefeed-different-from-twitter\">5.
        How is ScienceFeed different from Twitter?</h3><p>There are several differences,
        but the largest are that in ScienceFeed there is no character limitation and
        groups can be tagged as a specific event \u2013 facilitating real-time, online
        communication about the event.</p><h3 id=\"6-what-is-the-advantage-of-having-a-social-networking-tool-specifically-for-scientists\">6.
        What is the advantage of having a social networking tool specifically for
        scientists?</h3><p>I think the most important part is the non-dilution of
        information in an environment where the platform and focus is specifically
        on science. Consider the following: You can find a biomedical scientific paper
        by searching in Google, but you could also use PubMed, which has a high probability
        of faster and better results. It is the same as within <a href=\"https://web.archive.org/web/20120611032951/https://www.researchgate.net/\">ResearchGATE</a>:
        You have large groups (Methods, Immunology, Neuroscience, Philosophy, etc.)
        with a very focused population, which again makes your search more directed
        and efficient with better results.</p><h3 id=\"7-what-is-the-relationship-between-sciencefeed-and-researchgate\">7.
        What is the relationship between ScienceFeed and ResearchGATE?</h3><p>ScienceFeed
        will be a scientific microblogging platform completely autonomous from ResearchGATE,
        because I think they target the same group, but with various usage patterns.</p><p>The
        publication reference tool used for inserting papers into ScienceFeed accesses
        the custom-built database of ResearchGATE. This database now has a public
        API which makes it possible for everyone to connect to the ResearchGATE literature
        database. I think that microarticles which are pretty successful in Researchgate
        (published in our ResearchBLOG) could be a part of ScienceFeed as well. I
        see ScienceFeed as a platform which will be useful to various scientific platforms
        as <a href=\"https://web.archive.org/web/20120611032951/http://www.mendeley.com/\">Mendeley</a>,
        <a href=\"https://web.archive.org/web/20120611032951/http://www.academia.edu/\">Academia</a>,
        <a href=\"https://web.archive.org/web/20120611032951/https://www.researchgate.net/\">ResearchGATE</a>,
        etc. It could be a platform that helps connect all these different platforms.</p><h3
        id=\"8-will-there-be-a-publicly-available-api-for-sciencefeed\">8. Will there
        be a publicly available API for ScienceFeed?</h3><p>Yes, there will be an
        API.</p><h3 id=\"9-what-are-your-responsibilities-in-sciencefeed\">9. What
        are your responsibilities in ScienceFeed?</h3><p>I am, as in ResearchGATE,
        one of the co-founders and a kind of CEO. I want to build a team of innovative
        and forward-thinking individuals to help develop ideas and work conceptually
        on the future directions of ScienceFeed.</p><h3 id=\"10-what-did-you-do-before-working-on-sciencefeed\">10.
        What did you do before working on ScienceFeed?</h3><p>I am a co-founder and
        CEO of ResearchGATE and I am also working at Massachusetts General Hospital,
        Harvard Medical School, in Boston as a researcher. Before ResearchGATE I studied
        Medicine and Computer Science and completed my doctoral thesis in Virology,
        while working for some time in Gastroenterology as a medical doctor.</p><h3
        id=\"11-could-you-provide-contact-information-for-people-that-have-further-questions-about-sciencefeed\">11.
        Could you provide contact information for people that have further questions
        about ScienceFeed?</h3><p>I can be contacted anytime at: <a href=\"https://web.archive.org/web/20120611032951/mailto:ijad.madisch@sciencefeed.com\">ijad.madisch@sciencefeed.com</a>.</p><h2
        id=\"references\">References</h2><p>Bonetta L. Should You Be Tweeting? <em>Cell</em>.
        2009;139(3):452-453. doi:<a href=\"https://doi.org/10.1016/j.cell.2009.10.017\">10.1016/j.cell.2009.10.017</a></p><p>Saunders
        N, Beltr\xE3o P, Jensen L, et al. Microblogging the ISMB: A New Approach to
        Conference Reporting. <em>PLoS Comput Biol</em>. 2009;5(1):e1000263. doi:<a
        href=\"https://doi.org/10.1371/journal.pcbi.1000263\">10.1371/journal.pcbi.1000263</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Happy third birthday Nature Network! ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/happy-third-birthday-nature-network/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw4m</id>\n        <published>2010-02-14T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-18T08:32:15.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/3276406889_c13486bbfb_o.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/3276406889_c13486bbfb_o.jpeg\"></p><p>Nature
        Network turns <a href=\"https://web.archive.org/web/20120611031820/http://blogs.nature.com/nautilus/2008/02/happy_birthday_nature_network.html\">3
        years old today</a>, and it has been a very interesting ride. I wasn't around
        when Nature Network started, but posted by first Gobbledygook blog post (the
        blog had a different name back then) in August 2007. We passed the <a href=\"https://web.archive.org/web/20120611031820/http://network.nature.com/people/U6E5B2CE1/blog/2010/01/26/nature-network-blogs-receives-50-000th-comment\">50.000
        comments milestone</a> just a few weeks ago. And we were told that big changes
        to the blogging platform underneath are imminent.</p><p>I have had many, many
        positive experiences in these 2 1/2 years. I learned a lot about science publishing
        and met a large number of very nice and very clever people both online and
        offline. I wrote about 160 blog posts and an uncounted number of comments
        during that time, and writing blog posts is still a lot of fun and something
        I like doing on a regular basis (I decided a while ago to aim for one blog
        post per week). I am also excited about the upcoming <a href=\"https://web.archive.org/web/20120611031820/http://www.scienceonlinelondon.org/\">Science
        Online London 2010</a> meeting, although the exact date and location have
        not yet been set.</p><p>Happy birthday.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Nature.com iPhone app in pictures ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/nature-com-iphone-app-in-pictures/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw4n</id>\n        <published>2010-02-08T00:00:00.000+00:00</published>\n\t\t<updated>2023-07-13T14:13:30.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Just four weeks ago I wrote
        a blog post titled <a href=\"r294649\">How do you read papers? 2010 will be
        different</a>. Not only have we since seen the announcement of the Apple <a
        href=\"https://web.archive.org/web/20120611032102/http://www.apple.com/ipad/\">iPad</a>,
        but last Monday the free Nature.com iPhone app was <a href=\"https://web.archive.org/web/20120611032102/http://www.nature.com/press_releases/iphone.html\">launched</a>.
        The application gives access to the full text of all <em><em>Nature</em></em>
        and <em><em>Nature News</em></em> content (through until 30 April 2010, how
        access is handled afterwards hasn't been announced yet). A version for the
        <em><em>Android</em></em> platform was promised for April, and the app will
        work with the just-announced <em><em>iPad</em></em>. I included a few screenshots
        for those without an iPhone or iPod Touch. A free Nature.com personal account
        is needed to use the app.</p><figure class=\"kg-card kg-image-card\"><img
        src=\"https://web.archive.org/web/20120611032102im_/http://gallery.me.com/mfenner/100079/IMG_0626/web.jpg\"
        class=\"kg-image\" alt loading=\"lazy\"></figure><p>The iPhone app doesn't
        use HTML or PDF but rather <a href=\"https://web.archive.org/web/20120611032102/http://blogs.nature.com/wp/nascent/2010/02/new_naturecom_iphone_app.html\">the
        ePub format</a>. The Nature.com website will soon offer downloads in ePub
        format (an example article is <a href=\"https://web.archive.org/web/20120611032102/http://blogs.nature.com/wp/nascent/article.epub\">here</a>).
        <a href=\"https://web.archive.org/web/20120611032102/http://www.adobe.com/products/digitaleditions/\">Adobe
        Digital Editions</a> and <a href=\"https://web.archive.org/web/20120611032102/http://www.lexcycle.com/\">Stanza</a>
        are examples of ePub readers. In contrast to PDF, ePub adapts to the screen
        size and is therefore a much better format for the iPhone.</p><figure class=\"kg-card
        kg-image-card\"><img src=\"https://web.archive.org/web/20120611032102im_/http://gallery.me.com/mfenner/100079/IMG_0627/web.jpg\"
        class=\"kg-image\" alt loading=\"lazy\"></figure><p>References are links in
        the text, clicking on them opens a new window.</p><figure class=\"kg-card
        kg-image-card\"><img src=\"https://web.archive.org/web/20120611032102im_/http://gallery.me.com/mfenner/100079/IMG_0628/web.jpg\"
        class=\"kg-image\" alt loading=\"lazy\"></figure><p>Figures are also links
        in the text that open in a new window. The figures can be saved to the iPhone
        Photos application.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://web.archive.org/web/20120611032102im_/http://gallery.me.com/mfenner/100079/IMG_0630/web.jpg\"
        class=\"kg-image\" alt loading=\"lazy\"></figure><p>The iPhone app also gives
        access to the full text of <em><em>Nature News</em></em>. In contrast to <em><em>Nature</em></em>
        papers, images are rendered within the text.</p><figure class=\"kg-card kg-image-card\"><img
        src=\"https://web.archive.org/web/20120611032102im_/http://gallery.me.com/mfenner/100079/IMG_0640/web.jpg\"
        class=\"kg-image\" alt loading=\"lazy\"></figure><p><em><em>Nature</em></em>
        and <em><em>Nature News</em></em> content, as well as PubMed search results
        can be saved for later reading. This content (or rather the <em><em>DOI</em></em>)
        is also available from the new <a href=\"https://web.archive.org/web/20120611032102/http://www.nature.com/mobileapps/web/bookmarks\">Nature.com
        mobile apps</a> page. Because the <em><em>Nature.com mobile apps</em></em>
        page stores only the <em><em>DOI</em></em>, a <em><em>Nature</em></em> subscription
        is required to access the full-text article from there. From the <em><em>Nature.com
        mobile apps</em></em> page you can also export the citation in <em><em>RIS</em></em>
        format.</p><p>The Nature.com iPhone app also searches both Nature.com and
        PubMed. Regular searches can be saved.</p><figure class=\"kg-card kg-image-card\"><img
        src=\"https://web.archive.org/web/20120611032102im_/http://gallery.me.com/mfenner/100079/IMG_0633/web.jpg\"
        class=\"kg-image\" alt loading=\"lazy\"></figure><p>PubMed searches will retrieve
        abstracts, with a link to the full-text article via the <em><em>DOI</em></em>.</p><figure
        class=\"kg-card kg-image-card\"><img src=\"https://web.archive.org/web/20120611032102im_/http://gallery.me.com/mfenner/100079/IMG_0635/web.jpg\"
        class=\"kg-image\" alt loading=\"lazy\"></figure><p><a href=\"https://web.archive.org/web/20120611032102/http://mekentosj.com/papers/iphone/\">Papers
        for iPhone</a> is another app that allows PubMed searches. You can also search
        for the latest <em><em>Nature</em></em> content, but the full-text content
        is available only with a subscription and only as HTML or PDF.</p><figure
        class=\"kg-card kg-image-card\"><img src=\"https://web.archive.org/web/20120611032102im_/http://gallery.me.com/mfenner/100079/IMG_0643/web.jpg\"
        class=\"kg-image\" alt loading=\"lazy\"></figure><p>Support for <a href=\"https://web.archive.org/web/20120611032102/http://www.web-books.com/Publishing/epub.htm\">ePub</a>
        is the most exiting feature for me, as it opens the door for many interesting
        mobile applications. I hope that more scientific journals will start to use
        the format (Hindawi was one of the first publishers <a href=\"https://web.archive.org/web/20120611032102/http://www.hindawi.com/epub.html\">to
        support ePub</a>), and that we then start to see mobile apps for more than
        a single journal.</p><p>Bug reports, suggestions and feature requests can
        be sent to <a href=\"https://web.archive.org/web/20120611032102/mailto:mobile%40nature.com\">mobile@nature.com</a>.
        Or add your comments to Henry Gee's <a href=\"https://web.archive.org/web/20120611032102/http://network.nature.com/people/henrygee/blog/2010/02/01/nature-on-your-iphone\">Nature
        On Your iPhone</a> post.</p><h3 id=\"references\">References</h3><p>Fenner
        M. How do you read papers? 2010 will be different. Published online January
        10, 2010. doi:<a href=\"https://doi.org/10.53731/r294649-6f79289-8cw4h\">10.53731/r294649-6f79289-8cw4h</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ A digital preservation primer for scientists
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/a-digital-preservation-primer-for-scientists/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw4p</id>\n        <published>2010-02-01T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-31T08:00:34.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p><em>This weeks's <a href=\"https://web.archive.org/web/20120611032500/http://www.corporeality.net/museion/2010/02/01/a-digital-preservation-primer-for-scientists/\">blog
        post</a> is a guest post on the Biomedicine on Display blog \u2013 I was kindly
        invited by Thomas Soderqvist from the Medical Museum of the University of
        Copenhagen.</em></p><blockquote>The first email was sent in 1964, but that
        first email has been lost forever. - <a href=\"https://web.archive.org/web/20100405101403/http://www.esf.org/ext-ceo-news-singleview/article/digital-preservation-alliance-set-to-tackle-sciences-new-frontier-368.html\">Lucy
        Nowell</a></blockquote><p>As we have moved to digital formats both for primary
        research data and scientific publications, digital preservation has become
        critical to secure permanent access to scientific information. Digital preservation
        turned out to be much more difficult than creating digital content, as preservation
        requires long-term thinking about many issues including file formats, storage
        solutions and funding. Digital preservation turned out to be too big for individual
        libraries, publishers or research disciplines, and large collaborative efforts
        were started in the last five years.</p><h3 id=\"alliance-for-permanent-access\">Alliance
        for Permanent Access</h3><p>The <a href=\"https://web.archive.org/web/20100405101403/http://www.alliancepermanentaccess.eu/\">Alliance
        for Permanent Access</a> is a European strategic framework for digital preservation
        of scientific information. The alliance coordinates the efforts of different
        funders, research support organizations and major European research laboratories
        (e.g. <a href=\"https://web.archive.org/web/20100405101403/http://public.web.cern.ch/\">CERN</a>
        or <a href=\"https://web.archive.org/web/20100405101403/http://www.esa.int/esaCP/index.html\">ESA</a>).</p><h3
        id=\"sustainable-digital-data-preservation-and-access-network-partners-datanet-\">Sustainable
        Digital Data Preservation and Access Network Partners (DataNet)</h3><p><a
        href=\"https://web.archive.org/web/20100405101403/http://www.nsf.gov/funding/pgm_summ.jsp?pims_id=503141\">Sustainable
        Digital Data Preservation and Access Network Partners</a> is a digital preservation
        project by the <a href=\"https://web.archive.org/web/20100405101403/http://www.nsf.gov/\">National
        Science Foundation</a>. The deadline for proposals was May 2009, and $100
        million will be awarded over the next five years. Wow.</p><h3 id=\"portico\">Portico</h3><p><a
        href=\"https://web.archive.org/web/20100405101403/http://www.portico.org/\">Portico</a>
        is a not-for-profit digital preservation service for scholarly content. Portico
        was launched in 2005 with initial support by <a href=\"https://web.archive.org/web/20100405101403/http://www.jstor.org/\">JSTOR</a>,
        <a href=\"https://web.archive.org/web/20100405101403/http://www.ithaka.org/\">Ithaka</a>,
        the <a href=\"https://web.archive.org/web/20100405101403/http://www.loc.gov/\">Library
        of Congress</a>, and the <a href=\"https://web.archive.org/web/20100405101403/http://www.mellon.org/\">Andrew
        W. Mellon Foundation</a>. The Portico archive currently contains close to
        15 million papers and is archiving journal content for many publishers and
        libraries for a <a href=\"https://web.archive.org/web/20100405101403/http://www.portico.org/publishers/pub_contribution.html\">fee</a>.
        Portico steps in (a so-called trigger event) when a publisher</p><ul><li>stops
        operations</li><li>ceases to publish a title</li><li>no longer offers back
        issues</li><li>has a castastrophic failure of the delivery platform</li></ul><h3
        id=\"file-formats\">File formats</h3><p><a href=\"https://web.archive.org/web/20100405101403/http://www.pdfa.org/\">PDF/A</a>
        was approved as an ISO standard for long-term archiving of electronic documents
        in 2005. Before PDF/A, many organizations (including our institution) used
        the raster graphics format TIFF. The major advantage of the PDF format is
        the handling text and vector graphics in addition to raster images, allowing
        full-text search and smaller file sizes. Because the PDFformat is constantly
        changing, PDF/A was based on a specific PDF version (1.4) with the following
        specifications:</p><ul><li>self-contained, no external images or fonts</li><li>no
        sound or movies</li><li>metadata in the <a href=\"https://web.archive.org/web/20100405101403/http://blogs.nature.com/wp/nascent/2008/12/xmp_labelling_for_nature.html\">XMP</a>
        format</li><li>no password protection</li></ul><p>Most scientific papers are
        now produced in XML, usually using the <a href=\"https://web.archive.org/web/20100405101403/http://dtd.nlm.nih.gov/\">NLM
        DTD</a>. The <a href=\"https://web.archive.org/web/20100405101403/http://dtd.nlm.nih.gov/archiving/\">Archiving
        and Interchange Tag Set</a> is a flavor of the NLM DTD that is intented for
        archiving.</p><h3 id=\"storage-solutions\">Storage solutions</h3><p>Hard disks,
        tape and optical media are possible storage solutions. Tape is the ideal solution
        for long-term storage of research papers, but the digital preservation of
        research data in many areas (e.g. sequencing, high-energy physics) can\u2019t
        be done with tape because of the exponential growth of these data. Hard disk
        storage has another problem: the <a href=\"https://web.archive.org/web/20100405101403/http://www.genomeweb.com/sequencing/wellcome-trust-sanger-institute-upgrade-sequencing-capacity-unveils-annual-revie\">energy
        requirements of data centers</a>.</p><p>We live in a digital world, and this
        of course includes how we do and communicate science. It is surprising that
        we have barely started to think about digital preservation.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Scientists and librarians: friend or foe?
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/scientists-and-librarians-friend-or-foe/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw4f</id>\n        <published>2010-01-24T00:00:00.000+00:00</published>\n\t\t<updated>2023-09-07T08:07:04.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/101350718_fa52fcef35.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/101350718_fa52fcef35.jpeg\"></p><p>Following
        the <em>ScienceOnline2010</em> conference, librarian Dorothea Salo <a href=\"https://web.archive.org/web/20120611111844/http://scienceblogs.com/bookoftrogool/2010/01/science_online_2010_scientists.php\">wrote
        on her blog</a>:</p>\n<blockquote>This disconnect is the number one threat
        to science librarianship today \u2013 perhaps to all academic librarianship.
        How can science libraries persist when scientists haven't the least notion
        that libraries or librarians are relevant to their work?</blockquote>\n<p>These
        are serious questions, and of course I don't have the answers. But I would
        like to add my thoughts from a researcher perspective. The role of libraries
        in providing teaching material for students (textbooks, etc.) is another story
        that I will not touch today.</p>\n<p>I'm old enough to remember the time (maybe
        15 years ago) before literature searches were possible via the Internet and
        scientific papers were available in electronic form. I had to go to the library
        to use Medline or Current Contents in printed form (and later on CD-ROM),
        or to flip through the newest issues of the most interesting journals. I would
        photocopy the papers I would then read at home, and then file away for later
        use.</p>\n<p><em>PubMed</em>, <em>Scopus</em>, <em>Web of Science</em>, and
        <em>Google Scholar</em> now allow me to search the literature from my desk
        at work (or from home). Most researchers (including myself) probably don't
        have the skills for sophisticated searches, but these tools <a href=\"https://web.archive.org/web/20120611111844/http://network.nature.com/people/U2929A0EA/blog/2008/03/22/i-am-not-yelling-not-out-loud\">more
        or less</a> get the job done. Electronic publishing means that I can obtain
        a paper directly from the journal (as long as I access the journal from a
        computer in the university network), and licensing is handled (almost) transparently
        by the library.</p>\n<p>These developments have dramatically reduced the time
        researchers spend at a library. This is good, as this saves them a lot of
        time. But interactions between researchers and librarians have also been dramatically
        reduced. Publishers and other companies (e.g. <em>Thomson Reuters</em>, <em>Mendeley</em>,
        <em>Faculty of 1000</em>, to name just a few) have used the opportunities
        to adapt their offerings to the internet (e.g. electronic-only journals) and
        to create new products that weren't possible (or even thinkable) before. Although
        libraries have in many ways adapted to the internet as well, they probably
        haven't seized the opportunity to the same degree. The homepage of my university
        library is a place I visit much less often than <em>PubMed</em> or the pages
        of my favorite journals. Some ideas of how this could be changed are listed
        below. Most of them are not new, but maybe at least some libraries haven't
        gone all the way to make their pages an attractive destination for the researchers
        of their institution [1].</p>\n<h3 id=\"provide-and-support-online-reference-manager\">Provide
        and support online reference manager</h3>\n<p>Institutions should support
        at least one online reference manager, possible options include (in no particular
        order) Zotero, Mendeley, Endnote Web, Refworks, and CiteULike. RefWorks and
        Endnote Web are commercial products and require a private (Endnote) and/or
        institutional license. The institution should either pick a free reference
        manager as its primary choice or buy an institutional license in order to
        allow every researcher and student to use these tools without additional cost
        [2].</p>\n<p>As we can't expect everybody to use the same reference manager,
        libraries have to help with several products. The easiest way to do so is
        via an online forum (see next paragraph), as this is more efficient than one-to-one
        support and allows experienced users to help out. Online reference managers
        provide additional features (e.g. they can be used from different computers,
        allow shared folders for groups of users) and should therefore be preferred
        over standalone applications.</p>\n<h3 id=\"online-user-training-and-support\">Online
        user training and support</h3>\n<p>User support is obviously one of the central
        functions of science libraries. This has two aspects: helping with a specific
        problem (e.g. finding scientific literature), but also training users to do
        this on their own. The required skills include the use of <em>PubMed</em>
        and other databases and reference managers such as <em>Endnote</em> or <em>Zotero</em>.
        Skills in <a href=\"https://en.wikipedia.org/w/index.php?title=Evidence-based_medicine&amp;oldid=1168875604\">evidence-based
        medicine</a> are critical to find and appreciate the appropriate medical literature,
        but in my experience, many physicians and medical students would benefit from
        additional training in this area.</p>\n<p>Introductory classes, help in person,
        or a phone call are sometimes the best way to do this, but often users require
        quick help for a specific situation that can best be done with online tools.
        Appropriate tools include email, online forums, <em>Twitter</em>, <a href=\"https://web.archive.org/web/20120611111844/http://www.yammer.com/\">Yammer</a>
        (a microblogging tool similar to Twitter but for institutions), <em>SlideShare</em>,
        <em>FaceBook</em> (and <em>StudiVZ</em> in Germany), <em>FriendFeed</em>,
        and Wikis. Every institution should make a decision about the services they
        plan to support, with emphasis on tools that are easy to use.</p>\n<h3 id=\"institutional-bibliographies\">Institutional
        bibliographies</h3>\n<p>A regularly updated listing of all publications of
        an institution is not only a valuable PR service but is often also required
        by administrations to evaluate research output. Librarians are often involved
        in this, but there is probably a lot of untapped potential. As <a href=\"https://doi.org/10.53731/r294649-6f79289-8cw3k\">unique
        identifiers for researchers</a> become more widespread, there really no longer
        is a need for researchers to compile publication lists themselves [3].</p>\n<h3
        id=\"article-deposition-in-institutional-repositories\">Article deposition
        in institutional repositories</h3>\n<p>Most journals allow researchers to
        post their accepted papers in institutional repositories of their institution.
        But because this requires technical skills and extra time, many researchers
        aren't particularly eager to make use of them. Institutional bibliographies
        can obviously be nicely integrated with institutional repositories, thus reducing
        redundant work.</p>\n<h3 id=\"help-authors-with-article-submissions\">Help
        authors with article submissions</h3>\n<p>Article processing charges for authors
        are often handled by their libraries, and sometimes libraries have <a href=\"https://web.archive.org/web/20120611111844/http://www.biomedcentral.com/info/libraries/membership\">membership
        deals</a> with publishers that give authors a discount. But researchers often
        are left alone with the article submission process. Most authors submit at
        most a handful of papers each year, and they have to deal not only with different
        article formats between journals (most notably different reference styles)
        but also different article submission systems (e.g. <a href=\"https://web.archive.org/web/20120611111844/http://network.nature.com/people/mfenner/blog/2009/03/25/editorial-manager-interview-with-richard-wynne\">Editorial
        Manager</a>, <a href=\"https://web.archive.org/web/20120611111844/http://www.ejpress.com/index.shtml\">eJournal
        Press</a>, <a href=\"https://web.archive.org/web/20120611111844/http://scholarone.com/products/manuscript/\">Manuscript
        Central</a> or <a href=\"https://web.archive.org/web/20120611111844/http://benchpress.highwire.org/\">BenchPress</a>).
        The total number of papers submitted by an institution is much larger, and
        thus at least some recurring problems could be avoided or at least the time
        required reduced with centralized support from the library.</p>\n<h3 id=\"help-with-web-20-tools-for-scientists\">Help
        with Web 2.0 tools for scientists</h3>\n<p>Libraries don't have to reinvent
        all the Web 2.0 tools for scientists that are already out there, but they
        are a good place to help interested researchers get started with some of them
        (e.g. <em>ResearchGate</em>, <em>Nature Network</em>, or <em>Academia.edu</em>).
        Ideally, these tools could be integrated into the library web pages via an
        API.</p>\n<p><em>Three events from last week inspired me to write this: a
        blog post by (and short Twitter conversation with) Dorothea Salo (<a href=\"https://doi.org/10.53731/r294649-6f79289-8cw3k\"><em>Science
        Online 2010: Scientists and librariansonline_2010_scientists.php</em></a>),
        a meeting with the other organizers of <a href=\"https://web.archive.org/web/20120611111844/http://bibcamp.wordpress.com/\"><em>BibCamp
        Hannover</em></a> (\u201Ca BarCamp for librarians and other hackers\u201D
        in May 2010), and a discussion via email with <a href=\"https://web.archive.org/web/20120611111844/http://network.nature.com/people/obst/profile\"><em>Oliver
        Obst</em></a> from the Medical Library, University of M\xFCnster.</em></p>\n<h3
        id=\"further-thoughts\">Further thoughts</h3>\n<ol><li>I would like to be
        proven wrong by great examples of libraries gone Web 2.0.</li><li>My university
        picked RefWorks as its primary reference manager.</li><li>Scopus is already
        pretty good at this.</li></ol>\n<h3 id=\"references\">References</h3>\n<p>Evidence-based
        medicine. (2023). In <em>Wikipedia</em>. <a href=\"https://en.wikipedia.org/w/index.php?title=Evidence-based_medicine&amp;oldid=1168875604\">https://en.wikipedia.org/w/index.php?title=Evidence-based_medicine&amp;oldid=1168875604</a></p>\n<p>Fenner,
        M. (2010). <em>ORCID or how to build a unique identifier for scientists in
        10 easy steps</em>. <a href=\"https://doi.org/10.53731/r294649-6f79289-8cw3k\">https://doi.org/10.53731/r294649-6f79289-8cw3k</a></p>\n<figure
        class=\"kg-card kg-image-card\"><img src=\"https://web.archive.org/web/20120611111844im_/http://www.linkwithin.com/pixel.png\"
        class=\"kg-image\" alt=\"Related Posts Plugin for WordPress, Blogger...\"
        loading=\"lazy\"></figure> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ ScienceOnline2010 \u2013 I wish I was there
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/scienceonline2010-i-wish-i-was-there/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw4g</id>\n        <published>2010-01-17T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-01T06:10:59.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p><a href=\"https://web.archive.org/web/20120611111833/http://www.scienceonline2010.com/\">ScienceOnline2010</a>
        just finished a few hours ago, and from what everyone was saying it was yet
        another wonderful meeting. I attended last year and moderated a session called
        <a href=\"https://web.archive.org/web/20120611111833/http://network.nature.com/people/mfenner/blog/2009/01/16/scienceonline09-providing-public-health-and-medical-information-to-all\">Providing
        public health and medical information to all</a>, but unfortunately could
        not come this year. News about <em><em>ScienceOnline2010</em></em> are <a
        href=\"https://web.archive.org/web/20120611111833/http://www.scienceonline2010.com/index.php/wiki/BlogMedia_Coverage/\">all
        over the place</a>, including <a href=\"https://web.archive.org/web/20120611111833/http://network.nature.com/people/henrygee/blog/2010/01/16/the-beowulf-effect\">from</a>
        our own Henry Gee.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://web.archive.org/web/20120611111833im_/http://farm3.static.flickr.com/2735/4077980037_193311abe6_d.jpg\"
        class=\"kg-image\" alt loading=\"lazy\"><figcaption>Flickr picture by missbakersflickr.</figcaption></figure><p><a
        href=\"https://web.archive.org/web/20120611111833/http://network.nature.com/people/steelgraham/profile\">Graham
        Steel</a> has more experience attending ScienceOnline remotely (<a href=\"https://web.archive.org/web/20120611111833/http://mcblawg.blogspot.com/2009/01/science-online-09-how-was-it-via.html\">Science
        Online '09 \u2013 How was it\u2026. via the internet?</a>), but I did my best
        to follow the meeting via <a href=\"https://web.archive.org/web/20120611111833/http://twitter.com/#search?q=%23scio10\">Twitter</a>,
        <a href=\"https://web.archive.org/web/20120611111833/http://friendfeed.com/scienceonline2010\">FriendFeed</a>,
        <a href=\"https://web.archive.org/web/20120611111833/http://www.flickr.com/search/?q=scio10\">Flickr</a>,
        <a href=\"https://web.archive.org/web/20120611111833/http://www.youtube.com/results?search_query=%23scio10\">YouTube</a>
        and of course <a href=\"https://web.archive.org/web/20120611111833/http://www.scienceonline2010.com/index.php/wiki/BlogMedia_Coverage/\">blogs
        and media</a>. There was even a <a href=\"https://web.archive.org/web/20120611111833/http://scienceblogs.com/scienceonline/2010/01/scienceonline2010_iphone_app.php\">ScienceOnline2010
        iPhone app</a>. Another ScienceOnline2010 trend was the widespread use of
        <a href=\"https://web.archive.org/web/20120611111833/http://www.theflip.com/\">Flip</a>
        for short videos such as this one:</p><p>The overall online coverage far exceeds
        what I see at my usual science meetings, but following the sessions live (including
        the ability to ask questions) is far more difficult. For that you need video
        and microblogging (or the two combined in <em><em>Second Life</em></em>).
        Video of sessions from two rooms was streamed live at <a href=\"https://web.archive.org/web/20120611111833/http://www.ustream.tv/channel/scienceonline2010\">Ustream</a>
        and <em><em>Second Life</em></em>, but Ustream didn't always work for me (didn't
        try Second Life, all sessions were recorded and will appear on <em><em>YouTube</em></em>
        next week).</p><p>For me and many others <em><em>FriendFeed</em></em> is the
        perfect microblogging tool for conferences (<a href=\"https://web.archive.org/web/20120611111833/http://dx.doi.org/10.1371/journal.pcbi.1000263\">Microblogging
        the ISMB: A New Approach to Conference Reporting</a>). But the use of <em><em>FriendFeed</em></em>
        in Science 2.0 conferences seems on the decline during the last 12 months
        because of <em><em>Twitter</em></em>, and at <em><em>ScienceOnline2010</em></em>
        it was no longer possible to follow sessions using <em><em>FriendFeed</em></em>.
        <em><em>Twitter</em></em> is wonderful for many things, but makes it very
        difficult to create a connected discussion around a particular topic such
        as a conference session. But the <em><em>Twitter</em></em> board was cool:</p><figure
        class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://web.archive.org/web/20120611111833im_/http://farm5.static.flickr.com/4042/4278414875_2673a584b7_d.jpg\"
        class=\"kg-image\" alt loading=\"lazy\"><figcaption>Flickr picture by SignalShare.</figcaption></figure><p>After
        <em><em>ScienceOnline2010</em></em> is before <a href=\"https://web.archive.org/web/20120611111833/http://www.scienceonlinelondon.org/\">Science
        Online London 2010</a>. The <a href=\"https://web.archive.org/web/20120611111833/http://blog.f1000.com/2010/01/15/on-the-run&amp;acirc;&amp;#128;&amp;#148;15jan10/\">first
        planning meeting</a> took place last Friday. We hope to announce the location
        and date in the coming weeks, but we are aiming for a bigger (with enough
        room for at least 250 people) and longer (two days) meeting with enough parallel
        sessions to cover all the topics that we care about.</p><p>One personal goal
        I have for <em><em>Science Online London 2010</em></em> is to provide an even
        better experience for those unable to attend in person. <em><em>Second Life</em></em>
        worked <a href=\"https://web.archive.org/web/20120611111833/http://network.nature.com/people/joannascott/blog/2009/09/07/science-online-london-links\">pretty
        well</a> for us last year, and we even had one speaker <a href=\"https://web.archive.org/web/20120611111833/http://seedmagazine.com/content/article/telepresent_at_the_future/\">giving
        his presentation</a> this way. But maybe we can do better. Livestreaming of
        good quality audio is probably the most important thing, the video quality
        seems less critical. Alternatively, we can synchronize the audio with the
        slides from the presentation, something <em><em>SlideShare</em></em> calls
        <a href=\"https://web.archive.org/web/20120611111833/http://www.slideshare.net/faqs/slidecast\">SlideCast</a>.
        We might also find better ways to use <em><em>Twitter</em></em> for microblogging,
        e.g. by using separate hashtags for every session and a <em><em>Twitter</em></em>
        board in the sessions.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ How do you read papers? 2010 will be different
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/how-do-you-read-papers-2010-will-be-different/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw4h</id>\n        <published>2010-01-10T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-31T07:59:31.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>In November 2008 I wrote a
        blog post called <a href=\"https://web.archive.org/web/20120611111551/http://network.nature.com/people/mfenner/blog/2008/11/02/how-do-you-read-papers\">How
        do you read papers?</a> The blog post was actually about different strategies
        to <em><em>find</em></em> interesting papers, e.g. browsing journal tables
        of content (TOC), different search strategies, filtering by papers others
        read, or filtering by experts (e.g. <em><em>Faculty of 1000</em></em>). A
        paper by <a href=\"https://web.archive.org/web/20120611111551/http://network.nature.com/people/duncan/profile\">Duncan
        Hull</a> et al. published around that time in <em><em>PLoS Computational Biology</em></em>
        (<a href=\"https://web.archive.org/web/20120611111551/http://dx.doi.org/10.1371/journal.pcbi.1000204\">Defrosting
        the Digital Library: Bibliographic Tools for the Next Generation Web</a>)
        also talked about finding strategies and the best tools for this.</p><p>In
        this blog post I want to talk about the actual reading of scientific papers
        that you found with one of the strategies mentioned above. There are some
        interesting recent developments, and I think we will see some significant
        changes in how we read papers in 2010.</p><h3 id=\"printed-journal\">Printed
        journal</h3><p>Holding the printed journal in your hands is probably still
        the most satisfying reading experience because of professional typesetting
        and color reproduction. But unless you have a personal journal subscription,
        it is not convenient as you would have to go to the library to read the paper.
        Plus, many journals no longer produce a printed version, or the library has
        only an electronic subscription.</p><h3 id=\"photocopy\">Photocopy</h3><p>This
        used to be the most common way to read papers 20 years ago. But the quality
        of photocopies is usually worse than a printout of an electronic version,
        and photocopies are far more inconvenient to obtain. Reading photocopied papers
        will only be necessary for the small number of journals that produce no electronic
        version, or for older papers.<sup><a href=\"https://web.archive.org/web/20120611111551/http://blogs.plos.org/mfenner/2010/01/10/how_do_you_read_papers_2010_will_be_different/#fn1\">1</a></sup></p><h3
        id=\"pdf-printout\">PDF printout</h3><p>This is the way most people read scientific
        papers today, unless they just want to look up small parts of it. Quality
        color printers have become affordable, and the reading experience is similar
        to the printed journal with the added convenience of electronic distribution.
        Most people use PDF printouts for reading, and later discard the paper copy,
        sometimes even the same day. This is not only more expensive than reading
        on an electronic device, but also not very friendly to the environment.<sup><a
        href=\"https://web.archive.org/web/20120611111551/http://blogs.plos.org/mfenner/2010/01/10/how_do_you_read_papers_2010_will_be_different/#fn2\">2</a></sup></p><h3
        id=\"reading-pdfs-on-a-computer\">Reading PDFs on a computer</h3><p>This approach
        appears to be very common for reading just parts of a paper, e.g. to look
        up experimental details, a figure or reference. Most people now store papers
        as PDF (hopefully with an intelligent program such as <a href=\"https://web.archive.org/web/20120611111551/http://mekentosj.com/papers/\">Papers</a>)
        and not the PDF printouts. Looking at the PDF on the screen is therefore often
        the first step, and then the decision is made whether or not to print out
        the paper to read it in more detail. Reading PDFs on screen is possible, but
        not really convenient for longer texts. Screen sizes are often too small for
        the PDF format (A4 or US letter). Many people don't like the eye strain from
        looking at a screen for longer periods of time, although this is probably
        more relevant for reading books rather than reading a scientific paper.</p><p><a
        href=\"https://web.archive.org/web/20120611111551/http://getutopia.com/documents/overview\">Utopia</a>
        is a PDF viewer launched in December by the University of Manchester that
        enhances PDF files of the <em><em>Semantic Biochemical Journal</em></em> with
        interactive content and live linking to web resources. <a href=\"https://web.archive.org/web/20120611111551/http://duncan.hull.name/2009/12/11/utopia/\">Read
        more about Utopia</a> at <em><em>Duncan Hull</em></em>'s blog.</p><h3 id=\"reading-on-a-mobile-device\">Reading
        on a mobile device</h3><p>Many mobile devices such as the iPhone can open
        PDFs and <a href=\"https://web.archive.org/web/20120611111551/http://mekentosj.com/papers/iphone/\">Papers
        for iPhone</a> makes this process convenient. But PDFs in an A4 or US letter
        format are almost impossible to read on a small screen.</p><p>The <a href=\"https://web.archive.org/web/20120611111551/http://river-valley.tv/epub-is-the-only-format-we-need/\">ePub
        format</a> is more suitable for smaller screens found on mobile devices. ePub
        is usually used for e-Books, but the Open Access publisher Hindawi <a href=\"https://web.archive.org/web/20120611111551/http://www.hindawi.com/epub.html\">since
        2008 provides papers also in that format</a>. Although ePub is more suitable
        than PDF for mobile devices, it doesn't solve the problem that figures and
        tables are simply difficult to show on a small screen. Mobile devices are
        probably great for reading journal table of contents or the abstract of a
        paper (and an RSS reader such as <a href=\"https://web.archive.org/web/20120611111551/http://www.newsgator.com/individuals/netnewswireiphone/default.aspx\">NetNewsWire
        for iPhone</a> is perfect for this), but not fulltext papers.</p><h3 id=\"reading-on-an-e-reader\">Reading
        on an e-Reader</h3><p>The screen of an e-Reader uses <a href=\"https://web.archive.org/web/20120611111551/http://river-valley.tv/electronic-paper-technology/\">electronic
        ink</a> which not only means a much longer battery life, but also a very pleasing
        reading experience, including reading in direct sunlight. Electronic ink is
        black &amp; white, which is not a problem for fiction books, but limits the
        use for scholarly papers (and scientific textbooks). Ideally an e-Reader should
        have a 10\u2033 screen, similar in size to A4 or US letter paper.</p><p>The
        <a href=\"https://web.archive.org/web/20120611111551/http://www.techcrunch.com/2009/05/07/how-big-can-the-kindle-get/\">Kindle
        DX</a> from Amazon was announced in May 2009 and is currently the most popular
        e-Reader. The Kindle uses its own file format, but a <a href=\"https://web.archive.org/web/20120611111551/http://www.amazon.com/gp/help/customer/display.html?ie=UTF8&amp;nodeId=200324680\">recent
        software update</a> now allows the Kindle to open PDF files. Some journals
        (e.g. the <em><em>New England Journal of Medicine</em></em>) offer Kindle
        subscriptions, but that <a href=\"https://web.archive.org/web/20120611111551/http://patrickmd.net/blog/2009/05/22/cancelled-kindle-subscription-to-nejm/\">doesn't
        include early release articles</a> and no subscriber access to the journal
        website. A <a href=\"https://web.archive.org/web/20120611111551/http://www.nytimes.com/2010/01/09/technology/personaltech/09reader.html\">number
        of similar devices</a> were demonstrated this week at the Consumer Electronics
        Show in Las Vegas. The Kindle is primarily an e-Book reader, and <em><em>David
        Crotty</em></em> over on the Scholarly Kitchen blog <a href=\"https://web.archive.org/web/20120611111551/http://scholarlykitchen.sspnet.org/2010/01/06/doing-the-kindle-math-does-amazons-opacity-conceal-a-shameful-truth\">is
        skeptical</a> about dedicated e-readers, because he thinks that market is
        just too small.</p><h3 id=\"apple-islate\">Apple iSlate</h3><p>Unless you
        have been on a remote island for the last three months, you will know that
        Apple will announce a <a href=\"https://web.archive.org/web/20120611111551/http://daringfireball.net/2009/12/the_tablet\">tablet
        computer</a> later this month. There is wide speculation about the technical
        details, but it looks like this will be a very interesting device for reading
        scholarly papers. In contrast to e-Readers it will not use electronic ink.
        This means a shorter battery life, but allows color documents and many other
        more traditional computer uses. Based on the iPod and iPhone experience, many
        people think that the iSlate will change the way we use tablet computers.
        One of them is <em><em>Kent Anderson</em></em> (<a href=\"https://web.archive.org/web/20120611111551/http://scholarlykitchen.sspnet.org/2009/10/02/game-over-man-has-the-disruption-of-publishing-already-occurred/\">Game
        Over, Man \u2013 Has the Disruption of Publishing Already Occurred?</a>).</p><p>Sports
        Illustrated did a very nice <a href=\"https://web.archive.org/web/20120611111551/http://sportsillustrated.cnn.com/2009/magazine/12/02/tablet/index.html\">demo
        of a fictional tablet computer</a> in December, and it is obvious that many
        of these concepts can also be applied to scholarly publishing.</p><h3 id=\"reading-web-pages\">Reading
        Web Pages</h3><p>Most examples mentioned above try to reproduce the experience
        of reading something printed on paper on an electronic device. An alternative
        approach would move beyond the traditional format of a paper and rather takes
        advantage of the electronic medium. And it looks like the web technologies
        HTML5 and Flash are best suited for this. Cell Press was <a href=\"https://web.archive.org/web/20120611111551/http://network.nature.com/people/mfenner/blog/2009/07/26/how-does-the-article-of-the-future-look-like\">experimenting
        with this approach</a> in 2009, and officially launched their <a href=\"https://web.archive.org/web/20120611111551/http://beta.cell.com/index.php/2010/01/cell-launches-article-of-the-future-format/\">Article
        of the Future</a> with the first 2010 issue of Cell (all papers will be available
        without subscription for 60 days, you can provide feedback <a href=\"https://web.archive.org/web/20120611111551/http://beta.cell.com/index.php/feedback-cell-press-new-article-format/\">here</a>).
        The basic idea of the Article of the Future is to break away from the concept
        of reading a paper from beginning to end, and to make navigation between the
        different parts of a paper much easier.</p><p>Whereas the <em><em>Article
        of the Future</em></em> tries to make navigation with a paper easier, the
        <em><em>PLoS</em></em> <a href=\"https://web.archive.org/web/20120611111551/http://network.nature.com/people/mfenner/blog/2009/08/15/plos-one-interview-with-peter-binfield\">article-level
        metrics</a> help with navigating to related content: citations, blog posts,
        reader comments, etc. The <em><em>Notes</em></em> feature lets registered
        users highlight text for specific comments \u2013 very much what you would
        do on a printed paper (but with the added benefit that everybody can see this
        note).</p><p>I'm most excited about projects that enhance the scientific paper
        instead of recreating an exact electronic version of the traditional paper.
        And HTML is a more promising format than PDF for these approaches. <em><em>Michael
        Clarke</em></em> (with whom I had the pleasure to do a session at SciFoo 2009)
        reminded us that <em><em>Tim Berners-Lee</em></em> invented the WWW in 1991
        to facilitate scientific communication (with HTML and navigation both within
        and between documents as central concepts), but papers and journals have changed
        surprisingly little in the last 18 years (<a href=\"https://web.archive.org/web/20120611111551/http://scholarlykitchen.sspnet.org/2010/01/04/why-hasnt-scientific-publishing-been-disrupted-already/\">Why
        Hasn't Scientific Publishing Been Disrupted Already?</a>).</p><p>fn1. Many
        journals are scanning their older papers and make them available in electronic
        form, e.g. <em><em>Nature</em></em>. The first issue of <em><em>Nature</em></em>
        from 1869 can be seen <a href=\"https://web.archive.org/web/20120611111551/http://www.nature.com/nature/about/first/index.html\">here</a>.</p><p>fn2.
        We all know that computers haven't brought us the paperless office, but that
        we all use more paper than 10 years ago.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ ORCID or how to build a unique identifier
        for scientists in 10 easy steps ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/orcid-or-how-to-build-a-unique-identifier-for-scientists-in-10-easy-steps/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw3k</id>\n        <published>2010-01-03T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-31T07:58:42.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p><a href=\"https://web.archive.org/web/20151003022831/http://www.orcid.org/\">ORCID</a>
        stands for <em><em>Open Researcher and Contributor ID</em></em> and was <a
        href=\"https://web.archive.org/web/20151003022831/http://science.thomsonreuters.com/orcid/media/pdf/ORCID_Announcement.pdf\">announced</a>
        in early December. This blog post tries to summarize some of the problems
        that have to be solved to develop a unique identifier for scientists.</p><h3
        id=\"1-identify-the-problem\">1. Identify the problem</h3><p>The <a href=\"https://web.archive.org/web/20151003022831/http://www.gen2phen.org/researcher-identification-primer\">Researcher
        Identification Primer</a> by the Gen2Phen Knowledge Center lists some of the
        problems that a unique identifier for scientists tries to solve, including</p><ul><li>Disambiguation
        of author names in the scientific literature and establishing/validating relationships
        between authors and publications.</li><li>A solid foundation for permitting
        and tracking online scientific contributions, such as database submissions,
        scientific blogging, and community curation efforts.</li><li>Knowledge discovery
        applications using some or all of the above components.</li></ul><p>The Gen2Phen
        <a href=\"https://web.archive.org/web/20151003022831/http://www.gen2phen.org/event/irbw2009-workshop-may-13-14-toronto\">workshop</a>
        co-organized by <a href=\"https://web.archive.org/web/20151003022831/http://network.nature.com/people/U7739E111/profile\">Gudmundur
        Thorisson</a> in May 2009 discussed these issues in much more detail. One
        of several articles talking about the problem of disambiguation of author
        names (especially Asian author names) appeared in <em><em>Nature News</em></em>
        in <a href=\"https://web.archive.org/web/20151003022831/http://dx.doi.org/10.1038/451766a\">February
        2008</a>. A December 2009 <em><em>Nature</em></em> <a href=\"https://web.archive.org/web/20151003022831/http://dx.doi.org/10.1038/462825a\">editorial</a>
        emphasized that a unique identifier for researchers will be especially valuable
        to track scientific contributions that are not related to authoring a paper.
        Phil Bourne and J. Lynne Fink also wrote about this in PLoS Computational
        Biology in December 2008: <a href=\"https://web.archive.org/web/20151003022831/http://dx.doi.org/10.1371/journal.pcbi.1000247\">I
        Am Not a Scientist, I Am a Number</a>. A number of tools have tried to solve
        this problem, but it is not possible to link the researcher identities in
        the many systems.</p><h3 id=\"2-define-what-you-want-to-accomplish\">2. Define
        what you want to accomplish</h3><p><a href=\"https://web.archive.org/web/20151003022831/http://network.nature.com/people/gbilder/profile\">Geoff
        Bilder</a> gave a very good introduction to the problem at <a href=\"https://web.archive.org/web/20151003022831/http://www.scienceonlinelondon.org/\">Science
        Online London</a> in August and <a href=\"https://web.archive.org/web/20151003022831/http://www.stm-assoc.org/event_presentations.php?event_id=19\">STM
        Innovations</a> in December. Both talks were similar, but the latter is available
        as <a href=\"https://web.archive.org/web/20151003022831/http://river-valley.tv/crossref-contributor-id/\">video</a>
        and <a href=\"https://web.archive.org/web/20151003022831/http://www.stm-assoc.org/2009_12_04_Innovations_Bilder_CrossRef_Contributor_ID.pdf\">PDF</a>.
        He emphasized that ORCID is about <em><em>Knowledge Discovery</em></em> and
        not <em><em>Access Control</em></em>, and explained the terminology for <em><em>subject</em></em>,
        <em><em>identifier</em></em>, <em><em>profile</em></em>, <em><em>persona</em></em>
        and <em><em>credential</em></em>. <em><em>Access Control</em></em> is a related
        problem that is sometimes mixed in, but there is no requirement that a unique
        researcher identifier also has to provide secure access via whatever mechanism
        (<a href=\"https://web.archive.org/web/20151003022831/http://openid.net/\">Open
        ID</a> is one solution to that problem).</p><h3 id=\"3-win-support-of-stakeholders\">3.
        Win support of stakeholders</h3><p>Founding members of the ORCID initiative
        can be <a href=\"https://web.archive.org/web/20151003022831/http://science.thomsonreuters.com/orcid/gallery.html\">found
        on the ORCID homepage</a> and include publishers, funders, universities, organizations
        and software companies. A number of important stakeholders are already part
        of the initiative, support by more funders (besides the Wellcome Trust) and
        software companies (particularly those that build reference managers or social
        networking sites for scientists) would be great. Probably the biggest name
        not on the list is the U.S. National Library of Medicine that runs the <em><em>PubMed</em></em>
        database of biomedical literature (the ORCID members Wellcome Trust and British
        Library are involved in UK PubMed Central).</p><h3 id=\"4-make-decisions-about-the-general-design-of-the-system\">4.
        Make decisions about the general design of the system</h3><p>Some of the design
        decisions obviously are not set in stone at this stage. One continuing discussion
        is <em><em>centralized vs. federated</em></em>, and it looks like ORCID will
        be a centralized system similar to the DOI. Geoff Bilder has some <a href=\"https://web.archive.org/web/20151003022831/http://network.nature.com/people/mfenner/blog/2009/02/17/interview-with-geoffrey-bilder\">good
        arguments</a> for a centralized system. Another recurring theme is <em><em>how
        much control an individual researcher has</em></em> over his ORCID record.
        Although external assertion from publishers or funders will certainly be part
        of ORCID, the individual researcher will have an important role, not only
        because of privacy concerns, but also because this is the easiest way to fix
        errors that even the best automated algorithms for author assignment will
        produce. And it looks as if ORCID will be an extensible system that will for
        example allow publishers or social networking sites to add functionality they
        require. The discussion at the STM Innovations meeting in early December touches
        some of these issues and is <a href=\"https://web.archive.org/web/20151003022831/http://river-valley.tv/how-researcherid-will-resolve-name-ambiguity-in-the-scholarly-ecosystem/\">recorded
        as video</a> (after the talk by David Kochalko).</p><h3 id=\"5-pick-a-name\">5.
        Pick a name</h3><p>The name <em><em>Open Researcher and Contributor ID</em></em>
        (ORCID) is obviously a combination of <a href=\"https://web.archive.org/web/20151003022831/http://www.researcherid.com/\">ResearcherID</a>
        (Thomson Reuters) and <a href=\"https://web.archive.org/web/20151003022831/http://www.stm-assoc.org/2009_12_04_Innovations_Bilder_CrossRef_Contributor_ID.pdf\">Contributor
        ID</a> (CrossRef). I would have preferred a simpler name, but I guess we have
        to get used to ORCID.</p><h3 id=\"6-build-on-available-tools\">6. Build on
        available tools</h3><p>ORCID will be based on the ResearcherID software from
        Thomson Reuters. From what I\u2019ve seen, the <a href=\"https://web.archive.org/web/20151003022831/http://openid.net/\">Open
        ID</a> system will not be a central part of ORCID. But ORCID certainly will
        be designed to work together with Open ID and other authentication mechanisms.
        I don\u2019t know what Elsevier and the <a href=\"https://web.archive.org/web/20151003022831/http://www.stm-assoc.org/2009_12_04_Innovations_Weertman_Taking_the_guesswork_out_of_author_searching.pdf\">Scopus
        Author ID</a> will contribute to ORCID.</p><h3 id=\"7-form-an-independent-organization\">7.
        Form an independent organization</h3><p>In order to be adopted widely, ORCID
        must be run by an independent organization, and not by a single publisher,
        software company, research organization or funder. With the experience of
        <a href=\"https://web.archive.org/web/20151003022831/http://network.nature.com/people/mfenner/blog/2009/02/17/interview-with-geoffrey-bilder\">running
        the DOI system</a> to identify digital objects such as scientific papers,
        CrossRef would be one obvious candidate, but the ORCID founding members have
        yet to decide on that.</p><h3 id=\"8-secure-financing\">8. Secure financing</h3><p>Starting
        and maintaining ORCID will obviously cost money. In my little <a href=\"https://web.archive.org/web/20151003022831/http://network.nature.com/people/mfenner/blog/2009/04/26/a-few-questions-about-author-identifiers-the-answers\">survey
        about author identifiers back in April 2009</a>, the opinions were split about
        who should pay for this. Journal publishers and database maintainers (referring
        to such databases as PubMed, Scopus or Web of Science) were the two most common
        answers. ORCID will make it easier for funding agencies to evaluate scientists
        and they might therefore also contribute to the system. Individual researchers
        hopefully will not have to pay for any of this, but their input in time is
        obviously required.</p><h3 id=\"9-promote-orcid\">9. Promote ORCID</h3><p>A
        <em><em>Nature</em></em> <a href=\"https://web.archive.org/web/20151003022831/http://dx.doi.org/10.1038/462825a\">editorial</a>
        in December was a good start to promote ORCID to a wider audience. A unique
        identifier for scientists will only become accepted if widely used. That\u2019s
        why it is important that publishers and funders quickly adopt this service.
        Software companies that build interesting tools around ORCID are also critical,
        e.g. integration of ORCID into manuscript submission systems (including the
        use of ORCID for the peer reviewers) and social networking sites (including
        of course Nature Network). My experience with the DOI for papers (e.g. the
        <a href=\"https://web.archive.org/web/20151003022831/http://network.nature.com/people/mfenner/blog/2009/10/11/thoughts-on-the-pubmed-redesign\">limited
        support in PubMed</a>) tells me that adoption of ORCID will be a long process.</p><h3
        id=\"10-involve-individual-researchers\">10. Involve individual researchers</h3><p>Individual
        researchers currently have no way to get directly involved in ORCID. But some
        level of involvement is critical for an author identifier to work. The best
        place is currently probably the <a href=\"https://web.archive.org/web/20151003022831/http://www.linkedin.com/groups?gid=1807278\">LinkedIn
        Group</a> Unique Identifiers for Researchers started by <a href=\"https://web.archive.org/web/20151003022831/http://network.nature.com/people/U42E63119/profile\">Cameron
        Neylon</a>. But I hope we soon see ORCID discussions on Nature Network and
        other social networking sitess. The best place on Nature Network to discuss
        ORCID is currently probably the <a href=\"https://web.archive.org/web/20151003022831/http://network.nature.com/groups/socialnotworking/forum/topics\">Scientific
        Researchers and Web 2.0: Social Not Working?</a> Forum.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Science and Sustainability ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/science-and-sustainability/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw3j</id>\n
        \       <published>2009-12-27T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-03T05:09:24.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Sustainability in science
        is nothing new. The term sustainability science was probably first used in
        2001 (see <a href=\"https://web.archive.org/web/20151002031738/http://en.wikipedia.org/wiki/Sustainability_science\">Wikipedia
        entry</a>), and the title of this blog post was already used by a 2002 <a
        href=\"https://web.archive.org/web/20151002031738/http://dx.doi.org/10.1126/science.297.5583.897\">editorial</a>
        in <em><em>Science</em></em>. There are both journals (<a href=\"https://web.archive.org/web/20151002031738/http://ejournal.nbii.org/\">Sustainability:
        Science, Practice &amp; Policy</a>, <a href=\"https://web.archive.org/web/20151002031738/http://www.springerlink.com/content/120154/\">Sustainability
        Science</a>) and conferences (e.g. <a href=\"https://web.archive.org/web/20151002031738/http://www.nzsses.auckland.ac.nz/conference/index.htm\">here</a>
        and <a href=\"https://web.archive.org/web/20151002031738/http://www.vie.unu.edu/article/963\">here</a>)
        about this topic and you can get a <a href=\"https://web.archive.org/web/20151002031738/http://sustsci.aaas.org/files/University%20Survey%20V2.pdf\">degree</a>
        in sustainability science. The term sustainability is usually used in the
        context of climate change and the conservation of natural resources.</p><p>Here
        I want to use sustainability in a broader sense, using the original definition:
        <em><em>able to be maintained at a certain rate or level</em></em>.<sup><a
        href=\"https://web.archive.org/web/20151002031738/http://blogs.plos.org/mfenner/2009/12/27/science_and_sustainability/#fn1\">1</a></sup>
        Examples where the way we currently do science will probably no longer be
        sustainable in the future include grant applications that have a chance of
        success as low as 1% (<a href=\"https://web.archive.org/web/20151002031738/http://blogs.nature.com/peer-to-peer/2009/08/the_wait_continues_for_nih_cha.html\">the
        wait continues for NIH Challenge Grant applicants</a>), the ever-increasing
        costs for access to scholarly publications (the <a href=\"https://web.archive.org/web/20151002031738/http://www.sennoma.net/main/archives/2009/06/what_happened_to_serials_price.php\">serials
        crisis</a>), or the exponential growth of drug development costs without any
        increase in approval for new drugs in the last 60 years (<a href=\"https://web.archive.org/web/20151002031738/http://pipeline.corante.com/archives/2009/12/09/drug_companies_since_1950.php\">Drug
        Companies Since 1950</a>).</p><p>Sustainability in science requires the individual
        researcher to think about his responsibility, i.e. to go beyond research that
        is personally interesting and is paid for by someone. I do think that increasing
        sustainability in science is a worthy goal, and I picked six examples.</p><h3
        id=\"make-access-to-research-results-affordable\">Make access to research
        results affordable</h3><p>For those not working at an academic institution,
        many subscription-based journals now make their papers available after a 6-12
        month embargo period. Immediate full access to an individual paper in these
        journals can cost anywhere between $10 and $30 ($31.50 Cell, $15.00 Science,
        $32.00 Nature, $31.50 The Lancet, $10 New England Journal of Medicine). As
        you can guess from the wide range for these journals alone, these prizes are
        probably not calculated to cover actual costs. Deep Dyve <a href=\"https://web.archive.org/web/20151002031738/http://blog.deepdyve.com/2009/11/03/a-new-market-opportunity/\">launched
        a rental service for scientific content</a> in October. They charge $0.99
        per article rental, but currently include only a limited number of journals.</p><p>Most
        researchers have access to subscription-based journals through their institutions.
        My university library currently has a <a href=\"https://web.archive.org/web/20151002031738/http://dx.doi.org/10.3205/mbi000161\">budget</a>
        of about 900,000 \u20AC per year for just over 2000 researchers and 2600 students.
        Even with this money, our institution <a href=\"https://web.archive.org/web/20151002031738/http://network.nature.com/people/mfenner/blog/2009/10/18/open-access-week-a-researchers-perspective\">can't
        afford subscriptions to all journals</a> import for my work. And subscription
        costs are increasing much faster than library budgets. <a href=\"https://web.archive.org/web/20151002031738/http://network.nature.com/people/mfenner/blog/2009/12/13/on-giving-a-talk-about-open-access-in-my-department\">Open
        Access</a> obviously is one answer to this dilemma, but <a href=\"https://web.archive.org/web/20151002031738/http://dx.doi.org/10.1038/nmat2497\">may
        not work for all journals</a>. Most of us would probably be happy to pay for
        journal subscriptions if subscription costs simply remained reasonable. Because
        a handful of publishers own a large part of scientific journals, this will
        only happen if someone representing a large group of universities and research
        institutions sits at the negotiation table.</p><h3 id=\"reduce-the-bureaucracy-in-science-funding\">Reduce
        the bureaucracy in science funding</h3><p>We are currently spending too much
        time trying to obtain research funding compared to the time actually doing
        research. This is in part because the chances of obtaining a grant are often
        fairly low and grant applications have to be submitted many times, and because
        the duration of some grants is to short, e.g. only 2-3 years (sometimes meaning
        you have to start writing on the extension grant after the first year). Providing
        funding to excellent researchers for longer periods of time instead of funding
        projects is one approach to improve this situation. The Howard Hughes Medical
        Institute has done this for many years with <a href=\"https://web.archive.org/web/20151002031738/http://www.hhmi.org/research/investigators/\">HHMI
        investigators</a> and the Wellcome Trust last month announced a similar approach
        with <a href=\"https://web.archive.org/web/20151002031738/http://www.wellcome.ac.uk/News/Media-office/Press-releases/2009/WTX057403.htm\">Wellcome
        Trust Investigator Awards</a>.</p><h3 id=\"communicate-and-use-research-results\">Communicate
        and use research results</h3><p>A lot of research has practical value, but
        this practical value has to be explored. One nice example from my area of
        expertise is an international consortium to improve the outcome of a specific
        form of acute leukemia in the developing world. The first results <a href=\"https://web.archive.org/web/20151002031738/http://www.hematology.org/Publications/ASH-News-Daily/2009/4636.aspx\">were
        reported</a> at the ASH meeting earlier this month, one of only a handful
        of abstracts to be picked for the plenary session. But use of research results
        goes beyond translational research, using them for science education (both
        in schools and universities) is equally important.</p><p>Science blogging
        could have an important role in communicating research, and <a href=\"https://web.archive.org/web/20151002031738/http://phylogenomics.blogspot.com/2009/12/story-behind-nature-paper-on-phylogeny.html\">this
        blog post</a> from a few days ago is a wonderful example of how a blog post
        can enhance a <em><em>Nature</em></em> <a href=\"https://web.archive.org/web/20151002031738/http://dx.doi.org/10.1038/nature08656\">paper</a>.
        It would be great if more journals would follow the <em><em>PLoS</em></em>
        journals in linking to blogs posts about a paper,<sup><a href=\"https://web.archive.org/web/20151002031738/http://blogs.plos.org/mfenner/2009/12/27/science_and_sustainability/#fn2\">2</a></sup>
        and journals should help their authors to blog, e.g. by asking for a blog
        post (that could be hosted by the journal) on paper acceptance. Conference
        blogging is another area where science blogging would be a very welcome addition.
        It was nice to see <a href=\"https://web.archive.org/web/20151002031738/http://network.nature.com/people/mfenner/blog/2009/09/17/german-genetics-society-meeting-2009-introduction\">official
        conference blogging</a> at the German Genetics Conference this year, and I
        hope to see more of that.</p><h3 id=\"develop-and-promote-technologies-that-make-scholarly-research-more-efficient\">Develop
        and promote technologies that make scholarly research more efficient</h3><p>Obviously
        I have written a lot about this topic on this blog, e.g. about the <a href=\"https://web.archive.org/web/20151002031738/http://network.nature.com/people/mfenner/blog/2009/07/26/how-does-the-article-of-the-future-look-like\">article
        of the future</a>, <a href=\"https://web.archive.org/web/20151002031738/http://network.nature.com/people/mfenner/blog/2009/08/01/bibliographic-management-meets-web-2-0\">reference
        management</a>, <a href=\"https://web.archive.org/web/20151002031738/http://network.nature.com/people/mfenner/blog/2009/03/25/editorial-manager-interview-with-richard-wynne\">paper
        submission</a>, <a href=\"https://web.archive.org/web/20151002031738/http://network.nature.com/people/mfenner/blog/2009/05/01/extyles-interview-with-elizabeth-blake-and-bruce-rosenblum\">validation,
        formatting and exporting of scholarly content</a>, or <a href=\"https://web.archive.org/web/20151002031738/http://network.nature.com/people/mfenner/blog/2009/02/17/interview-with-geoffrey-bilder\">researcher
        identifiers</a>. But I believe that there is still a lot more that can be
        done, and I expect to see one or more disruptive technologies in the future.
        Time will tell if <a href=\"https://web.archive.org/web/20151002031738/http://network.nature.com/people/mfenner/blog/2009/07/18/using-google-wave-for-a-week-its-still-great\">Google
        Wave</a> is one of them, the Open Researcher Contributor Identification Initiative
        (<a href=\"https://web.archive.org/web/20151002031738/http://www.orcid.org/\">ORCID</a>)
        announced earlier this month certainly is a very big step forward.</p><h3
        id=\"preserve-research-data\">Preserve research data</h3><p>Providing and
        preserving the research data behind a project is becoming increasingly important,
        and simply writing up a paper <a href=\"https://web.archive.org/web/20151002031738/http://www.cotch.net/blog/20091223_1558\">is
        no longer enough</a>.<sup><a href=\"https://web.archive.org/web/20151002031738/http://blogs.plos.org/mfenner/2009/12/27/science_and_sustainability/#fn3\">3</a></sup>
        In many areas we lack the infrastructure (nomenclature, databases, etc.) and
        resources for this, especially for long-term preservation. One ambitious project
        is <a href=\"https://web.archive.org/web/20151002031738/http://www.elixir-europe.org/page.php\">Elixir</a>,
        which is trying to develop an infrastructure for biological information in
        Europe. The <a href=\"https://web.archive.org/web/20151002031738/https://cabig.nci.nih.gov/\">CaBIG</a>
        project at the U.S. National Cancer Institute is trying to do something similar
        for cancer research. Examples for digital preservation projects can be found
        at the <a href=\"https://web.archive.org/web/20151002031738/http://www.bl.uk/aboutus/stratpolprog/ccare/introduction/digital/\">British
        Library</a> and the German <a href=\"https://web.archive.org/web/20151002031738/http://www.langzeitarchivierung.de/eng/index.htm\">Nestor</a>
        project.</p><h3 id=\"involve-people-outside-of-universities-and-institutions-in-research\">Involve
        people outside of universities and institutions in research</h3><p>Many areas
        of research would profit from this approach. A prominent example of citizen
        science is <a href=\"https://web.archive.org/web/20151002031738/http://www.galaxyzoo.org/\">Galaxy
        Zoo</a>, where more than 150,000 people are helping with the classification
        of astronomy images. Involving people is especially in medical research. <a
        href=\"https://web.archive.org/web/20151002031738/http://www.pdonlineresearch.org/\">PD
        Online Research</a> is a wonderful community site about research on Parkinson
        disease that launched in June 2009. <a href=\"https://web.archive.org/web/20151002031738/http://scienceroll.com/personalized-medicine/\">Personalized
        genetics</a> can give the patient or healthy individual a more active role
        in healthcare decisions.</p><p>Whether sustainability will ultimately play
        a greater role in science will ultimately depend on those paying for research.
        If universities, institutions and funders continue to look mainly at goals
        that are both too short-term and only an indirect measure of scientific progress
        (e.g. the Impact Factor of a journal that a paper is published in), and don't
        honor activities such as data annotation, public outreach, etc., this will
        be very difficult. I wish you a great start into the new year.</p><p>The German
        word for sustainability is <em><em>Nachhaltigkeit</em></em>.</p><p>And please,
        please use the <a href=\"https://web.archive.org/web/20151002031738/http://www.doi.org/\">DOI</a>
        for that.</p><p>This blog post was one important inspiration for this post,
        as was the <a href=\"https://web.archive.org/web/20151002031738/http://www.nature.com/scifoo/index.html\">SciFoo</a>
        meeting in July, and many small things in between, including of course the
        <a href=\"https://web.archive.org/web/20151002031738/http://network.nature.com/people/mfenner/blog/2009/08/23/thoughts-on-the-science-online-london-conference\">Science
        Online London</a> meeting.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Increased cancer risk following computed
        tomography scans ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/increased-cancer-risk-following-computed-tomography-scans/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw3h</id>\n        <published>2009-12-20T00:00:00.000+00:00</published>\n\t\t<updated>2023-06-29T17:49:57.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/ioi90119f2.jpg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/ioi90119f2.jpg\"></p><figure
        class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/rb2_large_gray.png\"
        class=\"kg-image\" alt=\"ResearchBlogging.org\" loading=\"lazy\" width=\"70\"
        height=\"85\"></figure><p>Two papers (<a href=\"https://web.archive.org/web/20150922174153/http://dx.doi.org/10.1001/archinternmed.2009.427\">this</a>
        and <a href=\"https://web.archive.org/web/20150922174153/http://http//dx.doi.org/10.1001/archinternmed.2009.440\">this</a>)
        and an <a href=\"https://web.archive.org/web/20150922174153/http://dx.doi.org/10.1001/archinternmed.2009.453\">editorial</a>
        in the latest issue of <em><em>Archives of Internal Medicine</em></em> examine
        the cancer risks associated with the use of computed tomography (CT) examinations.<sup><a
        href=\"https://web.archive.org/web/20150922174153/http://blogs.plos.org/mfenner/2009/12/20/increased_cancer_risk_following_computed_tomography_scans/#fn1\">1</a></sup></p><p>Ionizing
        radiation increases the risk for developing cancer. There is direct evidence
        from atomic bomb survivors in Japan in 1945 and from nuclear accidents such
        as the one in Chernobyl in 1986. There are no studies directly demonstrating
        an increased cancer risk from the diagnostic use of X-rays (either conventional
        radiographs or computed tomography), as this would require long-term follow-up
        of a very large number of people. This risk can only be estimated, based on
        the assumption that there is no lower radiation threshold dose for cancer
        risk and that a linear correlation exists between dose and cancer risk. Similarly,
        we know very little about the actual radiation doses that patients receive
        during a diagnostic CT scan.</p><p>The paper by <strong><strong>Rebecca Smith-Bindman</strong></strong>
        and her coworkers looked at the radiation doses associated with the 11 most
        common computed tomography examinations in four hospitals in the San Francisco
        Bay Area. Radiation doses to individual patients were not measured directly,
        but were estimated using the commonly used \u201Ceffective dose\u201D. Median
        effective doses for routine computed tomography of the head, chest and abdomen-pelvis
        were 2, 8 and 16 mSv. The highest median effective doses (31 mSv) were used
        for multiphase CTs of the abdomen-pelvis (range 6-90 mSv). The 8 mSv dose
        for a routine chest CT is equivalent to 119 conventional chest X-rays. Interestingly,
        there was wide variation of effective doses used both between hospitals and
        within the same institution (with a mean 13-fold variation between the highest
        and lowest dose for each CT study type).</p><p>Based on these doses, the authors
        then estimated the increased risk for radiation-induced cancer following a
        CT examination. This risk is higher in younger people and in women. Women
        have a higher risk to develop lung cancer following radiation exposure and
        they have the added risk of developing breast cancer. The authors estimated
        that it would for example require approximately 620 CT scans for ruling out
        pulmonary embolism in 40-year-old women to induce one cancer.</p><p>The second
        paper by <strong><strong>Amy Berrington de Gonzalez</strong></strong> and
        coworkers tried to calculate the total number of CT scans performed in the
        US in 2007 and estimated the increased risk for cancer related to these CT
        scans based on examination type, age, and sex. They used a similar model to
        calculate the cancer risk as the first paper. Overall, about 72 million CT
        scans were performed in the US in 2007. The authors estimated that approximately
        29.000 additional cancers will eventually develop, equivalent to approximately
        2% of all cancers diagnosed annually in the US.</p><p>CT scans have dramatically
        improved patient care and the conclusions of these two papers should not preclude
        their use in patients where the potential benefits clearly outweigh the risks
        mentioned above. But in order to reduce the cancer risk associated with CT
        scans, the authors of the two papers and the editorial suggest optimizing
        and standardizing the CT scan procedure (remember the 13-fold difference in
        dose for the same procedure) and decreasing the number of unnecessary examinations.
        The latter is most relevant when CT scans are performed as screening procedures.</p><p>More
        blog posts discussing these papers can be found on <a href=\"https://web.archive.org/web/20150922174153/http://blogs.nature.com/stories/2049\">Nature
        Blogs</a> and <a href=\"https://web.archive.org/web/20150922174153/http://www.cancer.org/aspx/Blog/Comments.aspx?id=336\">Dr.
        Len's Cancer Blog</a>.</p><p><sup>1</sup> All three papers are available as
        full-text without a subscription. And none of the papers displays its DOI,
        which makes linking to them unnecessarily difficult.</p><h3 id=\"references\">References</h3><p>Smith-Bindman
        R. Radiation Dose Associated With Common Computed Tomography Examinations
        and the Associated Lifetime Attributable Risk of Cancer. <em>Arch Intern Med</em>.
        2009;169(22):2078. doi:<a href=\"https://doi.org/10.1001/archinternmed.2009.427\">10.1001/archinternmed.2009.427</a></p><p>Berrington
        De Gonz\xE1lez A. Projected Cancer Risks From Computed Tomographic Scans Performed
        in the United States in 2007. <em>Arch Intern Med</em>. 2009;169(22):2071.
        doi:<a href=\"https://doi.org/10.1001/archinternmed.2009.440\">10.1001/archinternmed.2009.440</a></p><p>Redberg
        RF. Cancer Risks and Radiation Exposure From Computed Tomographic Scans: How
        Can We Be Sure That the Benefits Outweigh the Risks? <em>Arch Intern Med</em>.
        2009;169(22):2049. doi:<a href=\"https://doi.org/10.1001/archinternmed.2009.453\">10.1001/archinternmed.2009.453</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ On giving a talk about Open Access in my
        department ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/on-giving-a-talk-about-open-access-in-my-department/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw3g</id>\n        <published>2009-12-13T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-12T07:37:21.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Earlier this month I gave
        this talk in my department. It is basically a summary of two blog posts that
        I wrote in October during <strong><strong>Open Access Week</strong></strong>
        (Open Access Week: a researcher's perspective <a href=\"https://web.archive.org/web/20150908065053/http://network.nature.com/people/mfenner/blog/2009/10/18/open-access-week-a-researchers-perspective\">part
        I</a> and <a href=\"https://web.archive.org/web/20150908065053/http://network.nature.com/people/mfenner/blog/2009/10/23/open-access-week-a-researchers-perspective-part-ii\">part
        II</a>), and I had given a similar talk in November in an <a href=\"https://web.archive.org/web/20150908065053/http://oa.helmholtz.de/index.php?id=254\">Open
        Access workshop</a> organized by the Helmholtz Association. But because this
        time my audience (researchers and clinicians in a university hospital) was
        less knowledgeable about Open Access, I added a few introductory slides in
        the beginning.</p><p>The discussion is usually the most interesting part,
        and this topic certainly has a lot of material for discussion. Interestingly,
        we talked mainly about the problem of <strong><strong>copyright</strong></strong>.
        Even though anybody who has ever submitted a paper to a (non-Open Access)
        journal has signed a copyright transfer agreement, the implications of this
        were not really clear to most people in the audience. Reuse of a figure or
        table in an academic seminar usually falls under <strong><strong>fair use</strong></strong>,
        but many journals still require a (free) permission.<sup><a href=\"https://web.archive.org/web/20150908065053/http://blogs.plos.org/mfenner/2009/12/13/on_giving_a_talk_about_open_access_in_my_department/#fn1\">1</a></sup>
        And using the same figure in a medical conference can cost several hundred
        dollars, and it doesn't really matter that you are one of the authors of the
        paper (slides 15-17 in the presentation). Some of my colleagues have run into
        issues with copyright, usually when the talks of a conference were later redistributed
        on a CD or website.</p><p>Unfortunately there wasn't enough time to discuss
        some of the other issues raised in the talk, e.g.</p><ul><li>Why can't our
        Medical School Library afford an institutional subscription for <em><em>Cell</em></em>?</li><li>Why
        is there no <strong><strong>institutional repository</strong></strong> at
        our university?</li><li>Why is it very unlikely that we will have a mandate
        for Open Access in Germany in the near future?</li><li>Why has the <strong><strong>Impact
        Factor</strong></strong> become so important in Medicine?</li></ul><p>The
        seminar was also interesting in that this was one of the rare occasions where
        I talked publicly in my department about some of the topics that I regularly
        write about on this blog. I always felt that most of my colleagues don't really
        care about these topics, and that they probably think I should rather spend
        my time working on the next paper or grant. I haven't gotten much feedback
        after the talk, but maybe I should reconsider that position.</p><p><sup>1</sup>
        Many journals use <a href=\"https://web.archive.org/web/20150908065053/http://www.copyright.com/\">Copyright.com</a>,
        which makes this process straightforward.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Nature Communications: Interview with Lesley
        Anson ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/nature-communications-interview-with-lesley-anson/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw3f</id>\n        <published>2009-11-26T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-13T15:39:36.000+00:00</updated>\n\t\t<category
        term=\"Interview\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p><a href=\"https://web.archive.org/web/20170507030644/http://www.nature.com/ncomms/about_journal.html\">Nature
        Communications</a> is a new journal that will launch in Spring 2010. The journal
        will publish papers in all areas of the physical, chemical and biological
        sciences and is open for submissions.</p><p>The Nature Publishing Group publishes
        one fully open access journal (<a href=\"https://web.archive.org/web/20170507030644/http://www.nature.com/msb/index.html\">Molecular
        Systems Biology</a>) and <a href=\"https://web.archive.org/web/20170507030644/http://www.nature.com/press_releases/greengold.html\">more
        than ten journals</a> that offer an open access option for authors (including
        <a href=\"https://web.archive.org/web/20170507030644/http://www.nature.com/emboj/index.html\">EMBO
        Journal</a>). <em>Nature Communications</em> will be the first Nature journal
        with an open access option for authors. <em>Nature Communications</em> papers
        where the author has not opted for open access will be available through an
        institutional subscription, or by purchasing an individual article.</p><p>There
        are many good arguments for open access, but from a journal perspective the
        publishing model must make business sense. Most open access journals use the
        author-pays model, and <a href=\"https://web.archive.org/web/20170507030644/http://dx.doi.org/10.1038/nmat2497\">an
        editorial in the August 2009 issue</a> of Nature Materials talked about some
        of the difficulties of this publishing model for the Nature journals \u2013
        the costs that are currently spread among many subscribers would be prohibitely
        high for an author-pays option. Some high-profile open access journals have
        article publication charges that are probably not covering all costs (e.g.
        <a href=\"https://web.archive.org/web/20170507030644/http://www.plosbiology.org/home.action\">PLoS
        Biology</a>) or use a different business model that doesn't require article
        publication charges (<a href=\"https://web.archive.org/web/20170507030644/http://www.bmj.com/\">BMJ</a>).
        <em>Nature Communications</em> will have an <a href=\"https://web.archive.org/web/20170507030644/http://www.nature.com/ncomms/open_access/index.html\">article
        publication charge of $5000</a>, which is higher than what most journals charge.
        I interviewed Lesley Anson, the Chief Editor of <em>Nature Communications</em>,
        to learn more about the journal.</p><h3 id=\"1-can-you-describe-nature-communications-for-me\">1.
        Can you describe Nature Communications for me?</h3><p><em>Nature Communications</em>
        is the latest journal in NPG's portfolio. It is an online-only multidisciplinary
        journal publishing original research papers in all areas of the biological,
        chemical and physical sciences. The published research will be of the quality
        associated with Nature-branded journals, but won't necessarily have the high
        impact or broad appeal of papers published in Nature and the Nature research
        journals. In other words, we expect that papers published in <em>Nature Communications</em>
        will be of interest and importance to specialists within each field.</p><p>All
        research papers will be in Article format, regardless of their length, and
        will undergo rigorous, yet efficient, peer review and be published rapidly
        online. Authors of primary research papers can choose to make their published
        article available via subscribed access, or open access through the payment
        of a publication fee. <em>Nature Communications</em> will also publish occasional
        Reviews and Editorials.</p><h3 id=\"2-what-will-you-be-doing-differently-from-other-nature-journals\">2.
        What will you be doing differently from other Nature journals?</h3><p>There
        are a number of differences between <em>Nature Communications</em> and other
        Nature-branded journals. For example, all other Nature titles publish print
        issues with regular news and comment sections and are available only by subscribed
        access.</p><p>Like other Nature-branded journals, <em>Nature Communications</em>
        has an independent team of editors who are responsible for maintaining the
        quality of the published research through rigorous peer review. However, <em>Nature
        Communications</em> has streamlined the editorial process \u2013 by limiting
        presubmission enquiries, appeals and the number of rounds of review \u2013
        in order to secure rapid decisions for authors. The journal has also undertaken
        to publish research papers within 28 days of acceptance.</p><p>Another distinctive
        feature of <em>Nature Communications</em> is its Editorial Advisory Panel
        \u2013 to be announced shortly \u2013 which will consist of recognized experts
        from all areas of science. Their collective expertise will support the editorial
        team in ensuring that every field is represented in the journal.</p><h3 id=\"3-is-nature-communications-still-a-journal-in-the-traditional-sense-the-journal-is-online-only-has-no-news-and-views-and-the-articles-will-be-so-specialized-that-most-people-will-probably-find-papers-by-a-database-search-rather-than-by-looking-at-the-table-of-contents-\">3.
        Is Nature Communications still a journal in the traditional sense? The journal
        is online only, has no news and views, and the articles will be so specialized
        that most people will probably find papers by a database search rather than
        by looking at the table of contents.</h3><p>I suppose it depends on your definition
        of a traditional journal. One could argue that we are going back to the roots
        of learned journals by focussing predominantly on primary research. In addition,
        like the traditional Nature-branded journals, <em>Nature Communications</em>
        has a defined scope and publishes only high-quality research.</p><p>We appreciate,
        though, that readers are accustomed to browsing journals by issue, therefore
        we are implementing technology to make the online browsing experience both
        intuitive and effective. There will be a number of ways for authors to find
        papers of interest to them, including personalization options and an extensive
        browse by subject category.</p><h3 id=\"4-why-did-you-decide-to-have-a-hybrid-model-of-both-open-access-and-subscribed-access\">4.
        Why did you decide to have a hybrid model of both open access and subscribed
        access?</h3><p>We consider ourselves fortunate in being able to offer authors
        the choice of publishing with open access as well as subscribed access. Increasing
        support by funders for open access publication has made hybrid business models
        more viable for publishers. Furthermore, <em>Nature Communications</em> focus
        on primary research is particularly suited to a hybrid model because the cost
        of commissioning, editing and producing secondary content is minimized. These
        factors, and the high rejection rates on Nature and the Nature research journals,
        make open access charges for any other Nature-branded journal prohibitively
        high in the current market.</p><h3 id=\"5-with-this-hybrid-model-in-place-it-will-be-interesting-to-closely-watch-how-open-access-and-subscribed-access-articles-are-accessed-over-time-\">5.
        With this hybrid model in place, it will be interesting to closely watch how
        open access and subscribed access articles are accessed over time.</h3><p>Yes,
        it will be interesting to monitor the average view rates for open-access versus
        subscribed access papers and we will be doing this following launch.</p><h3
        id=\"6-does-an-author-decide-about-open-vs-subscribed-access-before-or-after-a-paper-is-accepted-for-publication\">6.
        Does an author decide about open vs. subscribed access before or after a paper
        is accepted for publication?</h3><p>Authors won't have to make a final decision
        about access to their paper until the point at which their paper is accepted.
        Where authors do indicate a preference one way or the other during the editorial
        process, the reviewers will be blind to that choice.</p><h3 id=\"7-what-percentage-of-articles-do-you-expect-to-be-open-access\">7.
        What percentage of articles do you expect to be open access?</h3><p>We can't
        predict what the open-access take-up will be like, and we are therefore prepared
        for open access uptake varying from as little as 0% to as much as 100%. <em>Nature
        Communications</em> business model works at both extremes and all values in
        between.</p><h3 id=\"8-how-does-the-transfer-of-a-manuscript-rejected-at-another-nature-journal-work\">8.
        How does the transfer of a manuscript rejected at another Nature Journal work?</h3><p>The
        process of transferring a manuscript to <em>Nature Communications</em> is
        exactly the same as the transfer mechanism between the existing Nature-branded
        journals. Control rests entirely with the author, so transfers are only made
        at the authors request and with the understanding that the reviewers' reports
        from the previous journal will be transferred to <em>Nature Communications</em>.</p><p>Importantly,
        because all Nature journals are editorially independent, authors rejected
        from another Nature journal can choose to submit their paper to <em>Nature
        Communications</em> as a new submission. In that case, any submission or peer
        review details will remain confidential to the journal from which the manuscript
        was rejected.</p><h3 id=\"9-what-are-your-responsibilities-at-nature-communications\">9.
        What are your responsibilities at Nature Communications?</h3><p>I am the Chief
        Editor of <em>Nature Communications</em> , which means I am responsible for
        the editorial content of the journal. I have a team of talented editors to
        help in the task of selecting suitable manuscripts for publication: a biologist,
        a physicist and a chemist. Their profiles are <a href=\"https://web.archive.org/web/20170507030644/http://www.nature.com/ncomms/authors/about_eds/index.html\">available
        on our website</a>.</p><h3 id=\"10-what-did-you-do-before-starting-to-work-at-nature-communications\">10.
        What did you do before starting to work at Nature Communications?</h3><p>Before
        taking on the task of launching Nature Communications, I spent more than ten
        years as a manuscript editor at Nature. During that time, I handled a number
        of different areas in the cellular and molecular sciences, and was also responsible
        for the editorial content of Nature's <a href=\"https://web.archive.org/web/20170507030644/http://www.nature.com/nature/supplements/insights/index.html\">Insight
        Programme</a>. Before joining Nature I trained as a biophysicist at the University
        of Bristol and University College London.</p><h3 id=\"11-what-are-the-best-places-to-find-out-more-about-nature-communications\">11.
        What are the best places to find out more about Nature Communications?</h3><p>For
        more information about <em>Nature Communications</em>, including the journal's
        Aims and Scope, biographies of the editors and how to submit, please visit
        <a href=\"https://web.archive.org/web/20170507030644/http://www.nature.com/naturecommunications\">our
        website</a>. Any questions can be directed to our <a href=\"https://web.archive.org/web/20170507030644/http://network.nature.com/groups/naturecommunications/forum/topics\">dedicated
        forum</a> on Nature Network, or sent directly to the editorial team by e-mailing
        <a href=\"https://web.archive.org/web/20170507030644/mailto:natcomms%40nature.com\">natcomms@nature.com</a>.
        We look forward to hearing from you!</p><p><em>For further information, please
        also read the <a href=\"https://web.archive.org/web/20170507030644/http://blogs.nature.com/nautilus/2009/10/nature\">announcement</a></em>
        on the <em>Nautilus</em> blog and the <a href=\"https://web.archive.org/web/20170507030644/http://blog.openwetware.org/scienceintheopen/2009/11/16/nature-communications-qa/\">Nature
        Communications Q&amp;A</a> with Grace Baynes on the <em>Science in the open</em>
        blog._</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Publication bias in clinical trials ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/publication-bias-in-clinical-trials/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw3m</id>\n        <published>2009-11-18T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-31T07:56:16.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Last week the <em><em>New
        England Journal of Medicine</em></em> (<em><em>NEJM</em></em>) published a
        paper on selective outcome reporting in clinical trials (<a href=\"https://web.archive.org/web/20151003094331/http://dx.doi.org/10.1056/NEJMsa0906126\">Vedula
        et al. 2009</a>). The primary and secondary outcome(s) of a clinical trial
        could for example be survival in cancer patients or rate of heart attacks
        and other cardiovascular events in patients taking cholesterol-lowering drugs.
        These outcomes are defined in the study protocol before the first patient
        is treated, and whether or not the primary outcome is reached (using statistical
        testing) defines whether a trial was positive or negative. The study protocol
        is approved by an institutional review board (IRB) and can only be changed
        later (and that includes changes in the protocol-defined outcomes) if again
        approved by the IRB.</p><p>The study in the <em><em>NEJM</em></em> examined
        the outcomes of 20 clinical trials for the drug gabapentin using internal
        documents of the drug companies Pfizer and Parke-Davis, and compared them
        to the outcomes reported for those trials that were published as peer-reviewed
        papers. The internal company documents were obtained as the result of litigation
        in which the company admitted guilt for off-label marketing (i.e. marketing
        for uses that were not approved by the Food and Drug Administration) of gabapentin.</p><p>12
        of the 20 trials were published as peer-reviewed papers. In 8 of these 12
        papers the primary outcome differed from the primary outcome defined in the
        protocol. New primary outcomes were introduced in 6 papers, and protocol-defined
        primary outcomes were not reported in 5 papers. Trials with primary outcomes
        that were not significant were either not reported as full paper or were reported
        with a changed primary outcome.</p><p>Selective outcome reporting has also
        been reported by other authors and is not limited to trials funded by drug
        companies (Chan 2004). Selective outcome reporting is a major problem because
        it a) distorts our scientific knowledge and b) is unethical as it involves
        research on human subjects. This could for example lead to repeated studies
        of a clearly ineffective or harmful drug or intervention. The distortion of
        our scientific knowledge by selective outcome reporting in scientific journals
        is also a concern for research in other areas. Confirmation of important research
        findings by independent groups is important, but a lot of research is probably
        repeated simply because negative results were not published. Some of these
        reporting biases could be avoided by making more unpublished research data
        available, either by <a href=\"https://web.archive.org/web/20151003094331/http://usefulchem.blogspot.com/\">Open
        Notebook Science</a> or by publishing \u201Cunexciting negative\u201D findings
        in peer-review journals or preprint archives such as <a href=\"https://web.archive.org/web/20151003094331/http://precedings.nature.com/\">Nature
        Precedings</a>.</p><p>Clinical medicine tries to solve the problem of publication
        bias by making public registration of clinical trials mandatory before patient
        enrollment. This registration is required by most major medical journals since
        2004 (De Angelis 2004). U.S. legislation also requires clinical trial registration
        and since 2008 (<a href=\"https://web.archive.org/web/20151003094331/http://network.nature.com/people/mfenner/blog/2008/08/02/fdaaa-push-to-open-data-in-clinical-medicine\">FDAAA:
        Push to open data in clinical medicine</a>) this includes outcome reporting
        within 12 months after data for the last subject were received in the publicly
        available <a href=\"https://web.archive.org/web/20151003094331/http://www.clinicaltrials.gov/\">Clinicaltrials.gov</a>
        database. These efforts should ensure ethical standards of clinical research,
        and help to avoid the kinds of biases reported in the paper by Vedula et al.</p><p>Clinical
        trial registries obviously also serve other purposes, as they help interested
        patients and their relatives and treating physicians to find clinical trials
        they want to participate in, and they help researchers and clinicians to do
        a systematic overview of the ongoing research in a particular field. Just
        as there are centralized databases (e.g. <a href=\"https://web.archive.org/web/20151003094331/http://www.ncbi.nlm.nih.gov/pmc/\">PubMed
        Central</a> and the <a href=\"https://web.archive.org/web/20151003094331/http://www.controlled-trials.com/mrct/\">Current
        Controlled Trials</a> metaRegister of controlled trials) and institutional
        repositories for full-text papers, there are also both central (e.g. <a href=\"https://web.archive.org/web/20151003094331/http://clinicaltrials.gov/\">Clinicaltrials.gov</a>
        \u2013 Both PubMed Central and Clinicaltrials.gov are efforts by the U.S.
        <a href=\"https://web.archive.org/web/20151003094331/http://www.nih.gov/\">National
        Institutes of Health</a>) and institutional clinical trial registries. But
        in contrast to institutional repositories, there are no standard software
        tools available that an institution can use. I am involved in building a <a
        href=\"https://web.archive.org/web/20151003094331/http://www.mh-hannover.de/studien\">clinical
        trial registry for our institution</a>, and the effort is both technically
        demanding, and socially challenging. The information in a clinical trial registry
        is constantly changing and we need to keep the efforts required by the individual
        researchers at a mininum. We also have to walk a fine line of what information
        can be made publicly available, and here we follow the standards provided
        by both Clinicaltrials.gov and the <a href=\"https://web.archive.org/web/20151003094331/http://www.who.int/ictrp/en/\">WHO</a>.</p><p><a
        href=\"https://web.archive.org/web/20151003094331/https://eudract.emea.europa.eu/\">EudraCT</a>,
        the mandatory European clinical trials registry is regretably not available
        to the public.</p><h3 id=\"references\">References</h3><p>Vedula, S., Bero,
        L., Scherer, R., &amp; Dickersin, K. (2009). Outcome Reporting in Industry-Sponsored
        Trials of Gabapentin for Off-Label Use <em>New England Journal of Medicine,
        361</em> (20), 1963-1971 https://doi.org/<a href=\"https://web.archive.org/web/20151003094331/http://dx.doi.org/10.1056/NEJMsa0906126\">10.1056/NEJMsa0906126</a></p><p>Chan,
        A.-W. (2004). Outcome reporting bias in randomized trials funded by the Canadian
        Institutes of Health Research. Canadian Medical Association Journal, 171(7),
        735\u2013740. <a href=\"https://doi.org/10.1503/cmaj.1041086\">https://doi.org/10.1503/cmaj.1041086</a></p><p>De
        Angelis, C., Drazen, J. M., Frizelle, F. A., Haug, C., Hoey, J., Horton, R.,
        \u2026 Weyden, M. B. V. D. (2004). Clinical Trial Registration: A Statement
        from the International Committee of Medical Journal Editors. New England Journal
        of Medicine, 351(12), 1250\u20131251. <a href=\"https://doi.org/10.1056/nejme048225\">https://doi.org/10.1056/nejme048225</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Moving article-level metrics forward ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/moving-article-level-metrics-forward/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw3e</id>\n        <published>2009-11-11T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-19T08:54:37.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>In September <em><em>PLoS</em></em>
        started to show usage data (downloads, citations, but also use of social bookmarking
        services and blog posts) for all their published papers (<a href=\"https://web.archive.org/web/20120611103840/http://www.plos.org/cms/node/485\">article-level
        metrics at PLoS: addition of usage data</a>). <em><em>PLoS</em></em> is not
        the first publisher to do that, but certainly the largest to date. Two Nature
        Network bloggers wrote about these changes back in June (The Scientist: <a
        href=\"https://web.archive.org/web/20120611103840/http://network.nature.com/people/rpg/blog/2009/06/22/on-article-level-metrics-and-other-animals\">On
        article-level metrics and other animals</a>) and August (Gobbledygook: <a
        href=\"https://blog.front-matter.io/posts/plos-one-interview-with-peter-binfield\">PLoS
        One: Interview with Peter Binfield</a>), and a number of blogs commented on
        this new feature, including:</p><ul><li>A Blog around the Clock: <a href=\"https://web.archive.org/web/20120611103840/http://scienceblogs.com/clock/2009/09/article-level_metrics_at_plos_1.php\">Article-Level
        Metrics at PLoS \u2013 Download Data</a></li><li>The Scholarly Kitchen: <a
        href=\"https://web.archive.org/web/20120611103840/http://scholarlykitchen.sspnet.org/2009/09/22/plos-releases-article-level-usage-data/\">PLoS
        Releases Article-level Metrics</a></li><li>BMJ Group Blogs: <a href=\"https://web.archive.org/web/20120611103840/http://blogs.bmj.com/bmj/2009/11/02/richard-smith-the-beginning-of-the-end-for-impact-factors-and-journals/\">Richard
        Smith: The beginning of the end for impact factors and journals</a></li><li>Blue
        Lab Coats: <a href=\"https://web.archive.org/web/20120611103840/http://bluelabcoats.wordpress.com/2009/09/18/article-level-metrics-debut-at-plos/\">Article
        Level Metrics Debut at PLOS</a></li></ul><p>There are a number of reasons
        why article-level metrics are a good idea, and I hope that many other journal
        publishers will follow. But in this blog post I want to talk about some of
        the shortcomings of the current implementation of article-level metrics.</p><h3
        id=\"article-level-metrics-should-be-combined-from-different-places\">Article-level
        metrics should be combined from different places</h3><p>Full-text articles
        live in more than one place. Obviously at the journal publisher's website,
        but in many cases also in one or more institutional repositories and at <a
        href=\"https://web.archive.org/web/20120611103840/http://www.ncbi.nlm.nih.gov/pmc/\">PubMed
        Central</a> (or similar places for papers not published in the life sciences).
        Which of these places produces the most reliable article-level metrics or
        should the HTML views, PDF downloads, etc. from all these places be combined?
        The decentralized nature of institutional repositories makes it especially
        difficult to combine usage statistics from them, but there are <a href=\"https://web.archive.org/web/20120611103840/http://www.dini.de/projekte/oa-statistik/english/\">projects</a>
        that try to tackle this problem. A unique identifier is required to combine
        the usage data from these different sources, and we have the <a href=\"https://web.archive.org/web/20120611103840/http://www.doi.org/\">DOI</a>
        for that. <em><em>PubMed Central</em></em> and similar large repositories
        could not only start to provide their own usage data, but also combine them
        with the usage data from those journal publishers that already provide them.</p><h3
        id=\"article-level-metrics-need-author-identifiers\">Article-level metrics
        need author identifiers</h3><p>Evaluating the \u201Cimpact\u201D of a researcher
        is one obvious use for article-level metrics. In order to be able to do that
        for more than a handful of researchers, we need unique author identifiers.
        This year we have had many discussions about author identifiers (including
        <a href=\"https://blog.front-matter.io/posts/interview-with-geoffrey-bilder/\">this
        blog</a> and at the <a href=\"https://web.archive.org/web/20120611103840/http://network.nature.com/people/mfenner/blog/2009/08/23/thoughts-on-the-science-online-london-conference\">Science
        Online London Conference</a>), and I hope that in 2010 we will finally see
        an evolving standard that is picked up by journal publishers. It would be
        in the interest of PLoS to combine their article-level metrics with an author
        identifier as soon as possible, most likely the proposed CrossRef ContributorID,
        rather than the Elsevier Scopus Author Identifier or the Thomson Reuters Researcher
        ID.</p><h3 id=\"article-level-metrics-should-enhance-literature-searches\">Article-level
        metrics should enhance literature searches</h3><p>We all know how Google became
        the most popular search engine (<a href=\"https://web.archive.org/web/20120611103840/http://en.wikipedia.org/wiki/PageRank\">Pagerank</a>).
        And article usage data would be a tremendous boost for scientific literature
        databases such as PubMed. A literature search should sort the results by usage
        data (e.g. a combination of number of citations, HTML views and PDF downloads)
        rand not the rather boring publication date, author or journal name. Normally
        I would think that <em><em>Google Scholar</em></em> would be the first place
        to implement such a functionality, but I haven't seen much innovation from
        Google Scholar lately.</p><h3 id=\"article-level-metrics-should-not-only-be-numbers\">Article-level
        metrics should not only be numbers</h3><p>As we don't want to reduce a paper
        to simple numbers, it is important to provide more than HTML views and PDF
        download counts. Citations counts are useful numbers, but linking to the citing
        papers is even more interesting. Similarly, we want to see links to <em><em>Faculty
        of 1000</em></em> recommendations and blog posts aggregated at <em><em>ResearchBlogging.org</em></em>.
        If we extend this further, we should probably start to think about a better
        name for article-level metrics. And I hope we never start to call this ALM.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ UK PubMed Central: Interview with Phil Vaughan
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/uk-pubmed-central-interview-with-phil-vaughan/\"
        />\n\t\t<id>https://doi.org/10.53731/dzr4d0a-anr8e6y</id>\n        <published>2009-11-04T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T07:29:22.000+00:00</updated>\n\t\t<category
        term=\"Interview\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/web.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/web.jpeg\"></p><p><a
        href=\"https://web.archive.org/web/20120611110953/http://www.ncbi.nlm.nih.gov/pmc/\">PubMed
        Central</a> was launched in February 2000 by the U.S. National Institutes
        of Health (NIH) as a free digital archive of journal articles. Just as PubMed,
        PubMed Central covers research in the life sciences, but not other areas of
        research, e.g. engineering, physical sciences or astronomy.</p><p>Some journal
        articles are available as full text as soon as they are published, and most
        journals provide free access to full text articles within a year of publication.
        Some journals only provide the full text of some articles, including research
        funded by the NIH under the <a href=\"https://web.archive.org/web/20120611110953/http://publicaccess.nih.gov/policy.htm\">NIH
        Public Access Policy</a>. The majority of fulltext articles in PubMed Central
        are not Open Access, but are protected by copyright. These articles are often
        made available under a license that allows redistribution and reuse.</p><p>All
        articles are deposited using the <a href=\"https://web.archive.org/web/20120611110953/http://dtd.nlm.nih.gov/\">NLM-DTD</a>
        XML format, which is a standard text format suitable for text mining and long-term
        archiving. Most articles are deposited directly by the journals, so that authors
        do not have to get involved in the technical aspects of article deposition.</p><p>PubMed
        Central is a centralized archive of full text papers and not simply an interface
        to search these articles at the websites of the participating journals. Neither
        is PubMed Central an interface to search the various institutional repositories
        at universities and institutions. The NIH thinks that this centralized approach
        makes it easier to develop additional functionality, including the integration
        with other databases (e.g. the protein or nucleotide databases) hosted at
        the NIH.</p><p>UK PubMed Central was launched in 2007 as the first PubMed
        Central outside the United States (<a href=\"https://web.archive.org/web/20120611110953/http://pubmedcentralcanada.ca/\">PubMed
        Central Canada</a>, the second international PubMed Central, launched this
        week). In January 2010 UK PubMed Central will launch a number of new services,
        and I used the opportunity to ask UK PubMed Central Programme Manager Philip
        Vaughan a few questions.</p><h3 id=\"1-what-is-uk-pubmed-central\">1. What
        is UK PubMed Central?</h3><p><a href=\"https://web.archive.org/web/20120611110953/http://ukpmc.ac.uk/\">UK
        PubMed Central</a> offers free access to 1.6 million full-text journal articles
        in the fields of Life Sciences, Biomedicine and Health. Our content is free
        to read, print off and download. There is no registration process required:
        users can simply visit our site and start searching!It has been developed
        in consultation with the UK biomedical and health research community, and
        is about to launch some exciting new services in January 2010. Usage of our
        service has been growing steadily; we average 300,000 downloads a month currently.</p><h3
        id=\"2-why-do-we-need-more-than-one-pubmed-central-and-how-are-they-connected\">2.
        Why do we need more than one PubMed Central, and how are they connected</h3><p>UKPMC
        gives the UK research community access to all the content of <a href=\"https://web.archive.org/web/20120611110953/http://www.ncbi.nlm.nih.gov/pmc/\">PMC</a>,
        but with added value specifically for the UK. For example, it offers Grant
        Reporting features, whereby users can search for current grants from all of
        our 8 Funders, can link the publications they produce to the grants they originated
        from, and view the impact of their work through access to citations. UK researchers
        can also <a href=\"https://web.archive.org/web/20120611110953/https://ukmss.mimas.ac.uk/ukmss\">deposit
        their manuscripts directly</a> into UKPMC.We will also be accessing additional
        content not in PMC; around 475,000 extra articles, reviews, guidelines and
        theses. Through the involvement of our funders, we are capturing around 90%
        of recently published journal articles from biomedical research conducted
        in the UK.We are therefore increasing the visibility of UK research in the
        field.</p><p>Our colleagues at NCBI in the US have been very supportive of
        our activities: they have been keen for the PMC \u201Cproject\u201D to expand
        beyond the US. A Canadian version (<a href=\"https://web.archive.org/web/20120611110953/http://pubmedcentralcanada.ca/\">PMC
        Canada</a>) launched this week.</p><h3 id=\"3-why-does-a-search-use-pubmed-central-and-not-the-uk-version\">3.
        Why does a search use PubMed Central and not the UK version?</h3><p>The current
        UKPMC site searches PMC as it \u201Cmirrors\u201D its content. But this about
        to change; from January UKPMC will be a \u201Cstand alone\u201D service with
        its own up to date archive of content, as well as access to all the content
        of PubMed and PubMed Central.</p><h3 id=\"4-what-is-the-relationship-between-uk-pubmed-central-and-institutional-repositories\">4.
        What is the relationship between UK PubMed Central and institutional repositories?</h3><p>UKPMC
        is a subject repository and as such receives content from researchers at Higher
        Education institutions across the UK. Deposition in UKPMC is mandatory if
        a researcher has a grant from any of our 8 Funders: <a href=\"https://web.archive.org/web/20120611110953/http://www.wellcome.ac.uk/\">Wellcome
        Trust</a>, <a href=\"https://web.archive.org/web/20120611110953/http://www.cancerresearchuk.org/\">Cancer
        Research UK</a>, <a href=\"https://web.archive.org/web/20120611110953/http://www.mrc.ac.uk/\">Medical
        Research Council</a>, <a href=\"https://web.archive.org/web/20120611110953/http://www.bhf.org.uk/\">British
        Heart Foundation</a>, <a href=\"https://web.archive.org/web/20120611110953/http://www.arc.org.uk/\">Arthritis
        Research Campaign</a>, <a href=\"https://web.archive.org/web/20120611110953/http://www.bbsrc.ac.uk/\">Biotechnology
        and Biosciences Research Council</a>, <a href=\"https://web.archive.org/web/20120611110953/http://www.nihr.ac.uk/\">National
        Institute for Health Research</a> and the <a href=\"https://web.archive.org/web/20120611110953/http://www.sehd.scot.nhs.uk/cso/\">Chief
        Scientists Office</a>. Consequently we do not need to harvest content from
        other repositories. However, institutional repositories are welcome to harvest
        our content; we have an OAI-PMH interface to enable this. On the other hand,
        there are no plans to develop of institutional repositories from within UK
        PubMed Central.</p><h3 id=\"5-what-is-the-material-that-can-t-be-put-into-uk-pubmed-central\">5.
        What is the material that can't be put into UK PubMed Central?</h3><p>If the
        material is not peer-reviewed research published in a recognized journal by
        a known publisher, it would not be deposited into UK PubMed Central. One aspect
        of our development programme has been to identify what further content we
        could provide links to, for example published research theses and NHS clinical
        guidelines. But, we have rigid quality control procedures in place even to
        provide links to material. That said, we do remain open minded, in terms of
        what material we may consider linking to in the future. And who knows what
        might arise in the future. For example, there does seem to be an appetite
        to include images.</p><h3 id=\"6-can-i-submit-my-accepted-manuscript-if-it-was-not-funded-by-one-of-the-uk-pubmed-central-funders\">6.
        Can I submit my accepted manuscript if it was not funded by one of the UK
        PubMed Central funders?</h3><p>Unfortunately not at this time. We are hopeful
        that other UK research councils and funders of life sciences research will
        come on board in due course. The more funders that come on board, the stronger
        our service will become and the stronger our message on the importance of
        OA.</p><h3 id=\"7-what-is-the-uk-pubmed-central-oai-service\">7. What is the
        UK PubMed Central OAI service?</h3><p>The UK PubMed Central OAI service, (<a
        href=\"https://web.archive.org/web/20120611110953/http://ukpmc.ac.uk/ppmc-localhtml/oai_service.html\">UKPMC-OAI</a>)
        provides access to metadata of all items in the UKPMC archive, as well as
        to the full text of a subset of these items.</p><h3 id=\"8-what-are-your-responsibilities-at-uk-pubmed-central\">8.
        What are your responsibilities at UK PubMed Central?</h3><p>I am the Programme
        Manager. I am responsible for the current service which has been in existence
        since January 2007. I also co-ordinate all our current development activities,
        which are undertaken by ourselves at the <a href=\"https://web.archive.org/web/20120611110953/http://www.bl.uk/\">British
        Library</a>, by the University of Manchester (<a href=\"https://web.archive.org/web/20120611110953/http://mimas.ac.uk/\">MIMAS</a>),
        the National Centre for Text Mining (<a href=\"https://web.archive.org/web/20120611110953/http://www.nactem.ac.uk/\">NacTEM</a>
        \u2013 based at the University of Manchester) and the European Bioinformatics
        Institute (<a href=\"https://web.archive.org/web/20120611110953/http://www.ebi.ac.uk/\">EBI</a>)
        based at Hinxton in Cambridgeshire.</p><h3 id=\"9-what-did-you-do-before-starting-to-work-on-uk-pubmed-central\">9.
        What did you do before starting to work on UK PubMed Central?</h3><p>I originally
        trained as a librarian. Since then I have worked mainly in health and medical
        information work, both in Higher Education and in the National Health Service.
        My most recent post was for <a href=\"https://web.archive.org/web/20120611110953/http://www.jisc.ac.uk/\">JISC</a>
        (Joint Information Systems Committee) as a Programme Manager. I was responsible
        for a portfolio of development projects in the digital library sphere. I joined
        UKPMC at the <a href=\"https://web.archive.org/web/20120611110953/http://www.bl.uk/\">British
        Library</a> in May 2008.</p><h3 id=\"10-do-you-want-to-talk-about-future-plans-for-uk-pubmed-central\">10.
        Do you want to talk about future plans for UK PubMed Central?</h3><p>Yes please!
        We are soon to launch some exciting new initiatives in January 2010. Our website
        has been completely redesigned with a new more intuitive interface, and we
        will be expanding our content to include all content from PubMed (c. 18m references),
        patents, theses and <a href=\"https://web.archive.org/web/20120611110953/http://www.library.nhs.uk/GUIDELINESFINDER/\">NHS
        Clinical Guidelines</a>. Consequently our users will be able to access a vast
        collection of relevant content through one portal.</p><p>Our search engine
        will be utilising innovative new techniques such as text mining to retrieve
        more contextually relevant information, link to other relevant databases and
        provide a richer search experience for the user. We are also expanding our
        Grant Reporting functions to allow Grantees and Funders to assess the impact
        and value of their funded research, and increase their visibility.</p><p>Our
        Funders are keen to expand the programme, possibly towards a future <em><em>European
        PubMed Central</em></em>.We are hopeful that as part of this process some
        European Funders may be joining the programme shortly. Our Funders hope to
        make an announcement regarding this shortly.</p><p>We are holding a Showcase
        event on January 12th at the British Library in London to highlight these
        new developments and the future potential of the service.</p><h3 id=\"11-could-you-provide-contact-information-for-people-that-have-further-questions-about-pubmed-central\">11.
        Could you provide contact information for people that have further questions
        about PubMed Central?</h3><p>By all means, people can email us at <a href=\"https://web.archive.org/web/20120611110953/mailto:ukpmc%40bl.uk\">ukpmc@bl.uk</a>
        and my email is <a href=\"https://web.archive.org/web/20120611110953/http://bl.uk/\">Philip.Vaughan@bl.uk</a>.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Open Access Week: a researcher\u2019s perspective
        part II ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/open-access-week-a-researchers-perspective-part-ii/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw3c</id>\n        <published>2009-10-23T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-13T13:52:29.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>This week (October 19-23)
        is <a href=\"https://web.archive.org/web/20120611105548/http://www.openaccessweek.org/\">Open
        Access Week</a> \u2013 a good opportunity to think and write about this topic.
        On Monday I wrote in a <a href=\"https://web.archive.org/web/20120611105548/http://network.nature.com/people/mfenner/blog/2009/10/18/open-access-week-a-researchers-perspective\">blog
        post</a>:</p><blockquote>Open Access can be looked at from many different
        angles, including the researcher, the science library, the institution, the
        funding organization, the journal, the science journalist, and the general
        public. Most arguments for or against Open Access depend on that angle. As
        a researcher, I am most interested in whether Open Access will make my work
        easier. Again, a researcher can look at Open Access from different roles:
        reader, author, reviewer, editor.</blockquote><p>In that blog post I then
        wrote about the role of the researcher as a reader. Now I want to look at
        the perspective of the researcher as an author.</p><h3 id=\"choice-of-journal\">Choice
        of journal</h3><p>The decision of where to publish a manuscript for most researchers
        probably works something like \u201Cfind the best journal where I can publish
        my work with the least amount of trouble\u201D. <em><em>Best journal</em></em>
        usually is a subjective decision, but probably correlates with the <a href=\"https://web.archive.org/web/20120611105548/http://thomsonreuters.com/products_services/science/free/essays/impact_factor/\">Impact
        Factor</a> of a journal. As the average quality of manuscripts is higher in
        a <em><em>better journal</em></em>, this will help to value your research
        in the eyes of granting agencies and job search committees. <em><em>Better
        journal</em></em> often means higher rejection rates and/or higher numbers
        of readers. Both factors \u2013 and journals that publish a relatively small
        number of papers \u2013 favor a subscription business model<sup><a href=\"https://web.archive.org/web/20120611105548/http://blogs.plos.org/mfenner/2009/10/23/open_access_week_a_researchers_perspective_part_ii/#fn1\">1</a></sup>.</p><h3
        id=\"publication-cost\">Publication cost</h3><p>Most Open Access journals
        use an author-pays model to pay for publication costs. Funding agencies or
        institutions may pick up these costs, but authors may be left with costs of
        $2500 or more.</p><h3 id=\"institutional-repositories\">Institutional Repositories</h3><p>Self-archiving
        in institutional repositories (green access) is a great way to make your publication
        freely available if the paper is published in a journal that is not Open Access.
        Unfortunately this often requires extra efforts by the researcher, and the
        publication will be more difficult to find in the repository than in the journal.
        This creates little incentive for a researcher to get involved in self-archiving.</p><h3
        id=\"citation-advantage\">Citation advantage</h3><p>The effect of free access
        to the scientific literature on article downloads and citations is difficult
        to measure. Some<sup><a href=\"https://web.archive.org/web/20120611105548/http://blogs.plos.org/mfenner/2009/10/23/open_access_week_a_researchers_perspective_part_ii/#fn2\">2</a></sup>,
        but not all studies<sup><a href=\"https://web.archive.org/web/20120611105548/http://blogs.plos.org/mfenner/2009/10/23/open_access_week_a_researchers_perspective_part_ii/#fn3\">3</a></sup>
        show higher citation rates for articles that are freely available and this
        citation advantage might be modest<sup><a href=\"https://web.archive.org/web/20120611105548/http://blogs.plos.org/mfenner/2009/10/23/open_access_week_a_researchers_perspective_part_ii/#fn4\">4</a></sup>.
        Citations are generated by other researchers who have access to your paper,
        and therefore I'm not surprised if there is not much of a difference between
        papers in Open Access journals and popular journals that are subscribed my
        many institutions.</p><h3 id=\"better-access\">Better Access</h3><p>Researchers
        in poorer countries will have easier access to papers published in Open Access
        journals, although many subscription journals wave access fees through initiatives
        such as <a href=\"https://web.archive.org/web/20120611105548/http://www.who.int/hinari/en/\">Hinari</a>.
        Open Access makes it easier for journalists, high school students, patient
        advocacy groups and many more people to read your papers. This is obviously
        of great value to these groups, but I haven't seen many examples where the
        paper author directly benefitted from this.</p><h3 id=\"social-responsibility\">Social
        responsibility</h3><p>The argument that publicly funded research should be
        available to everybody at time of publication can be a motivation for many
        scientists, but I would be careful to turn this into an obligation. Different
        countries have different traditions, but in my home country Germany the independence
        of research and researchers (including the decision where to publish) has
        become a constitutional right after the atrocities committed in the name of
        \u201Cscience\u201D in Nazi Germany. All major German research organizations
        support Open Access, but in contrast to other countries there is no Open Access
        mandate.</p><h3 id=\"summary\">Summary</h3><p>Publishing in an Open Access
        journal has surprisingly little benefits for the author of a paper, and often
        means additional costs. Unless we want to mandate Open Access publishing from
        authors because it benefits the other stakeholders (which at least in Germany
        would be difficult), we should make publishing in an Open Access journal more
        attractive to authors. It looks like PLoS ONE is doing exactly that, as 400
        manuscripts published per month testify.</p><h3 id=\"references\">References</h3><p>Science
        in the open. (2009). Nature Materials, 8(8), 611\u2013611. <a href=\"https://doi.org/10.1038/nmat2497\">https://doi.org/10.1038/nmat2497</a></p><p>Eysenbach,
        G. (2006). Citation Advantage of Open Access Articles. PLoS Biology, 4(5),
        e157. <a href=\"https://doi.org/10.1371/journal.pbio.0040157\">https://doi.org/10.1371/journal.pbio.0040157</a></p><p>Davis,
        P. M., Lewenstein, B. V., Simon, D. H., Booth, J. G., &amp; Connolly, M. J.
        L. (2008). Open access publishing, article downloads, and citations: randomised
        controlled trial. BMJ, 337(jul31 1), a568\u2013a568. <a href=\"https://doi.org/10.1136/bmj.a568\">https://doi.org/10.1136/bmj.a568</a></p><p>Evans,
        J. A., &amp; Reimer, J. (2009). Open Access and Global Participation in Science.
        Science, 323(5917), 1025\u20131025. https://doi.org/10.1126/science.1154562</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Open Access Week: a researcher\u2019s perspective
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/open-access-week-a-researchers-perspective/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw3b</id>\n        <published>2009-10-18T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-13T13:50:56.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>This week (October 19-23)
        is <a href=\"https://web.archive.org/web/20120611105124/http://www.openaccessweek.org/\">Open
        Access Week</a>:</p><blockquote>Open Access Week is an opportunity to broaden
        awareness and understanding of Open Access to research, including access policies
        from all types of research funders, within the international higher education
        community and the general public.</blockquote><p>The following video from
        <a href=\"https://web.archive.org/web/20120611105124/http://www.arl.org/sparc/\">SPARC</a>
        (the Scholarly Publishing &amp; Academic Resources Coalition) is a good introduction:</p><p>Open
        Access can be looked at from many different angles, including the <em><em>researcher</em></em>,
        the <em><em>science library</em></em>, the <em><em>institution</em></em>,
        the <em><em>funding organization</em></em>, the <em><em>journal</em></em>,
        the <em><em>science journalist</em></em>, and the <em><em>general public</em></em>.
        Most arguments for or against Open Access depend on that angle. As a researcher,
        I am most interested in whether Open Access will make my work easier. Again,
        a researcher can look at Open Access from different roles:</p><ul><li>Reader</li><li>Author</li><li>Reviewer</li><li>Editor</li></ul><p>The
        role as a reviewer or editor for an open access paper should be essentially
        the same as for a paper with subscription-based access. The journal <em><em>Nature
        Communications</em></em> that launches in April 2010 with a hybrid publishing
        model of open access and subscription-based access will for example have reviewers
        and editors <a href=\"https://web.archive.org/web/20120611105124/http://www.nature.com/ncomms/open_access/pdf/open-access-faqs.pdf\">blinded
        to the author's choice</a>.</p><p>In this blog post I will look at Open Access
        from the perspective of the researcher as a reader.</p><h3 id=\"access\">Access</h3><p>As
        a researcher in a German university I am privileged to have institutional
        access to most journal articles that I need for my work. I use the program
        <a href=\"https://web.archive.org/web/20120611105124/http://mekentosj.com/papers/\">Papers</a>
        as my main reference manager. Papers allows me to order my currently 1715
        references (and PDFs of fulltext paper to most of them) by journal. Among
        the 20 journals with the most papers in my library, my institution doesn't
        have access to three of them:</p><ul><li><em><em>Cell</em></em> (don't ask)</li><li><em><em>Lancet
        Oncology</em></em></li><li><em><em>Nature Reviews Clinical Oncology</em></em></li></ul><p>Obviously
        three important journals for someone doing clinical cancer research. I could
        ask my institution to start subscribing to these journals, start a personal
        subscription (I had a personal subscription to <em><em>Nature Clinical Practice
        Oncology</em></em> for two years before it was renamed to <em><em>Nature Reviews
        Clinical Oncology</em></em>) which would set me back 150-200 \xE2\u201A\xAC
        per journal, or I could pay for an individual article (either through my library
        or directly from the journal). All this requires extra time and money, worth
        only if I think a paper/journal is really important.</p><p><em><em>PLoS Medicine</em></em>
        is the only open access journal among the 20 most popular journals in my Papers
        library (The <em><em>BMJ</em></em> has free access to its research articles
        and is the 24th most popular). Unfortunately there are only a few Open Access
        journals publishing papers that are relevant to my work.</p><p>As many others
        I do work from home in the evening or on the weekend, or while travelling.
        I am lucky that I can access my university network through <a href=\"https://web.archive.org/web/20120611105124/http://en.wikipedia.org/wiki/Virtual_private_network\">VPN</a>
        and therefore can get fulltext access to journal articles (one of the most
        important VPN uses for me). But some researchers might not be so lucky, or
        spend precious extra time setting up and using VPN.</p><p>Researchers that
        work in a poorer country, or for a smaller university or small biotech startup
        will have much larger problems. Medical doctors in community hospitals or
        private practice may not have easy access to any of the relevant journals,
        and they might depend on reprints given to them by colleagues or representatives
        from drug companies.</p><h3 id=\"sharing\">Sharing</h3><p>If several people
        work on a research project, they also want to share the relevant literature
        in the field. Most subscription-based journals retain the copyright to the
        paper and don't allow storing in a retrieval system or transmitting of papers
        without permission. This could mean that you can't email the PDF of a paper
        to a colleague even if you are the author or his institution also has a subscription.
        And this could also mean that you can't use a reference manager such as <a
        href=\"https://web.archive.org/web/20120611105124/http://www.refworks.com/\">Refworks</a>
        or <a href=\"https://web.archive.org/web/20120611105124/http://www.mendeley.com/\">Mendeley</a>
        to not only share references with your lab colleagues, but also the full-text
        PDF files. Strictly following the copyright can make something as common as
        a <em><em>journal club</em></em> a complicated affair.</p><h3 id=\"permissions\">Permissions</h3><p>As
        most subscription-based journals retain the copyright to the paper, you have
        to ask for permissions when reusing tables or figures. Most often this is
        the case when giving a lecture on a topic. For longer lectures this could
        mean a large number of required permissions, and the permissions might be
        granted just for a single occasion. Journals might not care much about using
        a single figure in a departmental seminar, but it definitely becomes an issue
        when the lecture is distributed electronically, e.g. as free <a href=\"https://web.archive.org/web/20120611105124/http://ocw.mit.edu/OcwWeb/web/home/home/index.htm\">OpenCourseWare</a>
        publication of teaching material. Some journals provide Powerpoint slides
        for the tables and figures and explicitly permit the educational noncommercial
        use. In my experience most researchers aren't aware that they are using copyrighted
        material in their slides, and I rarely see the required copyright attributions.</p><h3
        id=\"added-services\">Added services</h3><p>This category has great potential,
        but is currently not yet that relevant in my daily work. Open Access to fulltext
        articles allows things that aren't possible or much more complicated with
        subscription-based access. This includes fulltext searches (to find information
        not in the title, abstract or keywords), semantically enhanced articles, and
        article-level metrics (<a href=\"https://web.archive.org/web/20120611105124/http://network.nature.com/people/mfenner/blog/2009/08/15/plos-one-interview-with-peter-binfield\">recently
        introduced by PLoS</a>).</p><h3 id=\"summary\">Summary</h3><p>Researchers
        at large research institutions often have institutional access to most relevant
        papers. They are often not aware of the restrictions imposed upon them by
        the copyright of papers retained by most subscription-based journals. Open
        Access papers not only are freely accessible, but allow the uncomplicated
        redistribution and reuse for research and teaching, as well as innovative
        ways to find interesting research.</p><p>The perspective of the researcher
        as a paper author is stuff for another blog post\u2026</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Thoughts on the PubMed Redesign ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/thoughts-on-the-pubmed-redesign/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw3a</id>\n        <published>2009-10-11T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T07:27:53.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/web-pubmed.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/web-pubmed.jpeg\"></p><p>It
        was <a href=\"https://web.archive.org/web/20120611025631/http://network.nature.com/people/U2929A0EA/profile\">Anna
        Kushnir</a> who started it all. Frustrated with the limitations of PubMed
        when finishing her PhD thesis, she wrote a blog post in March 2008 (<a href=\"https://web.archive.org/web/20120611025631/http://network.nature.com/people/U2929A0EA/blog/2008/03/22/i-am-not-yelling-not-out-loud\">I
        Am Not Yelling. Not Out Loud.</a>) about her experience. The blog post created
        quite a stir in the blogosphere, especially among <a href=\"https://web.archive.org/web/20120611025631/http://mbanks.typepad.com/my_weblog/2008/04/the-anna-kushni.html\">science
        librarians</a>. At the heart of the controversy was Anna's complaint that
        PubMed is too complicated to use, and that some science librarians felt PubMed
        simply is complicated and that users such as Anna should take better advantage
        of the resources available to better use PubMed. David Lipman, director of
        the <a href=\"https://web.archive.org/web/20120611025631/http://www.ncbi.nlm.nih.gov/\">NCBI</a>
        and responsible for PubMed, said:</p><blockquote>Although the current engine
        works well for some users and some queries, I understand Anna's frustration
        and we are in the midst of a number of changes that will make PubMed work
        better for her and many other users.</blockquote><p>In May 2009 a PubMed redesign
        <a href=\"https://web.archive.org/web/20120611025631/http://www.nlm.nih.gov/pubs/techbull/mj09/ppt/sunrise_gillikin/sunrise_2009_gillikin.html\">was
        shown</a> at the 2009 Annual Meeting of the Medical Library Association (MLA)
        in Honolulu, and the presentation explains a lot of the ideas behind the redesign.
        On September 30 the redesigned PubMed <a href=\"https://web.archive.org/web/20120611025631/http://www.nlm.nih.gov/pubs/techbull/so09/so09_pm_redesign.html\">was
        unveiled to the public</a>, and as early as next week it will become the default
        PubMed web interface.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/35053.png\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"196\" height=\"127\"></figure><p>Several
        science bloggers have already written about the PubMed redesign, including
        a <a href=\"https://web.archive.org/web/20120611025631/http://laikaspoetnik.wordpress.com/2009/10/01/pubmed&amp;Acirc;&amp;reg;-redesign-is-here-to-try/\">very
        detailed blog post</a> by Jacqueline Limpens.</p><h3 id=\"what-is-pubmed\">What
        is PubMed?</h3><p>MEDLINE is a database of more than 19 million citations
        for biomedical articles, hosted by the U.S. National Library of Medicine.
        <a href=\"https://web.archive.org/web/20120611025631/http://www.pubmed.gov/\">PubMed</a>
        is the freely available Web interface to that database. Not only is the content
        of PubMed available from other databases (e.g. <a href=\"https://web.archive.org/web/20120611025631/http://www.scopus.com/\">Scopus</a>
        or <a href=\"https://web.archive.org/web/20120611025631/http://thomsonreuters.com/products_services/science/science_products/scholarly_research_analysis/research_discovery/web_of_science\">Web
        of Science</a>), but PubMed can be searched not only via the Web interface,
        but also from within other applications, e.g. a reference manager such as
        <a href=\"https://web.archive.org/web/20120611025631/http://www.endnote.com/\">Endnote</a>
        or <a href=\"https://web.archive.org/web/20120611025631/http://mekentosj.com/papers\">Papers</a>.
        And PubMed doesn't cover all scientific journals, many disciplines (e.g. physics,
        social sciences) aren't included at all. In other words, the Pubmed web interface
        is not the only way to find biomedical articles, and in fact will not find
        literature not related to the life sciences. But the PubMed web interface
        is probably by far the most popular way to search for biomedical literature.</p><h3
        id=\"what-is-the-target-audience\">What is the target audience?</h3><p>The
        PubMed website is intended for at least 5 different audiences:</p><ul><li>science
        librarian</li><li>researcher in the life sciences</li><li>clinician</li><li>patient
        or patient relative</li><li>teacher, high school student, journalist and anybody
        else interested in life sciences research</li></ul><p>Before PubMed <a href=\"https://web.archive.org/web/20120611025631/http://www.nlm.nih.gov/archive//20050113/news/press_releases/free_medline.html\">was
        announced in June 1997 by the U.S. vice president Al Gore</a> as free web-based
        access to the MEDLINE database, most users were librarians, plus of a small
        group of academics with paid access (remember <a href=\"https://web.archive.org/web/20120611025631/http://www.annals.org/cgi/content/abstract/105/2/321\">Grateful
        Med</a> ?). Now we have a number of target audiences with different experience
        in literature search strategies and different intentions:</p><ul><li>librarian
        vs. academic vs. the general public</li><li>basic life sciences research vs.
        clinical research</li></ul><p>As PubMed is the most popular but not the only
        interface to the MEDLINE database, the primary target audience will not be
        a librarian, but someone with less experience in searching the biomedical
        literature (and less time). I would lump academics together with the general
        public here, and think that the typical PubMed search should be as simple
        as the typical Google search. Everything much more complicated than a simple
        input box should be moved to an <em><em>advanced search options</em></em>
        page, or should be done via a different interface to the MEDLINE database.</p><p>Searching
        for clinical literature is very different from searching for basic science
        research. Here a search is often done to help in the decision making for a
        particular patient, and <a href=\"https://web.archive.org/web/20120611025631/http://en.wikipedia.org/wiki/Evidence-based_medicine\">evidence-based
        medicine</a> is used to find the most relevant scientific literature (with
        meta-analyses and randomized controlled trials providing the best evidence).</p><figure
        class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/91px-Tribolium.castaneum.jpg\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"91\" height=\"120\"></figure><p>Searching
        for basic science literature has very different goals. It is either finding
        the needle in the haystack, e.g. you want to find all the published literature
        on the <a href=\"https://web.archive.org/web/20120611025631/http://dx.doi.org/10.1126/science.1176325\">C3PO</a>
        gene, or you want to find a review article as an overview over a particular
        field. But basic science review articles don't have the rigourous tools available
        to evaluate clinical research mentioned above, and here review articles only
        differ in the personal perspective of the reviewers and completeness and actuality
        of the primary literature that was covered. Searching for basic science literature
        should also be tightly integrated with the other databases at the NCBI. This
        is done via the <a href=\"https://web.archive.org/web/20120611025631/http://www.ncbi.nlm.nih.gov/sites/gquery\">Entrez
        Search Page</a>, so that a search for <em><em>C3PO</em></em> also links to
        the organisms it was described in, e.g. this one:</p><p>I don't think that
        a search interface to MEDLINE can be good at both the clinical and basic science
        literature. The current PubMed is much closer to the latter, so I think that
        the primary target audience for PubMed is the <em><em>academic or general
        public interest in basic life sciences research</em></em>. A good search interface
        for the clinical literature would be something very different and has to include
        both databases of evidence-based evaluations (particularly from the <a href=\"https://web.archive.org/web/20120611025631/http://www.cochrane.org/\">Cochrane
        Collaboration</a>) and from ongoing and completed clinical trials (particularly
        <a href=\"https://web.archive.org/web/20120611025631/http://clinicaltrials.gov/\">Clinicaltrials.gov</a>,
        just like PubMed also hosted at the NIH).</p><h3 id=\"where-is-web-2-0\">Where
        is Web 2.0?</h3><p>A PubMed redesign in 2009 can't be complete without looking
        at what Web 2.0 has to offer. This means that users should be offered a personal
        PubMed account that links to their libraries for full-text articles, stores
        common searches, creates RSS outputs, allows sharing of search results with
        other users, publishes a link to an interesting article on Twitter, and possibly
        other enhancements (e.g. a public profile page of all your PubMed articles,
        but that wouldn't work without <a href=\"https://web.archive.org/web/20120611025631/http://themindwobbles.wordpress.com/2009/08/22/breakout-3-author-identity-creating-a-new-kind-of-reputation-online/\">author
        identifiers</a>). This also means a clean design, use of Javascript/AJAX for
        the user interface, a version for mobile users (particularly iPhone), and
        frequent small updates instead of a big design change every 2-3 years.</p><h3
        id=\"and-how-is-the-redesigned-pubmed\">And how is the redesigned PubMed?</h3><p>After
        this rather long introduction, what do I like about the PubMed Redesign?</p><h3
        id=\"like\">Like</h3><ul><li>Clean, uncluttered design</li><li>Saving a search
        as RSS is faster and more obvious. I hope that this will make many more people
        use RSS than email alerts for their regular searches (<a href=\"https://web.archive.org/web/20120611025631/http://network.nature.com/people/mfenner/blog/2009/06/21/recipe-receiving-journal-table-of-contents-automatically\">why
        I like RSS</a>)</li><li>Auto suggest: some of the most popular PubMed searches
        will be displayed based on the terms entered</li><li>Some use of Javascript/AJAX</li></ul><h3
        id=\"dislike\">Dislike</h3><ul><li>The <a href=\"https://web.archive.org/web/20120611025631/http://www.doi.org/\">DOI</a>
        (the best unique identifier for a paper and the easiest way to link to the
        full-text article) is still not displayed in the standard abstract view (you
        find the DOI in the Medline and XML views)</li><li>Small design flaw: no easy
        way to go back from advanced search to basic search</li><li>Layout is now
        different from MyNCBI and the other NCBI databases (maybe this is work in
        progress)</li><li>(As far as I know) no version for mobile users</li><li>No
        send to CiteULike/Connotea/Twitter/FriendFeed, etc. buttons (popular with
        many journals)</li></ul><p>The redesign will make it easier for inexperienced
        users to do quick searches (as mentioned above, probably the target audience).
        Experienced librarians might like the redesign less, as advanced searches
        have not become easier. But overall the changes are minor. My biggest complaint
        is the lack of DOI integration. A wasted opportunity. And \u2013 as mentioned
        above \u2013 I think we need a different MEDLINE interface for searching the
        clinical medicine literature.</p><p>How do you like the redesign? Jacqueline
        Limpens is <a href=\"https://web.archive.org/web/20120611025631/http://laikaspoetnik.wordpress.com/2009/10/01/pubmed&amp;Acirc;&amp;reg;-redesign-is-here-to-try/\">doing
        a poll on her blog</a>.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Conference Blogging: Interview with Alex
        Knoll ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/conference-blogging-interview-with-alex-knoll/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw39</id>\n        <published>2009-10-01T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T07:30:56.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n\t\t<category term=\"Interview\"/>\n        <media:content
        url=\"https://blog.front-matter.io/content/images/2022/08/knoll.jpeg\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/knoll.jpeg\"></p><p>Blogging
        is <a href=\"https://web.archive.org/web/20120611105344/http://www.nature.com/news/2009/090624/full/4591050a.html\">a
        great way to report from a scientific conference</a>. This could be done either
        with regular blog posts written in the evening or after the conference, and/or
        live-blogging using tools such as Friendfeed or Twitter. One or more blogging
        scientists can not only add a unique perspective to the reports about a conference,
        but for smaller conferences blogging might be the only way to learn more about
        a conference you were unable to attend in person.</p><p>Conference blogging
        (particularly live-blogging) basically requires four things:</p><ul><li>a
        wireless network,</li><li>a computer or mobile phone with a full battery,</li><li>a
        hashtag (and other tools to find the conference blog posts), and</li><li>a
        blogging policy by the conference organizers.</li></ul><p>Wireless networks
        are now commonplace, but enough battery power (or power outlets that conference
        participants can use) can be difficult. A hashtag such as <em><em>#solo09</em></em>
        for <a href=\"https://web.archive.org/web/20120611105344/http://www.scienceonlinelondon.org/\">Science
        Online London</a> is essential for live-blogging using Twitter.</p><p>The
        big problem is the blogging policy, or rather that there usually is a policy
        only for traditional media, but not for blogging. The blogging from the Cold
        Spring Harbor <em><em>Biology of Genomes</em></em> meeting in May by Daniel
        MacArthur <a href=\"https://web.archive.org/web/20120611105344/http://scienceblogs.com/geneticfuture/2009/06/on_the_challenges_of_conferenc.php\">started
        a very helpful discussion about blogging policies</a>. It is impossible to
        write anything specific about a conference \u2013 and that's the stuff that
        is most interesting \u2013 without a permission from the conference organizer
        and speaker. This is best done before the conference has started. A July <em><em>Nature</em></em>
        <a href=\"https://web.archive.org/web/20120611105344/http://www.nature.com/nature/journal/v460/n7252/full/460152a.html\">editorial</a>
        argues that an opt-out policy, where everything can be blogged about unless
        the speaker or poster presenter specifically says so, is a reasonable alternative.</p><p>The
        organizers of the <a href=\"https://web.archive.org/web/20120611105344/http://www.genetics2009.de/\">Annual
        Meeting of the German Genetics Society</a> that took place two weeks ago in
        Cologne did this right. Not only did they invite <a href=\"https://web.archive.org/web/20120611105344/http://network.nature.com/people/alexander-knoll/profile\">Alex
        Knoll</a> to become the official conference blogger, but they also put up
        a prominent link to his blog posts on the conference homepage, and they asked
        every speaker before the conference whether Alex would be allowed to blog
        about their talks. Because his blog on scienceblogs.de (<a href=\"https://web.archive.org/web/20120611105344/http://www.scienceblogs.de/alles-was-lebt\">Alles
        was lebt</a>) is in German, he decided to put up his blog posts here. I've
        asked him a few questions about this experience.</p><h3 id=\"1-did-you-have-fun-being-the-official-blogger-for-the-german-genetics-society-meeting\">1.
        Did you have fun being the official blogger for the <a href=\"https://web.archive.org/web/20120611105344/http://www.genetics2009.de/\">German
        Genetics Society Meeting</a>?</h3><p>This conference blogging job was a first
        for me in many ways. I usually blog in German, so I wasn't sure if I would
        be able to bring more than my dry, scientific English. I also knew beforehand
        that there would be no theme, that the meeting was a general one. I would
        have at least to give the impression of having understood the basics of the
        talks. There would be no flitting about from talk to talk, I wanted to get
        whole sessions without interruption.</p><p>But on the other hand, I also got
        to know lots of people, many more than I would have as a lowly PhD student.
        I attended a conference I almost certainly would not have without the invitation
        to come and blog.</p><p>And, as any other (science)blogger will tell you,
        blogging is a labour of love (don't stab me in the back now!). So yes, I had
        a great time!</p><h3 id=\"2-blogging-about-the-conference-must-have-been-a-lot-of-work-\">2.
        Blogging about the conference must have been a lot of work!</h3><p>About as
        much as I expected. I was frantically typing away at my little netbook keyboard
        during the talks to take notes, and used any spare time to put together the
        posts. So I did not have as easy a time as regular conference attendees. No
        problem, I came to do a job!</p><h3 id=\"3-did-you-meet-any-other-science-bloggers-at-the-conference\">3.
        Did you meet any other science bloggers at the conference?</h3><p>As far as
        I'm aware, I was the only blogger attending, and also the only one tweeting
        from the sessions (no worries, no unpublished data got out that route).</p><h3
        id=\"4-what-was-the-feedback-from-the-speakers-what-was-your-experience-getting-permissions-from-speakers-to-blog-about-their-sessions\">4.
        What was the feedback from the speakers? What was your experience getting
        permissions from speakers to blog about their sessions?</h3><p>I got the whole
        range. From the really open \u201CGo ahead! Write what you want, put it online.
        I'll talk about some unpublished stuff as well, but I don't mind\u201D to
        some who are not interested in getting their work out into a blog at all.
        Great news for the conference blogging crowd: the balance was tipped more
        to the pro side! Most of the speakers came out somewhere in between those
        two sides, probably being a bit cautious about that whole strange blogging
        stuff. But I got mostly positive feedback from them, and I believe the next
        blogger will have an easier time when blogging about their talks!</p><h3 id=\"5-what-tips-would-you-give-a-conference-organizer-who-wants-to-promote-blogging\">5.
        What tips would you give a conference organizer who wants to promote blogging?</h3><p>They
        should make clear from the start if blogging about the talks is generally
        OK. That doesn't mean all of the speakers have to allow blogging about their
        talk, but an official position will help everyone involved. You also don't
        need to have an <em><em>official</em></em> blogger, but especially at smaller
        meetings asking someone to blog beforehand is probably the only chance to
        get a blogger there at all.</p><p>I also have advice for speakers: Start your
        talk by telling your audience if blogging about it is OK! If a part of your
        talk is unpublished, tell them that as well. Or put an icon on your slides
        to indicate which is good to blog about, for example as Daniel MacArthur from
        the Genetic Future blog <a href=\"https://web.archive.org/web/20120611105344/http://scienceblogs.com/geneticfuture/2009/07/conference_blogging_icons_for.php\">has
        proposed</a>. If bloggers know beforehand if and what part of the talk is
        good to go, they will be more willing to take notes in earnest!</p><p>Now
        that my guest posting here at Martin's blog comes to an end, I would like
        to leave you with one of the last impressions, a rather lucky shot of Cologne
        Cathedral I took while leaving. Many thanks to Martin for hosting this conference
        blog!</p><figure class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/3969315341_4f8c590711.jpg\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"500\" height=\"375\"></figure>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ German Genetics Society Meeting 2009: Session
        V and VII ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/german-genetics-society-meeting-2009-session-v-and-vii/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwbt</id>\n        <published>2009-09-29T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-01T06:09:31.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p><em><em>The
        final guest post by <a href=\"https://web.archive.org/web/20120611031645/http://network.nature.com/people/alexander-knoll/profile\">Alex
        Knoll</a> reporting from the German Genetics Society Meeting in Cologne.</em></em></p><h3
        id=\"session-v\">Session V</h3><p>Friday ended with two talks in session V,
        the first by Tony Hyman from the Max Planck Institute for Cell Biology and
        Genetics in Dresden. He looked at the ways that cells structure and organize
        their cytoplasm by comparison with non-biological systems.</p><p>Next up was
        a talk on the innate immune response against the influenza virus by University
        of Freiburg's Otto Haller. When viruses infect mammalian hosts, a battle between
        interferons and virulence factors starts to rage. The interferon-induced GTPase
        Mx1 is an important resistance factor against influenza A viruses in mice.
        Most lab mouse strains are natural knockouts for Mx1, so they needed to create
        congenic, wild-type Mx1-expressing mice to research its function.</p><p>Interestingly,
        Mx1 expression protects mice against the usually lethal 1918 Spanish flu influenza
        A, even at high doses. Mx proteins are highly conserved in mammalian species
        and belong to the dynamin superfamily of large GTPases. Otto Haller presented
        new and unpublished data (obtained in collaboration with Oliver Daumke's group
        at the Berlin Max Delbr\xFCck Center for Molecular Medicine) on the role of
        the structure of the human MxA GTPase in repressing the virus.</p><h3 id=\"session-vii\">Session
        VII</h3><p>The final session of the meeting started with a talk by Andrew
        McMahon from the Harvard Stem Cell Institute in Cambridge, US, that I sadly
        missed. But one missed talk during the whole meeting is not that bad now,
        don't you think?<br>Ueli Grossniklaus then talked about epigenetics in the
        struggle between the two parental genomes of an Arabidopsis embryo. At the
        University of Z\xFCrich in Switzerland, his group is looking at the timing
        of expression of paternal alleles and their phenotypic consequences, all controlled
        by the maternal genome.</p><p>The last talk was given by Bruce Beutler from
        the Scripps Research Institute in La Jolla, US. He is looking into the ways
        in which the mammalian immune system is able to recognize microbes as foreign,
        and then mount an adequate response. A first answer was found when the receptor
        for LPS, a component of all Gram-negative microbes, was identified by positional
        cloning as Tlr4, a Toll-like receptor. You perhaps know Toll as a developmental
        gene in the Drosophila embryo, but in adult flies, it is required for the
        immune response to fungal and bacterial infections. So perhaps other Toll-like
        receptors also recognize other microbial ligands? Yes, and Bruce Beutler's
        group has been looking into the signaling pathways that lead from recognition
        by a Toll-like receptor to the induction of cellular responses. He and his
        group have used a forward genetic screen of randomly mutagenized mice. To
        date, they have generated over 100,000 mutant lines, and identified 32 mutations
        affecting Toll-like receptor signaling. This allowed them to deduce biochemical
        pathways that mediate much of the innate immune response. A similar feat was
        done with the genes involved in the resistance against mouse cytomegalovirus,
        with susceptibility mutations found in sensing and signaling pathways, but
        also in homeostasis and in development.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ German Genetics Society Meeting 2009: Session
        VI ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/german-genetics-society-meeting-2009-session-vi/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwbs</id>\n        <published>2009-09-25T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-01T06:08:22.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p><em><em>Another
        guest post by <a href=\"https://web.archive.org/web/20120611032254/http://network.nature.com/people/alexander-knoll/profile\">Alex
        Knoll</a> reporting from the German Genetics Society Meeting in Cologne.</em></em></p><p>Saturday
        had two more sessions before the end of the meeting. Irina Stancheva from
        the Wellcome Trust Centre for Cell Biology at the University of Edinburgh
        started us into the day with a talk on epigenetics in mouse development.</p><p>One
        form of epigenetic silencing is methylation of cytosine bases in DNA. This
        is done by DNA methyltransferases like Dnmt1 for maintenance methylation,
        or Dnmt3a and Dnmt3b for de novo methylation, at CpG sequences enriched at
        promoters. During mouse embryonic development, DNA methylation is essential,
        for a loss of either of the DNA methyltransferases is embryonically lethal.
        Methylation and demethylation during development is surprisingly dynamic,
        with loss and new gain, and differences between the embryo and the trophectoderm.
        Besides the Dnmts, there are further proteins involved in the regulation of
        methylation levels. One interesting protein here is Lsh, a chromatin remodelling
        ATPase belonging to the SNF2 family. It seems to have a low ATPase activity
        in vitro, but it cooperates with several known factors like the DNA methyltransferases
        and Histone deacetylases. With mouse promoter microarrays, Irina Stancheva's
        group compared wildtype and Lsh knockout cells, and found a reduction in promoter
        methylation when Lsh is missing. The patterns of DNA methylation observed
        in Lsh null cells suggest that this protein has a role in developmentally-programmed
        methylation events in the early mouse embryo.</p><p>Dominique Soldati-Favre
        from the University of Geneva in Switzerland gave an interesting talk about
        her work on apicomplexan parasites. This phylum includes important human and
        animal pathogens such as Toxoplasma gondii and Plasmodium falciparum causing
        toxoplasmosis and malaria respectively. They belong to the clade of Chromalveolates,
        whose ancestor acquired a plastid organelle by the secondary endosymbiosis
        of an alga. While some members of this clade are free living organisms or
        predators the Apicomplexa have evolved as obligate intracellular parasites.
        These parasites have developed an elaborated strategy to actively penetrate
        the host cells by a mechanism distinct from phagocytosis and involving gliding
        motility. This active mode of entry is favorable to the parasites, because
        this way they can evade the host cell defense mechanisms. To identify and
        study the molecular components of the vital process leading to host invasion,
        the Soldati's group has developed genetic tools beginning from reliable DNA
        transfection up to the establishment of an inducible expression system for
        the malaria parasites based on transcription machinery elements similar to
        those found in plants. Studies performed on T. gondii have established that
        the mechanism of host cell entry is the result of a concerted action of adhesins
        involved in the attachment of the parasite to the host cell, the actin cytoskeleton
        and myosin motors that relocalize these adhesins from anterior to posterior
        pole of the parasite, and proteases that finally release these adhesins from
        the parasite surface.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ German Genetics Society Meeting 2009: Session
        Plant Genetics II ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/german-genetics-society-meeting-2009-session-plant-genetics-ii/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwbr</id>\n        <published>2009-09-24T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-01T06:06:01.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p><em><em>Another
        guest post by <a href=\"https://web.archive.org/web/20120611033114/http://network.nature.com/people/alexander-knoll/profile\">Alex
        Knoll</a> reporting from the German Genetics Society Meeting in Cologne.</em></em></p><p>As
        promised, I attended the second Plant Genetics session of the meeting, thus
        missing the Epigenetics session.</p><p>I learned an important lesson at the
        first talk by Juliette de Meaux from the Max Planck Institute for Plant Breeding
        Research: Bring sweets for the audience, and you have everyone on your side!
        Her research is on the molecular basis of variation in the life cycle of the
        model plant species <em><em>Arabidopsis thaliana</em></em>. Natural Arabidopsis
        strains grow in very different climates, and therefore have to adapt their
        annual life cycle to the environmental conditions: germinating their seeds
        early or late, flowering quickly after germinating or growing vegetatively
        for months. The ability not to germinate although there are good conditions
        is called seed dormancy. This can be a very important trait, for example if
        the Arabidopsis strain grows at a location where a short favorable period
        is followed by a recurring period detrimental to the growth of the plant.
        Then the plants which did not germinate even during the short favorable period
        have an advantage. But such changes in seed germination time need the whole
        life cycle to be fine-tuned: For the seeds of the following season to be ready
        before winter, the growth rate has to faster, or the flowering time shorter.</p><p>Because
        of the varying locations where Arabidopsis grows, there should be variation
        in life history strategies to be found for selection to act upon. For the
        model system of germination rate, Juliette de Meaux' lab found a high variations
        in 180 natural genotypes they looked at. Some strains germinated at the day
        of harvest, while others didn't germinate at all even 250 days after harvest,
        and most somewhere in between. If seeds were exposed to a cold treatment 250
        days after harvest (to simulate winter), the strains that didn't germinate
        after the 250 days suddenly started to germinate, while others decreased in
        their germination rate at longer times of cold exposure. Such and other measurements
        allowed for the analysis of a very complex dataset to derive the different
        strategies of life history in Arabidopsis. For example, there is a correlation
        of growth rate and flowering time to be found, but only in strains growing
        to the north (of Europe), not in the southern strains. They also looked at
        the molecular basis of this life history variation, and the consequences of
        it, which were interesting parts of the talk in and of themselves.</p><p>The
        second talk was by R\xFCdiger Simon from the Institute of Genetics at the
        University of D\xFCsseldorf. Plants also possess stem cells, and they are
        located in niches (in plants called meristems) at the tips of the shoot and
        the root. For the shoot apical meristem (SAM), it is already known that it
        is composed of the stem cells and an organizing center underneath. The stem
        cell proliferation is regulated by a negative feedback loop: Cells in the
        organizing center express Wuschel, which promotes stem cell fate, but stem
        cells express Clavata3, that represses Wuschel via the receptors Clavata1
        and Clavata2. Apart from that, there is a second negative feedback mechanism
        of regulating Wuschel activity known. But according to computer simulations
        by R\xFCdiger Simon and his colleagues, there are further factors needed to
        explain the observed distributions of cells and gene expression. They looked
        for such factors, and found the coryne mutant, which resembles known clavata
        mutants; it must be in the same pathway.</p><p>R\xFCdiger Simon's lab also
        looked at the root tip stem cell niche, if it is perhaps also regulated by
        a Clavata-like pathway. Interestingly, they were able to find a Clavata3-related
        peptide in Cle40, that regulates the Wuschel homolog WOX5. While this is similar
        to the situation in the SAM, there are also differences: WOX5 is produced
        in the QC, which resembles the organizing centre that expresses Wuschel ,
        but Cle40 is not produced by the stem cells, but by already differentiated
        cells derived from those stem cells.</p><p>Next, Bhupendra Chaudary from Gautam
        Buddha University in Greater Noida, India, gave a short presentation on the
        fate of duplicated genes in polyploid cotton. After a genome duplication event,
        the evolutionary constraints on duplicated genes are relaxed, and one way
        change is possible is by generating differences in expression, allowing for
        subfunctionalization or neofunctionalization. They looked at expression differences
        in homoeologous genes (pairs of genes duplicated by a polyploidization event)
        in species of the cotton Gossypium, where parental diploid genomes as well
        as allopolyploids can be found. Interestingly, none of the parental genomes
        showed a dominant expression in the hybrids globally, but some tissue-specific
        transcriptional subfunctionalization.</p><p>The last talk of the session was
        given by Frank Kempken from the University of Kiel on mitochondrial mRNA editing
        in plants. Mitochondria possess their own rudimentary transcription and translation
        machinery, and in between they change the mRNAs in a way the nucleus doesn't:
        they edit the mRNA sequence, usually by exchanging a C for an U to create
        novel stop codons, or to modify the amino acid sequence. How this is done
        is largely unknown.</p><p>Frank Kempken's lab developed a system to work with
        isolated mitochondria, because genetic engineering of them in plants is not
        possible, and <em><em>in vitro</em></em> approaches have serious drawbacks.
        In their '<em><em>in organello</em></em>' system, they can electroporate the
        isolated mitochondria in buffer, and observe the editing done to the expressed
        mRNAs. This allowed them to observe correct recognition of editing sites of
        Arabidopsis mRNAs in the mitochondria of maize, for example, or that mRNAs
        from chloroplasts are not edited in mitochondria. This would at least partially
        be expected, but somehow the plastid transcripts are not recognized by the
        editing machinery in the mitochondria.</p><p>Using a novel binding assay (which
        requires 10 liters of Arabidopsis cell culture per experiment, whew!) they
        were able to find proteins that bind to mRNAs at editing sites. A knockout
        mutant of one of them leads to growth retardation and smaller plants, exactly
        what one would expect when mitochondria don't function properly anymore.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ German Genetics Society Meeting 2009: Session
        III ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/german-genetics-society-meeting-2009-session-iii/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwbq</id>\n        <published>2009-09-24T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-01T06:07:28.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p><em><em>Another
        guest post by <a href=\"https://web.archive.org/web/20120611033341/http://network.nature.com/people/alexander-knoll/profile\">Alex
        Knoll</a> reporting from the German Genetics Society Meeting in Cologne.</em></em></p><p>The
        last session on Thursday was split into two talks by Philippe Sansonetti from
        the Institute Pasteur in Paris and Julian Parkhill from the Sanger Institute
        in Hinxton, Great Britain. Both talked about pathogenic microbes, but from
        a different perspective.</p><p>After Philippe Sansonetti told us about <em><em>Shigella</em></em>
        and the innate immune system during invasion of the gut epithelium, Julian
        Parkhill gave us some insights into two (genomically) very different organisms.
        <em><em>Salmonella typhi</em></em>, responsible for typhoid fever, has evolved
        relatively recently by changing its niche; it went from being a gut pathogen
        to a systemic pathogen. This can be seen in its genome, because its evolution
        is not characterized by the gain of genes, but actually by the loss of many
        genes through single mutations. For bacteria, <em><em>Salmonella typhi</em></em>
        is rather strange: There is almost no recombination between strains, so there
        are very few SNPs that can by typed. By looking at 200 genes in about 200
        strains, they found 88 SNPs in total! Evolutionarily, their data point to
        mostly long-term neutral mutations, with only very few genes to be found that
        show evidence of positive selection. But the SNP data they acquired could
        be put to good use nonetheless: They were able to do an epidemiological analysis
        in the field by collecting S. typhi strains around Kathmandu.</p><p>The opposite
        of <em><em>S. typhi</em></em> in terms of recombination and SNPs is <em><em>Staphylococcus
        aureus</em></em>, which comprises a hugely diverse group of freely recombining
        strains. With next generation sequencing, they were able to track the appearance
        and travels of a specific strain around the world. They even got enough SNPs
        in their dataset to be able to distinguish strains from different wards in
        a single hospital!<br>The talk was also a lesson in technological progress:
        While the sequencing of the <em><em>Salmonella typhi</em></em> genome a few
        years ago took 1.5 years, the next generation sequencing of <em><em>Staphylococcus
        aureus</em></em> allowed the analysis of 66 genomes per run and week. Finally,
        we had a glimpse into the future: They are getting into single cell genome
        sequencing by doing laser capture microsdissection, and are already able to
        reach about 98% coverage!</p><p>Following this last talk of the day, the German
        Genetics Society awarded the honorary membership to Rolf Knippers. At least
        German speaking biologists should know him by name because of his well-known
        (and great, in my opinion) textbook <em><em>Molekulare Genetik</em></em> (Molecular
        Genetics), which first appeared in the early 1970s. But that was not the only
        reason for the award. Actually, Rolf Knippers has been a very good researcher
        and teacher, too! I didn't know him apart from his textbook before, but the
        laudatio and his acceptance speech (which he started by humbly asking if he
        deserved the award) made me wish I had met him earlier, perhaps as a student
        or even as a member of his lab.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ German Genetics Society Meeting 2009: Session
        Cellular Genetic Mechanisms ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/german-genetics-society-meeting-2009-session-cellular-genetic-mechanisms/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwbp</id>\n        <published>2009-09-22T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-01T06:04:25.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p><em><em>Another
        guest post by <a href=\"https://web.archive.org/web/20120611032931/http://network.nature.com/people/alexander-knoll/profile\">Alex
        Knoll</a> reporting from the German Genetics Society Meeting in Cologne.</em></em></p><p>Both
        sessions had some interesting talks, so it was really hard to decide between
        attending Cellular Genetic Mechanisms or Human Genetics, but in the end I
        went to the former.</p><p>The first talk by Marina Rodnina from the Max Planck
        Institute for Biophysical Chemistry is not easy to put into words. Not because
        of a bad presentation, I should add! Her work on biochemical properties of
        translation involves kinetic data of a row of proteins involved in the phases
        of translation: initiation, elongation, termination and ribosome recycling.</p><p>I'll
        give you a short summary of the initiation of translation in bacteria: First
        the 30S subunit of the ribosome binds a mRNA and the initiator tRNA with the
        help of effector proteins to form the 30S initiation complex. The 50S subunit
        then binds to that to form the 70S initiation complex. By fluorescently labelling
        all of the components of the complex, they were able to measure the rate constants
        (how do they bind and dissociate from the ribosome) and then calculate the
        binding rates to find the order of binding. This is hardest to establish for
        the mRNA, because of control elements like the composition of the Shine-Dalgarno
        sequence or secondary structures. But ignoring all of these elements, the
        most significant factor at this step is the mRNA concentration. Looking at
        secondary structure, the unfolding of the mRNA is the slow step after a quick
        binding. This represents a kind of stability switch to enable correct start
        codon recognition. Not only during initiation, but also for elongation Marina
        Rodnina's lab could show that a lot of checks are kinetic in nature. Essentially,
        this can be summarized by the concept of induced fit: correct substrates are
        selectively stabilized by accelerating their forward steps.</p><p>Following
        was a short presentation by Matthias Sch\xE4fer on unpublished research. At
        the ETH Z\xFCrich in Switzerland, he is looking into the molecular role of
        protection against reactive oxygen species (ROS) in the epidermis.</p><p>Aria
        Baniahmad fom the Jena University Hospital, Germany, talked about an interesting
        connection of telomerase activity and androgens in prostate cancer. There,
        telomerase is usually active, as in many cancers to allow the cancer cell
        to divide indefinitely. Androgens repress telomerase activity, which is probably
        one reason why prostate cancer occurs later in life, when androgen levels
        decrease in men.</p><p>The decrease of telomerase activity is based on binding
        of the androgen receptor to the promoter of the catalytic telomerase subunit
        hTERT. In many prostate cancers, an androgen receptor with a specific point
        mutation can be found. This mutated AR's binding to the telomerase promoter
        is weaker, which results in increased telomerase expression.</p><p>The session
        was closed with a talk by Thorsten Hoppe from the Institute for Genetics of
        K\xF6ln University, who presented intruiging, but unpublished data about his
        research on ubiquitin and ageing in <em><em>C. elegans</em></em>.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ German Genetics Society Meeting 2009: Session
        IV ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/german-genetics-society-meeting-2009-session-iv/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwbn</id>\n        <published>2009-09-21T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-01T06:02:57.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p><em><em>Another
        guest post by <a href=\"https://web.archive.org/web/20120611032512/http://network.nature.com/people/alexander-knoll/profile\">Alex
        Knoll</a> reporting from the German Genetics Society Meeting in Cologne.</em></em></p><p>The
        first session on Friday started with a talk by Frauke Melchior from the ZMBP
        in Heidelberg on SUMO. Apart from being interesting to work with, it also
        is good for some rather funny paper titles</p><figure class=\"kg-card kg-image-card\"><img
        src=\"https://web.archive.org/web/20120611032512im_/http://blogs.plos.org/mfenner/wp-includes/images/smilies/icon_wink.gif\"
        class=\"kg-image\" alt=\";-)\" loading=\"lazy\"></figure><p>At the start,
        she gave a short introduction on the proterties of SUMO. It is similar to
        Ubiquitin (it stands for Small Ubiquitin-like MOdifier) and gets covalently
        bound to lysines of hundreds of proteins to change their protein or DNA interactions,
        localization, or activity. A good example I also know from my work is the
        yeast DNA repair helicase Srs2, which only interacts with the SUMOylated form
        of the replication protein PCNA at the replication fork to suppress recombination.
        Many protein-protein interactions that are dependent on SUMOylation can be
        traced back to non-covalent recognition of a SUMO-interaction motif, SIM.</p><p>Like
        with ubiquitin, there is an enzymatic cascade to bind a SUMO unit to a target
        protein; however, there is only one E1 activating and one E2 conjugating enzyme,
        and a handful of E3 SUMO ligases (compared to hundreds for the ubiquitin pathway).
        Target recognition is not understood very well, but there is a known consensus
        site wich is recognized by the E2 enyzme for SUMOylation. The problem is:
        many proteins are SUMOylated at non-consensus sites. Another mechanism turns
        the usual direction of the pathway on its head: The target proteins interacts
        with SUMO via a SIM, while it is still bound to the E2 enzyme. This allows
        the E2 to transfer SUMO to the target protein.</p><p>Finally, Frauke Melchior
        told us about an interesting pair of proteins that are involved in SUMOylation:
        RanGAP (RanGTPase activating protein) interacts with RanBP2 at the nuclear
        pore complex after it gets SUMOylated. RanBP2 itself is a SUMO E3 ligase,
        but not for RanGAP. Without going into too much detail (unpublished data),
        the story unraveled by Frauke Melchior and her coworkers showed a really complex
        and intriguing picture of the role SUMO plays in regulating the activity of
        this complex and the effect on nuclear transport.</p><p>In the second talk
        of the session, Chris Wylie from the Developmental Biology division of the
        Cincinnati Children's hospital threw out the simple model of germ cell migration
        in mouse embryos found in the textbooks: During embryo development, the stem
        cells of the gametes, the germ line stem cells, have to migrate to their niche
        in the gonads. They start their travels in a structure called the allantois,
        go through the hindgut and from there to the genital ridges, where the gonads
        will form. Classically, it was thought that long range signals guide their
        migration. But this is problematic, because the target organ supposed to produce
        the guiding signal is not formed when the germ cells start their migration,
        and during the migration the surroundings and distances will change dramatically!
        That means there must be short range signals for guidance.</p><p>A nice example
        to test this is the trip from the midline above the gut to the genital ridges.
        Germ cells that stay at the midline will die by apoptosis. The previously
        known stem cell survival factor Steel is involved in preventing apoptosis
        in the cells. Its concentration decreases from the ridges to the midline;
        adding Steel everywhere experimentally saves the midline germ cells from apoptosis,
        while blocking Steel everywhere kills the germ cells laterally. They were
        able to show that Steel is not only involved in apoptosis, but also in the
        migration and proliferation of the germ cells. Steel is not only required
        at the late migration from the midline to the genital ridges; from the start
        in the allantois, loss of Steel leads to loss of germ cell number and migration.</p><p>Essentially,
        this means that not only is Steel one (of probably many) short range signals,
        but it also travels with the germ cells along their migration route, giving
        them a mobile stem cell niche!</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ German Genetics Society Meeting 2009: Evolution
        Session ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/german-genetics-society-meeting-2009-evolution-session/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwbm</id>\n        <published>2009-09-20T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-01T06:01:58.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p><em><em>Another
        guest post by <a href=\"https://web.archive.org/web/20120611031744/http://network.nature.com/people/alexander-knoll/profile\">Alex
        Knoll</a> reporting from the German Genetics Society Meeting in Cologne.</em></em></p><p>Just
        after lunch the next decision: Neurogenetics or Evolution? Here I went with
        the topic that is less far from my field, and attended the evolution session.
        Welcome to the modern times, because next generation sequencing and high throughput
        are the way to go!</p><p>These were the methods of choice for Julia Zeitlinger
        from the Stowers Institute for Medical Research in Kansas City to compare
        transcription factor binding sites between several Drosophila species. This
        goes back to the question, which process contributes more to evolution: mutations
        in the protein-coding parts of genes, or the sequences needed for the transcriptional
        regulation of these genes, the so-called cis-regulatory elements. There is
        evidence in some organisms of a high turnover of transcription factor binding
        sites, and Julia Zeitlinger wanted to compare these in the genus Drosophila.
        This was done with chromatin immunoprecipitation approaches, where you analyze
        the sequence of DNA fragments to which a target protein like a transcription
        factor is bound. Earlier, this was followed by hybidisation of microarrays
        (ChIP-chip), today these DNA fragments can be directly sequenced with next
        generation methods (ChIP-seq). They chose the dorso-ventral patterning in
        the Drosophila embryo as a model system, with transcription factors like Twist
        that are well studied, and that have conserved binding sites. Surprisingly,
        they found that Twist binds to about 8 times more positions than were expected;
        sometimes Twist bound at more than one position at target genes.</p><p>Across
        Drosophila species the binding sites of Twist were very similar, especially
        near transcriptional start sites the positions are mostly conserved. Although
        movements of binding sites exist, they are rare. So it seems that there is
        evolutionary pressure to maintain the sites.</p><p>Also about the evolutionary
        contributions of cis-regulatory regions was the talk by Diethard Tautz from
        the Max Planck Institute for Evolutionary Biology in Plants, Germany. But
        he addressed them with population genetics of wild house mouse strains. With
        microarray and qPCR experiments, his lab was able to find that the majority
        of genes they looked at follow a neutral evolution. When this is not the case,
        most of those genes show only tissue-specific changes in expression, which
        points to cis-regulatory elements.</p><p>They also found a newly evolved gene
        in the mouse: In a region that is completely free of annotated transcripts
        in other mammals, one transcript can be found in the mouse. Poldi, as it is
        called, is expressed in the mouse testis and encodes a non-protein coding
        RNA. They were able to follow its birth in the genus Mus, where it appeared
        about 2.5 million years ago by changes in promoter regions. And although Poldi
        appeared relatively recently, it plays a role in the mouse. A knockout results
        in mice with reduced sperm motility and smaller testis, because several chromatin-regulating
        proteins show different expression levels in the absence of Poldi.</p><p>Now
        on to some computational biology by Andrew Hufton from the Max Planck Institute
        for Molecular Genetics in Berlin. He analyzed a special kind of cis-regulatory
        elements: the so-called conserved non-coding elements (CNEs), that don't show
        much chance even over great evolutionary distances. Why do they exist? There
        are two competing hypotheses; either the CNEs repress genome rearrangements,
        or they promote the retention of duplicate genes nearby. To test both hypotheses,
        Andrew Hufton identified so-called phylogenetically conserved non-coding elements.
        These are elements associated with gene families and are not biased for one
        of the hypotheses. With experiments in zebrafish, he found that most of the
        PCNEs are enhancers, sequences involved in the regulation of gene expression.</p><p>Concerning
        the two competing hypotheses, he found a strong association between PCNE and
        synteny conservation \u2013 the first hypothesis: the PCNEs are enriched around
        genes with an ancient gene order. For the retention of duplicated genes, he
        showed us an alternative model.</p><p>In the last short talk of this session,
        Stephan Greiner told us about a plant with a strange inheritance. At the Max
        Planck Institute for Molecular Plant Physiology at Potsdam-Golm in Germany,
        he is working on the Evening Primrose Oenothera. It combines some very interesting
        genetic features like easy crossings between species, fertility of the resulting
        hybrids, biparental transmission of chloroplasts (that are usually inherited
        maternally) and something very strange called permanent-translocation heterozygosity:
        The chromosomes of Oenothera easily break at the centromeres, so that translocations
        of chromosome arms happen. This leads to rings or chains of chromosomes during
        meiosis that suppress homologous recombination and the intermixing of haploid
        chromosomes. In the end, there are a handful of stable genomes that a transmitted
        stably, and a hybrid plant with a combination of two of these genomes will
        always have hybrid offspring.<br>Add in the possibility to exchange one of
        several different chloroplast genomes in only two generations, and you will
        be able to generate compatibility charts of nuclear and chloroplast genomes,
        where lethal combinations and less severe phenotypes occur. Taken one step
        further, it is possible to identify speciation genes in the chloroplast genome.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ German Genetics Society Meeting 2009: Development
        Session ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/german-genetics-society-meeting-2009-development-session/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwbk</id>\n        <published>2009-09-19T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-01T06:00:58.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p><em><em>Another
        guest post by Alex Knoll reporting from the German Genetics Society Meeting
        in Cologne.</em></em></p><p>This time I had to decide between two parallel
        sessions for the first time at this meeting. Plant genetics or Development?
        Coming from plant molecular genetics myself, there perhaps was a ready-made
        decision, but I decided otherwise. There will be a second plant genetics session,
        and work with the axolotl and spiders lured me to the developmental biologists.
        But I had a rather hard time following all the new information, so please
        bear with me! To get at least a little bit of information about the plant
        genetics session, take a look into the meeting program for the abstracts (<a
        href=\"https://web.archive.org/web/20120611031830/http://conventus.de/fileadmin/media/2009/genetik/PDF/2009_09_14_Genetik_2009_Programm_klein.pdf\">PDF</a>).</p><p>Elly
        Tanaka from the Center for Regenerative Therapies in Dresden, Germany is working
        with the axolotl, a salamander, as her model to research the molecular and
        cellular events needed for spinal cord regeneration. Choosing the axolotl
        was a good idea because it can regenerate lots of tissues and organs, it even
        grows back whole legs and its tail. On the other hand, her group had to develop
        all of the molecular genetics fresh from the start, which was quite a lot
        of work I guess. But they did it, and now have EST sequences, can do single
        cell electroporation for gene transformations, morpholino knockdown of gene
        expression is possible. They were able to get transgenes transferred through
        the germline, can express genes in specific tissues and establish cell cultures.
        Quite a set, isn't it?</p><p>This enabled Elly Tanaka's lab to look at the
        events after the axolotl loses its tail by a cut, specifically how the spinal
        cord is able to grow back. There are two basic ideas how this is done: either
        it grows from the end, or it expands by cell division within the spinal cord.
        They found that the second hypothesis is true, because a about 500 \xC2\xB5m
        long zone right after the cut gives rise to the cells of the regenerated spinal
        cord. By looking at molecular markers at this zone, they were able to determine
        that the glial cells are the progenitors for the regeneration, and they need
        to revert to a more primitive state.</p><p>The second invited speaker of this
        session, Thomas Klein from the Institute of Genetics at the University of
        D\xFCsseldorf, spoke about the newly analyzed gene Lgd in the fly <em><em>Drosophila
        melanogaster</em></em> that regulates the activity of the well-known Notch
        gene by a new mechanism. Since this is about unpublished work, I won't go
        into more detail here.</p><p>Of the three short presentations in this session,
        the talk of Annegret B\xF6rdlein from the Institute of Human Genetics in Erlangen,
        Germany, also contained essentially unpublished data.</p><p>Luckily, I am
        free to write about the other two talks! Thomas Widmann from the Max Planck
        Institute for Cell Biology and Genetics in Dresden looked at the cell shape
        changes in the imaginal disc in Drosophila. This structure of the fly larva
        will later give rise to parts of the outside of the adult body, including
        the wings (who would have guessed?). In the wing disc epithelium there are
        to cell layers that chance their shape during development: One flattens, the
        other elongates to columns. Thomas Widmann was able to find the two transcription
        factors Dpp and Wingless implicated in this shape change, since columnar cells
        lacking these factors are shorter. How is this done in the cell? The actin-myosin
        cytoskeleton builds a meshwork underneath the plasma membrane to generate
        tension, and the amount of force is controlled by Rho1 that can phosphorylate
        Myosin II. By downregulating Rho1, the cell get elongated, its overexpression
        shortens them. Dpp is one factor that enhances the activity of Rho1. That
        way, Dpp and Rho1 maintain the length in these cells.</p><p>Finally Wim Damen
        told us about his work on the developmental processes in the spider <em><em>Achaearanea
        tepidariorum</em></em>. At the Deparment of Genetics at the University of
        Jena, he is looking into segmentation processes. What happens during segmentation
        is very well understood in Drosophila, where a gene cascade forms all of the
        segments at approximately the same time. In vertebrates, the somites are comparable
        as a segmentation process, but here one forms after the other. Wim Damen found
        that in the spider, the anterior and central segments are formed like in insects
        rapidly and almost at the same time, but the posterior segments are formed
        one by one like in vertebrates. Here are even homologous genes like Notch
        and Wnt8 required for the segmentation. In the central region, Hunchback is
        essential for the production of the spider's legs. After RNAi knockdown of
        Hunchback, the spiders lack some of their legs because the L1, 2 and 4 segments
        don't form. This combination of insect and vertebrate-like processes during
        segmentation probably means that also their last common ancestor possessed
        both mechanisms.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ German Genetics Conference 2009: Session
        II ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/german-genetics-conference-2009-session-ii/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwbh</id>\n        <published>2009-09-18T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-01T05:58:59.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p><em><em>Another
        guest post from Alex Knoll reporting from the German Genetics Conference in
        Cologne.</em></em></p><p>Dusko Ehrlich fom Jouy en Josas in France started
        off the second session of the meeting. He is working with the <a href=\"https://web.archive.org/web/20151003105714/http://www.metahit.eu/\">MetaHIT
        project</a>, which tries to do a metagenomic analysis of the human intestinal
        tract. This is interesting because each individual human carries about ten
        times more microbial cell in the gut than there are human cells in the whole
        body! These microbes provide the interface between the food we take in and
        the epithelial cells of the gut. There, they play many roles not only in metabolising
        materials and molecules we are not capable of, but they also produce vitamins
        for us and help the immune system. It is therefore very important to understand
        this further organ of our body, as Dusko Ehrlich called it.</p><p>The MetaHIT
        project takes many approaches to understand the interaction between the human
        intestinal microbes and human phenotypes like obesity ore bowel diseases.
        For example, they want to sequence a reference gene set and then look for
        associations of these genes with diseases. The reference gene set is produced
        by Solexa paired-end sequencing of samples from 124 individuals, which produced
        almost 0.6 terabases of sequence in total already! From these sequences contigs
        are produced and ORFs are predicted, which are almost completey of bacterial
        origin. This then allows for the comparison of bacterial genes and genomes
        between the sampled individuals, and also the establishment of a 'minimal
        metagenome' of the gut ecosystem for absolutely required functions.</p><p>The
        second talk was really interesting to me: In <em><em>Drosophila melanogaster</em></em>
        the male flies perform a courtship dance to win over the female. Barry Dickson
        from the Institute of Molecular Pathology in Vienna is looking for the genetic
        neurobiologic basis of this behaviour.</p><p>The fruitless gene, which produces
        a transcription factor, is absolutely required for the courtship of male flies;
        females don't produce a protein product due to alternative splicing. But when
        females carry the male form of the fru gene, they show the typical male courtship
        behaviour. This means fruitless is some kind of molecular switch for male
        behaviour in Drosophila by programming the nervous system. So they looked
        at neurons that express the fru gene with the help of reporter genes and found
        sensory, central and motor neurons that need to be active for male courtship.
        Dickson's lab was able to assemble a digital atlas of fru neurons, with stunning
        pictures, and were able to derive a 'wiring diagram'. Just six easy steps:
        Starting from fru-expressing olfactory receptor neurons that specifically
        sense pheromones it only takes this few neural connections to motor output
        in wing muscles that are required for the courtship song!</p><p>Now the group
        is trying to go the high throughput route by teaching a computer to analyze
        the courtship behaviour by itself, and the first results look very promising.</p><p>The
        third talk by Andrei Lupas of the Max Planck Institute for Developmental Biology
        in T\xFCbingen, Germany, was about the genetic basis of protein fold evolution.
        Autonomously folding units in proteins are called domains, and usually the
        fold of a domain is conserved with a high evolutionary permanence.</p><p>Surprisingly
        for me, there are only about 10\xC2\xB3 basic folds, that all were established
        around the time of the last universal common ancestor of all living organisms.<br>But
        there is the potential for a fold change in domains by specific alterations
        that go back to point mutations, deletions, insertions or recombination at
        the level of DNA. To understand how these changes come about, Lupas' group
        is looking at experimental changes and their outcome. For example, beta-propellers
        are structures that arise by repeating a single 'blade' a certain number of
        times. Actually, all present beta-propellers probably all go back to one ancestral
        blade that was amplified several times. How large can a propeller domain become?
        The biggest propeller in databases has 10 blades, a 14-blade propeller in
        yeast forms a split between blades 7 and 8. But Lupas was able to produce
        a 12-bladed propeller.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ German Genetics Society Meeting 2009: Session
        I ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/german-genetics-society-meeting-2009-session-i/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwbg</id>\n        <published>2009-09-18T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-01T05:59:56.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p><em><em>The
        second guest post from fellow science blogger Alex Knoll reporting from the
        German Genetics Conference currently held in Cologne.</em></em></p><p>The
        first session was all over the place in terms of topics.</p><p>Starting off
        the meeting, Linda Partridge from the Institute of Healthy Ageing in London
        and the Max Planck Institute for Biology of Ageing in Cologne told us about
        the Genetics of Ageing.</p><p>Looking back, there has been a linear increase
        of life expectancy in humans for a rather long time now, with about 2.5 years
        added every decade. That comes down to about 6 hours of increased life expectancy
        per day!</p><p>While there is no single cause for ageing, it is nonetheless
        controlled by genes and can evolve. And although life expectancy is generally
        correlated with the body size of animals, there are several exceptions like
        the little Brandt's bat that can live for 38 years, and there are also some
        organisms that don't seem to age at all!</p><p>At first it was thought that
        the research of ageing in model organisms would not be too relevant for the
        understanding of human ageing, because there were many unique pathways in
        the different animals. Interestingly, in many model organisms like the worm
        Caenorhabditis elegans, the fly <em><em>Drosophila melanogaster</em></em>
        and also the mouse, the insulin pathway plays a big role: When components
        of this pathway are knocked out, the lifespan of the animal increases. This
        means the healthy lifespan, the organisms spend more time in the prime of
        their life instead of just being old and sick for a longer time. Even in humans,
        population genetics studies found homologues of some of these genes as candidates.
        The implication of the insulin pathway fits nicely to earlier observations
        of dietary restriction: If you put an organism on a diet with less calories
        than it usually eats, it will live longer. This is rather easy to do in the
        fly: just dilute the sugar solution it eats. This way it was possible for
        the people in Linda Partridge's lab to compare putative genes implicated in
        ageing with dietary restriction.</p><p>They then asked the question: how deeply
        is the genetics of ageing conserved between organisms? By using comparative
        microarray studies with worm, fly and mouse, they were able to identify functional
        categories of genes that are up- or downregulated in ageing.</p><p>Frank Grosveld
        from the Erasmus Medical Center in Rotterdam talked about a systems biology
        approach to understand the transcriptional regulation of globin genes in the
        mouse. During the development of red blood cells, several large multiprotein
        complexes act as transcription factors and bind to regulate the proliferation
        and differentiation. With a systems biology procedure, Frank Grosveld's lab
        tried to find and identify binding partners of known transcription factors
        during early and late stages of erythrocyte differentiation. For example,
        GATA1 makes several different complexes that very early on repress non red
        cell genes to prime the lineage, later another complex with GATA1 represses
        proliferation as a requirement for differentiation.</p><p>Interestingly, the
        globin locus that is expressed during erythrocyte development, lies in between
        many olfactory genes. With the help of several proteins binding at a number
        of regulatory regions, the structure of the chromatin is altered so that these
        olfactory genes are looped out and the components of the globin locus come
        to lie near each other. This also enables long range interactions of elements
        that are farther away, sometimes several megabases! The chromatin loops also
        change depending on the tissue: the globin locus is expressed in the fetal
        liver, and there it contacts other actively expressed genes. In the fetal
        brain, on the other hand, the globin locus is inactive, and it contacts mostly
        other inactive genes. The looping can even be shown microscopically by measuring
        the volume of the the globin locus. In expressing tissue the volume decreases,
        which indicates extra looping.<br>Another interesting aspect of Frank Grosveld's
        work touches blood disorders like thalassemia and sickle cell anemia. These
        result from defects in the beta-globin gene and are hard to treat. The idea
        here is great: in fetal tissues, the gamma-globin genes are expressed, but
        they are repressed perinatally. They have been able to identify a handful
        of proteins that are responsible for this repression in mice, and downregulation
        of these proteins leads to an upregulation of gamma-globin expression and
        a downregulation of beta-globin. These repressors are now novel targets to
        develop a new type of treatment for these anemias.</p><p>Finally, Marjori
        Matzke from the Gregor Mendel Institute in Vienna spoke about epigenetics
        in plants. Specifically, she told us about her research into RNA-dependent
        DNA methylation (RdDM) as a way to regulate transcription in plants, where
        not only repeats and other such elements are processed, but also single genes.
        This is done via small RNAs and the action of the two RNA polymerases PolIV
        and PolV. These are related to the standard RNA polymerase PolII, but possess
        different C-terminal domains that are responsible for their functional diversification.
        After 24-nt long siRNAs are produced, they lead to de novo methylation and
        thus inactivation of target sites with the help of PolV and other factors.
        From this inactivated locus then further siRNAs are produced with PolIV to
        keep the methylated state. Using a silenced GFP expression system, the Matzke
        lab searched for mutants with defects in RdDM, and found several until now.<br>RNA-dependent
        DNA methylation as a further method of transcriptional regulation in the cell,
        for example for stress responses in plants that can't run away from the stress
        arrived at an interesting time in plant evolution. The group of flowering
        plants appeared rather abruptly in the fossil record, prompting Charles Darwin
        famously to speak about an 'abominable mystery'. PolV and other factors involved
        in RdDM are only to be found in flowering plants, which could let one conclude
        that the newly evolved epigenetic plasticity played at least a part in the
        evolution of this successful group.</p><p>The first day of the meeting ended
        with a public lecture by Peter Propping from Bonn in Germany. His talk in
        German was about the history and future of human genetics (\u201CDer Mensch
        und seine Gene in der Welt von morgen\u201D). He started by telling us about
        the problematic standing of human genetics in the middle of the last century,
        mostly because of concerns stemming from the earlier decades with eugenics,
        sterilizing and killing people because of genetic concerns.</p><p>The big
        successes then came with the research into monogenetic diseases, which firstly
        were reached by methods such as positional cloning. Now is the time to study
        multifactorial diseases, which are much harder to tackle; here we have many
        genes which only contribute a small amount to the phenotype, and environmental
        effects contributing as well. A nice example of a new kind of genetic defect
        are copy number variants, where a sequence is repeated a different number
        of times between individuals. But this is not well understood for now, because
        the same CNVs can be found in diseased patients, but also in healthy people.</p><p>In
        the future a lot of work will be done with next generation sequencing, which
        will hopefully put a lot of data into the hands of the researchers. On the
        other hand, this means that a lot of money will be spent \u2013 a criticism
        that can be heard already now.</p><p>Another part of his talk was about the
        possibilities of and problems of prenatal screening. It was rather surprising
        for me to hear that in Germany in about 10% of pregnancies a screening is
        done, mostly to look for chromosomal mutations like trisomy 21 (that is responsible
        for Down syndrome)! Pre-implantation diagnostics in the course of in vitro-fertilization,
        however, is not allowed in Germany, which lead to a PID tourism into other
        European countries.</p><p>Finally Peter Propping also talked about the new
        law for genetics diagnostics in Germany, which has some problems. For example,
        genetic analysis is defined by methods in the law, which leads to the curious
        case that even simple biochemical work such as blood group determination falls
        under the regulations of the new law!</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ German Genetics Society Meeting 2009: Introduction
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/german-genetics-society-meeting-2009-introduction/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwbj</id>\n        <published>2009-09-17T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-01T05:58:05.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p><em><em>This
        is the first of several posts by guest science blogger <a href=\"https://web.archive.org/web/20130719070905/http://network.nature.com/people/alexander-knoll/profile\">Alexander
        Knoll</a>, who will report from the <a href=\"https://web.archive.org/web/20130719070905/http://www.genetics2009.de/\">Annual
        Meeting of the German Genetics Society</a>. I will be back from my summer
        vacation on Sunday.</em></em></p><p>Away from my usually blogging grounds
        at <a href=\"https://web.archive.org/web/20130719070905/http://www.scienceblogs.de/alles-was-lebt\">Alles
        was lebt</a> at the German Scienceblogs, I want to bring you impressions <a
        href=\"https://web.archive.org/web/20130719070905/http://www.genetics2009.de/\">from
        the Annual Meeting of the German Genetics Society</a> in Cologne. We wanted
        to try out another way to tackle some of the problems of conference blogging,
        and informed all of the speakers beforehand about the blog. This way I could
        be informed about unpublished data in talks, and work around it with the researchers
        still being able to talk about fresh stuff.</p><p>In the next few days, there
        will be sessions about lots of different topics in genetics, from human genetics
        and medicine via other organisms like plants and microbes to general topics
        like cellular genetics and evolution. Which puts me in the hot seat, for I
        will have to appear knowledgable on all of these</p><figure class=\"kg-card
        kg-image-card\"><img src=\"https://web.archive.org/web/20130719070905im_/http://blogs.plos.org/mfenner/wp-includes/images/smilies/icon_wink.gif\"
        class=\"kg-image\" alt=\";-)\" loading=\"lazy\"></figure><p>I'm really looking
        forward to the flood of information that will hit me the next few days, and
        also to this blogging experience!</p><p>Since the <a href=\"https://web.archive.org/web/20130719070905/http://conventus.de/1292/\">blog
        is linked from the meeting website</a>, I'm hoping that some of the participants
        will comment on their impressions as well. Note for the Twitter people: I'll
        also try and hit out a few tweets as <a href=\"https://web.archive.org/web/20130719070905/http://www.twitter.com/Argent23\">@Argent23</a>
        with the hashtag #gfg09.</p><p>The following posts have appeared so far:</p><ul><li><a
        href=\"https://web.archive.org/web/20130719070905/http://network.nature.com/people/mfenner/blog/2009/09/18/german-genetics-society-meeting-2009-session-i\">Session
        I</a></li><li><a href=\"https://web.archive.org/web/20130719070905/http://network.nature.com/people/mfenner/blog/2009/09/18/german-genetics-conference-2009-session-ii\">Session
        II</a></li><li><a href=\"https://web.archive.org/web/20130719070905/http://network.nature.com/people/mfenner/blog/2009/09/19/german-genetics-society-meeting-2009-development-session\">Development
        Session</a></li><li><a href=\"https://web.archive.org/web/20130719070905/http://network.nature.com/people/mfenner/blog/2009/09/20/german-genetics-society-meeting-2009-evolution-session\">Evolution
        Session</a></li><li><a href=\"https://web.archive.org/web/20130719070905/http://network.nature.com/people/mfenner/blog/2009/09/21/german-genetics-society-meeting-2009-session-iv\">Session
        IV</a></li><li><a href=\"https://web.archive.org/web/20130719070905/http://network.nature.com/people/mfenner/blog/2009/09/22/german-genetics-society-meeting-2009-session-cellular-genetic-mechanisms\">Session
        Cellular Genetic Mechanisms</a></li><li><a href=\"https://web.archive.org/web/20130719070905/http://network.nature.com/people/mfenner/blog/2009/09/24/german-genetics-society-meeting-2009-session-iii\">Session
        III</a></li><li><a href=\"https://web.archive.org/web/20130719070905/http://network.nature.com/people/mfenner/blog/2009/09/24/german-genetics-society-meeting-2009-session-plant-genetics-ii\">Session
        Plant Genetics II</a></li><li><a href=\"https://web.archive.org/web/20130719070905/http://network.nature.com/people/mfenner/blog/2009/09/25/german-genetics-society-meeting-2009-session-vi\">Session
        VI</a></li><li><a href=\"https://web.archive.org/web/20130719070905/http://network.nature.com/people/mfenner/blog/2009/09/29/german-genetics-society-meeting-2009-session-v-and-vii\">Session
        V and VII</a></li><li><a href=\"https://web.archive.org/web/20130719070905/http://network.nature.com/people/mfenner/blog/2009/10/01/conference-blogging-interview-with-alex-knoll\">Interview
        with Alex Knoll</a></li></ul> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Thoughts on the Science Online London Conference
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/thoughts-on-the-science-online-london-conference/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw38</id>\n        <published>2009-08-23T00:00:00.000+00:00</published>\n\t\t<updated>2023-09-02T07:19:09.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2023/09/3849019527_261b65cac9_k.jpg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2023/09/3849019527_261b65cac9_k.jpg\"></p><p>We
        did it. Yesterday was <a href=\"https://web.archive.org/web/20151002164342/http://www.scienceonlinelondon.org/\">Science
        Online London</a>, a conference about the online communication of science
        that took place at the <a href=\"https://web.archive.org/web/20151002164342/http://www.rigb.org/\">Royal
        Institution</a>. I hope that everybody that attended had a great time. You
        can see a lot of conference coverage on Twitter (hashtag #solo09) and in the
        <a href=\"https://web.archive.org/web/20151002164342/http://www.friendfeed.com/solondon\">FriendFeed
        Science Online London group</a>. And don't forget the <a href=\"https://www.flickr.com/groups/solo09/pool/\">Flick
        group</a> with pictures such as this one by Jacqueline Spoetnik:</p><p>Several
        blog posts have already been written, most notably by Allyson Lister who posted
        their detailed reports on her <a href=\"https://web.archive.org/web/20151002164342/http://themindwobbles.wordpress.com/\">the
        mind wobbles</a> blog literally minutes after the sessions had ended. Nico
        Adams has also already posted blog posts about a number of sessions on his
        blog <a href=\"https://web.archive.org/web/20151002164342/http://wwmm.ch.cam.ac.uk/blogs/adams/\">Staudinger's
        Semantic Molecules</a>.</p><p><em><em>London Pub and Science Tour (Matt Brown)</em></em><br>*
        <a href=\"https://web.archive.org/web/20151002164342/http://wwmm.ch.cam.ac.uk/blogs/adams/?p=294\">Science
        Online London 2009! \u2013 The Prequel</a> (Staudinger's Semantic Molecules)<br>*
        <a href=\"https://web.archive.org/web/20151002164342/http://network.nature.com/hubs/london/blog/2009/08/23/science-online-london-2009-the-beer-and-stuff\">Science
        Online London: The Beer and Stuff</a> (Nature Network London Blog)</p><p><em><em>FringeFrivolous
        Preconference Event (Jenny Rohn)</em></em><br>* <a href=\"https://web.archive.org/web/20151002164342/http://wwmm.ch.cam.ac.uk/blogs/murrayrust/?p=2220\">Galaxy
        Zoo at Mendeley</a> (petermr's blog)<br>* <a href=\"https://web.archive.org/web/20151002164342/http://www.mendeley.com/blog/academic-life/fringe-frivolous-and-science-online-london-2009-pictures/\">Fringe
        Frivolous and Science Online 2009 Pictures</a> (Mendeley Blog)<br>* <a href=\"https://web.archive.org/web/20151002164342/http://network.nature.com/people/stuffysour/blog/2009/08/24/its-a-control-thing-dummy\">It's
        a control thing, dummy</a> (Science behind the scenes)<br>* <a href=\"https://web.archive.org/web/20151002164342/http://network.nature.com/people/eva/blog/2009/08/24/lolcats-and-labrats\">LOLcats
        and labrats</a> (Expression Patterns)<br>* <a href=\"https://web.archive.org/web/20151002164342/http://network.nature.com/people/UE19877E8/blog/2009/08/24/in-which-i-rest-on-my-laurels\">In
        which I rest on my laurels</a> (Mind the Gap)<br>* <a href=\"https://web.archive.org/web/20151002164342/http://network.nature.com/people/rpg/blog/2009/08/26/on-the-roof\">On
        the roof</a> (The Scientist)</p><p><em><em>Legal and Ethical Aspects of Science
        Blogging (Petra Boynton, David Allen Green (\u201CJack of Kent\u201D))</em></em><br>*
        <a href=\"https://web.archive.org/web/20151002164342/http://jackofkent.blogspot.com/2009/08/amongst-science-bloggers.html\">Among
        the science bloggers</a> (Jack of Kent)</p><p><em><em>Blogging for impact
        (Dave Munger, Daniel MacArthur)</em></em><br>* <a href=\"https://web.archive.org/web/20151002164342/http://themindwobbles.wordpress.com/2009/08/22/blogging-for-impact-science-online-london-2009/\">Blogging
        for Impact</a> (the mind wobbles)<br>* <a href=\"https://web.archive.org/web/20151002164342/http://wwmm.ch.cam.ac.uk/blogs/adams/?p=312\">Science
        In the Open 2009 London: Blogging for Impact</a> (Staudinger's Semantic Molecules)<br>*
        <a href=\"https://web.archive.org/web/20151002164342/http://seedmagazine.com/content/article/telepresent_at_the_future/\">Present
        at the Future</a> (Seed Magazine)</p><p><em><em>What is a scientific paper?
        (Lee-Ann Coleman, Katharine Barnes, Enrico Balli, Theo Bloom)</em></em><br>*
        <a href=\"https://web.archive.org/web/20151002164342/http://themindwobbles.wordpress.com/2009/08/22/breakout-1-what-is-a-scientific-paper/\">Breakout
        1: What is a scientific paper?</a> (the mind wobbles)<br>* <a href=\"https://web.archive.org/web/20151002164342/http://wwmm.ch.cam.ac.uk/blogs/adams/?p=317\">Notes
        from Science Online: What is a Scientific Paper?</a> (Staudinger's Semantic
        Molecules)<br>* <a href=\"https://web.archive.org/web/20151002164342/http://blog.openwetware.org/scienceintheopen/2009/08/23/the-future-of-the-paperdoes-it-have-one-and-the-answer-is-yes/\">The
        Future of the Paper\u2026Does it have one?</a> (Science in the Open)<br>*
        <a href=\"https://web.archive.org/web/20151002164342/http://www.sciencebase.com/science-blog/what-is-a-scientific-paper-solo09.html\">What
        is a scientific paper?</a> (Sciencebase)<br>* <a href=\"https://web.archive.org/web/20151002164342/http://cotch.net/blog/20090825_0007\">What
        is the scientific paper? 1: Observations</a> (Cotch.net)</p><p><em><em>Breakout
        2: Online communication of science by institutions and organizations (Ed Yong,
        Henry Scowcroft, Paolo Viscardi, Simon Frantz)</em></em><br>* <a href=\"https://web.archive.org/web/20151002164342/http://wwmm.ch.cam.ac.uk/blogs/adams/?p=315\">Notes
        from Science Online 2009: How the Web enables anyone to be a Scientist</a>
        (Staudinger's Semantic Molecules)</p><p><em><em>Cat herding: The challenges
        and rewards of managing online scientific communities (Arikia Millikan, Corie
        Lok, Ijad Madisch)</em></em><br>* <a href=\"https://web.archive.org/web/20151002164342/http://themindwobbles.wordpress.com/2009/08/22/cat-herding-the-challenges-and-rewards/\">Cat
        herding: the challenges and rewards of managing online science communities</a>
        (the mind wobbles)<br>* <a href=\"https://web.archive.org/web/20151002164342/http://wwmm.ch.cam.ac.uk/blogs/adams/?p=316\">Notes
        From Science Online: Cat Herding</a> (Staudinger's Semantic Molecules)</p><p><em><em>Breakout
        3: Author identity</em>:<em> Creating a new kind of reputation online (Duncan
        Hull, Geoffrey Bilder, Michael Habib, Reynold Guida)</em></em><br>* <a href=\"https://web.archive.org/web/20151002164342/http://themindwobbles.wordpress.com/2009/08/22/breakout-3-author-identity-creating-a-new-kind-of-reputation-online/\">Breakout
        3: author identity \u2013 creating a new kind of reputation online</a> (the
        mind wobbles)</p><p><em><em>Breakout 4: Citizen science</em>: <em>How the
        web enables anyone to be a scientist (Arfon Smith, Mike Peel)</em></em></p><p><em><em>Real-time
        statistics in science (Victor Henning, Richard Grant, Virginia Barbour)</em></em><br>*
        <a href=\"https://web.archive.org/web/20151002164342/http://themindwobbles.wordpress.com/2009/08/22/real-time-statistics-in-science/\">Real-time
        statistics in science</a> (the mind wobbles)<br>* <a href=\"https://web.archive.org/web/20151002164342/http://wwmm.ch.cam.ac.uk/blogs/adams/?p=314\">Notes
        from Science Online \xE2\u20AC\u201C Real time statistics and new impact metrics
        in science</a> (Staudinger's Semantic Molecules)</p><p><em><em>Google Wave:
        Just another ripple or science communication tsunami? (Cameron Neylon, Chris
        Thorpe, Ian Mulvany)</em></em><br>* <a href=\"https://web.archive.org/web/20151002164342/http://themindwobbles.wordpress.com/2009/08/22/google-wave-just-another-ripple-or-science-communication-tsunami/\">Google
        Wave: just another ripple or science communication tsunami</a> (the mind wobbles)<br>*
        <a href=\"https://web.archive.org/web/20151002164342/http://blog.openwetware.org/scienceintheopen/2009/08/23/reflecting-on-a-wave-the-demo-at-science-online-london-2009/\">Reflecting
        on a Wave: The demo at Science Online London 2009</a> (Science in the Open)<br>*
        <a href=\"https://web.archive.org/web/20151002164342/http://blogs.nature.com/wp/nascent/2009/08/riding_a_wave_of_science.html\">Riding
        a Wave of Science</a> (Nascent)<br>* <a href=\"https://web.archive.org/web/20151002164342/http://scienceblogs.com/highlyallochthonous/2009/08/surfing_the_google_wave.php\">Surfing
        the Google Wave</a> (Highly Allochtonous)</p><p><em><em>Far out: Speculations
        on science communication 50 years from now (John Gilbey)</em></em><br>* <a
        href=\"https://web.archive.org/web/20151002164342/http://themindwobbles.wordpress.com/2009/08/22/far-out-speculations-on-science-communication-50-years-from-now/\">Far
        out: speculation on science communication 50 years from now</a> (the mind
        wobbles)<br>* <a href=\"https://web.archive.org/web/20151002164342/http://wwmm.ch.cam.ac.uk/blogs/adams/?p=329\">Notes
        on Science Online \u2013 Science Communication 50 years from now</a> (Staudinger's
        Semantic Molecules)</p><p><em><em>General Posts</em></em><br>* <a href=\"https://web.archive.org/web/20151002164342/http://www.possibilitiesendless.com/?p=52\">Science
        Online London 2009</a> (Endless Possibilities)<br>* <a href=\"https://web.archive.org/web/20151002164342/http://colinsbeautypages.co.uk/science-online-london-2009/\">Science
        Online London 2009</a> (Colin's Beauty Pages)<br>* <a href=\"https://web.archive.org/web/20151002164342/http://network.nature.com/people/eva/blog/2009/08/23/coffee-break\">Coffee
        Break</a> (Expression Pattern)<br>* <a href=\"https://web.archive.org/web/20151002164342/http://www.ethicalpalaeontologist.com/2009/08/science-online-aftermath.html\">Science
        Online \u2013 Aftermath</a> (The Ethical Palaeontologist)<br>* <a href=\"https://web.archive.org/web/20151002164342/http://cotch.net/blog/20090823_2239\">Science
        Online, London '09</a> (Cotch.net)<br>* <a href=\"https://web.archive.org/web/20151002164342/http://scienceblogs.com/highlyallochthonous/2009/08/science_online_-\">Science
        Online \u2013 the London Edition</a><em><em>the</em></em>london_ed.php (Highly
        Allochthonous)<br>* <a href=\"https://web.archive.org/web/20151002164342/http://carmenego.wordpress.com/2009/08/23/science-schmooz-a-thon/\">Science
        Schmooz-a-thon</a> (Carmen Gets Around)<br>* <a href=\"https://web.archive.org/web/20151002164342/http://www.possibilitiesendless.com/?p=54\">Online
        science communication \u2013 a comparison</a> (Endless Possibilities)<br>*
        <a href=\"https://web.archive.org/web/20151002164342/http://www.russet.org.uk/blog/2009/08/science-online-london-2009/\">Science
        Online London 2009</a> (Exercise in Irrelevance)<br>* <a href=\"https://web.archive.org/web/20151002164342/http://www.axiope.com/community/viewtopic.php?f=8&amp;t=1021&amp;start=0\">Science
        Online London 2009 compared to 2008</a> (eCAT community)<br>* <a href=\"https://web.archive.org/web/20151002164342/http://themindwobbles.wordpress.com/2009/08/24/science-online-london-09-thoughts-rather-than-transcript/\">Science
        Online London 09: Thoughts, not Transcript</a> (the mind boggles)<br>* <a
        href=\"https://web.archive.org/web/20151002164342/http://duncan.hull.name/2009/08/24/solo09/\">I
        bet you think this blog is about you, don\xE2\u20AC\u2122t you?</a> (O'Really?)<br>*
        <a href=\"https://web.archive.org/web/20151002164342/http://network.nature.com/people/scurry/blog/2009/08/23/what-a-difference-a-year-makes\">What
        a difference a year makes</a> (Reciprocal space)<br>* <a href=\"https://web.archive.org/web/20151002164342/http://network.nature.com/people/etchevers/blog/2009/08/26/idle-vacation-thoughts-on-science-online-london-2009\">Idle
        vacation thoughts on Science Online London 2009</a> (A Developing Passion)<br>*
        <a href=\"https://web.archive.org/web/20151002164342/http://ukwebfocus.wordpress.com/2009/08/26/the-back-channels-for-the-science-online-2009-conference/\">The
        Back Channels of the Science Online 2009 Conference</a> (UK Web Focus)<br>*
        <a href=\"https://web.archive.org/web/20151002164342/http://scienceoftheinvisible.blogspot.com/2009/08/unpacking-solo09.html\">Unpacking
        Solo09</a> (Science of the Invisible)</p><p>As one of the conference organizers,
        I'm obviously biased as to how to judge the success of the conference. But
        I think that organizing a conference about the online communication of science
        is as much about how to do things, as it is about finding the right session
        topics. As Science Online London is only in its second year (and the sister
        <a href=\"https://web.archive.org/web/20151002164342/http://www.scienceonline09.com/\">ScienceOnline</a>
        in North Carolina in its third year), there are still a lot of things we can
        do better.</p><h3 id=\"what-i-liked\">What I liked</h3><p><em><em>No parallel
        sessions</em></em><br>Although we did have two slots with two parallel sessions
        each, all the other sessions were in the Faraday Theatre. I find that I always
        miss some great sessions in conferences with many parallel sessions. More
        importantly, this format makes sure that everybody goes to the same conference
        and discusses the same things. I like this because it builds a sense of community
        around the conference.</p><p><em><em>No unconference sessions</em></em><br>Deciding
        on the session topics and speakers at the beginning of the conference is a
        concept that worked well for similar events in the past (e.g. <a href=\"https://doi.org/10.53731/r294649-6f79289-8cw30\">SciBarCamp
        Palo Alto</a>, and in part <a href=\"https://web.archive.org/web/20151002164342/http://www.nature.com/natureconferences/sciblog2008/index.html\">Science
        Blogging London 2008</a>). We decided to not use this format, which not only
        made the day of the conference much less stressful for the organizers but
        also allowed us to invite some interesting speakers who otherwise might not
        have come. This format also made it easier to have different topics and speakers
        from last year's conference (only 3 out of the 29 speakers also spoke last
        year).</p><p><em><em>Live streaming of audio and video</em></em><br>We streamed
        audio and video of almost all sessions to <a href=\"https://web.archive.org/web/20151002164342/http://www.scienceonlinelondon.org/second-life.php\">Second
        Life</a>. Exceptions were the session on legal and ethical aspects of blogging
        (which we decided not to record because of the risk that some statements could
        be taken as legal advice), and the breakout sessions (where we could only
        record audio). One speaker (Dave Munger) even gave his presentation through
        Second Life.</p><p>Because the Second Life users could give feedback through
        Second Life, Twitter, or FriendFeed, this was really a virtual conference.
        Live video streaming (using Second Life or other technologies) should really
        become the norm for this kind of conference.</p><p><em><em>A perfect location</em></em><br>The
        Royal Institution was really a perfect place for the conference. You could
        argue about the pink color of the seats, but the <a href=\"https://web.archive.org/web/20151002164342/http://www.rigb.org/contentControl?action=displayContent&amp;id=00000001054\">Faraday
        Theatre</a> has just the right size and a great of history of communicating
        science.</p><h3 id=\"what-i-didn-t-like\">What I didn't like</h3><p><em><em>Not
        enough time in the sessions</em></em><br>We decided to go with 45-minute long
        sessions, and this turned out to be too short. I would have liked to have
        a 30-minute discussion in most sessions (some sessions worked well with shorter
        discussion time, e.g. <em><em>Legal and Ethical Aspects of Science Blogging</em></em>).
        Although there will always be sessions that require a different format, next
        time I would force speakers to limit their introduction to 15 minutes. And
        I would try to make the sessions 60 minutes long.</p><p><em><em>Not enough
        time between sessions</em></em><br>The best part of a conference is often
        the discussions we have between sessions. For this, we should have scheduled
        more time, e.g. by making the coffee breaks 45 minutes long and by having
        a conference dinner at the beginning of the conference. But the <a href=\"https://web.archive.org/web/20151002164342/http://www.scienceonlinelondon.org/blog/2009/07/20/announcing-social-events-for-thursday-friday/\">social
        events on Thursday and Friday</a> and the <a href=\"https://web.archive.org/web/20151002164342/http://network.nature.com/people/UE19877E8/blog/2009/08/06/in-which-we-change-venue-fringefrivolous-blogging-unconference-2009\">FringeFrivolous</a>
        unconference on Friday were not only interesting events but also great for
        networking. Doing a conference on a single day is just too short and I would
        make a repeat conference a two-day event. With more time I would also really
        like to do a brief introduction of every participant (\xC3 \_la <a href=\"https://web.archive.org/web/20151002164342/http://www.nature.com/scifoo/index.html\">SciFoo</a>).</p><p><em><em>Do
        more moderation</em></em><br>Conferences have a tendency to always have the
        same people saying the same things. Discussions are sometimes more about people
        saying something that is dear to their heart rather than asking a question
        or trying to understand the other side. More moderation could help to make
        the discussions more unexpected and productive.</p><p><em><em>That iPhone
        that just didn't stop ringing</em></em><br>Unfortunately, I just couldn't
        pay full attention to the last part of the discussion about real-time statistics.
        Despite <a href=\"https://web.archive.org/web/20151002164342/https://twitter.com/#search?q=%23solo09%20phone\">many
        pleas on Twitter</a>, that iPhone must have been ringing for at least 5 minutes.</p><p><em><em>This
        blog will go on summer vacation between August 27-September 20. The author
        will be in the Southwestern United States and hopes to have little or no internet
        coverage. During that time fellow German science blogger <a href=\"https://web.archive.org/web/20151002164342/http://network.nature.com/people/alexander-knoll/profile\">Alexander
        Knoll</a> will write a few guest posts from the Annual Conference of the German
        <a href=\"https://web.archive.org/web/20151002164342/http://www.gfgenetik.de/eng/tagungen/tagungen.php\">Gesellschaft
        </a></em><a href=\"https://web.archive.org/web/20151002164342/http://www.gfgenetik.de/eng/tagungen/tagungen.php\">f</a>or
        <em><a href=\"https://web.archive.org/web/20151002164342/http://www.gfgenetik.de/eng/tagungen/tagungen.php\">Geneti</a></em><a
        href=\"https://web.archive.org/web/20151002164342/http://www.gfgenetik.de/eng/tagungen/tagungen.php\">c</a>s<em>
        September 16-19.</em></em></p><p><em><em>Update 08/26/09: included more blog
        posts about Science Online London</em></em></p><h3 id=\"references\">References</h3><p>Fenner,
        M. (2009). <em>I was at SciBarCamp Palo Alto</em>. <a href=\"https://doi.org/10.53731/r294649-6f79289-8cw30\">https://doi.org/10.53731/r294649-6f79289-8cw30</a></p><figure
        class=\"kg-card kg-image-card\"><img src=\"https://web.archive.org/web/20151002164342im_/http://www.linkwithin.com/pixel.png\"
        class=\"kg-image\" alt=\"Related Posts Plugin for WordPress, Blogger...\"
        loading=\"lazy\"></figure> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Streamosphere: Interview with Euan Adie
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/streamosphere-interview-with-euan-adie/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw37</id>\n        <published>2009-08-20T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-29T10:29:59.000+00:00</updated>\n\t\t<category
        term=\"Interview\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/DALL-E-2022-08-29-12.29.34---Lucien-Freud-painting-of-a-garden-gnome-with-an-umbrella-interviewing-a-man-in-front-of-London-s-Big-Ben.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/DALL-E-2022-08-29-12.29.34---Lucien-Freud-painting-of-a-garden-gnome-with-an-umbrella-interviewing-a-man-in-front-of-London-s-Big-Ben.png\"></p><p><a
        href=\"https://web.archive.org/web/20151003123050/http://network.nature.com/people/euan/profile\">Euan
        Adie</a> in June announced the <a href=\"https://web.archive.org/web/20151003123050/http://streamosphere.nature.com/\">Streamosphere</a>
        service on the Nascent blog: <a href=\"https://web.archive.org/web/20151003123050/http://blogs.nature.com/wp/nascent/2009/06/welcome_to_the_streamosphere.html\">Welcome
        to the Streamosphere</a>. His simple explanation of what Streamosphere does:
        </p><blockquote><em><em>Streamosphere lets you track scientific discussion
        on the web, in real time.</em></em> </blockquote><p>The Nascent blog post
        explains Streamosphere in more detail, <a href=\"https://web.archive.org/web/20151003123050/http://blogs.nature.com/wp/nascent/2009/07/streamosphere_update.html\">in
        another post from July</a> Euan talks about some updates to the service. I've
        asked Euan a few questions to learn more about Streamosphere.</p><h3 id=\"1-can-you-explain-what-streamosphere-is-and-does\">1.
        Can you explain what Streamosphere is and does?</h3><p>Streamosphere is an
        aggregator of scientific activity on the web. It tracks what scientists are
        talking about on Twitter, wikis, blogs, social bookmarking services, forums
        and other web 2.0 services.</p><h3 id=\"2-why-do-we-need-such-a-tool\">2.
        Why do we need such a tool?</h3><p>I think scientific attention (any time
        you read an abstract, cite a paper or search for a particular gene in a database
        you're giving it attention) is valuable to aggregate. Traditionally scientists
        and publishers have measured attention with citation counts and to a lesser
        extent downloads but there's lots of other online activity \u2013 like blogging,
        commenting and bookmarking \u2013 that could be used in new metrics.</p><p>At
        the moment the relevant activity is</p><ul><li><em><em>distributed</em></em>
        people could be talking about a paper I'm interested in on Friendfeed, blogs,
        forums\u2026</li><li><em><em>noisy</em></em> there are tens of thousands of
        research scientists on Twitter but most of the time they're posting pictures
        of lolcats</li><li><em><em>lacking provenance</em></em> it's not easy to know
        whose opinions to trust</li></ul><p>Streamosphere attempts to tackle these
        issues by aggregating activity from lots of different sites, removing spam,
        providing filters and disambiguating users on different services. If I'm interested
        in what other scientists think about a particular paper then I can search
        for it on Streamosphere. If I want to keep track of everything related to
        a particular field then I can do that too.</p><h3 id=\"3-what-is-the-difference-between-streamosphere-postgenomic-and-nature-com-blogs\">3.
        What is the difference between Streamosphere, Postgenomic and Nature.com Blogs?</h3><p><a
        href=\"https://web.archive.org/web/20151003123050/http://www.postgenomic.com/\">Postgenomic</a>
        and <a href=\"https://web.archive.org/web/20151003123050/http://blogs.nature.com/\">Nature.com
        Blogs</a> only aggregate and analyze blog posts. Streamosphere gets a feed
        from Nature.com Blogs but covers other services too.</p><h3 id=\"4-what-is-the-difference-to-other-aggregators-such-as-friendfeed\">4.
        What is the difference to other aggregators such as FriendFeed?</h3><p>The
        main difference is that you can't interact with content on Streamosphere \u2013
        if you want to comment on a blog post or paper you have to visit it and leave
        your comment there.</p><p>Another would be that you don't follow people on
        Streamosphere, you'd follow topics.</p><h3 id=\"5-how-do-you-decide-whether-something-or-someone-is-related-to-science\">5.
        How do you decide whether something or someone is related to science?</h3><p>If
        you bookmark or discuss things with <a href=\"https://web.archive.org/web/20151003123050/http://www.doi.org/\">DOIs</a>,
        <a href=\"https://web.archive.org/web/20151003123050/http://arxiv.org/help/faq/whynostamp\">arxiv
        IDs</a> or <a href=\"https://web.archive.org/web/20151003123050/http://blogs.library.ucla.edu/biomedical/2008/09/02/convert-a-pubmed-id-to-a-pubmedcentral-id/\">PubMed
        IDs</a> then you're added to the database. At this point any of your activity
        that doesn't look scholarly doesn't get aggregated.</p><p>After that it's
        down to manual checks and whether or not you're following / being followed
        by other people in Streamosphere.</p><h3 id=\"6-can-we-follow-streamosphere-via-rss-or-twitter\">6.
        Can we follow Streamosphere via RSS or Twitter?</h3><p>Not yet! I'm hoping
        to open up the data in Streamosphere via a public API that can output RSS
        and other formats but don't want to do it before the system is stable. There
        are also questions surrounding how some messages can be republished. I'm not
        sure if Streamosphere's API output can include the contents of any tweets,
        for example, as to receive streaming updates from Twitter you need to sign
        an agreement saying that you won't distribute them outside of your application
        (can't remember the exact wording).</p><p>The best way to track updates about
        Streamosphere is to watch <a href=\"https://web.archive.org/web/20151003123050/http://blogs.nature.com/wp/nascent/\">Nascent</a>.</p><h3
        id=\"7-what-are-your-responsibilities-at-nature-com\">7. What are your responsibilities
        at Nature.com?</h3><p>I'm a product manager in the web publishing group. Generally
        speaking the areas I'm responsible for are aggregation, the Nature.com Blogs
        homepage and mobile platforms.</p><h3 id=\"8-what-did-you-do-before-working-for-nature-com\">8.
        What did you do before working for Nature.com?</h3><p>I was a bioinformatician
        at the University of Edinburgh in the medical genetics unit, working on candidate
        disease gene prioritization.</p><p>Before that I'd co-founded and worked on
        a start-up that tried to extract entities and sentiment from forum posts.
        We brought in very little revenue for eighteen months, ran out of funding
        and went bust in 2001. It was an education\u2026. \U0001F609</p><h3 id=\"9-do-you-want-to-talk-about-future-plans-for-streamosphere\">9.
        Do you want to talk about future plans for Streamosphere?</h3><p>Sure \u2013
        the main thing I'm looking forward to is personalization \u2013 being able
        to log in and tell the system what you're interested in. From then on whenever
        you visit the site particularly relevant items will be highlighted.</p><p>The
        API is another key development\u2026 I'm really interested in seeing what
        other people can do with the data.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ PLoS One: Interview with Peter Binfield
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/plos-one-interview-with-peter-binfield/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw36</id>\n        <published>2009-08-15T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-16T16:28:21.000+00:00</updated>\n\t\t<category
        term=\"Interview\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/maxresdefault.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/maxresdefault.jpeg\"></p><p>At
        <a href=\"https://web.archive.org/web/20151002113207/http://network.nature.com/people/mfenner/blog/2009/07/10/i-was-at-scibarcamp-palo-alto\">SciBar
        Camp Palo Alto last month</a>, Peter Binfield from <a href=\"https://web.archive.org/web/20151002113207/http://www.plosone.org/\">PLoS
        ONE</a> gave a very interesting presentation on <a href=\"https://web.archive.org/web/20151002113207/http://friendfeed.com/scibarcamp/3577ed2e/peter-binfield-article-level-metric-from-plos\">Article-level
        metrics from the PLoS perspective</a>. Particularly interesting was his announcement
        that <em><em>PLoS</em></em> journals will provide usage data (HTML pageviews,
        PDF and XML downloads) for all their articles in September. Usage data, like
        <a href=\"https://web.archive.org/web/20151002113207/http://dx.doi.org/10.1371/journal.pone.0006022\">all
        measures of scientific impact</a>, have their problems, but they are a welcome
        addition to citation-based metrics.</p><p>I\u2019ve interviewed Pete to ask
        him not only about article-level metrics, but also about the publishing model
        of <em><em>PLoS ONE</em></em> and how these two relate to each other.</p><h3
        id=\"1-can-you-describe-what-plos-one-is-and-does\">1. Can you describe what
        PLoS ONE is and does?</h3><p><a href=\"https://web.archive.org/web/20151002113207/http://www.plosone.org/\">PLoS
        ONE</a> is an Open Access, scholarly, peer reviewed journal for all of science.
        We will be three years old in December 2009, but already we are the <a href=\"https://web.archive.org/web/20151002113207/http://poeticeconomics.blogspot.com/2009/07/dramatic-growth-of-plos-one-soon-to-be.html\">third
        largest journal (of any type) in the world</a>, publishing approximately 4,600
        articles in 2009 alone and almost doubling in volume every year. We are online
        only (publishing in HTML, XML and PDF) and we publish daily (about 20 articles
        a day at present). In my view <em><em>PLoS ONE</em></em> is the most dynamic,
        innovative and exciting journal in the world, and I am proud to work on it.</p><p>In
        many ways <em><em>PLoS ONE</em></em> operates like any other journal however
        it diverges in several important respects. The founding principle of <em><em>PLoS
        ONE</em></em> was that there are certain aspects of publishing which are best
        conducted pre-publication and certain aspects which are best conducted post-publication.
        The advent of online publishing has allowed us to take a step back and re-evaluate
        these aspects of how we publish research, without the burden of centuries
        of tradition. In this way, we have been able to experiment with new ways of
        doing things which may result in dramatic improvements in the entire process
        of scholarly publication.</p><p>The most important thing which has come out
        of this premise is that unlike almost every other journal in the world, we
        make no judgment call whatsoever on the \u201Cimpact\u201D or \u201Csignificance\u201D
        or \u201Cinterest level\u201D of any submission. What this means is that if
        an article appropriately reports on well-conducted science, and if it passes
        our peer review process (which determines whether it deserves to join the
        scientific literature) then we will publish it. In this way, no author should
        ever receive the message that their article is scientifically sound but \u201Cnot
        interesting enough\u201D for our journal, or that their article is \u201Conly
        suited to a specialized audience\u201D. As a result, we short circuit the
        vicious cycle of submit to a \u201Ctop tier\u201D journal; get reviewed; get
        rejected; submit to the next journal down the list; repeat until accepted
        and we are therefore able to place good science into the public domain as
        promptly as possible, with the minimum of burden on the academic community.</p><p>The
        most recent example of the way in which we separate pre-publication activity
        from post-publication activity is with the development of our <a href=\"https://web.archive.org/web/20151002113207/http://everyone.plos.org/tag/article-level-metrics/\">Article-Level
        Metrics program</a>. <em><em>Article-level metrics</em></em> start from the
        assumption that the best way to measure the worth of an article is to look
        at the actual article itself (and not the journal it happens to have been
        published in). Following from this, it seems obvious that the best way to
        evaluate any article is to make use of the collective opinion of all experts
        in the field (and not a small number of peer reviewers, or a small number
        of people who ultimately go on to cite the article). An evaluation of this
        type (which requires that people actually read, and then act in a variety
        of ways, on the article) can only be done after the article is published (and
        not before, as happens when a journal rejects a paper because it thinks it
        is not \u201Cimpactful\u201D enough). Therefore, our development of new tools
        to facilitate the post-publication evaluation of individual articles is a
        great example of us separating out what is most appropriately conducted pre-publication
        vs post-publication.</p><p>I have gone into some detail on these issues in
        a recent peer reviewed paper \u2013 <a href=\"https://web.archive.org/web/20151002113207/http://conferences.aepic.it/index.php/elpub/elpub2009/paper/view/114\">PLoS
        One: background, future development, and article-level metrics</a> and I would
        also recommend Shirley Wu\u2019s excellent <a href=\"https://web.archive.org/web/20151002113207/http://shirleywho.wordpress.com/2009/08/06/the-evolution-of-scientific-impact/\">recent
        blog post on this topic</a>.</p><h3 id=\"2-can-you-describe-what-ambra-topaz-is-and-does\">2.
        Can you describe what Ambra/Topaz is and does?</h3><p>Basically Ambra is our
        publishing platform, which runs on top of the <a href=\"https://web.archive.org/web/20151002113207/http://everyone.plos.org/2009/05/13/all-plos-titles-now-on-the-same-publishing-platform/\">Topaz</a>
        infrastructure. For the full technical detail, the best information is found
        <a href=\"https://web.archive.org/web/20151002113207/http://ambraproject.org/\">here</a>.</p><h3
        id=\"3-can-you-talk-a-little-bit-more-about-the-post-publication-features-of-ambra-topaz\">3.
        Can you talk a little bit more about the post-publication features of Ambra/Topaz?</h3><p>Once
        an article is published, our platform allows users to leave feedback directly
        on the article. We were among the first journals to allow this, and we remain
        somewhat unique in this respect, although the concept is gaining broader acceptance
        and similar functionality is starting to appear at other publishers sites.
        Specifically, we allow users to leave a Note inline with a specific selection
        of text; or they can leave a general Comment on the entire article; or they
        can Star rate the article (on a 5 point scale in 3 categories). Comments and
        Notes form discussion threads, and users can then engage in debate on the
        points raised.</p><p>Users may not be anonymous, they must follow our guidelines
        for civilized academic debate, and when leaving feedback they are <a href=\"https://web.archive.org/web/20151002113207/http://www.plosone.org/static/commentGuidelines.action\">asked
        to declare any competing interests</a>. I want to make it clear that the post-publication
        functionality that we provide is not intended to provide post-publication
        peer review \u2013 it is post-publication discourse and feedback. All <em><em>PLoS</em></em>
        titles now share this same functionality.</p><h3 id=\"4-are-other-publishers-besides-plos-using-the-ambra-topaz-platform\">4.
        Are other publishers besides PLoS using the Ambra/Topaz platform?</h3><p>None
        that we are aware of although the NIH has an internal project. But Topaz is
        open source, so please contact us if you want to use it!</p><h3 id=\"5-what-article-level-metrics-does-plos-one-provide\">5.
        What article-level metrics does PLoS ONE provide?</h3><p>As of today (August
        2009), on every article, in every <em><em>PLoS</em></em> title we provide:</p><ul><li>Number
        of citations (as measured by <a href=\"https://web.archive.org/web/20151002113207/http://www.scopus.com/\">Scopus</a>
        and <a href=\"https://web.archive.org/web/20151002113207/http://www.pubmedcentral.nih.gov/\">PubMedCentral</a>)</li><li>Number
        of social bookmarks (as recorded by <a href=\"https://web.archive.org/web/20151002113207/http://www.citeulike.org/\">CiteULike</a>
        and <a href=\"https://web.archive.org/web/20151002113207/http://www.connotea.org/\">Connotea</a>)</li><li>Number
        of star ratings left by users on our system</li><li>Notes, Comments and any
        replies, as left by users of our system</li><li>Number of blog posts written
        about the article (as counted by the blog aggregators <a href=\"https://web.archive.org/web/20151002113207/http://www.postgenomic.com/\">Postgenomic</a>,
        <a href=\"https://web.archive.org/web/20151002113207/http://blogs.nature.com/\">Nature
        Blogs</a> and <a href=\"https://web.archive.org/web/20151002113207/http://www.bloglines.com/\">Bloglines</a>)</li><li>Specific
        trackbacks to the article from any web page using our trackback protocol</li></ul><p>In
        September we will be adding additional citation data as measured by <a href=\"https://web.archive.org/web/20151002113207/http://www.crossref.org/\">CrossRef</a>
        and, most significantly, the online usage for each article (going back to
        the original publication date and reported on a monthly basis, broken down
        by HTML pageviews, PDF downloads, and XML downloads). This development in
        particular is very exciting \u2013 no other publisher has made this data available
        for such a large corpus of articles.</p><p>After this, the next data source
        we will add will be blog coverage as aggregated by <a href=\"https://web.archive.org/web/20151002113207/http://researchblogging.org/\">ResearchBlogging.org</a>,
        and in subsequent months we will be adding other metrics as and when we can
        identify high quality sources which meet our criteria.</p><p><em><em>Article-level
        metrics</em></em> are a major development for <em><em>PLoS</em></em> and we
        believe that we are unique in the publishing industry with the transparent
        provision of such a range of <em><em>article-level metrics</em></em>. No other
        publisher provides as much (or any, in most cases) article-level data in such
        a comprehensive and open manner. It is our belief that once we have demonstrated
        what is possible, as well as the power of these metrics, the academic community
        will quickly begin to expect, and demand, this level of information from all
        journals. As a result the very nature of research reporting and evaluation
        will be improved as a result.</p><h3 id=\"6-how-do-article-level-metrics-fit-in-with-how-plos-one-conducts-peer-review\">6.
        How do article-level metrics fit in with how PLoS ONE conducts peer review</h3><p>We
        peer review all submissions for their <a href=\"https://web.archive.org/web/20151002113207/http://www.plosone.org/static/review.action\">scientific
        content</a>, but we do NOT peer review them in order to determine whether
        they are high or low impact (or interest or significance or relevance etc).
        Therefore, from the reader\u2019s point of view, when you encounter a <em><em>PLoS
        ONE</em></em> article you do not necessarily know how impactful, or interesting,
        or significant, or relevant that article might be (without actually reading
        it!). In the traditional model, you would have some indication as to the likely
        importance of an article by a knowledge of the journal in which it was published
        in (although we argue that this way of determining quality is actually <a
        href=\"https://web.archive.org/web/20151002113207/http://www.plos.org/cms/node/478\">one
        of the worst methods you could use</a>), however in <em><em>PLoS ONE</em></em>
        all you know is that the article is scientifically and methodologically sound
        (which are the only questions that our peer review process asks). Therefore,
        <em><em>article-level metrics</em></em> provide the reader with an indication
        as to the worth of an article once it is published. Until today, people have
        effectively said: this article was published in journal X, therefore knowing
        this one fact, I now know that the article is excellent/good/average/poor.
        I think that any sane person who considered that statement would realize how
        unscientific it was. With the advent of <em><em>article-level metrics</em></em>,
        a reader can now say \u201Cthis article was published as part of the scientific
        literature, it is irrelevant which journal it was published in as I have now
        been given a variety of information about the article itself which will help
        me decide whether the article is excellent / good / average / poor for my
        own purposes\u201D.</p><p>Therefore, <em><em>article-level metrics</em></em>
        do not supplant peer review and they also do not represent post-publication
        peer review. However they do provide the reader with new and valuable ways
        to do the post-publication evaluation and filtering of journal content.</p><h3
        id=\"7-what-are-plos-one-subject-areas-or-portals\">7. What are PLoS ONE subject
        areas or portals?</h3><p>We actually have several ways to \u2018parse\u2019
        our content by <a href=\"https://web.archive.org/web/20151002113207/http://www.plosone.org/static/browse.action\">topic</a>:
        All content is assigned to one or more of our 52 topic areas (for example
        Pathology or Oncology). These topics are assigned by the authors themselves
        and an article can appear in more than one topic. Having made that classification,
        readers can then <a href=\"https://web.archive.org/web/20151002113207/http://www.plosone.org/article/browse.action\">browse
        the topics</a> or subscribe to <a href=\"https://web.archive.org/web/20151002113207/http://www.plosone.org/static/rssFeeds.action\">an
        RSS feed per topic</a>.</p><p>However, we appreciate that this is not a very
        flexible way to find content that doesn\u2019t easily fall under our existing
        taxonomy structure. Therefore, we also have the ability to aggregate our articles
        into <a href=\"https://web.archive.org/web/20151002113207/http://www.plosone.org/article/browseVolume.action\">Collections</a>.
        A Collection is literally just an aggregation tool (post-publication) \u2013
        articles are still published as part of the normal run of the journal, but
        can then be assigned to join a Collection where they will also appear as part
        of a collection of related articles. For example, right now we have a very
        popular <a href=\"https://web.archive.org/web/20151002113207/http://www.plosone.org/article/browseIssue.action?issue=info%3Adoi%2F10.1371%2Fissue.pone.c01.i02\">Paleontology
        Collection</a>. As we publish new Paleontology articles they get added to
        this Collection to form a single location for all relevant articles in the
        field. This Collection functionality can also be used for the output of a
        single research effort, and an example of this is our <a href=\"https://web.archive.org/web/20151002113207/http://www.plosone.org/article/browseIssue.action?issue=info%3Adoi%2F10.1371%2Fissue.pone.c01.i01\">Stress-Induced
        Depression and Comorbidities Collection</a> which effectively replicated a
        \u201CSpecial Issue\u201D of a journal, and contained all the articles we
        published as written by the EUMOOD Research Consortia. Collections can be
        static, or can build up over time, and articles can appear in multiple Collections
        \u2013 as such they represent a very flexible way to re-present our content.</p><p>Then
        we have <em><em>PLoS</em></em> Hubs, which are under development right now.
        We see a Hub as a way to aggregate journal articles (along with other types
        of content) about a given topic into a single location. Once aggregated, we
        can then provide various community specific tools and services around this
        content. A Hub should not be thought of as a portal or an overlay journal
        \u2013 the distinguishing feature will be that a Hub will physically contain
        (and not just link out to) as much content as possible. Clearly, the easiest
        way to achieve this is by making the content Open Access, and so we also see
        Hubs as an opportunity to demonstrate the power of an Open Access copyright
        license. At the moment there is only one Hub (the <a href=\"https://web.archive.org/web/20151002113207/http://clinicaltrials.ploshubs.org/home.action\">PLoS
        Clinical Trials Hub</a>) but this is a rather old implementation of the concept
        and only contains <em><em>PLoS</em></em> content \u2013 therefore we are proactively
        working on a new release which will include more of the functionality described
        above.</p><p>Future developments to our platform will involve the ability
        to tag articles (perhaps by some combination of curated and user generated
        tags) which will provide yet another way to dynamically aggregate the content.</p><h3
        id=\"8-how-has-the-ambra-topaz-platform-handled-the-enormous-growth-of-plos-one\">8.
        How has the Ambra/Topaz platform handled the enormous growth of PLoS ONE?</h3><p>Great!
        We had a few architecture issues in the past due to the bleeding edge nature
        of the platform, but all seven of our journals have now migrated to the same
        platform and no substantial issues have come up since the we migrated our
        Community Journals (back in early 2008).</p><h3 id=\"9-what-are-your-responsibilities-at-plos\">9.
        What are your responsibilities at PLoS?</h3><p>I am the Managing Editor of
        <em><em>PLoS ONE</em></em> (one of seven titles at <em><em>PLoS</em></em>).
        Although this position is an Editorial one, it is the position which is ultimately
        responsible for everything associated with the journal. By this I mean that
        although other departments may not report into me, I am ultimately responsible
        for the marketing, production, operations, web etc of the journal. If we have
        a problem with any aspect of the journal, it is me that makes sure it gets
        solved!</p><h3 id=\"10-what-did-you-do-before-starting-to-work-at-plos\">10.
        What did you do before starting to work at PLoS?</h3><p>Well, I am a physicist
        from way back \u2013 I have a first degree in Physics with Astrophysics and
        a PhD in Underwater Optical Holography (which I always tell people sounds
        a lot more interesting than it was!). After my PhD I realized I wasn\u2019t
        interested in a life in academia and so I moved into Academic Publishing,
        which allowed me to stay in touch with academia and also to interact with
        leading researchers conducting the latest research. I started out at Institute
        of Physics Publishing, in Bristol UK, doing book acquisitions, then I moved
        to Holland to work for Kluwer Academic Publishers (KAP) to start up a reference
        work program for them. Via a series of moves I ended up running the KAP Earth,
        Environmental and Plant Sciences division \u2013 a large portfolio of books,
        reference works and journals in those areas. Around the time that KAP merged
        with Springer I moved into Business Development for a year or so, which was
        an interesting period working on Springer\u2019s <a href=\"https://web.archive.org/web/20151002113207/http://www.springer.com/open+access/open+choice\">Open
        Choice</a> program, online reference works and journal acquisitions among
        others. Then I left Springer, and also Holland, to move to California (my
        wife is from San Diego) where I worked for SAGE Publications, just North of
        LA, for 3 years. There I ran the SAGE US Journals division, which was made
        up of some 200 or so journals, mostly in the Social Sciences. In that position
        a large part of the job involved bidding on society titles, to publish them
        under contract. And then, finally, in March 2008 I moved to San Francisco,
        to work for <em><em>PLoS</em></em> and run <em><em>PLoS ONE</em></em>.</p><h3
        id=\"11-do-you-want-to-talk-about-future-plans-for-ambra-topaz\">11. Do you
        want to talk about future plans for Ambra/Topaz?</h3><p>The list of upcoming
        projects includes:</p><ul><li>More article-level metrics development</li><li>RDFa
        implementation</li><li>Automatic article relationships</li><li>Semantic enhancement</li><li>REST-based
        API</li><li>The ingest and publication of many types of content / data (structured
        and unstructured)</li><li>Tags</li><li>Enhanced search and browse functionality</li><li>A
        new process to submit articles directly to PubMed Central and other external
        repositories</li><li>Direct access to our underlying triple store (sparql
        endpoint, RDFa)</li></ul> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Recipe: Distributing papers for a journal
        club ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/recipe-distributing-papers-for-a-journal-club/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw35</id>\n        <published>2009-08-08T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-13T15:18:00.000+00:00</updated>\n\t\t<category
        term=\"Science Hack\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><h3 id=\"problem\">Problem</h3><p>You
        want to distribute papers for a regular journal club in your department.</p><h3
        id=\"solution\">Solution</h3><p>Create a group for your journal club in <a
        href=\"https://web.archive.org/web/20150922174148/http://www.friendfeed.com/\">FriendFeed</a>.
        You can create a either a private group, where only group member can read
        and post messages, or a public group that is open to everyone. Then invite
        all regular participants of your journal club to <em><em>FriendFeed</em></em>
        and make them join the group.</p><p>Announce the papers that you want to discuss
        in the journal club via a <em><em>FriendFeed</em></em> message. For this go
        to the webpage for the paper you want to discuss (e.g. <a href=\"https://web.archive.org/web/20150922174148/http://www.nature.com/nature/journal/v460/n7256/full/nature08237.html\">this
        paper</a>) and then use the <a href=\"https://web.archive.org/web/20150922174148/http://friendfeed.com/share/bookmarklet\">FriendFeed
        bookmarklet</a> to announce the paper (and additional information such as
        the date of the journal club) in the <em><em>FriendFeed</em></em> group. If
        the copyright of the paper allows this, you could also post the fulltext PDF
        of the paper to the <em><em>FriendFeed</em></em> group.</p><p>Use <em><em>FriendFeed</em></em>
        comments to capture the discussion about the paper in the journal club. The
        comments can also contain links to other relevant papers and the slides you
        may have prepaped for the journal club. This is helpful for those unable to
        attend the journal club in person, or to look back at the journal club a few
        months later.</p><p><a href=\"https://web.archive.org/web/20150922174148/http://network.nature.com/forums\">Nature
        Network forums</a>, <a href=\"https://web.archive.org/web/20150922174148/http://www.citeulike.org/\">CiteULike</a>,
        <a href=\"https://web.archive.org/web/20150922174148/http://www.labmeeting.com/\">Labmeeting</a>
        and <a href=\"https://web.archive.org/web/20150922174148/http://blogs.plos.org/mfenner/2009/08/08/recipe_distributing_papers_for_a_journal_club/http//www.basecamphq.com\">Basecamp</a>
        (and probably some other tools) offer similar functionality, so use the service
        you are most comfortable with. Of the tools mentioned, <em><em>FriendFeed</em></em>
        for me is the easiest to set up and use.</p><h3 id=\"discussion\">Discussion</h3><p>Email
        is not a good solution for regularly sending around large files. And discussions
        among a larger group of people (i.e. all members of a journal club) are difficult
        to follow via email. <a href=\"https://web.archive.org/web/20150922174148/http://wave.google.com/\">Google
        Wave</a> is a good alternative without these limitations, but is not yet publicly
        available.</p><p>A <a href=\"https://web.archive.org/web/20150922174148/http://openwetware.org/wiki/Journal_Club\">Wiki</a>
        or <a href=\"https://web.archive.org/web/20150922174148/http://blogs.nature.com/nature/journalclub/\">blog</a>
        could also be used to organize a journal club, but requires a larger effort
        to set up and maintain.</p><p>Many reference managers allow their users to
        create private groups for sharing references. But in order to work as a tool
        for a journal club, we also need messages/comments. Not only to discuss the
        paper, but simply to provide the date and presenter for the journal club or
        other organisational information. But I wouldn't be surprised if more reference
        managers besides <em><em>CiteULike</em></em> add these features in the future.</p><p>If
        all journal club papers should automatically be stored in a reference manager,
        use either <em><em>CiteULike</em></em> or put the papers for the journal club
        first into the reference manager and then export them via RSS feed into <em><em>FriendFeed</em></em>.
        This step can be automated if you create a group/folder for the journal club
        in your reference manager.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Bibliographic Management meets Web 2.0 ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/bibliographic-management-meets-web-2-0/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw34</id>\n        <published>2009-08-01T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-19T08:58:11.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/3774951723_0b9e697677.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/3774951723_0b9e697677.jpeg\"></p><p>Regular
        readers of this blog know that I often talk about bibliographic management
        tools (most recently <a href=\"https://blog.front-matter.io/posts/what-is-the-right-reference-manager-for-you\">here</a>
        and <a href=\"https://blog.front-matter.io/posts/reference-manager-overview\">here</a>),
        and it was probably for this reason that I was invited to an interesting full-day
        workshop last week at the <a href=\"https://web.archive.org/web/20150908064949/http://www.royalfree.nhs.uk/\">Royal
        Free Hospital Medical Library</a> in London: <em><em>Bibliographic Management
        meets Web 2.0</em></em>. The event was organized by science librarians <a
        href=\"https://web.archive.org/web/20150908064949/http://network.nature.com/people/franknorman/profile\">Frank
        Norman</a>, <a href=\"https://web.archive.org/web/20150908064949/http://network.nature.com/people/UB5280986/profile\">Nathalie
        Cornee</a> and <a href=\"https://web.archive.org/web/20150908064949/http://network.nature.com/people/U8136B832/profile\">Betsy
        Anagnostelis</a>, and was attended by about 20 science librarians. We had
        demos of the following software:</p><ul><li><a href=\"https://endnote.com/\">EndnoteWeb</a>,
        demo by Stephanie Marshall</li><li><a href=\"https://web.archive.org/web/20150908064949/http://www.refworks.com/\">RefWorks</a>,
        demo by Aaron Maierhofer</li><li><a href=\"https://en.wikipedia.org/wiki/Connotea\">Connotea</a>,
        demo by Grace Barnes</li><li><a href=\"https://en.wikipedia.org/wiki/CiteULike\">CiteULike</a>,
        demo by Kevin Emamy</li><li><a href=\"https://www.zotero.org/\">Zotero</a>,
        demo by Rintze Zelle</li><li><a href=\"https://www.mendeley.com/\">Mendeley</a>,
        demo by Victor Henning and Jan Reichelt</li></ul><p>This is a fairly complete
        list of bibliographic software with Web 2.0 features. Missing are some tools
        with similar features, as there simply wasn't enough time and money to invite
        them all (e.g. <a href=\"https://web.archive.org/web/20150908064949/http://www.2collab.com/\">2collab</a>
        and <a href=\"https://web.archive.org/web/20150908064949/http://www.labmeeting.com/\">Labmeeting</a>),
        several popular programs without these features (<a href=\"https://web.archive.org/web/20150908064949/http://www.refman.com/\">Reference
        Manager</a>, <a href=\"https://web.archive.org/web/20150908064949/http://www.citavi.com/\">Citavi</a>
        and <a href=\"https://www.papersapp.com/\">Papers</a>), and <a href=\"https://web.archive.org/web/20150908064949/http://jabref.sourceforge.net/\">JabRef</a>
        and similar tools for <a href=\"https://web.archive.org/web/20150908064949/http://www.bibtex.org/\">BibTeX</a>
        files used by LaTeX.</p><p>I gave a brief introduction of what features I
        would look for in a reference manager today (available on <a href=\"https://web.archive.org/web/20150908064949/http://www.slideshare.net/mfenner/which-reference-manager\">slideshare</a>).
        The six presenters then took up a challenge (Word file <a href=\"https://web.archive.org/web/20150908064949/http://friendfeed-media.com/f9221d4c733652d64845e3dc6e0c17eaea9a05a2\">here</a>)
        that was given to them the week before. We used a simplified version of a
        set of tasks (find reference, put citation into Word document, etc.) originally
        developed for <a href=\"https://web.archive.org/web/20150908064949/http://citefest.pbworks.com/\">CiteFest</a>
        at Northwestern University. Every participant was sitting in front of a computer
        and follow along with the tasks (the technical staff at the Royal Free did
        a marvelous job installing the software and bookmarklets on all computers
        before the workshop). The demos were nicely captured in the <a href=\"https://web.archive.org/web/20150908064949/http://friendfeed.com/bibman2\">FriendFeed
        room</a> we have set up for the workshop, so you can follow the details of
        the sessions there (the room also has some excellent links to other resources).</p><p>In
        the discussion at the end we all felt that all reference managers used that
        day were up to the challenge (<em><em>Connotea</em></em> and <em><em>CiteULike</em></em>
        couldn't put references into a Word document, but managed the rest of the
        tasks perfectly), and we decided not to declare a winner. We also felt that
        the market is developing so fast, that a feature comparison looked very different
        12 months ago (e.g. <em><em>Mendeley</em></em> just launched, no Web version
        of <em><em>Zotero</em></em>), and will again look very different 12 months
        from today. Most librarians in the room therefore felt that they probably
        have to support most of these tools at their institutions. We briefly talked
        about the cost of these tools (of the tools that were demoed, only <em><em>Endnoteweb</em></em>
        and <em><em>Refworks</em></em> are commercial). This might be an issue when
        licenses have to be renewed. I've set up a <a href=\"https://web.archive.org/web/20150908064949/http://network.nature.com/people/mfenner/blog/2009/03/15/reference-manager-overview\">reference
        manager feature comparison chart</a> a few months ago, and have updated this
        chart after the workshop.</p><p>One feature I really like in <em><em>Papers</em></em>
        is a full-text search of the PDF files in your library, which I think is a
        much easier way to find information than tagging (and David Crotty agrees
        with me: <a href=\"https://web.archive.org/web/20150908064949/http://www.cshblogs.org/cshprotocols/2009/02/23/why-article-tagging-doesnt-work/\">Why
        article tagging doesn't work</a>). I was therefore happy to see that <em><em>Zotero</em></em>,
        <em><em>Mendeley</em></em>, <em><em>CiteULike,</em></em> and <em><em>Refworks</em></em>
        all support this feature, something I have overlooked before. Full-text search
        is one more reason that online reference managers should be able to store
        PDF files. Another reason is that several people working on the same research
        project shouldn't all have to go out and download the full-text files themselves
        \u2013 or even worse, email them to each other. This sharing is not only an
        important features of Web 2.0 bibliographic tools, but is obviously also an
        area of potential problems with copyright (for papers that are not Open Access).
        <em><em>CiteULike</em></em>, <em><em>Mendeley</em></em> and <em><em>Refworks</em></em>
        all try to avoid these kinds of issues by allowing sharing of references and
        PDF files in private groups with a limited number of users.</p><p>It was interesting
        to see that the tools use very different approaches to integrate with the
        Web. <em><em>Connotea</em></em>, <em><em>CiteUlike</em></em> and <em><em>Refworks</em></em>
        are Web-based tools (the <a href=\"https://web.archive.org/web/20150908064949/http://www.refworks.com/refworks/WNCDownload.asp\">Refworks
        Write-N-Cite Windows module</a> can download the reference database for read-only
        offline use), whereas <em><em>Zotero</em></em>, <em><em>Mendeley</em></em>
        and <em><em>Endnote</em></em> synchronize between a desktop version and web
        version. I'm really torn between these two approaches. Web-only reduces the
        cost of development and maintenance (no need to develop separate versions
        for Web/Windows/Mac/Linux, users don't have to install new versions). Desktop/Web
        allows offline use users always have a copy of their data on their computer.
        There is probably no right answer to this, email is another example where
        both approaches are very successful.</p><p>Only after the meeting did I realize
        another interesting difference between the various tools. They all have different
        business models behind them: <em><em>Endnoteweb</em></em>: (mostly) single-user
        licenses, <em><em>Refworks</em></em>: site licenses, <em><em>Connotea</em></em>:
        owned by a publisher, <em><em>CiteUlike</em></em>: independent with support
        from a publisher, <em><em>Zotero</em></em>: Open Source and <em><em>Mendeley</em></em>:
        Web 2.0 company that plans free and paid services. This might actually be
        a deciding factor in determining which of these tools will be the most successful
        in the long-term future.</p><p>But in the end, the similarities far outweigh
        the differences between these tools. We didn't have time left to talk more
        about this, but for Bibliographic Management to move to Web 2.0, it's not
        really just about technology, but rather mostly about the users. We had an
        interesting discussion about that topic a few weeks ago (<a href=\"https://blog.front-matter.io/posts/how-to-close-the-digital-divide-among-scientists\">How
        to close the digital divide among scientists</a>). I believe that ultimately
        your collection of references should sit in a database that is accessible
        from the web. Some references you want to share with everybody (e.g. via tools
        like FriendFeed), and that includes your own publications. And some references
        you want to share with private groups of people, e.g. people in your lab or
        when coauthoring a paper. All the tools presented in the workshop allow you
        to do that.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ How does the article of the future look
        like? ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/how-does-the-article-of-the-future-look-like/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw33</id>\n        <published>2009-07-26T00:00:00.000+00:00</published>\n\t\t<updated>2023-07-27T15:48:49.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Last year <em><em>Elsevier</em></em>
        started the <a href=\"https://web.archive.org/web/20151002145328/http://article20.elsevier.com/contest/home.html\">Article
        2.0 Contest</a> and asked for the best ideas on how research articles should
        be presented on the web. The winners were <a href=\"https://web.archive.org/web/20151002145328/http://news.prnewswire.com/ViewContent.aspx?ACCT=109&amp;STORY=%2Fwww%2Fstory%2F03-31-2009%2F0004997400&amp;EDATE\">announced
        March 31</a>:</p><ul><li><em><em>Inigo Surguy</em></em> from <a href=\"https://web.archive.org/web/20151002145328/http://surguy.net/bricks/elsevier/00012998/0036/0001/05000486/about.html\">67
        Bricks</a> won <em><em>first prize</em></em>. His application used enhanced
        content navigation and allowed adding semantic data to the article as well
        as commenting on specific parts of the article.</li><li><em><em>Jacek Ambroziak</em></em>
        from <a href=\"https://web.archive.org/web/20151002145328/http://ambrosoft.com/cmsmadesimple/index.php?page=elsevier-application\">Ambrosoft</a>
        won <em><em>second prize</em></em> for an application that uses server-side
        and client-side technology to read journal articles on the <a href=\"https://web.archive.org/web/20151002145328/http://www.android.com/\">Android</a>
        mobile platform.</li><li><em><em>Stuart Chalk</em></em> from the University
        of North Florida won <em><em>third prize</em></em>. The link to his application
        is broken, but his idea was that research articles are non-linear and he provided
        customized interfaces on how the article is presented.</li></ul><p>This week
        Cell Press and Elsevier <a href=\"https://web.archive.org/web/20151002145328/http://www.elsevier.com/wps/find/authored_newsitem.cws_home/companynews05_01279\">announced</a>
        the <a href=\"https://web.archive.org/web/20151002145328/http://beta.cell.com/\">Article
        of the Future</a> project, again a project on how scientific articles should
        be presented online. It is not clear of how the material submitted in the
        Article 2.0 contest was used to create the Article of the Future prototypes.
        Some key features of the prototypes are:</p><ul><li>Tabbed browsing of article
        sections</li><li>hierarchical presentation of text and figures</li><li>graphical
        abstract and research highlights</li><li>integrated audio and video</li><li>real-time
        reference analyses</li></ul><p>Two sample articles are provided by Cell Press
        (<a href=\"https://web.archive.org/web/20151002145328/http://beta.cell.com/erickson/\">here</a>
        and <a href=\"https://web.archive.org/web/20151002145328/http://beta.cell.com/hochstim/\">here</a>).
        They are a good starting point to discuss what works and what doesn't. And
        I don't want to get into the discussion of whether naming this project <em><em>Article
        of the Future</em></em> is a little bit overambitious for the small changes
        that were proposed in the prototypes. Here are my thoughts on some of the
        features that might be useful in displaying research articles online (a lot
        of them have already been implemented by one journal or another):</p><h3 id=\"navigation\">Navigation</h3><p>Navigation
        to a specific section (e.g. discussion) is an obvious feature that many journals
        have implemented. This navigation should also work as links from the outside,
        and should also allow direct linking to a figure or table.</p><h3 id=\"abstract\">Abstract</h3><p>The
        traditional abstract can be extended for the online version of a manuscript.
        This could be an easier to read summary of the article or an audio or video
        abstract. Abstracts are important teasers to read the fulltext paper, and
        the current format might not be appropriate for everyone.</p><h3 id=\"integration-of-figures-and-tables\">Integration
        of figures and tables</h3><p>Most journals don't fully integrate figures and
        tables in their online papers, but rather put them on a separate page and
        link to them. This is similar to the PDF version of a paper, where figures
        often have to be placed away from the text section discussing them. The online
        version of a paper should allow viewing the figures and tables in parallel
        to reading the next, preferably by using a two column layout. Supplementary
        information should be integrated in a similar manner.</p><h3 id=\"references\">References</h3><p>Going
        back and forth between the citation in the text and the reference at the end
        of the article is one of the annoyances of the traditional paper format. Online
        papers should make this easier, e.g. by displaying the full reference when
        hovering over the citation. A separate column for the references could also
        work, but three columns (text, figures, and references) might confuse the
        typical reader. The reference section should include links to the referenced
        paper, preferably using the DOI. Additional information about these references
        (e.g. links to PubMed, links to the full text, number of citations) could
        also be provided. A \u201Creturn to text\u201D is a nice touch at <em><em>Biomed
        Central</em></em>.</p><h3 id=\"related-content\">Related content</h3><p>Other
        papers citing the article should be listed and linked to. Showing related
        articles would be helpful, but I have yet to see a working implementation
        of that feature (maybe with the help of services such as <a href=\"https://web.archive.org/web/20151002145328/http://www.citulike.org/\">CiteULike</a>
        or <a href=\"https://web.archive.org/web/20151002145328/http://www.mendeley.com/\">Mendeley</a>?).
        A good starting point would be to include other articles by the same authors
        and articles that are cited by the paper. Links to blog posts and other online
        content (e.g. on <em><em>Twitter</em></em> or <em><em>FriendFeed</em></em>)
        talking about the article would be very helpful, but that is difficult to
        do. Linking to the places that bookmark the article (e.g. on <em><em>CiteULike</em></em>,
        <em><em>Connotea</em></em>, <em><em>2collab</em></em>) is a good starting
        point to find other users with related interests. Therefore it is also helpful
        to make it easy to share the article using these services (as they all use
        bookmarklets for that, this is more about providing good import filters).</p><h3
        id=\"article-publication-history\">Article Publication History</h3><p>The
        publication history of the article (submission and acceptance dates, as well
        as reviewer comments, etc.) provides interesting addition information about
        a paper, and is for example provided by <a href=\"https://web.archive.org/web/20151002145328/http://www.biomedcentral.com/1472-6963/9/127/prepub\">BioMed
        Central journals</a>.</p><h3 id=\"comments-and-usage-statistics\">Comments
        and usage statistics</h3><p>Comments should be possible not only at the end
        of the article, but also within specific sections (such as <a href=\"https://web.archive.org/web/20151002145328/http://www.plosone.org/static/commentGuidelines.action\">notes</a>
        in PLoS journals). And comments should be implemented using an API, allowing
        viewing and adding comments from within other services. Usage statistics are
        another way to look at the popularity of a paper, and should soon be available
        for the <em><em>PLoS</em></em> journals.</p><h3 id=\"semantic-markup\">Semantic
        markup</h3><p>This is an area where I would expect the biggest changes to
        the current format \u2013 papers currently have little or no support for this
        and that is a shame. <a href=\"https://web.archive.org/web/20151002145328/http://imageweb.zoo.ox.ac.uk/pub/2008/plospaper/latest/\">Here</a>
        is an example of a semantically enhanced PLoS Neglected Tropical Diseases
        article. Another example is semantic markup used by <em><em>Nature Chemistry</em></em>,
        as discussed in <a href=\"https://chem-bla-ics.blogspot.com/2009/03/nature-chemistry-improves-publishing.html\">this
        blog post </a>by Egon Willighagen.</p><p>Kent Anderson over at the <em><em>scholarly
        kitchen blog</em></em> (<a href=\"https://web.archive.org/web/20151002145328/http://scholarlykitchen.sspnet.org/2009/07/21/the-article-of-the-future-lipstick-on-a-pig/\">The
        Article of the Future \u2013 Just Lipstick Again?</a>) and Marshall Kirkpatrick
        at <em><em>ReadWriteWeb</em></em> (<a href=\"https://web.archive.org/web/20151002145328/http://www.readwriteweb.com/archives/elseviers_prototype_is_this_the_scientific_article.php\">Elsevier's
        Prototype: Is This The Scientific Article of the Future?</a>) also wrote about
        this. And this was discussed on <a href=\"https://web.archive.org/web/20151002145328/http://friendfeed.com/science-online/cbbe2531/news-releases-elsevier-announces-article-of\">FriendFeed</a>
        and in the <a href=\"https://web.archive.org/web/20151002145328/http://network.nature.com/groups/goodpaper/forum/topics/5099\">Good
        Paper Journal Club</a>.</p><h3 id=\"references-1\">References</h3><p>Nature
        Chemistry improves publishing chemistry: a detailed analysis. Accessed July
        27, 2023. <a href=\"https://chem-bla-ics.blogspot.com/2009/03/nature-chemistry-improves-publishing.html\">https://chem-bla-ics.blogspot.com/2009/03/nature-chemistry-improves-publishing.html</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Using Google Wave for a week \u2013 it\u2019s
        still great! ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/using-google-wave-for-a-week-its-still-great/\"
        />\n\t\t<id>https://doi.org/10.53731/8ey1pyb-bdqppv7</id>\n        <published>2009-07-18T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-14T14:48:06.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p><a href=\"https://web.archive.org/web/20150922174142/http://wave.google.com/\">Google
        Wave</a> is a new tool for communication and collaboration on the web. When
        Wave was first announced May 28 at the <a href=\"https://web.archive.org/web/20150922174142/http://code.google.com/intl/de-DE/events/io/\">Google
        I/O conference</a>, many people immediately saw its potential as a great collaboration
        tool for scientists:</p><ul><li>Ricardo Vidal: <a href=\"https://web.archive.org/web/20150922174142/http://my.biotechlife.net/2009/05/29/using-the-google-wave-to-surf-the-streams/\">Using
        Google Wave to surf the streams</a></li><li>Me: <a href=\"https://web.archive.org/web/20150922174142/http://network.nature.com/people/mfenner/blog/2009/05/28/google-wave-dont-forget-the-scientists\">Google
        Wave \u2013 don't forget the scientists</a></li><li>Cameron Neylon: <a href=\"https://web.archive.org/web/20150922174142/http://blog.openwetware.org/scienceintheopen/2009/05/30/omg-this-changes-everything-or-yet-another-wave-of-adulation/\">OMG!
        This changes EVERYTHING! \u2013 or \u2013 Yet Another Wave of Adulation</a>
        and <a href=\"https://web.archive.org/web/20150922174142/http://blog.openwetware.org/scienceintheopen/2009/06/08/google-wave-in-research-the-slightly-more-sober-view-part-i-papers/\">Google
        Wave in Research \u2013 the slightly more sober view \u2013 Part I \u2013
        Papers</a></li><li>Peter Murray-Rust: <a href=\"https://web.archive.org/web/20150922174142/http://wwmm.ch.cam.ac.uk/blogs/murrayrust/?p=2026\">Google
        Wave first reactions</a> and <a href=\"https://web.archive.org/web/20150922174142/http://wwmm.ch.cam.ac.uk/blogs/murrayrust/?p=2032\">Google
        Wave and implications for science</a></li><li>Bj\xF6rn Brembs: <a href=\"https://web.archive.org/web/20150922174142/http://bjoern.brembs.net/news.php?item.521.3\">Will
        science ride the Google Wave into the 21st century</a></li></ul><p>We based
        our first impressions on the material available online, especially the video
        of the <a href=\"https://web.archive.org/web/20150922174142/http://www.youtube.com/watch?v=v_UyVmITiYQ&amp;feature=player_embedded\">Google
        Wave presentation</a> at Google I/O. The problem is, Wave is currently only
        available to selected developers, and will not be generally available until
        the end of the year. Wave is currently not even beta software and was announced
        now so that third-party developers have enough time to build (and test) extensions
        to Wave.</p><p>Those of us being invited to <a href=\"https://web.archive.org/web/20150922174142/http://www.nature.com/scifoo/index.html\">SciFoo</a>
        (which took place July 10-12 at Google) were lucky not only in attending a
        great conference, but also in getting a Wave account. Wave product manager
        <em><em>Steph Hannon</em></em> gave us an introduction to Wave on the first
        evening, and <em><em>Cameron Neylon</em></em> organized a session about Wave
        the next day. The session was mainly about the Wave extensions that we scientists
        would need (and I'm sure that Cameron will blog about that), but we could
        also ask two developers from the Wave team a lot of questions.</p><p>After
        using Wave for one week, I obviously have a much better feeling for how it
        can help scientists to communicate and collaborate. The best way to start
        is to think of Wave as email on steroids. Wave is web-based (which means that
        it currently only works when you have an internet connection) with a nice
        interface similar to Gmail or other webmail products. One big advantage over
        email is that all reply messages are directly connected to the original message
        (similar to comments on a blog). This is especially helpful for longer email
        threads and when more than two people are involved.</p><p>But Wave is also
        instant messaging. You see a small green dot next to your contacts that are
        currently online, and you can see them typing in real-time (which looks really
        creepy the first time you see that).</p><p>And Wave is also like a Wiki. You
        can not only respond to a message, but everybody participating in the Wave
        can also change the original message (and several people can work on the same
        message simultaneously). This works great for things such as listing all the
        blog posts about SciFoo.</p><p>The combination of wiki-style editing plus
        comments make Wave an interesting alternative to project management tools
        such as <a href=\"https://web.archive.org/web/20150922174142/http://basecamphq.com/\">Basecamp</a>.
        And this means that Wave can also be used to work on longer documents \u2013
        something that the Wave developers regularly do for documentation, etc. Wave
        documents can also contain images, videos, links, etc. Wave supports different
        fonts, text colors, bold and italic text, and four different heading levels
        (for titles and subtitles).</p><p>But in contrast to most online collaboration
        tools, Wave can be extended with additional functionality that scientists
        require. Bibliographic references would be an obvious example, and here tools
        such as <a href=\"https://web.archive.org/web/20150922174142/http://docs.google.com/\">Google
        Docs</a> or <a href=\"https://web.archive.org/web/20150922174142/http://buzzword.acrobat.com/\">Adobe
        Buzzword</a> fall short.</p><p>Wave extensions come in the form of gadgets
        (that work on the client) and robots (that work on the server). Wave gadgets
        are XML files, whereas robots can currently be developed in either Java or
        Python. Other programming languages (PHP, Ruby, Perl, etc.) for robots will
        soon become possible when robots no longer have to be hosted on <a href=\"https://web.archive.org/web/20150922174142/http://code.google.com/appengine\">Google
        App Engine</a>. Using the tools provided by Google, writing a robot is actually
        not that difficult and it took me only an hour to have a sample \u201CHello
        World!\u201D robot running in Wave. It will obviously take weeks or months
        to develop more sophisticated robots (e.g. for management of bibliographic
        references), but I'm sure that a number of exciting science-related extensions
        will be ready by the time Wave becomes publicly available later this year.</p><p>We
        plan a session with a live Wave demo at the <a href=\"https://web.archive.org/web/20150922174142/http://www.scienceonlinelondon.org/\">Science
        Online London</a> conference in August so that more scientists and science
        communicators become familiar with Wave. About 10 people that registered for
        the conference already have Wave accounts and I hope that some of them will
        come up with interesting science-related robots or gadgets. If you are a Wave
        user, you can reach me at mfenner@wavesandbox.com. And if you want to develop
        great science-related extensions for Wave, please contact <em><em>Cameron
        Neylon</em></em>.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ The Value of Peer Review ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/the-value-of-peer-review/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw31</id>\n
        \       <published>2009-07-13T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-01T05:54:16.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>This weekend
        I was at <a href=\"https://web.archive.org/web/20161107033419/http://www.nature.com/scifoo/everything.html\">SciFoo</a>,
        an invitation-only unconference by <em>O'Reilly Media</em>, <em>Nature</em>
        and <em>Google</em> that took place at Google. I was fortunate to be invited,
        and I'm still digesting all the impressions and discussions that I had (there
        were <em>many</em>). This post is the indirect result of two sessions and
        several related discussions on one particular topic that I'm most interested
        in \u2013 the process of scientific publication.</p><p>Peer review <a href=\"https://web.archive.org/web/20161107033419/http://www.nature.com/nature/peerreview/debate/index.html\">is
        usually seen as essential</a> for the quality of a published paper. At the
        same time peer review puts a large burden of work on the research community,
        and in general is unpaid work. But peer review is not living up to its full
        potential. We should start to see it not as a necessary, costly and time-consuming
        burden, but rather as a business opportunity. But for this the information
        communicated in the peer review process needs to leave the (digital) drawers
        of the journal editorial offices.</p><p>The published research paper is the
        most important piece of information used to evaluate the reputation of a scientist
        (the published book takes that role in many social sciences). This evaluation
        is most important when large sums of money and the personal careers of the
        involved scientists (in the form of research grants and jobs) depend on it.
        We usually begin with applying some sort of metrics to the publications of
        the scientist(s) under evaluation, most often the <a href=\"https://web.archive.org/web/20161107033419/http://thomsonreuters.com/products_services/science/free/essays/\">Journal
        Impact Factor</a>. Once we have reduced the number of scientists and papers
        to a small enough number, we can start reading the full-text papers in order
        to evaluate the quality of the science. Both approaches have shortcomings
        that I don't want to go into detail here (citation metric: artificial number,
        delay of several years if relying on citation counts; reading full-text paper:
        time constraints, often needs outside experts as science has become so specialized).
        The information contained in the peer review process is a large untapped resource
        that could potentially overcome many of these shortcomings.</p><p>The typical
        revenue streams of a scientific journal are currently subscriptions and author
        submission fees, and to a lesser extend advertising and subscription-based
        added value in the form of news items and editorials. The information contained
        in the peer review process is extremely valuable to granting agencies and
        job search committees and has the potential to become an additional major
        revenue source for scientific journals, thus allowing a reduction in author
        submission fees and/or free full-text access without a subscription. Many
        research organizations and funding agencies currently pay for journal subscriptions
        and author submission fees. If they would pay the journal publishers similar
        amounts of money for peer review information, they would obviously get much
        more value out of their money. Whereas this revenue would probably come mainly
        from granting agencies, large research organizations or companies would also
        pay for this information, as would the typical academic journal reader (obviously
        a much smaller sum) if it helps in filtering out the most relevant scientific
        papers.</p><p>The peer review process obviously would have to change in this
        model. If peer review becomes a major source of revenue for the journals,
        reviewers need to get paid for their efforts. And it will affect of what reviewers
        and editors write in their assessment if that information might later be seen
        by third parties \u2013 even if they remain anonymous. It is also not clear
        if the peer review information of rejected papers should be used (a large
        body of information at journals with high rejection rates). And if journal
        publishers don't buy in that model of selling peer review information, nobody
        stops other parties from doing additional peer review of papers already published
        and selling that information. Which sounds pretty much like what <a href=\"https://web.archive.org/web/20161107033419/http://www.f1000biology.com/\">Faculty
        of 1000</a> is doing, although they seem to be targeting the academic journal
        reader rather than the much more important funding agencies.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ I was at SciBarCamp Palo Alto ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/i-was-at-scibarcamp-palo-alto/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw30</id>\n        <published>2009-07-10T00:00:00.000+00:00</published>\n\t\t<updated>2023-09-02T06:49:04.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2023/09/3703736022_459c5f3ffc_k.jpg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2023/09/3703736022_459c5f3ffc_k.jpg\"></p><p><br><a
        href=\"http://www.scibarcamp.org/SciBarCamp_Palo_Alto\">SciBarCamp Palo Alto</a>
        took place July 8-9 in the <a href=\"https://web.archive.org/web/20161110193313/http://www.iftf.org/\">Institute
        for the Future</a>. I came right from the airport and arrived too late for
        the general introductions and session suggestions. But there was time for
        a little break before Sean Mooney started his keynote lecture.</p><h3 id=\"keynote-biomedical-research-in-the-age-of-cyberinfrastructure\"><a
        href=\"https://web.archive.org/web/20161110193313/http://ff.im/4YEeQ\">Keynote:
        Biomedical Research in the Age of Cyberinfrastructure</a></h3><p>Sean Mooney</p><p>Sean
        Mooney <a href=\"https://web.archive.org/web/20161110193313/http://www.buckinstitute.org/theInstitute/news.asp?id=31\">just
        recently joined the Buck Institute for Age Research</a> as director of their
        bioinformatics core. He was talking both about his extensive experience building
        web-based bioinformatics tools, but also about <a href=\"https://web.archive.org/web/20161110193313/http://laboratree.org/\">Laboratree</a>,
        a social networking tool for scientists with a focus on research management.
        The key argument he was trying to make is that we have a large number of online
        tools to store and analyze the data of our scientific experiments, but that
        there is still not enough effort to connect these tools. The infrasctructure
        networks that exist (e.g. <a href=\"https://web.archive.org/web/20161110193313/https://cabig.nci.nih.gov/\">caBIG</a>)
        usually focus on one particular domain (cancer research in this case), and
        the 27 NIH institutes all have their own approach to informatics. Researchers
        and administrators have a very different approach to online tools. Whereas
        researchers want to analyze data, administrators focus more on the much broader
        picture, e.g. asset management. Administrators often misjudge their needs
        for the needs of the scientist. Scientists often mistake today's needs for
        tomorrow's needs.</p><p>Sean also talked about his experience building <em>Laboratree</em>.
        He thinks that the social networking for scientists killer app is one that
        people \u201Chave to use\u201D not \u201Clike to use\u201D, and that successful
        tools are simple and start with a preexisting community.</p><p>After the keynote
        we had un-dinner in smaller groups, and I went to bed after being up for 24
        hours thanks to the 9 hour time difference. The next day we had the unconference
        sessions suggested the day before, and I talk a little bit about the sessions
        I attended. The rest of the sessions are well documented in the <a href=\"https://web.archive.org/web/20161110193313/http://friendfeed.com/scibarcamp\">SciBarCamp
        FriendFeed group</a> and on <a href=\"https://web.archive.org/web/20161110193313/http://twitter.com/#search?q=%23sbcPA\">Twitter</a>.</p><h3
        id=\"open-source-textbooks\"><a href=\"https://web.archive.org/web/20161110193313/http://ff.im/50EdW\">Open
        Source Textbooks</a></h3><p>Chris Patil</p><p>This was a great brainstorming
        session. We agreed that \u2013 with very few exceptions \u2013 there is no
        financial incentive for scientists to write textbooks. The main motivation
        is reputation, and we thought that the lack of return on textbook authoring
        is an opportunity for new approaches. The concept of Open Access textbooks
        is a social problem (e.g. who pays for the textbook, what are the author incentives
        when there is a long list of contributors), and not a technical problem. <a
        href=\"https://web.archive.org/web/20161110193313/http://ocw.mit.edu/OcwWeb/web/home/home/index.htm\">OpenCourseWare</a>
        was mentioned as a great educational resource that overlaps in intent with
        Open Access textbooks. Sean Mooney and Cameron Neylon mention the often unsolved
        copyright issues when creating Open Access material, and this includes potential
        issues with proper attribution with the <a href=\"https://web.archive.org/web/20161110193313/http://creativecommons.org/\">Creative
        Commons</a> license when reusing material. We briefly talked about document
        formats (where PDF probably is still important), and that we probably need
        to print most of the textbooks, at least until eBook readers become cheaper.</p><h3
        id=\"personal-genomics\"><a href=\"https://web.archive.org/web/20161110193313/http://ff.im/50N35\">Personal
        Genomics</a></h3><p>Melanie Swan</p><p>This for me was a great introduction
        to the topic, and the main emphasis of the session was probably on the consumer
        perspective. The first ever consumer genomics conference <a href=\"https://web.archive.org/web/20161110193313/http://www.consumergeneticsshow.com/\">was
        held in Boston last month</a>. One important, and still only partly solved
        issue is huge amount of data generated, especially if we take into account
        not only genetics, but also epigenetic changes, and the fact that not all
        cells of an individual are genetically identical (which is true especially
        in cancer). The technology is changing rapidly and the cost of sequencing
        a whole genome of an individual is constantly coming down. We talked about
        a few examples of genes that are already useful to test, one prominent example
        being <a href=\"https://web.archive.org/web/20161110193313/http://rbaltman.wordpress.com/2009/05/21/cms-made-a-mistake-in-not-approving-genetics-for-warfarin/\">CYP2C9</a>
        and warfarin (an anticoagulant) metabolism. Many chronic disease conditions
        are multigenetic, and therefore it is usually risk assessment rather than
        yes/no answers. Some personalized genetics testing companies are <a href=\"https://web.archive.org/web/20161110193313/http://www.navigenics.com/\">Navigenics</a>,
        <a href=\"https://web.archive.org/web/20161110193313/http://www.decode.com/\">Decode</a>,
        and <a href=\"https://web.archive.org/web/20161110193313/https://www.23andme.com/\">23andMe</a>.</p><h3
        id=\"article-level-metric-from-the-plos-perspective\"><a href=\"https://web.archive.org/web/20161110193313/http://ff.im/50Wty\">Article
        level metric from the PLoS perspective</a></h3><p>Peter Binfield</p><p>Peter
        started the session by addressing the problem: how do you access the worth
        of impact of journal articles, and at what level do we measure this: journal,
        research institution, individual researcher? he then went over currently used
        article level metrics that fall into six areas:</p><ul><li>citation metrics</li><li>usage
        metrics</li><li>expert rankings (Faculty of 1000)</li><li>Conversations (blogs,
        media coverage, comments)</li><li>social bookmarking (citeULike etc)</li><li>Other
        cool stuff (geotagging of authors, etc.)</li></ul><p>In this broader context
        article-level metrics can be seen as post-publication peer review. Much of
        this is still ongoing, ResearchBlogging.org is for example bulding an API
        so that blog posts about PLoS articles can be tracked. In August PLoS One
        will add information about usage statistics to all their papers. Because usage
        statistics are currently not widely available, this give a push to the role
        of usage statistics in evaluating a paper. Future work at PLoS will include
        better integration with Mendeley, Zotero, CiteULike and similar services.
        We briefly talked about the relative little use of commenting and tagging
        at PLoS One, and some people in the audience felt that we need automated tools
        (e.g. by looking at what papers are bookmarked or stored in Mendeley) rather
        than user generated content.</p><h3 id=\"spinning-science-the-good-and-the-bad-of-media-sensationalism\"><a
        href=\"https://web.archive.org/web/20161110193313/http://ff.im/51cld\">Spinning
        Science: The good and the bad of media sensationalism</a></h3><p><em>Naomi
        Most, Kiki Sanford</em></p><p>Naomi and Kiki started the session by putting
        up the provocative hypothesis that sensationalism is the way to report science.
        They cite Edwin Slosson who in 1921 said <em>Our best plan is probably to
        try to crowd out falsehood by truth and to present scientific information
        in a way that will be at least as attractive as the misinformation that now
        holds the field.</em> They point out that there are different realms of science
        communication, including</p><ul><li>science for scientists</li><li>science
        for scientists working in different fields</li><li>science for the educated
        public</li><li>science for students, and more</li></ul><p>We probably need
        more translators of science, rather than more people doing science. We are
        already overwhelmed with the massive amount of science created today. We had
        a longer discussion about the misunderstandings between scientists and their
        institution's PR people. Part of the problem is that scientists are not automatically
        good communicators. Should they all become good communicators? This is probably
        not possible and not required. We then talked about science rock stars and
        had the best quote of the meeting:</p><blockquote><em>Why do kids look up
        more to basketball players rather than scientists? They are taller.</em> (Jim
        Hardy)</blockquote><h3 id=\"scientific-publishing-in-5-10-years\"><a href=\"https://web.archive.org/web/20161110193313/http://ff.im/51jI5\">Scientific
        Publishing in 5-10 years</a></h3><p>Peter Binfield</p><p>This was a fun session
        of what we think science publishing will look like in the intermediate future.
        Peter asked the following questions:</p><ul><li>Do current publishers exist?</li><li>Does
        the journal exist as a package?</li><li>Does the article exist?</li><li>What
        business models dominate?</li><li>What new technical features do we seriously
        expect?</li><li>What new modes of scholarly communication may gain wide acceptance?</li></ul><p>Other
        questions that were asked by the audience include:</p><ul><li>What money exists
        in 5-10 years?</li><li>Who is doing the actual work of publishing?</li><li>What
        are the customers?</li></ul><p>We went through most of these points. We discussed
        a possible business model similar to iTunes where the per-article charges
        would be much lower than today. In the future the role of the librarian will
        change. It will be more about information, and less about journal subscriptions.
        We talked about how the process of producing and publishing a paper will become
        cheaper by better tools, and by using the <a href=\"https://web.archive.org/web/20161110193313/http://dtd.nlm.nih.gov/\">NLM-DTD</a>
        standard for submission. Articles in the future will not contain only text
        and figures, and we had a longer discussion on how digital media can be preserved
        in the long run, and that at some point we will not be able to keep all our
        data because of the dramatic increase in the carbon footprint required.</p><h3
        id=\"efficiency-and-incentives-in-research-how-to-bend-the-internet-to-scientists\"><a
        href=\"https://web.archive.org/web/20161110193313/http://ff.im/51tx6\">Efficiency
        and incentives in research \u2013 How to bend the internet to scientists</a></h3><p>Cameron
        Neylon, Jason Hoyt, Duncan Hull</p><p>The last session was really three separate
        little presentations by the three speakers. Cameron started with a presentation
        <a href=\"https://web.archive.org/web/20161110193313/http://www.slideshare.net/CameronNeylon/nesta-science-in-society\">he
        recently gave at NESTA</a> (Science in Society). One question he asked was
        how we maximise the efficiency in generating impact for our research? Jason
        Hoyt gave a good introduction to <a href=\"https://web.archive.org/web/20161110193313/http://www.mendeley.com/\">Mendeley</a>
        and used this as a basis of what social tools for scientists should look like.
        One important point: these tools should work with a userbase of 1, rather
        than needing a critical mass. Duncan Hull talked about Digital Identity on
        the Web, something <a href=\"https://web.archive.org/web/20161110193313/http://duncan.hull.name/2009/06/02/who-are-you/\">he
        has talked about before</a>. He pointed out that many papers in Google Scholar
        are by \u201Cforgotten password\u201D, \u201Calready registered\u201D, etc.
        OpenID is a solution to some of the problems of author identity, but is complicated
        to use and not secure enough for some specific scientific applications. Peter
        Binfield explained that an author identifier would be really helpful for PLoS,
        and that their databases currently can't identify an author that has for example
        changed institutions. We had a long discussion about potential benefits of
        researcher identifiers, and what is needed to really get the ball rolling.</p><p>After
        the final session I went to the pub with a few people (really strange to do
        that in Palo Alto), and after having some food hopped on the bus that brought
        me back to my hotel.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Recipe: Receiving Journal Table of Contents
        Automatically ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/recipe-receiving-journal-table-of-contents-automatically/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw3n</id>\n        <published>2009-06-21T00:00:00.000+00:00</published>\n\t\t<updated>2023-09-02T09:15:19.000+00:00</updated>\n\t\t<category
        term=\"Science Hack\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2023/09/paper_boy.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2023/09/paper_boy.png\"></p><h3
        id=\"problem\">Problem</h3><p>You want to regularly go through the papers
        published in the most important journals in your research field.</p><h3 id=\"solution\">Solution</h3><p>Subscribe
        to the journal table of contents (TOC) RSS feed. Almost all journals now provide
        their TOC as RSS feed that is updated with every new issue. <a href=\"https://web.archive.org/web/20150922174136/http://en.wikipedia.org/wiki/RSS\">RSS</a>
        is a standard web format used to publish frequently updated works. A journal
        article RSS feed usually contains one item for every article, each with title,
        authors, abstract and link to the fulltext article. To subscribe to the RSS
        feed of the journal TOC, look out for the RSS icon</p><figure class=\"kg-card
        kg-image-card\"><img src=\"https://web.archive.org/web/20150922174136im_/http://network.nature.com/images/feed-icon-14x14.png\"
        class=\"kg-image\" alt loading=\"lazy\"></figure><p>at the table of contents
        page. Links to the RSS feeds of some popular scientific journals are:</p><ul><li><a
        href=\"https://web.archive.org/web/20150922174136/http://www.nature.com/nature/current_issue/rss\">Nature</a></li><li><a
        href=\"https://web.archive.org/web/20150922174136/http://www.sciencemag.org/rss/current.xml\">Science</a></li><li><a
        href=\"https://web.archive.org/web/20150922174136/http://www.cell.com/rssFeed/Cell/rss.NewIssueAndArticles.xml\">Cell</a></li><li><a
        href=\"https://web.archive.org/web/20150922174136/http://www.pnas.org/rss/current.xml\">Proceedings
        of the National Academy of Sciences</a></li></ul><p>Although most web browsers
        (e.g. Internet Explorer 7, Firefox or Safari) will understand RSS feeds (so
        you can just click on the links provided above), you should use a dedicated
        RSS reader if you subscribe to more than a few RSS feeds. There are web-based
        RSS readers (<a href=\"https://web.archive.org/web/20150922174136/http://www.google.com/reader\">Google
        Reader</a> and <a href=\"https://web.archive.org/web/20150922174136/http://www.bloglines.com/\">Bloglines</a>
        are popular choices) and dedicated programs for <a href=\"https://web.archive.org/web/20150922174136/http://www.dmoz.org/Computers/Software/Internet/Clients/WWW/Feed_Readers/\">every
        platform</a> (e.g. <a href=\"https://web.archive.org/web/20150922174136/http://www.newsgator.com/individuals/feeddemon/default.aspx\">FeedDemon</a>
        for Windows or <a href=\"https://web.archive.org/web/20150922174136/http://www.newsgator.com/Individuals/NetNewsWire\">NetNewsWire</a>
        for Macintosh).</p><p>Dedicated RSS readers have two important features: they
        keep track of the journal articles you have already <em><em>read</em></em>,
        and they allow you to <em><em>mark</em></em> interesting articles for late
        use: reading the full-text article (online or after printing the PDF), and
        storing the article in your reference manager of choice.</p><p>RSS readers
        are also available for mobile devices such as the <em><em>iPhone</em></em>
        and are great for quickly going through a journal table of contents on the
        way to work.</p><h3 id=\"discussion\">Discussion</h3><p>Regular reading of
        journal table of contents in your field (browsing) is still an important way
        to keep up with the literature, even though the use of online databases to
        find specific articles (searching) has become more common in recent years.</p><p>Some
        people prefer to regularly flip through the printed journal when the latest
        issue arrives. But not only is there a delay between electronic publication
        and arrival of the printed journal, but most individuals can't afford to personally
        subscribe to more than a few journals at most. And looking at the printed
        copy subscribed to by the department or library is often no longer practical
        to do on a regular basis.</p><p>Receiving the journal TOC by <em><em>email</em></em>
        is a popular alternative, but has several disadvantages:</p><ul><li>Receiving
        the TOC by email requires a few extra steps, including providing your email
        address, and often signing up for a (free) account with the journal</li><li>Organizing
        the TOC emails with your email program (e.g. moving to appropriate subfolders)
        requires extra work</li><li>Marking an interesting article for later reading
        requires extra work, because the TOC is sent in one big email message</li><li>Sharing
        the TOC with coworkers is more difficult than with RSS feeds</li></ul><p>Because
        RSS is a universal computer-readable format, receiving the journal TOC can
        easily be extended. One example would be the integration of the journal RSS
        feeds into reference managers. <em><em>CiteULike</em></em> has this feature
        (e.g. the most recent issue of <a href=\"https://web.archive.org/web/20150922174136/http://www.citeulike.org/journal/nature\">Nature</a>),
        but I hope that more reference managers will do the same in the future.</p><p>Although
        almost all journals now provide RSS feeds to their TOC, how they do it might
        differ. Not every journal RSS feed uses the <a href=\"https://web.archive.org/web/20150922174136/http://www.doi.org/\">DOI</a>
        \u2013 now the preferred way to link to a journal article. There are also
        small differences in what information is provided in the RSS feed.</p><p><em><em>This
        blog post was inspired by a recent discussion about the <a href=\"https://web.archive.org/web/20150922174136/http://network.nature.com/people/mfenner/blog/2009/06/14/how-to-close-the-digital-divide-among-scientists\">digital
        divide among scientists</a>.</em></em></p><h3 id=\"references\">References</h3><p>Hammond,
        T., Hannay, T., &amp; Lund, B. (2004). The Role of RSS in Science Publishing.
        D-Lib Magazine, 10(12). <a href=\"https://doi.org/10.1045/december2004-hammond\">https://doi.org/10.1045/december2004-hammond</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ How to close the digital divide among scientists
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/how-to-close-the-digital-divide-among-scientists/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw3p</id>\n        <published>2009-06-14T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-31T07:53:14.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>The term <em><em>digital divide</em></em>
        usually describes <em><em>the troubling gap between those who use computers
        and the Internet and those who do not</em></em> (<a href=\"https://web.archive.org/web/20151001173737/http://en.wikipedia.org/wiki/Digital_divide\">Wikipedia</a>).
        Many if not most scientists are experienced users of computers and the internet,
        and use email or public databases such as <em><em>PubMed</em></em> on a daily
        basis. But few scientists regularly use Web 2.0 tools, which would include
        both general tools such as <em><em>Twitter</em></em>, <em><em>FriendFeed</em></em>
        or <em><em>Facebook</em></em>, as well as tools specifically targeted at scientists
        (and this would of course include <em><em>Nature Network</em></em>).</p><p>Regular
        readers of this blog know that I am fascinated by technology, especially if
        this technology makes it easier to publish scientific papers. And like others
        I sometimes get carried away (<a href=\"https://web.archive.org/web/20151001173737/http://network.nature.com/people/mfenner/blog/2009/05/28/google-wave-dont-forget-the-scientists\">Google
        Wave</a> is a good recent example). Even among those scientists open to blogs,
        wikis, etc., not everybody wants to follow every technology trend. This could
        simply be because that would take too much time, but most people probably
        just don't care that much about technology.</p><p>So what can we do about
        this digital divide among scientists? Science is often very specialized, and
        sometimes only a few people participate in a discussion about a particular
        topic. <a href=\"https://web.archive.org/web/20151001173737/http://radar.oreilly.com/\">Tim
        O'Reilly</a> has coined the term <em><em>alpha geek</em></em> for people that
        are the first to use new technologies, and there certainly is a place for
        <em><em>science alpha geeks</em></em>. But Science Online is about science
        communication, and communication tools that are used by only a handful of
        people usually don't fulfill their purpose.</p><p>One easy solution would
        be to simply wait 10-20 years until most senior scientists are <a href=\"https://web.archive.org/web/20151001173737/http://en.wikipedia.org/wiki/Digital_native\">digital
        natives</a> (those that have grown up with digital technology such as computers,
        the Internet or mobile phones), but that seems to be an awfully long time
        for something this important.</p><p>We could build better tools. Good tools
        simply work and don't need a lot of explanations. For me <a href=\"https://web.archive.org/web/20151001173737/http://mekentosj.com/papers/\">Papers</a>
        is such a tool, but strictly speaking not really Web 2.0, because it has no
        collaboration features. <em><em>Google Wave</em></em> could be another example,
        but only the next few months will tell. What makes a good Web 2.0 tool for
        scientists? Most importantly, that the tool solves an important everyday problem.
        Equally important, that there aren't high hurdles in using this tool in terms
        of cost and learning curve. Another hurdle: some Web 2.0 tools only start
        to become useful once they have signed up a large enough number of users.</p><p>But
        we also need to do more to communicate the usefulness of online tools for
        scientists. The original definition of the digital divide has a negative meaning
        and everybody probably agrees that we should at least try to overcome this
        divide. Although there certainly is also a digital divide among scientists,
        the general perception is probably not that those scientists that are not
        Web 2.0-savvy are at a disadvantage. We should have a much closer look at
        the tools that are currently available, define the scenarios where they can
        be useful, and focus on that. We talk too much about the details, technical
        or otherwise. One example: most scientists probably want to have an idea of
        when an online reference manager can be helpful rather than the tools they
        currently use, rather than discuss the subtle differences between the very
        similar <a href=\"https://web.archive.org/web/20151001173737/http://www.citeulike.org/\">CiteULike</a>,
        <a href=\"https://web.archive.org/web/20151001173737/http://www.connotea.org/\">Connotea</a>,
        and <a href=\"https://web.archive.org/web/20151001173737/http://www.2collab.com/\">2collab</a>.
        Part of the problem is that people want to make money with their Web 2.0 tools
        for scientists, but forget that collaboration is more important than competition
        when the market still has to grow and is currently probably too small for
        viable business opportunities.</p><p>This makes closing the digital divide
        among scientists very much a science education exercise, and I think that
        science librarians should play a central role in this. Not surprisingly, a
        seminar last week by our local science librarian in our department and <a
        href=\"https://web.archive.org/web/20151001173737/http://scienceblogs.com/confessions/2009/06/cool_conferences_mental_overlo.php\">a
        blog post</a> by science librarian John Dupuis (and the <a href=\"https://web.archive.org/web/20151001173737/http://friendfeed.com/johndupuis/8c6723b0/cool-conferences-mental-overload\">FriendFeed</a>
        discussion around his blog post) were the inspiration for this post (<a href=\"https://web.archive.org/web/20151001173737/http://friendfeed.com/coturnix/562bc610/wow-sunday-afternoon-and-i-don-t-even-know-on-what\">another
        FriendFeed discussion</a> started by Bora Zivkovic made be write the post
        today instead of going to bed early).</p><p><em><em>Update 06/15/09:</em></em><br>One
        good strategy to overcome the digital divide among scientists would be a <em><em>Science
        2.0 Cookbook</em></em>. Similar in format to the <a href=\"https://web.archive.org/web/20151001173737/http://oreilly.com/store/series/cookbooks.csp\">O'Reilly
        Cookbook series</a> for programming problems, the Science 2.0 cookbook would
        use the format problem/solution/discussion to provide a solution for problems
        like <em><em>How do I share references with my coworkers in the lab?</em></em>
        This could be started as a Wiki project.</p><figure class=\"kg-card kg-image-card\"><img
        src=\"https://web.archive.org/web/20151001173737im_/http://www.linkwithin.com/pixel.png\"
        class=\"kg-image\" alt=\"Related Posts Plugin for WordPress, Blogger...\"
        loading=\"lazy\"></figure> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Why do we go to conferences? ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/why-do-we-go-to-conferences/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw3q</id>\n
        \       <published>2009-06-07T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-01T05:51:48.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>I just returned
        from the <a href=\"https://web.archive.org/web/20151002134927/http://www.asco.org/ascov2/Meetings/ASCO+Annual+Meeting\">American
        Society of Clinical Oncology</a> (ASCO) meeting in Orlando, with approximately
        30.000 participants one of the largest oncology conferences. Like other conferences
        of this size, the experience can be overwhelming, but thankfully the organizers
        are getting better every year in using technology that helps in finding the
        most interesting sessions. Most sessions are made available as video podcasts
        or <a href=\"https://web.archive.org/web/20151002134927/http://www.asco.org/ASCOv2/MultiMedia/Virtual+Meeting\">online
        presentations</a>. There is currently still a delay of 24 hours, but I wouldn't
        be surprised to see the sessions streamed live as video over the internet
        in coming years. This year's ASCO also had the first official Twitter meet-up,
        although there still was relatively little <a href=\"https://web.archive.org/web/20151002134927/http://twitter.com/asco\">Twitter
        activity</a> compared to other conferences.</p><p>Last week <a href=\"https://web.archive.org/web/20151002134927/http://www.scienceonlinelondon.org/\">we
        announced</a> <em><em>Science Online London</em></em>, the follow-up conference
        of last year's <a href=\"https://web.archive.org/web/20151002134927/http://network.nature.com/groups/sciblog2008/forum/topics\">Science
        Blogging 2008: London</a>, to take place August 22 at the <a href=\"https://web.archive.org/web/20151002134927/http://www.rigb.org/registrationControl?action=home\">Royal
        Institution</a>. I am helping to organize the conference, and I'm finding
        myself in the middle of discussions about session topics, speakers and the
        right format to present and discuss science blogging, wikis, and other science-related
        activities happening online.</p><figure class=\"kg-card kg-image-card\"><img
        src=\"https://web.archive.org/web/20151002134927im_/http://www.mendeley.com/blog/wp-content/uploads/2009/05/solologo.gif\"
        class=\"kg-image\" alt loading=\"lazy\"></figure><p>These two events started
        me thinking about the reasons I go to conferences. After all, traveling to
        conferences is not only expensive, but can also be exhausting, and too much
        airline travel is certainly not good for the environment (places like <a href=\"https://web.archive.org/web/20151002134927/http://www.dopplr.com/\">Dopplr</a>
        can calculate your carbon profile). Here are a few points that I think make
        a conference a good conference worth attending in person:</p><h3 id=\"conferences-should-present-new-and-exciting-information-which-can-not-be-presented-differently\">Conferences
        should present new and exciting information which can not be presented differently</h3><p>Oral
        presentations at conferences are usually the first public presentation of
        interesting research findings before they appear as published paper a little
        (or much) later. What we don't want to see is the presentation of the same
        old data that we have already seen the year before. Good educational sessions
        and keynote lectures find informative or entertaining ways to present their
        information, and again should not be simply a repeat performance (unless the
        audience is completely different).</p><p>Most conferences encourage the presentation
        of unpublished work, but speakers are often careful in doing so for a variety
        of reasons, e.g. fear of getting scooped, fear of problems with journal submissions
        or fear of problems with patentable work. This fear can make conference presentations
        rather boring, as presenters might hold back with the real exiting stuff until
        these results are at least accepted for publication.</p><p><a href=\"https://web.archive.org/web/20151002134927/http://meetings.cshl.edu/\">Cold
        Spring Harbor Laboratory</a> try to solve this problem by policies that essentially
        make their meetings non-public. During the last week we have seen an intensive
        discussion (e.g. <a href=\"https://web.archive.org/web/20151002134927/http://scienceblogs.com/geneticfuture/2009/06/on_the_challenges_of_conferenc.php\">On
        the challenges of conference blogging</a>) whether or not the sessions in
        a CSHL meeting can be communicated publicly by participating scientists via
        blogs or Twitter. I think that there is nothing wrong with small conferences
        being non-public, and that the same rules should apply to science bloggers
        as they do apply to journalists. But the conference organizers should clearly
        state their policies regarding blogging (including Twitter, FriendFeed and
        other microblogging tools).</p><h3 id=\"conferences-should-enable-as-much-active-participation-of-as-many-participants-as-possible\">Conferences
        should enable as much active participation of as many participants as possible</h3><p>If
        we just want to listen to a presentation, we could do that without going to
        a conference, thanks to video streaming, <a href=\"https://web.archive.org/web/20151002134927/http://www.slideshare.net/\">SlideShare</a>
        and other ways of presenting online. Sometimes a paper is even published on
        the same the day as the plenary session, as happened recently with the <a
        href=\"https://web.archive.org/web/20151002134927/http://network.nature.com/people/mfenner/blog/2008/11/23/what-are-the-right-numbers-for-jupiter\">JUPITER</a>
        trial.</p><p>Smaller sessions that leave enough room for discussions, <a href=\"https://web.archive.org/web/20151002134927/http://en.wikipedia.org/wiki/Unconference\">unconferences</a>
        and poster sessions are all good formats to encourage active participation.
        It should be a goal at least for smaller conferences that every attendee has
        had a chance for active participation in one way or another. But active participation
        in a session is much more focussed than disussions in coffee breaks between
        sessions or afterwards in the bar.</p><h3 id=\"conferences-should-facilitate-personal-networking\">Conferences
        should facilitate personal networking</h3><p>Meeting someone in person is
        very different from interacting online via email, Twitter or social network.
        For many people this is the real reason to go to a conference. Or as Henry
        Gee puts it (slightly out of context), \u201Cthe most important part is to
        <a href=\"https://web.archive.org/web/20151002134927/http://network.nature.com/people/U9556F6A5/blog/2007/08/06/someday-all-conferences-will-be-like-this\">hang
        around in bars</a>.\u201D Smaller conferences (e.g. 100-150 people), enough
        time for coffee and lunch breaks between sessions, and social activities around
        conferences (from <a href=\"https://web.archive.org/web/20151002134927/http://network.nature.com/groups/sciblog2008/forum/topics/1959\">science
        tours</a> to skiing) all facilitate networking.</p><p>I'm looking forward
        to go to a very special conference in five weeks: <a href=\"https://web.archive.org/web/20151002134927/http://www.nature.com/nature/meetings/scifoo/index.html\">Science
        Foo Camp</a>. And let's see whether we can put together an interesting <em><em>Science
        Online London</em></em> conference. Please suggest and discuss session topics
        and speakers in the <a href=\"https://web.archive.org/web/20151002134927/http://network.nature.com/groups/solondon/forum/topics\">Nature
        Network Forum</a>, <a href=\"https://web.archive.org/web/20151002134927/http://friendfeed.com/solondon\">FriendFeed
        group</a> or via <a href=\"https://web.archive.org/web/20151002134927/mailto:topics%40scienceonlinelondon.org\">email</a>
        until June 19. We are still looking for interesting session ideas, speaker
        suggestions and other suggestions to make this an exciting conference.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Google Wave \u2013 don\u2019t forget the
        scientists ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/google-wave-dont-forget-the-scientists/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwbf</id>\n        <published>2009-05-28T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T07:39:17.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p><a href=\"https://web.archive.org/web/20151003053215/http://wave.google.com/\">Google
        Wave</a> is a new tool to communicate online and collaborate and was announced
        today at the <a href=\"https://web.archive.org/web/20151003053215/http://code.google.com/intl/de-DE/events/io/\">Google
        I/O</a> conference. Google Wave is not only a product, but also an open protocol
        that anyone can use to build his own wave server.</p><p>Google Wave is already
        very interesting by itself, but can also be extended further:</p><ul><li>by
        <em><em>robots</em></em> that automate common tasks and run on the server,
        and</li><li>by <em><em>gadgets</em></em> that allow new ways of user interactions
        and run on the client.</li></ul><p>This sounds all rather geeky, but why should
        a scientist care about <em><em>Google Wave</em></em>? Part of the job of every
        scientist is to communicate and collaborate, and email is by far the most
        widely used tool to do that. Email has many shortcomings, some of which can
        be overcome by blogs, wikis, and a constantly growing number of other Web
        2.0 tools from Twitter to FriendFeed. But Google Wave goes one step further.
        The basic idea of a wave is a document (and this can be everything from text
        to pictures) combined with the discussion about that document, and that is
        a very natural design for many scientific communications.</p><p>Google Wave
        will be publicly available later this year. I hope that by that time it will
        also have the first extensions designed specifically for scientists, e.g.
        for</p><ul><li><em><em>references</em></em> with <a href=\"https://web.archive.org/web/20151003053215/http://network.nature.com/people/mfenner/blog/2009/05/25/oai-pmh-interview-with-tony-hammond\">embedded
        metadata</a> and discussions about these references</li><li><em><em><a href=\"http://ff.im/3lpdq\">molecular
        structures</a></em></em> and other scientific data types</li><li><em><em>scientific
        manuscripts</em></em> in progress (Google Wave has nice tools for collaborative
        document editing)</li><li><em><em>lab notebooks</em></em> (again because of
        the wiki-like editing features)</li></ul><p>Google Wave could turn into serious
        competition for the <a href=\"https://web.archive.org/web/20151003053215/http://friendfeed.com/the-life-scientists\">The
        Life Scientists Room</a> at FriendFeed. And it is a great topic to discuss
        further at <a href=\"https://web.archive.org/web/20151003053215/http://en.wikipedia.org/wiki/Science_Foo_Camp\">Science
        Foo Camp 2009</a>.</p><p><em><em>Update 5/29/09:</em></em> You can now <a
        href=\"https://web.archive.org/web/20151003053215/http://www.youtube.com/watch?v=v_UyVmITiYQ&amp;eurl=http%3A%2F%2Fwave%2Egoogle%2Ecom%2F&amp;feature=player_embedded\">watch</a>
        the Google I/O presentation. And Ricardo Vidal also blogged about Google Wave
        from a scientist perspective (<a href=\"https://web.archive.org/web/20151003053215/http://my.biotechlife.net/2009/05/29/using-the-google-wave-to-surf-the-streams/\">Using
        the (Google) Wave to surf the streams</a>).</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ OAI-PMH: Interview with Tony Hammond ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/oai-pmh-interview-with-tony-hammond/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw3r</id>\n        <published>2009-05-25T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-13T15:36:05.000+00:00</updated>\n\t\t<category
        term=\"Interview\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Most of us
        find, store and sometimes read scientific papers electronically. Although
        abstracts and full-text papers are usually available as web pages in HTML
        format, PDF is clearly the preferred format for storing and printing papers.</p><p>But
        publishing scientific papers in electronic form obviously requires more than
        providing the content in HTML or PDF format. We want to find the papers we
        are interested in on the journal homepage or in a digital library (e.g. <a
        href=\"https://web.archive.org/web/20151003101404/http://www.pubmed.gov/\">PubMed</a>),
        and for this we need metadata about the paper. The metadata could simply be
        an digital object identifier (<a href=\"https://web.archive.org/web/20151003101404/http://www.doi.org/\">DOI</a>),
        but the metadata could also contain important information required to find
        a paper in a search strategy (e.g. authors, title, publication date or keywords).</p><p>As
        <a href=\"https://web.archive.org/web/20151003101404/http://network.nature.com/people/duncan/profile\">Duncan
        Hull</a> <em><em>et al.</em></em> noted in a <em><em>PLoS Computational Biology</em></em>
        paper last year (<a href=\"https://web.archive.org/web/20151003101404/http://dx.doi.org/10.1371/journal.pcbi.1000204\">Defrosting
        the digital library: bibliographic tools for the next generation web</a>),
        metadata are often disconnected from the data, and there are no universally
        agreed standards to represent these metadata.</p><p>But why should we as scientists
        care about the technologies used to publish and distribute a paper? We shouldn't
        forget that these technologies could allow new and innovative ways to find
        and read scientific papers. One simple example: storing the metadata in the
        PDF file (using <a href=\"https://web.archive.org/web/20151003101404/http://blogs.nature.com/wp/nascent/2008/12/xmp_labelling_for_nature.html\">XMP</a>)
        could make it much easier to import a large collection of PDF files into a
        reference manager.</p><p>One such initiative to provide the metadata of a
        scientific paper is OAI-PMH. I asked Tony Hammond from Nature.com a few questions
        about this newly supported protocol, as well as some more general questions
        about metadata provided by the Nature Publishing Group journals.</p><h3 id=\"1-can-you-describe-what-oai-pmh-is-and-does\">1.
        Can you describe what OAI-PMH is and does?</h3><p>Well, we'll first need to
        unpack that double acronym. OAI-PMH is the <a href=\"https://web.archive.org/web/20151003101404/http://www.openarchives.org/pmh/\">Protocol
        for Metadata Harvesting</a> which comes from the <a href=\"https://web.archive.org/web/20151003101404/http://www.openarchives.org/\">Open
        Archives Initiative</a>. It's traditionally been known simply as OAI, although
        these days it's more properly referred to in full as OAI-PMH in view of the
        arrival of a new sibling protocol: OAI-ORE, which stands for <a href=\"https://web.archive.org/web/20151003101404/http://www.openarchives.org/ore/\">Object
        Reuse and Exchange</a>. The two protocols are complementary: OAI-PMH deals
        with metadata harvesting, while OAI-ORE is concerned with content aggregation
        and compound digital objects.</p><p>In brief, OAI-PMH provides an interoperability
        framework for networked repositories to exchange metadata records on their
        holdings. Such metadata typically includes bibliographic-type descriptions
        of repository items, such as title, authors and other identifying information.
        At a technical level OAI-PMH provides a very simple Web-based API for querying
        a repository by item, by set of items or by date range with data records being
        returned in an XML format which can be validated by a W3C XML Schema. A basic
        metadata format using <a href=\"https://web.archive.org/web/20151003101404/http://dublincore.org/\">Dublin
        Core</a> is available from all OAI-PMH implementations, while other richer
        community-specific metadata formats are encouraged for a fuller semantic exchange.</p><h3
        id=\"2-what-is-prism-aggregator-message-pam-\">2. What is PRISM Aggregator
        Message (PAM)?</h3><p>I posted an entry <a href=\"https://web.archive.org/web/20151003101404/http://www.crossref.org/CrossTech/2009/05/post_2.html\">PRISM
        Aggregator Message</a> on CrossTech recently which delved into the <a href=\"https://web.archive.org/web/20151003101404/http://www.idealliance.org/industry_resources/intelligent_content_informed_workflow/about_the_prism_aggregator_message\">PRISM
        Aggregator Message</a> (PAM) format and provided some specific details and
        also reasons why we chose to use it. Basically our choice of PAM stems from
        our earlier work with RSS and <a href=\"https://web.archive.org/web/20151003101404/http://prismstandard.org/\">PRISM</a>.</p><p>Our
        first foray into semantic descriptions was with RSS feeds. While still at
        Elsevier I had collaborated with Timo Hannay and Ben Lund at Nature Publishing
        Group and wrote up a piece for <em><em>XML.com</em></em> entitled <a href=\"https://web.archive.org/web/20151003101404/http://www.xml.com/lpt/a/1252\">Why
        Choose RSS 1.0?</a> which described how journal RSS feeds could be enhanced
        with PRISM metadata. Specifically that piece reviewed the different RSS strains
        and came out strongly in favour of RSS 1.0 which being an RDF application
        was truly extensible and could accommodate new vocabularies. The identification
        of PRISM as a useful vocabulary was largely based on noting the adjacency
        of two RDF use cases in an early edition of the W3C RDF Primer: RSS and PRISM.
        I had been reading up on RSS and RDF and I suddenly thought \u201CBingo!\u201D,
        we can add in PRISM terms to the RSS feeds since PRISM is a very handy supplement
        to Dublin Core and provides support for enumerated fields such as volume,
        issue, and page number. Another advantage for publishers was that PRISM is
        a simple term set and did not require any specialist library knowledge. A
        later paper by the same authors <a href=\"https://web.archive.org/web/20151003101404/http://www.dlib.org/dlib/december04/hammond/12hammond.html\">The
        Role of RSS in Science Publishing</a> published with <em><em>D-Lib Magazine</em></em>
        made a more in-depth review of RSS in scholarly publishing and concluded again
        that RSS 1.0 with its transparent support for new vocabularies such as PRISM
        was the right way to go.</p><p>We wanted to provide this standard article
        description that we were shipping with RSS also with OAI-PMH records. Unfortunately
        we could not simply move over the RDF properties into an OAI-PMH delivered
        RDF/XML payload. The problem with OAI-PMH is that it requires a record to
        be constrained by a W3C XML Schema. This is where <a href=\"https://web.archive.org/web/20151003101404/http://www.idealliance.org/industry_resources/intelligent_content_informed_workflow/about_the_prism_aggregator_message\">PRISM
        Aggregator Message</a> (PAM) comes in.</p><p>PAM is an application of PRISM
        and defines a W3C XML Schema for XML content aggregators to use. The message
        is simply structured as a sequence of one or more articles each with a body
        section for XHTML content and a head section with PRISM metadata. The body
        sections are optional so PAM can be used exclusively as a simple metadata
        packaging format as we have chosen to implement for OAI-PMH.</p><h3 id=\"3-how-does-pam-relate-to-the-nlm-dtd\">3.
        How does PAM relate to the NLM DTD?</h3><p>Well, both are schemas for content.
        This was my blind spot with regard to PAM for many years. Our focus was on
        metadata exchange. PRISM was a vocabulary for metadata, or rather a set of
        closely related vocabularies. No problem. And yet there was this thing called
        PAM which was busying itself with content. And we had no interest in that
        as we had our own Nature-specific DTD. But the PRISM folks were very enthusiastic
        \u2013 so clearly there was a need.</p><p>It only dawned on me relatively
        slowly that the PAM DTD (also available in W3C XML Schema form since PRISM
        2.0) was the correspondent of the NLM DTD in the scholarly world. It provides
        an interchange format for content elements. So the real impetus behind the
        development of the PRISM metadata vocabularies was as a direct support to
        XML content exchange although content is not actually required to be present
        and the metadata alone can be used in different applications.</p><h3 id=\"4-what-are-typical-use-cases-for-oai-pmh\">4.
        What are typical use cases for OAI-PMH?</h3><p>The main use of OAI-PMH is
        to sync, or perhaps a better term would be align, the holdings descriptions
        of digital repository collections, where the word \u201Crepository\u201D should
        be understood in its broadest context. The protocol exposes a machine interface
        for the robot harvesting of records from a data provider which a service provider
        will build upon to provide value add services. But this machine interface
        can sometimes also be accessed through a user interface (such as that provided
        by the Nature OAI-PMH service) which adds a browser onto the repository records.</p><p>For
        additional uses of OAI-PMH a good start point is the paper by Herbert Van
        de Sompel, Jeff Young and Thom Hickey in <em><em>D-Lib Magazine</em></em>
        on <a href=\"https://web.archive.org/web/20151003101404/http://www.dlib.org/dlib/july03/young/07young.html\">Using
        the OAI-PMH \u2026 Differently</a>. This paper notes that the metadata formats
        used by OAI-PMH are any that can validated by a W3C XML Schema and that therefore
        OAI-PMH is nothing less than \u201Ca medium for incremental, date-sensitive
        exchange of any form of semi-structured data\u201D. OAI-PMH clearly has legs.</p><h3
        id=\"5-why-should-researchers-care-about-oai-pmh\">5. Why should researchers
        care about OAI-PMH?</h3><p>I'm not sure that researchers should want to have
        any specific knowledge of OAI-PMH. Bear in mind that at heart this is an infrastructural
        technology which exists down in the data pipes and service conduits and is
        analogous to the fibre or radio channels that deliver broadband services to
        users.</p><p>Applications that make use of the syndicated metadata records
        that OAI-PMH provides for, however, are another matter. Those are very definitely
        things that researchers will care much about. It is difficult to distil those
        consumer applications into any specific categories as the services platform
        that OAI-PMH supports is very broad, ranging from general to domain-specific
        descriptions to full text records, and beyond.</p><h3 id=\"6-what-are-the-different-data-formats-that-descriptions-of-nature-com-articles-are-provided-how-do-they-differ\">6.
        What are the different data formats that descriptions of Nature.com articles
        are provided? How do they differ?</h3><p>At Nature Publishing Group we are
        working towards a common delivery architecture for our metadata. We are defining
        a core set of properties and making descriptions built from that property
        set available across multiple channels. Currently we are focussing on the
        basic bibliographic record which supports reference linking so that links
        can be made back to the platform. But once the channels are established they
        can be readily amplified to carry additional properties using the various
        channels' native packaging mechanisms. Metadata channels include both standalone
        services (e.g. RSS, OAI-PMH, etc.) as well as content objects themselves (HTML,
        PDF, etc.).</p><p>On the services side we began almost six years ago with
        RSS feeds, which being RSS 1.0 are full RDF/XML documents. The open data model
        implicit in RDF means that we can readily add new properties into our feeds.
        A case in point is the <a href=\"https://web.archive.org/web/20151003101404/http://www.iupac.org/inchi/\">InChI</a>
        identifier for chemical substances which we are currently working towards
        adding into our RSS feeds for <em><em>Nature Chemistry</em></em>, similarly
        to what the Royal Society of Chemistry has done earlier with their <a href=\"https://web.archive.org/web/20151003101404/http://www.rsc.org/Publishing/Journals/ProjectProspect/index.asp\">Project
        Prospect</a>.</p><p>We have just released our OAI-PMH service which provides
        the same basic property set as RSS but in PAM format \u2013 see the post <a
        href=\"https://web.archive.org/web/20151003101404/http://blogs.nature.com/wp/nascent/2009/05/a_catalog_for_naturecom.html\">A
        Catalog for Nature.com</a>. As alluded to above OAI-PMH comes from an earlier
        generation of protocols that put more rather emphasis on validation (or packaging
        the elements) than on data modelling (or relating the elements). That is,
        while the records served by the OAI-PMH server are validatable using W3C XML
        Schema the properties they contain are not directly reusable within an open,
        cross-application context such as is provided for by RDF. We do though have
        a simple stylesheet that can generate RDF/XML from these OAI-PMH records.</p><p>On
        the content side we added in the same properties to our HTML using META tags
        a year ago now \u2013 see the post <a href=\"https://web.archive.org/web/20151003101404/http://blogs.nature.com/wp/nascent/2008/05/naturecom_adds_metadata.html\">Nature.com
        adds metadata</a>. These properties are easily extractable by tools as simple
        key/value pairs. While this metadata is not directly representable as RDF
        it can be readily generated. We are anyway moving to make this property set
        more accessible by adding in <a href=\"https://web.archive.org/web/20151003101404/http://googlewebmastercentral.blogspot.com/2009/05/introducing-rich-snippets.html\">RDFa</a>
        which has now gone mainstream following Google's recent <a href=\"https://web.archive.org/web/20151003101404/http://googlewebmastercentral.blogspot.com/2009/05/introducing-rich-snippets.html\">announcement
        of rich snippets</a> and their <a href=\"https://web.archive.org/web/20151003101404/http://google.com/support/webmasters/bin/answer.py?hl=en&amp;answer=146898\">support
        for RDFa</a>.</p><p>We also began at the end of that year a programme to embed
        <a href=\"https://web.archive.org/web/20151003101404/http://www.adobe.com/products/xmp/\">XMP</a>
        packets into all of our newly published PDF files, again using the same basic
        property set \u2013 see the post <a href=\"https://web.archive.org/web/20151003101404/http://blogs.nature.com/wp/nascent/2008/12/xmp_labelling_for_nature.html\">XMP
        Labelling for Nature</a>. The XMP packets are essentially simple RDF/XML documents.</p><p>You
        can begin to see where all this is going. We are aiming to make all our descriptions
        conformant to a common data model, i.e. to RDF. That way, regardless of the
        distribution channel used the data delivered down that pipe can be merged
        into the common semantic graph.</p><h3 id=\"7-what-tools-can-researchers-use-to-retrieve-these-descriptions\">7.
        What tools can researchers use to retrieve these descriptions?</h3><p>Many
        of these channels are amenable to repurposing. The metadata they carry can
        be consumed within application-specific contexts, or it can be extracted from
        the channel medium for use in a wider generic context. Consider, for example,
        an RSS feed which can be used directly by a desktop or Web-based RSS reader.
        But it can also be mined for its metadata content, trivially in this case
        since the medium is already RDF/XML. Or consider again the metadata within
        an XMP packet in a PDF document which can be read by a viewer application
        (e.g. Adobe Acrobat) and presented to the user in a \u201CDocument Properties\u201D
        display. But it can also be extracted simply by locating the XMP packet and
        reading the single XML child element which is itself a full RDF/XML document.</p><p>So
        one could say there are two classes of tools, those that operate at an application
        or specific layer and those that operate at a more generic layer, albeit with
        some preprocessing steps to unpack the metadata.</p><p>I should really expand
        here on OAI-PMH specifically since this is new for us. The primary means of
        interacting with an OAI-PMH server is via its service endpoint. Obviously
        to manage pagination seamlessly (the resumption token provides a cursor into
        the result record set) a library or tool is of enormous assistance. The OAI
        website provides a reasonably full <a href=\"https://web.archive.org/web/20151003101404/http://www.openarchives.org/pmh/tools/tools.php\">listing
        of PMH tools</a> available.</p><p>Our OAI-PMH server implements Jeff Young's
        <a href=\"https://web.archive.org/web/20151003101404/http://www.oclc.org/research/software/oai/cat.htm\">OAICat</a>
        which is a Java servlet webapp providing a repository framework which also
        comes with a <a href=\"https://web.archive.org/web/20151003101404/http://www.nature.com/oai/\">forms
        interface</a> for testing. This interface is especially useful for occasional
        use, e.g. a single \u201C<em><em>GetRecord</em></em>\u201C:http://www.nature.com/oai/html/getRecord.html
        or call to \u201C<em><em>ListRecords</em></em>\u201C:http://www.nature.com/oai/html/listRecords.html
        (or \u201C<em><em>ListIdentifiers</em></em>\u201C:http://www.nature.com/oai/html/listIdentifiers.html),
        although repetitive calls to <em><em>ListRecords</em></em> (or <em><em>ListIdentifiers</em></em>)
        would quickly become tedious.</p><p>For harvesting we have used for testing
        purposes the <a href=\"https://web.archive.org/web/20151003101404/http://oai.rubyforge.org/\">ruby-oai</a>
        gem for Ruby by Ed Summers and Will Groppe which includes a library and simple
        client which can also be run interactively as a shell. Note that this gem
        is not listed on the OAI-PMH tools page.</p><p>We have also made use of the
        open-source Java client <a href=\"https://web.archive.org/web/20151003101404/http://www.oclc.org/research/software/oai/harvester2.htm\">OAIHarvester2</a>,
        again by Jeff Young of OCLC. We used this for test harvesting of our full
        record collection as it was a robust implementation and we had earlier run
        into some problems with the Ruby app as it is not as finished as it might
        be, although it remains very configurable and easy to use. Our intention is
        to proceed with the Ruby app for incremental harvesting. We're aiming to become
        consumers of our own services for quality control purposes.</p><h3 id=\"8-what-are-your-responsibilities-at-nature-com\">8.
        What are your responsibilities at Nature.com?</h3><p>I work within the Platform
        Technologies group on infrastructural projects supporting discovery and access
        across the nature.com platform, especially those that are built upon open
        technologies. My job handle is <em><em>Application Architect</em></em> although
        we're working on deconstructing that. I don't have line responsibilities but
        do supervise the development of our new interfaces.</p><p>We are corralling
        these various standards \u2013 some come from the wider Web world, some from
        the digital library community, some come from industry, and some are closer
        to home \u2013 under the general moniker of <a href=\"https://web.archive.org/web/20151003101404/http://www.nature.com/libraries/public_interfaces/index.html\">Public
        Interfaces</a>. We also have a new documentation centre for this which is
        located on our <a href=\"https://web.archive.org/web/20151003101404/http://www.nature.com/libraries/index.html\">Librarian
        Gateway</a>.</p><p>I do maintain an active presence with various external
        bodies, not unsurprisingly given that the focus of my work is on defining
        and building interfaces. I have been from the beginning very involved in <a
        href=\"https://web.archive.org/web/20151003101404/http://www.crossref.org/\">CrossRef</a>
        and the development of <a href=\"https://web.archive.org/web/20151003101404/http://www.doi.org/\">DOI</a>
        and related technologies. Most recently I have worked with a CrossRef WG to
        draw up a best practices document for scholarly publishers and RSS, and we
        are now starting work on a companion document for embedding metadata. I am
        also on the <a href=\"https://web.archive.org/web/20151003101404/http://www.idealliance.org/industry_resources/intelligent_content_informed_workflow/prism/membership\">PRISM
        WG</a> and a regular contributor.</p><p>Other activities I'm involved with
        include being a member of the <a href=\"https://web.archive.org/web/20151003101404/http://www.loc.gov/standards/sru/\">SRU</a>
        Editorial Board and of the eJournal Joint Technical Panel on <a href=\"https://web.archive.org/web/20151003101404/http://www.bl.uk/aboutus/stratpolprog/legaldep/\">Legal
        Deposit</a> here in the UK. I have previously been a member of the OpenURL
        Standard Committe that developed <a href=\"https://web.archive.org/web/20151003101404/http://www.niso.org/standards/z39-88-2004/\">ANSI/NISO
        Z39.88</a>, and worked as a member of the <a href=\"https://web.archive.org/web/20151003101404/http://www.openarchives.org/ore/\">OAI-ORE</a>
        TC and the JISC <a href=\"https://web.archive.org/web/20151003101404/http://www.jisc.ac.uk/aboutus/committees/workinggroups/palsmetadatagroup.aspx\">PALS
        Metadata and Interoperability WG</a>.</p><h3 id=\"9-what-did-you-do-before-starting-to-work-for-nature-com\">9.
        What did you do before starting to work for Nature.com?</h3><p>Before working
        with Nature I was with Elsevier (2001-2004) as part of their Advanced Technology
        Group, and prior to that I worked with Academic Press (1997-2001) as Head
        of the Online Resource Activity. With Academic Press I was part of Electronic
        Publishing team that managed IDEAL \u2013 one of the first successful large
        journals platforms that applied consortial site licenses.</p><p>My previous
        experiences included a long-ish stint (1986-1995) with NATO SACLANTCEN in
        La Spezia, Italy, as Scientific Editor and subsequently as Head of the Information
        Branch. The facility was named SACLANT ASW Research Centre when I joined and
        had been transmuted into NATO Undersea Research Centre by the time I left
        (the anti-submarine warfare aspect deftly tidied away). Same mission though,
        to work on basic research (from oceanography to operational research) that
        would aid the NATO nations in their submarine detection programmes. (It now
        seems to be commuted to NURC alone.)</p><p>Prior to that I worked (1982-1985)
        as Assistant to the Editors for the North-Holland Publishing Company journal
        <em><em>Nuclear Physics A</em></em> based in Copenhagen, Denmark, and previous
        to that as a Research Associate in the Space Physics Laboratory at the University
        of Kent at Canterbury, UK where I collaborated in building a micrometeoroid
        sensor experiment which was deployed by the Space Shuttle.</p><h3 id=\"10-do-you-want-to-talk-about-future-plans-for-metadata-at-nature-com\">10.
        Do you want to talk about future plans for metadata at Nature.com?</h3><p>Sure.
        I guess I should separate out metadata management per se from metadata delivery
        and discovery. As a company we have an active programme underway to review
        wholesale our various ontologies and vocabularies in order to coordinate and
        streamline them. We also have ongoing initiatives to add in text mining to
        our production workflow and to address the entity extraction problem. Having
        better and richer vocabularies and new terms is one step. The next step is
        how to communicate that value in an open and structured manner to consumer
        applications.</p><p>My particular focus is on delivery channels. As I mentioned
        earlier we are working towards providing a notion of public interfaces: a
        set of open interfaces for delivering standard object descriptions. Complementing
        the OAI-PMH service which provides a catalog for nature.com we are also currently
        working on an SRU (<a href=\"https://web.archive.org/web/20151003101404/http://www.loc.gov/standards/sru/\">Search
        and Retrieve by URL</a>) service to support structured searching. And that
        would also be accessible through simple <a href=\"https://web.archive.org/web/20151003101404/http://www.opensearch.org/\">OpenSearch</a>
        conventions.</p><p>We will be extending our page markup to include <a href=\"https://web.archive.org/web/20151003101404/http://www.w3.org/TR/rdfa-syntax/\">RDFa</a>
        which will not only provide metadata in RDF format but will also localize
        those descriptions to the content fragment so that cut-and-paste operations
        will scoop up any descriptive markup along with the actual content.</p><p>We
        are now close to completing our support across our full title range for <a
        href=\"https://web.archive.org/web/20151003101404/http://www.adobe.com/products/xmp/\">XMP</a>
        in PDFs. A related development will be to embed XMP into our images (JPEGs
        and GIFs) so that all of our main resources then become self-describing. It
        is a wonder that we have gotten thus far in online publishing sending out
        content entities which are not unambiguously labelled.</p><p>And beyond this
        all lie the promises and challenges of the Semantic Web.</p><figure class=\"kg-card
        kg-image-card\"><img src=\"https://web.archive.org/web/20151003101404im_/http://www.linkwithin.com/pixel.png\"
        class=\"kg-image\" alt=\"Related Posts Plugin for WordPress, Blogger...\"
        loading=\"lazy\"></figure> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ What is the right reference manager for
        you? ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/what-is-the-right-reference-manager-for-you/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw3s</id>\n        <published>2009-05-17T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-13T13:49:22.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Reference managers are essential
        tools to read and write scholarly papers. In the last few years we have seen
        both a number of new reference managers (most of them web-based), but also
        a trend for the established reference managers to gain social networking features.
        More choice is great, but it also creates confusion about the right tool to
        use. I have talked about reference managers <a href=\"https://web.archive.org/web/20151002030110/http://network.nature.com/people/mfenner/blog/2009/03/15/reference-manager-overview\">before</a>,
        but in this slideshow I look at the features that I find important.</p><p>And
        there are at least two features that I like, but haven't really seen implemented
        in a reference manager:</p><ul><li><em><em>Integration of an RSS reader for
        journal table of contents (TOC)</em></em>. Currently I use a standard RSS
        reader, and it requires too many steps to get interesting references from
        a TOC into my reference manager.</li><li><em><em>Tracking the post-publication
        discussion</em></em>. I want my reference manager to link to the papers that
        cite a particular reference (I currently use <a href=\"https://web.archive.org/web/20151002030110/http://www.scopus.com/\">Scopus</a>
        for that) and link to <a href=\"https://web.archive.org/web/20151002030110/http://network.nature.com/people/mfenner/blog/2009/04/28/faculty-of-1000-interview-with-richard-grant\">Faculty
        of 1000</a> or <a href=\"https://web.archive.org/web/20151002030110/http://researchblogging.org/\">ResearchBlogging.org</a>
        comments on that paper.</li></ul><p>In the last slide I wonder whether there
        is a) one perfect reference manager, b) one perfect reference manager for
        my particular needs, or c) I will always need more than one reference manager
        and have to move references back and forth between them. Currently I'm at
        c), using mostly Papers, Endnote and Connotea. But Mendeley, Zotero, Refworks
        and Endnote are moving in a direction where they try to cover all requirements.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ eXtyles: Interview with Elizabeth Blake
        and Bruce Rosenblum ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/xtyles-interview-with-elizabeth-blake-and-bruce-rosenblum/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw3t</id>\n        <published>2009-05-01T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-13T15:34:52.000+00:00</updated>\n\t\t<category
        term=\"Interview\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Scientific
        papers are submitted to a journal as word processor files, usually in Microsoft
        Word format. After the paper is accepted for publication, the journal takes
        the manuscript and translates the text into a format that is better suited
        for publication online and/or in print. XML and the <a href=\"https://web.archive.org/web/20151002164418/http://dtd.nlm.nih.gov/\">NLM
        DTD</a> \u2013 a set of XML schema modules \u2013 have evolved as the standard
        data format for this purpose. Files in the NLM DTD format can in turn be translated
        into HTML and/or PDF for publication. The NLM DTD format is also used to transfer
        journal articles from publishers to archives (e.g. <a href=\"https://web.archive.org/web/20151002164418/http://www.pubmedcentral.nih.gov/\">PubMed
        Central</a>) and for long-term archiving.</p><p><a href=\"https://web.archive.org/web/20151002164418/http://www.inera.com/extylesinfo.shtml\">eXtyles</a>
        is a tool that facilitate the translation between these different document
        formats, and in the process also help to clean up broken references and other
        errors in the manscript. As paper authors usually don\u2019t see much of what
        happens to their manuscript after submission, I thought I\u2019d ask Elizabeth
        Blake and Bruce Rosenblum from <a href=\"https://web.archive.org/web/20151002164418/http://www.inera.com/\">Inera</a>
        (the company behind eXtyles) a few questions.</p><h3 id=\"1-can-you-describe-what-extyles-is-and-does\">1.
        Can you describe what eXtyles is and does?</h3><p>Elizabeth Blake: <a href=\"https://web.archive.org/web/20151002164418/http://www.inera.com/\">Inera</a>
        offers several <a href=\"https://web.archive.org/web/20151002164418/http://www.inera.com/extylesinfo.shtml\">eXtyles
        products</a>, all of which are designed to clean up, structure, validate,
        and export scholarly content. The desktop version of eXtyles is the most widely
        used product; it\u2019s a plug-in to Microsoft Word that is customized according
        to the editorial style and production requirements of each publisher that
        uses it. eXtyles:</p><ul><li>collects and exports manuscript metadata</li><li>cleans
        up extraneous or incorrect document formatting</li><li>applies structure to
        the document on the paragraph and character level (using author- and editor-friendly
        Word styles rather than visually intrusive tags)</li><li>automatically enforces
        certain editorial style requirements through large-scale, context-sensitive
        find and replace</li><li>parses, restructures, links, and corrects bibliographic
        references using internal templates and databases as well as external sources
        such as <a href=\"https://web.archive.org/web/20151002164418/http://www.ncbi.nlm.nih.gov/sites/entrez\">PubMed</a>
        and <a href=\"https://web.archive.org/web/20151002164418/http://www.crossref.org/\">CrossRef</a></li><li>links
        citations and callouts to their respective references and objects</li><li>exports
        high-quality XML from Word according to the <a href=\"https://web.archive.org/web/20151002164418/http://dtd.nlm.nih.gov/\">NLM
        DTD</a> or any other DTD required by the publisher</li></ul><p>eXtyles is
        a uniquely flexible tool in that it can accommodate any editorial style and
        the wide variety of workflows used by different publishers, and it can also
        process any Word-readable, author-submitted manuscript.</p><h3 id=\"2-what-is-the-difference-between-extyles-and-the-microsoft-word-article-authoring-add-in\">2.
        What is the difference between eXtyles and the <a href=\"https://web.archive.org/web/20151002164418/http://www.microsoft.com/mscorp/tc/scholarly_communication.mspx#Tools\">Microsoft
        Word Article Authoring Add-in</a> ?</h3><p><em><em>Bruce Rosenblum:</em></em>
        eXtyles makes two assumptions. First, eXtyles does not rely on the author
        to complete document structuring tasks \u2013 in our experience, journals
        have not succeeded in having authors provide sufficiently accurate styling
        or markup in Word files (the application used by most scholarly authors) to
        allow for automatic creation of high-quality XML. Second, eXtyles assumes
        that authors make other kinds of mistakes, whether adding inappropriate formatting,
        using unsupported fonts for special characters, or making informational errors
        in reference lists, and all of these problems must be corrected as part of
        the publishing process.</p><p>eXtyles is designed to overcome the limitations
        of how authors commonly prepare manuscripts by providing the tools that publishers
        need to clean up, rapidly edit, and then convert manuscripts to XML. eXtyles
        has been carefully developed over ten years to accurately address the reality
        of what publishers see in author submissions.</p><p>By contrast, the Microsoft
        Word Article Authoring Add-in has been developed as a content creation tool.
        It is designed for authors to structure articles in Word 2007 as they write.
        In this model, authors must add structural information rather than just submit
        the text of their article. The Add-in assumes authors will create reference
        lists with the <a href=\"https://web.archive.org/web/20151002164418/http://office.microsoft.com/en-us/word/HA100674921033.aspx\">Word
        2007 citation manager</a> and will adhere to all requirements necessary to
        successfully save the manuscript to NLM DTD XML when they have completed writing
        their article. Also, the Microsoft Add-in does not provide tools to prepare
        an article for XML conversion if the Add-in was not used during creation of
        the article, which is a key feature of eXtyles.</p><p>Fundamentally the target
        audience differs: the Microsoft Add-in assumes use by authors, whereas eXtyles
        provides tools to publishing personnel that allow authors to concentrate on
        great scientific research rather than the technical aspects of article publication.</p><h3
        id=\"3-what-are-the-most-common-problems-in-submitted-manuscripts-that-can-be-fixed-by-extyles-are-there-problems-that-have-to-be-fixed-manually\">3.
        What are the most common problems in submitted manuscripts that can be fixed
        by eXtyles? Are there problems that have to be fixed manually?</h3><p><em><em>Elizabeth
        Blake:</em></em> The most common problems range from relatively simple issues
        such as extraneous formatting or misapplied styles to more complex issues
        such as missing data or incorrect or uncited references. Hovering in between
        these are violations of editorial style \u2013 for example, British versus
        American spelling or non-standard abbreviations for units of measure \u2013
        which eXtyles can also correct.</p><p>Some problems do have to be fixed manually.
        eXtyles does not take the place of an editor; rather, it automates as much
        of the low-level copy editing as can be reliably automated while drawing the
        editor\u2019s attention to issues that require follow up. An example would
        be eXtyles flagging a callout to a table that is missing from the manuscript;
        this obviously requires human intervention, but the warning saves time and
        flags problems early in the workflow when they are easier to resolve.</p><p>On
        a larger scale, the problem eXtyles is designed to solve is getting the accepted
        author manuscript published as quickly and accurately as possible. The fully
        eXtyled file can be flowed into a typesetting system such as InDesign with
        the paragraph styles aligned to the composition template, saving a lot of
        labor during the typesetting stage, or the Word file can be converted directly
        to NLM XML with the push of a button, allowing users to create rich, valid
        XML without any XML knowledge or expertise.</p><h3 id=\"4-extyles-helps-with-editorial-tasks-such-as-document-cleanup-and-citation-checking-why-shouldn-t-these-tasks-be-left-to-the-authors-and-checked-when-a-manuscript-is-submitted\">4.
        eXtyles helps with editorial tasks such as document cleanup and citation checking.
        Why shouldn\u2019t these tasks be left to the authors and checked when a manuscript
        is submitted?</h3><p><em><em>Elizabeth Blake:</em></em> Theoretically these
        tasks are the authors\u2019 responsibility! In practice it is an extremely
        rare manuscript that doesn\u2019t have errors, particularly reference errors.
        Our goal is not to discourage authors from submitting clean and accurate manuscripts;
        our goal is to facilitate the process when that doesn\u2019t happen, which
        is most of the time. The eXtyles reference-processing tools, in particular
        the tools that link and correct references with data retrieved from PubMed
        and CrossRef, go a step beyond what even a very thorough copy editor is typically
        able to flush out given the time constraints of a deadline-driven workflow.</p><p>As
        for performing these tasks at submission, the eXtyles integration with <a
        href=\"https://web.archive.org/web/20151002164418/http://www.editorialmanager.com/homepage/home.htm\">Editorial
        Manager</a> does just that, providing an informative reference quality check
        early in the workflow so that responsibility for fixing the references can,
        if the publisher prefers, be pushed back on the authors.</p><h3 id=\"5-if-extyles-validates-and-corrects-references-why-do-most-journals-insist-on-bibliographies-formatted-in-a-specific-house-style\">5.
        If eXtyles validates and corrects references, why do most journals insist
        on bibliographies formatted in a specific house style?</h3><p><em><em>Elizabeth
        Blake:</em></em> There are two ways in which eXtyles corrects references:
        one is by correcting the data (e.g., PubMed reports that the first author
        in reference 2 is incorrect) and the other is by correcting the format according
        to the publisher\u2019s house style. Ensuring correct data in a reference,
        which eXtyles does with <a href=\"https://web.archive.org/web/20151002164418/http://www.inera.com/refcorrection.shtml\">Automatic
        Reference Correction</a>, is part of ensuring accuracy in the scientific record.
        As for the varieties of reference styles, many developed as necessary elements
        of print publication \u2013 for instance, some abbreviated house styles were
        devised as paper-saving measures. So long as print is not dead, these concerns
        are still relevant. However, in an electronic world, formatting of references
        may be less important, though a good editor will always have an argument for
        why their style is preferable (I say that as a former editor). We at Inera
        remain neutral on the topic since eXtyles can reformat references according
        to any preferred editorial style if a publisher requires it.</p><h3 id=\"6-what-is-the-nlm-dtd-what-was-your-part-in-developing-it\">6.
        What is the NLM DTD? What was your part in developing it?</h3><p>Bruce Rosenblum:
        The <a href=\"https://web.archive.org/web/20151002164418/http://dtd.nlm.nih.gov/\">NLM
        DTD</a> is a family of tag sets designed for full-text XML markup of scholarly
        articles. The intent of the NLM DTD Suite is to mark up and preserve the intellectual
        content of journals independent of the form in which the content is delivered.
        <a href=\"https://web.archive.org/web/20151002164418/http://dtd.nlm.nih.gov/faq.html\">The
        suite can be used to publish and archive journal content, and to facilitate
        content interchange between organizations</a>. And despite the NLM moniker,
        the suite was designed from day-one for full-text markup of journal content
        in any discipline.</p><p>Our work on the NLM DTD started in 2001 when the
        <a href=\"https://web.archive.org/web/20151002164418/http://lib.harvard.edu/\">Harvard
        University Library</a>, under a <a href=\"https://web.archive.org/web/20151002164418/http://www.mellon.org/\">Mellon
        Foundation</a> grant, was asked to study formats for long-term archiving of
        eJournal content. Harvard decided that PDF was not a viable archive format,
        and discovered that every publisher had a proprietary DTD. Harvard then approached
        Inera, because of our experience working with many DTDs including <a href=\"https://web.archive.org/web/20151002164418/http://download.www.techstreet.com/cgi-bin/pdf/free/228869/12083-a.pdf\">ISO
        12083</a>, to study the feasibility of developing a single DTD into which
        the content from all publishers could be converted for the purposes of long-term
        archiving. The <a href=\"https://web.archive.org/web/20151002164418/http://www.diglib.org/preserve/hadtdfs.pdf\">e-Journal
        Archjive DTD Feasibility Study</a> we wrote describes the requirements for
        such a DTD.</p><p>At the same time, NLM was making major revisions to the
        <a href=\"https://web.archive.org/web/20151002164418/http://www.pubmedcentral.nih.gov/\">PubMed
        Central</a> 1.0 DTD. NLM, Harvard, and Mellon decided to combine resources
        on a single project co-developed by NLM, <a href=\"https://web.archive.org/web/20151002164418/http://www.mulberrytech.com/\">Mulberry
        Technologies</a>, and Inera. Version 1.0 of the NLM DTD was released in April
        2003. The scope of use was originally focused on the needs of PubMed Central,
        and a long-term archive (now <a href=\"https://web.archive.org/web/20151002164418/http://www.portico.org/\">Portico</a>)
        seed-funded by the Mellon Foundation.</p><p>The NLM DTD was quickly adopted
        by others when they discovered the coverage and flexibility. And as publishers
        switched from SGML to XML, they found that adopting an off-the-shelf public
        DTD was far less expensive than converting their existing SGML DTDs to XML.
        As use has expanded, support has grown so that many off-the-shelf solutions
        are now available for working with the DTD. Inera continues to serve on the
        <a href=\"https://web.archive.org/web/20151002164418/http://dtd.nlm.nih.gov/working-group.html\">NLM
        DTD Advisory Board</a>.</p><h3 id=\"7-how-does-extyles-use-the-nlm-dtd\">7.
        How does eXtyles use the NLM DTD?</h3><p><em><em>Bruce Rosenblum:</em></em>
        eXtyles users, with no knowledge of XML, can create high-quality XML according
        to the NLM DTD as a simple one-button action after using eXtyles to easily
        complete editorial preparation of a manuscript. In other words, eXtyles XML
        creation is a natural by-product of normal manuscript preparation for publication,
        and it requires no specialized user knowledge.</p><p>Because eXtyles was developed
        as an open platform that can be customized to the editorial and production
        needs of any publisher, it is internally DTD agnostic. In this regard, eXtyles
        can be used to convert content to any of the DTDs in the NLM DTD Suite (<a
        href=\"https://web.archive.org/web/20151002164418/http://dtd.nlm.nih.gov/publishing/\">Journal
        Publishing</a>, <a href=\"https://web.archive.org/web/20151002164418/http://dtd.nlm.nih.gov/archiving/\">Archive
        and Interchange</a>, or <a href=\"https://web.archive.org/web/20151002164418/http://dtd.nlm.nih.gov/book/\">Book</a>).</p><p>Furthermore,
        the NLM DTD suite actually allows for a wide range of interpretation, and
        eXtyles can easily meet any of those interpretations. For example, the NLM
        DTD supports two table models, XHTML and <a href=\"https://web.archive.org/web/20151002164418/http://dtd.nlm.nih.gov/options/OASIS/tag-library/19990315/n-xe20.html\">CALS</a>.
        eXtyles can produce content in either table model, depending on the workflow
        requirements of the publisher. A wide range of other configuration options
        are available to meet the needs of specific publisher requirements.</p><h3
        id=\"8-can-the-nlm-dtd-also-used-by-authors-to-submit-their-papers-to-journals-or-repositories-if-not-what-are-the-limitations\">8.
        Can the NLM DTD also used by authors to submit their papers to journals or
        repositories? If not, what are the limitations?</h3><p><em><em>Bruce Rosenblum:</em></em>
        In theory authors could submit their papers to journals or repositories in
        XML. However, in practice this has not occurred and we do not consider it
        likely to occur in the near future. There are a few key obstacles.</p><p>First,
        the primary job of researchers is to conduct research and report the results.
        Because technical knowledge of publishing formats is not a required part of
        the typical researcher\u2019s job, the majority of researchers do not submit
        papers to journals or repositories in XML when they can much more easily do
        so in PDF or Word.</p><p>By extension of this point, most publishers are interested
        in high-quality research. One publisher told us, \u201CIf a manuscript with
        great science is submitted on birch bark, we\u2019ll find a way to publish
        it.\u201D We believe that in a world where journals compete for the best papers,
        publishers will continue to put research quality ahead of submission formats.</p><p>Second,
        creation of high-quality XML is just not that simple. Even with the tools
        that have been developed in the past ten years, publishers with experienced
        editorial and production teams still have problems producing consistently
        high-quality XML; if you doubt this point, please look at a typical first
        round PubMed Central publisher validation report. If publishers with experienced
        production teams do not find this easy, then we believe that production of
        consistently high-quality XML by authors is not likely to occur in the next
        few years.</p><h3 id=\"10-what-are-your-responsibilities-at-inera\">10. What
        are your responsibilities at Inera?</h3><p><em><em>Bruce Rosenblum:</em></em>
        As CEO, I am involved in all aspects of Inera. My background is originally
        in software development, and I use this expertise to guide the development
        and quality assurance of eXtyles. I am also responsible for managing the business
        side of Inera. But probably my most important role is coordinating the incredibly
        creative team of people who work on eXtyles.</p><p><em><em>Elizabeth Blake:</em></em>
        My role is primarily customer facing, from marketing to configuration and
        training up through support. My goal is to ensure that potential customers
        get all the information they need about eXtyles to make the right decision
        and to ensure that, once they become customers, they continue to be happy
        with that decision. We rely heavily on customer feedback when planning enhancements
        to eXtyles, and I tend to focus on the user experience when we work through
        the details of any new project.</p><h3 id=\"11-what-did-you-do-before-starting-to-work-on-extyles\">11.
        What did you do before starting to work on eXtyles?</h3><p><em><em>Bruce Rosenblum:</em></em>
        Before eXtyles, Inera spent years providing SGML and XML consulting and software
        development services to publishers. Prior to that, I spent 15 years developing
        commercial software products for companies like Microsoft, Word Perfect, Houghton
        Mifflin, and Broderbund. Going way back, I\u2019ve always had an interest
        in problems of working with text \u2013 my first professional software project
        was building a word processor for Chinese on an Apple II in 1980.</p><p><em><em>Elizabeth
        Blake:</em></em> I started in scholarly publishing as a copy editor for the
        Cell Press journal <em><em>Neuron</em></em> and then worked as the managing
        editor of <em><em>Neuron</em></em> for several years before moving to <em><em>The
        New England Journal of Medicine</em></em>. At Inera, my years of real-world
        editorial and production experience have been very valuable and help to ensure
        that eXtyles development is centered on solving the problems that publishers
        face every day.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Faculty of 1000: Interview with Richard
        Grant ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/faculty-of-1000-interview-with-richard-grant/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw3v</id>\n        <published>2009-04-28T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T07:33:56.000+00:00</updated>\n\t\t<category
        term=\"Interview\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/f353fdfe5c24bfb525680563a4a5c04b3760fafd.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/f353fdfe5c24bfb525680563a4a5c04b3760fafd.jpeg\"></p><p><a
        href=\"https://web.archive.org/web/20151003075116/http://network.nature.com/people/rpg/blog\">Richard
        Grant</a>, who needs no introduction here on Nature Network, has just moved
        to London <a href=\"https://web.archive.org/web/20151003075116/http://network.nature.com/people/rpg/blog/2009/04/09/on-the-payroll\">to
        start a new job</a> as <em><em>information architect</em></em> for <a href=\"https://web.archive.org/web/20151003075116/http://www.f1000biology.com/\">Faculty
        of 1000</a>. I took this opportunity to ask Richard a few questions not only
        about Faculty of 1000, but also about his role in the company and future plans
        for the service that they have in mind.</p><h3 id=\"1-can-you-describe-what-faculty-of-1000-is-and-does\">1.
        Can you describe what Faculty of 1000 is and does?</h3><p>The scientific literature
        is immense, and growing. It has become very difficult to keep up, especially
        if you\u2019re going to keep an eye on developments not immediately in your
        own area. For someone new to a field it\u2019s almost impossible to know \u2014
        without insider knowledge \u2014 what papers are important, which are the
        key publications; where a field is going and what are the key developments.</p><p>So
        what we do is provide a kind of \u2018filter\u2019 on top of the literature:
        we have about five thousand principle investigators, who we call \u2018Faculty\u2019,
        across biology and medicine, who in the course of their own reading will write
        short evaluations on the important and influential papers in their field.
        We\u2019re also recruiting <a href=\"https://web.archive.org/web/20151003075116/http://www.f1000biology.com/about/associateFMs\">Associate
        Faculty members</a>: trusted junior members of a Faculty member\u2019s lab
        or practice who will write their own evaluations and increase our coverage.
        And we\u2019re not just talking about stuff that\u2019s published in <em><em>Nature</em></em>
        or <em><em>Cell</em></em> \u2014 or <em><em>NEJM</em></em> or <em><em>The
        Lancet</em></em> \u2014 but in the specialized, work-a-day journals. What\u2019s
        more, this expert opinion, or what we\u2019re calling \u2018post-publication
        peer review\u2019, gives our users a measure of the \u2018quality\u2019 of
        individual papers that is independent of, and much quicker than, the impact
        factor of the journal.</p><h3 id=\"2-what-part-of-faculty-of-1000-is-free-and-what-part-needs-a-paid-subscription\">2.
        What part of Faculty of 1000 is free and what part needs a paid subscription</h3><p>You
        can search or browse the entire database, and sign up for email alerts, so
        you can see which papers have been evaluated. You can\u2019t actually read
        the evaluations themselves unless you have an institutional or personal subscription.</p><h3
        id=\"3-how-does-faculty-of-1000-integrate-with-reference-managers-such-as-endnote-refworks-zotero-or-connotea\">3.
        How does Faculty of 1000 integrate with reference managers such as Endnote,
        Refworks, Zotero or Connotea?</h3><p>You can download evaluations into a reference
        manager just like you can papers from PubMed. We\u2019re working on proper
        integration with online tools (such as <a href=\"https://web.archive.org/web/20151003075116/http://www.citeulike.org/\">CiteULike</a>
        and <a href=\"https://web.archive.org/web/20151003075116/http://www.connotea.org/\">Connotea</a>)
        and other \u2018social media\u2019 tools. I\u2019m also keen to work with
        <a href=\"https://web.archive.org/web/20151003075116/http://www.mendeley.com/\">Mendeley</a>
        to improve the user experience.</p><h3 id=\"4-what-are-the-incentives-for-faculty-members-to-evaluate-papers\">4.
        What are the incentives for faculty members to evaluate papers?</h3><p>Exposure
        and kudos, mainly! The Faculty member\u2019s name is displayed prominently
        on the evaluations (you can see who\u2019s written an evaluation even without
        a subscription). Reputation is important to scientists and being invited to
        become a Faculty member says to the rest of the community that your opinion
        is respected and your peers think highly of you. We also profile Faculty members
        who write timely or important evaluations, or who have news of their own (grants,
        papers, awards) and give them publicity through press releases, etc.</p><p>What\u2019s
        more, our Faculty members <em><em>like</em></em> the combination of expert
        opinion and original articles. They see a value in it, and realize that there\u2019s
        a kind of synergy going on here; if they contribute then others will be encouraged
        to too, and everybody wins.</p><p>I\u2019d like to explore how evaluations
        might become citable \u2014 so that Faculty can put their work for us on their
        CV, how it might benefit their career, grant applications etc. We\u2019re
        also considering more tangible benefits.</p><h3 id=\"5-how-are-faculty-members-selected\">5.
        How are faculty members selected?</h3><p>The Heads of Faculty, for each subject
        or speciality, are elected or selected on the recommendation of large numbers
        of medics and scientists we talk to. They divide their Faculty into Sections
        and then select two or three Section Heads. These scientists in turn identify
        the sub-fields within their Section and select Faculty Members, checking with
        Heads of Faculty. The Section Heads select Faculty Members on the basis of
        various criteria:</p><ul><li>the number of Faculty Members should be proportionally
        representative of the number of papers published within that field;</li><li>the
        selected Faculty Members should be well respected by their peers and perceived
        as being fair-minded;</li><li>there must be a good representation of genders,
        nationalities and age/seniority.</li></ul><p>Faculty Members themselves are
        being asked to co-opt younger workers within their groups \u2014 post-docs,
        say \u2014 to help increase coverage and to write their own evaluations. We
        call these \u2018Associate Faculty\u2019.</p><h3 id=\"6-can-faculty-of-1000-users-comment-on-papers-or-paper-evaluations\">6.
        Can Faculty of 1000 users comment on papers or paper evaluations?</h3><p>Not
        at the moment, no. Faculty members can comment, or contribute a \u2018dissent\u2019
        if they disagree with an evaluation, and authors of the evaluated papers are
        encouraged to respond, but we feel it\u2019s important for users to know that
        they can trust what we publish. However, we\u2019re currently planning to
        launch a forum whereby users <em><em>can</em></em> comment freely on evaluated
        papers. This would be open to anyone who registers, without a subscription,
        but kept distinct from the main evaluation.</p><h3 id=\"7-can-paper-authors-comment-on-evaluations-of-their-papers\">7.
        Can paper authors comment on evaluations of their papers?</h3><p>Yes! At the
        moment we get emails from authors saying that they\u2019re pleased to have
        their papers selected, but we\u2019re going to make it possible for them to
        comment on the evaluations directly so that a conversation with the Faculty
        can be initiated.</p><h3 id=\"8-what-is-faculty-of-1000-reports\">8. What
        is Faculty of 1000 Reports?</h3><p>F1000 Reports carries short reviews, or
        commentaries, on emerging trends identified from within the F1000 database.
        <a href=\"https://web.archive.org/web/20151003075116/http://f1000medicine.com/reports/\">F1000
        Medicine Reports</a> features studies that are likely to change clinical practice
        and summarizes implications for clinicians. <a href=\"https://web.archive.org/web/20151003075116/http://www.f1000biology.com/reports/\">F1000
        Biology Reports</a> contextualizes important and exciting papers or clusters
        of publications. The Advisory Board (for <a href=\"https://web.archive.org/web/20151003075116/http://f1000biology.com/reports/advisoryboard\">F1000
        Biology Reports</a> and <a href=\"https://web.archive.org/web/20151003075116/http://f1000medicine.com/reports/advisoryboard\">F1000
        Medicine Reports</a>) identifies potential topics and invites appropriate
        Faculty members to write about them.</p><h3 id=\"9-what-are-your-responsibilities-at-faculty-of-1000\">9.
        What are your responsibilities at Faculty of 1000?</h3><p>Well, my job title
        is \u2018Information Architect\u2019, which means quite a bit more than \u2018web
        manager\u2019. I have overall responsibility for the presentation of the F1000
        service, and I have to ensure that the web site is fast and intuitive, and
        that the content is suitable for both medics and biologists. I\u2019m also
        keen to keep F1000 relevant in the Web 2.0 world.</p><h3 id=\"10-what-did-you-do-before-starting-to-work-for-faculty-of-1000\">10.
        What did you do before starting to work for Faculty of 1000?</h3><p>I was
        at the University of Sydney for three years, the token cell biologist in an
        NMR lab, looking at RNA-binding zinc fingers. Before that I was at the MRC-LMB
        in Cambridge for six years, learning how to do X-ray crystallography and NMR
        and applying those techniques to cell biological questions.</p><h3 id=\"11-do-you-want-to-talk-about-future-plans-for-faculty-of-1000\">11.
        Do you want to talk about future plans for Faculty of 1000?</h3><p>As I\u2019ve
        sorted of already hinted, we\u2019re in the middle of a major redesign. We
        have some new features that I hope you\u2019ll find very exciting \u2014 one
        of which I really can\u2019t talk about yet! \u2014 including forums, a re-vamped
        \u2018MyF1000\u2032 site, integration of F1000 Reports, more systematic literature
        scanning, talking to social media sites, RSS (at last!), a blog, and a lot
        of behind the scenes tweaks.</p><h3 id=\"12-where-can-we-provide-feedback-about-faculty-of-1000\">12.
        Where can we provide feedback about Faculty of 1000?</h3><p>Write to me! Or
        email info@f1000.com. The new site will also have a feedback form.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ A few questions about author identifiers:
        the answers ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/a-few-questions-about-author-identifiers-the-answers/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw3w</id>\n        <published>2009-04-26T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T07:38:19.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>I've recently asked <a href=\"https://web.archive.org/web/20150922174131/http://network.nature.com/people/mfenner/blog/2009/04/13/a-few-questions-about-author-identifiers\">a
        few questions about author identifiers for scientists</a>. Here are the results
        (based on 48 responses). The results are also available as <a href=\"https://web.archive.org/web/20150922174131/http://spreadsheets.google.com/pub?key=rpPHC7BnyO2VJPglm246fKA&amp;output=xls\">.xls
        file</a>.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Popularity of online reference managers
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/popularity-of-online-reference-managers/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw3x</id>\n        <published>2009-04-18T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-31T07:52:24.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Now that we have a <a href=\"https://web.archive.org/web/20151003053433/http://network.nature.com/people/mfenner/blog/2009/03/15/reference-manager-overview\">number
        of online reference managers to choose from</a>, I thought it would be interesting
        to look at their popularity \u2013 both in absolute numbers of visitors and
        the in changes during the last 12 months. Online tools such as <a href=\"https://web.archive.org/web/20151003053433/http://www.compete.com/\">Compete</a>
        allow everybody to do just that, and their basic functions are free to use.
        I've picked <em><em>unique visitors</em></em>, but there are of course other
        statistics to look at, including total number of visits.</p><p><a href=\"https://web.archive.org/web/20151003053433/http://www.citeulike.org/\">CiteULike</a>
        is the most popular online reference manager, and it is obvious that the <a
        href=\"https://web.archive.org/web/20151003053433/http://www.springer-sbm.com/index.php?id=291&amp;backPID=13041&amp;L=0&amp;tx_tnc_news=4739&amp;cHash=56bfa6b56c\">announcement
        by Springer to sponsor them</a> last August has helped their site traffic.
        Only CiteULike and <a href=\"https://web.archive.org/web/20151003053433/http://www.labmeeting.com/\">Labmeeting</a>
        show a significant increase in unique visitors in the last 6 months.</p><p>The
        statistics are more complicated for tools that include both a desktop client
        and online database (<a href=\"https://web.archive.org/web/20151003053433/http://www.endnote.com/\">Endnote</a>,
        <a href=\"https://web.archive.org/web/20151003053433/http://www.mendeley.com/\">Mendeley</a>,
        <a href=\"https://web.archive.org/web/20151003053433/http://www.zotero.org/\">Zotero</a>)
        and these numbers should be interpreted with caution. I've included <a href=\"https://web.archive.org/web/20151003053433/http://www.refworks.com/\">RefWorks</a>
        in both graphs for better comparison. It is probably safe to say that both
        Endnoteweb and the online version of Mendeley are not as popular as the online
        only reference managers in the first graph. This could either mean that online
        only tools are far more popular than desktop applications (which I doubt)
        or that most references are still primarily stored in desktop programs and
        not shared online. Something that Eva Amsen already described last year (<a
        href=\"https://web.archive.org/web/20151003053433/http://network.nature.com/people/eva/blog/2008/08/19/how-to-get-scientists-to-adopt-web-2-0-technologies\">How
        to get scientists to adopt web 2.0 technologies</a>). To put these numbers
        into perspective: <a href=\"https://web.archive.org/web/20151003053433/http://ncbi.nlm.nih.gov/\">ncbi.nlm.nih.gov</a>
        (the home of PubMed and other NCBI databases) sees about 2.5 million unique
        visitors a month.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ A few questions about author identifiers
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/a-few-questions-about-author-identifiers/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw3y</id>\n        <published>2009-04-13T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-31T07:51:37.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>The scientific articles we
        write are uniquely identified by <a href=\"https://web.archive.org/web/20151001190903/http://www.doi.org/\">Digital
        Object Identifiers</a> (DOI). Many people believe that we also need unique
        identifiers for the authors of those articles. Some of the arguments why author
        identifiers could be very helpful are found in this <a href=\"https://web.archive.org/web/20151001190903/http://network.nature.com/people/mfenner/blog/2009/02/17/interview-with-geoffrey-bilder\">interview
        with Geoffrey Bilder</a>, this <a href=\"https://web.archive.org/web/20151001190903/http://www.gen2phen.org/researcher-identification/researcher-identification-primer\">Researcher
        Identification Primer</a>, and this <a href=\"https://web.archive.org/web/20151001190903/http://friendfeed.com/e/c1fd00ec-15f9-d894-4ea9-4ffeaac5ae28/A-specialist-OpenID-service-to-provide-unique/\">FriendFeed
        discussion</a>. There is also an increasing number of scientific papers on
        the topic, including:</p><ul><li><a href=\"https://web.archive.org/web/20151001190903/http://dx.doi.org/10.1038/451766a\">Scientific
        publishing: Identity crisis</a> (Nature)</li><li><a href=\"https://web.archive.org/web/20151001190903/http://dx.doi.org/10.1038/embor.2008.217\">What's
        in a name?</a> (EMBO Reports)</li><li><a href=\"https://web.archive.org/web/20151001190903/http://dx.doi.org/10.1371/journal.pcbi.1000247\">I
        Am Not a Scientist, I Am a Number</a> (PLoS Computational Biology)</li><li><a
        href=\"https://web.archive.org/web/20151001190903/http://dx.doi.org/10.1126/science.323.5922.1662\">Are
        you ready to become a number?</a> (Science)</li><li><a href=\"https://web.archive.org/web/20151001190903/http://dx.doi.org/10.1038/ng0409-383\">Metadata
        for the metaconsortium</a> (Nature Genetics)</li></ul><p>Although most people
        agree that we need author identifiers for scientists, many details of how
        this should be implemented are not clear. I've listed some of the issues below.
        If possible, please take a few minutes and answer the questions for yourself
        in <a href=\"https://web.archive.org/web/20151001190903/http://www.polldaddy.com/s/FF71A13C726B335C/\">this
        poll</a>.</p><h3 id=\"1-what-is-the-purpose-of-an-author-identifier-for-scientists\">1.
        What is the purpose of an author identifier for scientists?</h3><ul><li>Unique
        identifier</li><li>Author profile</li><li>Authentication</li><li>Other:</li></ul><p>An
        author identifier should obviously uniquely identify an author. Some people
        like to add other functions, namely the ability to add a profile (e.g. a web
        page listing all papers of an author) and authentication. I think that the
        latter two functions can better be provided by a combination of unique identifier
        and some of today's tools (see also question #10).</p><h3 id=\"2-what-is-the-best-name-for-an-author-identifier-for-scientists\">2.
        What is the best name for an author identifier for scientists?</h3><ul><li><a
        href=\"https://web.archive.org/web/20151001190903/http://help.scopus.com/robo/projects/schelp/h_autsrch_intro.htm\">Author
        ID</a> (Scopus)</li><li><a href=\"https://web.archive.org/web/20151001190903/http://www.researcherid.com/\">Researcher
        ID</a> (Thomson Reuter)</li><li><a href=\"https://web.archive.org/web/20151001190903/http://www.crossref.org/CrossTech/2009/02/an_interview_about_author_ids.html\">Contributor
        ID</a> (CrossRef)</li><li>Digital Author Identifier</li><li>Other:</li></ul><p>We
        need a name for author identifiers. Some of the names above are already associated
        with an existing (or planned) service. Just pick a name and stick with it.</p><h3
        id=\"3-the-author-identifier-system-should-be-used-for-\">3. The author identifier
        system should be used for:</h3><ul><li>Authors</li><li>Reviewers</li><li>Editors</li><li>Database
        submitters</li><li>Bloggers</li><li>Commenters</li><li>Other:</li></ul><p>I
        believe that the author identifier system should be applied to all of the
        above. But it doesn't have to be implemented for all these uses at the same
        time.</p><h3 id=\"4-who-should-pay-for-the-author-identifier-system\">4. Who
        should pay for the author identifier system?</h3><ul><li>Journal Publisher</li><li>Blogger</li><li>Database
        maintainer</li><li>Author</li><li>Other:</li></ul><p>Those that gain the most
        from the author identifier system should pay for it. But because I think that
        quick adoption of the system is important, I wouldn't make authors pay.</p><h3
        id=\"5-should-author-identifiers-be-managed-by-a-central-organization\">5.
        Should author identifiers be managed by a central organization?</h3><ul><li>Yes</li><li>No</li></ul><p>I
        think yes, and for the reasons that Geoffrey Bilder explained in <a href=\"https://web.archive.org/web/20151001190903/http://network.nature.com/people/mfenner/blog/2009/02/17/interview-with-geoffrey-bilder\">the
        interview with me</a>. In my opinion a distributed system would create too
        many new problems.</p><h3 id=\"6-which-organization-should-manage-author-identifiers\">6.
        Which organization should manage author identifiers?</h3><ul><li>CrossRef</li><li>U.S.
        National Library of Medicine</li><li>Other:</li></ul><p>The main reason that
        many people are reluctant to have author identifiers managed by a single institution
        is that they don't want a single publisher or other commercial entity to control
        this system. But both CrossRef and the National Library of Medicine have a
        good track record for implementing publishing standards. I would prefer Crossref,
        as the National Library of Medicine is only concerned with a subset of papers,
        i.e. the biomedical literature.</p><h3 id=\"7-should-an-author-identifier-system-for-scientists-be-based-on-openid\">7.
        Should an author identifier system for scientists be based on OpenID?</h3><ul><li>Yes</li><li>No</li></ul><p>I
        would say no. OpenID is a distributed system, which is not desirable as discussed
        in questions #5 and #10. And OpenID also handles authentication, something
        which isn't necessarily required (as discussed in question #1).</p><h3 id=\"8-should-there-be-one-or-several-author-identifier-systems\">8.
        Should there be one or several author identifier systems?</h3><ul><li>One</li><li>Several</li><li>Several
        with one top system</li></ul><p>Similar to the DOI, I want only one unique
        author identifier. But this one unique identifier can then be linked to several
        other systems, e.g. an OpenID for authentication or a Nature Network, LinkedIn
        or Mendeley profile to list all your papers and other contributions.</p><p>I
        hope that enough people also answer these questions in the <a href=\"https://web.archive.org/web/20151001190903/http://www.polldaddy.com/s/FF71A13C726B335C/\">poll</a>
        I posted.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Twitter for Peer Review ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/twitter-for-peer-review/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw3z</id>\n
        \       <published>2009-03-31T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-31T07:50:40.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>A recent <em><em>Nature News</em></em>
        article by Geoff Brumfiel (<a href=\"https://web.archive.org/web/20150924053130/http://www.nature.com/news/2009/090318/full/458274a.html\">Science
        journalism: Supplanting the old media?</a>) has stirred up many interesting
        discussions about the relationship of science blogging and traditional science
        journalism. Good starting places to follow these discussions (and engage in
        them) are <a href=\"https://web.archive.org/web/20150924053130/http://technorati.com/search/http://www.nature.com/news/2009/090318/full/458274a.html\">Technorati</a>,
        <a href=\"https://web.archive.org/web/20150924053130/http://blogs.nature.com/stories/858\">Nature.com
        Blogs</a> and <a href=\"https://web.archive.org/web/20150924053130/http://friendfeed.com/e/4f3817ea-f82c-3a94-4e1c-3368926a24ed/Defining-the-Journalism-vs-Blogging-Debate-with-a/\">FriendFeed</a>.</p><p>Science
        blogging extends, but also threatens traditional science journalism. At the
        same time, aggregators and microblogging services such as <a href=\"https://web.archive.org/web/20150924053130/http://www.friendfeed.com/\">FriendFeed</a>,
        <a href=\"https://web.archive.org/web/20150924053130/http://www.twitter.com/\">Twitter</a>,
        but also <a href=\"https://web.archive.org/web/20150924053130/http://www.facebook.com/\">Facebook</a>
        also are both an enhancementent and a threat to science blogs. Instead of
        writing blog posts or commenting on them, many science bloggers spend increasing
        amounts of time with these services, e.g. in <a href=\"https://web.archive.org/web/20150924053130/http://friendfeed.com/rooms/the-life-scientists\">The
        Life Scientists</a> room on FriendFeed.</p><p>But microblogging and aggregation
        services have also emerged as new tools for another area of science communication,
        namely the <a href=\"https://web.archive.org/web/20150924053130/http://www.nature.com/nature/peerreview/debate/index.html\">peer
        review</a> process. The interaction between authors and editors or editors
        and reviewers traditionally happens via email (because peer review is usually
        anonymous, authors don't communicate directly with reviewers). Twitter and
        similar tools fullfill the requirement for privacy (in the form of direct
        messages and private rooms and special services for organizations such as
        <a href=\"https://web.archive.org/web/20150924053130/http://www.yammer.com/\">Yammer</a>).</p><p>What
        are the advantages of these tools for the peer review process? All communications
        can be stored in one place in the form of a discussion thread. FriendFeed
        and Facebook allow users to mark posts they like and this can show agreement
        between reviewers. Messages can also be sent to and from non-traditional devices
        such as cell phones. Many senior researchers are already overworked with peer
        review, so this way they can at least post their reviews from the golf course
        or their yacht. And authors want to learn about their accepted paper as soon
        as possible, and this is not necessarily when they sit in front of their computer.</p><p>But
        most importantly, microblogging enforces brevity. Virginia Walbot recently
        complained in a <em><em>Journal of Biology</em></em> comment (<a href=\"https://web.archive.org/web/20150924053130/http://dx.doi.org/10.1186/jbiol125\">Are
        we training pit bulls to review our manuscripts?</a>) about reviewers</p><blockquote><em><em>dismissing
        the years of labor and stating that the manuscript can only be reconsidered
        with substantially more data providing definitive proof of each claim</em></em>.</blockquote><p>As
        Twitter messages (also known as tweets) can only be 140 characters long, reviewers
        are forced to write short reviews, and editors to write short notes to the
        authors. And if the 140 characters aren't enough, they can always point to
        other places with services like <a href=\"https://web.archive.org/web/20150924053130/http://bit.ly/5gfc9\">bit.ly</a>.</p><figure
        class=\"kg-card kg-image-card\"><img src=\"https://web.archive.org/web/20150924053130im_/http://farm4.static.flickr.com/3463/3402929290_6e010842b6.jpg\"
        class=\"kg-image\" alt loading=\"lazy\"></figure> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Editorial Manager: Interview with Richard
        Wynne ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/editorial-manager-interview-with-richard-wynne/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw40</id>\n        <published>2009-03-25T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-13T15:32:17.000+00:00</updated>\n\t\t<category
        term=\"Interview\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Practically
        all scientific journals now use web-based systems for paper submissions and
        peer review. This saves the authors a lot of time compared to paper submissions
        by postal mail (until 15 years ago) or email (until 5 years ago). Unfortunately
        the submission process is still far from perfect and requires authors to spend
        many hours formatting manuscripts, references and images instead of focusing
        on the scientific content.</p><p>The tools (word processors, reference managers,
        graphics programs, etc.) that most authors use to write manuscripts have become
        more sophisticated every year, but often don't help much with creating structured
        documents. Structure is the most important feature of a scientific manuscript
        (title, authors, abstract, materials and methods, references, etc.), and this
        is much more relevant than the layout (fonts, page margins, etc.).</p><p>There
        are two different approaches to create structured manuscripts. Authors could
        use tools such as the <a href=\"https://web.archive.org/web/20150908031524/http://network.nature.com/people/mfenner/blog/2008/11/07/interview-with-pablo-fernicola\">Microsoft
        Word Article Authoring Add-in</a> or <a href=\"https://web.archive.org/web/20150908031524/http://network.nature.com/people/mfenner/blog/2009/02/27/lemon8-xml-interview-with-mj-suhonos\">Lemon8-XML</a>
        and submit structured manuscripts in the <a href=\"https://web.archive.org/web/20150908031524/http://www.inera.com/nlmresources.shtml\">NLM
        DTD</a> XML format. Or journal submission systems could improve the process
        of creating structured manuscripts from standard word processor files (e.g.
        Microsoft Word). To better understand the second option, I asked Richard Wynne
        from <a href=\"https://web.archive.org/web/20150908031524/http://www.editorialmanager.com/homepage/about.html\">Aries</a>
        a few questions about <a href=\"https://web.archive.org/web/20150908031524/http://www.editorialmanager.com/homepage/home.htm\">Editorial
        Manager</a>.</p><h3 id=\"1-can-you-describe-what-editorial-manager-is-and-does\"><em><em>1.
        Can you describe what Editorial Manager is and does?</em></em></h3><p>Editorial
        Manager is like plumbing for scholarly publishing. It manages the flow of
        scholarly manuscripts from submission to acceptance. Like good plumbing it
        should be invisible, reliable and afford some luxury.</p><p>While most of
        us could theoretically do our own plumbing, we usually discover that it's
        better to pay a professional. It's the same with online peer review systems.
        Most scholarly societies, publishers and university presses could develop
        and host their own workflow systems; but have discovered that it's less messy
        and less expensive to use a commercial solution such as Editorial Manager.</p><p>More
        than 3,100 journals from 150 publishers have adopted Editorial Manager. In
        the interest of fairness, I should mention other available solutions:</p><ul><li><a
        href=\"https://web.archive.org/web/20150908031524/http://pkp.sfu.ca/?q=ojs\">Open
        Journal Systems</a>,</li><li><a href=\"https://web.archive.org/web/20150908031524/http://scholarone.com/products/manuscript/\">Manuscript
        Central</a>,</li><li><a href=\"https://web.archive.org/web/20150908031524/http://www.ejpress.com/index.shtml\">eJournal
        Press</a>,</li><li><a href=\"https://web.archive.org/web/20150908031524/http://benchpress.highwire.org/\">BenchPress</a>.</li></ul><p>Thanks
        to a healthy competitive environment, online peer review is one of the most
        innovative areas of scholarly publishing.</p><h3 id=\"2-in-what-document-formats-can-manuscripts-be-submitted-to-editorial-manager-can-manuscripts-be-submitted-from-online-word-processors-such-as-google-docs\">2.
        In what document formats can manuscripts be submitted to Editorial Manager?
        Can manuscripts be submitted from online word processors such as Google Docs?</h3><p>There
        are virtually no technical limitations on the types of files that can be loaded
        into Editorial Manager. However:</p><ul><li>Only some file types (such as
        Office, LaTeX, and image formats etc.) can be automatically converted to PDF
        format. Other types of file (e.g. Video or audio files) can be uploaded and
        are accessible during workflow from links in the generated PDF, and from the
        manuscript file inventory for authorized editors.</li><li>Superimposed on
        this technical handling is journal policy. Acceptable submission items (e.g.
        manuscript, data set etc.) are configured by the journal according to their
        idiosyncratic workflow preferences. So while one journal using Editorial Manager
        may permit the upload of supplemental data, another may choose not to make
        this option available.</li></ul><p>We have not interfaced with Google Docs
        at an API level, but this would become a priority if large numbers of authors
        found it a productive authoring tool for scholarly manuscripts. In the interim
        Google Docs provides many supported download file format options such as RTF.</p><h3
        id=\"3-why-do-most-publishers-prefer-not-to-have-manuscripts-submitted-as-pdf-file-s-\">3.
        Why do most publishers prefer not to have manuscripts submitted as PDF file(s)?</h3><p>Editorial
        Manager does support upload of manuscripts in PDF format. However many publishers
        discourage this practice for good reasons:</p><ul><li>Some journals ask reviewers
        to directly edit the manuscript in word processing format \u2013 obviously
        not possible if the author uploads a PDF.</li><li>If the manuscript is accepted,
        the publisher will need access to original source files to undertake copy
        editing, image formatting, composition etc. Obtaining source files up-front
        allows the publisher to accelerate the workflow and eliminates the time-consuming
        and cumbersome step of obtaining source files from the author after acceptance.
        Publishers that do accept PDF submissions must ensure that subsequently submitted
        source files match the revised manuscript that was accepted by the editors
        as an error prone and unnecessary step.</li></ul><p>It's unfortunate that
        publishers don't take the time to explain their reasoning regarding PDF submissions.
        This contributes to the scholar street wisdom that publishers are out of touch.</p><h3
        id=\"4-can-manuscripts-be-transferred-from-preprint-servers-such-as-arxiv-or-nature-preceedings\">4.
        Can manuscripts be transferred from preprint servers such as arXiv or Nature
        Preceedings?</h3><p>Yes, manuscripts can be directly transferred from the
        <a href=\"https://web.archive.org/web/20150908031524/http://arxiv.org/\">arXiv</a>
        server by entering the appropriate arXiv number during the submission process.
        Editorial Manager then automatically collects the source files from the arXiv
        server. The feature is journal configurable.<br>We have not yet implemented
        a similar feature for <a href=\"https://web.archive.org/web/20150908031524/http://precedings.nature.com/\">Nature
        Precedings</a>.</p><h3 id=\"5-how-does-editorial-manager-support-the-nlm-dtd-format-can-manuscripts-be-submitted-in-that-format\">5.
        How does Editorial Manager support the <a href=\"https://web.archive.org/web/20150908031524/http://www.inera.com/nlmresources.shtml\">NLM
        DTD</a> format? Can manuscripts be submitted in that format?</h3><p>Editorial
        Manager does process files with structured DTDs, but that's not really the
        point of your question. Here's the issue: reliably structured manuscripts
        theoretically present workflow benefits:</p><ul><li>During submission, manuscript
        metadata could be automatically harvested from the file, thereby avoiding
        author re-keying of title, abstract, etc.</li><li>Journal styling and composition
        could be applied automatically, thereby avoiding manual steps currently required
        to structure unformatted manuscripts \u2013 a massive cost and time saving.</li></ul><p>Today
        these benefits remain largely theoretical because they depend entirely on
        authors uploading standardized, structured manuscripts. The question is: who
        should have ultimate responsibility for manuscript structure quality? In my
        opinion not authors \u2013 their primary focus should be manuscript content
        not manuscript format. Part of the publisher's role is to take care of manuscript
        structuring. Trying to offload this responsibility to authors is not a good
        use of their time.</p><p>Eventually authoring tools could solve the problem
        by enabling transparent insertion of structure during manuscript authoring,
        but initiatives in this area are still immature in terms of technical feasibility,
        operational convenience and economic sustainability. Until this changes, we\xE2\u20AC\u2122re
        focused on adding server-side tools to Editorial Manager that don\xE2\u20AC\u2122t
        place any extra technical or financial burden on the author.</p><h3 id=\"6-does-editorial-manager-help-with-the-formatting-of-bibliographies-e-g-by-checking-the-references-against-online-databases-or-the-formatting-of-references-in-the-journal-style\">6.
        Does Editorial Manager help with the formatting of bibliographies, e.g. by
        checking the references against online databases or the formatting of references
        in the journal style?</h3><p>Yes, Editorial Manager provides this facility,
        but format styles are determined by the individual journals/publishers that
        use the system.</p><p>Journals can select an Editorial Manager option that
        automatically links author submitted bibliographies to PubMed and/or CrossRef.
        The system can also format the author's bibliography to journal style. This
        means that we broadly accept whatever style the author has used. We power
        the service with <a href=\"https://web.archive.org/web/20150908031524/http://www.inera.com/extylesinfo.shtml\">eXtyles</a>.
        The output of the process is clean XML of the bibliography.</p><p>This is
        an excellent example of how Editorial Manager improves workflow without displacing
        work back to the author. Alternative approaches are burdensome to the author
        because they require her to pre-format the bibliography or mandate the purchase/use
        of reference management tools and plug-ins.</p><h3 id=\"7-what-is-the-preferred-format-for-graphics-can-editorial-manager-help-with-conversions-into-a-different-format-e-g-tiff-to-pdf-\">7.
        What is the preferred format for graphics? Can Editorial Manager help with
        conversions into a different format (e.g. TIFF to PDF)?</h3><p>Editorial Manager
        has no preferred graphic format. The preference is determined by the journal/publisher
        using the system.</p><p>Preferences are the result of the publisher's production
        and content delivery objectives. For example, a journal that re-draws graphics
        may not care about format. A journal that produces high quality print may
        reject RGB images, but RGB images would typically be acceptable for an online-only
        journal.</p><p>Editorial Manager does include an automatic image checking
        option. Journals that configure this feature can provide feedback to authors
        concerning the acceptability of submitted images. Just to be clear, this tool
        provides feedback and education, it does not prevent submission.</p><h3 id=\"8-does-editorial-manager-support-the-sword-simple-web-service-offering-repository-deposit-protocol\">8.
        Does Editorial Manager support the <a href=\"https://web.archive.org/web/20150908031524/http://www.elearning.ac.uk/features/sword\">SWORD</a>
        (Simple Web-service Offering Repository Deposit) protocol?</h3><p>Back in
        2002 Aries proposed an XML-based standard and anticipated that the \u201CSubmission
        and Manuscript eXchange Format\u201D (SMXF) would provide a system-neutral
        standard for the exchange of manuscript metadata and content . The broad adoption
        of such a standard would provide key benefits (see 2002 <a href=\"https://web.archive.org/web/20150908031524/http://www.editorialmanager.com/homepage/press-releases/200211.pdf\">Press
        Release</a>). Despite our best efforts, there was little interest at the time,
        and as a consequence Editorial Manager supports dozens of XML input/output
        formats. So, from our point of view, the emergence of a standardized manuscript
        transfer format is a great boon and I've no doubt that SWORD deposit will
        soon be an Editorial Manager feature.</p><h3 id=\"9-how-can-authors-give-feedback-e-g-to-report-problems-or-request-features\">9.
        How can authors give feedback, e.g. to report problems or request features?</h3><p>Most
        user feedback comes indirectly via publishers so that they can filter editorial
        and policy questions. However, we are also happy to hear suggestions directly
        from users. They can reach us at <a href=\"https://web.archive.org/web/20150908031524/mailto:marketing%40edmgr.com\">marketing@edmgr.com</a>.
        Users are also invited to talk to their journals/publishers about participating
        in User Group meetings (London and Boston) or the <a href=\"https://web.archive.org/web/20150908031524/http://www.editorialmanager.com/homepage/emdiscussion.html\">Listserv</a>
        discussions.</p><h3 id=\"10-what-are-your-responsibilities-within-the-editorial-manager-team\">10.
        What are your responsibilities within the Editorial Manager team?</h3><p>A
        distinguishing characteristic of Editorial Manager is that it is genuinely
        the result of a broad-based team effort. I joined Aries approximately 10 years
        ago and have been privileged to participate in the growth of Editorial Manger
        from idea to sustainable solution processing more than 1,000,000 submissions
        per year. Along the way I have forged key relationships, and led the product
        management, sales and marketing team.</p><h3 id=\"11-what-did-you-do-before-starting-to-work-in-the-editorial-manager-team\">11.
        What did you do before starting to work in the Editorial Manager team?</h3><p>After
        graduating from the University of Edinburgh, I started my career in software
        but jumped at the opportunity to start a multimedia company for <a href=\"https://web.archive.org/web/20150908031524/http://www.ovid.com/site/products/tools/silverplatter/access_tools.jsp\">SilverPlatter</a>
        in the early 90's. Working with scientists we published interactive video,
        audio, graphics and text on CD-ROM. In those days few scientists owned CD-ROM
        drives so I'd carry one around with me. At one point I remember a professor
        at Cornell excitedly showing me something called <a href=\"https://web.archive.org/web/20150908031524/http://de.wikipedia.org/wiki/NCSA_Mosaic\">Mosaic</a>
        and thinking: that's just hypertext. Since then I have been a lot more inquisitive
        about innovations that originate in academia!</p><h3 id=\"12-do-you-want-to-talk-about-future-plans-for-editorial-manager\">12.
        Do you want to talk about future plans for Editorial Manager?</h3><p>There
        are many opportunities to innovate and improve the experience for authors,
        reviewers and editors; and we work on a rich list of suggestions and enhancements.
        We do not announce innovation details until they are close to being deployed,
        but there are a couple of great releases coming this year.</p><p>Recently
        we received the following comment form an editor: Editorial Manger has the
        \u201Cfeel\u201D of actually responding to the user. I think that a number
        of subtleties account for this impression, including the language used, the
        flow of the algorithm, and the customized real time feedback to the user.
        Our ambition is to achieve and surpass this level of satisfaction for all
        users.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Word processor support in citation managers:
        Is there a better way? ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/word-processor-support-in-citation-managers-is-there-a-better-way/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw41</id>\n        <published>2009-03-21T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T07:35:22.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/3371450153_62cbe77494.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/3371450153_62cbe77494.jpeg\"></p><p>Citations
        of the relevant literature are an essential feature of scientific papers.
        Reference Manager software helps adding these citations and creating a bibliography.
        Are there differences in how reference managers work together with your word
        processor of choice?</p><h3 id=\"support-for-your-favorite-word-processor\">Support
        for your favorite word processor</h3><p>Support for word processors other
        than Microsoft Word is spotty. The <a href=\"https://web.archive.org/web/20150906104449/http://www.mendeley.com/download_client\">Mendeley
        plugin</a> is only a few months old, and the latest Zotero release (1.5b)
        <a href=\"https://web.archive.org/web/20150906104449/http://www.zotero.org/support/word_processor_integration\">broke
        the plugin for Word 2004</a>. I expect the Word for Macintosh support of both
        these tools to become better over time. Google Docs doesn't have any reference
        manager integration. This greatly limits its usefulness for writing scientific
        papers. The RefWorks plugin connects to an online database, so you can't add
        or edit references without an internet connection.</p><p>Most word processor
        plugins add an extra menu that allows to add and edit citations (allowing
        the user to search the reference manager database), and to add and edit bibliographies
        (allowing the user to pick a citation style, see below). Most reference managers
        also allow scanning for reference tags in documents produced by other word
        processors (e.g. in the .rtf format), but that process requires a few extra
        steps.</p><h3 id=\"support-for-your-favorite-journal\">Support for your favorite
        journal</h3><p>I think it is very unfortunate that paper authors have to deal
        with a large number of different citation styles. All that we really need
        for paper references is the DOI (e.g. <a href=\"https://web.archive.org/web/20150906104449/http://dx.doi.org/10.1038/455708a\">doi:10.1038/455708a</a>)
        to make the reference automatically identifiable and some basic information
        (authors, title, journal, year, issue) to make the reference readable. But
        it is beyond my understanding why anybody would care about formatting details
        such as whether the pulication year appears before or after the journal name.
        There have been initiatives to standardize the formatting of references (e.g.
        <a href=\"https://web.archive.org/web/20150906104449/http://www.nlm.nih.gov/citingmedicine/\">Citing
        Medicine</a>), but for now paper authors have to format their bibliographies
        in the style required by the journal. Citation styles are an important asset
        for those that write reference manager software. Many people will recall that
        Thomson Reuters (who makes Endnote) <a href=\"https://web.archive.org/web/20150906104449/http://www.nature.com/nature/journal/v455/n7214/full/455708a.html\">sued</a>
        George Mason University (who makes Zotero) last year, because Zotero added
        a feature that could convert Endnote .ens citation style files into <a href=\"https://web.archive.org/web/20150906104449/http://xbiblio.sourceforge.net/csl/\">Citation
        Style Language</a> .csl files. Mendeley is also using .csl for citation styles.</p><h3
        id=\"is-there-a-better-way\">Is there a better way?</h3><p>Word processor
        plugins are fragile and usually break when a new software version is released
        (see for example <a href=\"https://web.archive.org/web/20150906104449/http://www.endnote.com/support/en_wpchart_mac.asp\">this
        chart</a> for Endnote and Word for Macintosh). Native word processor support
        for references allows a much tighter integration into the word processor interface.
        Lastly, documents produced by different reference managers are not interchangeable,
        as each plugin uses a slightly different formatting approach. This means you
        can't write on a paper using Endnote and send it to your coauthor who uses
        Zotero.</p><p>The latest versions of Microsoft Word (2007 and 2008 Macintosh)
        have <a href=\"https://web.archive.org/web/20150906104449/http://blogs.msdn.com/joe_friend/archive/2006/07/13/664960.aspx\">built-In
        support for citations and bibliographies</a>, but this feature is severely
        limited for the requirements of academic papers. Only a handful of citation
        styles are supported, adding more styles is possible but requires <a href=\"https://web.archive.org/web/20150906104449/http://blogs.msdn.com/microsoft_office_word/archive/2007/12/14/bibliography-citations-1011.aspx\">some
        serious skills in XML editing</a>. References are stored in one flat file
        (<a href=\"https://web.archive.org/web/20150906104449/https://www.uwec.edu/help/Word07/bib-srcfile.htm\">Sources.xml</a>)
        and can't be searched. OpenOffice is also struggling with built-in <a href=\"https://web.archive.org/web/20150906104449/http://bibliographic.openoffice.org/\">bibliographic
        support</a>.</p><p>LaTex has long included support for references using <a
        href=\"https://web.archive.org/web/20150906104449/http://www.bibtex.org/About\">BibTex</a>
        and shows how citation support should be done. Tools like <a href=\"https://web.archive.org/web/20150906104449/http://jabref.sourceforge.net/\">JabRef</a>
        or <a href=\"https://web.archive.org/web/20150906104449/http://bibdesk.sourceforge.net/\">BibDesk</a>
        extend this functionality, and most reference managers will import/export
        bibtex files.</p><p>Both Microsoft Word and OpenOffice should open up their
        citation APIs to third-party tools. This would create better citation tools,
        allows the easier exchange of documents between authors (journal submissions),
        and would it make easier for smaller tools such as Papers to integrate with
        word processors (a workaround is described <a href=\"https://web.archive.org/web/20150906104449/http://vnoel.wordpress.com/2008/02/14/papers-word-2008-bibliography-heaven/\">here</a>).
        If they wait too long, we will probably see the online word processors such
        as Google Docs, Zoho Writer start adding an API for citations and bibliographies
        and all of the sudden become very serious alternatives for writing scientific
        papers. <a href=\"https://web.archive.org/web/20150906104449/http://network.nature.com/people/mfenner/blog/2009/02/27/lemon8-xml-interview-with-mj-suhonos\">Lemon8-XML</a>
        already has very good bibliography support.</p><p><em><em>P.S. Bruce D'Arcus
        has recently come to similar conclusions (<a href=\"https://web.archive.org/web/20150906104449/http://community.muohio.edu/blogs/darcusb/archives/2009/03/01/the-babel-of-citations\">The
        Babel of Citations</a>).</em></em></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Reference Manager Overview ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/reference-manager-overview/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw42</id>\n
        \       <published>2009-03-15T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T07:39:44.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/Reference-Manager-Overview.jpg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/Reference-Manager-Overview.jpg\"></p><p><em><em>18
        April 2009: I've updated the chart and added 2collab, the \u201CRead\u201D
        category, sharing of PDF files, and the Mendeley bookmarklet and full-text
        search.</em></em></p><p><em><em>15 July 2009: I've updated the chart to indicate
        that Mendeley and </em>L<em>abmeeting have integrated PDF viewers and that
        2collab can search Scopus.</em></em></p><p><em><em>20 July 2009: I've added
        the offline version of RefWorks for Windows, EndNote OpenOffice plugin, and
        full-text search in several tools.</em></em></p><p><em><em>22 February 2010:
        Many small changes, including a few more categories. Added Citavi and dropped
        2collab, LabMeeting</em>,<em> and Connotea.</em></em></p><p><em><em>6 August
        2010: Added Mendeley API and iPhone app, EndNote X4 features.</em></em></p><p><em><em>19
        September 2010: Moved chart to <a href=\"https://web.archive.org/web/20150905233309/http://blogs.plos.org/mfenner/reference-manager-overview/\">different
        location</a>, PDF download, Creative Commons license.</em></em></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Zotero: Interview with Trevor Owens ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/zotero-interview-with-trevor-owens/\"
        />\n\t\t<id>https://doi.org/10.53731/ftm7mbj-jpteh8h</id>\n        <published>2009-03-04T00:00:00.000+00:00</published>\n\t\t<updated>2023-08-06T13:20:52.000+00:00</updated>\n\t\t<category
        term=\"Interview\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2023/08/reader.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2023/08/reader.png\"></p><p><a
        href=\"https://web.archive.org/web/20150906100323/http://www.zotero.org/\">Zotero</a>
        is a reference manager built as an extension of the <a href=\"https://web.archive.org/web/20150906100323/http://www.mozilla-europe.org/en/firefox/\">Firefox</a>
        web browser. The best introduction to Zotero is probably this short video.</p><p>Last
        week the newest version (1.5 beta) <a href=\"https://web.archive.org/web/20150906100323/http://www.zotero.org/blog/zotero-15-beta-released-join-us-in-the-clouds/\">was
        announced</a> on the Zotero blog. Among the most exciting new features is
        the synchronization of library data with the Zotero server, which in the future
        will allow a lot of interesting social features. I asked <em><em>Trevor Owens</em></em>
        from Zotero a few questions about Zotero, particularly some of the new features.</p><h3
        id=\"1-can-you-describe-what-zotero-is-and-does\">1. Can you describe what
        Zotero is and does?</h3><p>Zotero is an easy-to-use yet powerful research
        tool that helps you gather, organize, and analyze sources (citations, full
        texts, web pages, images, and other objects), and lets you share the results
        of your research in a variety of ways. An extension to the popular open-source
        web browser Firefox, Zotero includes the best parts of older reference manager
        software \u2014 the ability to store author, title, and publication fields
        and to export that information as formatted references \u2014 and the best
        parts of modern software and web applications (like iTunes and <a href=\"https://web.archive.org/web/20150906100323/http://www.delicious.com/\">del.icio.us</a>),
        such as the ability to interact, tag, and search in advanced ways. Zotero
        integrates tightly with online resources; it can sense when users are viewing
        a book, article, or other object on the web, and on most major research and
        library sites it will find and automatically save the full reference information
        for the item. Since it lives in the web browser, it can effortlessly transmit
        information to, and receive information from, other web services and applications;
        since it runs on one's personal computer, it can also communicate with software
        running there (such as Microsoft Word). And it can be used offline as well
        (e.g., on a plane, in an archive without WiFi).</p><h3 id=\"2-why-is-zotero-a-firefox-plugin-and-not-a-desktop-application\">2.
        Why is Zotero a Firefox plugin and not a desktop application?</h3><p>For most
        researchers the web is the first and primary point of entry for their research
        process. We thought it would be ideal to integrate Zotero as tightly as possible
        with the interface researchers already use to interact with the the journals,
        libraries, and databases they regularly consult.</p><h3 id=\"3-why-is-zotero-a-firefox-plugin-and-not-a-web-based-application\">3.
        Why is Zotero a Firefox plugin and not a web-based application?</h3><p>Two
        reasons, first as a extension Zotero can sit alongside any page a researcher
        visits. Many of our users will keep Zotero partway open as they work on research
        online, allowing them to organize and annotate their research without leaving
        the page they are on. Second, as an extension users have full access to their
        collections when they are offline. This is particularly important for researchers
        working in remote locations or with flakey connections. For example, researchers
        working in offline archives can manually add items and attach scans and photos.
        If you're writing a paper on a plane you can add citations to your documents.
        In short being inside the browser gives us the best of both worlds. Zotero
        offers direct connectivity to web content, while still always remaining accessible.
        The last thing I would note is that Zotero is rapidly becoming a web application.
        With our newest release users can browse and share their collections online
        and in the near future users will be able to further manipulate their collections
        through our web application.</p><h3 id=\"4-did-you-consider-google-gears-for-offline-access\">4.
        Did you consider Google Gears for offline access?</h3><p>Both <a href=\"https://web.archive.org/web/20150906100323/http://gears.google.com/\">Google
        Gears</a> and Zotero rely on a local instance of <a href=\"https://web.archive.org/web/20150906100323/http://www.sqlite.org/about.html\">sqlite</a>
        for data storage, but Zotero predates Gears by over a year. Google Gears is
        intended more to synchronize a web application for offline use, while Zotero
        fundamentally is a research database that users expect to be able to interact
        with fully regardless of their network connectivity.</p><h3 id=\"5-does-zotero-work-with-google-docs\">5.
        Does Zotero work with Google Docs?</h3><p>Yes, users can drag and drop citations
        and bibliographic entries into google documents, or for that matter any sort
        of text field. We have a <a href=\"https://web.archive.org/web/20150906100323/http://www.zotero.org/support/zotero_and_google_tools\">short
        screencast</a> which demos this functionality.</p><h3 id=\"6-can-you-briefly-describe-the-citation-style-language-csl-\">6.
        Can you briefly describe the Citation Style Language (CSL)?</h3><p><a href=\"https://web.archive.org/web/20150906100323/http://www.zotero.org/support/dev/creating_citation_styles\">CSL</a>
        is an XML language for citation formatting. It is designed to provide a nice
        balance between power and ease-of-use. It is also designed to be independent
        of any particular application, document format, or programming language.</p><h3
        id=\"7-how-can-zotero-users-share-their-references-with-others\">7. How can
        Zotero users share their references with others?</h3><p>At the moment users
        can export collections and libraries and email them to associates. Users can
        also share their library online, and by next week users will be able to import
        references directly from any users shared library. By next month users will
        be able to create groups for more seamless sharing of references and attachments.</p><h3
        id=\"8-for-zotero-2-0-you-plan-to-offer-users-the-ability-to-share-collections-with-others-through-the-zotero-server-is-there-a-difference-to-similar-services-e-g-connotea-citeulike-or-mendeley-and-do-you-plan-integration-with-them\">8.
        For Zotero 2.0 you plan to offer users the ability to share collections with
        others through the Zotero Server. Is there a difference to similar services
        (e.g. Connotea, CiteULike or Mendeley) and do you plan integration with them?</h3><p>In
        many ways the collaborative features currently in the works for Zotero are
        similar to the other services you mention. I think the biggest difference
        is the way in which sharing collections through groups will be tightly coupled
        into the Zotero client, and writing applications through our Word and Open
        Office plugins. The social and collaborative features we are launching directly
        connect into our hundreds of thousands of users' existing workflows. Zotero
        is also a non-commercial, open-source project directed by academics who are
        committed to enabling scholarship. Finally, Zotero is oriented toward storing
        anything related to your research (papers, books, audio, video, datasets,
        images, etc) while other solutions are almost entirely oriented toward working
        with research papers.</p><h3 id=\"9-what-are-your-responsibilities-within-the-zotero-project\">9.
        What are your responsibilities within the Zotero project?</h3><p>Over the
        last two years as the community lead and evangelist I have been responsible
        for spreading the word about Zotero through workshops and presentations at
        conferences and institutions, as well as helping support the ever growing
        community of users, evangelists, and developers through Zotero's forums and
        by writing a majority of Zotero's user documentation.</p><h3 id=\"10-what-did-you-do-before-starting-to-work-on-zotero\">10.
        What did you do before starting to work on Zotero?</h3><p>Before working on
        Zotero I worked as the press coordinator for the Games Learning and Society
        Conference in Madison and as a Academic Advisor at the University of Wisconsin.
        My undergraduate degree is in the History of Science.</p><h3 id=\"11-do-you-want-to-talk-about-future-plans-for-zotero\">11.
        Do you want to talk about future plans for Zotero?</h3><p>You can consult
        our development roadmap online <a href=\"https://web.archive.org/web/20150906100323/http://www.zotero.org/support/development_roadmap\">here</a>.
        Beyond that I would recommend taking a look at the work we are doing with
        the internet archive <a href=\"https://web.archive.org/web/20150906100323/http://www.dancohen.org/2007/12/12/zotero-and-the-internet-archive-join-forces/\">here</a>.
        Once you take a look at those I would be happy to <a href=\"https://web.archive.org/web/20150906100323/http://www.zotero.org/support/contact_us\">answer
        any questions</a> that come up.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Lemon8-XML: Interview with MJ Suhonos ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/lemon8-xml-interview-with-mj-suhonos/\"
        />\n\t\t<id>https://doi.org/10.53731/ew3e999-93v00dz</id>\n        <published>2009-02-27T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-17T07:41:56.000+00:00</updated>\n\t\t<category
        term=\"Interview\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/2276034665_456342fb50_c.jpg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/2276034665_456342fb50_c.jpg\"></p><p>Finishing
        an exciting research project and writing it up in a paper are the first two
        steps in getting your work published. The next two steps \u2013 submitting
        your paper to a journal and getting it through the review process \u2013 have
        changed dramatically in the last 10-15 years. No longer do we have to print
        out our manuscript using one of the few available laser printers in the department,
        paste our gel pictures on cardboard and number the figures with Letraset.
        And then send it off with the mail. And then repeat the process for every
        revision of the manuscript.</p><p>Now of course we submit our manuscripts
        online using a manuscript submission system such as <a href=\"https://web.archive.org/web/20151003091211/http://www.editorialmanager.com/homepage/home.htm\">Editorial
        Manager</a> or <a href=\"https://web.archive.org/web/20151003091211/http://www.ejpress.com/index.shtml\">eJournalPress</a>.
        Which is not to say that the process is necessarily easy or fun. Many of us
        can tell stories of spending hours or whole days until the manuscript is finally
        submitted. We struggle with the conversion of the different parts of the manuscript
        into a single PDF file, have problems with fonts, have to deal with different
        graphics formats (e.g. PDF, JPEG, EPS, TIFF), don\u2019t use the correct style
        for our references, etc.</p><p>The flip side of this is the time and money
        spent at the journal to format your accepted manuscript into something that
        can be turned into a journal article published online or in print.</p><p>Some
        of these problems wouldn\u2019t exist if we used a common document format
        for manuscript writing, manuscript revisions and manuscript printing and online
        viewing. That common document format does exist and is called <a href=\"https://web.archive.org/web/20151003091211/http://dtd.nlm.nih.gov/publishing/\">NLM
        Journal Publishing DTD</a> (and no, it\u2019s not LaTex). This document format
        is used in the workflow of many journals, but until now has rarely been used
        by authors. Last November <a href=\"https://web.archive.org/web/20151003091211/http://network.nature.com/people/mfenner/blog/2008/11/07/interview-with-pablo-fernicola\">I
        talked with Pablo Fermicola</a> about a free tool that allows Microsoft Word
        to save manuscripts in that format (<a href=\"https://web.archive.org/web/20151003091211/http://www.microsoft.com/DOWNLOADS/details.aspx?FamilyID=09c55527-0759-4d6d-ae02-51e90131997e&amp;displaylang=en\">Microsoft
        Word Authoring Add-In</a>). <a href=\"https://web.archive.org/web/20151003091211/http://www.inera.com/extylesinfo.shtml#NLM\">eXtyles
        NLM</a> is another tool for Microsoft Word with similar functionality.</p><p><a
        href=\"https://web.archive.org/web/20151003091211/http://pkp.sfu.ca/lemon8\">Lemon8-XML</a>
        takes a different approach in helping academic authors convert their manuscripts
        into the NLM DTD format. Version 1.0 of the software <a href=\"https://web.archive.org/web/20151003091211/http://pkp.sfu.ca/node/1891\">was
        released today</a>, so this was a great opportunity to talk with the lead
        developer <em><em>MJ Suhonos</em></em> about Lemon8-XML.</p><h3 id=\"1-can-you-describe-what-lemon8-xml-is-and-does\">1.
        Can you describe what Lemon8-XML is and does?</h3><p>Lemon8-XML is a freely-available,
        open source web application that aims to help academic authors and editors
        convert scholarly articles from layout formats like Microsoft Word to structured
        XML formats without requiring a great deal of knowledge of XML or the schema
        that they\u2019re working with. It\u2019s based on the <a href=\"https://web.archive.org/web/20151003091211/http://opendocument.xml.org/overview\">OpenDocument</a>
        format internally, and the <a href=\"https://web.archive.org/web/20151003091211/http://dtd.nlm.nih.gov/publishing/\">NLM
        Journal Publishing DTD</a> as the default export format.</p><p>Originally,
        Lemon8-XML came from a bunch of scripts that performed a series of tasks:</p><ul><li>convert
        an author\u2019s article from a myriad of document formats to OpenDocument,</li><li>parse
        the article and try to extract metadata, determine section structure based
        on layout information, and parse citations into their disparate elements,</li><li>export
        this semantic data as XML.</li></ul><p>The work to date on Lemon8-XML has
        been building these functions into an easy-to-use web UI that also provides
        some editing facilities; for example, to fix problems from incomplete or incorrect
        parsing. One of the most promising features of Lemon8-XML is its ability to
        parse citations in a wide range of formats, and automatically try to correct
        or enhance them by searching for their complete records in, eg. PubMed, CrossRef,
        and WorldCat.</p><h3 id=\"2-what-are-the-advantages-of-using-lemon8-xml-over-traditional-word-processors-such-as-microsoft-word\">2.
        What are the advantages of using Lemon8-XML over traditional word processors
        such as Microsoft Word?</h3><p>I should start by clarifying that Lemon8-XML
        wasn\u2019t really intended to be used as a word processor, but rather a conversion
        tool to be used after the writing was done. This was to fit in with existing
        practices, where authors upload papers to a journal and the editing is done
        afterwards. Of course, the advent of online word processors challenges this
        notion, and has caused us to think differently about the editing aspects of
        Lemon8-XML. Cross-platform deployment and online collaboration are things
        that obviously the web is great for. An author could, for example, upload
        a paper to Lemon8-XML, and work together with an editor on that same copy,
        regardless of what desktop tools they have. One advantage of this idea is
        that the burden of work is shared between more people, whether that\u2019s
        an author and a copyeditor, or multiple editors. This is a big deal for small
        journals who don\u2019t have funds for dedicated staff.</p><p>Within PKP in
        general, we also try to keep the requirements for our software as low as possible,
        both technically and financially. So, for journals like <a href=\"https://web.archive.org/web/20151003091211/http://www.openmedicine.ca/\">Open
        Medicine</a>, who are entirely volunteer-run, paying $230 per copy for Microsoft
        Word on each computer actually represents a significant cost. Using OpenOffice
        on the desktop and a single copy of Lemon8-XML on a server \u2014 both of
        which are free \u2014 lets them spend this out-of-pocket expense on other
        things to keep their journal alive and growing. Microsoft Word also has an
        unfortunate history of being variable and inconsistent across platforms and
        versions. We wanted to help people escape that, which is one of the reasons
        for converting everything to OpenDocument as early as possible. In addition,
        stewarding documents through an online workflow can be a laborious and frustrating
        process, so the possibility for journals to make the editing process more
        centralized and interactive by integrating Lemon8-XML is a compelling one.</p><h3
        id=\"3-how-does-lemon8-xml-compare-to-the-microsoft-word-article-authoring-add-in-that-also-produces-nlm-journal-publishing-dtd-output\">3.
        How does Lemon8-XML compare to the Microsoft Word Article Authoring Add-In,
        that also produces NLM Journal Publishing DTD output?</h3><p>In many ways,
        we\u2019re working in parallel with Pablo Fermicola\u2019s group at Microsoft
        \u2014 <a href=\"https://web.archive.org/web/20151003091211/http://perspectives.on10.net/blogs/jonudell/Word-for-scientific-publishing/\">they\u2019re
        basically building an editor</a> for placing a structured NLM schema on top
        of the Microsoft WordML (DOCX) XML format, while Lemon8-XML places the NLM
        schema on top of the OpenDocument (ODT) XML format. Of course, there\u2019s
        nothing saying that Lemon8-XML couldn\u2019t be modified to read DOCX files
        generated with the Article Authoring Add-In or vice-versa. This difference
        is really a reflection of the two competing standards, and the tools they
        use, with the same ultimate goal: to allow users to generate semantically-structured
        documents from layout-based ones. In addition, the Article Authoring Add-In
        is built on Microsoft Word 2007 as a platform, which I think has some limitations;
        for example, most of the PKP team don\u2019t use Windows, so the Article Authoring
        Add-In is basically inaccessible to us. But overall, our goals appear to be
        very similar.</p><p>To my mind, the main difference between the projects is
        in how they approach the user: the Article Authoring Add-In presents new tools
        for adding semantic mark-up in a (somewhat) familiar interface; many authors
        are already familiar with Microsoft Word and are comfortable working in that
        environment. My concern with this approach is that it still has strong ties
        to the layout paradigm, so, for example, marking text as \u201Carticle title\u201D
        may not be sufficiently different in authors\u2019 minds from marking text
        as \u201C16 point bold\u201D. I also think the idea of presenting an entire
        document in a single free-form editor reinforces the layout paradigm, as opposed
        to identifying the distinct elements which comprise a scholarly article. Lemon8-XML,
        on the other hand, builds from these individual elements, and assembles them
        within the user interface based on their structural relations. You can see
        this reflected in the tabs in the current interface: \u201CMetadata, Sections,
        Citations\u201D \u2014 these are the front, body, back matter of an article.</p><p>This
        places restrictions on how a user can edit their article, which is sometimes
        frustrating, but it forces them to think about what they\u2019re doing and
        the meaning of their content: why do I have to place it here, what content
        is valid in this element, etc. In a future version, this will all be on the
        same web page, similar to how it would appear in Microsoft Word, but again
        with the semantic structure visually enforced instead of being totally free-form.</p><h3
        id=\"4-what-is-the-difference-between-lemon8-xml-and-online-word-processors-such-as-google-docs\">4.
        What is the difference between Lemon8-XML and online word processors such
        as Google Docs?</h3><p>Unlike most word processor software, Lemon8-XML is
        built around the semantic notion of a document, not its appearance. We wanted
        to help people begin to think about the meaning and structure of their articles,
        not just whether they look good on the screen or as a PDF. It turns out this
        is a tough challenge, though \u2014 people have a hard time with WYSIWYM (What
        You See Is What You Mean) editors, and there\u2019s often a lot of complex
        structure to present visually for editing. One thing people seem to be comfortable
        with, or at least used to, is entering metadata and information in web forms,
        so much of the Lemon8-XML user interface is built that way.</p><p>Lemon8-XML
        is also specifically aimed at modeling and editing scholarly articles, which
        have a long history of practice and some very rigid conventions that aren\u2019t
        applicable more broadly. This means it\u2019s not a general-purpose editor
        like most word processors, but that also means we can focus on the specific
        things it should do, and refine them rather than trying to please everyone
        and falling victim to feature-creep.</p><h3 id=\"5-why-did-you-pick-the-nlm-journal-publishing-dtd-as-document-format\">5.
        Why did you pick the NLM Journal Publishing DTD as document format?</h3><p>I
        did a survey in 2003 of available DTDs to represent scholarly journal articles,
        looking for something I could use as a common source for generating HTML and
        PDF. I selected the NLM DTD above the others (eg. BioMed Central, <a href=\"https://web.archive.org/web/20151003091211/http://www.docbook.org/whatis\">DocBook</a>,
        <a href=\"https://web.archive.org/web/20151003091211/http://www.erudit.org/apropos/info.html\">Erudit</a>,
        <a href=\"https://web.archive.org/web/20151003091211/http://www.tei-c.org/index.xml\">Text
        Encoding Initiative</a>) since it seemed to strike a good balance between
        comprehensiveness and granularity; it can be as simple or as complex as you
        need it to be. It also had a very thorough citation model and a modular design,
        so extensibility wasn\u2019t a concern \u2014 I liked the \u201Cjournal articles
        plus\u201D concept that it was built with. And, of course, being stewarded
        by the National Library of Medicine meant it would likely be well-maintained
        and remain open. The fact that it became <a href=\"https://web.archive.org/web/20151003091211/http://www.pubmedcentral.nih.gov/about/faq.html#q21\">the
        central XML standard for PubMed Central as an archival format</a> was just
        icing on the cake.</p><p>Another reason is that, among the STM journals at
        least, a lot of established practice has developed around generating HTML
        and PDF from NLM XML specifically, and we want to support that. Actually,
        we want to expand adoption of the NLM DTD by making it accessible to humanities
        and social science journals, as well. The information contained in the XML
        is essentially identical regardless of subject, which means we just need to
        develop discipline-specific rendering; for example, for different citation
        styles. I think there\u2019s an incredible amount of room for growth and improvement
        in this area in particular.</p><h3 id=\"6-does-lemon8-xml-integrate-with-manuscript-submission-systems-such-as-open-journal-systems\">6.
        Does Lemon8-XML integrate with manuscript submission systems such as Open
        Journal Systems?</h3><p>Not yet, but that\u2019s the next major area of development
        immediately following the 1.0 release. <a href=\"https://web.archive.org/web/20151003091211/http://pkp.sfu.ca/?q=ojs\">OJS</a>
        has been so successful, one of our biggest challenges has been keeping it
        flexible enough to support a wide range of workflows, and we want to continue
        with that by taking as much of the technology from Lemon8-XML as possible
        and folding it into OJS. I don\u2019t know if we\u2019ll see a side-by-side
        kind of integration immediately, but rather strategic enhancements of certain
        aspects of OJS: automatic document conversion, annotation directly within
        articles, extraction and stripping of metadata to improve blindedness, automatically
        parsing and linking citations, etc. By going this way, we give users the ability
        to choose specific features that are useful for them, and at the same time
        build upon the huge community that already exists for OJS in terms of development,
        testing, and feedback.</p><p>There\u2019s definitely still value in a stand-alone
        Lemon8-XML for cases where people don\u2019t want journal workflow, or where
        they\u2019re integrating with a different kind of system. So, we will be working
        on a Lemon8-XML 2.0 that\u2019s built on the same modular, reliable framework
        as the rest of the PKP suite, and back-porting code from OJS.</p><h3 id=\"7-what-is-the-public-knowledge-project\">7.
        What is the Public Knowledge Project?</h3><p><a href=\"https://web.archive.org/web/20151003091211/http://pkp.sfu.ca/node/1410\">PKP</a>
        is a small research group distributed between Simon Fraser University, University
        of British Columbia, Stanford University and Arizona State University that
        has been quietly <a href=\"https://web.archive.org/web/20151003091211/http://www.openmedicine.ca/article/view/276\">developing
        open source software for online publishing and knowledge sharing</a> for the
        past 10 years, under the direction of Dr. <a href=\"https://web.archive.org/web/20151003091211/http://ed.stanford.edu/suse/faculty/displayRecord.php?suid=willinsk\">John
        Willinsky</a> at Stanford. Our major aim is to provide tools for improving
        access to academic research, as well as helping improve the quality and efficiency
        of its production. Our philosophy is also to create partnerships between researchers,
        librarians, publishers, to help them build sustainable and globally accessible
        scholarly infrastructure. In my mind, it\u2019s also about giving people options
        and choices aside from what\u2019s being offered commercially, especially
        to those who can\u2019t afford them, like a lot of developing-world journals.</p><p>We
        have four applications in addition to Lemon8-XML: <a href=\"https://web.archive.org/web/20151003091211/http://pkp.sfu.ca/?q=ojs\">Open
        Journal Systems</a>, our most popular, is being used by over 2500 journals
        in over 50 countries. We also produce a conference management system (<a href=\"https://web.archive.org/web/20151003091211/http://pkp.sfu.ca/?q=ocs\">Open
        Conference Systems</a>), an OAI metadata indexing system (<a href=\"https://web.archive.org/web/20151003091211/http://pkp.sfu.ca/?q=harvester\">Open
        Archives Harvester</a>), and a monograph publishing system (<a href=\"https://web.archive.org/web/20151003091211/http://pkp.sfu.ca/omp\">Open
        Monograph Press</a>), currently under development. All of our software is
        freely available under the GPL open source license, and we have an active
        community of over 1500 users. We\u2019ve worked with small, volunteer-run
        humanities journals, to major international society conferences, to high-profile,
        ISI-ranked medical journals.</p><h3 id=\"8-what-are-your-responsibilities-within-the-lemon8-xml-project\">8.
        What are your responsibilities within the Lemon8-XML project?</h3><p>Because
        our group\u2019s so small, we all share responsibilities \u2014 there are
        only a handful of people to do almost all of the development, and that\u2019s
        in addition to handling the support, correspondence, and software maintenance
        of the rest of the PKP suite, not to mention providing various international
        workshops. So, we often divvy roles based on expertise or interest. Since
        bringing Lemon8-XML to PKP, I do the vast majority of Lemon8-XML development,
        but I also manage collaborations with our development and research partners,
        and write white papers on the software design we use to share our ideas, on
        top of contributing to the daily stuff above.</p><p>Probably the biggest struggle
        in developing Lemon8-XML has been that it\u2019s one person, about half-time,
        doing all of the coding, testing, etc. We already have a number of very exciting
        partnerships with groups who will be testing and providing feedback, and have
        contributed a talented developer who\u2019s recently started half-time as
        well. Of course, we can always use more help with the coding side of things.
        Our team is quite spread-out geographically, so we have a lot of experience
        with working across time zones and with distributed development practices.
        I\u2019m hoping that after the 1.0 release, more people will become interested
        and will want to help get involved. Whether contributing plugins for citation
        processing, or helping us improve the UI \u2014 really, anything that helps
        the software grow will benefit more authors and editors, which is the main
        goal.</p><h3 id=\"9-what-did-you-do-before-starting-to-work-on-lemon8-xml\">9.
        What did you do before starting to work on Lemon8-XML?</h3><p>I worked for
        a two-person medical informatics journal that was publishing around 50 articles
        a year using Microsoft FrontPage and managed entirely via email. My job was
        to transition it to an online manuscript management system (naturally, I chose
        OJS), convert around 300 back articles from FrontPage HTML into valid NLM
        XML, develop a custom rendering system that would create HTML and PDF galleys
        from that XML, get the journal accepted into PubMed Central, and establish
        an impact factor from ISI (which is now 3.0) \u2014 oh, and continue publishing
        50 articles a year. The journal also ran an international medical conference
        during that time (using OCS). Three years later, I left to do my Masters degree
        in Library/Information Studies, during which time I joined PKP and started
        working on Lemon8-XML, based on a lot of the things I\u2019d learned from
        my time at the journal.</p><h3 id=\"10-do-you-want-to-talk-about-future-plans-for-lemon8-xml\">10.
        Do you want to talk about future plans for Lemon8-XML?</h3><p>The most common
        question I\u2019m asked is, \u201Cwhen will it be ready?\u201D, which for
        many people really means, \u201Cwhen will it be a one-click magic bullet for
        getting my journal into PubMed Central?\u201D. I\u2019m proud of the Lemon8-XML
        1.0 release, and I feel that it represents a significant milestone given how
        far we\u2019ve come \u2014 but there\u2019s still a long way to go before
        we get to that point. I hope people will view the 1.0 version as a stable
        tool that\u2019s already being used in production by at least one journal,
        and a strong indicator of PKP\u2018s commitment to developing research and
        software in this area.</p><p>I mentioned the Open Journal Systems integration,
        which is both a strategic and pragmatic move; this will be our main focus,
        as well as integration with OMP from its earliest inception. We also want
        to improve the editing aspect of Lemon8-XML \u2014 there is some great work
        being done in the area of using style templates for providing structural mark-up
        in traditional word processors; we will be working more closely with Peter
        Sefton\u2019s group on the ICE project, who have a lot of experience. I\u2019d
        also like to re-visit the idea of using web-based WYSIWYM editors like <a
        href=\"https://web.archive.org/web/20151003091211/http://www.wymeditor.org/\">WYMeditor</a>
        or an enhanced <a href=\"https://web.archive.org/web/20151003091211/http://tinymce.moxiecode.com/\">TinyMCE</a>
        as part of a user interface overhaul, and possibly integrating more closely
        with Google Docs if that\u2019s an option. Certainly, there\u2019s room for
        adding more citation lookup plugins: <a href=\"https://web.archive.org/web/20151003091211/http://www.oaister.org/about.html\">OAIster</a>,
        Amazon.com, <a href=\"https://web.archive.org/web/20151003091211/http://citeseer.ist.psu.edu/citeseer.html\">CiteSeer</a>,
        etc. as well as improving the existing ones. Finally, we want to try applying
        the approach we\u2019ve used with citation parsing and lookup with other scholarly
        article elements; for example, checking quotations for correctness and plagiarism,
        extracting and linking author/contributor identifiers, and so on. We also
        have some ideas around <a href=\"https://web.archive.org/web/20151003091211/http://www.dlib.org/dlib/may06/apps/05apps.html\">OpenURL</a>
        that may or may not come into Lemon8-XML development.</p><p>We\u2019re also
        starting a major side-project based entirely around the NLM DTD in two parts:
        1) building mappings from various other XML schemas to NLM; and 2) building
        a standard set of rendering tools for generating HTML and PDF from NLM XML,
        in a way that can be easily customized for an individual journal. There are
        already a lot of groups out there using NLM but currently the practice is
        quite fragmented \u2014 we\u2019d like to see these journals and publishers
        become more connected and share their work as a community. As I say, we want
        to help increase adoption as a way to raise the bar on journal quality and
        improve options for publishing and archiving.</p><p>One of the most important
        things we\u2019ve learned during the development of Lemon8-XML has been the
        value of user feedback early and often, and remaining aware of related work
        that\u2019s going on, so we can remain efficient by building partnerships
        instead of working in parallel. We\u2019ll continue pursuing this approach,
        and I\u2019d encourage anyone who is interested in any of these areas or has
        ideas of their own to contribute to <a href=\"https://web.archive.org/web/20151003091211/http://pkp.sfu.ca/contact\">get
        in touch with us</a>.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Papers for iPhone released \u2013 time for
        more poetry ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/papers-for-iphone-released-time-for-more-poetry/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw45</id>\n        <published>2009-02-19T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T07:36:59.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p><a href=\"https://web.archive.org/web/20150924053123/http://mekentosj.com/papers/\">Papers</a>
        is a great Macintosh program to manage the PDF files of scientific papers
        on your (Macintosh) computer. I've mentioned several times that I like the
        program and I <a href=\"https://web.archive.org/web/20150924053123/http://network.nature.com/people/mfenner/blog/2008/10/03/interview-with-alexander-griekspoor\">interviewed</a>
        the author Alex Griekspoor back in October. Today the <a href=\"https://web.archive.org/web/20150924053123/http://mekentosj.com/papers/iphone/\">iPhone
        version of Papers</a> was released and it is a great companion for those moments
        when you <em><em>really</em></em> have to look up that particular <em><em>Nature</em></em>
        paper while discussing <em><em>the release of calcium from intracellular stores</em></em>
        in the bar.</p><p>As a thank you for beta testing the iPhone version, Alex
        Griekspoor is giving me three copies of Papers for Mac (or rather three serial
        numbers, Papers can be downloaded and used for 30 days without registration).
        As I already own Papers, and in the spirit of some recent poetry <a href=\"https://web.archive.org/web/20150924053123/http://network.nature.com/people/mfenner/blog/2008/11/30/why-do-we-blog-and-other-important-questions-answered-by-34-science-bloggers\">here
        on Nature Network</a> (and elsewhere in the blogosphere, answers to question
        #11), I'm giving these serial numbers away to the best poetry about using
        the iPhone for finding, reading or writing science papers. Please post your
        poetry in the comments section of this blog post, the submission deadline
        is next Thursday at 8 PM.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Author Identifiers: Interview with Geoffrey
        Bilder ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/interview-with-geoffrey-bilder/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw1h</id>\n        <published>2009-02-17T20:27:00.000+00:00</published>\n\t\t<updated>2022-08-16T16:25:25.000+00:00</updated>\n\t\t<category
        term=\"Interview\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/hNo7lvc0_400x400--1-.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/hNo7lvc0_400x400--1-.jpeg\"></p><p>Almost
        exactly two years ago, <a href=\"https://web.archive.org/web/20090221213233/http://www.crossref.org/\"><strong>CrossRef</strong></a>
        invited a number of people to discuss unique identifiers for researchers (<a
        href=\"https://web.archive.org/web/20090221213233/http://www.crossref.org/CrossTech/2007/02/crossref_author_id_meeting.html\"><strong>CrossRef
        Author ID meeting</strong></a>). One year ago Thomson Reuters launched <strong>ResearcherID</strong>
        (<a href=\"https://web.archive.org/web/20090221213233/http://network.nature.com/people/mfenner/blog/2008/01/21/thomson-scientific-launches-researcherid-to-uniquely-identify-authors\"><strong>Thomson
        Scientific launches ResearcherID to uniquely identify authors</strong></a>).
        And two months ago Phil Bourne and Lynn Fink wrote about this topic in a \_<strong>PLoS
        Computational Biology</strong> paper (<a href=\"https://web.archive.org/web/20090221213233/http://dx.doi.org/10.1371/journal.pcbi.1000247\"><strong>I
        Am Not a Scientist, I Am a Number</strong></a>).</p><p>So it comes as no surprise
        that we also talked about author identifiers at the recent <a href=\"https://web.archive.org/web/20090221213233/http://www.scienceonline09.com/index.php/wiki/\"><strong>ScienceOnline09</strong></a>
        meeting in North Carolina (both in the session <a href=\"https://web.archive.org/web/20090221213233/http://www.scienceonline09.com/index.php/wiki/Reputation_authority_and_incentives/\"><strong>Impact
        Factors and researcher incentives</strong></a> and over drinks afterwards).
        <a href=\"https://web.archive.org/web/20090221213233/http://network.nature.com/people/U42E63119/profile\"><strong>Cameron
        Neylon</strong></a> wrote down his thoughts after the meeting in a blog post
        (<a href=\"https://web.archive.org/web/20090221213233/http://blog.openwetware.org/scienceintheopen/2009/01/20/a-specialist-openid-service-to-provide-unique-researcher-ids/\"><strong>A
        specialist OpenID service to provide unique researcher IDs?</strong></a>),
        and this resulted in <a href=\"https://web.archive.org/web/20090221213233/http://friendfeed.com/e/c1fd00ec-15f9-d894-4ea9-4ffeaac5ae28/A-specialist-OpenID-service-to-provide-unique\"><strong>a
        very interesting</strong></a> discussion on <strong>FriendFeed</strong>. And
        at about the same time both <a href=\"https://web.archive.org/web/20090221213233/http://network.nature.com/people/jandot/profile\"><strong>Jan
        Aerts</strong></a> (<a href=\"https://web.archive.org/web/20090221213233/http://saaientist.blogspot.com/2009/01/who-o-o-are-you-who-who-who-who.html\"><strong>Who-o-o
        are you? Who who? Who who?</strong></a>) and Christopher Leonard (<a href=\"https://web.archive.org/web/20090221213233/http://blogs.openaccesscentral.com/blogs/pmcblog/entry/some_thoughts_on_unique_author\"><strong>Some
        thoughts on unique author IDs</strong></a>) independently wrote blog posts
        about the same topic. This week <a href=\"https://web.archive.org/web/20090221213233/http://network.nature.com/people/U42E63119/profile\"><strong>Cameron
        Neylon</strong></a> summarized the discussion in another blog post (<a href=\"https://web.archive.org/web/20090221213233/http://blog.openwetware.org/scienceintheopen/2009/02/15/contributor-ids-an-attempt-to-aggregate-and-integrate/\"><strong>Contributor
        IDs \u2013 an attempt to aggregate and integrate</strong></a>).</p><p>Science
        bloggers have put a lot of thought into the idea of a unique author identifier
        and I\u2019ve collected more reading material about author ID at <strong>Connotea</strong>
        using the tag <a href=\"https://web.archive.org/web/20090221213233/http://www.connotea.org/tag/authorid\"><strong>authorid</strong></a>.
        But I was also very curious to learn more about the work that has already
        been done. That\u2019s why I asked <a href=\"https://web.archive.org/web/20090221213233/http://network.nature.com/people/gbilder/profile\"><strong>Geoffrey
        Bilder</strong></a> from <strong>CrossRef</strong> a few questions. In the
        end Geoffrey talked not only about author identifiers, but also about CrossRef,
        DOIs and many other aspects of scholarly publishing.</p><h3 id=\"1-can-you-describe-what-crossref-is-and-does\">1.
        Can you describe what CrossRef is and does?</h3><p>Let me start with what
        it does because this is a little less likely to make your eyes glaze-over.</p><p>CrossRef
        was originally founded by scholarly publishers to fight <a href=\"https://web.archive.org/web/20090221213233/http://en.wikipedia.org/wiki/Link_rot\"><strong>link-rot</strong></a>.</p><p>Web
        links have a half-life of about six years. That is, after six years a link
        is likely to break because the content that it pointed to has been moved.
        To a lay-audience this might be a mere annoyance, but to scholarly and professional
        publishers broken links are anathema. The scholarly record is built on a foundation
        of links in the form of citations. If these online citation links break, the
        online scholarly citation record breaks.<br><br>But surely fighting link-rot
        should be simple, right? After all, the glory of the web is its decentralized
        architecture, one in which the domain name that you own can be used as a namespace
        for identifiers. <a href=\"https://web.archive.org/web/20090221213233/http://en.wikipedia.org/wiki/Tim_Berners-Lee\"><strong>Tim
        Berners-Lee</strong></a> has said that \u201Ccool URIs never die\u201D. Aren\u2019t
        \u201Cpersistent URIs\u201D merely a matter of being disciplined in the way
        that you mint URIs and in being conscientious about sensibly redirecting URIs
        when things change location on your web server?</p><p>Well, certainly the
        majority of broken links on the web are the result of careless web administrators
        not taking the time to structure and redirect their web site\u2019s URIs properly,
        but there are a significant percentage of links that will break despite the
        best efforts of webmasters. This is because in some cases the domain name
        in the link will change, and in these cases the whole \u201Cdomain name as
        URI minting name-space\u201D starts to crumble. When otherwise sensible technorati
        refer to \u201Cowning\u201D a domain name, it makes me want to stick forks
        in my eyeballs. We do not \u201Cown\u201D domain names. At best, we only lease
        them and there are manifold ways in which we could lose control of a domain
        name \u2013 through litigation, through forgetfulness, through poverty, through
        voluntary transfer, etc. Once you don\u2019t control a domain name anymore,
        then you can\u2019t control your domain-name-based persistent identifiers
        either.</p><p>Incidentally, another technorati meme that makes me want to
        self-harm with cutlery is the notion that \u201Cpersistent identifiers don\u2019t
        matter in the age of the search engine. If a link breaks, we can just find
        the content again wherever it has moved.\u201D This, naturally, is the self-serving
        argument often used by Google and it\u2019s starry-eyed acolytes. Even just
        few minutes\u2019 reflection reveals the gaping hole in this approach.</p><p>The
        hole is this \u2013 how do you cite a specific copy of something if there
        are multiple <strong>almost identical</strong> copies of it located in different
        places? For instance, lets say there are 2 copies (X and Y) of an article
        which only differ in a few paragraphs, but those few paragraphs are crucial
        and likely to change the reader\u2019s interpretation of the work. How, in
        a world where persistent linking is maintained by search engines, do you create
        a citation link to article X instead of article Y? To create a search-based
        link that is more likely to resolve to article X, you would essentially have
        to encode the entire article in the search URI! Even this wouldn\u2019t guarantee
        you that the link directed a future reader to article X first; it is still
        possible that article Y might end up getting a higher ranking because more
        people have linked to it and it therefore has a higher page-rank (or equivalent).
        Believe me, even variations of the search engine scenario (using document
        hashes for citations, pingbacks, etc.) quickly unravel after a little reflection.</p><p>This
        is all a long-winded and ranty way of saying that the issue of persistent
        identifiers on the web is just a wee bit more complex than most people think.
        So how does CrossRef address the persistent identifier issue?</p><p>From our
        perspective, the persistent identifier problem is much more a social problem
        than a technical one.</p><p>In fact, the technical part of our service is
        relatively straightforward. CrossRef provides a level of indirection (i.e.
        a pointer) between an identifier and a URL. When publishers put something
        online, they assign a CrossRef <a href=\"https://web.archive.org/web/20090221213233/http://www.doi.org/\"><strong>Digital
        Object Identifier</strong></a> (DOI) to it and submit a record for that item
        with CrossRef. The record includes the CrossRef DOI, basic bibliographic metadata
        for the content and a URL that points to the current location of the content.
        People citing the publisher\u2019s content are encouraged to use the CrossRef
        DOI for the citation instead of the publisher\u2019s URL. When a researcher
        clicks on a CrossRef DOI, the CrossRef service redirects the URL to whatever
        URL the publisher has currently registered for that CrossRef DOI. This means
        that the publisher can update their CrossRef DOI record to point to a completely
        new URI (including a new domain name) and any CrossRef DOI citations will
        continue to work. We provide a few other services based on this infrastructure
        too. So, for instance, we can resolve an <a href=\"https://web.archive.org/web/20090221213233/http://www.oclc.org/research/projects/openurl/default.htm\"><strong>OpenURL</strong></a>
        to a CrossRef DOI (by querying the publisher-submitted bibliographic metadata),
        resolve a free-text query to a CrossRef DOI and we can also return bibliographic
        metadata instead of redirecting if that is what the user wants.</p><p>So-far,
        so good, but this isn\u2019t anything that couldn\u2019t be accomplished using
        other redirection tools such as <a href=\"https://web.archive.org/web/20090221213233/http://www.purl.org/\"><strong>PURLs</strong></a>,
        <a href=\"https://web.archive.org/web/20090221213233/http://www.handle.net/\"><strong>CNRI
        Handles</strong></a>, <a href=\"https://web.archive.org/web/20090221213233/http://www.oasis-open.org/committees/tc_home.php?wg_abbrev=xri\"><strong>XRIs</strong></a>,
        <a href=\"https://web.archive.org/web/20090221213233/http://numly.com/numly/default.asp\"><strong>NUmly
        Numbers</strong></a>, etc.? The crucial question to ask of any such service
        is, \u201Cwhat guarantees that the publisher will actually update their URL
        pointers?\u201D If the publisher doesn\u2019t update these pointers, then
        the links will break anyway. It isn\u2019t enough that a publisher decides
        to use PURLs, if they then don\u2019t update their PURLs- in perpetuity.</p><p>This
        is where it is important to explain the organizational structure and the social
        effect that this has on the service.</p><p>CrossRef was founded as a non-profit,
        membership organization for publishers. Note that we are entirely catholic
        in our definition of what a publisher is, so our membership includes commercial
        publishers, non-profit publishers, open access publishers, institutional repositories,
        NGOs and IGOs, Video publishers, Wiki-based publishers, etc. We are also open
        to publishers of all disciplines (humanities, social sciences, sciences, professional),
        geographies and content types (journals, books, database records, videos,
        etc.)</p><p>In practice, what unites our membership is a concern that their
        content should be considered worthy of trust by professional researchers.
        One way in which researchers assess the trustworthiness of content is by determining
        how it sits within the scholarly record. Does it provide evidence for its
        assertions in citations? Do other people cite it?</p><p>When a publisher joins
        CrossRef, they agree to a <a href=\"https://web.archive.org/web/20090221213233/http://www.crossref.org/02publishers/59pub_rules.html\"><strong>set
        of enforceable terms and conditions</strong></a> that govern the way in which
        they use CrossRef\u2019s persistent citation infrastructure. Specifically,
        they agree to:</p><ul><li>Register DOIs within a week of something being published
        online</li><li>Update the URLs associated with a DOI when said URLs change</li><li>Link
        citations in their content via the DOI</li></ul><p>In joining CrossRef they
        also agree that CrossRef can fine them or throw them out of the service if
        they do not meet the terms and conditions of the service. Note that the penalty
        of being thrown out can be quite severe as it effectively means that the publisher
        would become invisible in the online scholarly citation record. In short,
        the system has a built-in social feedback loop that strongly enforces good
        citizenship.</p><p>As I said, the technical infrastructure of CrossRef is
        pretty mundane, and it is the social aspect of the service that does the most
        to guarantee the persistency of CrossRef citation links.</p><h3 id=\"2-what-are-your-responsibilities-within-crossref\">2.
        What are your responsibilities within CrossRef?</h3><p>Thinking of, gathering
        the requirements for, designing and (most importantly) launching new services.</p><p>Last
        year we launched a plagiarism detection service called <a href=\"https://web.archive.org/web/20090221213233/http://www.crossref.org/crosscheck.html\"><strong>CrossCheck</strong></a>.
        This year I am working on Contributor ID, another project tentatively named
        CrossMark and a bunch of smaller projects designed to encourage the use of
        DOIs in citations.</p><h3 id=\"3-what-did-you-do-before-starting-to-work-for-crossref\">3.
        What did you do before starting to work for CrossRef?</h3><p>In the early
        nineties Allen Renear and I co-founded Brown University\u2019s Scholarly Technology
        Group, where we were charged with providing advanced consulting and support
        to Brown\u2019s research community. In the mid-nineties I grew tired of the
        politics, resource constraints and institutional paralysis that seems to grip
        so many universities and I decided to do something as far away from the academic
        sphere as possible. In short, I worked at a management consultancy doing R&amp;D
        for their IT group. In 2000 I was lured into managing the web development
        efforts for an Information Architecture firm called Dynamic Diagrams. In 2001
        we were bought by <a href=\"https://web.archive.org/web/20090221213233/http://www.ingentaconnect.com/\"><strong>Ingenta</strong></a>
        in the UK. I became Ingenta\u2019s CTO and I moved to Oxford in 2002. I left
        Ingenta in 2005, did a brief spell of consulting for publishers in 2006 and
        joined CrossRef in 2007.</p><h3 id=\"4-what-are-your-thoughts-on-how-an-author-identifier-should-look-like\">4.
        What are your thoughts on how an author identifier should look like? </h3><p>First
        of all, I think we need to stop talking about \u201Cauthor\u201D identifiers.
        One of the first requirements we found when interviewing publishers, researchers
        and librarians is that we would ideally like to be able to identify any party
        who contributes to the scholarly literature in any way. That is, we would
        also like to be able to identify reviewers, editors, correspondents, bloggers,
        commenters, etc. This is why we have taken to calling our project the \u201CCrossRef
        Contributor ID\u201D project. This isn\u2019t just playing with words either.
        For instance, as soon as you start thinking about things like \u201Chow do
        you accommodate reviewers\u201D in this system you need to think of things
        like pseudo-anonymity. That is, you want somebody to be able to get credit
        for doing reviews in a way that doesn\u2019t necessarily reveal who reviewed
        what. In turn, the pay-off for designing a system whereby anonymous reviewers
        might be credited with reviews could be profound. It might ultimately result
        in researchers having much more incentive to review if reviewing were something
        that could be counted and rated in the same way that authorship is.</p><p>Second,
        I think that people conflate a lot of issues when they talk about \u201Cauthor
        identifiers\u201D [sic]. Are they talking about the simple token used (e.g.
        a unique string or a number assigned to an individual like a social security
        number), are they talking about an authentication mechanism (e.g. <a href=\"https://web.archive.org/web/20090221213233/http://openid.net/what/\"><strong>OpenID</strong></a>,
        <a href=\"https://web.archive.org/web/20090221213233/http://shibboleth.internet2.edu/\"><strong>Shibboleth</strong></a>)
        or are they talking about the profile information associated with an identifier
        (e.g. publications, affiliation, contact info, etc.)? Obviously, these all
        overlap in some ways, but how they relate and what you choose to focus on
        depends largely on your use cases.</p><p>Third, speaking of use cases, our
        requirements gathering has identified two broad categories of use cases that,
        though related, have profoundly different implementation implications. One
        category of use cases identified revolves around \u201Cknowledge discovery\u201D
        and the other category of cases revolves around \u201Cauthentication.\u201D</p><p>The
        \u201Cknowledge discovery\u201D use cases are probably the most obvious things
        that people would like to be able to do with a contributor ID such as:</p><ul><li>Determine
        what IDs authored/edited/reviewed document X</li><li>What documents where
        authored/edited/reviewed by ID Y</li><li>What IDs are related to ID Z and
        what is the nature of that relationship (e.g. co-authored, edited, reviewed)</li><li>What
        (subject to privacy settings) is the profile information for ID Z (e.g. institutional
        affiliation, email address, etc.)</li><li>All the author IDs and their respective
        publications where the institutional affiliation recorded by the author is
        X</li><li>Etc.</li></ul><p>At this point I feel obliged to point out that
        the bulk of our requirements gathering has been focused on trying to understand
        the needs of our member publishers. The reason I mention this here is that
        the bulk of the \u201Cauthentication\u201D use cases that we identified are
        all focused around making publisher back-office systems less cumbersome. So,
        for instance, publishers are interested in using a \u201Ccontributor id\u201D
        for:</p><ul><li><a href=\"https://web.archive.org/web/20090221213233/http://en.wikipedia.org/wiki/Single_sign-on\"><strong>single
        sign-on</strong></a> (SSO) for manuscript tracking systems</li><li>Disambiguating
        contact information for use by editorial offices, royalty payments systems,
        copyright clearances, etc.</li><li>Automatic updating of email addresses for
        table of contents (TOC) alerts and other automated email communications</li><li>Automated
        tools for detecting potential reviewers, including tools for detecting potential
        conflicts of interest</li><li>Synchronization with publisher web site user
        profiles and granting researchers customized, privileged access to content
        based on profiles</li><li>Understanding all of the manifold ways in which
        an individual \u201Ccontributes\u201D to a publisher or a field (e.g. As an
        editor, reviewer, letter writer, conference chair, etc.).</li><li>Etc.</li></ul><p>As
        I said, these are very publisher-focused use cases, but this is not to say
        that we are not interested in the use cases posed by librarians, researchers
        and funding agencies. We have actively been talking to people from each of
        these constituencies and we are trying to understand if there are ways in
        which we can help them. For instance, we have recently been speaking to a
        group of researchers who are interested in using some sort of authenticated
        contributor ID as a mechanism for controlling who gets trusted access to sensitive
        genome-wide aggregate genotype data.</p><p>The interesting thing to note about
        these \u201Cauthentication\u201D use cases is that they have far more stringent
        requirements than the \u201Cknowledge discovery\u201D use cases. In other
        words if you are only trying to address the knowledge discovery problem, it
        might be fine to use automated techniques to disambiguate authors and assign
        IDs to them. State-of-the-art mechanisms for automatic disambiguation of authors
        from a defined corpus can be 96-97% accurate, which sounds pretty good. At
        least until you realize that CrossRef has ~200K new article DOIs deposited
        each month, each of which on average has about 3 authors. This could potentially
        leave you with upwards of 20K in mis/un-identified authors. This error rate
        might be an acceptable tradeoff for knowledge discovery type applications,
        but it certainly isn\u2019t suitable for authentication type applications.</p><p>Speaking
        of authentication, I think the fourth thing to note is that, though I think
        <strong>OpenID</strong> will probably play an important role in any service
        we provide, by itself it makes a pretty bad identity token and would provide
        little utility on its own. This all gets back to some of the issues that I
        raised above when discussing persistent identifiers: URI-based identifiers
        are fragile because they depend on the domain name. What happens if your OpenID
        is tied to a domain that you don\u2019t control (e.g. a company, an institution
        a country)? How can you guarantee that, should you leave that company/institution/country
        that they will do the right thing and let you maintain or redirect that identifying
        credential?</p><p>The traditional geeky response to this scenario is \u201Cdon\u2019t
        get yourself into that situation. Only tie your <strong>OpenID </strong>to
        a domain that you own.\u201D (Insert forks in eyeballs). Again, you do not
        \u201Cown\u201D a domain name. You lease it. What happens if you lose control
        of it due to litigation, forgetfulness, poverty, divorce, death? Death? Yes,
        what happens when somebody dies? When I die does the not-yet-born Georgia
        Bilder get to buy \u201Cmy\u201D domain \u201Cgbilder.com\u201D and make it
        the basis of her identity? Mmm\u2026 Gets kind of complicated doesn\u2019t
        it?</p><p>Of course, lots of the same issues can be raised with CrossRef,
        right? What guarantees that CrossRef won\u2019t become evil and co-opt all
        of our identities? This, of course is the big fear underlining the knee-jerk
        reaction against \u201Ccentralized systems\u201D in favor of \u201Cdistributed
        systems\u201D. The problem with this, as I mentioned in the <a href=\"https://web.archive.org/web/20090221213233/https://friendfeed.com/e/c1fd00ec-15f9-d894-4ea9-4ffeaac5ae28/A-specialist-OpenID-service-to-provide-unique/\"><strong>FriendFeed
        thread</strong></a> is that my personal and unfashionable observation is that
        \u201Cdistributed\u201D begets \u201Ccentralized.\u201D For every distributed
        service created, we\u2019ve then had to create a centralized service to make
        it useable again (ICANN, Google, Pirate Bay, CrossRef, DOAJ, ticTocs, WorldCat,
        etc.). This gets us back to square one and makes me think the real issue is-
        how do you make the centralized system that eventually emerges accountable?
        This is, of course, a social issue more than a technical issue and involves
        making sure that whatever entity emerges has clearly defined data portability
        policies and a \u201Cliving will\u201D that attempts to guarantee that the
        service can be run in perpetuity- even if by another organization. For the
        record, I don\u2019t think adopting the slogan \u201Cdon\u2019t be evil\u201D
        is enough ;).</p><p>Anyway- I could go on talking about what the contributor
        ID \u201Cshould look like\u201D for a very, very long time, but I think that
        the above probably addresses some of the major points that are raised when
        the topic is discussed.</p><h3 id=\"5-what-are-the-benefits-and-maybe-disadvantages-if-crossref-manages-the-author-identifier\">5.
        What are the benefits (and maybe disadvantages) if CrossRef manages the author
        identifier?</h3><p>I think the biggest potential disadvantage that CrossRef
        has is that it is a consensus-based organization that is governed by sometimes
        fierce competitors. This aspect of the organization can sometimes slow things
        down. On the other hand, this can also be a huge strength for us. Once a consensus
        is agreed, we can move very quickly and push uptake across the industry.</p><p>Research
        increasingly transcends institutional, geographic and discipline boundaries,
        so I think another advantage that we have is that we are well positioned to
        provide a service that is similarly unconstrained.</p><p>Finally, I think
        that we have a very interesting advantage by virtue of the fact that our infrastructure
        is already integrated upstream in the publication process. There is a useful
        property of the system that we are designing in that, as researchers used
        the CrossRef identifier in their interactions with publishers and this data
        is fed back into our system via DOI deposits, you could start to develop a
        trust-metric based on the types of claims attached to an author\u2019s profile.
        For instance, an author profile that consisted of nothing but self-claims
        (e.g. I claim I wrote paper X) might not be very worthy of trust whereas an
        author profile that consisted of publications that had been verified by the
        publisher (by virtue of those publications having been processed along with
        the CrossRef contributor ID) would have far more credibility. You can start
        to see an interesting hierarchy of publication claims emerging such as:</p><ul><li>Proxy
        claims (Leigh claims Geoffrey wrote article X)</li><li>Self Claims (Geoffrey
        claims Geoffrey wrote article X)</li><li>Verified claims (Geoffrey claims
        Geoffrey wrote article X <strong>and</strong> the \u201CJournal of Psychoceramics\u201D
        confirms this claim)</li><li>Verified Proxy Claims (Geoffrey (who has already
        been verified as an author of article X) claims that Kirsty was also an author
        of article X)</li></ul><h3 id=\"6-how-does-your-author-identifier-relate-to-other-identifiers-e-g-researcherid-scopus-author-idor-openid\">6.
        How does your author identifier relate to other identifiers, e.g. <a href=\"https://web.archive.org/web/20090221213233/http://www.researcherid.com/\">ResearcherID</a>,
        <a href=\"https://web.archive.org/web/20090221213233/http://help.scopus.com/robo/projects/schelp/h_autsrch_intro.htm\">Scopus
        Author ID</a>or <a href=\"https://web.archive.org/web/20090221213233/http://openid.net/what/\">OpenID</a>?</h3><p>OpenID
        is a different kettle of fish, and I discussed it already above. As for the
        others (I\u2019d add <a href=\"https://web.archive.org/web/20090221213233/http://www.authorresolver.com/\"><strong>Author
        Resolver</strong></a>, <a href=\"https://web.archive.org/web/20090221213233/http://repec.org/\"><strong>RePEC</strong></a>,
        <a href=\"https://web.archive.org/web/20090221213233/http://www.scilink.com/start.action\"><strong>SciLink</strong></a>,
        <a href=\"https://web.archive.org/web/20090221213233/http://bibserver.berkeley.edu/cgi-bin/mathweb/index.py\"><strong>MathPeople</strong></a>,
        <a href=\"https://web.archive.org/web/20090221213233/http://network.nature.com/\"><strong>Nature
        Network</strong></a>, etc.), we\u2019ve actually been talking to some of these
        parties in order to understand how they might relate to a CrossRef Contributor
        ID. One obvious difference is in the use-cases being addressed. All of the
        above are focused on \u201Cknowledge discovery\u201D use-cases. None of them
        pretends to provide any sort of authentication services. It is also interesting
        to note that in a lot of the above cases, the parties see their author identification
        functionality as a means to an end. For instance, their primary application
        is \u201Ccreating better metrics\u201D or \u201Crunning a social network\u201D
        or \u201Cexpert identification\u201D for recruiting purposes. In these cases
        they don\u2019t necessarily see a CrossRef system as being competitive and,
        in fact, they think that such a service might even improve their primary application.</p><h3
        id=\"7-can-you-talk-about-the-current-status-and-next-planned-steps-of-the-contributorid-project\">7.
        Can you talk about the current status and next planned steps of the ContributorID
        project?</h3><p>We just ended lengthy period of investigation and requirements
        gathering. In the process we went down a few blind alleys. Now we are working
        on a prototype that we will test with a few publishers. It is hard to say
        how long this will take as we are just in the process of planning this phase.</p><h3
        id=\"8-satisfying-many-different-interests-is-one-of-the-biggest-challenges-in-creating-an-author-identifier-what-are-the-lessons-learned-from-implementing-the-digital-object-identifier-doi-\">8.
        Satisfying many different interests is one of the biggest challenges in creating
        an author identifier. What are the lessons learned from implementing the digital
        object identifier (<a href=\"https://web.archive.org/web/20090221213233/http://www.doi.org/\">DOI</a>)?</h3><p>I\u2019ll
        give you one tactical lesson and one strategic lesson.</p><p>The tactical
        lesson is foremost in my mind because I have recently been trying to build
        tools to encourage researchers to use DOIs in their citations. The problem
        arrises when a researcher occasionally encounters a DOI that is 80 characters
        long. There is just no way that a researcher is going to insert <strong>that</strong>
        in a citation. The tactical lesson here is that it is sometimes better to
        make an identifier opaque and short. This is also a tremendously unfashionable
        position to take, but I think that one of Clay Shirky\u2019s observations
        about hierarchical categorization systems also applies to identifiers. If
        you make the identifier human-interpretable and add semantics, then people
        will be extremely tempted to start hard-coding ontologies into their identifiers.
        This makes said identifiers both long and inherently brittle. The ontologies
        will inevitably evolve, and then people will want to change the identifiers-
        at which point they will either break or you have a giant identifier mapping
        subsystem to create.</p><p>We see a manifestation of this syndrome already
        with the DOI. Each DOI has a four-digit \u201Cprefix\u201D which is effectively
        a namespace for the assigning publisher. Note that I said the \u201Cassigning\u201D
        publisher- this is not necessarily the publisher who currently \u201Cowns\u201D
        the DOI with that prefix. What this often means is that, when publisher A
        acquires publisher B, publisher A will ask CrossRef if we can create new DOIs
        for all of publisher B\u2019s backfiles so that they all have the same prefix!
        The answer to their request is \u201Cno\u201D, but you wouldn\u2019t believe
        how stroppy publishers can get about this. They somehow imbue this ridiculous
        four-digit prefix with branding significance. This, of course, is absolutely
        mental, but it is a predictable form of mental. The French went mad when they
        had to replace their region-encoded license plates with opaque EU ones. People
        in the US go mad when they are given new area codes. In short, when people
        associate semantic significance in identifiers, you will face problems.</p><p>The
        strategic lesson is basically a recapitulation of the \"technical vs \u201Csocial\u201D
        theme I\u2019ve been banging on about. I think that, at first, even our membership
        thought of the CrossRef DOI as being a technical solution to a problem, not
        a social one. It has become much clearer to us over the years that CrossRef
        DOIs are only as persistent as CrossRef staff. That is, we sometimes have
        to bang on lots of heads and threaten members with fines and worse in order
        to make sure that they are meeting their terms &amp; conditions. The good
        news is that CrossRef has become essential infrastructure for a wide variety
        of publishers who are often at each other\u2019s throats in any other circumstances.
        In many ways these \u201Cdifferent interests\u201D are our strength. Everybody
        wants it to work better, nobody wants to see it die and nobody wants it to
        be co-opted. We are working hard to put the social structures into place that
        will guarantee its longevity. Part of this is making sure that we are fiscally
        sound (which we are) and part of this is making sure that, even if we do disappear,
        other stakeholders can run the system if need be.</p><h3 id=\"9-what-can-researchers-interested-in-author-identifiers-do-to-help\">9.
        What can researchers interested in author identifiers do to help?</h3><ul><li>Feed
        CrossRef more use cases.</li><li>Let CrossRef know what you think will/won\u2019t
        work.</li><li>Make sure you let your publishers know if you think this is
        a good idea. Naturally, I expect you will also let them know if you think
        it is a bad idea ;-)</li></ul><p>I can be reached at <strong>gbilder at crossref
        dot org</strong>.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Mutation, selection and metastasis ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/mutation-selection-and-metastasis/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw46</id>\n        <published>2009-02-14T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-16T16:26:20.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><figure class=\"kg-card kg-image-card\"><img
        src=\"https://blog.front-matter.io/content/images/2022/08/DarwinBadge.gif\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"135\" height=\"149\"></figure><p>Mutation
        and selection are important concepts in cancer biology. One well-known example
        is hereditary colon cancer. Patients with mutations in the DNA mismatch repair
        genes <em><em>MLH1</em></em> or <em><em>MSH2</em></em> develop colon cancer
        because of an increased rate of mutations. And tumors in patients with familial
        polyposis coli have a growth advantage because of a mutation in the tumor
        suppressor gene APC. Mutations and selection also help to explain the process
        of metastasis, the formation of secondary tumor foci at distant sites in the
        body. Understanding metastasis is important, because it is often this spread
        of the tumor that makes a previously localized cancer an incurable disease.</p><p>In
        1977 a landmark paper in <em><em>Science</em></em> by Isaiah Fidler and Margaret
        Kripke (Fidler 1977) described a mouse model of lung metastasis using the
        syngeneic B16 mouse melanoma cell line. This melanoma cell line originated
        spontaneously in a C57BL/6 mouse in 1954 and is known to metastasize to the
        lung. They produced several clones of the B16 cells, each clone originating
        from a single cell and therefore genetically identical. Cells from these clones
        were then injected into the tail vein of C57BL/6 mice. The number of lung
        metastases in these mice varied dramatically between clones and was also different
        from the parental cell line. Fidler and Kripke concluded that a subpopulation
        of highly metastatic cells preexists in the parent population and is selected
        during the metastatic process.</p><p>In 1994 I started to work on a research
        project that tried to identify molecules responsible for the selection process
        in this B16 lung metastasis model. This was before microarrays and the sequencing
        of the mouse genome, and we used a technique called differential display to
        identify differentially expressed genes in two variant B16 cell lines that
        created low and high numbers of lung metastases. We identified a novel gene
        that turned out to be a transcriptional regulator (Shioda 1996) but probably
        is not that critical for the metastatic process.</p><p>In 2009 we have learned
        a lot more about the metastatic process, but we still know much more about
        genes involved in tumor cell proliferation, apoptosis, etc. than the genes
        critical for the metastatic process. And we still have not come up with a
        clever way to specifically treat that malignant subpopulation of tumor cells
        that will later produce metastatic disease.</p><h3 id=\"references\">References</h3><p>Fidler,
        I., &amp; Kripke, M. (1977). Metastasis results from preexisting variant cells
        within a malignant tumor. Science, 197(4306), 893\u2013895. <a href=\"https://doi.org/10.1126/science.887927\">https://doi.org/10.1126/science.887927</a></p><p>Shioda,
        T., Fenner, M. H., &amp; Isselbacher, K. J. (1996). msg1, a novel melanocyte-specific
        gene, encodes a nuclear protein and is associated with pigmentation. Proceedings
        of the National Academy of Sciences, 93(22), 12298\u201312303. <a href=\"https://doi.org/10.1073/pnas.93.22.12298\">https://doi.org/10.1073/pnas.93.22.12298</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ CiteULike: Interview with Kevin Emamy ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/interview-with-kevin-emamy/\" />\n\t\t<id>https://doi.org/10.53731/fe3njcc-crnxhks</id>\n
        \       <published>2009-01-30T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-14T15:32:52.000+00:00</updated>\n\t\t<category
        term=\"Interview\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>One interesting
        session at <a href=\"https://web.archive.org/web/20150922174120/http://scienceonline09.com/\">ScienceOnline09</a>
        was <a href=\"https://web.archive.org/web/20150922174120/http://www.scienceonline09.com/index.php/wiki/Social_networking_for_scientists/\">Social
        networking for scientists</a>, moderated by Cameron Neylon and Deepak Singh.
        We now have so many of these social networking sites, that it becomes difficult
        to differentiate between them and to see how they can interact with each other.
        One important category is social bookmarking sites for scientists. I spoke
        with Kevin Emamy from <a href=\"https://web.archive.org/web/20150922174120/http://www.citeulike.org/\">CiteULike</a>
        to find out more.</p><p><em><em>Most of the CiteULike team. Kevin is the second
        person from the right.</em></em></p><h3 id=\"1-can-you-describe-what-citeulike-is-and-does\">1.
        Can you describe what CiteULike is and does?</h3><p>CiteULike is social bookmarking
        for research papers. It enables you to easily store references online, share
        them in groups and discover new ones.</p><p>It's run as a web service, so
        everything is always stored online. You can access it from any computer (most
        of us use more than one these days) and if you're lazy and stupid like me
        you're much less likely to lose anything. Sharing and discovery obviously
        work better this way too.</p><p>The social side of it is simply that by default
        everyones posts are public and you can see who has bookmarked the same papers
        as you, what tags they are giving them and from there you can go on to browse
        what else they are bookmarking.</p><p>And then we have groups which are shared
        libraries of posts, newsfeeds for every user action, RSS feeds, watchlists,
        <a href=\"https://web.archive.org/web/20150922174120/http://www.citeulike.org/citegeist\">CiteGeist</a>
        (which is a hotlist of posts) and obviously search as ways to encourage this
        social discovery.</p><h3 id=\"2-do-your-users-basically-just-store-their-own-bookmarks-or-do-you-also-see-a-lot-of-use-of-the-social-networking-features\">2.
        Do your users basically just store their own bookmarks or do you also see
        a lot of use of the social networking features?</h3><p>In the 30 days up to
        the Christmas Holidays 08, CiteULike received 116,477 posts and 6,189 of those
        were copies made directly from other user's librarys, which is the successful
        end result of the social stuff. That doesn't count people who find an article,
        go to the original source to read it, and then post it.</p><p>The other social
        stuff is hard to quantify without diving into the weblogs. Also, once you
        get into the realms of counting pageviews and linkouts etc. it becomes easy
        to mislead yourself about what is really going on, which is why we use \u201Cposts\u201D
        as a genuine metric (assuming you are on top of the spam).</p><p>But the social
        discovery stuff is certainly used. Groups for example; well over 50% are active,
        by which I mean people have posted to them in the last 90 days. Watchlists
        (following another user's posts) and RSS are very active. Many people search
        the site, either directly or through RSS feeds.</p><p>One thing that is definitely
        true is that many more people browse the site than actually register and post,
        by a factor of say 5:1, and I'm discounting the random Google traffic that
        just bounces on and off.</p><p>Of course, the service would never have got
        off the ground if it didn't provide individual value to a user without any
        social features, so yes, many people use it just like that and always will.</p><h3
        id=\"3-how-is-citeulike-different-from-other-social-bookmarking-tools-e-g-connotea-2collab-or-delicious\">3.
        How is CiteULike different from other social bookmarking tools, e.g. Connotea,
        2collab or delicious?</h3><p>It differs from <a href=\"https://web.archive.org/web/20150922174120/http://delicious.com/\">delicious</a>
        because we extract and bookmark citation metadata along with the URL, so it's
        aimed at professional researchers and scientists. We have over 50 sites where
        we do this, covering most of the online sources of journal papers. Because
        of this specialization our userbase is very different and therefore much more
        relevant when you look at the community features. The tags, as one example,
        are very specialized.</p><p>There are lots of differences in detail with the
        other two 'scholarly' services but it seems that the users have voted with
        their feet (or should I say mice); CiteULike is far and away the most popular
        service. If you count the number of papers posted we estimate that CiteULike
        is currently 3-5 times the size of <a href=\"https://web.archive.org/web/20150922174120/http://www.connotea.org/\">Connotea</a>
        both in total posts and posts on a daily basis (2 million+ posts and very
        little spam for CiteULike vs. 650k posts including a significant proportion
        of spam for connotea, 3k-5k daily posts for CiteULike vs. 1k to 1.5k claimed
        for Connotea).</p><h3 id=\"4-does-citeulike-integrate-with-other-social-networking-sites-and-services-for-scientists-e-g-connotea-mendeley-or-friendfeed-does-it-integrate-with-desktop-reference-managers\">4.
        Does CiteULike integrate with other social networking sites and services for
        scientists, e.g. Connotea, Mendeley or FriendFeed? Does it integrate with
        desktop reference managers?</h3><p>You can export and import files to and
        from pretty much all these services.</p><p>In the case of <a href=\"https://web.archive.org/web/20150922174120/http://friendfeed.com/\">FriendFeed</a>
        I have seen many people using RSS feeds to display their CiteULike posts there,
        which is great, it's a really good service.</p><p><a href=\"https://web.archive.org/web/20150922174120/http://www.mendeley.com/\">Mendeley</a>
        are based in London like us and we have begun to discuss ways where we can
        integrate more tightly, the point being to make the workflow better for users
        of both services.</p><h3 id=\"5-what-is-your-policy-regarding-personal-pdf-files-uploaded-to-citeulike\">5.
        What is your policy regarding personal PDF files uploaded to CiteULike?</h3><p>Only
        the person who uploaded a PDF can download it, so CiteULike is acting as an
        online storage drive.</p><p>We have also allowed uploads to \u201Cprivate
        groups\u201D which are invite only and otherwise invisible. In this case the
        user will commit that they have a right to distribute the document to the
        people in the group,<br>who they already know.</p><h3 id=\"6-what-are-your-responsibilities-within-citeulike\">6.
        What are your responsibilities within CiteULike?</h3><p>There are only five
        of us, so we don't really have roles. Unlike the rest of the team, I can't
        write code or design applications, so I have to leave that to my esteemed
        colleagues.</p><p>One of the things I try and do is to promote CiteULike and
        increase our userbase and traffic, which is a bit of a capricious art, but
        one way that has worked for us is to try to engage with, dare I say it,<br>the
        publishers.</p><p>Springer, who we <a href=\"https://web.archive.org/web/20150922174120/http://www.springer.com/company/citeulike?SGWID=0-164102-0-0-0\">recently
        agreed a sponsorship with</a>, have been invaluable to us in this regard.
        They are one of the few major publishers who are really progressive and actually
        understand this stuff.</p><h3 id=\"7-what-did-you-do-before-starting-to-work-for-citeulike\">7.
        What did you do before starting to work for CiteULike?</h3><p>We all worked
        in the software industry, sometimes together. Richard wrote CiteULike as a
        tool for his own use when he was back doing research at university.</p><h3
        id=\"8-do-you-want-to-talk-about-future-plans-for-citeulike\">8. Do you want
        to talk about future plans for CiteULike?</h3><p>Well the team are continuously
        improving the service, making it perform better, fixing things that break
        etc. I wish I could count the number of improvements that have been made over
        the last 18 months. That is part of the secret to it's growth, the users can
        tell when the developers are making an effort. We have a very active newsgroup
        where users make feature and functionality requests or report problems. I
        have regularly seen my colleagues put stuff live in a matter of hours following
        a user request, which is one of the advantages of a service that is run by
        it's developers.</p><p>We have wanted to do some kind of recommendation system
        for a long time; automated collaborative filtering or whatever. We certainly
        have the data to do it. But it is, I'm told, a hard problem if you want to
        get useful results. It's possible we'll work with someone else on this.</p><p>It
        was really interesting to see <a href=\"https://web.archive.org/web/20150922174120/http://www.plos.org/\">PLoS</a>
        announcing the variety of impact metrics they want to publish about their
        articles, a small part of which is going to be social bookmarking posts. We
        are currently giving them this data on request, it would be nice to allow
        anyone to get this sort of data out of CiteULike themselves (we do already
        make the whole CiteULike dataset freely available for download).</p><p>Another
        example of that is that a lot of other sites want to display CiteULike tag
        data along with the relevant articles; there are 6.7 million user created
        tags on CiteULike now (that's total not distinct)<br>and those tags have been
        given by people who know the subjects. I suppose I am talking about some kind
        of API, which would also allow reference managers etc. to integrate with CiteULike
        more easily, as you asked about above.</p><p>Having said that, there is a
        great temptation to continually add more features or try to make it into something
        different to what it really is and I'm not sure if that is the right approach
        (though we have been guilty of it).</p><p>For example, one of the biggest
        issues we have is that CiteULike is good at matching articles that have been
        posted by hand but not articles imported by file upload. By \u201Cmatch\u201D
        I mean identify that two articles from different sources are in fact the same,
        which is the basis of the social stuff; seeing who is reading what you're
        reading etc. Seeing as 40% or so of our posts come via file upload, it would
        be great to fix. Matching is done by DOI and PMID; however we ran some tests
        that showed only 5% of file uploaded articles contain these, so maybe we'll
        try a different approach.</p><p>So what we try to focus on is to make it better
        and more efficient at what it does well: social bookmarking for research papers.
        There is plenty of work to do in that regard.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ JoVE: Interview with Moshe Pritsker ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/interview-with-moshe-pritsker/\"
        />\n\t\t<id>https://doi.org/10.53731/e5fkxk7-79487ej</id>\n        <published>2009-01-24T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-14T15:33:20.000+00:00</updated>\n\t\t<category
        term=\"Interview\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>The <a href=\"https://web.archive.org/web/20150924053056/http://scienceonline09.com/\">ScienceOnline09</a>
        meeting last weekend not only had a number of interesting presentations and
        discussions, but even more importantly, was a great opportunity to personally
        interact with a great number of people that share your ideas and interests.
        It was the first time I personally met <a href=\"https://web.archive.org/web/20150924053056/http://network.nature.com/people/U06343707/profile\">Moshe
        Pritsker</a>, the CEO, Editor-in-Chief and co-founder of the Journal of Visualized
        Experiments (<a href=\"https://web.archive.org/web/20150924053056/http://www.jove.com/\">JoVE</a>),
        <em><em>a peer-reviewed, free access, online journal devoted to the publication
        of biological research in a video format</em></em> (taken from <a href=\"https://web.archive.org/web/20150924053056/http://www.jove.com/index.stt\">About
        JoVE</a>). As I like to write about new technologies that help scientists
        publish their research, I asked Moshe a few questions after the meeting.</p><h3
        id=\"1-can-you-describe-what-jove-is-and-does\">1. Can you describe what JoVE
        is and does?</h3><p><em><em>JoVE</em></em> is the first video journal for
        biological and biomedical research. We publish articles that include step-by-step
        video demonstrations of experimental techniques and procedures. For example,
        <a href=\"https://web.archive.org/web/20150924053056/http://www.jove.com/index/details.stp?ID=923\">A
        Behavioral Assay to Measure Responsiveness of Zebrafish to Changes in Light
        Intensities</a> by the group of John Dowling at Harvard or <a href=\"https://web.archive.org/web/20150924053056/http://www.jove.com/index/details.stp?ID=1067\">Calcium
        Imaging of Cortical Neurons using Fura-2 AM</a> by the group of Ricardo Dolmetsch
        at Stanford. We call these articles video-articles or video-protocols. They
        also include a text part which is similar to traditional scientific articles
        (abstract, introduction, experiment, materials and references).</p><p>This
        novel video-based approach to scientific publishing is applied to increase
        reproducibility and transparency of experimental studies, which is the <em><em>bottleneck</em></em>
        problem in the life sciences today. As every bench scientist knows, it is
        very difficult to repeat biological experiments based on their text description
        in traditional scientific journals. This is because the text format presents
        a requirement for scientists to understand the complex reality and numerous
        <em><em>small</em></em> details of the experiment from reading. It is very
        difficult. Visualization through video provides a solution to this problem
        by clear unambiguous demonstration of experimental techniques and procedures.
        Using this new approach will enable increase efficiency and productivity across
        all the areas of biological research and drug discovery.</p><p>Being a scientific
        journal, <em><em>JoVE</em></em> is indexed in PubMed and MEDLINE, and has
        an editorial board of 22 distinguished professors from Harvard, Princeton,
        NIH and other leading institutions in US, Europe and Japan. After two years,
        since its foundation in October 2006, <em><em>JoVE</em></em> has published
        nearly 300 articles across all the areas of experimental biology including
        neuroscience, cell biology, developmental biology, stem cell research, immunology,
        bioengineering and plant biology. Most of the articles are produced at the
        laboratories in the leading academic research institutions including Harvard,
        MIT, Berkeley, Stanford, UCSF, Yale and others.</p><h3 id=\"2-what-kind-of-research-is-well-suited-to-be-published-in-jove-and-what-kind-of-research-doesn-t-work-well\">2.
        What kind of research is well-suited to be published in JOVE? And what kind
        of research doesn't work well?</h3><p>The <em><em>JoVE</em></em> video-based
        format of publication is very effective for description of experimental techniques
        in all the areas of biological and clinical research. We have accumulated
        a lot of experience in production and publication of video-articles in these
        areas. This format can be also applied for experiments in chemistry and physics.
        For example, we have recently published a video-article on a <a href=\"https://web.archive.org/web/20150924053056/http://www.jove.com/index/details.stp?ID=942\">creation
        of chemical libraries using Ugi reaction</a> by <a href=\"https://web.archive.org/web/20150924053056/http://network.nature.com/people/jcbradley/profile&amp;#39;s\">Jean-Claude
        Bradley</a> group at Drexel University.</p><p>We have less experience with
        video-publication on theoretical and computational research, e.g. bioinformatics.
        We currently explore developing different formats for these non-experimental
        areas of science.</p><h3 id=\"3-how-do-you-help-authors-with-video-production\">3.
        How do you help authors with video production?</h3><p>We know that most scientists
        do not have experience in video-production, and therefore cannot make good
        quality videos on their own experiments. Therefore, we take complete responsibility
        for this part. Specifically, we send video-professionals to film at the laboratories
        that want to publish their experiments in <em><em>JoVE</em></em>.</p><p>The
        entire <em><em>JoVE</em></em> publication process works as following:</p><ul><li>authors
        submits a text description (protocol) of their experiment to <em><em>JoVE</em></em></li><li><em><em>JoVE</em></em>
        sends one of its video-professionals to film the experiment in the authors\xE2\u20AC\u2122
        laboratory</li><li><em><em>JoVE</em></em> editors edit the video</li><li>the
        video is submitted to the approval by authors and reviewers</li></ul><p>To
        facilitate integration of video into scientific publishing, <em><em>JoVE</em></em>
        has developed a network of video-professionals to conduct production of scientific
        videos in research labs across 30 cities in USA, Canada, UK, Germany and Japan
        including such centers of academic research as Boston, San Diego, San Francisco,
        New York, Chicago, Seattle, Toronto, Vancouver, London, Berlin and others.
        These video-professionals are selected, interviewed and trained by <em><em>JoVE</em></em>
        before they are sent to film in the laboratories. This infrastructure enables
        production and publication of video-articles from university laboratories
        around the world.</p><h3 id=\"4-can-you-talk-a-little-bit-about-the-peer-review-process\">4.
        Can you talk a little bit about the peer review process?</h3><p>The video-articles
        are sent to reviewers in a regular fashion: 2-3 anonymous reviewers at different
        universities. The reviewers provide their comments according to the timeline
        in videos, e.g. \"introduce changes at 2 minutes 35 seconds\". They also provide
        comments on the text part, e.g. \"introduce changes in paragraph 4\".</p><p>We
        are more interested in the applicability and technical clarity rather than
        novelty of the methods published. To achieve our goal, to increase transparency
        and efficiency in biological research, we need to visualize all the experimental
        techniques applied today. It is less important whether they are <em><em>old</em></em>
        or <em><em>new</em></em>. For example, purification and transplantation of
        hematopoetic stem cells are used for more than 40 years. Yet, it is very difficult,
        even impossible, to learn these techniques based on text descriptions. So,
        it should be published on video.</p><h3 id=\"5-what-are-your-responsibilities-within-jove\">5.
        What are your responsibilities within JoVE?</h3><p>As every CEO of a start-up,
        I wear multiple hats. I oversee and coordinate the work of different parts
        of <em><em>JoVE</em></em> including editorial, publishing, IT, video-production,
        business development, marketing and sales. My personal responsibilities as
        Editor-in-Chief include management of the editorial and publishing processes,
        marketing in academia and publishing industry, and PR.</p><p>I consider myself
        <em><em>EXTREMELY</em></em> lucky to meet very smart and hard-working people
        working with me on <em><em>JoVE</em></em>, including my two partners and <em><em>JoVE</em></em>
        co-founders, Nikita Bernstein and Klaus Korak (M.D.). Among others are Aaron
        Kolski-Andreaco (Ph.D.), Nandita Singh (Ph.D.), Mark Shalinsky (Ph.D.), Alvin
        Liang and Lori Chesla. A large fraction of doctorate-holders in the team enables
        us to adapt our innovative product to the high demands of the scientific community.</p><h3
        id=\"6-what-did-you-do-before-starting-to-work-for-jove\">6. What did you
        do before starting to work for JoVE?</h3><p>I was doing my Ph.D. in Molecular
        Biology at Princeton, working on embryonic stem cells and bioinformatics.
        This is where the <em><em>JoVE</em></em> idea was born since I, like any other
        scientists around, was suffering from low reproducibility of experiments.
        Then I was working as a post-doc at Harvard Medical School, Massachusetts
        General Hospital, for one year. Then I met my partners, Nikita Bernstein and
        Klaus Korak, and <em><em>JoVE</em></em> was started.</p><h3 id=\"7-do-you-want-to-talk-about-future-plans-for-jove\">7.
        Do you want to talk about future plans for JoVE?</h3><p>My dream is to build
        a large comprehensive online video-library that will include a video-protocol
        for every possible experimental technique in biological and medical research.
        This will tremendously increase productivity of research in academia and biotech
        industry, accelerating development of new technologies and drug discovery.
        This will also have a strong impact on scientific education and science policy
        at all levels.</p><p>Being initially focused on basic biological research,
        we received numerous requests to expand our approach into clinical medicine,
        psychology and other fields. We are doing our first <a href=\"https://web.archive.org/web/20150924053056/http://www.jove.com/index/details.stp?ID=992\">steps</a>
        in these directions too.</p><p><em><em>Further Reading</em></em></p><ul><li><a
        href=\"https://web.archive.org/web/20150924053056/http://jove-blog.blogspot.com/\">Official
        JoVE blog</a> with posts from <a href=\"https://web.archive.org/web/20150924053056/http://network.nature.com/people/U2929A0EA/profile\">Anna
        Kushnir</a> (<a href=\"https://web.archive.org/web/20150924053056/http://network.nature.com/people/U2929A0EA/blog/2008/01/07/blogging-can-help-you-get-a-job-continued\">Blogging
        Can Help You Get a Job, Continued</a>) and <a href=\"https://web.archive.org/web/20150924053056/http://network.nature.com/people/steelgraham/profile\">Graham
        Steel</a>.</li><li><a href=\"https://web.archive.org/web/20150924053056/http://scienceblogs.com/clock/2008/02/visualize_this_interview_with.php\">Visualize
        This! Interview with Moshe Pritsker</a> (A Blog around the Clock)</li><li><a
        href=\"https://web.archive.org/web/20150924053056/http://arstechnica.com/journals/science.ars/2009/01/20/science-online-09-moving-beyond-text\">Science
        Online 09: moving beyond text</a> (Nobel Intent)</li><li><a href=\"https://web.archive.org/web/20150924053056/http://www.boston.com/news/local/massachusetts/articles/2008/08/21/out_in_the_open_some_scientists_sharing_results/?page=2\">Out
        in the open: Some scientists sharing results</a> (The Boston Globe)</li><li><a
        href=\"https://web.archive.org/web/20150924053056/http://usefulchem.blogspot.com/2008/11/from-ons-to-peer-review-our-jove.html\">From
        ONS to Peer Review: our JoVE Article is Published</a> (Useful Chemistry)</li><li><a
        href=\"https://web.archive.org/web/20150924053056/http://network.nature.com/groups/goodpaper/forum/topics/3785\">JOURNAL
        CLUB: A Behavioral Assay to Measure Responsiveness of Zebrafish to Changes
        in Light Intensities</a> (Good Paper Journal Club)</li></ul> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ ScienceOnline09: Providing public health
        and medical information to all ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/scienceonline09-providing-public-health-and-medical-information-to-all/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw49</id>\n        <published>2009-01-16T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-01T05:46:01.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>This Sunday
        I will moderate a session called <a href=\"https://web.archive.org/web/20151003022812/http://www.scienceonline09.com/index.php/wiki/Public_health_and_medical_information/\">Providing
        public health and medical information to all</a> at <a href=\"https://web.archive.org/web/20151003022812/http://www.scienceonline09.com/index.php/wiki\">ScienceOnline09</a>.
        I didn't pick the title, but it is a topic I care a lot about. Because the
        session is intended as an open discussion, I thought that a blog post would
        be good way to organize my thoughts and ideas that I have for this session<sup><a
        href=\"https://web.archive.org/web/20151003022812/http://blogs.plos.org/mfenner/2009/01/16/scienceonline09_providing_public_health_and_medical_information_to_all/#fn1\">1</a></sup>.
        And even though there are only two days left, I might even get some valuable
        feedback.</p><p>We science bloggers have many recurring themes, and this session
        is again about access to information and filtering out the important information.</p><h3
        id=\"access\">Access</h3><p>The traditional format to provide important medical
        information is the peer-reviewed journal article. Unless you work at a large
        research institution or university hospital, only part of these papers will
        be available as full-text articles. Notable examples of journals with immediate
        open access to peer reviewed research are the <a href=\"https://web.archive.org/web/20151003022812/http://www.bmj.com/channels/research.dtl\">British
        Medical Journal</a>, <a href=\"https://web.archive.org/web/20151003022812/http://medicine.plosjournals.org/\">PLoS
        Medicine</a>, <a href=\"https://web.archive.org/web/20151003022812/http://www.biomedcentral.com/bmcmed/\">BMC
        Medicine</a> and <a href=\"https://web.archive.org/web/20151003022812/http://www.openmedicine.ca/\">Open
        Medicine</a>. Many other medical journals provide free fulltext access 6-12
        months after publication, and this is now a requirement for research funded
        by many funding agencies, including the <a href=\"https://web.archive.org/web/20151003022812/http://publicaccess.nih.gov/policy.htm\">NIH</a>,
        the <a href=\"https://web.archive.org/web/20151003022812/http://www.wellcome.ac.uk/About-us/Policy/Spotlight-issues/Open-access/Policy/index.htm\">Wellcome
        Trust</a>, <a href=\"https://web.archive.org/web/20151003022812/http://www.hhmi.org/about/research/journals/main?action=search\">Howard
        Hughes Medical Institute</a>.</p><p>Clinical trials are essential to improve
        the prevention, diagnosis and treatment of many medical conditions. Since
        2005 all clinical trials have to registered in one of several central databases
        (e.g. <a href=\"https://web.archive.org/web/20151003022812/http://www.clinicaltrials.gov/\">clinicaltrials.gov</a>)
        before the first patient is treated. The information in these publicly accessible
        databases includes the trial design and participating centers. Since September
        2008, clinicaltrials.gov started to also report key results, as required by
        the <a href=\"https://web.archive.org/web/20151003022812/http://network.nature.com/people/mfenner/blog/2008/08/02/fdaaa-push-to-open-data-in-clinical-medicine\">Federal
        Drug Administration Amendment Act</a>. It is important to remember that <a
        href=\"https://web.archive.org/web/20151003022812/http://network.nature.com/people/mfenner/blog/2009/01/10/what-science-is-worth-shouting-about\">not
        all clinical trials eventually will be published</a>, so that looking just
        at the published literature will not give a complete picture.</p><h3 id=\"filtering\">Filtering</h3><p>Access
        to important medical information is only the first step. The filtering of
        this information is at least as important. With filtering I mean both finding
        the important research papers and evaluating them in a larger context. A meta-analysis
        is a systematic review that follows a standard set of rules for finding and
        evaluating research papers, a format championed by the <a href=\"https://web.archive.org/web/20151003022812/http://www.cochrane.org/\">Cochrane
        Collaboration</a>. A meta-analysis can not only summarize published research
        papers, but sometimes also uses the raw data of the published research (the
        so-called individual patient data meta-analysis). I would wish that the meta-analysis
        receives the same kind of attention in the blogosphere as the open access
        to research papers.</p><p>Whereas a positive outcome in a good meta-analysis
        is the best evidence for the usefulness of a healthcare intervention, most
        filtering of biomedical research papers comes to us in different ways:</p><ul><li>Review
        articles</li><li>Journal editorials</li><li>Science blogging</li><li>Articles
        by science journalists</li><li> <a href=\"https://web.archive.org/web/20151003022812/http://network.nature.com/people/mfenner/blog/2008/12/05/open-access-is-not-enough-the-source-is-also-important\">Direct
        to consumer advertising</a> (United States and New Zealand only)</li><li>Social
        networking sites such as <a href=\"https://web.archive.org/web/20151003022812/http://www.connotea.org/\">Connotea</a>,
        <a href=\"https://web.archive.org/web/20151003022812/http://www.citeulike.org/\">CiteULike</a>
        or <a href=\"https://web.archive.org/web/20151003022812/http://www.friendfeed.com/\">FriendFeed</a></li></ul><p>I
        would argue that science articles in traditional media (e.g. newspapers) and
        direct to consumer advertising may work in drawing your attention to a research
        paper, but they are usually useless in evaluating biomedical research. And
        obviously I believe that science blogging has great potential to help in both
        the finding and evaluation of important biomedical research. Meta-analyses
        take a very long time and review articles take a long time. A thoughtful blog
        post on a recently published paper can provide an important service. <a href=\"https://web.archive.org/web/20151003022812/http://researchblogging.org/\">Research
        Blogging</a> and <a href=\"https://web.archive.org/web/20151003022812/http://blogs.nature.com/\">Nature
        Blogs</a> are two services to help find these blog posts. Social networking
        sites for scientists are a great tool to find interesting research papers,
        but I don't know how they can help evaluate a research paper. <a href=\"https://web.archive.org/web/20151003022812/http://www.f1000medicine.com/\">Faculty
        of 1000 Medicine</a> is a very interesting approach to the filtering problem,
        but I haven't used the service enough to comment on it here.</p><p><em><em>Addendum
        (01/18/09)</em></em><br>It can be a good thing to have your presentation on
        the second day of a conference. You come up with new ideas. I changed the
        title to better convey what I would like to talk about in this session: <em><em>Reporting
        medical research:</em></em> <em><em>specific problems and specific solutions</em></em>.
        And I've added another topic besides access and filtering:</p><h3 id=\"motivation\">Motivation</h3><p>There
        are many reasons why people are interested in reporting or learning about
        medical research. But betroffenheit and financial interests are two very strong
        reasons that should always be kept in mind. Betroffenheit is a German word
        that means something that is directly affecting your life. If you are a patient
        with a serious medical condition, or have a sick friend or relative, you obviously
        have very different needs than someone who just wants to catch up on the latest
        research on the release of calcium from intracellular stores. Betroffenheit
        is not confined to medical research, climate change is another example.<br>Obviously
        there are often important financial interests behind the outcome of medical
        research. And this not only means the interests of drug companies or device
        manufacturers. Most presentations of medical research in larger meetings now
        begin with a financial disclosure slide.</p><p>I've updated the <a href=\"https://web.archive.org/web/20151003022812/http://www.slideshare.net/mfenner/providing-public-health-and-medical-information-to-all-presentation-924116\">Slideshare
        Presentation</a> that I want to give as an introduction to the session. And
        the conference Wiki page for the session is <a href=\"https://web.archive.org/web/20151003022812/http://www.scienceonline09.com/index.php/wiki/Public_health_and_medical_information/\">here</a>.</p><p>fn1.
        Yet another argument for the usefulness of science blogging.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ What science is worth shouting about? ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/what-science-is-worth-shouting-about/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw4b</id>\n        <published>2009-01-10T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-31T07:44:22.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>A few weeks ago I wrote about
        the different ways results of a clinical trial can be reported (<a href=\"https://web.archive.org/web/20151003033024/http://network.nature.com/people/mfenner/blog/2008/11/23/what-are-the-right-numbers-for-jupiter\">What
        are the right numbers for JUPITER</a>). Inspired by blog posts by <em><em>Eva
        Amsen</em></em> (<a href=\"https://web.archive.org/web/20151003033024/http://network.nature.com/people/eva/blog/2008/12/29/failure\">Failure</a>)
        and <em><em>Sally Church</em></em> (<a href=\"https://web.archive.org/web/20151003033024/http://www.pharmastrategyblog.com/2009/01/over-hyped-cancer-drugs-or-sensational-journalism.html\">Over
        hyped cancer drugs or sensational journalism?</a>), I thought more about what
        makes scientific findings worth talking about outside of your immediate research
        community. I will look at cancer research, and it is obvious that some research
        findings are more exciting than others. But it less obvious that it is as
        important who is communicating the research and what is the intended audience.
        This is especially true for translational research<sup><a href=\"https://web.archive.org/web/20151003033024/http://blogs.plos.org/mfenner/2009/01/10/what_science_is_worth_shouting_about/#fn1\">
        </a></sup>(Translational Research 2008), where research findings can change
        the way we treat patients and drug companies (and others) can potentially
        earn a lot of money.</p><h3 id=\"the-academic-researcher\">The academic researcher</h3><p>Academic
        researchers involved in basic or clinical cancer research are interested in
        publications and grant money. As Eva <a href=\"https://web.archive.org/web/20151003033024/http://network.nature.com/people/eva/blog/2008/12/29/failure\">said</a>:
        the unit of success is the publication record. Basic cancer research can be
        very exciting and touches many related fields from signal transduction to
        epigenetics. But what confuses me is when basic research findings are related
        to the treatment of human cancer, which is a completely different story. Cell
        lines are not living organisms, mice are not men and very few basic research
        findings make it into a clinical trial.<br>Unfortunately less than one in
        five studies in cancer (they all have to be registered with <a href=\"https://web.archive.org/web/20151003033024/http://www.clinicaltrials.gov/\">clinicaltrials.gov</a>
        since 2005) have been published in peer-reviewed journals (Ramsey 2008). Negative
        results will usually not be published, and this so-called publication bias
        creates many problems. Just imagine 5 clinical trials with a new drug where
        one trial will show an advantage for the new treatment. This trial will be
        published in a nice journal, probably one negative trial will be published
        in a small journal and the remaining 3 trials will remain unpublished. Just
        looking at the published literature will of course give the wrong impression,
        but these are the only data that are available to most people.</p><h3 id=\"the-drug-company\">The
        drug company</h3><p>A drug company is interested in marketing approval of
        a drug. This approval is obtained from the <em><em>Food and Drug Administration</em></em>
        (FDA) in the United States and from the <em><em>European Medicines Agency</em></em>
        EMEA for most of Europe. Approval of a cancer drug usually requires one or
        more large randomized trials (so-called phase III trials) that shows that
        the drug improves survival. And up to 50% of these phase III trials fail to
        show the desired effect, even when earlier (so-called phase II) trials were
        positive<sup><a href=\"https://web.archive.org/web/20151003033024/http://blogs.plos.org/mfenner/2009/01/10/what_science_is_worth_shouting_about/#fn3\">
        </a></sup>(Chan 2008). <a href=\"https://web.archive.org/web/20151003033024/http://www.gpc-biotech.com/en/anticancer_programs/satraplatin/clinical_trials/index.html\">Satraplatin</a>
        is one recent example of a drug that showed promising results in the treatment
        of prostate cancer but failed to prolong survival \u2013 and therefore was
        not approved by the FDA.</p><h3 id=\"the-insurance-company-or-whoever-pays-for-medical-care-\">The
        insurance company (or whoever pays for medical care)</h3><p>The drug erlotinib
        was approved for the treatment of pancreatic cancer, but the median benefit
        in overall survival was less than 2 weeks<sup><a href=\"https://web.archive.org/web/20151003033024/http://blogs.plos.org/mfenner/2009/01/10/what_science_is_worth_shouting_about/#fn4\">
        </a></sup>(Moore 2007). Insurance companies are interested in treatments that
        are not only effective, but also cost-effective. For cancer treatments one
        can calculate the cost per quality-adjusted life year (QALY). Adding erlotinib
        to gemcitabine in the treatment of pancreatic cancer would cost about $410,000
        per year of life saved<sup><a href=\"https://web.archive.org/web/20151003033024/http://blogs.plos.org/mfenner/2009/01/10/what_science_is_worth_shouting_about/#fn5\">
        </a></sup>(Miksad 2007). Costs over $100.000 per year of life saved are considered
        high and the high cost is the reason that the British National Institute for
        Health and Clinical Excellence (NICE) decided to not recommend <a href=\"https://web.archive.org/web/20151003033024/http://www.medscape.com/viewarticle/579628\">4
        new drugs for the treatment of renal cancer</a> in August 2008. NICE doesn't
        question the effectiveness of these drugs, but wants these drugs to become
        cheaper.</p><h3 id=\"the-media\">The media</h3><p>Cancer research sells. Cancer
        is very common and many people can tell sad stories of friends or relatives
        that died because of cancer. And we want to hear encouraging stories. But
        the media often confuse promising findings in basic research or early clinical
        trials with a new cure for cancer. One of the more famous examples is the
        statement <em><em>Judah is going to cure cancer in two years</em></em> by
        James Watson in a 1998 <em><em>New York Times</em></em> story on angiogenesis
        research (<a href=\"https://web.archive.org/web/20151003033024/http://query.nytimes.com/gst/fullpage.html?res=9F04E6D6113EF930A35756C0A96E958260&amp;sec=&amp;spon=&amp;partner=permalink&amp;exprod=permalink\">A
        Cautious Awe Greets Drugs That Eradicate Tumors in Mice</a>). Another example
        is this recent article (cited by <em><em>Sally Church</em></em> in her blog
        post mentioned above) in the <em><em>Times</em></em> (<a href=\"https://web.archive.org/web/20151003033024/http://www.timesonline.co.uk/tol/life_and_style/men/article4375429.ece\">Cancer
        drug could save the lives of 10,000 a year</a>). <em><em>Ben Goldacre</em></em>
        has written more than one critical blog post about how traditional media report
        cancer research (e.g. <a href=\"https://web.archive.org/web/20151003033024/http://www.guardian.co.uk/commentisfree/2008/jul/19/cancer.foodtech\">Still
        no cure for cancer hysteria</a>).</p><h3 id=\"the-patient\">The patient</h3><p>A
        patient with cancer needs a drug treatment that either cures his cancer or
        prolongs survival. The new treatment should either be better or have fewer
        side effects than the current standard of care. But many cancer patients can't
        wait until a new cancer drug is approved and available for prescription. So
        whenever possible, patients should participate in a clinical trial. Clinical
        trial participation by adult cancer patients is unfortunately low (less than
        5% compared to more than 50% for children with cancer<sup><a href=\"https://web.archive.org/web/20151003033024/http://blogs.plos.org/mfenner/2009/01/10/what_science_is_worth_shouting_about/#fn6\">
        </a></sup>(Sateren 2002)), but this is the best way to receive a promising
        new drug as early as possible (and to stop receiving it when the drug has
        been shown to be ineffective or toxic).</p><h3 id=\"conclusions\">Conclusions</h3><p>We
        should be careful how we report research findings outside of specialist journals
        or research meetings, especially if these findings could have important consequences
        outside our immediate research community. And as a critical reader we should
        assume that most published research findings are false<sup><a href=\"https://web.archive.org/web/20151003033024/http://blogs.plos.org/mfenner/2009/01/10/what_science_is_worth_shouting_about/#fn7\">
        </a></sup>(Ioannidis 2005).</p><h3 id=\"references\">References</h3><p>Translational
        Research: Getting the message across. (2008). Nature, 453(7197), 839\u2013839.
        <a href=\"https://doi.org/10.1038/453839a\">https://doi.org/10.1038/453839a</a></p><p>Ramsey,
        S., &amp; Scoggins, J. (2008). Commentary: Practicing on the Tip of an Information
        Iceberg? Evidence of Underpublication of Registered Clinical Trials in Oncology.
        The Oncologist, 13(9), 925\u2013929. <a href=\"https://doi.org/10.1634/theoncologist.2008-0133\">https://doi.org/10.1634/theoncologist.2008-0133</a></p><p>Chan,
        J. K., Ueda, S. M., Sugiyama, V. E., Stave, C. D., Shin, J. Y., Monk, B. J.,
        \u2026 Kapp, D. S. (2008). Analysis of Phase II Studies on Targeted Agents
        and Subsequent Phase III Trials: What Are the Predictors for Success? Journal
        of Clinical Oncology, 26(9), 1511\u20131518. <a href=\"https://doi.org/10.1200/jco.2007.14.8874\">https://doi.org/10.1200/jco.2007.14.8874</a></p><p>Moore,
        M. J., Goldstein, D., Hamm, J., Figer, A., Hecht, J. R., Gallinger, S., \u2026
        Parulekar, W. (2007). Erlotinib Plus Gemcitabine Compared With Gemcitabine
        Alone in Patients With Advanced Pancreatic Cancer: A Phase III Trial of the
        National Cancer Institute of Canada Clinical Trials Group. Journal of Clinical
        Oncology, 25(15), 1960\u20131966. <a href=\"https://doi.org/10.1200/jco.2006.07.9525\">https://doi.org/10.1200/jco.2006.07.9525</a></p><p>Miksad,
        R. A., Schnipper, L., &amp; Goldstein, M. (2007). Does a Statistically Significant
        Survival Benefit of Erlotinib Plus Gemcitabine for Advanced Pancreatic Cancer
        Translate Into Clinical Significance and Value? Journal of Clinical Oncology,
        25(28), 4506\u20134507. https://doi.org/10.1200/jco.2007.13.0401</p><p>Sateren,
        W. B., Trimble, E. L., Abrams, J., Brawley, O., Breen, N., Ford, L., \u2026
        Christian, M. C. (2002). How Sociodemographics, Presence of Oncology Specialists,
        and Hospital Cancer Programs Affect Accrual to Cancer Treatment Trials. Journal
        of Clinical Oncology, 20(8), 2109\u20132117. <a href=\"https://doi.org/10.1200/jco.2002.08.056\">https://doi.org/10.1200/jco.2002.08.056</a></p><p>Ioannidis,
        J. P. A. (2005). Why Most Published Research Findings Are False. PLoS Medicine,
        2(8), e124. <a href=\"https://doi.org/10.1371/journal.pmed.0020124\">https://doi.org/10.1371/journal.pmed.0020124</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ My Personal Plans for 2009 ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/my-personal-plans-for-2009/\" />\n\t\t<id>https://doi.org/10.53731/a4290ef-f1jdggn</id>\n
        \       <published>2008-12-28T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-14T15:02:19.000+00:00</updated>\n
        \       <media:content url=\"\" medium=\"image\"/>\n        <content type=\"html\"><![CDATA[
        <p><img src=\"\"></p><p>The end of the year is always a time to think about
        the past and the future. Even more so if you also have your birthday (FemaleScienceProfessor
        calls it <a href=\"https://web.archive.org/web/20150923121708/http://science-professor.blogspot.com/2007/12/christmas-time-birthdays.html\">Christmas
        Time Birthdays</a>). Below are some of my plans for the next year. The general
        theme: more overlap of science blogging with my daytime job as physician treating
        cancer patients and doing cancer research.</p><h3 id=\"meet-fellow-science-bloggers\">Meet
        fellow science bloggers</h3><p>I'm looking forward to <a href=\"https://web.archive.org/web/20150923121708/http://www.scienceonline09.com/\">ScienceOnline'09</a>
        in January. Please contact me by email if you have an interesting idea for
        the session Providing public health and medical information to all. <a href=\"https://web.archive.org/web/20150923121708/http://www.chiswick.demon.co.uk/CISB09.html\">Cromer
        is so Bracing</a> in February will be very different, maybe something like
        conversations at the fireplace? And I hope we repeat <a href=\"https://web.archive.org/web/20150923121708/http://www.nature.com/natureconferences/sciblog2008/index.html\">Science
        Blogging 2008: London</a>.</p><h3 id=\"start-a-new-job\">Start a new job</h3><p>If
        everything works out as expected, I will start a new job next year. It will
        still be at my institution and will in fact be very similar, but will present
        new challenges and opportunities. One of these new opportunities is science
        communication, or how to communicate our efforts in cancer research and treating
        cancer patients both within our institution and to the public.</p><h3 id=\"blog-more-about-research\">Blog
        more about research</h3><p>Science blogging <a href=\"https://web.archive.org/web/20150923121708/http://network.nature.com/people/mfenner/blog/2008/08/31/science-blogging-is-the-new-email\">means
        many different things to different people</a>. Blogging about research (your
        own or that of other people) is one important part of it. In 2008 I have written
        only a few blog posts about research (e.g. <a href=\"https://web.archive.org/web/20150923121708/http://network.nature.com/people/mfenner/blog/2008/11/23/what-are-the-right-numbers-for-jupiter\">this
        one</a>), but I want to do more of it in 2009. <a href=\"https://web.archive.org/web/20150923121708/http://blogs.nature.com/\">Nature.com
        Blogs</a> and <a href=\"https://web.archive.org/web/20150923121708/http://www.researchblogging.org/\">Research
        Blogging</a> are great tools to find blogging about research, and I hope the
        <a href=\"https://web.archive.org/web/20150923121708/http://researchblogging.org/news/?p=109\">broken
        integration</a> of Nature Network blog posts with Research Blogging will soon
        be fixed.</p><h3 id=\"start-a-new-blog\">Start a new blog</h3><p>Related to
        the last two topics, I might start a new blog. This would be a German-language
        blog and would be an official blog of our institution. But first I have to
        convince a few people that such a blog is a good idea. I might ask <a href=\"https://web.archive.org/web/20150923121708/http://network.nature.com/people/edyong/profile\">Ed
        Yong</a> for advice, as he writes for <a href=\"https://web.archive.org/web/20150923121708/http://info.cancerresearchuk.org/\">Cancer
        Research UK</a>.</p><h3 id=\"find-good-papers\">Find good papers</h3><p>The
        <a href=\"https://web.archive.org/web/20150923121708/http://network.nature.com/groups/goodpaper/forum/topics\">Good
        Paper Journal Club</a> is a Nature Network Forum to promote good scientific
        writing. It is a good idea and the forum has over 200 members and some very
        interesting discussions, but it is very time-consuming to find good examples
        of well-written papers. The best approach would be regular contributions by
        a large number of people, but the incentives for doing so are probably not
        there. But it is possible to pick well-written papers from a journal I read
        anyway, so I will try to do that for <em><em>Nature</em></em> in regular intervals
        in 2009. And in January I will give my first seminar on science writing.</p><h3
        id=\"collaborate-with-fellow-science-bloggers\">Collaborate with fellow science
        bloggers</h3><p>We constantly have many interesting and (sometimes) important
        discussions. Why shouldn't more of these discussions turn into formal projects,
        e.g. a paper or a presentation at a science conference? Science bloggers are
        a very diverse mix of people, and this could lead to some very interesting
        approaches.</p><h3 id=\"spend-more-time-cooking\">Spend more time cooking</h3><p>I
        think it is important to also do stuff not related to science. Some fellow
        Nature Network bloggers write books (<a href=\"https://web.archive.org/web/20150923121708/http://network.nature.com/people/UE19877E8/blog/2008/11/15/in-which-books-are-judged-by-covers\">Jennifer
        Rohn</a>, <a href=\"https://web.archive.org/web/20150923121708/http://stores.lulu.com/siegeofstars\">Henry
        Gee</a>), write about books (<a href=\"https://web.archive.org/web/20150923121708/http://petrona.typepad.com/\">Maxine
        Clarke</a>), write about music (<a href=\"https://web.archive.org/web/20150923121708/http://scientistmusicians.wordpress.com/\">Eva
        Amsen</a>), write about food (<a href=\"https://web.archive.org/web/20150923121708/http://sunday-night-dinner.blogspot.com/\">Anna
        Kushnir</a>) or write about their favorite city (<a href=\"https://web.archive.org/web/20150923121708/http://network.nature.com/hubs/london/blog/2008/12/09/going-solo\">Matt
        Brown</a>). I like cooking. I don't write about it, but I hope to do more
        cooking in 2009. Preparing good food is not only tasty and fun, but also a
        good distraction from the daytime work. And reading a good cookbook (for example
        <a href=\"https://web.archive.org/web/20150923121708/http://www.becomingachef.com/culinary_artistry.php\">Culinary
        Artistry</a>) can be as entertaining as reading a good novel.</p><h3 id=\"go-to-a-warm-place-in-the-summer\">Go
        to a warm place in the summer</h3><p>This year's summer vacation was basically
        a trip to London for a long weekend. Next year I need a longer summer vacation,
        and also a place with more sun. We have almost finished planning our trip
        to this place:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img
        src=\"https://web.archive.org/web/20150923121708im_/http://farm1.static.flickr.com/197/487031747_5f63a95cd9_m_d.jpg\"
        class=\"kg-image\" alt loading=\"lazy\"><figcaption><a href=\"https://web.archive.org/web/20150923121708/http://www.flickr.com/photos/scingram/487031747/\">Flickr
        Picture by Scott Ingram</a></figcaption></figure> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Just DOI it! ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/just-doi-it/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw4c</id>\n        <published>2008-12-22T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-31T07:43:20.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>With the <a href=\"https://web.archive.org/web/20151003053153/http://www.nature.com/nature/journal/v456/n7224/\">December
        18 issue</a> <em><em>Nature</em></em> started to support XMP markup in article
        PDFs (reported last week on the <em><em>Nascent</em></em> blog by <em><em>Tony
        Hammond</em></em>)<sup><a href=\"https://web.archive.org/web/20151003053153/http://blogs.plos.org/mfenner/2008/12/22/just_doi_it/#fn1\">1</a></sup>.
        XMP stands for Extensible Metadata Platform and is a technology to embed metadata
        in files, including PDFs<sup><a href=\"https://web.archive.org/web/20151003053153/http://blogs.plos.org/mfenner/2008/12/22/just_doi_it/#fn2\">2</a></sup>.
        XMP was created by Adobe (with XMP support in PDF files since 2001), but is
        an open standard with backing by others, including Creative Commons<sup><a
        href=\"https://web.archive.org/web/20151003053153/http://blogs.plos.org/mfenner/2008/12/22/just_doi_it/#fn3\">3</a></sup>.
        The Digital Object Identifier (<a href=\"https://web.archive.org/web/20151003053153/http://www.doi.org/\">DOI</a>)
        is the most important piece of information in the metadata, as the DOI provides
        a link to the journal publisher website where more metadata can be retrieved.
        XMP support in scientific PDFs is unfortunately still very uncommon and probably
        hasn't changed much since <a href=\"https://web.archive.org/web/20151003053153/http://network.nature.com/people/lindenb/profile\">Pierre
        Lindenbaum</a> checked last year<sup><a href=\"https://web.archive.org/web/20151003053153/http://blogs.plos.org/mfenner/2008/12/22/just_doi_it/#fn4\">4</a></sup>.</p><p>Adding
        metadata to PDFs seems to be a no-brainer. We have done the same with music
        (mp3 ID) and photos (IPTC and EXIF) for years and it has been a tremendous
        help in organizing these files stored on our computers. Unfortunately there
        aren't too many tools that can extract the DOI or other metadata from the
        XMP in article PDFs. But I expect more desktop software to support XMP, once
        XMP support in scientific articles is more widespread. We will then be able
        to add a journal PDF to our reference manager of choice and have the relevant
        metadata (including authors, title, journal and issue) automatically filled
        in. As well as many other creative uses. Until then we need tools like <a
        href=\"https://web.archive.org/web/20151003053153/http://mekentosj.com/papers/\">Papers</a>
        or <a href=\"https://web.archive.org/web/20151003053153/http://www.mendeley.com/\">Mendeley</a>
        that can extract metadata from PDF files without this XMP information.</p><p>For
        a more technical discussion of XMP in scientific articles, please read the
        set of blog posts by Tony Hammond<sup><a href=\"https://web.archive.org/web/20151003053153/http://blogs.plos.org/mfenner/2008/12/22/just_doi_it/#fn5\">5</a></sup>,<sup><a
        href=\"https://web.archive.org/web/20151003053153/http://blogs.plos.org/mfenner/2008/12/22/just_doi_it/#fn6\">6</a></sup>,<sup><a
        href=\"https://web.archive.org/web/20151003053153/http://blogs.plos.org/mfenner/2008/12/22/just_doi_it/#fn7\">7</a></sup>.</p><p>fn1.
        <a href=\"https://web.archive.org/web/20151003053153/http://blogs.nature.com/wp/nascent/2008/12/xmp_labelling_for_nature.html\">XMP
        Labelling for Nature</a></p><p>fn2. <a href=\"https://web.archive.org/web/20151003053153/http://www.adobe.com/products/xmp/\">Adding
        intelligence to media</a></p><p>fn3. <a href=\"https://web.archive.org/web/20151003053153/http://wiki.creativecommons.org/XMP\">XMP</a></p><p>fn4.
        <a href=\"https://web.archive.org/web/20151003053153/http://plindenbaum.blogspot.com/2007/05/is-there-any-xmp-in-scientific-pdf-no.html\">Is
        there any XMP in scientific pdf? No</a></p><p>fn5. <a href=\"https://web.archive.org/web/20151003053153/http://www.crossref.org/CrossTech/2007/08/metadata_in_pdf_1_strategies.html\">Metadata
        in PDF: 1. Strategies</a></p><p>fn6. <a href=\"https://web.archive.org/web/20151003053153/http://www.crossref.org/CrossTech/2007/08/metadata_in_pdf_2_use_cases.html\">Metadata
        in PDF: 2. Use Cases</a></p><p>fn7. <a href=\"https://web.archive.org/web/20151003053153/http://www.crossref.org/CrossTech/2007/08/metadata_in_pdf_3_deployment_1.html\">Metadata
        in PDF: 3. Deployment</a></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Open access is not enough \u2013 the source
        is also important ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/open-access-is-not-enough-the-source-is-also-important/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw4d</id>\n        <published>2008-12-05T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-31T07:42:35.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Direct to consumer advertising
        (DTCA) \u2013 advertising for prescription drugs \u2013 is only allowed in
        the United States (since 1997, when restrictions were loosened) and New Zealand.
        Drug companies pay for direct to consumer advertising (more than $4 billion
        in 2005 (Donohue 2007)) because they believe that it increases prescription
        rates. In a clever study published in the <em><em>British Medical Journal</em></em>
        in September<sup><a href=\"https://web.archive.org/web/20150922174115/http://blogs.plos.org/mfenner/2008/12/05/open_access_is_not_enough_the_source_is_also_important/#fn2\">
        </a></sup>(Law 2008) Michael Law and colleagues looked at the prescription
        rates of the drugs etanercept, mometasone, and tegaserod in Canada. DTCA is
        not allowed in Canada, but English-speaking Canadians see these ads in US
        magazines and US TV commercials. The study authors found that prescriptions
        were higher compared to French-speaking Canada (supposedly not using the US
        media) for one of the three drugs studied (tegaserod). The study authors explain:</p><p>The
        European Union is considering changes in legislation that would allow direct
        to consumer advertising (<a href=\"https://web.archive.org/web/20150922174115/http://www.pharmalot.com/2008/10/eu-plan-gives-pharma-direct-access-to-patients/\">EU
        Plan Gives Pharma Direct Access To Patients</a>). Not a good idea. Direct
        to consumer advertising not only means easily identified ads, but also information
        campaigns about diseases and treatments that are biased towards prescribing
        a particular drug.</p><p>The problems surrounding direct to consumer advertising
        are a reminder that open access to scientific and medical information is not
        enough. Similar conflicts of interest exist when car manufacturers would talk
        about climate change or crop producers about genetically engineered crops.
        We need not access to as much information as possible, but rather access to
        independent and objective information of high quality. Scientific journals
        and learned societies have traditionally played an important role in this.
        Once they've built up more reputation, science bloggers could have a bigger
        role in this in the future.</p><h3 id=\"references\">References</h3><p>Donohue,
        J. M., Cevasco, M., &amp; Rosenthal, M. B. (2007). A Decade of Direct-to-Consumer
        Advertising of Prescription Drugs. New England Journal of Medicine, 357(7),
        673\u2013681. <a href=\"https://doi.org/10.1056/nejmsa070502\">https://doi.org/10.1056/nejmsa070502</a></p><p>Law,
        M. R., Majumdar, S. R., &amp; Soumerai, S. B. (2008). Effect of illicit direct
        to consumer advertising on use of etanercept, mometasone, and tegaserod in
        Canada: controlled longitudinal study. BMJ, 337(sep02 1), a1055\u2013a1055.
        <a href=\"https://doi.org/10.1136/bmj.a1055\">https://doi.org/10.1136/bmj.a1055</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Why do we blog and other important questions,
        answered by 34 science bloggers ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/why-do-we-blog-and-other-important-questions-answered-by-34-science-bloggers/\"
        />\n\t\t<id>https://doi.org/10.53731/8gj67xy-yz5r80q</id>\n        <published>2008-11-30T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-14T15:03:21.000+00:00</updated>\n\t\t<category
        term=\"Interview\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>What started
        out as <a href=\"https://web.archive.org/web/20151003123037/http://network.nature.com/groups/nnbloggername/forum/topics/3392\">a
        few questions to science bloggers</a> in the <em><em>Nature Network Bloggers
        Forum</em></em>, has turned into a collection of more than 30 blog posts not
        limited to <em><em>Nature Network</em></em> (big thanks to <a href=\"https://web.archive.org/web/20151003123037/http://scienceblogs.com/clock/2008/11/the_science_blog_meme.php\">Bora</a>
        and others for spreading the word). The following science bloggers answered
        a set of 10 questions about their blogging (roughly in chronological order):</p><ul><li><a
        href=\"https://web.archive.org/web/20151003123037/http://network.nature.com/people/henrygee/blog/2008/11/14/that-martin-fenner-effect\">Henry
        Gee</a></li><li><a href=\"https://web.archive.org/web/20151003123037/http://network.nature.com/people/U27CE62BB/blog/2008/11/14/blog-survey\">Eva
        Amsen</a></li><li><a href=\"https://web.archive.org/web/20151003123037/http://network.nature.com/people/stuffysour/blog/2008/11/14/its-the-need-to-communicate\">Steffi
        Suhr</a></li><li><a href=\"https://web.archive.org/web/20151003123037/http://network.nature.com/people/scurry/blog/2008/11/14/about-a-blog\">Stephen
        Curry</a></li><li><a href=\"https://web.archive.org/web/20151003123037/http://petrona.typepad.com/petrona/2008/11/pinning-ones-hamster-to-the-mast.html\">Maxine
        Clarke</a></li><li><a href=\"https://web.archive.org/web/20151003123037/http://network.nature.com/people/mfenner/blog/2008/11/14/some-answers-for-henry-gee\">Martin
        Fenner</a></li><li><a href=\"https://web.archive.org/web/20151003123037/http://scienceblogs.com/clock/2008/11/the_science_blog_meme.php\">Bora
        Zivkovic</a></li><li><a href=\"https://web.archive.org/web/20151003123037/http://keeperofthesnails.blogspot.com/2008/11/nature-meme.html\">Clare
        Dudman</a></li><li><a href=\"https://web.archive.org/web/20151003123037/http://genomicron.blogspot.com/2008/11/why-do-we-blog-and-other-important.html\">T.
        Ryan Gregory</a></li><li><a href=\"https://web.archive.org/web/20151003123037/http://network.nature.com/people/massimopinto/blog/2008/11/15/whats-this-bel-paese\">Massimo
        Pinto</a> (and <a href=\"https://web.archive.org/web/20151003123037/http://www.galileonet.it/postdoc/article/74/alt-si-ma-quanti-siete\">another
        post</a> in Italian)</li><li><a href=\"https://web.archive.org/web/20151003123037/http://www.tuibguy.com/?p=2407\">Mike
        Haubrich</a></li><li><a href=\"https://web.archive.org/web/20151003123037/http://sandwalk.blogspot.com/2008/11/why-do-we-blog-and-other-important.html\">Larry
        Moran</a></li><li><a href=\"https://web.archive.org/web/20151003123037/http://scienceblogs.com/evolvingthoughts/2008/11/another_goldang_meme.php\">John
        Wilkins</a></li><li><a href=\"https://web.archive.org/web/20151003123037/http://network.nature.com/people/U3EABC9C8/blog/2008/11/15/oh-noes-meta-blogging\">Kristi
        Vogel</a></li><li><a href=\"https://web.archive.org/web/20151003123037/http://blindscientist.genedrift.org/2008/11/16/the-science-blog-meme/\">Paolo
        Nuin</a></li><li><a href=\"https://web.archive.org/web/20151003123037/http://network.nature.com/people/etchevers/blog/2008/11/16/me-me-meme\">Heather
        Etchevers</a></li><li><a href=\"https://web.archive.org/web/20151003123037/http://network.nature.com/people/U71147CBA/blog/2008/11/16/on-the-theme-of-martins-meme\">Lee
        Turnpenny</a></li><li><a href=\"https://web.archive.org/web/20151003123037/http://my.biotechlife.net/2008/11/16/the-science-blog-meme/\">Ricardo
        Vidal</a></li><li><a href=\"https://web.archive.org/web/20151003123037/http://network.nature.com/people/boboh/blog/2008/11/16/memetic-selections\">Bob
        O'Hara</a></li><li><a href=\"https://web.archive.org/web/20151003123037/http://mndoci.com/blog/2008/11/16/why-do-we-blog/\">Deepak
        Singh</a></li><li><a href=\"https://web.archive.org/web/20151003123037/http://network.nature.com/people/U81B5C465/blog/2008/11/16/la-meme-chose\">Frank
        Norman</a></li><li><a href=\"https://web.archive.org/web/20151003123037/http://fredcobio.wordpress.com/2008/11/17/scientistist-their-desks\">Jim
        Hardy</a></li><li><a href=\"https://web.archive.org/web/20151003123037/http://blog.pansapiens.com/2008/11/17/that-science-blog-meme-thing-going-around/\">Andrew
        Perry</a></li><li><a href=\"https://web.archive.org/web/20151003123037/http://pbeltrao.blogspot.com/2008/11/why-do-we-blog.html\">Pedro
        Beltrao</a></li><li><a href=\"https://web.archive.org/web/20151003123037/http://shirleywho.wordpress.com/2008/11/17/the-science-blog-meme-why-do-we-blog/\">Shirley
        Wu</a></li><li><a href=\"https://web.archive.org/web/20151003123037/http://www.amarkos.gr/blog/2008/11/252/\">Angelos
        Markos</a></li><li><a href=\"https://web.archive.org/web/20151003123037/http://www.corporeality.net/museion/2008/11/17/why-do-we-blog-and-other-important-questions-reply-to-martin-fenner-nature-networks/\">Thomas
        Soderqvist</a></li><li><a href=\"https://web.archive.org/web/20151003123037/http://the-mouse-trap.blogspot.com/2008/11/science-blog-meme.html\">Sandy
        Gautam</a></li><li><a href=\"https://web.archive.org/web/20151003123037/http://duncan.hull.name/2008/11/17/science-blog-meme-why-do-we-blog/\">Duncan
        Hull</a></li><li><a href=\"https://web.archive.org/web/20151003123037/http://jdupuis.blogspot.com/2008/11/science-blog-meme-why-do-we-blog.html\">John
        Dupuis</a></li><li><a href=\"https://web.archive.org/web/20151003123037/http://network.nature.com/people/mike/blog/2008/11/18/follow-those-lemmings-where\">Mike
        Fowler</a></li><li><a href=\"https://web.archive.org/web/20151003123037/http://network.nature.com/people/erikacule/blog/2008/11/18/meme-scheme\">Erika
        Cule</a></li><li><a href=\"https://web.archive.org/web/20151003123037/http://network.nature.com/people/strippedscience/blog/2008/11/18/100th-comic-strip\">Viktor
        Po</a></li><li><a href=\"https://web.archive.org/web/20151003123037/http://network.nature.com/people/rpg/blog/2008/11/19/the-martin-fenner-effect\">Richard
        Grant</a></li><li><a href=\"https://web.archive.org/web/20151003123037/http://scienceblogs.com/notrocketscience/2008/11/why_blog_the_meme_returns.php\">Ed
        Yong</a></li><li><a href=\"https://web.archive.org/web/20151003123037/http://scienceblogs.com/grrlscientist/2008/11/navelgazing_courtesy_of_nature.php\">GrrlScientist</a></li><li><a
        href=\"https://web.archive.org/web/20151003123037/http://www.pharmastrategyblog.com/2008/12/science-blog-meme.html\">Sally
        Church</a></li></ul><p><em><em>Please contact me if I missed a blog post.</em></em></p><p>Reading
        these blog posts is not only interesting and entertaining, but probably also
        a very good introduction to the current state of science blogging. Below is
        a personal summary of some of the answers. Oh, the best title was probably
        from <a href=\"https://web.archive.org/web/20151003123037/http://network.nature.com/people/U81B5C465/blog/2008/11/16/la-meme-chose\">Frank
        Norman</a>: <em><em>La meme chose</em></em>.</p><h3 id=\"1-what-is-your-blog-about\">1.
        What is your blog about?</h3><p>Most bloggers seem to write about many different
        science-related topics. And only a minority about the actual science they
        are doing. Some bloggers gave more specific answers:</p><ul><li><em><em>My
        blog is about science, in particular evolution and genomes.</em></em> (<a
        href=\"https://web.archive.org/web/20151003123037/http://genomicron.blogspot.com/2008/11/why-do-we-blog-and-other-important.html\">T.
        Ryan Gregory</a>)</li><li><em><em>It</em>'<em>s a sort of a window of transparency
        over a weird scientific environment, the Italian science jobs and funding
        market.</em></em> (<a href=\"https://web.archive.org/web/20151003123037/http://network.nature.com/people/massimopinto/blog/2008/11/15/whats-this-bel-paese\">Massimo
        Pinto</a>)</li><li><em><em>Basically the philosophical implications of science.</em></em>
        (<a href=\"https://web.archive.org/web/20151003123037/http://scienceblogs.com/evolvingthoughts/2008/11/another_goldang_meme.php\">John
        Wilkins</a>)</li><li><em><em>Anything releted to Biotechnology in Frederick
        County, MD.</em></em> (<a href=\"https://web.archive.org/web/20151003123037/http://fredcobio.wordpress.com/2008/11/17/scientistist-their-desks\">Jim
        Hardy</a>)</li><li><em><em>The general theme is how we can bring the worlds
        of information technology and the life sciences together.</em></em> (<a href=\"https://web.archive.org/web/20151003123037/http://mndoci.com/blog/2008/11/16/why-do-we-blog/\">Deepak
        Singh</a>)</li><li><em><em>I am trying to put the people behind the science
        into the spotlight: the technicians, operational support, science management
        and others.</em></em> (<a href=\"https://web.archive.org/web/20151003123037/http://network.nature.com/people/stuffysour/blog/2008/11/14/its-the-need-to-communicate\">Steffi
        Suhr</a>)</li><li><em><em>We write about making sense of medicine and medical
        science in museums.</em></em> (<a href=\"https://web.archive.org/web/20151003123037/http://www.corporeality.net/museion/2008/11/17/why-do-we-blog-and-other-important-questions-reply-to-martin-fenner-nature-networks/\">Thomas
        Soderqvist</a>)</li><li><em><em>Ostensibly about theoretical population biology.</em></em>
        (<a href=\"https://web.archive.org/web/20151003123037/http://network.nature.com/people/mike/blog/2008/11/18/follow-those-lemmings-where\">Mike
        Fowler</a>)</li><li><em><em>I am interested in how the internet is changing
        the way we publish and communicate science.</em></em> (<a href=\"https://web.archive.org/web/20151003123037/http://network.nature.com/people/mfenner/blog/2008/11/14/some-answers-for-henry-gee\">me</a>)</li></ul><h3
        id=\"2-what-will-you-never-write-about\">2. What will you never write about?</h3><p>Several
        people mentioned that they would not give out personal information about other
        people, or comment directly on what's going on in their institution/company.
        Most people also avoid to talk religious beliefs or politics. Confidential
        information, including unreleased papers, was mentioned several times. The
        <a href=\"https://web.archive.org/web/20151003123037/http://network.nature.com/people/henrygee/blog/2008/03/05/the-release-of-calcium-from-intracellular-stores-and-other-stuff\">release
        of calcium from intracellular stores</a> is another topic that several people
        would never blog about. Also:</p><ul><li><em><em>Only write about things I
        actually understand.</em></em> (<a href=\"https://web.archive.org/web/20151003123037/http://scienceblogs.com/notrocketscience/2008/11/why_blog_the_meme_returns.php\">Ed
        Yong</a>)</li><li><em><em>I will never ask anyone to give me money via this
        blog.</em></em> (<a href=\"https://web.archive.org/web/20151003123037/http://petrona.typepad.com/petrona/2008/11/pinning-ones-hamster-to-the-mast.html\">Maxine
        Clarke</a>)</li><li><em><em>I hope that I will not have to write blog posts
        that are evaluated, measured and put on a resum\xE9.</em></em> (<a href=\"https://web.archive.org/web/20151003123037/http://network.nature.com/people/mfenner/blog/2008/11/14/some-answers-for-henry-gee\">me</a>)</li></ul><h3
        id=\"3-have-you-ever-considered-leaving-science\">3. Have you ever considered
        leaving science?</h3><p>Several people said something similar to <a href=\"https://web.archive.org/web/20151003123037/http://scienceblogs.com/clock/2008/11/the_science_blog_meme.php\">Bora
        Zivkovic</a>: <em><em>Leaving research \u2013 yes, I already did that. Leaving
        science \u2013 never.</em></em></p><h3 id=\"4-what-would-you-do-instead\">4.
        What would you do instead?</h3><p>Some interesting answers. And a science
        background would be helpful in most of the jobs:</p><ul><li><em><em>Zookeeper,
        or an animal trainer in a circus</em></em> (<a href=\"https://web.archive.org/web/20151003123037/http://scienceblogs.com/clock/2006/06/how_to_become_a_biologist.php\">Bora
        Zivkovic</a>)</li><li><em><em>Jazz trumpeteer</em></em> (<a href=\"https://web.archive.org/web/20151003123037/http://network.nature.com/people/massimopinto/blog/2008/11/15/whats-this-bel-paese\">Massimo
        Pinto</a>)</li><li><em><em>I</em>'<em>d live on a beach somewhere, just fishing
        all day</em></em> (<a href=\"https://web.archive.org/web/20151003123037/http://fredcobio.wordpress.com/2008/11/17/scientistist-their-desks\">Jim
        Hardy</a>)</li><li><em><em>Own a used book store</em></em> (<a href=\"https://web.archive.org/web/20151003123037/http://jdupuis.blogspot.com/2008/11/science-blog-meme-why-do-we-blog.html\">John
        Dupuis</a>)</li><li><em><em>I</em>'<em>d try my best to get a job in video
        game development</em></em> (<a href=\"https://web.archive.org/web/20151003123037/http://blog.pansapiens.com/2008/11/17/that-science-blog-meme-thing-going-around/\">Andrew
        Perry</a>)</li><li><em><em>Playing football for England</em></em> (<a href=\"https://web.archive.org/web/20151003123037/http://www.pharmastrategyblog.com/2008/12/science-blog-meme.html\">Sally
        Church</a>)</li><li><em><em>Tend olive trees in Greece</em></em> (<a href=\"https://web.archive.org/web/20151003123037/http://duncan.hull.name/2008/11/17/science-blog-meme-why-do-we-blog/\">Duncan
        Hull</a>)</li><li><em><em>Yoga instructor</em></em> (<a href=\"https://web.archive.org/web/20151003123037/http://network.nature.com/people/erikacule/blog/2008/11/18/meme-scheme\">Erika
        Cule</a>)</li><li><em><em>Graphic designer</em></em> (<a href=\"https://web.archive.org/web/20151003123037/http://my.biotechlife.net/2008/11/16/the-science-blog-meme/\">Ricardo
        Vidal</a>)</li><li><em><em>Write very bad science fiction</em></em> (<a href=\"https://web.archive.org/web/20151003123037/http://scienceblogs.com/evolvingthoughts/2008/11/another_goldang_meme.php\">John
        Wilkins</a>)</li></ul><h3 id=\"5-what-do-you-think-will-science-blogging-be-like-in-5-years\">5.
        What do you think will science blogging be like in 5 years?</h3><p>This was
        a difficult question that some didn't answer. <a href=\"https://web.archive.org/web/20151003123037/http://sandwalk.blogspot.com/2008/11/why-do-we-blog-and-other-important.html\">Larry
        Moran</a> said: <em><em>pretty much the same as it is now.</em></em> <a href=\"https://web.archive.org/web/20151003123037/http://genomicron.blogspot.com/2008/11/why-do-we-blog-and-other-important.html\">T.
        Ryan Gregory</a> thinks that <em><em>more professional researchers will join
        the blogosphere as this becomes socially acceptable.</em></em> <a href=\"https://web.archive.org/web/20151003123037/http://blog.pansapiens.com/2008/11/17/that-science-blog-meme-thing-going-around/\">Andrew
        Perry</a> thinks that <em><em>research groups will be tied together more and
        more by their blogs.</em></em> <a href=\"https://web.archive.org/web/20151003123037/http://network.nature.com/people/U27CE62BB/blog/2008/11/14/blog-survey\">Eva
        Amsen</a> thinks that <em><em>there will be so many science blogs that we
        have to specialize.</em></em> And I wrote that <em><em>some science bloggers
        will be able to make enough money to earn a living from it.</em></em></p><h3
        id=\"6-what-is-the-most-extraordinary-thing-that-happened-to-you-because-of-blogging\">6.
        What is the most extraordinary thing that happened to you because of blogging?</h3><p><a
        href=\"https://web.archive.org/web/20151003123037/http://www.corporeality.net/museion/2008/11/17/why-do-we-blog-and-other-important-questions-reply-to-martin-fenner-nature-networks/\">Thomas
        Soderqvist</a> said that <em><em>there is no the most extraordinary thing.
        But I hadn</em>'<em>t expected to get so many interesting contacts with colleagues
        around the world.</em></em> Many people (including myself) had similar answers.
        Going to <a href=\"https://web.archive.org/web/20151003123037/http://www.nature.com/nature/meetings/scifoo/index.html\">SciFoo</a>
        is certainly an extraordinary thing an SciFoo invitation was mentioned by
        <a href=\"https://web.archive.org/web/20151003123037/http://pbeltrao.blogspot.com/2008/11/why-do-we-blog.html\">Pedro
        Beltrao</a>, <a href=\"https://web.archive.org/web/20151003123037/http://fredcobio.wordpress.com/2008/11/17/scientistist-their-desks\">Jim
        Hardy</a>, <a href=\"https://web.archive.org/web/20151003123037/http://duncan.hull.name/2008/11/17/science-blog-meme-why-do-we-blog/\">Duncan
        Hull</a> and <a href=\"https://web.archive.org/web/20151003123037/http://mndoci.com/blog/2008/11/16/why-do-we-blog/\">Deepak
        Singh</a>. Some other answers:</p><ul><li><em><em>The Editor-in-Chief of Nature
        once told David Attenborough that he should read my blog.</em></em> (<a href=\"https://web.archive.org/web/20151003123037/http://scienceblogs.com/notrocketscience/2008/11/why_blog_the_meme_returns.php\">Ed
        Yong</a>)</li><li><em><em>Getting a job with PLoS in the comments of one of
        my posts.</em></em> (<a href=\"https://web.archive.org/web/20151003123037/http://scienceblogs.com/clock/2008/11/the_science_blog_meme.php\">Bora
        Zivkovic</a>)</li><li><em><em>Co-founded a network of science bloggers (The
        DNA Network) and been invited (and accepted!) to work at MIT.</em></em> (<a
        href=\"https://web.archive.org/web/20151003123037/http://my.biotechlife.net/2008/11/16/the-science-blog-meme/\">Ricardo
        Vidal</a>)</li><li><em><em>Getting interviewed by Jon Udell.</em></em> (<a
        href=\"https://web.archive.org/web/20151003123037/http://mndoci.com/blog/2008/11/16/why-do-we-blog/\">Deepak
        Singh</a>)</li><li><em><em>I loaned a power cable to a Nature editor.</em></em>
        (<a href=\"https://web.archive.org/web/20151003123037/http://network.nature.com/people/boboh/blog/2008/11/16/memetic-selections\">Bob
        O'Hara</a>)</li></ul><h3 id=\"7-did-you-write-a-blog-post-or-comment-you-later-regretted\">7.
        Did you write a blog post or comment you later regretted?</h3><p>For most
        people that was not a big issue. <a href=\"https://web.archive.org/web/20151003123037/http://scienceblogs.com/notrocketscience/2008/11/why_blog_the_meme_returns.php\">Ed
        Yong</a> regrets to have written nice things about studies that later turned
        out to be rubbish not so good.</p><h3 id=\"8-when-did-you-first-learn-about-science-blogging\">8.
        When did you first learn about science blogging?</h3><p>Many different answers.
        <a href=\"https://web.archive.org/web/20151003123037/http://www.nodalpoint.org/\">Nodalpoint</a>
        was mentioned by several bloggers, including <a href=\"https://web.archive.org/web/20151003123037/http://duncan.hull.name/2008/11/17/science-blog-meme-why-do-we-blog/\">Duncan
        Hull</a>, <a href=\"https://web.archive.org/web/20151003123037/http://blindscientist.genedrift.org/2008/11/16/the-science-blog-meme/\">Paolo
        Nuin</a> and <a href=\"https://web.archive.org/web/20151003123037/http://pbeltrao.blogspot.com/2008/11/why-do-we-blog.html\">Pedro
        Beltrao</a>. <a href=\"https://web.archive.org/web/20151003123037/http://genomicron.blogspot.com/2008/11/why-do-we-blog-and-other-important.html\">T.
        Ryan Gregory</a> was introduced to science blogging by his graduate student.
        The most hilarious answer is from <a href=\"https://web.archive.org/web/20151003123037/http://network.nature.com/people/henrygee/blog/2008/11/14/that-martin-fenner-effect\">Henry
        Gee</a> and involves a garage, an old washing-machine motor and heavier-than-air
        flight.</p><h3 id=\"9-what-do-your-colleagues-at-work-say-about-your-blogging\">9.
        What do your colleagues at work say about your blogging?</h3><p>The standard
        answer seems to be that most of them don't know or don't care. I would hope
        that in the future we will have more answers like the one from <a href=\"https://web.archive.org/web/20151003123037/http://scienceblogs.com/clock/2008/11/the_science_blog_meme.php\">Bora
        Zivkovic</a>: <em><em>That's what they are paying me for and I hope they are
        happy.</em></em></p><h3 id=\"10-how-the-heck-do-you-have-time-to-blog-and-do-research-at-the-same-time\">10.
        How the heck do you have time to blog and do research at the same time?</h3><p>Most
        people blog in their spare time. I hope to see more <em><em>daytime bloggers</em></em>
        that blog as part of their science job in 5 years (this relates to questions
        #5, #8 and #9).</p><h3 id=\"11-extra-credit-are-you-able-to-write-an-entry-to-your-blog-that-takes-the-form-of-a-poem-about-your-research\">11.
        Extra credit: are you able to write an entry to your blog that takes the form
        of a poem about your research?</h3><p>Not all bloggers answered that question,
        but you can find poetry by <a href=\"https://web.archive.org/web/20151003123037/http://network.nature.com/people/etchevers/blog/2008/11/16/me-me-meme\">Heather
        Etchevers</a> (who suggested that question), <a href=\"https://web.archive.org/web/20151003123037/http://network.nature.com/people/scurry/blog/2008/11/12/public-engagement-ring\">Stephen
        Curry</a> (who inspired it), <a href=\"https://web.archive.org/web/20151003123037/http://network.nature.com/people/henrygee/blog/2007/11/09/the-noble-five-hundred\">Henry
        Gee</a>, <a href=\"https://web.archive.org/web/20151003123037/http://network.nature.com/people/U27CE62BB/blog/2008/11/04/unexpected-haikus\">Eva
        Amsen</a>, <a href=\"https://web.archive.org/web/20151003123037/http://scienceblogs.com/clock/2008/08/well_versed_in_science.php\">Bora
        Zivkovic</a>, <a href=\"https://web.archive.org/web/20151003123037/http://petrona.typepad.com/petrona/2006/07/petronarati.html\">Maxine
        Clarke</a> (a play), <a href=\"https://web.archive.org/web/20151003123037/http://network.nature.com/people/massimopinto/blog/2008/11/15/whats-this-bel-paese\">Massimo
        Pinto</a> (science fiction), <a href=\"https://web.archive.org/web/20151003123037/http://shirleywho.wordpress.com/karaoke/\">Shirley
        Wu</a> (karaoke), <a href=\"https://web.archive.org/web/20151003123037/http://network.nature.com/people/mike/blog/2008/11/18/follow-those-lemmings-where\">Mike
        Fowler</a>, <a href=\"https://web.archive.org/web/20151003123037/http://network.nature.com/people/erikacule/blog/2008/11/18/meme-scheme\">Erika
        Cule</a>, <a href=\"https://web.archive.org/web/20151003123037/http://network.nature.com/people/U3EABC9C8/blog/2008/11/15/oh-noes-meta-blogging\">Kristi
        Vogel</a>, <a href=\"https://web.archive.org/web/20151003123037/http://network.nature.com/people/boboh/blog/2008/03/17/the-deeper-meaning-of-a-residual-plot\">Bob
        O'Hara</a> (art), <a href=\"https://web.archive.org/web/20151003123037/http://network.nature.com/people/strippedscience/blog/2008/11/18/100th-comic-strip\">Viktor
        Po</a> (a dance) and <a href=\"https://web.archive.org/web/20151003123037/http://network.nature.com/people/mfenner/blog/2008/11/14/some-answers-for-henry-gee\">myself</a>.
        <a href=\"https://web.archive.org/web/20151003123037/http://blindscientist.genedrift.org/2008/11/16/the-science-blog-meme/\">Paolo
        Nuin</a> needs a few more encouraging comments before he will write a poem.</p><p>Update:
        <a href=\"https://web.archive.org/web/20151003123037/http://blog.pansapiens.com/2008/11/17/that-science-blog-meme-thing-going-around/\">Andrew
        Perry</a> has created two great wordle images for <a href=\"https://web.archive.org/web/20151003123037/http://tinyurl.com/5aeq88\">question
        #1</a> and <a href=\"https://web.archive.org/web/20151003123037/http://tinyurl.com/5z498r\">question
        #2</a>.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ What are the right numbers for JUPITER?
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/what-are-the-right-numbers-for-jupiter/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwbe</id>\n        <published>2008-11-23T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-31T07:41:46.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Results of clinical trials
        can sometimes not only change our understanding of the condition studied,
        but may also affect the way we practice medicine. The Justification for the
        Use of Statins in Primary Prevention: an Intervention Trial Evaluating Rosuvastatin
        (<em><em>JUPITER</em></em>) is such a study.</p><p>JUPITER was investigating
        the prevention of major cardiovascular events (myocardial infarction, stroke,
        hospitalization for unstable angina, arterial revascularization, death from
        cardiovascular causes) by treatment with rosuvastatin compared to placebo.
        Many clinical trials before have looked at the reduction of cardiovascular
        events by statin treatment in people with elevated cholesterol levels. But
        in the JUPITER trial, 17,802 apparently healthy men and women with normal
        levels of LDL cholesterol (&lt; 130 mg/dl) were included based on age (&gt;
        50 years for men, &gt; 60 years for women) and elevated levels of high-sensitivity
        C-reactive protein (&gt; 2,0 mg/l), a marker for inflammation. The trial was
        stopped early in March of this year (after a median follow-up of 1.9 years
        instead of the planned 4 years) because treatment with rosuvastatin significantly
        reduced the number of cardiovascular events: 0.77 per 100 person-years compared
        to 1.36 per 100 person-years for placebo. In other words, treating 120 people
        for 1.9 years with rosuvastatin (at a cost of about $287.000) would prevent
        one cardiovascular event.</p><p>The JUPITER trial is important not only because
        it shows that a statin can have a beneficial effect in people with normal
        LDL cholesterol. Which complicates our understanding on how statins work.
        More importantly, we now have to reconsider who should be treated with statins.
        What do we do with a small but significant effect in a large group of apparently
        healthy people? The treatment is expensive (cardiovascular events can probably
        be prevented for less than $287.000 by other means, e.g. changes in diet and
        exercise) and can have side effects (e.g. an increase in newly diagnosed diabetes
        in the JUPITER trial). And, like most important studies, the JUPITER trial
        raises a number of important new questions. But instead of discussing some
        of these questions I rather want to look at how we can obtain information
        about the JUPITER trial.</p><h3 id=\"clinical-trial-databases\">Clinical Trial
        Databases</h3><p>Since 2005 all clinical trials have to be registered in publicly
        available databases, and information about JUPITER is available.<sup><a href=\"https://web.archive.org/web/20150924053051/http://blogs.plos.org/mfenner/2008/11/23/what_are_the_right_numbers_for_jupiter/#fn1\">1</a></sup>
        Since September 2008, newly registered trials also have to report their main
        outcomes.<sup><a href=\"https://web.archive.org/web/20150924053051/http://blogs.plos.org/mfenner/2008/11/23/what_are_the_right_numbers_for_jupiter/#fn2\">2</a></sup>
        This will become important in the future, as the main outcomes of unpublished
        trials (most likely trials with negative results) will become publicly available
        no later than 12 months after data for the last subject were received.</p><h3
        id=\"press-releases\">Press Releases</h3><p>JUPITER was stopped early in March
        2008 and AstraZeneca (the sponsor of the trial and manufacturer of rosuvastatin)
        issued a press release.<sup><a href=\"https://web.archive.org/web/20150924053051/http://blogs.plos.org/mfenner/2008/11/23/what_are_the_right_numbers_for_jupiter/#fn3\">3</a></sup>
        Another press release was issued on November 9 when the JUPITER results were
        first presented publicly.<sup><a href=\"https://web.archive.org/web/20150924053051/http://blogs.plos.org/mfenner/2008/11/23/what_are_the_right_numbers_for_jupiter/#fn4\">4</a></sup>
        As can be expected from press releases, there is selective reporting of the
        trial results. No absolute numbers for risk reductions were reported, and
        emphasis was put on relative risk reductions. Instead of the actual number
        needed to treat (NNT, 120 patients treated for 1.9 years), a projected NNT
        (25 patients treated for 5 years) was reported. And a significant increase
        in newly diagnosed diabetes (3.0% vs. 2.4%, p=0.01) was reported as <em><em>\u201Cthere
        was a small increase in physician reported diabetes consistent with data from
        other large placebo controlled statin trials.\u201D</em></em></p><h3 id=\"presentation-at-a-meeting\">Presentation
        at a Meeting</h3><p>The JUPITER results were presented on November 9 at the
        annual meeting of the American Heart Association (AHA) in New Orleans. More
        than 6,000 people were listening to this presentation according to <a href=\"https://web.archive.org/web/20150924053051/http://network.nature.com/people/UD280A82C/profile\">James
        Butcher</a> on the Nature in the Field blog<a href=\"https://web.archive.org/web/20150924053051/http://blogs.plos.org/mfenner/2008/11/23/what_are_the_right_numbers_for_jupiter/#fn5\">5</a>.
        The abstract of the presentation is available here.<a href=\"https://web.archive.org/web/20150924053051/http://blogs.plos.org/mfenner/2008/11/23/what_are_the_right_numbers_for_jupiter/#fn6\">6</a>
        The abstract also lists the potential conflicts of interest of the study authors
        (the senior author Paul Ridger Ridker is co-inventor of patents on CRP testing
        in cardiovascular disease). The AHA issued a press release on that day<a href=\"https://web.archive.org/web/20150924053051/http://blogs.plos.org/mfenner/2008/11/23/what_are_the_right_numbers_for_jupiter/#fn7\">7</a>
        and commented primarily on the role of CRP testing in the trial.</p><h3 id=\"journal-paper\">Journal
        Paper</h3><p>The JUPITER study was published in the <em><em>New England Journal
        of Medicine (NEJM)</em></em> on November 20<sup><a href=\"https://web.archive.org/web/20150924053051/http://blogs.plos.org/mfenner/2008/11/23/what_are_the_right_numbers_for_jupiter/#fn8\">8</a></sup>,
        but the paper was preleased on the day of the presentation at the AHA meeting.
        The full-text PDF of the paper is available without subscription. The full
        paper is of course the best source to all the primary data. As is typical
        for many medical journals, it contains a structured abstract, which is a nice
        summary of the paper. Interestingly, the <em><em>NEJM</em></em> is conducting
        a poll and asks the readers two questions on how the JUPITER results changed
        their clinical practice.<sup><a href=\"https://web.archive.org/web/20150924053051/http://blogs.plos.org/mfenner/2008/11/23/what_are_the_right_numbers_for_jupiter/#fn9\">9</a></sup>
        And there are over 400 reader comments as of today.</p><h3 id=\"editorials\">Editorials</h3><p>The
        full paper is discussed in an editorial in the same issue<sup><a href=\"https://web.archive.org/web/20150924053051/http://blogs.plos.org/mfenner/2008/11/23/what_are_the_right_numbers_for_jupiter/#fn10\">10</a></sup>,
        and is also discussed in an editorial in the British Medical Journal<sup><a
        href=\"https://web.archive.org/web/20150924053051/http://blogs.plos.org/mfenner/2008/11/23/what_are_the_right_numbers_for_jupiter/#fn11\">11</a></sup>.
        Only the editorial in the <em><em>NEJM</em></em> is available without subscription,
        but both critically discuss the paper and put it in perspective.</p><h3 id=\"traditional-news\">Traditional
        News</h3><p>The JUPITER trial was of course discussed in many traditional
        news media such as newspapers, radio and television. The <em><em>New York
        Times</em></em> had a long article<sup><a href=\"https://web.archive.org/web/20150924053051/http://blogs.plos.org/mfenner/2008/11/23/what_are_the_right_numbers_for_jupiter/#fn12\">12</a></sup>
        where the author had interviewed not only the study authors but also several
        experts in the field. The article discusses several issues surrounding the
        study, but failed to report the absolute risk reduction or the number needed
        to treat (important numbers for the reasons discussed above). National Public
        Radio discussed the story with two cardiologists, including the author of
        the editorial in the <em><em>NEJM</em></em> (available as transcript and audio
        file).<sup><a href=\"https://web.archive.org/web/20150924053051/http://blogs.plos.org/mfenner/2008/11/23/what_are_the_right_numbers_for_jupiter/#fn13\">13</a></sup>
        The interview is again short on actual numbers, but puts JUPITER in perspective
        for the typical radio listener. The Nature News article<sup><a href=\"https://web.archive.org/web/20150924053051/http://blogs.plos.org/mfenner/2008/11/23/what_are_the_right_numbers_for_jupiter/#fn14\">14</a></sup>
        also didn't mention the number needed to treat. Stopping a trial early can
        be controversial, because the numbers for risks and benefits might look different
        at the planned end of the trial. Nature News should have talked to someone
        that was not involved in that decision in the JUPITER trial.</p><h3 id=\"blogs\">Blogs</h3><p>Scintilla
        has aggregated the blog posts on this study<sup><a href=\"https://web.archive.org/web/20150924053051/http://blogs.plos.org/mfenner/2008/11/23/what_are_the_right_numbers_for_jupiter/#fn15\">15</a></sup>.
        Harriet Hall on the Science-Based Medicine Blog not only has the story with
        the best title (<em><em>Statins Are Better on JUPITER</em></em>), but gives
        a detailed analysis of the study results. Ben Goldacre on Bad Science has
        a shorter blog post that is more of a discussion of absolute risk, relative
        risk and number needed to treat (as the title of the blog post suggests).<sup><a
        href=\"https://web.archive.org/web/20150924053051/http://blogs.plos.org/mfenner/2008/11/23/what_are_the_right_numbers_for_jupiter/#fn16\">16</a></sup></p><h3
        id=\"conclusions\">Conclusions</h3><p>There are many ways we can learn more
        about the JUPITER trial, and most of this information is freely available,
        including the full-text of the paper. It is not the access to the primary
        data that is the problem, but rather the many different ways the results can
        be put into perspective. And for that we need not only a basic understanding
        of cardiovascular risks, but also clinical trials. And we should not forget
        the financial and other interests that are always connected to large trial
        like this. I didn't do a systematic analysis of the newspaper articles and
        blog posts about the study, but it is clear to me that science blogs can add
        an important perspective.</p><p>fn1. JUPITER \u2013 Crestor 20mg Versus Placebo
        in Prevention of Cardiovascular (CV) Events. <a href=\"https://web.archive.org/web/20150924053051/http://clinicaltrials.gov/show/NCT00239681\">ClinicalTrials.gov
        NCT00239681 October 13, 2005</a></p><p>fn2. <a href=\"https://web.archive.org/web/20150924053051/http://network.nature.com/people/mfenner/blog/2008/08/02/fdaaa-push-to-open-data-in-clinical-medicine\">FDAAA:
        Push to open data in clinical medicine</a></p><p>fn3. Crestor Outcomes Study
        JUPITER Closes Early Due To Unequivocal Evidence Of Benefit. <a href=\"https://web.archive.org/web/20150924053051/http://www.astrazeneca.com/pressrelease/5385.aspx\">AstraZeneca
        Press Release March 31, 2008</a></p><p>fn4. CRESTOR Demonstrates Dramatic
        CV Risk Reduction in a Large Statin Outcomes Study. <a href=\"https://web.archive.org/web/20150924053051/http://www.astrazeneca.com/pressrelease/5412.aspx\">AstraZeneca
        Press Release November 9, 2008</a></p><p>fn5. AHA 2008: Should statins be
        put in the water? James Butcher. <a href=\"https://web.archive.org/web/20150924053051/http://blogs.nature.com/news/blog/2008/11/should_statins_be_put_in_the_w.html\">In
        the Field November 11, 2008</a></p><p>fn6. Late-breaking abstracts. <a href=\"https://web.archive.org/web/20150924053051/http://americanheart.mediaroom.com/index.php?s=54&amp;item=212\">News
        Conference November 9, 2008</a></p><p>fn7. American Heart Association Comment
        on JUPITER trial. <a href=\"https://web.archive.org/web/20150924053051/http://americanheart.mediaroom.com/index.php?s=43&amp;item=582\">AHA
        Press Release November 9, 2008</a></p><p>fn8. P. M Ridker, E. Danielson, F.
        A.H. Fonseca, J. Genest, A. M. Gotto, J. J.P. Kastelein, W. Koenig, P. Libby,
        A. J. Lorenzatti, J. G. MacFadyen, B. G. Nordestgaard, J. Shepherd, J. T.
        Willerson, R. J. Glynn (2008). Rosuvastatin to Prevent Vascular Events in
        Men and Women with Elevated C-Reactive Protein <em>New England Journal of
        Medicine, 359</em> (21), 2195-2207 DOI: <a href=\"https://web.archive.org/web/20150924053051/http://dx.doi.org/10.1056/NEJMoa0807646\">10.1056/NEJMoa0807646</a></p><p>fn9.
        The JUPITER Trial: Will You Change Your Practice? <a href=\"https://web.archive.org/web/20150924053051/http://www.nejm.org/clinical-directions/jupiter-statins-trial/?query=TOC\">Clinical
        Directions</a></p><p>fn10. M. A. Hlatky (2008). Expanding the Orbit of Primary
        Prevention \u2014 Moving beyond JUPITER <em>New England Journal of Medicine,
        359</em> (21), 2280-2282 DOI: <a href=\"https://web.archive.org/web/20150924053051/http://dx.doi.org/10.1056/NEJMe0808320\">10.1056/NEJMe0808320</a></p><p>fn11.
        N. Donner-Banzhoff, A. Sonnichsen (2008). Statins and primary prevention of
        cardiovascular events <em>BMJ, 337</em> (nov14 2) DOI: <a href=\"https://web.archive.org/web/20150924053051/http://dx.doi.org/10.1136/bmj.a2576\">10.1136/bmj.a2576</a></p><p>fn12.
        Cholesterol-Fighting Drugs Show Wider Benefit. Pam Belluck. <a href=\"https://web.archive.org/web/20150924053051/http://www.nytimes.com/2008/11/10/health/10heart.html\">New
        York Times November 10, 2008</a></p><p>fn13. Study Finds Statins Benefit Patients
        With no History of Heart Problems. <a href=\"https://web.archive.org/web/20150924053051/http://www.pbs.org/newshour/bb/health/july-dec08/statins_11-10.html\">PBS
        Newshour November 10, 2008</a></p><p>fn14. Should healthy people take statins
        too? Katharine Sanderson. <a href=\"https://web.archive.org/web/20150924053051/http://www.nature.com/news/2008/081110/full/news.2008.1218.html\">Nature
        News November 10, 2008</a></p><p>fn15. Search for term rosuvastatin. <a href=\"https://web.archive.org/web/20150924053051/http://scintilla.nature.com/search/feed_item?t=rosuvastatin\">Scintilla</a></p><p>fn16.
        Statins Are Better on JUPITER. Harriet Hall. <a href=\"https://web.archive.org/web/20150924053051/http://www.sciencebasedmedicine.org/?p=282\">Science-Based
        Medicine November 11, 2008</a></p><p>fn17. You are 80% less likely to die
        from a meteor landing on your head if you wear a bicycle helmet all day. Ben
        Goldacre. <a href=\"https://web.archive.org/web/20150924053051/http://www.badscience.net/2008/11/you-are-80-less-likely-to-die-from-a-meteor-landing-on-your-head-if-you-wear-a-bicycle-helmet-all-day/\">Bad
        Science November 15, 2008</a></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Some answers for Henry Gee ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/some-answers-for-henry-gee/\" />\n\t\t<id>https://doi.org/10.53731/a31c37h-hvvj84r</id>\n
        \       <published>2008-11-14T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-14T16:49:37.000+00:00</updated>\n\t\t<category
        term=\"Interview\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p><a href=\"https://web.archive.org/web/20150924053046/http://network.nature.com/people/henrygee/blog/2008/11/14/that-martin-fenner-effect\">Henry</a>
        was the first Nature Network blogger to answer a few questions about science
        blogging that <a href=\"https://web.archive.org/web/20150924053046/http://network.nature.com/groups/nnbloggername/forum/topics/3392\">we
        discussed</a> in the Nature Network Bloggers forum. Some more posts can be
        found <a href=\"https://web.archive.org/web/20150924053046/http://network.nature.com/blogs/posts/search?q=martinmeme\">here</a>
        and <a href=\"https://web.archive.org/web/20150924053046/http://petrona.typepad.com/petrona/2008/11/pinning-ones-hamster-to-the-mast.html\">here</a>.</p><h3
        id=\"1-what-is-your-blog-about\">1. What is your blog about?</h3><p>I am interested
        in how the internet is changing the way we publish and communicate science.
        I write from the perspective of someone that consumes and sometimes produces
        science. Journal publishers, science librarians, patients and others will
        look at this topic from a different angle. This blog started as <em><em>Publish
        or Perish 2.0</em></em>, but I later changed the name to Gobbledygook. Mainly
        because I liked the word.</p><h3 id=\"2-what-will-you-never-write-about\">2.
        What will you never write about?</h3><p>Of course I don't know. But I hope
        that I will not have to write blog posts that are evaluated, measured and
        put on a resum\xE9 similar to scientific papers now.</p><h3 id=\"3-have-you-ever-considered-leaving-science\">3.
        Have you ever considered leaving science?</h3><p>As a medical doctor in a
        university hospital I spend part of the day treating patients. I very much
        like the combination, but sometimes it is very exhausting. And research, both
        basic and clinical research, can lead into many dead ends. I've been there
        more than once.</p><h3 id=\"4-what-would-you-do-instead\">4. What would you
        do instead?</h3><p>Start a Web 2.0 company. Become a professional chef. Not
        really.</p><h3 id=\"5-what-do-you-think-will-science-blogging-be-like-in-5-years\">5.
        What do you think will science blogging be like in 5 years?</h3><p>I wrote
        down some of my thoughts on this in the post <a href=\"https://web.archive.org/web/20150924053046/http://network.nature.com/people/mfenner/blog/2008/08/31/science-blogging-is-the-new-email\">Science
        blogging is the new email</a>. Science blogging will be very common and at
        the same time very specialized. Some science bloggers will be able to make
        enough money to earn a living from it.</p><h3 id=\"6-what-is-the-most-extraordinary-thing-that-happened-to-you-because-of-blogging\">6.
        What is the most extraordinary thing that happened to you because of blogging?</h3><p>Many,
        many things. Most importantly, meeting a lot of very interesting people both
        online and in real life.</p><h3 id=\"7-did-you-write-a-blog-post-or-comment-you-later-regretted\">7.
        Did you write a blog post or comment you later regretted?</h3><p>Fortunately
        not too often. When I sounded patronizing.</p><h3 id=\"8-when-did-you-first-learn-about-science-blogging\">8.
        When did you first learn about science blogging?</h3><p>From an article in
        <em><em>Cell</em></em> by Laura Bonetta: <a href=\"https://web.archive.org/web/20150924053046/http://dx.doi.org/10.1016/j.cell.2007.04.032\">Scientists
        enter the blogosphere</a>.</p><h3 id=\"9-what-do-your-colleagues-at-work-say-about-your-blogging\">9.
        What do your colleagues at work say about your blogging?</h3><p>Most of them
        don't know about my science blogging. The rest doesn't really care. I hope
        that will change in 5 years (see #5).</p><h3 id=\"10-how-the-heck-do-you-have-time-to-blog-and-do-research-at-the-same-time\">10.
        How the heck do you have time to blog and do research at the same time?</h3><p>Only
        because blogging means something else to me and doesn't really count as work.
        I don't blog during work hours. And I blog for fun and not money.</p><h3 id=\"11-extra-credit-are-you-able-to-write-an-entry-to-your-blog-that-takes-the-form-of-a-poem-about-your-research\">11.
        Extra credit: are you able to write an entry to your blog that takes the form
        of a poem about your research?</h3><p>There once was a doctor from Hannover,<br>it
        was cancer he tried to uncover.<br>Doing a mouse model was all the hype,<br>but
        instead of a phenotype,<br>all he got was a hangover.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ NLM DTD: Interview with Pablo Fernicola
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/interview-with-pablo-fernicola/\"
        />\n\t\t<id>https://doi.org/10.53731/e18npj3-3akbqq0</id>\n        <published>2008-11-07T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-14T15:35:58.000+00:00</updated>\n\t\t<category
        term=\"Interview\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>The Article
        Authoring Tag Set of the National Library of Medicine (NLM DTD for short)
        <em><em>creates a standardized format for new journal articles that can be
        used by authors to submit publications to journals and to archives such as
        PubMed Central.</em></em>[1] The Microsoft Word Article Authoring Add-in that
        was released earlier this year reads and writes this format. <a href=\"https://web.archive.org/web/20150924053041/http://network.nature.com/people/pablofe/profile\">Pablo
        Fernicola</a> from Microsoft first explains the Add-in in a video and then
        answers a few questions.</p><h3 id=\"1-can-you-describe-what-the-microsoft-word-article-authoring-add-in-is-and-does\">1.
        Can you describe what the Microsoft Word Article Authoring Add-in is and does?</h3><p>There
        is an already ongoing transition to digital workflows for journals, as well
        as a nascent transition to digital distribution and consumption. Generating
        content that is best suited for digital distribution, as well as for archival,
        search, and semantic analysis in the future, is going to be essential. As
        a community, today we are not taking full advantage of the potential that
        the tools and formats currently in use present to us, and trying to bolt these
        capabilities to existing print centric processes is costly, inefficient, and
        does not allow for exercising the benefits afforded by the digital medium.
        Authoring for print delivery still dominates many of the processes, and constrains
        the final outcome, even if print distribution is discontinued.</p><p>It is
        important to realize that the content we generate today is what we will be
        accessing, and relying on as reference material, in the future. It is imperative
        that we generate content that is best suited for the way it will be consumed.
        Also, it would be ideal if this transition could be done in a non-intrusive
        and low-cost approach as possible.</p><p>The Article Authoring Add-in for
        Word 2007<sup><a href=\"https://web.archive.org/web/20150924053041/http://blogs.plos.org/mfenner/2008/11/07/interview_with_pablo_fernicola/#fn2\">2</a></sup>
        is a free download, which provides new capabilities to the Word application,
        focused on Scholarly Publishing. The overall goal for the Authoring Add-in
        project is to help improve the scholarly publishing process for workflows
        that rely on Microsoft Word or Word generated content, covering the authoring
        experience, editorial workflow, and archiving of STM articles, with an eye
        towards generating content that is best suited for preservation, digital consumption,
        and search. A core capability provided by the add-in is the ability to open
        and save files in the NLM XML format.</p><h3 id=\"2-how-is-the-authoring-add-in-different-from-commercial-tools-such-as-extyles-from-inera\">2.
        How is the Authoring Add-in different from commercial tools such as eXtyles
        from Inera?</h3><p>The add-in differs in at least the following ways:</p><ul><li>It
        is targeted at both authors and editorial staff audiences</li><li>It focuses
        on enhancing the experience within Word, both for authors and editorial staff,
        and not just for content but also for metadata</li><li>Enables providing a
        consistent experience for authors, in relation to templates and the entering
        of metadata, across journals</li><li>Enables two way interaction with the
        NLM formats (article and book formats), saving and opening NLM files within
        Word</li><li>Provides a platform for software vendors to build on top of</li><li>Builds
        on the transition to XML as the underlying native format in Word 2007</li></ul><h3
        id=\"3-what-advantages-do-you-see-for-authors-that-submit-their-manuscripts-in-the-nlm-journal-publishing-xml-format\">3.
        What advantages do you see for authors that submit their manuscripts in the
        NLM Journal Publishing XML format?</h3><p>The add-in doesn't force authors
        to submit their articles in the NLM format, but makes the conversion to that
        format a lot easier as part of the workflow. The add-in provides a way for
        authors to enter information in their articles so that this content (semantics
        and metadata) is preserved through the publishing workflow, in a way that
        is ready to save as a valid NLM document, while still using the Word user
        interface. I would expect that the more common scenario will be that of journals
        providing templates and authors submitting docx files, augmented with NLM
        data through the add-in, and that the journals or repository staff will be
        the ones doing the conversion to the NLM format.</p><h3 id=\"4-how-do-you-think-the-author-submission-process-will-change-in-relation-to-formats\">4.
        How do you think the author submission process will change in relation to
        formats?</h3><p>Many journals already use the NLM format as part of their
        publishing workflow, as well as for their archival format. Some publishers
        are moving to the format now. And, certainly for NIH-funded research, all
        articles eventually end up in the NLM format as part of the submission to
        PubMed Central. But I don't know of any journals that take in the NLM format
        directly from authors.</p><p>We have tried to take a very end-user-centric
        approach in the project. We would like for authors not to have to be aware
        of the underlying format. We don't want authors to think of XML, for example,
        as formats should be something that happens in the background, which the authoring
        tools handle for the authors, and just make the authors' work easier, and
        their content more easily searchable and relevant.</p><p>In our work with
        the journals, publishers, and repositories we focus a lot on interoperability
        based on formats and protocols commonly used in the community, not only in
        the form of the NLM format itself, but also by incorporating technologies
        such as SWORD<sup><a href=\"https://web.archive.org/web/20150924053041/http://blogs.plos.org/mfenner/2008/11/07/interview_with_pablo_fernicola/#fn4\">4</a></sup>
        and OAI-ORE<sup><a href=\"https://web.archive.org/web/20150924053041/http://blogs.plos.org/mfenner/2008/11/07/interview_with_pablo_fernicola/#fn5\">5</a></sup>.</p><h3
        id=\"5-what-is-your-job-at-microsoft-what-did-you-do-before-working-on-the-authoring-add-in\">5.
        What is your job at Microsoft? What did you do before working on the Authoring
        Add-in?</h3><p>I have always been involved in software development, working
        and managing both small and large teams. Currently I am a group manager at
        Microsoft, in charge of running this overall project, which also includes
        an online service focused on the peer review process. I drive the development,
        the technology direction and architecture, and community engagement as it
        relates to scholarly publishing<sup><a href=\"https://web.archive.org/web/20150924053041/http://blogs.plos.org/mfenner/2008/11/07/interview_with_pablo_fernicola/#fn6\">6</a></sup>.
        Before starting this effort, I worked for many years on developer platform
        technologies related to text, reading, graphics, and multimedia, both at Microsoft
        and at Apple, as well as being the Program Manager in charge of the web developer
        platform in Internet Explorer for a couple of versions of the browser.</p><h3
        id=\"6-do-you-plan-to-also-release-an-add-in-for-microsoft-word-2008-for-macintosh\">6.
        Do you plan to also release an Add-in for Microsoft Word 2008 for Macintosh?</h3><p>We
        are investigating how we can best bring the authoring focused features to
        Word 2008 users. On Windows, Word 2007 is now in many ways a developer platform
        in its own right, there are even software development kits for it, and Word
        2007 provides a lot of extensibility and programmability to developers. The
        equivalent developer support is not provided in Word 2008, with the Macintosh
        offering's strength being on providing a great end user experience to its
        end user audience.</p><h3 id=\"7-do-you-want-to-talk-about-future-plans-for-the-authoring-add-in\">7.
        Do you want to talk about future plans for the Authoring Add-in?</h3><p>We
        got a lot of feedback on our version 1 of the add-in, which we made available
        this past July, from folks involved in the back-end of the publishing workflow,
        such as folks at journals, publishers, and repositories, as well as from companies
        that provide the software tools and services in support of this work (of note
        is the integration work we did with Design Science for their MathType package<a
        href=\"https://web.archive.org/web/20150924053041/http://blogs.plos.org/mfenner/2008/11/07/interview_with_pablo_fernicola/#fn7\">7</a>).</p><p>Development
        work on version 2 is currently underway and we expect to make available a
        Technology Preview soon, with the final release of version 2 in 2009. In version
        1 we focused quite a bit on the architecture and getting the basic infrastructure
        in place to provide support for the NLM format. In version 2 there is a greater
        focus on the author experience, as well as on continuing to improve the support
        for the format.</p><p>Some of the driving questions that we would like to
        address are:</p><ul><li>in which ways can we make the submission/upload process
        easier for authors</li><li>Can we make the author and article metadata more
        reliable and consistent, thereby reducing the roundtrips between authors and
        the journals, as well as reducing the cost for cleaning up the data?</li></ul><p>And
        overall, the philosophy is to simplify, simplify, simplify. Especially for
        authors, help them get the content into the article, and keep the technology
        in the background. For the staff at journals and repositories, provide them
        with access to all the richness of the NLM format, and the flexibility that
        they will need to build their own solutions.</p><p>fn1. <a href=\"https://web.archive.org/web/20150924053041/http://dtd.nlm.nih.gov/articleauthoring/\">Article
        Authoring Tag Set</a></p><p>fn2. <a href=\"https://web.archive.org/web/20150924053041/http://www.microsoft.com/downloads/details.aspx?familyid=09c55527-0759-4d6d-ae02-51e90131997e&amp;displaylang=en\">Article
        Authoring Add-in for Microsoft Office Word 2007</a></p><p>fn3. <a href=\"https://web.archive.org/web/20150924053041/http://www.inera.com/extylesinfo.shtml\">eXtyles
        Product Information</a></p><p>fn4. <a href=\"https://web.archive.org/web/20150924053041/http://www.jisc.ac.uk/whatwedo/programmes/reppres/tools/sword\">SWORD</a></p><p>fn5.
        <a href=\"https://web.archive.org/web/20150924053041/http://www.openarchives.org/ore/\">Open
        Archives Initiative Object Reuse and Exchange</a></p><p>fn6. <a href=\"https://web.archive.org/web/20150924053041/http://blogs.msdn.com/exscientia/\">ex
        Scientia</a></p><p>fn7. <a href=\"https://web.archive.org/web/20150924053041/http://www.dessci.com/en/products/mathtype/\">MathType</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ How do you read papers? ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/how-do-you-read-papers/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwbb</id>\n
        \       <published>2008-11-02T00:00:00.000+00:00</published>\n\t\t<updated>2023-09-01T21:12:12.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2023/09/reading.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2023/09/reading.png\"></p><p>Working
        in science is as much about reading papers as it is about writing papers.
        There are usually two ways you can come across an interesting scientific paper:</p><ul><li><em><em>Active
        Searching</em></em>. Literature search on a particular topic</li><li><em><em>Passive
        Browsing</em></em>. Scanning the literature in regular intervals for papers
        of interest</li></ul><p>The focused active search is typically used when you
        collect information for a research project or write a paper or grant proposal.
        This is stuff for another blog post and can be better explained by a science
        librarian like <a href=\"https://web.archive.org/web/20151003123041/http://network.nature.com/people/obst/profile\">Oliver
        Obst</a> or <a href=\"https://web.archive.org/web/20151003123041/http://network.nature.com/people/U81B5C465/profile\">Frank
        Norman</a>. Now I want to talk about different ways to keep track of the current
        literature in your field. I would assume that most if not all people involved
        in science do this in one way or another, and I also think that many people
        are struggling with the best strategy (see Richard's related post on this
        topic: <a href=\"https://web.archive.org/web/20151003123041/http://network.nature.com/people/rpg/blog/2008/10/27/too-many-fish-in-the-sea\">Too
        many fish in the sea</a>).</p><p>The basic concept behind browsing is that
        it is a passive activity where the scientific papers come to you regularly
        in one way or another. A good strategy should be efficient (not involve too
        much of your time), cost-effective and should have a good signal to noise
        ratio (i.e. finds many interesting papers without going through too much uninteresting
        stuff).</p><h3 id=\"journal-subscriptions\">Journal Subscriptions</h3><p>The
        old-fashioned way. You receive a print copy of journals of interest in regular
        intervals and flip through the journal. This strategy works for a few journals,
        but is usually too expensive and too unfocused as a general strategy. I currently
        have three personal journal subscriptions, but the main reasons are that I
        either can't get them in electronic form or have no institutional subscription.
        Departmental subscriptions that are circulated around help saving some costs.
        But I have to confess that I haven't been to a library to flip through a few
        journals for more than 10 years. I very much like the feeling of a printed
        journal in my hands, but browsing in electronic form is not only cheaper but
        also much faster (even more so with articles released early in electronic
        form). Many journals now exist only in electronic form or <a href=\"https://web.archive.org/web/20151003123041/http://resources.bmj.com/bmj/about-bmj/the-bmjs-publishing-model\">publish
        articles continously</a> rather than in a weekly or monthly schedule.</p><h3
        id=\"journal-tables-of-content-toc-by-email-or-rss\">Journal tables of content
        (TOC) by email or RSS</h3><p>I would guess that this is currently the most
        popular browsing strategy. I prefer RSS to email because it means less clutter
        in my email inbox and because every journal article is a separate item that
        can be saved for later. I currently follow 8 journals. <a href=\"https://web.archive.org/web/20151003123041/http://mekentosj.com/papers/\">Papers</a>
        also uses this strategy, but this feature could be refined in future versions
        of the program. The TOC strategy probably works best for the leading journals
        in your field of research, but isn't very efficient for journals with only
        1-2 interesting articles per issue, e.g. high volume general interest journals
        such as <em><em>PNAS</em></em>. Podcasts (e.g. the <a href=\"https://web.archive.org/web/20151003123041/http://www.nature.com/nature/podcast/\">Nature
        Podcast</a>) are basically extended TOCs in audio format.</p><h3 id=\"filtering-by-experts\">Filtering
        by experts</h3><p>You let someone else do the filtering for you. The traditional
        approach is the review article. The major drawback is of course the delay
        between publication of the original research and the publication of the review.
        A different \u2013 and faster \u2013 approach is used by <a href=\"https://web.archive.org/web/20151003123041/http://www.f1000biology.com/\">Faculty
        of 1000 Biology</a> (they also have a similar service for medicine). The most
        interesting papers are highlighted and reviewed by leading researchers in
        the field. <em><em>Research Highlights</em></em> in <em><em>Nature</em></em>
        and similar features in other journals try to do the same on a much smaller
        scale.</p><p>Filtering by experts is a resource-intensive and subjective process,
        and it is very possible that very exciting research published in an obscure
        journal might be missed. Most will remember that internet search started out
        with expert filtering, exemplified by Yahoo. It didn't work.</p><h3 id=\"filtering-by-author-or-keyword\">Filtering
        by author or keyword</h3><p>A good browsing strategy should consider the papers
        you have read already. In the approaches mentioned above this happens in your
        mind when you flip through the table of contents of a journal. A smarter approach
        is to regularly receive customized searches (again delivered via email or
        RSS). This is a popular strategy (explained <a href=\"https://web.archive.org/web/20151003123041/http://www.nlm.nih.gov/pubs/techbull/mj05/mj05_rss.html\">here</a>
        for PubMed) and can involve keywords (e.g. the molecule or organism you work
        on) or authors (your colleagues and competitors).</p><h3 id=\"filtering-by-papers-you-read\">Filtering
        by papers you read</h3><p>A more systematic approach would not just pick a
        few keywords, but would use the information from all the papers you've read
        already, particulary those that you liked. Social bookmarking tools such as
        <a href=\"https://web.archive.org/web/20151003123041/http://www.connotea.org/\">Connotea</a>
        or <a href=\"https://web.archive.org/web/20151003123041/http://www.citeulike.org/\">CiteULike</a>
        have this information, but only if you give type in all those papers. It is
        more convenient to use that information directly from your reference manager
        where you have stored references or even fulltext PDFs to your most important
        papers anyway. Reference managers are usually used for writing papers and
        unfortunaly don't yet use this information to help you find interesting papers.
        One reason I like <a href=\"https://web.archive.org/web/20151003123041/http://network.nature.com/people/mfenner/blog/2008/10/03/interview-with-alexander-griekspoor\">Papers</a>
        and <a href=\"https://web.archive.org/web/20151003123041/http://network.nature.com/people/mfenner/blog/2008/09/05/interview-with-victor-henning-from-mendeley\">Mendeley</a>
        is that they both have the potential to fill this gap.</p><h3 id=\"filtering-by-papers-others-read\">Filtering
        by papers others read</h3><p>You probably have guessed that this blog post
        would somehow suggest a Web 2.0 solution to this problem. The papers stored
        in the reference manager of other scientists can of course be used to find
        papers that might also interest you. This process can of course be automated
        (rather than the personal recommendation from a colleague) and should be anonymous.
        But neither Connotea nor CiteULike do that, and I don't know of any other
        online tool currently available.</p><p>In 2010 I want to use a tool that scans
        Pubmed or other databases for papers of interest based on the papers stored
        in my reference manager. The tool would give me a weekly report that can also
        be printed out for reading and note taking.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Book Review: Bad Science by Ben Goldacre
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/book-review-bad-science-by-ben-goldacre/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwba</id>\n        <published>2008-10-24T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-15T14:58:36.000+00:00</updated>\n\t\t<category
        term=\"Book Review\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/51YX1oB8D-L._SX328_BO1-204-203-200_.jpg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/51YX1oB8D-L._SX328_BO1-204-203-200_.jpg\"></p><p><em><em>Ben
        Goldacre: Bad Science. Published September 2008 by Fourth Estate Ltd. Paperback,
        352 pages, ISBN 0007240198</em></em></p><p><a href=\"https://web.archive.org/web/20150922174108/http://network.nature.com/people/UA495AB88/profile\">Ben
        Goldacre</a>, blogger of the <em><em>Bad Science</em></em>[1] column in the
        Guardian newspaper, in September published a book based on material from his
        blog. Just like the newspaper column, the book is primarily intended for a
        general audience rather than the trained scientist or medical doctor. And
        it helps to live in Great Britain, where most of the examples of bad science
        given in the book happened.</p><p>But the book is not really a collection
        of scary and sometimes hilarious bad science stories. Ben Goldacre takes these
        examples and tries to teach the reader evidence-based medicine. Evidence-based
        medicine<sup><a href=\"https://web.archive.org/web/20150922174108/http://blogs.plos.org/mfenner/2008/10/24/book_review_bad_science_by_ben_goldacre/#fn2\">2</a></sup>
        or EBM uses the scientific method to make decisions about the care of individual
        patients. It is funny how many people \u2013 including medical doctors \u2013
        throw away all the research evidence that is available and instead rely on
        personal experiences. And evidence-based medicine helps to distinguish good
        research from bad research, e.g. by stressing the importance of randomized
        controlled trials. The book was very stimulating reading for me, including
        the chapter about the placebo effect<sup><a href=\"https://web.archive.org/web/20150922174108/http://blogs.plos.org/mfenner/2008/10/24/book_review_bad_science_by_ben_goldacre/#fn3\">3</a></sup>.
        But I'm a medical doctor, and I don't know whether Ben Goldacre succeeded
        in every reader with this teaching mission. Even so, most readers will look
        much more carefully at science stories in the media after finishing the book.
        And that is a good thing.</p><p>More reviews of the book can be found in these
        fine publications:</p><ul><li><a href=\"https://web.archive.org/web/20150922174108/http://www.telegraph.co.uk/arts/main.jhtml?xml=%2Farts%2F2008%2F09%2F27%2Fbogol127.xml\">Daily
        Telegraph</a></li><li><a href=\"https://web.archive.org/web/20150922174108/http://www.newscientist.com/channel/opinion/mg20026772.600-review-ibad-sciencei-by-ben-goldacre.html\">TimeOut
        London</a></li><li><a href=\"https://web.archive.org/web/20150922174108/http://dx.doi.org/10.1136/bmj.a1856\">British
        Medical Journal</a></li><li><a href=\"https://web.archive.org/web/20150922174108/http://www.newscientist.com/channel/opinion/mg20026772.600-review-ibad-sciencei-by-ben-goldacre.html\">New
        Scientist</a></li></ul><p>fn1. <a href=\"https://web.archive.org/web/20150922174108/http://www.badscience.net/\">Bad
        Science</a></p><p>fn2. <a href=\"https://web.archive.org/web/20150922174108/http://en.wikipedia.org/wiki/Evidence-based_medicine\">Evidence-based
        Medicine Wikipedia entry</a></p><p>fn3. <a href=\"https://web.archive.org/web/20150922174108/http://www.badscience.net/2008/08/my-placebo-programme-on-bbc-radio-4/\">Placebo
        programme on BBC Radio 4</a></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Open Access \u2013 what\u2019s in it for
        me? ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/open-access-whats-in-it-for-me/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwb9</id>\n        <published>2008-10-14T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-13T13:48:01.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Today is Open Access Day<sup><a
        href=\"https://web.archive.org/web/20151003084018/http://blogs.plos.org/mfenner/2008/10/14/open_access_whats_in_it_for_me/#fn1\">1</a></sup>,
        intended to broaden awareness and understanding of Open Access. Many science
        bloggers have written about Open Access today,and links to a lot of these
        blog posts have been collected by Bora Zivkovic<sup><a href=\"https://web.archive.org/web/20151003084018/http://blogs.plos.org/mfenner/2008/10/14/open_access_whats_in_it_for_me/#fn2\">2</a></sup>
        or are found in the FriendFeed room set up for the day<sup><a href=\"https://web.archive.org/web/20151003084018/http://blogs.plos.org/mfenner/2008/10/14/open_access_whats_in_it_for_me/#fn3\">3</a></sup>.
        The purchase of <em><em>Biomed Central</em></em> \u2013 the largest Open Access
        publisher \u2013 by <em><em>Springer</em></em> announced last week<sup><a
        href=\"https://web.archive.org/web/20151003084018/http://blogs.plos.org/mfenner/2008/10/14/open_access_whats_in_it_for_me/#fn4\">4</a></sup>,
        and the announcement of the Open Access Scholarly Publishers Association (<em><em>OASPA</em></em>)
        today<sup><a href=\"https://web.archive.org/web/20151003084018/http://blogs.plos.org/mfenner/2008/10/14/open_access_whats_in_it_for_me/#fn5\">5</a></sup>
        are strong signs that Open Access has grown up and is no longer new and experimental.
        This is probably a good time to give a personal report on the role of Open
        Access in my own work, and obviously that perspective is very different from
        the perspective of a journal publisher or a patient advocate<sup><a href=\"https://web.archive.org/web/20151003084018/http://blogs.plos.org/mfenner/2008/10/14/open_access_whats_in_it_for_me/#fn6\">6</a></sup>.
        I wish that more of the discussion would be about practical benefits or disadvantages
        for the people involved, rather than using the sometimes \u201Creligious\u201D
        arguments for or against Open Access.</p><h3 id=\"do-i-have-access-to-the-papers-i-want-to-read\">Do
        I have access to the papers I want to read?</h3><p>I am in the privileged
        situation to work for a university hospital with institutional subscriptions
        to most journals I need. From the 10 journals I read the most (measured by
        the number of PDFs stored in the program Papers<a href=\"https://web.archive.org/web/20151003084018/http://blogs.plos.org/mfenner/2008/10/14/open_access_whats_in_it_for_me/#fn7\">7</a>),
        one journal is open access (The Oncologist), three additional journals allow
        free acces after 6-12 months (PNAS, Cancer Research and Blood) and one journal
        is only available through my private subscription (Nature Clinical Practice
        Oncology). I would guess that I have access to about 95% of the full-text
        papers I want to read.</p><h3 id=\"can-other-people-read-my-publications\">Can
        other people read my publications?</h3><p>I've blogged about this before<sup><a
        href=\"https://web.archive.org/web/20151003084018/http://blogs.plos.org/mfenner/2008/10/14/open_access_whats_in_it_for_me/#fn8\">8</a></sup>,
        and little has changed in the 6 months since that post. Looking at my last
        5 papers, only one of them is freely available (because the journal allows
        free access after 12 months), and for one of them even my own institution
        doesn't have access. Good publications are still critical to advance my career,
        so publishing in \u201Cgood\u201D journals is more important to me than publishing
        in journals where as many people as possible can read my papers \u2013 and
        most people interested in my work probably also work in institutions with
        fulltext access. The citation advantage of Open Access papers would be an
        incentive to publish in Open Access journals, but to me that question still
        remains unanswered<sup><a href=\"https://web.archive.org/web/20151003084018/http://blogs.plos.org/mfenner/2008/10/14/open_access_whats_in_it_for_me/#fn9\">9</a></sup>.
        I currently have limited research funding, so an Author-pays fee is a hurdle
        for me. I was coauthor of one paper this year that really should have been
        Open Access. It is a detailed guideline on how to treat patients with testicular
        cancer and should have been made freely available.</p><h3 id=\"where-do-i-need-more-open-access\">Where
        do I need more Open Access?</h3><p>Most research never gets published and
        there are many good reasons why that is so. But the situation is different
        for clinical research involving the treatment of patients. A clinical trial
        not only costs a lot of money, but is also potentially harmful to a patient.
        For these reasons clinical trials need approval by institutional review boards
        and other institutions before they are even started, acting as a sort of peer
        review at the beginning. And the desired endpoint for a clinical trial is
        not necessarily a publication, but rather the approval of a new drug. A recent
        <em><em>PLoS Medicine</em></em> paper found that only 43% of the clinical
        trials used for approval of drugs by the American Food and Drug Administration
        (FDA) were later published<sup><a href=\"https://web.archive.org/web/20151003084018/http://blogs.plos.org/mfenner/2008/10/14/open_access_whats_in_it_for_me/#fn10\">10</a></sup>.
        And many other clinical trials with negative results not even appear in the
        documents submitted for drug approval, meaning that these data are lost forever.
        This so-called publication bias creates many problems, and is unfortunately
        encouraged my most journals. Fortunately this situation has recently changed.
        Clinical trials must be registered in public databases since 2005, and since
        last month the main results also have to be published in the public database
        once the trial has been completed<sup><a href=\"https://web.archive.org/web/20151003084018/http://blogs.plos.org/mfenner/2008/10/14/open_access_whats_in_it_for_me/#fn11\">11</a></sup>.</p><p>fn1.
        <a href=\"https://web.archive.org/web/20151003084018/http://openaccessday.org/\">Open
        Access Day</a></p><p>fn2. <a href=\"https://web.archive.org/web/20151003084018/http://scienceblogs.com/clock/2008/10/open_access_day_the_blog_posts.php\">Open
        Access Day \u2013 the blog posts</a></p><p>fn3. <a href=\"https://web.archive.org/web/20151003084018/http://friendfeed.com/rooms/open-access-day\">Open
        Access Day FriendFeed Room</a></p><p>fn4. <a href=\"https://web.archive.org/web/20151003084018/http://www.sciam.com/blog/60-second-science/post.cfm?id=open-access-publisher-biomed-centra-2008-10-07\">Open
        access publisher BioMed Central sold to Springer</a></p><p>fn5. <a href=\"https://web.archive.org/web/20151003084018/http://www.oaspa.org/\">Open
        Access Scholarly Publishers Association</a></p><p>fn6. <a href=\"https://web.archive.org/web/20151003084018/http://mcblawg.blogspot.com/2008/10/why-i-am-oa-advocate.html\">Why
        I am an OA Advocate</a></p><p>fn7. <a href=\"https://web.archive.org/web/20151003084018/http://network.nature.com/people/mfenner/blog/2008/10/03/interview-with-alexander-griekspoor\">Interview
        with Alexander Griekspoor</a></p><p>fn8. <a href=\"https://web.archive.org/web/20151003084018/http://network.nature.com/people/mfenner/blog/2008/04/11/public-access-week-who-could-read-my-papers\">Public
        Access Week: Who could read my papers?</a></p><p>fn9. <a href=\"https://web.archive.org/web/20151003084018/http://network.nature.com/people/mfenner/blog/2008/08/01/article-downloads-and-citations-of-open-access-papers\">Article
        downloads and citations of open access papers</a></p><p>fn10. <em><em>PLoS
        Medicine</em></em> 2008 <a href=\"https://web.archive.org/web/20151003084018/http://dx.doi.org/10.1371/journal.pmed.0050191\">doi:10.1371/journal.pmed.0050191</a></p><p>fn11.
        <a href=\"https://web.archive.org/web/20151003084018/http://network.nature.com/people/mfenner/blog/2008/08/02/fdaaa-push-to-open-data-in-clinical-medicine\">FDAAA:
        Push to open data in clinical medicine</a></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Someone who should have won a Nobel Prize
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/someone-who-should-have-won-a-nobel-prize/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwb8</id>\n        <published>2008-10-05T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-15T14:57:42.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>The 2008 Nobel Prizes will
        be announced next week, starting with the Nobel Prize in Physiology or Medicine
        on Monday. There will be a live webcast on Monday at 9:30 AM GMT for those
        interested<sup><a href=\"https://web.archive.org/web/20150922174101/http://blogs.plos.org/mfenner/2008/10/05/someone_who_should_have_won_a_nobel_prize/#fn1\">1</a></sup>.
        As every year just before the announcement, speculation about this year's
        winners is in full swing. <a href=\"https://web.archive.org/web/20150922174101/http://network.nature.com/people/U113B3294/profile\">M.
        William Lensch</a>, here on Nature Network correctly predicted last year's
        winners<sup><a href=\"https://web.archive.org/web/20150922174101/http://blogs.plos.org/mfenner/2008/10/05/someone_who_should_have_won_a_nobel_prize/#fn2\">2</a></sup>,
        and this year he is trying it again<sup><a href=\"https://web.archive.org/web/20150922174101/http://blogs.plos.org/mfenner/2008/10/05/someone_who_should_have_won_a_nobel_prize/#fn3\">3</a></sup>.
        Thomson Reuters uses scientific methods for their predictions (including citation
        counts over 30 years and other awards), and they nominate<sup><a href=\"https://web.archive.org/web/20150922174101/http://blogs.plos.org/mfenner/2008/10/05/someone_who_should_have_won_a_nobel_prize/#fn4\">4</a></sup>
        these three discoveries:</p><ul><li>Toll-like receptors and innate immunity</li><li>the
        role of microRNAs in gene regulation</li><li>the development of meta-analysis
        and application to clinical medicine</li></ul><p>There will be of course many
        more blog posts about the Nobel Prizes this week, both on Nature Network<sup><a
        href=\"https://web.archive.org/web/20150922174101/http://blogs.plos.org/mfenner/2008/10/05/someone_who_should_have_won_a_nobel_prize/#fn5\">5</a></sup>
        and elsewhere. But in this blog post I want to talk about someone who will
        not win a Nobel Prize, but who would very much have deserved to do so. I am
        talking about <em><em>Judah Folkman</em></em> who invented the field of angiogenesis
        research and worked on it for more than 35 years. But the prize can only be
        awarded to living people, and Judah Folkman passed away this January. A <em><em>Nature</em></em>
        obiturary<sup><a href=\"https://web.archive.org/web/20150922174101/http://blogs.plos.org/mfenner/2008/10/05/someone_who_should_have_won_a_nobel_prize/#fn6\">6</a></sup>
        and recent <em><em>PNAS</em></em> article<sup><a href=\"https://web.archive.org/web/20150922174101/http://blogs.plos.org/mfenner/2008/10/05/someone_who_should_have_won_a_nobel_prize/#fn7\">7</a></sup>
        summarize his life and scientific achievements. Here I want to explain my
        personal reasons why I think he would have deserved a Nobel Prize.</p><h3
        id=\"angiogenesis-reseach-is-hypothesis-driven\">Angiogenesis reseach is hypothesis-driven</h3><p>Folkman
        first published his concept of tumor angiogenesis in 1971<sup><a href=\"https://web.archive.org/web/20150922174101/http://blogs.plos.org/mfenner/2008/10/05/someone_who_should_have_won_a_nobel_prize/#fn8\">8</a></sup>.
        He postulated that the recruitment of dedicated blood vessels is essential
        to tumor growth. It took 25 years of experimental work by Folkman and others
        until the concept of angiogenesis became widely accepted. Interestingly, another
        hypothesis that changed our understanding of cancer biology was also published
        that year: Knudson's two-hit hypothesis of tumor suppressor genes<sup><a href=\"https://web.archive.org/web/20150922174101/http://blogs.plos.org/mfenner/2008/10/05/someone_who_should_have_won_a_nobel_prize/#fn9\">9</a></sup>.
        Judah Folkman often said <em><em>Science goes where you imagine it.</em></em>
        A lot of today's research is not at all about proving an important hypothesis,
        and some people even mistakenly propose that concepts are no longer needed<sup><a
        href=\"https://web.archive.org/web/20150922174101/http://blogs.plos.org/mfenner/2008/10/05/someone_who_should_have_won_a_nobel_prize/#fn10\">10</a></sup>.</p><h3
        id=\"angiogenesis-research-is-full-of-failures\">Angiogenesis research is
        full of failures</h3><p>The story of angiogenesis research is a very complicated
        one. Not only took it Judah Folkman a long time and a lot of subbornness before
        his views became accepted, but there were many failures and setbacks along
        the way. Some scientific breakthroughs were an instant success, e.g. RNA interference
        awarded a Nobel Prize in 2006<sup><a href=\"https://web.archive.org/web/20150922174101/http://blogs.plos.org/mfenner/2008/10/05/someone_who_should_have_won_a_nobel_prize/#fn11\">11</a></sup>,
        but most research is just very complicated, including medical research. A
        September <em><em>Science</em></em> article about medical interventions found
        a median interval of 24 years between first description and earliest highly
        cited article<sup><a href=\"https://web.archive.org/web/20150922174101/http://blogs.plos.org/mfenner/2008/10/05/someone_who_should_have_won_a_nobel_prize/#fn12\">12</a></sup>.</p><h3
        id=\"angiogenesis-research-has-had-an-impact\">Angiogenesis research has had
        an impact</h3><p>The number of Pubmed citations is one good indicator for
        the research activity in a given field. Pubmed today lists 37,482 publications
        about angiogenesis, including 19985 publications from the last five years.
        This compares favorably to research about telomerase (8040 publications),
        and microRNA (3541 publications), two areas of research mentioned in the discussions
        about potential 2008 winners. Impact can be also measured in other ways, but
        it is clear that the concept of angiogenesis has not only profoundly changed
        cancer research, but is also important in many other diseases, as summarized
        in a 2005 <em><em>Nature</em></em> article<a href=\"https://web.archive.org/web/20150922174101/http://blogs.plos.org/mfenner/2008/10/05/someone_who_should_have_won_a_nobel_prize/#fn13\"><sup>13</sup></a>.</p><h3
        id=\"angiogenesis-research-is-medical-research\">Angiogenesis research is
        medical research</h3><p>As the name already suggests, the Nobel Prize for
        Physiology or Medicine is actually two prizes in one. It is a Nobel Prize
        in Biology, awarded for major achievements in our understanding of all aspects
        of biology. But is also a Nobel Prize in Medicine, where major advances in
        our understanding of human disease are awarded. The 2005 Nobel Prize to Barry
        Marshall and Robin Warren for the role of Helicobacter pylori in gastric disease<sup><a
        href=\"https://web.archive.org/web/20150922174101/http://blogs.plos.org/mfenner/2008/10/05/someone_who_should_have_won_a_nobel_prize/#fn14\">14</a></sup>
        is a good recent example of the latter category.<br>The research by Folkman
        and others has changed the way we think about cancer, but also the way we
        treat cancer. Each year, more than one million patients with colon, lung or
        breast cancer are treated with the anti-VEGF antibody bevacizumab. Other drugs
        targeting angiogenesis are either already in clinical use (e.g. sunitinib
        for renal cancer) or in development. This makes angiogenesis research a prime
        example for translational research. I very much agree with the views expressed
        in a set of articles in <em><em>Nature</em></em> this June<sup><a href=\"https://web.archive.org/web/20150922174101/http://blogs.plos.org/mfenner/2008/10/05/someone_who_should_have_won_a_nobel_prize/#fn15\">15</a></sup>,
        that more has to be done to connect our much better understanding of fundamental
        biological processes to the way we diagnose, prevent and treat diseases. And
        a Nobel Prize would be a strong signal.</p><p>fn1. <a href=\"https://web.archive.org/web/20150922174101/http://nobelprize.org/prize_announcements/medicine/index.html\">Announcement
        of the Nobel Prize in Physiology or Medicine</a></p><p>fn2. <a href=\"https://web.archive.org/web/20150922174101/http://network.nature.com/people/U113B3294/blog/2007/09/15/nobel-redux\">Nobel
        Redux</a></p><p>fn3. <a href=\"https://web.archive.org/web/20150922174101/http://network.nature.com/people/U113B3294/blog/2008/10/03/nobels-2008\">Nobels
        2008</a></p><p>fn4. <a href=\"https://web.archive.org/web/20150922174101/http://scientific.thomsonreuters.com/nobel/\">2008
        Nobel Predictions</a></p><p>fn5. <a href=\"https://web.archive.org/web/20150922174101/http://network.nature.com/groups/nnbloggername/forum/topics/3062\">Collective
        Blogging \u2013 Nobel Prize announcements</a></p><p>fn6. <em><em>Nature</em></em>
        2008 <a href=\"https://web.archive.org/web/20150922174101/http://dx.doi.org/10.1038/451781a\">doi:10.1038/451781a</a></p><p>fn7.
        <em><em>PNAS</em></em> 2008 <a href=\"https://web.archive.org/web/20150922174101/http://dx.doi.org/10.1073/pnas.0806582105\">doi:10.1073/pnas.0806582105</a></p><p>fn8.
        <em><em>N Engl J Med</em></em> 1971 <a href=\"https://web.archive.org/web/20150922174101/http://www.ncbi.nlm.nih.gov/pubmed/4938153?dopt=abstract\">Tumor
        angiogenesis: therapeutic implications</a></p><p>fn9. <em><em>PNAS</em></em>
        1971 <a href=\"https://web.archive.org/web/20150922174101/http://www.pnas.org/content/68/4/820\">Mutation
        and Cancer: Statistical Study of Retinoblastoma</a></p><p>fn10. <a href=\"https://web.archive.org/web/20150922174101/http://www.wired.com/science/discoveries/magazine/16-07/pb_theory\">The
        End of Theory: The Data Deluge Makes the Scientific Method Obsolete</a></p><p>fn11.
        <a href=\"https://web.archive.org/web/20150922174101/http://nobelprize.org/nobel_prizes/medicine/laureates/2006/index.html\">Nobel
        Prize in Physiology or Medicine 2006</a></p><p>fn12. <em><em>Science</em></em>
        2008 <a href=\"https://web.archive.org/web/20150922174101/http://dx.doi.org/10.1126/science.1160622\">doi:10.1126/science.1160622</a></p><p>fn13.
        <em><em>Nature</em></em> 2005 <a href=\"https://web.archive.org/web/20150922174101/http://blogs.plos.org/dx.doi/org/10.1038/nature04478\">doi:10.1038/nature04478</a></p><p>fn14.
        <a href=\"https://web.archive.org/web/20150922174101/http://nobelprize.org/nobel_prizes/medicine/laureates/2005/index.html\">Nobel
        Prize in Physiology or Medicine 2005</a></p><p>fn15. <em><em>Nature</em></em>
        2008 <a href=\"https://web.archive.org/web/20150922174101/http://dx.doi/org/10.1038/453839a\">doi:10.1038/453839a</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Papers: Interview with Alexander Griekspoor
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/interview-with-alexander-griekspoor/\"
        />\n\t\t<id>https://doi.org/10.53731/fy8ppqw-wctn03p</id>\n        <published>2008-10-03T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-15T14:57:10.000+00:00</updated>\n\t\t<category
        term=\"Interview\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/StoryPic7.jpg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/StoryPic7.jpg\"></p><p>Good
        software solves a problem. When one journal after another switched to PDF
        as electronic document format, and journals started to appear only in electronic
        form, storing papers as printouts in folders became impractical. But the PDF
        files will soon start to clutter the hard drive, despite efforts to organize
        them by topic, year or author. At least for Macintosh users, <a href=\"https://web.archive.org/web/20150924053037/http://mekentosj.com/papers/\">Papers</a>
        is one practical and elegant solution to this problem. I talked with Papers
        author <a href=\"https://web.archive.org/web/20150924053037/http://network.nature.com/people/mekentosj/profile\">Alexander
        Griekspoor</a> not only about Papers, but also about his career switch from
        cell biologist to software developer.</p><h3 id=\"1-can-you-describe-what-papers-is-and-does\">1.
        Can you describe what Papers is and does?</h3><p>The tag-line we coined for
        Papers is \u201Cyour personal library of science\u201D, a play-of-words on
        the well-known PLoS acronym. And this program for the Mac provides exactly
        that, it helps you manage and organize your personal scientific literature
        library. It provides a complete workflow for finding new articles using built-in
        search engines, browsing the publisher\u2019s website using the built-in Safari
        web browser, downloading, archiving and renaming the PDF files, and organizing
        and indexing these articles. Finally, it allows you to easily read the papers
        and share them with colleagues.</p><h3 id=\"2-how-is-papers-different-from-other-macintosh-bibliography-tools\">2.
        How is Papers different from other Macintosh bibliography tools?</h3><p>Papers
        distinguishes itself from other bibliography tools in that it is not a typical
        reference manager to begin with. The Mac has had several good reference management
        applications for a long time already, but when I created Papers I wanted to
        make a different application, one that didn\u2019t exist yet and one there
        was clearly a need for, one to manage all those PDF files that people were
        downloading. In the years before, the publishing industry had introduced PDFs
        as a replacement for sending articles by regular mail and it was a great success
        in that it made access to the literature much easier.</p><p>Still, their support
        of the researcher ended the moment you pressed the download button. Your web
        browser would save some cryptically named PDF file on your hard disk, which
        soon quickly filled up with dozens of these files. So whereas PDFs were introduced
        to save us from the messy file cabinets with hundreds of paper copies of your
        articles, we were now facing the digital equivalent of that on our desktop.</p><p>That
        was when it struck me that Apple had already solved this issue for MP3 files
        a few years earlier, iTunes had allowed us to stop bothering about managing
        MP3s and instead allowed us to focus on the songs. Papers was designed to
        do exactly the same when it comes to managing PDFs and instead lets us focus
        on the articles. Obviously, now the have seen how things can be different
        you notice that most reference managers on the Mac have started to play catch
        up, and are introducing PDF management features as well. Still, for us this
        has always been the key element and is just the start of many exciting things
        to come.</p><h3 id=\"3-what-recommendations-do-you-give-windows-and-linux-users\">3.
        What recommendations do you give Windows and Linux users?</h3><p>The most
        obvious answer is to buy a Mac of course \U0001F609 But more seriously, at
        the moment I\u2019m not aware of a program on Windows or Linux that offers
        the same feature set and user experience that Papers offers. But like the
        other reference management tools on the Mac there\u2019s a similar trend of
        adopting<br>these kind of features in bibliography tools on Linux and Windows
        as well.</p><h3 id=\"4-what-did-you-do-before-working-on-papers\">4. What
        did you do before working on Papers?</h3><p>Perhaps surprisingly I\u2019m
        a cell biologist of training and not a computer scientists or IT person. I
        studied medical biology at the Free University in Amsterdam and ended up doing
        my PhD at the Netherlands Cancer Institute in Amsterdam as well, where I studied
        the immune system using <a href=\"https://web.archive.org/web/20150924053037/http://dx.doi.org/10.1016/j.mib.2005.04.007\">live-cell
        fluorescence microscopy</a>.</p><h3 id=\"5-how-did-you-get-involved-in-writing-macintosh-software\">5.
        How did you get involved in writing Macintosh software?</h3><p>It all started
        out as a hobby driven by a long-time interest for both design and technology.
        I was introduced to the Mac when my dad brought home one of these \u201Cportable\u201D
        classic Macs when I was about 14 years old, and almost immediately I started
        experimenting with Photoshop et al. During university I earned some money
        in my spare time by designing and building websites, but it wasn\u2019t until
        about the time I started by PhD that Apple introduced Mac OS X and with it
        came the free set of developer tools that finally made it easy enough for
        someone without the classical IT background to start building his/her own
        Mac applications. Together with my best friend and fellow PhD student Tom
        Groothuis we started building a number of tools for molecular biologists (<a
        href=\"https://web.archive.org/web/20150924053037/http://mekentosj.com/enzymex/\">EnzymeX</a>),
        which we distributed for free under our \u201Cmek en tosj\u201D monicker.
        It didn\u2019t take long before the hobby started to get out of hand as the
        popularity of our programs started to soar.</p><h3 id=\"6-you-talked-about-your-postdoc-choice-in-a-2007-nature-jobs-article-what-made-you-decide-to-move-from-postdoc-to-company-founder\">6.
        You talked about your postdoc choice in a 2007 <a href=\"https://web.archive.org/web/20150924053037/http://dx.doi.org/10.1038/nj7130-948b\">Nature
        Jobs article</a>. What made you decide to move from postdoc to company founder?</h3><p>When
        the time came to pick a postdoc I knew one thing for sure, the programming
        was something I was so passionate about that it should be part of the postdoc
        rather than a spare time project. That\u2019s why I picked the text mining
        group at the <a href=\"https://web.archive.org/web/20150924053037/http://www.ebi.ac.uk/\">European
        Bioinformatics Institute</a> in Cambridge UK, also driven by an interest in
        the changes that were/are ongoing in the scientific publishing industry. I
        applied for a two year EU Marie Curie fellowship which I was fortunate to
        get, however it would take a few months between the end of my PhD and all
        the bureaucracy before I could get started in Cambridge. This was when I decided
        to build Papers. I got the idea for this \u201CiTunes for PDF files\u201D
        already two years earlier, but never had the time to do it. I did tell everybody
        I knew about it, but no one had done it and now finally I had some spare time
        on my hands.</p><p>The first beta of the program was released right at the
        time I started my postdoc and it was a success right from the start. In fact
        it was so successful and offered so many opportunities that it was soon difficult
        to focus on my actual postdoc and after a year I realized that this was the
        thing I was really passionate about and was what I wanted to concentrate fully
        on. That was when I decided to quit my job and become the company founder
        of Mekentosj Inc. \U0001F609</p><h3 id=\"7-do-you-want-to-talk-about-future-plans-for-papers\">7.
        Do you want to talk about future plans for Papers?</h3><p>It\u2019s still
        to early to talk in many details but like I said, for us the current version
        of Papers has always been the foundation on which we can build many exciting
        things we envision. We\u2019re working hard on the next major release of Papers
        which will definitely be a big step up. And obviously the introduction of
        the iPhone is something that also brings very exciting possibilities, so many
        things to look forward to!</p><p><em><em>Alex, thanks a lot for this interview.
        For more information, you can read an <a href=\"https://web.archive.org/web/20150924053037/http://www.macresearch.org/interview_with_alexander_griekspoor_from_mekentosj\">interview</a>
        from two years ago, or visit the <a href=\"https://web.archive.org/web/20150924053037/http://network.nature.com/groups/papers/forum/topics\">Mekentosj
        Papers Nature Network Forum</a>. And please tell me how you manage all these
        PDF files and how you use these references when writing a paper yourself.</em></em></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ New ways to look at your presentation ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/new-ways-to-look-at-your-presentation/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw1j</id>\n        <published>2008-09-26T04:45:00.000+00:00</published>\n\t\t<updated>2022-08-01T05:45:09.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>This blog
        post is about presentations. And this usually means PowerPoint presentations,
        although some people do well without it<sup><a href=\"https://web.archive.org/web/20080929085351/http://network.nature.com/people/mfenner/blog/2008/09/26/new-ways-to-look-at-your-presentation#fn1\"><strong>1</strong></a></sup>.
        Edward Tufte argues that PowerPoint can be a really bad tool to create slides<sup><a
        href=\"https://web.archive.org/web/20080929085351/http://network.nature.com/people/mfenner/blog/2008/09/26/new-ways-to-look-at-your-presentation#fn2\"><strong>2</strong></a></sup>.
        But it is probably not the software, but rather the people that produce these
        slides that are responsible for the quality<sup><a href=\"https://web.archive.org/web/20080929085351/http://network.nature.com/people/mfenner/blog/2008/09/26/new-ways-to-look-at-your-presentation#fn3\"><strong>3</strong></a></sup>.
        The Neurotic Physiology blog published a list of things you shouldn\u2019t
        do during a Powerpoint presentation<sup><a href=\"https://web.archive.org/web/20080929085351/http://network.nature.com/people/mfenner/blog/2008/09/26/new-ways-to-look-at-your-presentation#fn4\"><strong>4</strong></a></sup>.
        But there are also many tips to create better presentations. A May 2008 <em>Nature
        Methods</em> editorial<sup><a href=\"https://web.archive.org/web/20080929085351/http://network.nature.com/people/mfenner/blog/2008/09/26/new-ways-to-look-at-your-presentation#fn5\"><strong>5</strong></a></sup>
        gives ten such suggestions. Links to some more Powerpoint tips were collected
        in a Nautilus blog post<sup><a href=\"https://web.archive.org/web/20080929085351/http://network.nature.com/people/mfenner/blog/2008/09/26/new-ways-to-look-at-your-presentation#fn6\"><strong>6</strong></a></sup>
        by <a href=\"https://web.archive.org/web/20080929085351/http://network.nature.com/people/maxine/profile\"><strong>Maxine
        Clarke</strong></a>. One positive example is this presentation by <a href=\"https://web.archive.org/web/20080929085351/http://network.nature.com/people/mza/profile\"><strong>Matt
        Wood</strong></a><strong> </strong>from the Science Blogging London conference:</p><p><a
        href=\"https://web.archive.org/web/20080929085351/http://www.slideshare.net/mza/how-to-make-friendfeeds-and-influence-people-presentation?type=powerpoint\">How
        to make Friendfeeds and influence people</a></p><p>View SlideShare <a href=\"https://web.archive.org/web/20080929085351/http://www.slideshare.net/mza/how-to-make-friendfeeds-and-influence-people-presentation?type=powerpoint\"><strong>presentation</strong></a>
        or <a href=\"https://web.archive.org/web/20080929085351/http://www.slideshare.net/upload?type=powerpoint\"><strong>Upload</strong></a>
        your own. (tags: <a href=\"https://web.archive.org/web/20080929085351/http://slideshare.net/tag/science\"><strong>science</strong></a>
        <a href=\"https://web.archive.org/web/20080929085351/http://slideshare.net/tag/blogs\"><strong>blogs</strong></a>)</p><p>The
        Nature Network <a href=\"https://web.archive.org/web/20080929085351/http://network.nature.com/groups/scivis/forum/topics\"><strong>Visualization
        &amp; Science Forum</strong></a> is a great place for further discussions.</p><p>Presentations
        can also be created online. Google Docs and Zoho Show have been around for
        a while now, but 280Slides<sup><a href=\"https://web.archive.org/web/20080929085351/http://network.nature.com/people/mfenner/blog/2008/09/26/new-ways-to-look-at-your-presentation#fn7\"><strong>7</strong></a></sup>
        is a fairly new offering with a very slick interface. The advantages of these
        programs: slides can be created by several authors working together and slides
        can be easily shared. But presentations created with Powerpoint can also be
        shared online. Slideshare and Scribd are the most popular tools for this,
        and since last week these presentations can be embedded into Nature Network
        blog posts. By default, these presentations are public and can be seen by
        everybody. But they can also be uploaded as private presentations and only
        those that know the secret URL can see them. Presentations in the life sciences
        can also be uploaded to Nature Precedings<sup><a href=\"https://web.archive.org/web/20080929085351/http://network.nature.com/people/mfenner/blog/2008/09/26/new-ways-to-look-at-your-presentation#fn8\"><strong>8</strong></a></sup>.
        This way the scientific presentation receives a DOI and becomes citable. But
        Nature Precedings has still a long way to go with currently only about 50
        presentations available. Which is a bit surprising, since it looks like the
        perfect platform to host conference presentations.</p><p>YouTube videos or
        podcasts are probably the preferred format to share presentations that also
        include the recorded audio. Having the audio available is especially important
        for those presentations that have little text on their slides. Many presentations
        from the TED (Technology, Entertainment, Design) conference<sup><a href=\"https://web.archive.org/web/20080929085351/http://network.nature.com/people/mfenner/blog/2008/09/26/new-ways-to-look-at-your-presentation#fn9\"><strong>9</strong></a></sup>
        have been made available as TEDTalks, including this one by Neuroanatomist
        Jill Bolte Taylor:</p><p>If you want to give a presentation remotely (i.e.
        to one or more people in a different location), you could use that feature
        in Google Docs<sup><a href=\"https://web.archive.org/web/20080929085351/http://network.nature.com/people/mfenner/blog/2008/09/26/new-ways-to-look-at-your-presentation#fn10\"><strong>10</strong></a></sup>.
        Or use a full-fledged web conferencing solution such as Dimdin<sup><a href=\"https://web.archive.org/web/20080929085351/http://network.nature.com/people/mfenner/blog/2008/09/26/new-ways-to-look-at-your-presentation#fn11\"><strong>11</strong></a></sup>,
        which is free for up to 20 users and also is available as Open Source community
        edition.</p><p><sup>1</sup> <a href=\"https://web.archive.org/web/20080929085351/http://network.nature.com/people/henrygee/blog/2008/04/18/power-point-to-the-people\"><strong>Powerpoint
        to the People</strong></a></p><p><sup>2</sup> <strong>Kemp M.</strong> PowerPoint
        presentations and the culture of pitch. <em>Nature</em>2006; <a href=\"https://web.archive.org/web/20080929085351/http://dx.doi.org/10.1038/442140a\"><strong>doi:10.1038/442140a</strong></a></p><p><sup>3</sup>
        <a href=\"https://web.archive.org/web/20080929085351/http://freakonomics.blogs.nytimes.com/2007/06/20/dont-hate-powerpoint-hate-the-powerpointers/\"><strong>Don\u2019t
        hate Powerpoint; Hate the Powerpointers</strong></a></p><p><sup>4</sup> <a
        href=\"https://web.archive.org/web/20080929085351/http://scicurious.wordpress.com/2008/08/12/and-now-a-powerpoint-presentation/\"><strong>And
        Now, a Powerpoint Presentation</strong></a></p><p><sup>5</sup> Talking points.
        <em>Nature Methods</em> 2008; <a href=\"https://web.archive.org/web/20080929085351/http://dx.doi.org/10.1038/nmeth0508-371\"><strong>doi:10.1038/nmeth0508-371</strong></a></p><p><sup>6</sup>
        <a href=\"https://web.archive.org/web/20080929085351/http://blogs.nature.com/nautilus/2008/05/how_to_give_a_good_presentatio.html\"><strong>How
        to give a good presentation</strong></a></p><p><sup>7</sup> <a href=\"https://web.archive.org/web/20080929085351/http://280slides.com/\"><strong>280Slides</strong></a></p><p><sup>8</sup>
        <a href=\"https://web.archive.org/web/20080929085351/http://precedings.nature.com/\"><strong>Nature
        Preceedings</strong></a></p><p><sup>9</sup> <a href=\"https://web.archive.org/web/20080929085351/http://www.ted.com/\"><strong>TED</strong></a></p><p><sup>10</sup>
        <a href=\"https://web.archive.org/web/20080929085351/http://network.nature.com/people/andrewsun/blog/2007/10/01/google-docs-now-with-presentation\"><strong>Google
        Docs \u2013 Now with Presentation</strong></a></p><p><sup>11</sup> <a href=\"https://web.archive.org/web/20080929085351/http://www.dimdim.com/\"><strong>Dimdim</strong></a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ How to lure (German) researchers back to
        Germany ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/how-to-lure-german-researchers-back-to-germany/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw1k</id>\n        <published>2008-09-19T19:21:00.000+00:00</published>\n\t\t<updated>2022-08-01T05:43:48.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>The <strong>German
        Academic International Network (GAIN)</strong><sup><a href=\"https://web.archive.org/web/20080921133726/http://network.nature.com/people/mfenner/blog/2008/09/19/how-to-lure-german-researchers-back-to-germany#fn1\"><strong>1</strong></a></sup>
        informs German researchers working in North America about research opportunities
        in Germany. The implied intention is to lure German researchers back to Germany.
        GAIN project director Katja Simons explains:</p><p><em>Many german researchers
        abroad are highly interested in returning but they need support creating networks
        and receiving information on career opportunities in Germany. Germany has
        invested a great deal in their education and is in need of these bright minds
        and their experience they gained abroad.</em></p><p>GAIN is a joint initiative
        by the <strong>Alexander von Humboldt Foundation (AvH)</strong>, the <strong>German
        Academic Exchange Service (DAAD)</strong> and the <strong>German Research
        Foundation (DFG)</strong>. Their 8th annual meeting took place two weeks ago
        in Boston<sup><a href=\"https://web.archive.org/web/20080921133726/http://network.nature.com/people/mfenner/blog/2008/09/19/how-to-lure-german-researchers-back-to-germany#fn2\"><strong>2</strong></a></sup>.
        More than 200 researchers working in North America participated, together
        with representatives from many German research organizations, including Matthias
        Kleiner, president of the German Research Foundation (DFG)<sup><a href=\"https://web.archive.org/web/20080921133726/http://network.nature.com/people/mfenner/blog/2008/09/19/how-to-lure-german-researchers-back-to-germany#fn3\"><strong>3</strong></a></sup>
        and Margeret Wintermantel, president of the <strong>German Recotors\u2019
        Conference</strong> (HRK, the association of all higher education institutions
        in Germany)<sup><a href=\"https://web.archive.org/web/20080921133726/http://network.nature.com/people/mfenner/blog/2008/09/19/how-to-lure-german-researchers-back-to-germany#fn4\"><strong>4</strong></a></sup>.
        Representatives from business and politics (members of the parliament) were
        also present.</p><p>To get a more personal perspective, I talked to two researchers
        that attented the meeting. <a href=\"https://web.archive.org/web/20080921133726/http://network.nature.com/profile/avmaier\"><strong>Alexander
        Maier</strong></a>, a research fellow at the <a href=\"https://web.archive.org/web/20080921133726/http://network.nature.com/affiliations/735\"><strong>NIH</strong></a>,
        thinks that the GAIN meeting was a success. Sceptical at the beginning of
        the conference, he acknowledges that things have changed and that doing reseach
        in Germany has become much more attractive. The <strong>excellence initiative</strong>
        by the German Government is one big reason for that change<sup><a href=\"https://web.archive.org/web/20080921133726/http://network.nature.com/people/mfenner/blog/2008/09/19/how-to-lure-german-researchers-back-to-germany#fn5\"><strong>5</strong></a></sup>.
        The most rewarding part of the program for him was the workshop on how to
        apply for professorhips.</p><p>Florian Jaeger, an assistant professor from
        the University of Rochester (his blog is here<sup><a href=\"https://web.archive.org/web/20080921133726/http://network.nature.com/people/mfenner/blog/2008/09/19/how-to-lure-german-researchers-back-to-germany#fn6\"><strong>6</strong></a></sup>)
        is on the GAIN advisory board. He also got the impression that the German
        reseach system is changing, and that</p><p><em>Many institutions in Germany
        seem to be inspired to learn from the positive aspects of the American system
        (and maybe even to improve on it).</em></p><p>But both Alexander and Florian
        felt that the research environment in Germany is still far from perfect, and
        the German research organizations should not think that all problems have
        been solved. Startup grants are often relatively low and junior research groups
        are usually not as independent as in the United States. And Florian thinks
        that the research atmosphere \u2013 the way people interact and approach problems
        \u2013 is still more stimulating in the United States.</p><p>Most reports
        about the GAIN meeting are in the German media, including the newspapers Hamburger
        Abendblatt<sup><a href=\"https://web.archive.org/web/20080921133726/http://network.nature.com/people/mfenner/blog/2008/09/19/how-to-lure-german-researchers-back-to-germany#fn7\"><strong>7</strong></a></sup>
        and S\xFCddeutsche Zeitung<sup><a href=\"https://web.archive.org/web/20080921133726/http://network.nature.com/people/mfenner/blog/2008/09/19/how-to-lure-german-researchers-back-to-germany#fn8\"><strong>8</strong></a></sup>.
        I found one blog post from a German postdoc attending the meeting<sup><a href=\"https://web.archive.org/web/20080921133726/http://network.nature.com/people/mfenner/blog/2008/09/19/how-to-lure-german-researchers-back-to-germany#fn9\"><strong>9</strong></a></sup>.
        Nature Network is a good place to have a discussion not only about the research
        environment in different countries, but also to learn more about similar strategies
        carried out by other countries, e.g. France, Italy, Japan or China. Feel free
        to leave your comments about why you left your home country to do research
        somewhere else<sup><a href=\"https://web.archive.org/web/20080921133726/http://network.nature.com/people/mfenner/blog/2008/09/19/how-to-lure-german-researchers-back-to-germany#fn10\"><strong>10</strong></a></sup>,
        or why you returned after finishing your PhD or postdoc<sup><a href=\"https://web.archive.org/web/20080921133726/http://network.nature.com/people/mfenner/blog/2008/09/19/how-to-lure-german-researchers-back-to-germany#fn11\"><strong>11</strong></a></sup>.</p><p><sup>1</sup>
        <a href=\"https://web.archive.org/web/20080921133726/http://www.gain-network.org/\"><strong>GAIN
        Homepage</strong></a></p><p><sup>2</sup> <a href=\"https://web.archive.org/web/20080921133726/http://www.eurekalert.org/pub_releases/2008-09/df-wc091008.php\"><strong>DFG
        news report of the meeting</strong></a></p><p><sup>3</sup> <a href=\"https://web.archive.org/web/20080921133726/http://www.dfg.de/en/index.html\"><strong>DFG
        Homepage</strong></a></p><p><sup>4</sup> <a href=\"https://web.archive.org/web/20080921133726/http://www.hrk.de/index_eng.php\"><strong>HRK
        Homepage</strong></a></p><p><sup>5</sup> <a href=\"https://web.archive.org/web/20080921133726/http://www.dfg.de/en/research_funding/coordinated_programmes/excellence_initiative/general_information.html\"><strong>Excellence
        initiative</strong></a></p><p><sup>6</sup> <a href=\"https://web.archive.org/web/20080921133726/http://hlplab.wordpress.com/\"><strong>HLP/Jaeger
        lab blog</strong></a></p><p><sup>7</sup> <a href=\"https://web.archive.org/web/20080921133726/http://www.abendblatt.de/daten/2008/09/15/937232.html\"><strong>Lockrufe
        der deutschen Forschung</strong></a></p><p><sup>8</sup> <a href=\"https://web.archive.org/web/20080921133726/http://jetzt.sueddeutsche.de/texte/anzeigen/446385\"><strong>In
        Boston werben Politiker f\xFCr deutsche Unis</strong></a></p><p><sup>9</sup>
        <a href=\"https://web.archive.org/web/20080921133726/http://sonjatoots.blogspot.com/2008/09/one-with-boston.html\"><strong>Sonja
        in the City</strong></a></p><p><sup>10</sup> <a href=\"https://web.archive.org/web/20080921133726/http://network.nature.com/people/etchevers/blog\"><strong>A
        Developing Passion</strong></a></p><p><sup>11</sup> <a href=\"https://web.archive.org/web/20080921133726/http://network.nature.com/people/massimopinto/blog\"><strong>Science
        in the Bel Paese</strong></a></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ It&#x27;s time for Conference 2.0 ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/its-time-for-conference-2-0/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw1m</id>\n
        \       <published>2008-09-12T16:16:00.000+00:00</published>\n\t\t<updated>2022-08-01T05:42:49.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p><em><strong>Conference
        2.0</strong> \u2013 A scheduled meeting of people sharing a common interest
        that takes advantage of Web 2.0<sup><a href=\"https://web.archive.org/web/20080929012015/http://network.nature.com/people/mfenner/blog/2008/09/12/its-time-for-conference-2-0#fn1\"><strong>1</strong></a></sup>
        concepts.</em></p><p>Scientific conferences are essential both for the exchange
        of ideas and for networking. But they don\u2019t have to be organized the
        same way as 10-20 years ago. Web 2.0 tools now allow much broader user participation
        before, during and after the conference. Technology conferences have seen
        this change already<sup><a href=\"https://web.archive.org/web/20080929012015/http://network.nature.com/people/mfenner/blog/2008/09/12/its-time-for-conference-2-0#fn2\"><strong>2</strong></a></sup>.
        We also already have open source software to organize conferences<sup><a href=\"https://web.archive.org/web/20080929012015/http://network.nature.com/people/mfenner/blog/2008/09/12/its-time-for-conference-2-0#fn3\"><strong>3</strong></a></sup>.
        I\u2019ve collected a few of those ideas and concepts below.</p><p><strong>1.
        Keep the conference small</strong><br>Active user participation works better
        in smaller conferences, e.g. not more than maybe 150 participants (derived
        from Dunbar\u2019s number<sup><a href=\"https://web.archive.org/web/20080929012015/http://network.nature.com/people/mfenner/blog/2008/09/12/its-time-for-conference-2-0#fn4\"><strong>4</strong></a></sup>
        introduced by <a href=\"https://web.archive.org/web/20080929012015/http://network.nature.com/profile/duncan\"><strong>Duncan
        Hull</strong></a>). This will exclude large or very large conferences \u2013
        the largest scientific conferences today have more than 10.000 participants.
        But those larger conferences can still adopt some of the principles discussed
        below.</p><p><strong>2. Allow for user input to the conference program</strong><br>Even
        though most scientific conferences ask for abstract submissions well before
        the conference, the conference schedule is ultimately decided my a small program
        committee. But conference organizers could well ask for user input about session
        topics. In the BarCamp or unconference format, the conference program is even
        decided on the first day of the conference<sup><a href=\"https://web.archive.org/web/20080929012015/http://network.nature.com/people/mfenner/blog/2008/09/12/its-time-for-conference-2-0#fn5\"><strong>5</strong></a></sup>.</p><p><strong>3.
        Provide free WiFi</strong><br>This is essential for liveblogging about the
        conference. And free WiFi in combination with a good conference website with
        detailed schedule, message boards and practical information would greatly
        reduce the amount of printed material that needs to be handed out at the conference.</p><p><strong>4.
        Set aside time for networking</strong><br>There should be enough time (and
        space) between sessions to talk to the other conference participants. After
        all, this is one main reason for many people to attend a conference. And the
        conference organizers can facilitate networking in other ways. Poster sessions
        (see below) are one way, a very short introduction by every participant (either
        in person or on the conference website) is another idea.</p><p><strong>5.
        Pay attention to poster sessions and discussions</strong><br>Conferences can
        have other session formats than oral presentations. Poster sessions are an
        often neglected part of many conferences. But they are a great tool for networking,
        especially with younger scientists. The conference organizers should set aside
        enough time and avoid parallel oral sessions. Providing drinks and food also
        helps. Round-table discussions are another underused format with a lot of
        potential.</p><p><strong>6. Encourage blogging</strong><br>There should be
        a clear policy regarding blogging stated at the conference website. And this
        policy should make it easy for conference participants to blog. This means
        no preregistration and no required affiliation with a news service or journal.
        Conference organizers should provide a tag for the conference so that blog
        entries can be tracked.</p><p><em>Blogging about the conference is encouraged
        by the conference organizers. Please use the tag *conference</em>name* for
        all your blog posts. Please don\u2019t blog about sessions marked <strong>non_public</strong>
        in the conference program. They contain information that should not become
        become public at this time, e.g. because they discuss unpublished results.
        For further questions regarding blogging at the conference, please contact
        \u2026_</p><p>There are many different ways to blog about a conference, microblogging
        via FriendFeed is currently a very popular option<sup><a href=\"https://web.archive.org/web/20080929012015/http://network.nature.com/people/mfenner/blog/2008/09/12/its-time-for-conference-2-0#fn6\"><strong>6</strong></a></sup>.</p><p><strong>7.
        Produce podcasts</strong><br>Podcasts with audio and video of the slides are
        a great way to capture oral sessions at a conference. They are espcially valuable
        for those unable to attend. This week\u2019s <strong>Science in the 21st Century</strong>
        conference is a good example of how this can be done<sup><a href=\"https://web.archive.org/web/20080929012015/http://network.nature.com/people/mfenner/blog/2008/09/12/its-time-for-conference-2-0#fn7\"><strong>7</strong></a></sup>.</p><p><strong>8.
        Organize parallel local conferences</strong><br>The costs and annoyances of
        traveling, combined with concerns about the carbon footprint<sup><a href=\"https://web.archive.org/web/20080929012015/http://network.nature.com/people/mfenner/blog/2008/09/12/its-time-for-conference-2-0#fn8\"><strong>8</strong></a></sup>
        have led to new concepts. Instead of following the conference from the distance
        via live-streaming or live-blogging, why not organize several parallel local
        conferences<sup><a href=\"https://web.archive.org/web/20080929012015/http://network.nature.com/people/mfenner/blog/2008/09/12/its-time-for-conference-2-0#fn9\"><strong>9</strong></a></sup>?
        The Singularity web conference next month is using this concept<sup><a href=\"https://web.archive.org/web/20080929012015/http://network.nature.com/people/mfenner/blog/2008/09/12/its-time-for-conference-2-0#fn10\"><strong>10</strong></a></sup>.
        Will the next science blogging conference happen in parallel in several locations?</p><p><sup>1</sup>
        <a href=\"https://web.archive.org/web/20080929012015/http://oreilly.com/pub/a/oreilly/tim/news/2005/09/30/what-is-web-20.html\"><strong>What
        is Web 2.0</strong></a></p><p><sup>2</sup> <a href=\"https://web.archive.org/web/20080929012015/http://money.cnn.com/2008/03/11/technology/fost_conference.fortune/\"><strong>Welcome
        to Conference 2.0</strong></a></p><p><sup>3</sup> <a href=\"https://web.archive.org/web/20080929012015/http://pkp.sfu.ca/?q=ocs\"><strong>Open
        Conference Systems</strong></a></p><p><sup>4</sup> <a href=\"https://web.archive.org/web/20080929012015/http://en.wikipedia.org/wiki/Dunbar%27s_number\"><strong>Dunbar\u2019s
        number</strong></a></p><p><sup>5</sup> <a href=\"https://web.archive.org/web/20080929012015/http://network.nature.com/blogs/user/UE19877E8/2008/08/11/in-which-i-am-utterly-fooed\"><strong>In
        which I am utterly Fooed</strong></a></p><p><sup>6</sup> <a href=\"https://web.archive.org/web/20080929012015/http://scienceblogs.com/principles/2008/09/microblogging_conference_talks.php\"><strong>Micro-Blogging
        Conference Talks</strong></a></p><p><sup>7</sup> <a href=\"https://web.archive.org/web/20080929012015/http://pirsa.org/C08021\"><strong>Perimeter
        Institute Recorded Seminar Archive</strong></a></p><p><sup>8</sup> <a href=\"https://web.archive.org/web/20080929012015/http://www.carbonfootprint.com/\"><strong>Carbon
        Footprint</strong></a></p><p><sup>9</sup> <a href=\"https://web.archive.org/web/20080929012015/http://www.insideria.com/2008/06/building-conference-20.html\"><strong>Building
        Conference 2.0</strong></a></p><p><sup>10</sup> <a href=\"https://web.archive.org/web/20080929012015/http://www.headconference.com/\"><strong>Head
        \u2013 the global web conference</strong></a></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Mendeley: Interview with Victor Henning
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/interview-with-victor-henning-from-mendeley/\"
        />\n\t\t<id>https://doi.org/10.53731/eewgt6b-bh097qd</id>\n        <published>2008-09-05T06:18:00.000+00:00</published>\n\t\t<updated>2022-08-15T14:52:33.000+00:00</updated>\n\t\t<category
        term=\"Interview\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/2822759480_c330822084_o.jpg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/2822759480_c330822084_o.jpg\"></p><p>In
        the last few months we have seen an ever increasing number of new social networking
        (Web 2.0) sites for scientists. Good Web 2.0 tools for scientists primarily
        try to solve a problem. But by adding a social aspect, they will gain useful
        features that would otherwise not be possible. <a href=\"https://web.archive.org/web/20080920001317/http://network.nature.com/profile/U27CE62BB\"><strong>Eva
        Amsen</strong></a> has recently written a great blog post about this<sup><a
        href=\"https://web.archive.org/web/20080920001317/http://network.nature.com/people/mfenner/blog/2008/09/05/interview-with-victor-henning-from-mendeley#fn1\"><strong>1</strong></a></sup>.
        Many of these new services have overlapping functions, e.g. almost all of
        them allow the user to maintain a list of contacts. This raises two questions:</p><ol><li>Which
        of these sites has (or have) the features that I\u2019m most interested in?</li><li>Do
        any of these sites work with the commonly used desktop tools and with each
        other, so that I don\u2019t have to maintain duplicate information, e.g. the
        list of my publications?</li></ol><p><a href=\"https://web.archive.org/web/20080920001317/http://network.nature.com/profile/U42E63119\"><strong>Cameron
        Neylon</strong></a> in August posted an open letter to the developers of these
        sites<sup><a href=\"https://web.archive.org/web/20080920001317/http://network.nature.com/people/mfenner/blog/2008/09/05/interview-with-victor-henning-from-mendeley#fn2\"><strong>2</strong></a></sup>
        and also started a comprehensive list<sup><a href=\"https://web.archive.org/web/20080920001317/http://network.nature.com/people/mfenner/blog/2008/09/05/interview-with-victor-henning-from-mendeley#fn3\"><strong>3</strong></a></sup>.
        <a href=\"https://web.archive.org/web/20080920001317/http://network.nature.com/profile/http-network-nature-comprofilegerrymck\"><strong>Gerry
        McKiernan</strong></a><strong> </strong>collects information about social
        networking sites for scientists on his SciTechNet blog<sup><a href=\"https://web.archive.org/web/20080920001317/http://network.nature.com/people/mfenner/blog/2008/09/05/interview-with-victor-henning-from-mendeley#fn4\"><strong>4</strong></a></sup>.
        Mendeley<sup><a href=\"https://web.archive.org/web/20080920001317/http://network.nature.com/people/mfenner/blog/2008/09/05/interview-with-victor-henning-from-mendeley#fn5\"><strong>5</strong></a></sup>
        is one of these new Web 2.0 sites for scientists (they launched in August),
        and I spoke with <a href=\"https://web.archive.org/web/20080920001317/http://network.nature.com/profile/U4C4A58A2[6\"><strong>Victor
        Henning</strong></a>, one of the founders of Mendeley, about it.</p><p><strong>1.
        Can you describe what Mendeley is and does?</strong><br>Mendeley is actually
        two things: Mendeley Desktop and Mendeley Web. Mendeley Desktop is free academic
        software (available for Windows, Mac and Linux) for managing &amp; sharing
        research papers. Mendeley Web lets you back up your research papers online,
        shows you research trends in your academic discipline, and connects you to
        like-minded researchers.</p><p><strong>2. What is the connection to Last.fm?</strong><br>There
        is a conceptual as well as a personal connection. Conceptually, in the long
        run Mendeley aims to do for research what Last.fm did for music. For those
        of your readers who don\u2019t know Last.fm, this is how it works: When you
        install Last.fm\u2019s desktop software on your computer, it will monitor
        which music you listen to and automatically build a profile of your musical
        taste on the Last.fm website. The website then recommends you music that you
        might like, shows you statistics about the most popular songs and artists
        in your favourite genre, and lets you discover people with a similar taste
        in music. By aggregating the listening habits and tags of its 20 million users,
        Last.fm has managed to create the largest ontological classification (and
        the largest open database) of music in the world \u2013 it would be great
        if we could achieve the same for research papers.</p><p>So, if you install
        Mendeley Desktop on your computer, you can manage and share research papers
        on your machine, but you can also upload your papers to your private account
        on Mendeley Web to access them online. Mendeley Web anonymously aggregates
        the metadata of these papers to generate statistics about the most popular
        authors and papers in your research discipline, and \u2013 in the future \u2013
        generates recommendations for papers which you might like. One thing that
        we handle very differently from Last.fm is privacy: The Last.fm website lets
        everyone know which music you listen to, whereas Mendeley Web keeps all your
        research data in your private account which can\u2019t be accessed by anyone
        else. The conceptual parallels between Last.fm and Mendeley are outlined in
        more detail in a talk I gave both at the EuroScience Open Forum 2008 in Barcelona
        and at the Southampton Open Science Workshop<sup><a href=\"https://web.archive.org/web/20080920001317/http://network.nature.com/people/mfenner/blog/2008/09/05/interview-with-victor-henning-from-mendeley#fn7\"><strong>7</strong></a></sup>.</p><figure
        class=\"kg-card kg-image-card\"><img src=\"https://blog.front-matter.io/content/images/2022/08/2822784112_f01ed9673b_o.jpg\"
        class=\"kg-image\" alt loading=\"lazy\" width=\"640\" height=\"400\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/2822784112_f01ed9673b_o.jpg
        600w, https://blog.front-matter.io/content/images/2022/08/2822784112_f01ed9673b_o.jpg
        640w\"></figure><p>Besides the conceptual similarities, the personal connection
        to Last.fm is Dr. Stefan Gl\xE4nzer. He was Last.fm\u2019s first investor
        and executive chairman, and now has the same role at Mendeley. My co-founder
        Jan and I first met him back in 2003, when he was a guest lecturer in Entrepreneurship
        at our university, the WHU Vallendar<sup><a href=\"https://web.archive.org/web/20080920001317/http://network.nature.com/people/mfenner/blog/2008/09/05/interview-with-victor-henning-from-mendeley#fn8\"><strong>8</strong></a></sup>,
        and we contributed a case study to the book he published together with our
        professors. So when we were looking for funding, we approached him again in
        June 2007, he was fascinated by the idea of Mendeley and luckily decided to
        join us. He also brought us in touch with the former founding engineers of
        Skype, who became investors as well.</p><p><strong>3. What are your responsibilities
        within Mendeley?</strong><br>I do most of the conceptual work behind Mendeley
        and write the specifications for our developers: What is the vision of Mendeley
        Desktop and Mendeley Web in the long term, which features should we develop
        next to get there, how does each feature work in detail, right down to questions
        like \u201Cwhere do we place this button and how do we label it?\u201D. So
        you can blame me for all the usability problems you might encounter.</p><p>I\u2019m
        also responsible for staying in touch with the academic community and incorporating
        its wishes into the Mendeley development roadmap, which has the enjoyable
        side effect that I get to travel to all these wonderful academic conferences.
        Next week, I\u2019ll be at the Science in the 21st Century conference at the
        Perimeter Institute for Theoretical Physics, Waterloo/Ontario<sup><a href=\"https://web.archive.org/web/20080920001317/http://network.nature.com/people/mfenner/blog/2008/09/05/interview-with-victor-henning-from-mendeley#fn9\"><strong>9</strong></a></sup>.</p><p><strong>4.
        What did you do before starting to work for Mendeley?</strong><br>Until a
        little more than a year ago, I thought I\u2019d pursue an academic career
        \u2013 I\u2019m currently finishing my Ph.D. on decision-making and choice
        at the Bauhaus-University of Weimar. I\u2019ve been saying \u201Ccurrently
        finishing\u201D for almost a year now, but I\u2019m hopeful that I\u2019ll
        manage to submit my thesis by the end of this year :-) Prior to that, I\u2019ve
        worked in film production and the music industry a lot, and I opened a caf\xE9/bar<sup><a
        href=\"https://web.archive.org/web/20080920001317/http://network.nature.com/people/mfenner/blog/2008/09/05/interview-with-victor-henning-from-mendeley#fn10\"><strong>10</strong></a></sup>
        opposite the WHU in parallel to writing my master\u2019s thesis. I actually
        left Vallendar the day after the opening night to pursue my Ph.D. in Weimar,
        so I had all of the work and little of the fun of owning a caf\xE9/bar!</p><p><strong>5.
        What is your policy regarding users sharing their PDF files of publications
        with others?</strong><br>I think it\u2019s important to point out that we\u2019re
        not a \u201CNapster for research papers\u201D \u2013 i.e. no free-for-all
        peer-to-peer filesharing. Quite a lot of people are disappointed when I tell
        them that! Sharing is currently limited to \u201CShared Document Groups\u201D
        of max. 10 people (e.g. a lab, or collaborators on a research paper), although
        you can create and join as many Shared Document Groups as you like. Also,
        as we state in our terms of use<sup><a href=\"https://web.archive.org/web/20080920001317/http://network.nature.com/people/mfenner/blog/2008/09/05/interview-with-victor-henning-from-mendeley#fn11\"><strong>11</strong></a></sup>,
        you may only share PDFs with the permission of the copyright owner \u2013
        e.g. your own articles or working papers, articles from Open Access databases,
        articles under a Creative Commons/Scientific Commons license, or perhaps when
        you and the person you are sharing the PDF with both have licensed access
        to the database the PDF was taken from.</p><p>We also encourage users to post
        their own papers and working papers on their Mendeley profiles \u2013 depending
        on whether they have permission to do so from their publishers. As you can
        imagine, we\u2019re big fans of Open Access!</p><p><strong>6. How is Mendeley
        different from other desktop reference managers such as Endnote?</strong><br>There
        are a number of things that make Mendeley Desktop unique, but I\u2019d probably
        highlight the collaboration aspect, the \u201Cautomatic metadata extraction\u201D,
        the online back-up/multi-machine support, and the cross-platform support:</p><ul><li>As
        far as I know, Mendeley Desktop is the only desktop reference management software
        that lets you share and collaboratively annotate research papers. We\u2019re
        also working on a \u201Cgroups\u201D feature in Mendeley Web which labs can
        use for discussions, sharing files, setting up a lab blog/wiki etc. \u2013
        all of this will tie into the reference management seamlessly.</li><li>The
        \u201Cautomatic metadata extraction\u201D is quite unique as well: When you
        drop your PDFs into Mendeley Desktop, it will automatically extract the full-text
        to make it searchable, try to guess the correct metadata from the full-text
        (author, title, journal, volume, issue etc.) so you don\u2019t have to type
        it in manually, and also parse each documents\u2019 cited references, so you
        can add them to your library as well.</li><li>Due to the integration with
        Mendeley Web, you can back-up your entire library for online access through
        simple drag &amp; drop in Mendeley Desktop. Also, this means that you can
        install Mendeley Desktop on multiple computers and easily synchronize your
        PDF library across them via the Mendeley Online Library.</li><li>Last but
        not least, Mendeley Desktop is the only desktop reference manager that is
        available on all three major platforms (Windows, Mac, and Linux).</li></ul><p>Not
        to mention that, in comparison to solutions such as EndNote, RefMan, RefWorks
        etc., which cost hundreds of Euros per license, Mendeley Desktop is completely
        free.</p><p><strong>7. How is Mendeley different from other social networking
        sites for scientists?</strong><br>While social networking is an aspect of
        Mendeley Web, we don\u2019t see ourselves primarily as a social network. We
        don\u2019t believe that social networking in itself is the killer feature
        that researchers are looking for \u2013 rather we\u2019re using a social network
        to enable researchers to share their data. I think that <a href=\"https://web.archive.org/web/20080920001317/http://network.nature.com/profile/neilfws\"><strong>Neil
        Saunders</strong></a>, who is also here on Nature Network, said it best: \u201CReally,
        it\u2019s our data that needs to be social, not ourselves\u201D. So we\u2019ve
        tried to develop a research tool which is useful without any network effects,
        and which uses networking as a means rather than an end.</p><p>To invoke the
        analogy to Last.fm again: Even though people have profiles on Last.fm and
        can connect to each other, Last.fm is not primarily a social network. Last.fm
        connects the music first, and networks of people form around the music as
        a second step.</p><p><strong>8. Does Mendeley integrate with other social
        networking sites and services for scientists, e.g. Connotea or CiteULike?
        Does it integrate with desktop reference managers?</strong><br>At the moment
        we\u2019re focusing on increasing the speed and stability of Mendeley, as
        well as introducing more features which make Mendeley useful as a standalone
        software. However, compatibility with Connotea or CiteULike is something we\u2019ll
        be working on in the near future.</p><p>Regarding integration with other desktop
        reference managers: At the Science Blogging Conference<sup><a href=\"https://web.archive.org/web/20080920001317/http://network.nature.com/people/mfenner/blog/2008/09/05/interview-with-victor-henning-from-mendeley#fn11\"><strong>11</strong></a></sup>
        I briefly spoke to <a href=\"https://web.archive.org/web/20080920001317/http://network.nature.com/profile/mekentosj\"><strong>Alexander
        Griekspoor</strong></a>, the developer of the Mac software Papers<sup><a href=\"https://web.archive.org/web/20080920001317/http://network.nature.com/people/mfenner/blog/2008/09/05/interview-with-victor-henning-from-mendeley#fn12\"><strong>12</strong></a></sup>,
        whether we couldn\u2019t make our software compatible so that Papers users
        and Mendeley Desktop users could share and synchronize their collections online.
        As for EndNote: It\u2019s already possible to import/export data to/from Mendeley
        in the EndNote XML format \u2013 but, sadly, I don\u2019t think that EndNote\u2019s
        developers would be inclined to enable online sharing between EndNote and
        Mendeley.</p><p><strong>9. Do you want to talk about future plans for Mendeley?</strong><br>Sure!
        Besides speed and stability, which I already mentioned, we\u2019ll be working
        on two main issues to better integrate Mendeley into the research workflow.
        First, there will be a \u201Ccite-while-you-write\u201D plugin for Microsoft
        Word (or Open Office, if our users would prefer that), so that you can generate
        reference lists from your Mendeley library automatically. Similarly, we\u2019ll
        improve the integration with LaTeX by automating the BibTeX file export from
        Mendeley Desktop. Second, we\u2019ll introduce a \u201Cbookmarklet\u201D like
        the ones CiteULike or Connotea have, which lets you import metadata/papers
        from websites into your Mendeley Online Library with a single click. This
        metadata will then be automatically synchronized with the Mendeley Desktop
        library on your computer.</p><p>The Microsoft Word/LaTeX integration and the
        online bookmarklet will be available very soon. Over the coming months, we\u2019ll
        also introduce OCR to Mendeley Desktop, so that you can extract metadata,
        full-text and references from older scanned-image documents; we\u2019ll integrate
        Mendeley Desktop with external databases such as PubMed, Scopus, and Web of
        Science; we\u2019ll implement the groups/lab management feature on Mendeley
        Web that I already mentioned; there will be much more detailed research trend
        statistics on Mendeley Web; we\u2019ll introduce the recommendation engine
        for academic papers, and many more little goodies. For example, a frequent
        user request has been automatic PDF file renaming based on the metadata \u2013
        so that\u2019s going to be in one of the next versions.</p><p><strong>10.
        If a user is interested to learn more about Mendeley or give feedback, who
        should he contact?</strong><br>You can always contact me directly at <a href=\"https://web.archive.org/web/20080920001317/mailto:victor.henning@mendeley.com\"><strong>victor.henning@mendeley.com</strong></a>.
        There is also a Mendeley team blog on which there is plenty of behind-the-scenes
        information<sup><a href=\"https://web.archive.org/web/20080920001317/http://network.nature.com/people/mfenner/blog/2008/09/05/interview-with-victor-henning-from-mendeley#fn13\"><strong>13</strong></a></sup>.
        You can also submit feature requests or bug reports on our homepage (the buttons
        on the top left).</p><p>Victor, thank you very much for giving me this interview.</p><p><sup>1</sup>
        <a href=\"https://web.archive.org/web/20080920001317/http://network.nature.com/blogs/user/U27CE62BB/2008/08/19/how-to-get-scientists-to-adopt-web-2-0-technologies\"><strong>How
        to get scientists to adopt web 2.0 technologies</strong></a></p><p><sup>2</sup>
        <a href=\"https://web.archive.org/web/20080920001317/http://blog.openwetware.org/scienceintheopen/2008/08/06/an-open-letter-to-the-developers-of-social-network-and-%E2%80%98web-20%E2%80%99-tools-for-scientists\"><strong>An
        open letter to the developers of social network and web 2.0 tools for scientists</strong></a></p><p><sup>3</sup>
        <a href=\"https://web.archive.org/web/20080920001317/http://docs.google.com/View?docid=dhs5x5kr_572hccgvcct\"><strong>A
        critical analysis Google Docs</strong></a></p><p><sup>4</sup> <a href=\"https://web.archive.org/web/20080920001317/http://scitechnet.blogspot.com/\"><strong>SciTechNet</strong></a></p><p><sup>5</sup>
        <a href=\"https://web.archive.org/web/20080920001317/http://www.mendeley.com/\"><strong>Mendeley</strong></a></p><p><sup>6</sup>
        <a href=\"https://web.archive.org/web/20080920001317/http://www.mendeley.com/profiles/victor-henning\"><strong>Victor
        Henning\u2019s profile on Mendeley</strong></a></p><p><sup>7</sup> <a href=\"https://web.archive.org/web/20080920001317/http://www.youtube.com/watch?v=UzJbrA9EY7A\"><strong>A
        Last.fm for Research</strong></a></p><p><sup>8</sup> <a href=\"https://web.archive.org/web/20080920001317/http://www.whu.edu/cms/index.php?id=1959&amp;amp;L=1&amp;amp;1354\"><strong>WHU
        Otto Beisheim School of Management</strong></a></p><p><sup>9</sup> <a href=\"https://web.archive.org/web/20080920001317/http://www.science21stcentury.org/\"><strong>Science
        in the 21st Century</strong></a></p><p><sup>10</sup> <a href=\"https://web.archive.org/web/20080920001317/http://www.korova-bar.de/korova/\"><strong>Korova
        Bar</strong></a></p><p><sup>11</sup> <a href=\"https://web.archive.org/web/20080920001317/http://www.mendeley.com/terms/\"><strong>Mendeley
        terms of use</strong></a></p><p><sup>12</sup> <a href=\"https://web.archive.org/web/20080920001317/http://www.nature.com/natureconferences/sciblog2008/index.html\"><strong>Science
        Blogging 2008: London</strong></a></p><p><sup>13</sup> <a href=\"https://web.archive.org/web/20080920001317/http://mekentosj.com/papers/\"><strong>Papers</strong></a></p><p><sup>14</sup>
        <a href=\"https://web.archive.org/web/20080920001317/http://www.mendeley.com/blog\"><strong>Mendeley
        blog</strong></a></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Science blogging is the new email ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/science-blogging-is-the-new-email/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwb6</id>\n        <published>2008-08-31T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-01T05:41:24.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>The just
        finished conference <a href=\"https://web.archive.org/web/20150906080125/http://www.nature.com/natureconferences/sciblog2008/index.html\">Science
        Blogging 2008: London</a> was a wonderful chance for real-life socialising
        networking. I started to upload some fotos to Flickr (e.g. <a href=\"https://web.archive.org/web/20150906080125/http://www.flickr.com/photos/mfenner/2813527160/\">Scott
        Keir explaining sign language</a>, see all fotos tagged <em><em>sciblog</em></em>
        <a href=\"https://web.archive.org/web/20150906080125/http://www.flickr.com/photos/tags/sciblog/\">here</a>),
        some of them are too embarrassing and I will keep them for bribes reference
        later on.</p><p>The meeting was also a great opportunity to think about where
        we are today with scienceblogging. Having a conference is a good sign that
        the field is evolving<sup><a href=\"https://web.archive.org/web/20150906080125/http://blogs.plos.org/mfenner/2008/08/31/science_blogging_is_the_new_email/#fn1\">1</a></sup>,
        and you can see several subdisciplines evolving:</p><ul><li>conference blogging
        (also includes event blogging)</li><li>edublogging</li><li>metablogging (blogging
        about blogging, by far the largest discipline)</li><li>research blogging (blogging
        about scientific experiments, the smallest discipline)</li><li>investigational
        blogging (the keynote lecture by Ben Goldacre described this very well)</li><li>evolution
        blogging (a large subdiscipline)</li><li>news blogging (blogging about science
        news)</li><li>watercooler blogging (small pieces of interesting or funny thoughts/pictures)</li><li>summary
        blogging (summarizing other blog posts and linking to them)</li><li>diary
        blogging (blogging as a personal diary of self-expression)</li><li>hoax blogging
        (see <a href=\"https://web.archive.org/web/20150906080125/http://phylogenomics.blogspot.com/2008/04/confessions-of-april-fool-and-dope-on.html\">this</a>
        example by Jonathan Eisen)</li></ul><p>There is no particular order to this
        list and there are certainly more disciplines and some of the names could
        be catchier. Most bloggers will blog in more than one category. But these
        categories can help to think about what you are doing in your own blogging.
        And it helps when you think about blogrolls or blogging networks such as Nature
        Network or scienceblogs.com. Could we for example see a conference blogging
        network in the future?</p><p>We ended the conference with a challenge to recruit
        more senior faculty for science blogging. Jonathan Eisen is a professor at
        U.C. Davis and might try an April Fools joke again next year, but faculty
        new to blogging will probably be more interested in conference blogging, edublogging
        and research blogging (the boundaries between the three can be blurry). I
        am all for this challenge, as it will move science blogging forward. And next
        week I will meet a department head that wants to start blogging. Maybe we
        can put up another challenge for the next science blogging conference: have
        a <a href=\"https://web.archive.org/web/20150906080125/http://network.nature.com/blogs/user/mfenner/2008/07/12/nobel-blogging\">blogging
        Nobel Prize winner</a> as keynote speaker.</p><p>I finally get to the title
        of this post. Henry Gee made some <a href=\"https://web.archive.org/web/20150906080125/http://network.nature.com/blogs/user/henrygee/2008/08/30/professor-steve-steve-to-claim-political-asylum-shock-horror-probe\">very
        thoughtful comments</a> in the plenary session at the end. Blogging is much
        closer to the informal discussions you have in the hallway or via email than
        it is to peer-reviewed papers. We have to convince faculty members (and other
        people involved in science) that blogging is the new email. Just as email
        was either unknown or looked at in a funny way 20 years ago, blogging will
        become a tool of daily life for most scientists. We can wait until the current
        generation of children and young students is old enough to become faculty
        members themselves, or we can promote the use of science blogging to shorten
        this time.</p><p>fn1. Will we soon have a discussion about starting a journal?</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ London Science Tour in Pictures ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/london-science-tour-in-pictures/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwb5</id>\n        <published>2008-08-29T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-15T14:49:37.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"https://images.unsplash.com/photo-1572299240425-9ecc0a7cb826?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDQ0fHxsb25kb24lMjBhbmQlMjBzY2llbmNlfGVufDB8fHx8MTY2MDU3NDkyNg&amp;ixlib&#x3D;rb-1.2.1&amp;q&#x3D;80&amp;w&#x3D;2000\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://images.unsplash.com/photo-1572299240425-9ecc0a7cb826?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDQ0fHxsb25kb24lMjBhbmQlMjBzY2llbmNlfGVufDB8fHx8MTY2MDU3NDkyNg&amp;ixlib&#x3D;rb-1.2.1&amp;q&#x3D;80&amp;w&#x3D;2000\"></p><p>Pictures
        missing</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Edublogging for beginners ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/edublogging-for-beginners/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwb4</id>\n
        \       <published>2008-08-24T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-31T07:39:41.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>This blog entry is primarily
        intended for science educators that are interested in starting a blog for
        their teaching activities. Some of them will not be familiar with blogging
        and other web 2.0 tools. Not the typical audience of this blog, but I would
        greatly appreciate feedback, as I'm in the process of writing an article about
        this topic (in German).</p><h3 id=\"what-is-blogging-and-all-this-web-2-0-stuff\">What
        is blogging and all this web 2.0 stuff?</h3><p>A good starting point is <a
        href=\"https://web.archive.org/web/20150928190257/http://plcmclearning.blogspot.com/\">Learning
        2.0</a>, a self-learning program originally intended to teach librarians about
        blogs, wikis, <a href=\"https://web.archive.org/web/20150928190257/http://www.flickr.com/\">Flickr</a>,
        RSS, <a href=\"https://web.archive.org/web/20150928190257/http://www.technorati.com/\">Technorati</a>,
        <a href=\"https://web.archive.org/web/20150928190257/http://www.youtube.com/\">YouTube</a>
        and other <a href=\"https://web.archive.org/web/20150928190257/http://en.wikipedia.org/wiki/Web_2.0\">Web
        2.0</a> tools.</p><h3 id=\"why-should-i-start-a-blog\">Why should I start
        a blog?</h3><p>Because a blog could help with teaching students. A blog can
        serve as a simple noticeboard for lecture topics, homework assignments, etc.
        It is also a great place to post additional material. But more importantly,
        students can comment, ask questions or make suggestions. <a href=\"https://web.archive.org/web/20150928190257/http://ncwcbio101.wordpress.com/\">This
        class</a> by Bora Zivkovic is one example. Oliver Obst <a href=\"https://web.archive.org/web/20150928190257/http://www.slideshare.net/obsto/science-blogs-and-online-forums-as-teaching-tools-the-library-view-presentation/\">pointed
        out</a> that blogs (and other online tools) can save time (and money) compared
        to one-by-one interactions in person or via email. The motivation for students
        is nicely explained in <a href=\"https://web.archive.org/web/20150928190257/http://meredith.wolfwater.com/wordpress/2008/08/17/teaching-online-with-drupal/\">this
        blog post</a> by Meredith Farkas: blogging or posting comments on blogs is
        a great way for students to reflect what they have learned and to discuss
        it with fellow students. Tony Griffith recently talked about <a href=\"https://web.archive.org/web/20150928190257/http://www.sciencebridge.net/uploads/akt-ver-attatchments/Griffiths_icg_08.pdf\">why
        do students find genetics so difficult to learn?</a>. He emphasized that students
        typically are not taught the <em><em>research mode</em></em>, where thinking
        and problem-solving are more important than learning facts.</p><h3 id=\"where-do-i-host-the-blog\">Where
        do I host the blog?</h3><p>Most teaching blogs will be hosted at a university
        server. The university IT department will probably offer a blogging platform
        such as <a href=\"https://web.archive.org/web/20150928190257/http://movabletype.org/\">MovableType</a>
        or <a href=\"https://web.archive.org/web/20150928190257/http://wordpress.org/\">WordPress</a>.
        If the university IT department doesn't offer such a service, blogs can also
        be hosted somewhere else. <a href=\"https://web.archive.org/web/20150928190257/http://www.edublogs.org/\">Edublogs</a>,
        <a href=\"https://web.archive.org/web/20150928190257/http://www.21classes.com/\">21classes</a>
        and <a href=\"https://web.archive.org/web/20150928190257/http://www.classblogmeister.com/\">Class
        Blogmeister</a> not only offer blog hosting, but offer additional features
        such as a central portal for all blogs, class blogs, access restricted to
        students, control of student entries.</p><h3 id=\"where-can-i-find-other-people-interested-in-edublogging\">Where
        can I find other people interested in edublogging?</h3><p>Many science bloggers
        are also involved in edublogging, and you find interesting discussions about
        edublogging both here in Nature Network or in many other science blogs (e.g.
        <a href=\"https://web.archive.org/web/20150928190257/http://search.technorati.com/edublog\">here</a>).
        The Edublogs magazine (e.g. <a href=\"https://web.archive.org/web/20150928190257/http://magazine.edublogs.org/2008/01/28/who-are-the-top-edubloggers/\">this
        post</a> on popular edubloggers) is another good starting point.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Science Blogging in German ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/science-blogging-in-german/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwb3</id>\n
        \       <published>2008-08-17T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-15T14:46:06.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Most scientific papers are
        now published in English, and I believe that <a href=\"https://web.archive.org/web/20120611040415/http://network.nature.com/blogs/user/mfenner/2008/01/16/should-all-papers-be-published-in-english\">this
        trend</a> is good for international collaboration. Therefore I believe that
        blogs intended for scientists should also be written in English. The topics
        and discussions in German language science blogs are often similar to what
        we discuss in English, and it makes the audience much smaller if we restrict
        ourselves to a particular language (the same could be said about French, Italian,
        Spanish, Japanese or Chinese blog posts).</p><p>But there are good reasons
        to write German language science blogs, and the German science blogosphere
        is indeed very active. For those understanding German, I've listed some of
        the more popular blogs and blog hostings sites below:</p><ul><li><a href=\"https://web.archive.org/web/20120611040415/http://www.scienceblogs.de/\">ScienceBlogs.de</a>.
        29 blogs from the German language sister of <a href=\"https://web.archive.org/web/20120611040415/http://www.scienceblogs.com/\">ScienceBlogs</a></li><li><a
        href=\"https://web.archive.org/web/20120611040415/http://www.scilogs.de/\">SciLogs</a>
        A collection of science blogs, hosted by publisher <a href=\"https://web.archive.org/web/20120611040415/http://www.spektrumverlag.de/\">Spektrum
        der Wissenschaft</a></li><li><a href=\"https://web.archive.org/web/20120611040415/http://www.academics.de/blog/\">academics.de</a>.
        The blog by the academic job portal</li><li><a href=\"https://web.archive.org/web/20120611040415/http://blog-de.scholarz.net/\">scholarz.blog</a>
        by the social networking site scholarz.net</li><li><a href=\"https://web.archive.org/web/20120611040415/http://www.sciblog.at/\">SciBlog</a>.
        An Austrian blog about science communication</li><li><a href=\"https://web.archive.org/web/20120611040415/http://www.wissenswerkstatt.net/\">Wissenswerkschaft</a>
        by Marc Scheloske</li><li><a href=\"https://web.archive.org/web/20120611040415/http://kamenin.wordpress.com/\">Begrenzte
        Wissenschaft</a> by Sven Ke\xC3\u0178en</li><li><a href=\"https://scilogs.spektrum.de/fischblog/\">Fischblog</a>
        by Lars Fischer</li><li><a href=\"https://www.medinfo-agmb.de/\">medinfo</a>
        by <a href=\"https://web.archive.org/web/20120611040415/http://network.nature.com/profile/obst\">Oliver
        Obst</a></li><li><a href=\"https://infobib.de/\">infob ib</a> by <a href=\"https://web.archive.org/web/20120611040415/http://network.nature.com/profile/U351AAAEA\">Christian
        Hauschke</a> and four other authors.</li></ul> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ We need markup for science blogs ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/we-need-markup-for-science-blogs/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwb2</id>\n        <published>2008-08-11T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-13T13:45:23.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Like many other blogging platforms,
        Nature Network uses <a href=\"https://web.archive.org/web/20120611040405/http://textism.com/tools/textile/\">Textile</a>
        to format blog entries. Textile is a markup language, and Andrew Sun has nicely
        put together the most important tags in <a href=\"https://web.archive.org/web/20120611040405/http://network.nature.com/blogs/user/andrewsun/2007/09/09/textism-a-better-guide-to-formatting-in-nature-network\">this
        blog post</a>.</p><p>Unfortunately, Textile doesn't much help with formatting
        that is specific to science blogging. Specifically, there is no standard way
        to link to journal articles. Should we use the <a href=\"https://web.archive.org/web/20120611040405/http://www.doi.org/\">DOI</a>,
        should we link to <a href=\"https://web.archive.org/web/20120611040405/http://www.pubmed.gov/\">Pubmed</a>,
        or should we link to the journal homepage? If we do the latter, should we
        link to the fulltext (that might not be accessible to everybody) or the abstract?
        And why is there no standard markup for this?</p><p><a href=\"https://web.archive.org/web/20120611040405/http://www.mediawiki.org/\">MediaWiki</a>,
        the platform behind <a href=\"https://web.archive.org/web/20120611040405/http://www.wikipedia.org/\">Wikipedia</a>,
        uses a different markup language. Here, <a href=\"https://web.archive.org/web/20120611040405/http://en.wikipedia.org/wiki/Wikipedia:PMID\">linking
        to PubMed</a> is semiautomated. <a href=\"https://web.archive.org/web/20120611040405/http://de.wikipedia.org/wiki/Vorlage:DOI\">Linking
        to DOIs</a> is also supported. And the <a href=\"https://web.archive.org/web/20120611040405/http://openwetware.org/wiki/Biblio\">Biblio</a>
        extension, also used by <a href=\"https://web.archive.org/web/20120611040405/http://openwetware.org/\">OpenWetWare</a>,
        makes linking to papers even easier.</p><p>We have often talked about standard
        data formats. And the small things also matter. One result of standard blog
        linking to papers: it would become much easier to find all blog posts that
        link to a particular paper.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Looking back on a year of gobbledygook ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/looking-back-on-a-year-of-gobbledygook/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw1p</id>\n        <published>2008-08-03T00:00:00.000+00:00</published>\n\t\t<updated>2023-07-13T11:58:59.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>A year ago today I wrote my
        first blog post on Nature Network (<strong><a href=\"https://doi.org/10.53731/r294649-6f79289-8cw1q\">Open
        access may become mandatory for NIH-funded research</a></strong>). This is
        blog post #84 one year later and a good time to reflect on the experience.
        In May of last year I started the science blog <a href=\"https://web.archive.org/web/20080929033935/http://blog.xartrials.com/\"><strong>in
        a nutshell</strong></a>, hosted on my own server and written just for fun.
        I discovered Nature Network in July and started <strong>Publish or Perish
        2.0</strong>. In November 2007 I <strong><a href=\"https://doi.org/10.53731/r294649-6f79289-8cw99\">changed
        the blog name</a></strong> to <strong>Gobbledygook</strong>.</p><p>I try to
        write about the paper writing process from the perspective of a researcher.
        I\u2019m interested in the technical changes in paper writing thanks to Web
        2.0. Open access is another important topic and the perspective of a researcher
        is obviously very different from a journal publisher, science library, or
        the interested public. I am sometimes not comfortable writing about open access,
        as this is a very political topic and the discussion can move away from arguments
        and into something about doing the right thing. That\u2019s why I would never
        write about Evolution vs. Intelligent Design or some of the other hotly debated
        topics in science blogging.</p><p>The blog post that received the most comments
        is <a href=\"https://doi.org/10.53731/r294649-6f79289-8cw1r\"><strong>My Paper
        Writing Dream Machine 1.0</strong></a>. That was also one of my favorite blog
        posts as I would love to see more of the potential of Web 2.0 technologies
        in our paper writing tools. I also enjoyed the discussion on posters at scientific
        meetings (<strong><a href=\"https://doi.org/10.53731/r294649-6f79289-8cw9x\">Are
        posters worth the effort?</a></strong>) and on blogging from conferences (<strong><a
        href=\"https://doi.org/10.53731/r294649-6f79289-8cwaj\">Scientific meetings
        need more bloggers</a></strong>).</p><p>I participated in a wonderful SynchroBlogging
        effort on April Fools Day (organized by <a href=\"https://web.archive.org/web/20080929033935/http://phylogenomics.blogspot.com/\"><strong>Jonathan
        Eisen</strong></a> and with \u201Chelp\u201D from the <a href=\"https://web.archive.org/web/20080929033935/http://homepage.mac.com/jonathan_eisen/Wabda/Wabda.html\"><strong>World
        Anti-Brain Doping Authority</strong></a>) with <strong><a href=\"https://doi.org/10.53731/c99ks6c-c04z2dh\">What
        can Erythopoetin do for you?</a></strong> I think we should do more SynchroBlogging,
        and not just on April 1st. <strong>Public Access Week</strong> was another
        SynchroBlogging effort and I learned a lot about access to my own papers in
        <strong><a href=\"https://doi.org/10.53731/r294649-6f79289-8cwa9\">Public
        Access Week: Who could read my papers?</a></strong></p><p>Only two blog posts
        are about scientific research. <a href=\"https://doi.org/10.53731/r294649-6f79289-8cw9r\"><strong>Using
        RNAinterference to identify genes that protect from cancer</strong></a> was
        my contribution to <strong><a href=\"https://web.archive.org/web/20080929033935/http://www.justscience.net/2008/?page_id=1368\">Just
        Science 2008</a></strong>. In <strong><a href=\"https://doi.org/10.53731/r294649-6f79289-8cwav\">Mouse
        models of human cancer and the need for more translational research</a></strong>,
        I wrote about a presentation by Mario Capecchi at the International Genetics
        Conference. I would love to do more <strong><a href=\"https://web.archive.org/web/20080929033935/http://www.researchblogging.org/index.php\">ResearchBlogging</a></strong>,
        but I think that we have to wait a few more years before science blogging
        has attracted enough people that read and comment on specific research findings.</p><p>Thanks
        to this blog I have met a number of very interesting and intelligent people
        with similar interests (see <strong><a href=\"https://web.archive.org/web/20080929033935/http://scienceblogs.com/clock/2008/05/eurotrip_08_berlin_part_iii_we.php\">this
        blog entry</a></strong> by Bora Zivkovic and <strong><a href=\"https://web.archive.org/web/20080929033935/http://network.nature.com/london/news/blog/matt/2008/07/12/dinner-with-the-nobel-prize-winners\">this
        blog entry</a></strong> by Matt Brown). That\u2019s why I\u2019m very much
        looking forward to the <strong><a href=\"https://web.archive.org/web/20080929033935/http://www.nature.com/natureconferences/sciblog2008/index.html\">Science
        Blogging 2008: London</a></strong> conference at the end of this month. My
        goal for the next year is help to make reading and writing science blogs part
        of everyday life at more universities and research institutions.</p><h3 id=\"references\">References</h3><p>Fenner
        M. Open access may become mandatory for NIH-funded research. Published online
        August 3, 2007. doi:<a href=\"https://doi.org/10.53731/r294649-6f79289-8cw1q\">10.53731/r294649-6f79289-8cw1q</a></p><p>Fenner
        M. A case for Goobledygook. Published online November 11, 2007. doi:<a href=\"https://doi.org/10.53731/r294649-6f79289-8cw99\">10.53731/r294649-6f79289-8cw99</a></p><p>Fenner
        M. My Paper Writing Dream Machine 1.0. Published online June 14, 2008. doi:<a
        href=\"https://doi.org/10.53731/r294649-6f79289-8cw1r\">10.53731/r294649-6f79289-8cw1r</a></p><p>Fenner
        M. Are posters worth the effort? Published online March 1, 2008. doi:<a href=\"https://doi.org/10.53731/r294649-6f79289-8cw9x\">10.53731/r294649-6f79289-8cw9x</a></p><p>Fenner
        M. Scientific meetings need more bloggers. Published online May 17, 2008.
        doi:<a href=\"https://doi.org/10.53731/r294649-6f79289-8cwaj\">10.53731/r294649-6f79289-8cwaj</a></p><p>Fenner
        M. What can Erythopoetin do for you? Published online April 1, 2008. doi:<a
        href=\"https://doi.org/10.53731/c99ks6c-c04z2dh\">10.53731/c99ks6c-c04z2dh</a></p><p>Fenner
        M. Public Access Week: Who could read my papers? Published online April 11,
        2008. doi:<a href=\"https://doi.org/10.53731/r294649-6f79289-8cwa9\">10.53731/r294649-6f79289-8cwa9</a></p><p>Fenner
        M. Using RNA interference to identify genes that protect from cancer. Published
        online February 7, 2008. doi:<a href=\"https://doi.org/10.53731/r294649-6f79289-8cw9r\">10.53731/r294649-6f79289-8cw9r</a></p><p>Fenner
        M. Mouse models of human cancer and the need for more translational research.
        Published online July 14, 2008. doi:<a href=\"https://doi.org/10.53731/r294649-6f79289-8cwav\">10.53731/r294649-6f79289-8cwav</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ FDAAA: Push to open data in clinical medicine
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/fdaaa-push-to-open-data-in-clinical-medicine/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwb1</id>\n        <published>2008-08-02T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-31T07:37:05.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>In 2005 registration of clinical
        trials in publicly available databases before the first patient was entered
        became <a href=\"https://web.archive.org/web/20120611042509/http://www.icmje.org/clin_trial.pdf\">mandatory</a>
        for papers submitted to the most important medical journals. In September
        of last year, U.S. President Bush signed the Federal Drug Administration Amendment
        Act (FDAAA) into law. Starting September 2008, all clinical trials registered
        in the <a href=\"https://web.archive.org/web/20120611042509/http://www.clinicaltrials.gov/\">clinicaltrials.gov</a>
        database (with the exception of phase I trials) have to report key results
        of the main outcomes no later than 12 months after data for the last subject
        were received.</p><p>This required reporting of results has so far largely
        gone unnoticed in the medical community, but will dramatically change the
        way research involving patients is conducted and reported. The 12 month deadline
        will probably lead to earlier reporting of many trial results, and not publishing
        negative results will be much more difficult. The required reporting in a
        standardized format will also facilitate the meta-analysis of several similar
        trials.</p><p>Reporting of trial results in this format <a href=\"https://web.archive.org/web/20120611042509/http://www.bmj.com/cgi/content/full/334/7605/1177\">will
        not be considered previous publication</a> by member journals of The Internal
        Committee of Medical Journal Editors (ICMJE).</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Article downloads and citations of open
        access papers ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/article-downloads-and-citations-of-open-access-papers/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwb0</id>\n        <published>2008-08-01T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-31T07:35:56.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>The <em><em>British Medical
        Journal</em></em> this week published <a href=\"https://web.archive.org/web/20120611040451/http://www.bmj.com/cgi/content/full/337/jul31_1/a568\">Open
        access publishing, article downloads, and citations: randomised controlled
        trial</a> by Phlip Davis et al. There are already <a href=\"https://web.archive.org/web/20120611040451/http://biology.plosjournals.org/perlserv/?request=get-document&amp;doi=10.1371%2Fjournal.pbio.0040157\">several
        publications</a> that looked at the full paper downloads and citations of
        open access papers compared to closed access papers. But this is the first
        prospectively randomized study, thus avoiding some of the typical problems
        of retrospective evaluations (e.g. that important papers are more likely to
        have free access).</p><p>Articles published in 11 <a href=\"https://web.archive.org/web/20120611040451/http://www.the-aps.org/\">American
        Physiological Society</a> journals between January and April 2007 were randomly
        (1 out of 7) made open access at the time of publication. Full text viewing,
        PDF downloads and citations were measured over a 12 month period. The authors
        found a significant increase in readership (full text HTML and PDF) but no
        difference in citation rates.</p><p>There are plausible arguments why citation
        rates weren't different between the two groups. Most researchers that cite
        APS papers in their own publications will have institutional access to these
        journals. But citation rates of open access papers are a political topic,
        that's why we already have a number of reactions from the blogosphere (e.g.
        from <a href=\"https://web.archive.org/web/20120611040451/http://scholarlykitchen.sspnet.org/2008/07/31/open-access-doesnt-drive-citations/\">The
        Scholarly Kitchen</a>, <a href=\"https://web.archive.org/web/20120611040451/http://openaccess.eprints.org/index.php?%2Farchives%2F441-Davis-et-als-1-year-Study-of-Self-Selection-Bias-No-Self-Archiving-Control%2C-No-OA-Effect%2C-No-Conclusion.html\">Stevan
        Harnard</a> and <a href=\"https://web.archive.org/web/20120611040451/http://gunther-eysenbach.blogspot.com/\">Gunther
        Eysenbach</a>). There are also some <a href=\"https://web.archive.org/web/20120611040451/http://www.bmj.com/cgi/eletters/337/jul31_1/a568\">direct
        responses</a> to the paper at the BMJ website. The main criticism of the paper
        is the short time of 12 months to look at the citation rate. The citations
        will increase in the next few years, but because all papers from APS journals
        are made available as full text after 12 months, there will be no longer a
        difference in access to the two groups of papers.</p><p>What surprised me
        post about the paper is the journal. I would have expected that it would appear
        in an APS journal, but a medical journal? The <a href=\"https://web.archive.org/web/20120611040451/http://www.bmj.com/cgi/content/extract/337/jul31_1/a1051\">editorial</a>
        explains the reasoning behind it. Like many other journals, the BMJ is trying
        out new access models. All research papers (but not the other content, including
        the editorial) in the BMJ are open access. And as Fiona Godlee in the editorial
        puts it:</p><blockquote><em><em>Academic publishing is going through interesting
        times. We don</em>'<em>t know which model will prevail, or indeed whether
        there will ultimately be one or several coexisting models.</em></em></blockquote>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ First authorship by women in a German medical
        journal ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/first-authorship-by-women-in-a-german-medical-journal/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwaz</id>\n        <published>2008-07-27T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-31T07:34:59.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>The German medical journal
        <em><em>Deutsches </em>\xC4<em>rzteblatt</em></em> did an analysis of the
        <a href=\"https://web.archive.org/web/20120611085236/http://www.aerzteblatt.de/int/article.asp?id=60949\">percentage
        of female first authors over the last 50 years</a>. The number was 0-4% as
        recently as 25 years ago, but there has been a yearly increase to 18% last
        year (see this <a href=\"https://web.archive.org/web/20120611085236/http://www.aerzteblatt.de/int/bild.asp?id=24380\">figure</a>),
        both for submitted and accepted manuscripts. This number corresponds to the
        percentage of female senior faculty in Germany, but 64% of students starting
        to study medicine last year were women. A similar increase \u2013 although
        to higher numbers \u2013 has been seen in biology (see <a href=\"https://web.archive.org/web/20120611085236/http://dx.doi.org/10.1002/ajhb.10160\">this
        study</a>).</p><p>These numbers seem to indicate that women are neither less
        likely nor more likely to have a manuscript accepted. Unless you assume that
        women are more often denied first authorship than men. But I was surprised
        to learn how little progress had been made between 1957 and 1982. <a href=\"https://web.archive.org/web/20120611085236/http://content.nejm.org/cgi/content/full/355/3/281\">This
        study</a> of female first and senior authorship in American medical journals
        probably gives the explanation. The numbers of female medical students didn't
        start to rise until the 1970s, and they probably started to write their first
        papers about ten years later. Which would mean that in another 25 years female
        first and senior authors in medical journals should be as common as their
        male colleagues. Isn't that a bit long in the future?</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Edublogging at Science Blogging 2008: London
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/edublogging-at-science-blogging-2008-london/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cway</id>\n        <published>2008-07-24T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-29T10:12:03.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/DALL-E-2022-08-29-12.09.11---Alfred-Sisley-oil-painting-of-a-garden-gnome-with-an-umbrella-in-front-of-Westminster-cathedral-on-a-winter-morning.png\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/DALL-E-2022-08-29-12.09.11---Alfred-Sisley-oil-painting-of-a-garden-gnome-with-an-umbrella-in-front-of-Westminster-cathedral-on-a-winter-morning.png\"></p><p>The
        <a href=\"https://web.archive.org/web/20120611085429/http://www.nature.com/natureconferences/sciblog2008/index.html\">Science
        Blogging 2008: London</a> conference will highlight the wide variety of science
        blogging that has evolved in recent years. I haven't seen anybody trying to
        create formal categories, but I see <em><em>research blogging</em></em>, <em><em>conference
        blogging</em></em>, <em><em>watercooler blogging</em></em>, <em><em>comic
        strip blogging</em></em> \u2013 and <em><em>edublogging</em></em>. Breakout
        session 5 of the conference is called <em><em>Science blogs and online forums
        as teaching tools</em></em>. <a href=\"https://web.archive.org/web/20120611085429/http://medinfo.netbib.de/\">Oliver
        Obst</a>, <a href=\"https://web.archive.org/web/20120611085429/http://network.nature.com/blogs/user/jeffmarlow\">Jeff
        Marlow</a> and myself will try to organize an interesting panel discussion
        on the topic. Edublogging covers a wide range of topics, as you can guess
        when looking at these (random) science education blogs:</p><ul><li><a href=\"https://web.archive.org/web/20120611085429/http://sciencegeekgirl.wordpress.com/\">Sciencegeekgirl</a></li><li><a
        href=\"https://web.archive.org/web/20120611085429/http://www.stevespangler.com/\">Steve
        Spangler</a></li><li><a href=\"https://web.archive.org/web/20120611085429/http://blog.makezine.com/\">MAKE:
        Blog</a></li><li><a href=\"https://web.archive.org/web/20120611085429/http://micropopbio.org/\">Microbial
        Population Biology</a></li></ul><p>The last blog is especially interesting.
        It is hosted by <a href=\"https://web.archive.org/web/20120611085429/http://edublogs.org/\">Edublogs</a>.
        They not only provide a hosting platform for teacher and student blogs, but
        also offer special features that are especially useful for educational blogging,
        e.g. managing and aggregating student blogs and sharing material.</p><p>My
        interest in this topic started when we began the <a href=\"https://web.archive.org/web/20120611085429/http://network.nature.com/group/goodpaper\">Good
        Paper Journal Club</a> here on Nature Network. Some questions I would like
        to address in the session include:</p><ul><li>How are educators (professors,
        teachers, etc.) using blogs?</li><li>How are students using blogs?</li><li>How
        are science libraries using blogs?</li><li>Are there special features required
        for edublogging, e.g. team blogs, restricted access, sharing of documents?</li><li>Do
        university administrators facilitate blogging on education?</li></ul><p>Please
        leave your comments either here or in the <a href=\"https://web.archive.org/web/20120611085429/http://network.nature.com/forums/sciblog2008/2105\">Science
        Blogging 2008: London</a> forum.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Do online journals narrow science and scholarship?
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/do-online-journals-narrow-science-and-scholarship/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwax</id>\n        <published>2008-07-19T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-31T07:33:59.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>James Evans, a sociologist
        from the University of Chicago, <a href=\"https://web.archive.org/web/20120611091345/http://dx.doi.org/10.1126/science.1150473\">reports</a>
        his research on the kind and frequency of citations over the last 60 years
        in the latest issue of <em><em>Science</em></em>. He found a change in citation
        behavior as more and more journals became electronically available: fewer
        journals and articles were cited and the cited articles were more recent.</p><p>These
        findings seem to contradict our expectations (and <a href=\"https://web.archive.org/web/20120611091345/http://www.sciencemag.org/cgi/doi/10.1126/science.321.5887.329a\">research
        by other groups</a>). The greater availability of research papers in recent
        years thanks to electronic publication (and open access) should broaden and
        not narrow the papers that we read and ultimately cite in our own publications.
        But looking at my own behavior when reading papers or writing a publication,
        and thinking about many discussions we had on related topics, these findings
        make perfect sense.</p><p>Today's technology allows us to make the distribution
        of scientific papers in electronic form very efficient, and thanks to this
        technology we have new business models (author-pays) and an ever-increasing
        number of journals. Access to research articles is now easier, cheaper and
        for a broader audience than in ever was before. This is of course a wonderful
        development, but unfortunately creates a new problem: <em><em>information
        overflow</em></em> and how to filter out the relevant information.</p><p>Twenty
        years ago the typical researcher would use the personal or institutional journal
        subscription to regularly follow the important papers in his field. <em><em>Index
        Medicus</em></em> and <em><em>Current Contents</em></em> were used to find
        additional articles, but they were cumbersome to use. Today few researchers
        regularly read printed journals. Most papers are found by searches of online
        databases and by subscriptions of tables of content by email or RSS. There
        are many clever tools to facilitate this, but most people probably are overwhelmed
        by the information and stick to some very specific research interests and
        high-profile journals.</p><p>This is where the filtering of information becomes
        critical. Technology can help a great deal in finding the most relevant research
        papers, but I would argue that human intervention is still far more important.
        For most people including myself peer review is the first step in that filtering
        process. Connected to peer review is the editorial decision that something
        is not only scientifically sound but also interesting. This editorial decision
        is sometimes debatable but is a very effective filtering process. Post-publication
        filtering by human intervention in the form of comments, voting or paid services
        (e.g. <a href=\"https://web.archive.org/web/20120611091345/http://www.f1000biology.com/\">Faculty
        of 1000 Biology</a>) is still in its infancy.</p><p>I am hoping for better
        filtering tools in the future, both pre- and post-publication. I'm confident
        that technology can be a big help (especially when full-text searching takes
        off), but will never replace human editing. Until then, maybe we should kep
        at least some important print subscriptions so that we don't miss that fascinating
        research paper that for some reason wasn't picked up by that fancy electronic
        tool.</p><p>David Crotty (in his highly recommended blog <em><em>Bench Marks</em></em>)
        also <a href=\"https://web.archive.org/web/20120611091345/http://www.cshblogs.org/cshprotocols/2008/07/18/scientific-citations-and-the-alleged-death-of-the-long-tail/\">blogged
        about this topic</a>. Philip Davis also <a href=\"https://web.archive.org/web/20120611091345/http://scholarlykitchen.sspnet.org/2008/07/18/online-journal-paradox/\">wrote
        about</a> the <em><em>Science</em></em> article on <em><em>the scholarly kitchen</em></em>
        blog. And Thomas Lemberger <a href=\"https://web.archive.org/web/20120611091345/http://blog-msb.embo.org/blog/2008/07/impact_of_online_publishing.html\">blogged
        about the article</a> on <em><em>The Seven Stones</em></em>.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Why is genetics so difficult for students
        to learn? ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/why-is-genetics-so-difficult-for-students-to-learn/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwaw</id>\n        <published>2008-07-15T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-01T05:37:57.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>This Sunday
        morning at the <a href=\"https://web.archive.org/web/20120611091404/http://www.geneticsberlin2008.com/\">International
        Congress of Genetics</a>, <a href=\"https://web.archive.org/web/20120611091404/http://www.botany.ubc.ca/people/griffith.htm\">Tony
        Griffiths</a> gave an interesting presentation with the above title. He identified
        12 possible reasons why students have problems learning genetics. His main
        argument: students should learn concepts and principles and apply them creatively
        in novel situations (the <em><em>research mode</em></em>). Instead, too many
        details are often crammed into seminars and textbooks. In other words, students
        often stay at the lowest level of <a href=\"https://web.archive.org/web/20120611091404/http://projects.coe.uga.edu/epltt/index.php?title=Bloom%27s_Taxonomy\">Bloom's
        taxonomy</a>, the remembering of knowledge. The highest level, the creation
        of new knowledge, is seldom reached, although these skills are of course critical
        for a successful researcher.</p><p>Andrew Moore from <a href=\"https://web.archive.org/web/20120611091404/http://www.embo.org/scisoc/index.html\">EMBO</a>
        talked about the teaching of genetics in the classroom. He was concerned that
        a survey found that molecular evolution (or molecular phylogeny) was taught
        in not more than 30% of European classrooms. He gave some examples of how
        principles of genetics can be integrated into high school teaching.</p><p>Wolfgang
        Nellen explained his successful <a href=\"https://web.archive.org/web/20120611091404/http://www.siriuswork.de/sciencebridge.net/tmp/\">Science
        Bridge</a> project of teaching genetics in the classroom, using biology students
        as teachers. Interestingly, they have not only taught high school students,
        but also journalists and \u2013 priests (German language link <a href=\"https://web.archive.org/web/20120611091404/http://www.sueddeutsche.de/wissen/artikel/770/134514/\">here</a>).
        Politicians were the only group of people that weren't interested in his offer
        of a basic science course.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Mouse models of human cancer and the need
        for more translational research ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/mouse-models-of-human-cancer-and-the-need-for-more-translational-research/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwav</id>\n        <published>2008-07-14T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-01T05:36:28.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>One of the
        opening lectures this Saturday of the <a href=\"https://web.archive.org/web/20120611091608/http://www.geneticsberlin2008.com/\">International
        Congress of Genetics</a> was held by <a href=\"https://web.archive.org/web/20120611091608/http://capecchi.genetics.utah.edu/\">Mario
        Capecchi</a>. His talked was entitled <em><em>Modeling human disease in the
        mouse: from cancer to neuropsychiatric disorders</em></em>. In the first half
        he described his mouse model of synovial sarcoma. Synovial sarcoma is an aggressive
        and often fatal soft tissue tumor. The pathogenesis of the disease is poorly
        understood, but synovial sarcoma is characterized by a t(X;18) translocation
        that creates a fusion of the SYT and SSX (SSX1, SX2 or SSX4) genes.</p><p>Early
        and ubiquitous expression of a SYT-SSX transgene is lethal in the mouse embryo,
        so Mario Capecchi's group created a mouse that expresses the fusion gene only
        at specific timepoints and only in skeletal muscle. Practically all mice develop
        tumors that resemble synovial sarcoma in human. This mouse model provides
        an attractive preclinical platform for new treatment strategies. Those interested
        in the full story can read the Cancer Cell paper (Haldar 2007) that was published
        last year.</p><p>Everybody has a different reason to be interested in research.
        It can be the curiousity to better understand a fundamental process, It can
        be the wish to create a business opportunity. It can be the determination
        to do something about climate change or poverty. Or it can be the desire to
        better help a patient with a disease that is difficult or impossible to treat.
        I trained as a medical doctor and currently spend most of my time treating
        patients with cancer. Just last week I was seeing a young patient with synovial
        sarcoma and lung metastasis. Understanding the biology of cancer is essential
        to find better treatment strategies and we have witnessed many <a href=\"https://web.archive.org/web/20120611091608/http://en.wikipedia.org/wiki/Imatinib\">positive
        examples</a> for this.</p><p>This so-called translational research is unfortunately
        a wonderful concept that more often than not doesn't work in practice. Basic
        science often is poorly connected to clinical medicine, both on a personal
        and institutional level. But change is apparently underway, if you believe
        <a href=\"https://web.archive.org/web/20120611091608/http://www.nature.com/nature/journal/v453/n7197/index.html\">the
        cover story</a> of the June 12 issue of Nature.</p><h3 id=\"references\">References</h3><p>M
        HALDAR, J HANCOCK, C COFFIN, S LESSNICK, M CAPECCHI (2007). A Conditional
        Mouse Model of Synovial Sarcoma: Insights into a Myogenic Origin <em>Cancer
        Cell, 11</em> (4), 375-388 https://doi.org/<a href=\"https://web.archive.org/web/20120611091608/http://dx.doi.org/10.1016/j.ccr.2007.01.016\">10.1016/j.ccr.2007.01.016</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ In which I became a conference blogger ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/in-which-i-became-a-conference-blogger/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwat</id>\n        <published>2008-07-13T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-01T05:35:29.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>The 20th
        <a href=\"https://web.archive.org/web/20120611091433/http://www.geneticsberlin2008.com/\">International
        Congress of Genetics</a> started in Berlin yesterday. This is the first time
        that I attend a meeting as a science blogger. An interesting experience since
        you look at the talks from a different perspective and you have to try to
        cover topics that are of general interest but often not really your area of
        expertise.</p><p>The conference started yesterday afternoon with a press conference
        with Rudi Balling, Alfred Nordheim, Mario Capecchi, Christiane N\xFCsslein-Volhard,
        Oliver Smithies and Ernst-Ludwig Winnacker. The International Congress of
        Genetics takes place every 5 years, but wasn't held in Germany since 1927.
        The main reason for this is the horrible crimes that were done between 1933
        and 1945 in the name of \u201CEugenics\u201D [1]. This dark history of Genetics
        in Germany was also discussed at the press conference. On July 14 there will
        be a special announcement by the German Society for Human Genetics (<a href=\"https://web.archive.org/web/20120611091433/http://www.gfhev.de/en/index.htm\">GfH</a>),
        as this is the 75th anniversary of a German law that allowed the sterilization
        of people with \u201Cgenetic\u201D diseases against their will. The GfH will
        say that they deeply regret the behavior of German geneticists during that
        time. This is a topic that has special meaning to me, since one of the leading
        German geneticists involved was <a href=\"https://web.archive.org/web/20120611091433/http://en.wikipedia.org/wiki/Otmar_Freiherr_von_Verschuer\">Ottmar
        von Verschuer</a> who is a cousin of my great-grandmother. The German Research
        Foundation (DFG) did <a href=\"https://web.archive.org/web/20120611091433/http://www.mpiwg-berlin.mpg.de/KWG/guests_e.htm\">extensive
        research</a> on the involvement of the Kaiser-Wilhelm Society (which became
        the DFG after 1945) in the crimes committed between 1933 and 1945 in the beginning
        of this century (see this <a href=\"https://web.archive.org/web/20120611091433/http://www.nature.com/nature/journal/v425/n6959/full/425650b.html\">Nature
        News</a> article).</p><p>Another topic debated in the press conference was
        the use of genetics to treat patients, more specifically gene therapy and
        stem cells. Mario Capecchi and others stressed that ethical decisions on these
        issues should be done by society and that the scientists would only provide
        the tools. Oliver Smithies pointed out that we should make the clear distinction
        between somatic gene therapy and gene therapy targeting the germline, and
        that the latter approach would be not only risky but in most cases uneccessary.</p><p>The
        expectations for the conference were nicely summarized by Oliver Smithies,
        who said that science happens in unexpected jumps, and that these jumps are
        often produced by people from whom you don't expect it.</p><p>fn1. I previously
        blogged about how the journal Nature <a href=\"https://web.archive.org/web/20120611091433/http://network.nature.com/blogs/user/mfenner/2007/10/23/nature-in-nazi-germany-70-years-ago-no-open-access\">was
        banned</a> in Germany 70 years ago.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Nobel blogging? ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/nobel-blogging/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwas</id>\n        <published>2008-07-12T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-01T05:34:40.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Last night
        we had the first in a series of <a href=\"https://web.archive.org/web/20120611091423/http://network.nature.com/group/berlin\">Nature
        Network Berlin</a> dinners scheduled around the International Congress of
        Genetics. It was a very entertaining evening, not least because of our special
        guests <a href=\"https://web.archive.org/web/20120611091423/http://www.pathology.unc.edu/common/smithies.htm\">Oliver
        Smithies</a>, <a href=\"https://web.archive.org/web/20120611091423/http://capecchi.genetics.utah.edu/\">Mario
        Capecchi</a> (both 2007 Nobel laureates) and Matt Brown (<a href=\"https://web.archive.org/web/20120611091423/http://network.nature.com/london/news/blog/matt/2008/07/10/medley-of-medals-for-london-scientists\">Nature
        Network London Editor of the Year</a>). Just one of the many stories was by
        Oliver Smithies, who told us how he constructed a PCR machine after listening
        to a talk by G. Mullis \u2013 way before commercial Taq polymerase and PCR
        machines. And that machine is still running.</p><p>You could argue that surprisingly
        few people showed up for this event, including only four PhD students. But
        I don't worry too much about this, because increasing the awareness for these
        events takes time. But I wonder whether we could do better to disseminate
        the knowledge and life experience of these accomplished scientists. Time and
        travel costs allow only relatively few people to listen to keynote lectures
        or take part in a networking dinner.</p><p>The solution is obvious: we have
        to convince our Nobel laureates to become science bloggers. In many ways they
        are the perfect bloggers. Most of them probably don't know yet about science
        blogging, and some of them will need help with the technology. And perhaps
        only a few will be interested. But with a little help this could turn out
        very well. And we would have good company for <a href=\"https://web.archive.org/web/20120611091423/http://network.nature.com/profile/charlesdarwin\">Charles
        Darwin</a>.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ I will participate in the Elsevier Article
        2.0 Contest ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/i-will-participate-in-the-elsevier-article-2-0-contest/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwar</id>\n        <published>2008-06-30T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-03T05:13:12.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>We have been talking a lot
        about Web 2.0 approaches for scientific papers. Now Elsevier announced an
        <a href=\"https://web.archive.org/web/20120611092506/http://article20.elsevier.com/contest/home.htm\">Article
        2.0 Contest</a>:</p><p><em><em>Demonstrate your best ideas for how scientific
        research articles should be presented on the web and compete to win great
        prizes!</em></em></p><p>The contest runs from September 1st until December
        31st. Elsevier will provide 7.500 full text articles in XML format (through
        a <a href=\"https://web.archive.org/web/20120611092506/http://en.wikipedia.org/wiki/Representational_State_Transfer\">REST</a>
        API). The contestants that creates the best article presentation (creativity,
        value-add, ease of use and quality) will win prizes.</p><p>This is a very
        interesting contest, and I plan to participate. I do know enough about programming
        web pages that I can create something useful in four months. My development
        platform of choice is <a href=\"https://web.archive.org/web/20120611092506/http://www.rubyonrails.org/\">Ruby
        on Rails</a> and Rails has great REST support. I will use the next two months
        before the contest starts to think about the features I want to implement.</p><p>I'm
        sure that other people are also considering to participate in this contest
        or would like to make suggestions for features. Please contact me by commenting
        or via Email or <a href=\"https://web.archive.org/web/20120611092506/http://friendfeed.com/mfenner\">FriendFeed</a>.
        A great opportunity to not only talk about Science 2.0, but actually do something
        about it.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Online reference managers: not quite there
        yet ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/online-reference-managers-not-quite-there-yet/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwaq</id>\n        <published>2008-06-23T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-13T13:43:11.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>For my <a href=\"https://web.archive.org/web/20120611092952/http://network.nature.com/blogs/user/mfenner/2008/06/14/my-paper-writing-dream-machine-1-0\">Paper
        Writing Dream Machine</a> I obviously need a reference manager. My list of
        required features includes:</p><ul><li>Easy addition of references by integration
        with Pubmed, Google Scholar and other online databases. A special bookmarklet
        would be a bonus.</li><li>Commenting on references, e.g. custom tags or free-form
        text</li><li>Creation of reference lists, e.g. by tags</li><li>Sharing of
        reference lists to user-defined groups or to everybody</li><li>Integration
        of the references into your word processor of choice. An export function into
        a common format such as .ris is a minimum. A better solution would be an open
        programming interface (API).</li></ul><p>For obvious reasons (sharing references
        with your coauthors) an online reference manager is the easiest way to accomplish
        these feature requests.</p><h3 id=\"connotea\"><a href=\"https://web.archive.org/web/20120611092952/http://www.connotea.com/\">Connotea</a></h3><p>You
        import references into Connotea via bookmarklet or by entering the DOI. A
        direct query of Pubmed is not possible. References can be tagged and commented
        on. Unfortunately it is not possible to create a reference list for a particular
        paper that is only seen by your coauthors (Connotea groups are all or nothing).
        References can be exported into common formats, but no direct word processor
        integration. A Connotea Web API is <a href=\"https://web.archive.org/web/20120611092952/http://www.connotea.org/wiki/WebAPI\">available</a>.</p><h3
        id=\"citeulike\"><a href=\"https://web.archive.org/web/20120611092952/http://www.citeulike.org/\">CiteULike</a></h3><p>CiteULike
        is very similar in features to Connotea. The same limitations (no private
        group for reference list, no word processor integration) also apply.</p><h3
        id=\"2collab\"><a href=\"https://web.archive.org/web/20120611092952/http://www.2collab.com/\">2collab</a></h3><p>A
        newer service created by Elsevier. Again similar in features to CiteULike
        and Connotea. Private groups for your coauthors to share a reference list
        are supported. No direct word processor integration. 2collab has a public
        API.</p><h3 id=\"refworks\"><a href=\"https://web.archive.org/web/20120611092952/http://www.refworks.com/\">RefWorks</a></h3><p>In
        contrast to Connotea and CiteULike this is a commercial product (our university
        has a subscription). Again no direct integration with Pubmed (only copy and
        paste), but a bookmarklet. And again difficulties to create a list of references
        that is visible just to your coauthors. Write-n-Cite is a RefWorks plugin
        for Microsoft Word. No API.</p><h3 id=\"endnote-web\"><a href=\"https://web.archive.org/web/20120611092952/http://www.endnoteweb.com/enwebinfo.asp\">EndNote
        Web</a></h3><p>EndNote Web is promoted as a sort of Endnote Lite, i.e. a web-based
        tool with just the basic features of the commercial desktop application. Again
        no direct Pubmed Search, but integration with <a href=\"https://web.archive.org/web/20120611092952/http://isiknowledge.com/\">Web
        of Science</a> (just like Endnote a product from Thomson Scientific). Sharing
        of reference lists to just your coauthors is possible. Endnote Web comes with
        a Microsoft Word plugin for ease paper writing.</p><p>With the exception of
        Connotea and 2collab, all the systems mentioned above allow you to store the
        full-text PDF. This is a handy feature, but online storing of creates copyright
        issues for papers that are not public access.</p><p><a href=\"https://web.archive.org/web/20120611092952/http://www.zotero.org/\">Zotero</a>,
        a Firefox extension, is not on this list, because references are stored locally
        and cannot easily be shared with others.</p><p>Surprisingly, none of the tools
        supports all my requirements. Endnote Web comes closest, but is far from perfect
        (e.g. sometimes slow, also needs Web of Science). Is it so difficult to build
        a Pubmed query function and group reference list into the tools?</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ My Paper Writing Dream Machine 1.0 ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/my-paper-writing-dream-machine-1-0/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw1r</id>\n        <published>2008-06-14T14:41:00.000+00:00</published>\n\t\t<updated>2022-08-03T05:04:18.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>I\u2019ve written a similar
        post <a href=\"https://web.archive.org/web/20081014105337/http://network.nature.com/blogs/user/mfenner/2008/03/31/pubmed-and-other-annoyances-in-the-paper-writing-process\"><strong>before</strong></a>,
        put I would like to talk about some of the features that I would like to see
        in an ideal paper writing application.</p><p><strong>Intelligent Formatting</strong><br>Content
        and formatting should be separated from each other. A manuscript should require
        as little formatting as possible, and that formatting (including the format
        of references) should be defined in a Journal style that is automatically
        applied to the manuscript. <a href=\"https://web.archive.org/web/20081014105337/http://www.wolfram.com/products/publicon/index.html\"><strong>Publicon</strong></a>
        by Wolfram Research tried to achieve this, but unfortunately appears to be
        a dead product.</p><p><strong>References</strong><br>A reference database
        should be integrated into the paper writing application. Ideally this would
        be a web-based database such as <a href=\"https://web.archive.org/web/20081014105337/http://www.connotea.org/\"><strong>Connotea</strong></a>,
        <a href=\"https://web.archive.org/web/20081014105337/http://www.citeulike.org/\"><strong>CiteULike</strong></a>.
        Both <a href=\"https://web.archive.org/web/20081014105337/http://www.refworks.com/\"><strong>Refworks</strong></a>
        and <a href=\"https://web.archive.org/web/20081014105337/http://www.endnoteweb.com/enwebinfo.asp\"><strong>EndNote
        Web</strong></a> already offer some level of integration.</p><p><strong>Versioning</strong><br>Storing
        all versions of a manuscript is very important for obvious reasons: backup,
        keeping track of revisions and coordinating the input from more than one author.
        Version control is standard practice in software development, using tools
        like <a href=\"https://web.archive.org/web/20081014105337/http://subversion.tigris.org/\"><strong>Subversion</strong></a>
        or the newer <a href=\"https://web.archive.org/web/20081014105337/http://git.or.cz/index.html\"><strong>Git</strong></a>.</p><p><strong>Integration
        with Online Submission Systems</strong><br>Submitting a manuscript to an online
        manuscript submission system such as <a href=\"https://web.archive.org/web/20081014105337/http://www.editorialmanager.com/homepage/home.htm\"><strong>EditorialManager</strong></a>
        or <a href=\"https://web.archive.org/web/20081014105337/http://www.topazproject.org/trac/\"><strong>Topaz</strong></a>
        is too complicated. This process could and should be automated.</p><p><strong>Summary</strong><br>My
        Paper Writing Dream Machine will in all likelihood turn out to be a web-based
        application, using on one of the more advanced platforms <a href=\"https://web.archive.org/web/20081014105337/http://gears.google.com/\"><strong>Google
        Gears</strong></a>, <a href=\"https://web.archive.org/web/20081014105337/http://silverlight.net/\"><strong>Microsoft
        Silverlight</strong></a> or <a href=\"https://web.archive.org/web/20081014105337/http://www.adobe.com/de/products/flex/\"><strong>Adobe
        Flex</strong></a>. And the data will be in XML using a standard <a href=\"https://web.archive.org/web/20081014105337/http://en.wikipedia.org/wiki/Document_Type_Definition\"><strong>DTD</strong></a>.
        Some of the pieces of the puzzle already exist, but nobody has yet put them
        together in a way that it creates a compelling alternative to the currently
        used systems.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ I like poster sessions ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/i-like-poster-sessions/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwap</id>\n
        \       <published>2008-06-04T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-19T08:59:09.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>As I <a href=\"https://blog.front-matter.io/posts/are-posters-worth-the-effort\">said
        before</a> on this blog, I do like poster sessions. The poster sessions at
        the just finished <a href=\"http://www.asco.org/\">American Society of Clinical
        Oncology</a> meeting didn't offer food and drink, but were otherwise very
        enjoyable. The meeting is probably special because a lot of high quality research
        will be presented as poster, as there is just not enough time for enough oral
        sessions. Many of the poster presenters were senior faculty. I also like the
        printouts that were available from most posters \u2013 but there still was
        a lot of picture taking with digital cameras. A very good feature was the
        oral summary of some of the poster sessions: 15 minute presentations of 5-10
        posters, summarized and commented on by an expert in the field.</p><p>I had
        some very informative discussions with a number of poster presenters. When
        you are familiar with the research topic it is often possible to go straight
        to the interesting issues, the nonlinear and interactive format of a poster
        is then often better than an oral presentation. The downside of a poster presentation
        is obviously that the format is good for presenting to a small audience only.
        But the poster presenter will usually get much more feedback than from an
        oral presentation.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ How technology can help you to survive a
        meeting ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/how-technology-can-help-you-to-survive-a-meeting/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwan</id>\n        <published>2008-06-02T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-15T14:39:28.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>I'm currently
        in Chicago at the <a href=\"https://web.archive.org/web/20120611092305/http://www.asco.org/ASCO/Meetings/ASCO+Annual+Meeting\">annual
        meeting</a> of the American Society of Clinical Oncology (ASCO). This is a
        large meeting on clinical cancer research with about 30.000 people attending.
        Rather than writing about the specific research presented and discussed at
        the meeting, I would like to talk about how (web) technology can help in having
        a better conference. I will focus on two (obvious) issues:</p><ul><li>How
        do I find the relevant information out of thousands of abstracts and sessions?</li><li>How
        can I benefit from the meeting even if not physically present?</li></ul><p>ASCO
        has done a number of things to help. All <a href=\"https://web.archive.org/web/20120611092305/http://www.abstract.asco.org/\">meeting
        abstracts</a> where made available a few weeks before the meeting. The meeting
        program is available online, and you can create your person schedule that
        you can print out or export to you calendar software. The schedule is also
        available for Palm users. At the meeting, you find free WiFi throughout the
        conference. Most talks are made available as videocasts (for a fee now, made
        publicly available October 1) or podcasts. ASCO also even has an educational
        session with three talks titled <em><em>Using the Internet to Keep Current:
        From Podcasts to Virtual Meetings to RSS</em></em>.</p><p>Information about
        the meeting is difficult to find. With the exception of blogs and websites
        that cover the meeting form a business perspective \u2013 results from clinical
        trials presented at the meeting can have a profound impact on the stock performance
        \u2013 there isn't a lot of blogging about the meeting (as discussed <a href=\"https://web.archive.org/web/20120611092305/http://network.nature.com/blogs/user/mfenner/2008/05/17/scientific-meetings-need-more-bloggers\">here
        before</a>). This means that the filtering out of the interesting information
        still has to be done the traditional way, basically going through the 5000+
        abstracts.</p><p><strong>Conclusion</strong>: The meeting organizers provide
        a number of wonderful tools, but they haven't yet discovered Web 2.0. More
        blogging or online discussion would make the meting much more interesting.
        And the function to create a personal schedule could be greatly enhanced by
        using user input, e.g. listing the most popular talks or allowing you to share
        your schedule with a colleague. You can get a lot out of the meeting even
        if you are not physically present, but the information filtering has still
        a way to go.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Microsoft stops Live Search Academic ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/microsoft-stops-live-search-academic/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwam</id>\n        <published>2008-05-24T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T07:35:13.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Microsoft yesterday <a href=\"https://web.archive.org/web/20120611102727/http://blogs.msdn.com/livesearch/archive/2008/05/23/book-search-winding-down.aspx\">announced</a>
        on the Live Search Blog that their <a href=\"https://web.archive.org/web/20120611102727/http://search.live.com/academic/\">Academic
        Search</a> will be closed next week.</p><p>And <a href=\"https://web.archive.org/web/20120611102727/http://scholar.google.com/\">Google
        Scholar</a> still has shortcomings, including the lack of special limitation
        features that are found in PubMed. A more detailed comparison of PubMed and
        Google Scholar can be found in <a href=\"https://web.archive.org/web/20120611102727/http://www.pubmedcentral.nih.gov/articlerender.fcgi?tool=pubmed&amp;pubmedid=17971893\">this
        paper</a>.</p><p>Does this announcement simply reflect a shift in strategy
        at Microsoft, or is academic search no longer interesting to Microsoft, Google,
        etc.?</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Why local hubs in Nature Network are important
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/why-local-hubs-in-nature-network-are-important/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwak</id>\n        <published>2008-05-24T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-13T13:41:32.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Earlier this week Matt Brown
        announced important changes to the Nature Network software: <a href=\"https://web.archive.org/web/20120611102855/http://network.nature.com/london/news/blog/matt/2008/05/21/the-first-step-towards-new-local-hubs\">The
        first step towards new local hubs</a>. Most importantly, it is now possible
        to set your location and hub. The hub can be the same as the location, or
        a city or region nearby (as in my case <a href=\"https://web.archive.org/web/20120611102855/http://network.nature.com/hubs/berlin\">Berlin</a>).
        Later this year, Nature Network will add new hubs to the existing London and
        Boston. Hubs that are now picked by many people are more likely to become
        full-fledged hubs. Some of the early popular hubs include <a href=\"https://web.archive.org/web/20120611102855/http://network.nature.com/groups/nyc/notice/2008/05/20/join-the-new-york-hub\">New
        York</a>, <a href=\"https://web.archive.org/web/20120611102855/http://network.nature.com/forums/scibarcamp/1597\">Toronto</a>
        and <a href=\"https://web.archive.org/web/20120611102855/http://network.nature.com/forums/berlin/1596\">Berlin</a>
        (there are certainly more, but there is no way for me to see them listed).</p><p>As
        we know from the London and Boston hubs, local hubs have local events listings,
        local meetups, local news and jobs information. We had several <a href=\"https://web.archive.org/web/20120611102855/http://network.nature.com/blogs/user/maxine/2008/05/08/web-2-0-and-biology-8-may-2008\">discussions</a>
        here on Nature Network of what Web 2.0 can bring to scientists and that only
        those tools and increase the productivity or add something new will become
        popular. Local event and job listings for scientists are two services that
        I see as extremely valuable, basically I don't see any way other than as Web
        services to do them properly.</p><p>Location information is becoming increasingly
        popular in other parts of the Web and the <a href=\"https://web.archive.org/web/20120611102855/http://en.oreilly.com/where2008/public/content/home\">Where
        2.0</a> conference on the topic just finished earlier this month. <a href=\"https://web.archive.org/web/20120611102855/http://www.researcherid.com/\">ResearcherID</a>,
        a tool to assign a unique identifier to every researcher, is one example where
        scientific information is mapped to locations. You can see a map of my paper
        coauthors <a href=\"https://web.archive.org/web/20120611102855/http://labs.researcherid.com/mashlets/rid/mashletsServer.jsp?rid=A-7225-2008&amp;mid=CollaborationNetwork&amp;cat=Map\">here</a>.</p><p>Scientific
        research and communication is not bound to locations, but local networks are
        at least as important as virtual networks. We of course all do this already
        for many years, but we are just starting to figure out how social networks
        such as Nature Network can enhance our physical networks and connect them
        to the larger virtual network. Philipp Selenko has a clear vision, he sees
        this as a great opportunity for PhD students to do the same kind of networking
        that is usually restricted to seasoned faculty (and often happens behind closed
        doors). Read <a href=\"https://web.archive.org/web/20120611102855/http://network.nature.com/forums/berlin/1332\">his
        post</a> on the Berlin forum for more details.</p><p>And please join the Berlin
        hub if you work in that region.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Scientific meetings need more bloggers ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/scientific-meetings-need-more-bloggers/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwaj</id>\n        <published>2008-05-17T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-01T05:31:53.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>In one of
        my first blog posts (before I joined Nature Network) about a year ago I wrote
        about the <a href=\"https://web.archive.org/web/20120611102648/http://blog.xartrials.com/2007/6/6/asco_2007_meeting\">American
        Society of Clinical Oncology (ASCO) 2007 Meeting</a>. I was surprised that
        only a handful of blogs reported about the event, one of the largest and most
        important meetings for clinical cancer research.</p><p>One would think that
        blogging and scientific meetings would be a natural combination. Those that
        can't go to a meeting need a filtered summary, and a blogging scientist would
        be a perfect person for the job. The experience with blog posts about technology
        meetings also says that this should work. <a href=\"https://web.archive.org/web/20120611102648/http://blogs.nature.com/news/blog/\">In
        the Field</a> is Nature's blog about conferences and events and there is the
        occasional blog post about a meeting.</p><p>So why are there not more bloggers
        at science meetings? I think that this is simply a problem of critical mass.
        1) there are still not enough science bloggers around and 2) most science
        blogs (including this one) don't write about research results, but rather
        about other aspects of science. This could well change in a few years and
        I expect to see an increasing number of science blogs reporting from meetings.
        And I will try to blog about the most interesting sessions in the fields of
        leukemia and lymphoma when I go to ASCO 2008 in Chicago at the end of the
        month.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Designer debacles and other misdemeanors
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/designer-debacles-and-other-misdemeanors/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwah</id>\n        <published>2008-05-15T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-31T07:32:58.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>In the last issue of Nature,
        a <a href=\"https://web.archive.org/web/20120611103129/http://www.nature.com/news/2008/080514/full/453275a.html\">news
        feature</a> and <a href=\"https://web.archive.org/web/20120611103129/http://www.nature.com/nature/journal/v453/n7193/full/453260a.html\">research
        highlight</a> look at two recent high-profile paper retractions. The two papers
        by biochemist Homme Hellinga delt with rational enzyme design. A second group
        couldn't reproduce the results, ultimately leading to the paper retractions.
        Then a third group was able to demonstrate that rational enzyme design is
        indeed possible.</p><p>The research highlight looks at the troubles of the
        second reseach group led by John Richard. He wasted a lot of time and money
        trying to reproduce Hellinga's findings and in the end did not gain anything.</p><p>Non-reproducible
        work is a common problem in research, and papers containing this questionable
        work are rarely retracted. I would guess that most of the time this is unintentional.
        John P. A. Ioannidis explains this in an PLoS Medicine essay: <a href=\"https://web.archive.org/web/20120611103129/http://dx.doi.org/10.1371/journal.pmed.0020124\">Why
        most published research findings are false</a>.</p><p>Sometimes the reasons
        behind non-reproducible results can be calculated, and this includes drug
        trials in clinical medicine. <a href=\"https://web.archive.org/web/20120611103129/http://jco.ascopubs.org/cgi/content/abstract/25/23/3482\">Statistical
        Power of Negative Randomized Controlled Trials Presented at American Society
        for Clinical Oncology Annual Meetings</a> found that more than half of these
        randomized controlled trials that showed no benefit for a new treatment did
        not have enough patients to detect even a medium-sized treatment effect.</p><p>What
        should we do about this? The first step is to accept the fact that a significant
        number of research findings you read in a paper are not reproducible. We have
        to be careful to start a PhD thesis or other research project based on a few
        exciting papers, especially when this work was done by someone else. Thinking
        about this, I should have taken that advice myself before starting a particular
        project 5 years ago.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Web 2.0 for Scientists: Where are the Applications?
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/web-2-0-for-scientists-where-are-the-applications/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwag</id>\n        <published>2008-05-10T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-13T13:40:24.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>The <a href=\"https://web.archive.org/web/20120611103012/http://www.cshblogs.org/cshprotocols/2008/02/14/why-web-20-is-failing-in-biology/\">success
        or failure</a> of Web 2.0 efforts for scientists depends to a large extend
        on the availability of cool applications that make the everyday life of a
        scientist easier. Many of these applications of course already exist, but
        I would argue that there is a lot of room for improvement. And I would also
        argue that in a lot of cases we just have to take the example of the Web 2.0
        world and adapt it to the needs of scientists \u2013 Nature Network itself
        would be an example of this approach.</p><h3 id=\"meetings-and-seminars\">Meetings
        and Seminars</h3><p>Scientific meetings and seminars are one example were
        we can do better. Web 2.0 is an ideal approach for this, and <a href=\"https://web.archive.org/web/20120611103012/http://upcoming.yahoo.com/\">Upcoming</a>
        is the classic application. There are of course a number of websites that
        list meetings and seminars for scientists, but they either focus on the big
        meetings or list just the seminars of a particular institution. Look at the
        discussion <a href=\"https://web.archive.org/web/20120611103012/http://network.nature.com/forums/berlin/1360\">How
        to find a science event in Berlin</a> in the Nature Network Berlin Forum to
        see what I mean.</p><h3 id=\"what-can-we-do-to-improve-the-situation\">What
        can we do to improve the situation?</h3><p>We can wait that either one of
        the big players or a clever startup has a great idea. But one of the attractive
        features of Web 2.0 is user participation. We need more discussions between
        scientists and software developers on what is needed and what can be done.
        These discussions are of course already taking place, but science bloggers
        can do more to collect interesting ideas and articulate them. We want the
        integration of reference managers in online writing tools such as <a href=\"https://web.archive.org/web/20120611103012/http://docs.google.com/\">Google
        Docs</a> or <a href=\"https://web.archive.org/web/20120611103012/http://www.buzzword.com/\">Buzzword</a>,
        but how do we make our voice heard?</p><p>Secondly, we can write applications
        ourselves. The barriers of entry have become really low, and one reason are
        the APIs (application programming interfaces) of both science applications
        or conventional Web 2.0 apps:</p><ul><li><a href=\"https://web.archive.org/web/20120611103012/http://eutils.ncbi.nlm.nih.gov/entrez/query/static/eutils_help.html\">Pubmed</a></li><li><a
        href=\"https://web.archive.org/web/20120611103012/http://www.scopus.com/scsearchapi/\">Scopus</a></li><li><a
        href=\"https://web.archive.org/web/20120611103012/http://network.nature.com/blogs/user/ianmulvany/2007/08/14/java-wrapper-for-the-connotea-api-now-available\">Connotea</a></li><li><a
        href=\"https://web.archive.org/web/20120611103012/http://code.google.com/apis/maps/\">Google
        Maps</a></li><li><a href=\"https://web.archive.org/web/20120611103012/http://code.google.com/apis/documents/overview.html\">Google
        Docs</a></li><li><a href=\"https://web.archive.org/web/20120611103012/http://code.google.com/apis/youtube/overview.html\">YouTube</a></li><li><a
        href=\"https://web.archive.org/web/20120611103012/http://www.flickr.com/services/api/\">Flickr</a></li><li><a
        href=\"https://web.archive.org/web/20120611103012/http://technorati.com/developers/api/\">Technorati</a></li><li><a
        href=\"https://web.archive.org/web/20120611103012/http://developers.facebook.com/\">Facebook</a></li><li><a
        href=\"https://web.archive.org/web/20120611103012/http://developer.ebay.com/common/api/\">eBay</a></li><li><a
        href=\"https://web.archive.org/web/20120611103012/http://www.amazon.com/gp/browse.html?node=3435361\">Amazon</a></li><li><a
        href=\"https://web.archive.org/web/20120611103012/http://developer.yahoo.com/\">Yahoo</a></li></ul><p>And
        there were <a href=\"https://web.archive.org/web/20120611103012/http://www.ghastlyfop.com/blog/2007/10/facebook-code-on-bebo.html\">hints</a>
        of a Nature Network API. With some skills in PHP, Python, Java or Ruby, anybody
        could create an interesting mashup with these APIs over a weekend. Maybe linking
        Connotea tags to YouTube videos and Flickr pictures?</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Publish or Perish: no longer just a buzzword
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/publish-or-perish-no-longer-just-a-buzzword/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwaf</id>\n        <published>2008-05-07T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-29T20:14:30.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p><a href=\"https://docs.google.com/\">Google
        Publish or Perish</a> is a new science writing tool that facilitates paper
        submissions. The tool was field-tested at the NIH and should be particularly
        valuable for open access and public access journals. Accepted papers are automatically
        added to your <a href=\"https://www.researcherid.com/\">Researcher ID</a>
        account.</p><p>For more information, read <a href=\"https://web.archive.org/web/20120611102605/http://network.nature.com/forums/nnbloggername/1523\">this</a>
        forum post by Matt Brown.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ When calls for papers go wrong ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/when-calls-for-papers-go-wrong/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwae</id>\n        <published>2008-05-05T15:48:00.000+00:00</published>\n\t\t<updated>2022-08-01T11:54:14.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Last week I received email
        invitations from three different journals to submit a research article. I
        should have felt flattered, but it is unclear why it is me that received invitations
        to the journals <a href=\"https://web.archive.org/web/20120611103403/http://la-press.com/journal.php?journal_id=4\"><em>Biomarker
        Insights</em></a>, <a href=\"https://web.archive.org/web/20120611103403/http://la-press.com/journal.php?journal_id=103\"><em>Genomics
        Insights</em></a> and <a href=\"https://web.archive.org/web/20120611103403/http://www.medsci.org/\"><em>International
        Journal of Medical Sciences</em></a>. All three journals already exist for
        a few years, and I wouldn't say that the focus of my research is biomarkers
        or genomics.</p><p>Then I thought about a recent blog post by Gunther Eysenbach:
        <a href=\"https://web.archive.org/web/20120611103403/http://gunther-eysenbach.blogspot.com/2008/03/black-sheep-among-open-access-journals.html\">Black
        sheep among Open Access Journals and Publishers</a>. In this post he calls
        the sending of unsolicited emails simply spamming and argues that <em><em>there
        are also throw-away journals out there from shady publishers trying to cash
        in on the current surge of interest in open access publishing.</em></em></p><p>And
        this is what all three journals mentioned above have in common: they are open
        access journals and the author pays for the (accepted) article. It is obvious
        that any journal that gets paid by the author is interested in soliciting
        articles whereas a subscriber-pays journal would be interested in attracting
        new readers. There is nothing wrong with this, but there are two potential
        problems. (1) Like most people I don't like spam. (2) Journals with an author-pays
        business model have to be extremely careful about the quality of their papers.</p><p>Potential
        authors should first check whether the journal (if it is a biomedical journal)
        is indexed in <a href=\"https://web.archive.org/web/20120611103403/http://www.ncbi.nlm.nih.gov/sites/entrez?db=journals\">Medline</a>
        (Genomics Insights is not) and either has a reasonable impact factor or (for
        new journals) receives enough citations.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Considering posting your paper in a repository?
        Think again ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/considering-posting-your-paper-in-a-repository-think-again/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwad</id>\n        <published>2008-04-29T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-13T13:38:30.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Our <a href=\"https://web.archive.org/web/20120611110637/http://network.nature.com/blogs/user/mfenner/2008/04/11/public-access-week-who-could-read-my-papers\">recent</a>
        discussion on public access made me have a closer look on the options I have
        for my own papers. The results aren't pretty.</p><h3 id=\"most-journals-allow-posting-post-prints-on-a-university-website\">Most
        journals allow posting post-prints on a university website</h3><p>The copyright
        agreement with the journal is the easy part. Most publishers allow posting
        of post-prints (after peer-review, but not the journal PDF) in a non-commercial
        repository, usually the repository of your institution. Below are the policies
        of three prominent publishers.</p><h3 id=\"elsevier\"><a href=\"https://web.archive.org/web/20120611110637/http://www.elsevier.com/wps/find/supportfaq.cws_home/rightsasanauthor\">Elsevier</a></h3><blockquote><em><em>As
        an author, you retain rights for a large number of author uses, including
        use by your employing institute or company. These rights are retained and
        permitted without the need to obtain specific permission from Elsevier. These
        include (\u2026) the right to post a revised personal version of the text
        of the final article (to reflect changes made in the peer review process)
        on the author's personal or institutional web site or server, with a link
        to the journal home page</em></em></blockquote><h3 id=\"springer\"><a href=\"https://web.archive.org/web/20120611110637/http://www.springer.com/authors/journal+contributors?SGWID=0-154202-12-467999-0\">Springer</a></h3><blockquote><em><em>An
        author may self-archive an author-created version of his/her article on his/her
        own website. He/she may also deposit this version on his/her institution's
        and funder's (funder-designated) repository at the funder\xE2\u20AC\u2122s
        request or as a result of a legal obligation, including his/her final version,
        provided it is not made publicly available until after 12 months of official
        publication. He/she may not use the publisher's PDF version which is posted
        on www.springerlink.com for the purpose of self-archiving or deposit. Furthermore,
        the author may only post his/her version provided acknowledgement is given
        to the original source of publication and a link is inserted to the published
        article on Springer's website. The link must be accompanied by the following
        text: \u201CThe original publication is available at www.springerlink.com\u201D.</em></em></blockquote><h3
        id=\"nature-publishing-group\"><a href=\"https://web.archive.org/web/20120611110637/http://www.nature.com/authors/editorial_policies/license.html\">Nature
        Publishing Group</a></h3><blockquote><em><em>When a manuscript is accepted
        for publication in an NPG journal, authors are encouraged to submit the author's
        version of the accepted paper (the unedited manuscript) to PubMedCentral or
        other appropriate funding body's archive, for public release six months after
        publication. In addition, authors are encouraged to archive this version of
        the manuscript in their institution's repositories and, if they wish, on their
        personal websites, also six months after the original publication. In all
        these cases, authors should cite the publication reference and DOI number
        on any deposited version, and provide a link from it to the URL of the published
        article on the journal's website.</em></em></blockquote><p>The policies of
        some of the smaller publishers can be more difficult to find. Sometimes an
        email exchange with the publisher will be necessary.</p><h3 id=\"many-universities-have-institutional-repositories\">Many
        universities have institutional repositories</h3><p><a href=\"https://web.archive.org/web/20120611110637/http://www.opendoar.org/\">OpenDOAR</a>
        is a directory of open access repositories. My university doesn't yet have
        an institutional repository. After a short email exchange they offered to
        host my post-prints on a public webserver. I currently have no details on
        the software platform used or how many people in my university use this service.</p><h3
        id=\"post-prints-may-no-longer-be-available\">Post-prints may no longer be
        available</h3><p>Most publishers don't allow posting of the journal PDF. You
        have to post the final manuscript after per-review (post-print). The problem:
        I no longer have these manuscripts for papers published more than a few years
        ago \u2013 thinking that the PDF would be enough.</p><h3 id=\"your-post-prints-are-hard-to-find\">Your
        post-prints are hard to find</h3><p><a href=\"https://web.archive.org/web/20120611110637/http://www.opendoar.org/search.php\">OpenDOAR</a>
        has a search function, but searching several institutional repositories at
        once is complicated. Your best bet is probably to find a paper in <a href=\"https://web.archive.org/web/20120611110637/http://www.pubmed.gov/\">Pubmed</a>
        and then try to find the institutional repository for that author. But maybe
        you have to check several institutional repositories if the authors are not
        all from the same institution.</p><h3 id=\"conclusions\">Conclusions</h3><p>Posting
        your paper in an institutional repository can be a challenging project. It
        is therefore advisable to think about this before paper submission. What is
        your publication strategy? Do you need open access? Does the journal offer
        free content after an embargo period of 6 or 12 months? What is the journal
        policy regarding post-prints? And most importantly, keep the manuscript version
        right after peer-review. A central repository such as <a href=\"https://web.archive.org/web/20120611110637/http://www.pubmedcentral.nih.gov/\">Pubmed
        Central</a> doesn't have most of these shortcomings.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ ResearcherID now with Mashups ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/researcherid-now-with-mashups/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwac</id>\n        <published>2008-04-22T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T07:33:16.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>A real Web 2.0 application
        needs a serious <a href=\"https://web.archive.org/web/20120611110207/http://en.wikipedia.org/wiki/Mashup_\">mashup</a>
        (web_application_hybrid). At least the folks at ResearcherID thought so. You
        might <a href=\"https://web.archive.org/web/20120611110207/http://network.nature.com/blogs/user/mfenner/2008/01/21/thomson-scientific-launches-researcherid-to-uniquely-identify-authors\">remember</a>
        that ResearcherID creates a unique author ID for each interested scientist
        and was launched by Thomson Scientific (recently renamed Thomson Reuters)
        earlier this year.</p><p>The new ResearcherID features include a mashup with
        Yahoo Maps that shows the location of your collaborators. Here are some examples
        from fellow Nature Networkers:</p><ul><li><a href=\"https://web.archive.org/web/20120611110207/http://labs.researcherid.com/mashlets/rid/mashletsServer.jsp?rid=A-7225-2008&amp;mid=CollaborationNetwork&amp;cat=Map\">Martin
        Fenner</a></li><li><a href=\"https://web.archive.org/web/20120611110207/http://labs.researcherid.com/mashlets/rid/mashletsServer.jsp?rid=A-7602-2008&amp;mid=CollaborationNetwork&amp;cat=Map\">Raf
        Aerts</a></li><li><a href=\"https://web.archive.org/web/20120611110207/http://labs.researcherid.com/mashlets/rid/mashletsServer.jsp?rid=A-7499-2008&amp;mid=CollaborationNetwork&amp;cat=Map\">Bob
        O'Hara</a></li></ul><p>Wentworthville, Australia is the furthest I can go
        to find a paper co-author.</p><p>Now the really interesting question would
        be: when do we see mashups with Nature Networkers? For a start we have the
        <a href=\"https://web.archive.org/web/20120611110207/http://www.flickr.com/groups/nnl/pool/map?mode=group\">Nature
        Network London Flickr Mashup</a> created by Matt.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ On Guest authors and Ghostwriters ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/on-guest-authors-and-ghostwriters/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwab</id>\n        <published>2008-04-19T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-13T13:36:55.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>The legal disputes following
        the withdrawal from the market of two drugs for the treatment of pain (the
        COX-2 inhibitors rofecoxib and valdecoxib) have led to another critical examination
        of the paper publishing process. I have <a href=\"https://web.archive.org/web/20120611111125/http://network.nature.com/blogs/user/mfenner/2008/02/23/should-peer-review-be-confidential\">written</a>
        in February about the drug company Pfizer trying to obtain confidential peer
        review documents from the journals <a href=\"https://web.archive.org/web/20120611111125/http://jama.ama-assn.org/\">JAMA</a>
        and <a href=\"https://web.archive.org/web/20120611111125/http://www.nejm.org/\">NEJM</a>.
        Courts in Chicago and Boston have <a href=\"https://web.archive.org/web/20120611111125/http://sciencenow.sciencemag.org/cgi/content/full/2008/401/1\">denied</a>
        such requests.</p><p>An <a href=\"https://web.archive.org/web/20120611111125/http://jama.ama-assn.org/cgi/content/full/299/15/1800\">article</a>
        and accompanying <a href=\"https://web.archive.org/web/20120611111125/http://jama.ama-assn.org/cgi/content/full/299/15/1833\">editorial</a>
        in this week's JAMA look at guest authorship and ghostwriting in publications
        related to rofecoxib (better known as Vioxx, produced by Merck). Guest authorship
        was defined as an author that does not meet authorship criteria. The <a href=\"https://web.archive.org/web/20120611111125/http://www.icmje.org/\">Uniform
        Requirements for Manuscripts to Biomedical Journals</a> from the International
        Commitee of Medical Journal Editors (ICMJE) define authorship as follows:</p><blockquote><em><em>Authorship
        credit should be based on </em></em><br><em><em>1) substantial contributions
        to conception and design, or acquisition of data, or analysis and interpretation
        of data; </em></em><br><em><em>2) drafting the article or revising it critically
        for important intellectual content; and </em></em><br><em><em>3) final approval
        of the version to be published. </em></em><br><em><em>Authors should meet
        conditions 1, 2, and 3.</em></em></blockquote><p>Ghostwriting was defined
        as the failure to designate an individual that made significant contributions
        to the research or writing of a manuscript.</p><p>The JAMA <a href=\"https://doi.org/10.1001/jama.299.15.1800\">article</a>
        did a systematic analysis of the court documents obtained during litigation
        related to rofecoxib. Guest authorship was identified in 16% of research articles
        and 26% of review articles; ghostwriting was identified in 13% of research
        articles and 10% of review articles. The <a href=\"https://web.archive.org/web/20120611111125/http://jama.ama-assn.org/cgi/content/full/299/15/1833\">editorial</a>
        in the same issue is called <em><em>Impugning the Integrity of Medical Science:
        The Adverse Effects of Industry Influence</em></em> and dicusses this article
        as well an another article called <a href=\"https://web.archive.org/web/20120611111125/http://jama.ama-assn.org/cgi/content/full/299/15/1813\">Reporting
        Mortality Findings in Trials of Rofecoxib for Alzheimer Disease or Cognitive
        Impairment</a> in the same issue. The editorial proposes that drastic action
        is necessary and includes a list of 11 measures.</p><p>Criteria for authorship
        and disclosure of financial interests are clearly defined not only by the
        ICMJE, but also by the <a href=\"https://web.archive.org/web/20120611111125/http://www.blackwell-synergy.com/doi/full/10.1111/j.1525-1497.2005.41015.x\">World
        Association of Medical Editors</a> (WAME) and by most journals. And the European
        Medical Writers Association (EMWA) has published <a href=\"https://web.archive.org/web/20120611111125/http://www.emwa.org/Mum/EMWAguidelines.pdf\">guidelines</a>
        on the role of medical writers in peer-reviewed publications. As medical writers
        usually don't fulfill the authorship criteria defined above (with the possible
        exception of review articles), they should rather be acknowledged. The EMWA
        guidelines propose the following wording:</p><blockquote><em><em>We thank
        Dr Jane Doe who provided medical writing services on behalf of XYZ Pharmaceuticals
        Ltd.</em></em></blockquote><p>The rules are clear and it is also clear that
        there will be violations of these rules. Guest authorship and ghostwriting
        are probably common practices, not only in publications supported by drug
        companies. Typical examples would be the inclusion of the department head
        that did little more than to provide financial support or the exclusion of
        the technician that did critical experiments but is not acknowledged. Cases
        of suspected guest authorship or ghostwriting should be taken seriously and
        the papers in JAMA will ignite a renewed discussion on these topics.</p><p>For
        different views on this topic, look at <a href=\"https://web.archive.org/web/20120611111125/http://blogs.nature.com/nm/spoonful/2008/04/exit_ghost.html\">Exit
        ghost</a> by Juan Carlos Lopez over at <em><em>Spoonful of Medicine</em></em>
        and <a href=\"https://web.archive.org/web/20120611111125/http://pipeline.corante.com/archives/2008/04/18/cut_it_out_cut_it_out_now.php\">Cut
        it out. Cut it out now.</a> by Derek Lowe at <em><em>In the Pipeline</em></em>.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Public Access Week: Personal Summary ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/public-access-week-personal-summary/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwaa</id>\n        <published>2008-04-13T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-13T13:35:31.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>The new <a href=\"https://web.archive.org/web/20120611110656/http://network.nature.com/blogs/user/mfenner/2008/04/06/public-access-week-new-nih-public-access-policy-starts-today\">NIH
        Public Access policy</a> started this past Monday. Fellow Nature Networker
        <a href=\"https://web.archive.org/web/20120611110656/http://network.nature.com/profile/steelgraham\">Graham
        Steel</a> has <a href=\"https://web.archive.org/web/20120611110656/http://mcblawg.blogspot.com/2008/04/open-access-week-highlights-from.html\">summarized</a>
        this week's reaction of the blogosphere. I would like to highlight some of
        the discussions we had here on Nature Network.</p><p>Bob O'Hara wonders about
        the cost of publishing in <a href=\"https://web.archive.org/web/20120611110656/http://network.nature.com/blogs/user/boboh/2008/04/09/open-access-show-us-the-money\">Open
        Access: Show us the Money!</a>. He argues that shifting the costs from reader
        to author can create problems. Most authors, especially those with limited
        resources, would be reluctant to pay submision fees if they can also submit
        to a journal without those fees. But the reader-pays model could give authors
        more bargaining power with journals. The post created an interesting discussion
        about the different aspects of publishing costs</p><p>Graham Steel pointed
        out the <a href=\"https://web.archive.org/web/20120611110656/http://network.nature.com/forums/harvardpublishingforum/1331\">Second
        European Conference on Scientific Publishing in Biomedicine and Medicine</a>
        that takes place in Oslo September 4-6 in Oslo, Norway. The conference focusses
        on open access and bibliometrics.</p><p>I wrote two blog posts about public
        access. In Germany, most research organizations have signed the <a href=\"https://web.archive.org/web/20120611110656/http://oa.mpg.de/openaccess-berlin/berlindeclaration.html\">Berlin
        Declaration</a>, but in contrast to the new NIH policy, there is no mandatory
        public access. In another blog entry, I looked at public access to my own
        research papers \u2013 most of them are only accessible for those with institutional
        journal subscriptions.</p><p>What is the next step for me? That I need to
        learn more about self-archieving \u2013 both the policies of the journals
        I have published and the institutional repository at my university.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Public Access Week: Who could read my papers?
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/public-access-week-who-could-read-my-papers/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwa9</id>\n        <published>2008-04-11T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-13T13:34:13.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>I did a little experiment
        to figure out whether the full-text versions of my last 15 papers (published
        between 1997-2008) are available online. The result:</p><ul><li>3 papers available
        for everybody</li><li>10 papers only available from within my institution
        (Journal subscription required)</li><li>2 papers only available for purchase</li></ul><p>Interestingly,
        the papers in the two journals with the highest impact factor are both available
        as full-text. And the third full-text paper is my paper with the most citations
        (and published in 1998).</p><p>Conclusion: Not that anyone would care what
        I have to say, but you have to work in an institution with a good library
        budget to read my papers.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Public Access Week: How do we do it in Germany?
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/public-access-week-how-do-we-do-it-in-germany/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwa8</id>\n        <published>2008-04-10T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T07:31:46.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Starting this week, papers
        submitted from NIH-funded research have to be <a href=\"https://web.archive.org/web/20120611110754/http://publicaccess.nih.gov/policy.htm\">made
        publicly available</a> no later than 12 months after publication. But what
        is the current situation in Germany, especially mandatory Open Access?</p><p>The
        <a href=\"https://web.archive.org/web/20120611110754/http://oa.mpg.de/openaccess-berlin/berlindeclaration.html\">Berlin
        Declaration</a> from October 2003 was a strong statement of support for Open
        Access and was signed by all major research and funding organizations, including
        <em><em>Deutsche Forschungsgemeinschaft (DFG)</em></em>, <em><em>Max Planck
        Gesellschaft (MPG)</em></em>, <em><em>Helmholtz-Gesellschaft</em></em>, <em><em>Fraunhofer-Gesellschaft</em></em>
        and <em><em>Leibniz-Gemeinschaft</em></em>. In contrast to the new NIH public
        access policy (and the <a href=\"https://web.archive.org/web/20120611110754/http://www.wellcome.ac.uk/About-us/Policy/Spotlight-issues/Open-access/Policy/index.htm\">Welcome
        Trust</a> and <a href=\"https://web.archive.org/web/20120611110754/http://www.hhmi.org/about/research/journals/main?action=search\">Howard
        Hughes Medical Institute</a>), there is no mandatory Open Access in any of
        these organizations.</p><p>The German Publisher <em><em>Springer</em></em>,
        one of the largest STM (Science, Technology and Medicine) publishers, has
        a <a href=\"https://web.archive.org/web/20120611110754/http://www.springer.com/open+choice?SGWID=0-40359-0-0-0\">Springer
        Open Choice</a> option. Authors who pay for this option will retain the copyright
        of their paper and the article will be made available with full Open Access.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Public Access Week: New NIH Public Access
        Policy starts Today ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/public-access-week-new-nih-public-access-policy-starts-today/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwa7</id>\n        <published>2008-04-06T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T07:08:36.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Around Christmas, <a href=\"https://web.archive.org/web/20120611110624/http://network.nature.com/blogs/user/mfenner/2007/12/26/mandatory-open-access-for-nih-funded-research-signed-into-law\">mandatory
        open access for NIH-funded research</a> was signed into law:</p><blockquote><em><em>The
        Director of the National Institutes of Health shall require that all investigators
        funded by the NIH submit or have submitted for them to the National Library
        of Medicine</em>'<em>s PubMed Central an electronic version of their final,
        peer-reviewed manuscripts upon acceptance for publication, to be made publicly
        available no later than 12 months after the official date of publication:
        Provided, That the NIH shall implement the public access policy in a manner
        consistent with copyright law.</em></em></blockquote><p>Starting April 7,
        the new <a href=\"https://web.archive.org/web/20120611110624/http://publicaccess.nih.gov/policy.htm\">NIH
        Public Access Policy</a> implementing this law will take effect for most NIH
        grantees. The NIH is <a href=\"https://web.archive.org/web/20120611110624/http://grants.nih.gov/grants/guide/notice-files/NOT-OD-08-060.html\">soliciting
        comments</a> until May 1st for this new policy. Open Access and this new policy
        are complicated topics that simply can't be covered in a single blog post.
        This week will certainly see a lot of discussion on this topic, both on Nature
        Network and elsewhere. Please state your view on the topic either in blog
        entries or join the discussion in the <a href=\"https://web.archive.org/web/20120611110624/http://network.nature.com/forums/harvardpublishingforum/1320\">Publishing
        in the New Millenium Forum</a>. I will try to summarize (some) of the discussion
        at the end of this <em><em>Public Access Week</em></em>.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ What can Erythopoetin do for you? ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/what-can-erythopoetin-do-for-you/\"
        />\n\t\t<id>https://doi.org/10.53731/c99ks6c-c04z2dh</id>\n        <published>2008-04-01T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-14T15:08:46.000+00:00</updated>\n
        \       <media:content url=\"\" medium=\"image\"/>\n        <content type=\"html\"><![CDATA[
        <p><img src=\"\"></p><p>Erythropoietin is an effective drug to increase your
        number of red blood cells. It is primarily used in anemic patients with <a
        href=\"https://web.archive.org/web/20120611111109/http://jco.ascopubs.org/cgi/content/abstract/26/1/132\">cancer</a>
        and on <a href=\"https://web.archive.org/web/20120611111109/http://kidney.niddk.nih.gov/kudiseases/pubs/anemia/\">dialysis</a>,
        but it is also popular with athletes that want to (illegally) increase their
        endurance performance, most notably cyclists and cross country skiers.</p><p>Although
        the typical work of a scientist is a very different from a cyclist performing
        in the Tour de France, a first case of erythropoietin use(or rather misuse)
        has now been reported in Germany. A neurobiology postdoc working on the role
        of erythropoietin in <a href=\"https://web.archive.org/web/20120611111109/http://www.ncbi.nlm.nih.gov/pubmed/17483696\">Alzheimer
        disease</a> has apparently had the idea to do a little self-experimenting
        \u2013 probably thinking of the famous experiment by Barry Marshall that <a
        href=\"https://web.archive.org/web/20120611111109/http://nobelprize.org/nobel_prizes/medicine/laureates/2005/marshall-lecture.pdf\">won
        him</a> a Nobel Price. Or he was pictured \u2013 during his long experiments
        lasting well into the night \u2013 the famous German cross country skier Johann
        M\xFChlegg who <a href=\"https://web.archive.org/web/20120611111109/http://sports.espn.go.com/oly/winter02/xcountry/news?id=1339831\">tried
        to win</a> an Olympic Gold medal in Salt Lake City with the help of darbepoetin.
        What he didn't think of was the price of erythropoietin. After burning some
        20.000 Euro, the technician and then the principal investigator became suspicious.
        The case is now under investigation by the university and the <a href=\"https://web.archive.org/web/20120611111109/http://www.dfg.de/\">Deutsche
        Forschungsgemeinschaft</a>. What the authorities don't know is how to handle
        this case. Is this simply misappropriation of the research funds, is this
        brain doping, or is this a misunderstood brilliant scientist? The <a href=\"https://web.archive.org/web/20120611111109/http://www.wabda.org/\">World
        Anti-Brain Doping Authority</a> now got involved to help clear the issues.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Pubmed and other Annoyances in the Paper
        Writing Process ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/pubmed-and-other-annoyances-in-the-paper-writing-process/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwa5</id>\n        <published>2008-03-31T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-03T05:12:06.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Anna's <a href=\"https://web.archive.org/web/20120612090300/http://network.nature.com/blogs/user/U2929A0EA/2008/03/22/i-am-not-yelling-not-out-loud\">recent
        post</a> about her struggles with Pubmed searches reminded me that there is
        still a lot that could and should be done to improve the paper (or thesis)
        writing process. This is my personal list of major annoyances:</p><ul><li><strong>Pubmed</strong>.
        This topic has been extensively covered in Anna's post.</li><li><strong>Bibliographies</strong>.
        The process from finding a paper in Pubmed to storing it into your bibliographic
        software to downloading and storing the PDF to creating a bibliography in
        a paper is extremely complicated. In my case this process involves a web browser,
        <a href=\"https://web.archive.org/web/20120612090300/http://www.endnote.com/\">Endnote</a>,
        <a href=\"https://web.archive.org/web/20120612090300/http://mekentosj.com/papers/\">Papers</a>,
        a PDF viewer and Microsoft Word.</li><li><strong>Writing a paper</strong>.
        The idiosyncrasies of Microsoft Word (the tool probably used by most people
        for paper writing) would make for a different blog post. Microsoft Word can
        do many things that are never needed in a scientific manuscript, but lacks
        features that are important. And it likes to crash on long texts.</li><li><strong>Collective
        Writing</strong>. The process of having several people working on a manuscript
        and managing different versions is overly complicated.</li><li><strong>Paper
        submission</strong>. The online tools such as <a href=\"https://web.archive.org/web/20120612090300/http://www.editorialmanager.com/homepage/home.htm\">Editorial
        Manager</a> are nice, but there is still too much formatting work required
        (in a format that is probably different depending on the journal).</li></ul><p>Interestingly,
        the way we do paper writing and paper submission has changed a lot between
        ca. 1985 and 1995. Basically the transition from analog to digital. Who still
        remembers Index Medicus, Current Contents, copying papers in the library,
        Letraset for figure numbering, mailing hard copies of manuscripts around,
        etc.?</p><p>But what has changed in the last 10-15 years? Probably not that
        much. Web 2.0 is an overused term, but there is so much potential for improvement
        in the area of manuscript writing. We should <em><em>not</em></em> be satisfied
        with what Pubmed, Endnote, Microsoft Word, etc. offer today. That is why I
        don't understand some of the discussion surrounding Anna's blog post, basically
        advising her to just sit down and learn her Pubmed stuff.</p><p>If that is
        not enough for you, some people have already taken the next step: <a href=\"https://web.archive.org/web/20120612090300/http://pubs.nrc-cnrc.gc.ca/jchla/jchla29/c07-035.pdf\">Web
        3.0 and health librarians: an introduction</a>.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Is Wikipedia for Scientists? ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/is-wikipedia-for-scientists/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwa4</id>\n
        \       <published>2008-03-21T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-31T07:32:06.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Participation in a social
        network can have it's perks. Thanks to the O'Reilly Group on <a href=\"https://web.archive.org/web/20120612090051/http://www.facebook.com/\">Facebook</a>
        (that other social network), I received a review copy of <a href=\"https://web.archive.org/web/20120612090051/http://www.oreilly.com/catalog/9780596515164/index.html\">Wikipedia:
        The Missing Manual</a>. But why would a scientist want to know how to write
        and edit articles on Wikipedia?</p><p>Wikipedia has become a respectable source
        of information that rivals the more traditional encylopedias such as the Encyclopaedia
        Britannica. Remember the <a href=\"https://web.archive.org/web/20120612090051/http://www.nature.com/nature/journal/v438/n7070/full/438900a.html\">December
        2005 Nature study</a> that compared the two? Wikipedia has accurate information
        even on such obscure topics as dwarf <a href=\"https://web.archive.org/web/20120612090051/http://secure.wikimedia.org/wikipedia/en/wiki/Mammuthus_primigenius\">woolly
        mammoths</a> from Wrangel Island.</p><p>But we all know that Wikipedia is
        <a href=\"https://web.archive.org/web/20120612090051/http://www.nature.com/nature/journal/v443/n7111/full/443493a.html\">not
        perfect</a>. If we want to improve the information on topics we care about
        \u2013 and probably have spent years working on \u2013 we could become a Wikipedia
        editor. Especially if we are interested in an audience that includes not only
        fellow scientists, but also people from other scientific disciplines, journalists
        or students.</p><p>Writing and editing content on Wikipedia is a complicated
        process. Because anyone can edit content, a great number of rules exist to
        make sure that the articles have correct information, don't violate privacy,
        aren't misused as marketing opportunity, etc. All these rules, as well as
        many practical tips and other tools are of course available <a href=\"https://web.archive.org/web/20120612090051/http://en.wikipedia.org/wiki/Help:Contents\">online</a>.
        But <em><em>Wikipedia: The Missing Manual</em></em> is a very good text for
        the aspiring new Wikipedia editor that wants a more systematic introduction.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Six degrees of separation on Nature Network
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/six-degrees-of-separation-on-nature-network/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwa3</id>\n        <published>2008-03-18T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-31T07:31:09.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>A March 13 Nature News article
        (<a href=\"https://web.archive.org/web/20120612094211/http://www.nature.com/news/2008/080313/full/news.2008.670.html\">Six
        degrees of messaging</a>) talks about a study on Microsoft Messenger chat
        users. Any random two Microsoft Messenger users (out of about 240 million)
        could be connected two each other via an average of 6 users that have chatted
        with each other.</p><p>This study is just another confirmation of the <a href=\"https://web.archive.org/web/20120612094211/http://en.wikipedia.org/wiki/Six_degrees_of_separation\">six
        degrees of separation</a> concept. A 2001 <a href=\"https://web.archive.org/web/20120612094211/http://www.pnas.org/cgi/reprint/98/2/404.pdf\">PNAS
        paper</a> found the same for scientific collaboration networks, using common
        authorship for a paper as connector. The mean distance of two random authors
        in the MEDLINE database was 4.6.</p><p>Based on these findings, you can almost
        expect the same connections through joint authorship between two random Nature
        Network members. Now if I could only find a tool that would help with that
        task. Not everybody is a mathematician and can simply calculate his <a href=\"https://web.archive.org/web/20120612094211/http://www.ams.org/mathscinet/collaborationDistance.html\">Erd\xF6s
        number</a> right from the American Mathematical Society website.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Is Web 2.0 failing in Biology? ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/is-web-2-0-failing-in-biology/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwa2</id>\n        <published>2008-03-16T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-13T13:32:14.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>David Crotty, the Executive
        Editor from CSH Protocols, last month wrote a provocative blog post called
        <a href=\"https://web.archive.org/web/20120612090221/http://www.cshblogs.org/cshprotocols/2008/02/14/why-web-20-is-failing-in-biology/\">Why
        Web 2.0 is failing in Biology</a>. He did an informal poll among scientists
        and found that none of them read science blogs or use social networking sites
        for scientists. His arguments why that is so?</p><ul><li><em><em>Time</em></em>.
        Scientists have little time, and rather spend this time in the laboratory
        or reading papers</li><li><em><em>Trust</em></em>. Web 2.0 sites for scientists
        haven't (yet) build a reputation. For important decisions (e.g. a critical
        protocol for an experiment), they rather ask a colleague they know.</li><li><em><em>Inappropriate
        Tools</em></em>. The requirements for scientists are very different from the
        typical <a href=\"https://web.archive.org/web/20120612090221/http://www.facebook.com/\">Facebook</a>
        or <a href=\"https://web.archive.org/web/20120612090221/http://www.digg.com/\">Digg</a>
        user.</li></ul><p>I believe that David is right in his analysis that the big
        majority of scientists (at least in the life sciences) don't read science
        blogs or participate in social networking sites like <em><em>Nature Network</em></em>.
        This could mean two things: a) Web 2.0 is not working for biologists or b)
        we are just at the beginning and need to be patient. As a science blogger
        I like to believe in b). Fortunately or unfortunately, the success of any
        Web 2.0 project depends on a large number of users.</p><p>As of 2008, I think
        that Science 2.0 (or whatever you want to call it) has had a good start. But
        it is very important that we stay focused on where we want to go and not get
        distracted by the possibilities that the technology offers. One goal I've
        set for myself and have written about in this blog: Web 2.0 should make the
        process of paper writing much easier. This includes easy access to papers
        needed for your manuscript (including open access), online writing tools such
        as <a href=\"https://web.archive.org/web/20120612090221/http://www.buzzword.com/\">Buzzword</a>
        or <a href=\"https://web.archive.org/web/20120612090221/http://docs.google.com/\">Google
        Docs</a>, online tools for managing or sharing your references (e.g. <a href=\"https://web.archive.org/web/20120612090221/http://www.connotea.org/\">Connotea</a>
        or <a href=\"https://web.archive.org/web/20120612090221/http://www.refworks.com/\">Refworks</a>)
        and tools for collaboration and coordination (e.g. <a href=\"https://web.archive.org/web/20120612090221/http://www.basecamphq.com/\">Basecamp</a>).
        Right now, the different pieces don't quite fit together, but the potential
        is there for tremendous savings of time and money. And that is attractive.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ What is a PhD in Germany? ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/what-is-a-phd-in-germany/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwa1</id>\n
        \       <published>2008-03-14T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T07:06:31.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Nature News this week <a href=\"https://web.archive.org/web/20120612090323/http://www.nature.com/news/2008/080312/full/452138a.html\">reports</a>
        that</p><blockquote>Seven US-educated scientists working at the Max Planck
        Society's institutes are facing criminal charges for impersonating a doctor.</blockquote><p>This
        extremely embarrassing story is fortunately no longer possible. The German
        Kultusministerkonferenz decided on <a href=\"https://web.archive.org/web/20120612090323/http://www.kmk.org/aktuell/pm080306c.htm\">March
        6</a> (text in German) to allow U.S. PhDs to call themselves Dr. in Germany.
        Until this story <a href=\"https://web.archive.org/web/20120612090323/http://blogs.wsj.com/health/2008/03/07/who-are-you-calling-doctor/\">evolved</a>,
        I didn't even know that this is an issue.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Happy Pi Day ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/happy-pi-day/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cwa0</id>\n        <published>2008-03-14T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T07:07:37.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>To celebrate the annual <a
        href=\"https://web.archive.org/web/20120612093017/http://www.exploratorium.edu/pi/\">Pi
        Day</a>, and in the good tradition of geeky <a href=\"https://web.archive.org/web/20120612093017/http://bio-rad.cnpg.com/lsca/videos/ScientistsForBetterPCR/\">music
        by scientists</a>, I would like to draw your attention to the <a href=\"https://web.archive.org/web/20120612093017/http://www.youtube.com/watch?v=8g_6yBKDLWs\">American
        Pi Song</a> (lyrics are found <a href=\"https://web.archive.org/web/20120612093017/http://www.math.utep.edu/Faculty/lesser/americanpi.html\">here</a>),
        best listened to at 1:59 PM today.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ How to COPE with uniform requirements ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/how-to-cope-with-uniform-requirements/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw9z</id>\n        <published>2008-03-11T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-31T07:30:09.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>You have finished all the
        experiments and are in the middle of writing that wonderful manuscript that
        will change not only the field you are working in but also your personal career.
        But then you encounter all these complicated issues related to paper writing,
        including <a href=\"https://web.archive.org/web/20120612092424/http://network.nature.com/blogs/user/maxine/2008/02/08/duplicate-publication-7-february-2008\">duplicate
        publications</a>, <a href=\"https://web.archive.org/web/20120612092424/http://network.nature.com/forums/askthenatureeditor/788\">joint
        first authors</a>, <a href=\"https://web.archive.org/web/20120612092424/http://network.nature.com/blogs/user/rafaerts/2008/02/25/multi-authored-papers-i-thought-20-authors-was-a-lot\">multi-authored
        papers</a> and <a href=\"https://web.archive.org/web/20120612092424/http://network.nature.com/forums/neuroscience/1170\">paper
        rejections</a>.</p><p>You understand that these are sensitive ethical issues
        and you want to do the right thing. When is joint first authorship a problem,
        can I publish a paper a second time if it is written in another language,
        should my department head be a coauthor, etc. You will of course discuss these
        questions with your coauthors, but where else can you look for advice?</p><ul><li><em><em>Journal
        author guidelines.</em></em> The first and most useful place to look for advice,
        both for technical aspects, but also for ethical issues surrounding your manuscript.
        Author guidelines probably often are read too late (days before submission)
        and not carefully enough. The Editorial policies of <em><em>Nature</em></em>
        are found <a href=\"https://web.archive.org/web/20120612092424/http://www.nature.com/authors/editorial_policies/index.html\">here</a>.</li><li><em><em>ICMJE
        (International Commitee of Medical Journal Editors)</em></em>. The <a href=\"https://web.archive.org/web/20120612092424/http://www.icmje.org/index.html\">Uniform
        Requirements for Manuscripts Submitted to Biomedical Journals</a> could be
        the next place for advice. The text contains a lot of useful information for
        both authors and editors, including special reporting guidelines such as <a
        href=\"https://web.archive.org/web/20120612092424/http://www.consort-statement.org/index.aspx?o=1011\">CONSORT</a>
        for randomized controlled trials.</li><li><em><em>COPE (Committee on Publication
        Ethics)</em></em> <a href=\"https://web.archive.org/web/20120612092424/http://www.publicationethics.org.uk/\">COPE</a>
        is another useful resource that I recently discovered. I especially like the
        Case section, where real-life examples such as <a href=\"https://web.archive.org/web/20120612092424/http://www.publicationethics.org.uk/cases/zeroseventwo\">ghost
        authorship</a> or <a href=\"https://web.archive.org/web/20120612092424/http://www.publicationethics.org.uk/cases/onethreetwo\">reviewer
        competing interests</a> are discussed.</li></ul><p>If there are still open
        questions after reading these guidelines, join the regular discussion in the
        Nature Network blogs and forums on these topics, most recently <a href=\"https://web.archive.org/web/20120612092424/http://network.nature.com/forums/neuroscience/1170\">Nobel
        prize-winning lab retracts paper from Nature</a> in th</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Experimental Travel ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/experimental-travel/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw9y</id>\n
        \       <published>2008-03-06T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-15T14:32:19.000+00:00</updated>\n\t\t<category
        term=\"Book Review\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/348337.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/348337.jpeg\"></p><p>Today
        is <a href=\"https://web.archive.org/web/20120612091432/http://www.worldbookday.com/\">World
        Book Day</a>, at least in the United Kingdom. So I wanted to join my fellow
        NN Bloggers in our newest <em><em>SynchroBlogging</em></em> effort and wrote
        this post about science and books. I decided to write about the last book
        I bought \u2013 which was yesterday.</p><p>The book is in German and is called
        <em><em>Italien \u2013 Kurzes Reisehandbuch von Karl Baedeker</em></em>. The
        Baedeker series of travel guides (this one is about Italy) is still popular,
        but was started around 150 years ago. My book is the third edition and was
        printed in 1895. I will be traveling to the Amalfi Coast near Naples for my
        Easter holiday and I thought this would be a good opportunity to do some experimental
        tourism.</p><p><a href=\"https://www.lonelyplanet.com/experimentaltravel/\">Experimental
        Travel</a> is a playful new way of traveling that I learned about exactly
        one year ago on March 6 (another good reason for this post) when I bought
        <a href=\"https://web.archive.org/web/20120612091432/http://shop.lonelyplanet.com/product_detail.cfm?productID=2738\">this</a>
        book in a bookstore in Auckland on my first vacation day in New Zealand. The
        books describes many travel experiments and laboratory results, including</p><ul><li><em><em>Airport
        tourism</em></em>. Spend 24 hours in an airport without getting on a plane</li><li><em><em>Confluence
        seeking</em></em>. Visit ordered points such as exactly 35\xB0 S / 117\xB0
        E using a GPS device</li><li><em><em>Mascot travel</em></em>. Take pictures
        of your mascot outside famous landmarks, made famous by the French movie <a
        href=\"https://web.archive.org/web/20120612091432/http://movies.nytimes.com/movie/244109/Am-lie/overview\">Amelie</a>.</li></ul><p>The
        experiment I wanted to do since reading this book was historic travel, i.e.
        traveling with the help of a guidebook from a different time. Italy is perfect
        for that, because my 1895 guidebook can still be very useful for many places
        I will be visiting. <a href=\"https://web.archive.org/web/20120612091432/http://en.wikipedia.org/wiki/Pompei\">Pompei</a>
        is a good example. I will try to write lab notes and report on the outcome
        of the experiment.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Are posters worth the effort? ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/are-posters-worth-the-effort/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw9x</id>\n        <published>2008-03-01T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-01T05:31:09.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Posters are
        an important tool to communicate your research findings to a larger audience.
        The format is different from oral presentations or full papers, and <a href=\"https://web.archive.org/web/20120612094621/http://www.ploscompbiol.org/article/info:doi/10.1371/journal.pcbi.0030102\">special
        rules</a> for a good poster apply. Posters can be an important step before
        a full publication, although many posters will <a href=\"https://web.archive.org/web/20120612094621/http://www.ncbi.nlm.nih.gov/sites/entrez?db=pubmed&amp;uid=17296415\">never</a>
        be peer-reviewed and published.</p><p>The problem with posters is that they
        are second class citizens to oral presentations in most meetings. My personal
        experience with posters, both my own work and posters from others, has been
        mixed. In some meetings the poster presentation was a relaxed event (including
        beer and brezels in the last meeting) with good discussions in front of the
        poster, but often the poster presentation is not much more than a trick to
        increase conference attendance.</p><p>A <a href=\"https://web.archive.org/web/20120612094621/http://www.aerzteblatt-international.de/int/article.asp?src=search&amp;id=58801\">recent
        paper</a> (link to english version) in the German journal <em><em>Deutsches
        </em>\xC4<em>rzteblatt</em></em> systematically interviewed poster authors
        and attendees at a German meeting. This meeting used the format of a moderated
        poster presentation. The attendance in the poster presentations was very low,
        but was valued by younger scientists and by the moderators. One third of the
        posters had already been presented at another meeting, an issues that touches
        the problem of duplicate papers that we recently discussed <a href=\"https://web.archive.org/web/20120612094621/http://network.nature.com/forums/harvardpublishingforum/954\">here</a>
        on Nature Network. In <a href=\"https://web.archive.org/web/20120612094621/http://www.ncbi.nlm.nih.gov/sites/entrez?db=pubmed&amp;uid=17296415\">another
        study</a>, 12% of the posters had already been published as full paper at
        the time of the meeting.</p><p>In my opinion poster presentations are an important
        part of every scientific meeting. They should be taken seriously by using
        a competitive peer review process, including the rejection of abstracts that
        have already been presented or published. And they should be allowed enough
        space and time in the meeting schedule. Maybe we could also come up with new
        formats (e.g. this <a href=\"https://web.archive.org/web/20120612094621/http://www.ncbi.nlm.nih.gov/pubmed/18246386\">video
        in poster</a>) that make the poster presentation both fun and scientifically
        engaging.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Should Peer Review be confidential? ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/should-peer-review-be-confidential/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw9w</id>\n        <published>2008-02-23T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-13T13:30:27.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Donald Kennedy, the edior-in-chief
        of Science, yesterday wrote an <a href=\"https://web.archive.org/web/20120611110359/http://www.sciencemag.org/cgi/content/summary/319/5866/1009\">editorial</a>
        about a legal dispute between the <a href=\"https://web.archive.org/web/20120611110359/http://www.nejm.org/\">New
        England Journal of Medicine</a> and the drug company <a href=\"https://web.archive.org/web/20120611110359/http://www.pfizer.com/\">Pfizer</a>.
        Pfizer wants the NEJM to provide the reviewer comments on submitted papers
        about the two Pfizer products celecoxib (Celebrex) and valdecoxib (Bextra).
        Both drugs are used to treat pain and belong to the COX-2 inhibitor class
        of drugs. Rofecoxib (Vioxx) is another COX-2 inhibitor produced by Merck.
        Rofecoxib and valdecoxib, but not celecoxib were withdrawn from the market
        about three years ago because of an increased risk of cardiovascular side
        effects, including heart attacks.</p><p>Research findings about cardiovascular
        side effects of COX-2 inhibitors are at the center of the dispute and Pfizer
        is now seeking arguments for their case not just from published papers but
        also in confidential peer reviews and manuscripts that were rejected. This
        legal dispute is important because it touches central aspects of the peer
        review process.</p><p>The findings of scientific papers can have consequences
        not only to the scientific community involved, but also for the personal fortunes
        of their authors (e.g. new jobs or grants), the treatment of patients, our
        policies towards climate change \u2013 or the profit of a drug company. With
        that much at stake, the temptation to move the scientific argument from the
        editorial office to the courtroom is there. We should resist this temptation,
        or the peer review process and the way we communicate science will never be
        the same again.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ An easy online list of all your publications
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/an-easy-online-list-of-all-your-publications/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw9v</id>\n        <published>2008-02-22T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-31T07:29:25.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>There are many reasons to
        list all your publications online. Maybe you are looking for a new job or
        want to attract students to start their PhD in your lab. Usually you find
        this information on the home page of your laboratory or department, but several
        tools can automate this process.</p><h3 id=\"nature-network\">Nature Network</h3><p>You
        can list your publications in your Nature Network profile. Simply add the
        DOI or Pubmed ID in the <a href=\"https://web.archive.org/web/20120611110316/http://network.nature.com/publications/new\">form</a>
        provided. (Some of) my publications are listed <a href=\"https://web.archive.org/web/20120611110316/http://network.nature.com/profile/mfenner/publications\">here</a>.</p><h3
        id=\"facebook\">Facebook</h3><p><a href=\"https://web.archive.org/web/20120611110316/http://www.facebook.com/\">Facebook</a>
        has a similar feature for those unfortunate souls not yet on Nature Network.
        Use the Facebook application <a href=\"https://web.archive.org/web/20120611110316/http://apps.facebook.com/medlinepublications/\">Medline
        Publications</a>.</p><h3 id=\"google-scholar\">Google Scholar</h3><p>Only
        Facebook members can see your Medline publications. But everybody can use
        Google Scholar. My publications are listed <a href=\"https://web.archive.org/web/20120611110316/http://scholar.google.com/scholar?hl=de&amp;lr=&amp;q=autor%3A%22mh+fenner%22\">here</a>.</p><h3
        id=\"pubmed\">Pubmed</h3><p>Why not use the original? Use the search term
        \u201CFenner MH\u201D[Author]. My publications are listed <a href=\"https://web.archive.org/web/20120611110316/http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&amp;Cmd=Search&amp;Term=%22Fenner%20MH%22%5BAuthor%5D\">here</a>.</p><h3
        id=\"scopus\">Scopus</h3><p>Searches in Google Scholar and Pubmed search by
        name. This means that the links above don't work if your name is not unique.
        <a href=\"https://web.archive.org/web/20120611110316/http://www.scopus.com/\">Scopus</a>
        uses a unique author ID to overcome these problems. My author ID: 7006600833
        and 7006600825. If you have more than one author ID (as in my case), you can
        ask Scopus to merge them together into one author ID. Scopus also provides
        an <a href=\"https://web.archive.org/web/20120611110316/http://searchapidocs.scopus.com/\">API</a>
        to create mashups with other data. One example is <a href=\"https://web.archive.org/web/20120611110316/http://info.scopus.com/scsearchapi/geoCitations/index.html\">this</a>
        mashup with Google Maps that shows a map of the most highly cited papers by
        subject area. The problem with Scopus? You have to sign up for a user account
        to use Scopus.</p><h3 id=\"researcherid\">ResearcherID</h3><p>The new kid
        on the block. ResearcherID is currently only available to <a href=\"https://web.archive.org/web/20120611110316/http://isiwebofknowledge.com/\">ISI
        Web of Knowledge</a> users, for all others it is invitation only. But everybody
        can access your publications. My researcherID is A-7225-2008 and the list
        of my publications can be found <a href=\"https://web.archive.org/web/20120611110316/http://www.researcherid.com:80/rid/A-7225-2008\">here</a>.</p><p>The
        problem with ResearcherID? ResearcherID is tightly integrated with other Thomson
        Scientific products. You need a ISI Web of Knowledge account to add papers,
        Or you can import your citations from a RIS file, a file format from the Thomson
        Scientific <a href=\"https://web.archive.org/web/20120611110316/http://www.refman.com/\">Reference
        Manager</a>.</p><p>As you can see, all these tools have their shortcomings.
        Pubmed and Google Scholar fall short, because searching by name just doesn't
        work. Scopus and ResearcherID are nice and provide additional features, e.g.
        the Hirsch number or citations of your papers. But the commercial interests
        of Elsevier and Thomson Scientific have introduced important limitations.</p><p>So
        for the time being, the best tool is <em><em>Nature Network</em></em>. And
        there is great potential for improvements, e.g. integration with <a href=\"https://web.archive.org/web/20120611110316/http://www.connotea.org/\">Connotea</a>
        or linking to coauthors that are also Nature Network members.</p><p>In related
        news, Ian Mulvany today announced on his Nature Network blog that Connotea
        is now <a href=\"https://web.archive.org/web/20120611110316/http://network.nature.com/blogs/user/U3DF456C6/2008/02/22/connotea-is-now-openid-enabled\">OpenID
        enabled</a>.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Are names important? ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/are-names-important/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw9t</id>\n
        \       <published>2008-02-17T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-13T13:29:25.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>A Nature News article last
        week talked about the confusion that happens if a number of authors have the
        same or similar names (<a href=\"https://web.archive.org/web/20120611110744/http://www.nature.com/news/2008/080213/full/451766a.html\">Scientific
        publishing: Identity crisis</a>). This is apparently a special issue in China
        because of the difficulties transliterating Chinese characters into English
        and the use of only a limited number of surnames. The Nature Nanotechnology
        \u2013 Asia Pacific and Beyond Forum has a discussion about this topic (<a
        href=\"https://web.archive.org/web/20120611110744/http://network.nature.com/forums/nnano/939\">What's
        in an Asian name?</a>).</p><p>The difficulties for German authors are much
        smaller, and this is probably true for other European languages. We do have
        a fair number of surnames, but umlauts in our names (e.g. in the very popular
        last name M\xFCller) are frequently lost. As <a href=\"https://web.archive.org/web/20120611110744/http://network.nature.com/profile/cesarsanchez\">Cesar
        Sanchez</a> pointed out in the Nature Nanotechnology discussion mentioned
        above, Pubmed started using diacritics, including umlauts, last year (<a href=\"https://web.archive.org/web/20120611110744/http://www.nlm.nih.gov/pubs/techbull/nd07/nd07_diacritics.html\">Diacritics
        in PubMed Displays and Searching</a>). And the American Physical Society started
        to allow Chinese, Japanese and Korean authors to use names in their own language
        (<a href=\"https://web.archive.org/web/20120611110744/http://pra.aps.org/PhysRevLett.99.230001\">Editorial:
        Which Wei Wang?</a>).</p><p>But the problem is the same. There are at least
        6 different <em><em>M. Fenner</em></em> in the MEDLINE database, one of them
        my cousin. Using the middle initial can help. I try to publish as <em><em>MH
        Fenner</em></em>, and very smart people will figure out that papers written
        by <em><em>H Fenner</em></em> are from my father. And what happens when you
        marry? My wife and I have different last names (which is uncommon in Germany)
        and one small reason was the scientific track record (including publications)
        connected to this name. Some of the other issues are nicely summarized in
        a PLOS post by Richard Cave (<a href=\"https://web.archive.org/web/20120611110744/http://www.plos.org/cms/node/133\">Unique
        Author Identification</a>, thanks Cesar Sanchez).</p><p>The solution? We need
        unique identifiers for authors. I recently wrote about <a href=\"https://web.archive.org/web/20120611110744/http://network.nature.com/blogs/user/mfenner/2008/01/21/thomson-scientific-launches-researcherid-to-uniquely-identify-authors\">ResearcherID</a>,
        one such effort announced this January by Thomson Scientific. The problem
        with ResearcherID is that author identity is a very sensitive issue and many
        people will be reluctant to rely on a private company for that. Elsevier is
        doing something similar in their Scopus database (<a href=\"https://web.archive.org/web/20120611110744/http://info.scopus.com/etc/authoridentifier/\">The
        Scopus Author Identifier</a>).</p><p>Author identifiers should really come
        from a neutral organization such as CrossRef (a publishing organization that
        brought us the DOI to uniquely identify a scientific paper). They held a meeting
        with various interested parties in February 2007 (<a href=\"https://web.archive.org/web/20120611110744/http://www.crossref.org/CrossTech/2007/02/crossref_author_id_meeting.html\">CrossRef
        Author ID meeting</a>). Because of the number of parties involved and the
        different issues, this is a very slow process. And what is the <a href=\"https://web.archive.org/web/20120611110744/http://www.nlm.nih.gov/\">U.S.
        Library of Medicine</a> doing on this issue? After all, they publish MEDLINE,
        the most important database of biomedical research.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ How Nature Network changed my life ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/how-nature-network-changed-my-life/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw9s</id>\n        <published>2008-02-14T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T07:05:28.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Nature Network turns one year
        old <a href=\"https://web.archive.org/web/20120611110926/http://blogs.nature.com/nautilus/2008/02/happy_birthday_nature_network.html\">today</a>
        and it's time to celebrate. We already have a number of interesting \u2013
        and entertaining \u2013 birthday celebrations. I want to contribute with my
        personal experience at Nature Network.</p><p>During the day I treat cancer
        patients and do cancer research at a German University hospital. But I have
        been interested in programming for many years, first with the Applescript
        language (I was involved with the <a href=\"https://web.archive.org/web/20120611110926/http://www.macscripter.net/\">Macscripter</a>
        website) and more recently <a href=\"https://web.archive.org/web/20120611110926/http://www.rubyonrails.org/\">Ruby
        on Rails</a>. Open sharing of resources and information using blogs and other
        tools is common in these communities.</p><p>I joined Nature Network last August.
        In May I had started a <a href=\"https://web.archive.org/web/20120611110926/http://blog.xartrials.com/\">science
        blog</a> on my on server, more as a personal experiment than a serious blogging
        effort. The inspiration came from an article by Laura Bonetta published in
        Cell entitled <a href=\"https://web.archive.org/web/20120611110926/http://www.cell.com/content/article/abstract?uid=PIIS0092867407005430\">Scientists
        enter the blogosphere</a>. Moving to Nature Network gave me a much wider audience,
        but also meant a commitment to a more serious blogging effort.</p><p>The topics
        I pick for my blog mostly relate to how the internet has changed the way we
        publish our scientific work. Writing regular blog posts about these topics
        has forced me to do a lot of background research and I have probably learned
        more than I would have by just reading papers and other people's blog posts
        or comments.</p><p>In the early 1990s, when Internet use was mostly by dialup
        and could cost $10 per hour, I was involved with the Compuserve network. I
        was an assistant Sysop with the MacUser Forum and we had message boards, chat
        and file downloads.</p><p>Nature Network has many of the same features, but
        with the technology of the 21st century. The community of fellow <a href=\"https://web.archive.org/web/20120611110926/http://network.nature.com/forums/nnbloggername/941\">NatWorkers</a>
        is one big reason to stick around here. Not only did I learn a lot from others,
        but is also just fun to learn about <a href=\"https://web.archive.org/web/20120611110926/http://network.nature.com/blogs/user/UE19877E8/2008/01/20/in-which-i-witness-the-dawn-of-a-new-advertising-era\">singing
        scientists</a> and houses in <a href=\"https://web.archive.org/web/20120611110926/http://network.nature.com/forums/nnbloggername/945?page=2\">Cromer</a>.</p><p>Did
        Nature Network change my life? At least a little bit already. I wish Nature
        Network a happy birthday.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Using RNA interference to identify genes
        that protect from cancer ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/using-rna-interference-to-identify-genes-that-protect-from-cancer/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw9r</id>\n        <published>2008-02-07T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-31T07:28:32.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Cancer is caused by genetic
        changes<sup><a href=\"https://web.archive.org/web/20120611110843/http://blogs.plos.org/mfenner/2008/02/07/using_rna_interference_to_identify_genes_that_protect_from_cancer/#fn1\">1</a></sup>.
        Oncogenes harbor activating mutations that cause or promote cancer, whereas
        tumor suppressor genes<sup><a href=\"https://web.archive.org/web/20120611110843/http://blogs.plos.org/mfenner/2008/02/07/using_rna_interference_to_identify_genes_that_protect_from_cancer/#fn2\">2</a></sup>
        protect from cancer. In this model, genetic changes in one copy of an oncogene,
        but both copies of a tumor suppressor gene are required to initiate cancer.
        This simple model is complicated by the fact that more than one genetic change
        is usually required to initiate cancer, and that other so called epigenetic
        changes (such as promoter hypermethylation) are also important.</p><p>Myelodysplastic
        syndromes are malignant disorders of the bone marrow that show insufficient
        production of blood cells and harbor the risk of progressing to acute myeloid
        leukemia. The 5q syndrome is a distinct subtype that is characterized by loss
        of genetic material at chromosome 5q31, a characteristic morphology of the
        bone marrow, and a fairly benign clinical course. We would expect to find
        a tumor suppressor gene in the deleted region on chromosome 5, but no genetic
        changes on the other allele of chromosome 5 could be detected. The traditional
        strategies to identify the genetic changes responsible for the 5q syndrome
        therefore didn't work.</p><p>Research by Benjamin Ebert et al. presented at
        the American Society of Hematology meeting in December and now published in
        Nature<sup><a href=\"https://web.archive.org/web/20120611110843/http://blogs.plos.org/mfenner/2008/02/07/using_rna_interference_to_identify_genes_that_protect_from_cancer/#fn3\">3</a></sup>
        claims to have finally identified the genetic change responsible for 5q syndrome.
        They used RNA interference to in turn knock out each of the 40 genes in the
        common deleted region on chromosome 5q31. They observed the phenotype of human
        hematopoetic progenitor cells transfected with short hairpin RNAs. The shRNA
        targeting the gene RPS14 recapitulated the phenotype of patients with 5q syndrome.</p><p>To
        confirm the role of RPS14 in 5q syndrome, RPS14 was overexpressed in hematopoetic
        cells from patients with 5q syndrome and indeed reverted the erythroid differentiation
        effect. Reduced expression or inactivating mutations of the one remaining
        RPS14 gene in 5q syndrome patients was ruled out by sequencing and gene expression
        profiling.</p><p>Further evidence for the importance of RPS14 in 5q syndrome
        comes from studies of related genes. Expression of RPS14 is required for proper
        function of the 40s ribosomal subunit. Germline mutations of two other ribosomal
        proteins, RPS19 and RPS24, have been identified in the congenital disorder
        Diamond-Blackfan anemia, and the disease in these children has similar features.</p><p>As
        a medical student, I was fortunate enough to listen to Alfred Knudson give
        a talk about is two-hit hypothesis of tumor suppressor genes<sup><a href=\"https://web.archive.org/web/20120611110843/http://blogs.plos.org/mfenner/2008/02/07/using_rna_interference_to_identify_genes_that_protect_from_cancer/#fn2\">2</a></sup>,
        and I was fascinated by cancer genetics ever since. Genetics continues to
        be a driving force in our understanding of cancer. The next big step in the
        5q syndrome story will be a better understanding of why the drug lenalidomide
        works so well in this disease, and how this relates to RPS14 function. More
        information about the Ebert paper can be found in this Nature <a href=\"https://web.archive.org/web/20120611110843/http://www.nature.com/nature/journal/v451/n7176/full/451252a.html\">News
        and Views</a> article.</p><p>fn1. <a href=\"https://web.archive.org/web/20120611110843/http://content.nejm.org/cgi/content/short/358/5/502\">Croce
        C. Oncogenes and Cancer</a></p><p>fn2. <a href=\"https://web.archive.org/web/20120611110843/http://www.pubmedcentral.nih.gov/articlerender.fcgi?tool=pubmed&amp;pubmedid=5279523\">Knudson
        AG. Mutation and Cancer: Statistical Study of Retinoblastoma</a></p><p>fn3.
        <a href=\"https://web.archive.org/web/20120611110843/http://www.nature.com/nature/journal/v451/n7176/full/nature06494.html\">Ebert
        BL et al. Identification of RPS14 as a 5qsyndrome gene by</a><br><a href=\"https://web.archive.org/web/20120611110843/http://www.nature.com/nature/journal/v451/n7176/full/nature06494.html\">RNA
        interference screen</a></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Just Science starts tomorrow ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/just-science-starts-tomorrow/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw9q</id>\n        <published>2008-02-03T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-31T07:27:41.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p><a href=\"https://web.archive.org/web/20120611110608/http://www.justscience.net/2008/?page_id=1368\">Just
        Science</a> is an effort to collect blog posts about science that are written
        within one week. Just Science 2008 will start <a href=\"https://web.archive.org/web/20120611110608/http://scienceblogs.com/gnxp/2008/01/just_science_announcement.php\">tomorrow</a>
        and ends February 8. Science bloggers that agree to participate should write
        one daily blog entry for these five days. The blog entries should talk about
        science, and not about topic related to science (e.g. open access). Interested
        readers can subscribe to the <a href=\"https://web.archive.org/web/20120611110608/http://www.justscience.net/2008/?feed=rss2\">RSS
        Feed</a> and will automatically receive all blog posts.</p><p>The recently
        launched <a href=\"https://web.archive.org/web/20120611110608/http://www.researchblogging.org/\">Research
        Blogging</a> is a related effort to aggregate blog posts about science.</p><p>Like
        many other science bloggers, I do not write directly about science, but rather
        about issues that are important for scientists. I have so far been reluctant
        to blog about science. Why is that? Jon Udell two weeks ago wrote a <a href=\"https://web.archive.org/web/20120611110608/http://blog.jonudell.net/2008/01/22/bloggers-talk-to-bloggers-scientists-talk-to-scientists/\">blog
        post</a> where he observes that bloggers talk to bloggers and scientists talk
        to scientists. I agree with him that we need better tools to integrate scientific
        publishing and the blogosphere.</p><p>But more importantly, many Scientists
        (including myself) are still reluctant to talk about their science in the
        blogosphere. This is understandable if you have unpublished results, half-baked
        ideas, etc that are not yet ready to be shared with the scientific community.
        But non-scientists usually don't read the scientific literature, as most papers
        are difficult to impossible to understand \u2013 and access to scientific
        literature can be expensive. We shouldn't forget to communicate our research
        to the community. If we don't do that, we shouldn't be surprised if the traditional
        media either don't report our research at all, or give a distorted view that
        we are not happy with.</p><p>Having said that, I don't have have any immediate
        plans to blog about science. My area of expertise is cancer research, and
        talking about cancer research is even more complicated because of often unrealistic
        expectations that these findings quickly translate into new treatment options
        for patients.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Duplicate Papers: another trick to improve
        your publication record ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/duplicate-papers-another-trick-to-improve-your-publication-record/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw9p</id>\n        <published>2008-01-24T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T19:31:28.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Nature today <a href=\"https://web.archive.org/web/20120611092517/http://www.nature.com/doifinder/10.1038/451397a\">published</a>
        a report on the prevalence of duplicate papers in Medline. In this report
        Mounir Errami and Harold Garner estimate that there as many as 200.000 duplicate
        papers in Medline or 1% of all published papers.</p><p>The article has already
        been widely cited, including of course <a href=\"https://web.archive.org/web/20120611092517/http://www.nature.com/news/2008/080123/full/news.2008.520.html\">Nature
        News</a> and <a href=\"https://web.archive.org/web/20120611092517/http://network.nature.com/forums/harvardpublishingforum/954\">Nature
        Network</a>, but also <a href=\"https://web.archive.org/web/20120611092517/http://feeds.arstechnica.com/~r/arstechnica/science/~3/221820549/something-rotten-in-the-state-of-scientific-publishing\">Noble
        Intent</a> and <a href=\"https://web.archive.org/web/20120611092517/http://feeds.feedburner.com/~r/DigitalKoans/~3/222411428/\">DigitalKoans</a>.</p><p>The
        original paper by Errami and Garner was published in <a href=\"https://web.archive.org/web/20120611092517/http://bioinformatics.oxfordjournals.org/cgi/content/full/24/2/243\"><em>Bioinformatics</em></a>.
        They used the search engine eTBLAST to find duplicate papers and deposited
        the results in a database called <a href=\"https://web.archive.org/web/20120611092517/http://spore.swmed.edu/dejavu/\">Deja
        Vu</a>. When you search Deja Vu for scientists you know, you find scary results.</p><p>Nobody
        likes duplicate papers, but it's just another trick to improve your publication
        record. Another popular trick is the <a href=\"https://web.archive.org/web/20120611092517/http://www.nature.com/embor/journal/v8/n11/full/7401095.html\">inflation</a>
        of paper authors. But the basic trick is still the heavy use of the <a href=\"https://web.archive.org/web/20120611092517/http://chronicle.com/jobs/2004/02/2004020901c.htm\">least
        publishable unit</a> or LPU.</p><p>Both authors and journals are inclined
        to publish as many papers as possible. So what will change these practices?
        If the quality of the work of a scientist isn't simply measured by numerical
        indices such as number of publications. So it's up to those that decide about
        grants and jobs to find a better way to pick up the best scientists.</p><p>Corie
        Lok has <a href=\"https://web.archive.org/web/20120611092517/http://network.nature.com/forums/harvardpublishingforum/954\">started</a>
        a discussion about this topic in the <em><em>Publishing in the New Millenium
        Forum</em></em>, please post your comments there.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Scientific writers can help publish good
        papers ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/scientific-writers-can-help-publish-good-papers/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw9n</id>\n        <published>2008-01-23T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-01T11:57:01.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Advice by your supervisor,
        <a href=\"https://web.archive.org/web/20120611092138/http://network.nature.com/blogs/user/mfenner/2007/09/30/books-about-scientific-writing\">books</a>,
        <a href=\"https://web.archive.org/web/20120611092138/http://network.nature.com/blogs/user/mfenner/2007/11/26/can-a-workshop-improve-your-scientific-writing\">workshops</a>
        and <em><em>a lot</em></em> of experience can improve the quality of your
        scientific writing. But when you are about to submit your paper and don't
        want to take any chances \u2013 especially when English is not your first
        language \u2013 a scientific writer can be helpful. You can pay someone to
        do this, but even better would be a scientific writer that is employed by
        your university or research organization (I've written about this <a href=\"https://web.archive.org/web/20120611092138/http://network.nature.com/topics/show/567?page=2\">before</a>).</p><p>Not
        many institutions in Germany have the resources (or vision) to hire such a
        person. I was therefore glad to see a job posting for a scientific writer
        at the <a href=\"https://web.archive.org/web/20120611092138/http://www.mpiib-berlin.mpg.de/\">Max
        Planck Institute for Infection Biology</a> in Berlin, Germany. More institutions,
        including of course my own university, should follow this example. (Disclaimer:
        I'm not affiliated with the Max Planck Institute in any way. I worked across
        the street for five years).</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Thomson Scientific launches ResearcherID
        to uniquely identify authors ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/thomson-scientific-launches-researcherid-to-uniquely-identify-authors/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw9m</id>\n        <published>2008-01-21T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-01T11:56:02.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Thomson Scientific last week
        <a href=\"https://web.archive.org/web/20120611092246/http://scientific.thomson.com/press/2008/8429910/\">announced</a>
        <em><em>ResearcherID</em></em>. ResearcherID tries to solve a problem that
        has annoyed me for many years. In contrast to papers and journals, authors
        are not associated with a unique ID in databases such as PubMed. You are lucky
        if you have an uncommon last name that contains only letters from the English
        alphabet. For the rest of us, a typical PubMed search for your name will also
        pick up papers by other authors. In my case for example papers by my cousin
        Mathias Fenner.</p><p>The missing unique ID for authors makes it impossible
        to automate the creation of publication lists for authors or insitutions.
        You already can get email alerts or RSS feeds of papers published by a specific
        person (colleague or competitor), but without unique ID, this is tricky. ResearcherID
        will also automate the maintenance of your <a href=\"https://web.archive.org/web/20120611092246/http://network.nature.com/blogs/user/mfenner/2007/08/17/do-you-know-your-hirsch-number\">Hirsch
        number</a> (for those interested in this kind of metric).</p><p>Scientists
        interested in ResearcherID should register at the <a href=\"https://web.archive.org/web/20120611092246/http://www.researcherid.com/\">reseacherID.com</a>
        website. Registration is currently by invitation only.</p><p>There is one
        major problem with ResearcherID. It is not clear from the press release of
        who owns and controls this information. This is a very sensitive issue and
        Thomson Scientific a major player in this field. Remember <a href=\"https://web.archive.org/web/20120611092246/http://www.passport.net/\">Microsoft
        Passport</a>? The majority of web users was uncomfortable having a central
        user ID and password managed by Microsoft. The service eventually failed,
        and we now have the open standard <a href=\"https://web.archive.org/web/20120611092246/http://openid.net/\">Open
        ID</a>. Similarly, ResearcherID can only work if the user database is either
        shared openly or hosted by someone like the NIH.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Microsoft Office 2008 for Mac released ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/microsoft-office-2008-for-mac-released/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw9k</id>\n        <published>2008-01-20T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T07:04:22.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>January is an important month
        for Macintosh users. <a href=\"https://web.archive.org/web/20120611092917/http://www.macworldexpo.com/\">MacWorld
        Expo</a> takes place every year in San Francisco and we usually see a lot
        of new software and hardware. The <a href=\"https://web.archive.org/web/20120611092917/http://www.apple.com/macbookair/\">MacBook
        Air</a> is a wonderful new subnotebook perfect for successful scientists with
        many talks to give and enough money to spend.</p><p>But <a href=\"https://web.archive.org/web/20120611092917/http://www.microsoft.com/mac/products/Office2008/default.mspx\">Microsoft
        Office 2008 for Mac</a> is probably the most important new product from a
        scientists perspective. If you live in the U.S., you can buy Office right
        now, us international users will have to wait a few weeks. Office 2008 runs
        natively (i.e. much faster) on Intel Macs, so everybody with those newer Macs
        wants to upgrade for that reason alone. Powerpoint and Excel are important,
        but Microsoft Word is the application I use most of the time.</p><p>Microsoft
        Word 2008 has a new feature called <a href=\"https://web.archive.org/web/20120611092917/http://www.appleinsider.com/articles/07/11/14/road_to_mac_office_2008_word_08_vs_pages_3_0.html&amp;page=3\">citations</a>,
        basically a simple reference manager. This feature first appeared in Office
        2007 for Windows. Citations integrates nicely with your Word document, but
        can't handle the more sophisticated needs of a research paper, e.g. automatic
        importing form online databases and dozens of reference styles for all the
        journals you possibly want to submit to.</p><p>Unfortunately you can't use
        the current version of <a href=\"https://web.archive.org/web/20120611092917/http://www.endnote.com/\">Endnote</a>
        with Microsoft Word 2008. Thomson Scientific (the Endnote publisher) is <a
        href=\"https://web.archive.org/web/20120611092917/http://www.endnote.com/support/en_wpchart_mac.asp\">working</a>
        on a version for Microsoft Word 2008. The update is made more difficult by
        the fact that support for Visual Basic for Applications (VBA) was dropped
        in Office 2008. The alternative reference managers <a href=\"https://web.archive.org/web/20120611092917/http://www.sonnysoftware.com/\">Bookends</a>
        and <a href=\"https://web.archive.org/web/20120611092917/http://www.thirdstreetsoftware.com/\">Sente</a>
        also currently don't work with Microsoft Word 2008.</p><p>Microsoft Word 2008
        by default uses the new XML-based .docx format introduced in Office 2007 for
        Windows. This format was originally not supported by Nature, Science and other
        STM publishers (read <a href=\"https://web.archive.org/web/20120611092917/http://blogs.nature.com/wp/nascent/2007/06/word_2007_and_the_stm_publishe.html\">this</a>
        Nascent post for the reasons behind it). Nature is <a href=\"https://web.archive.org/web/20120611092917/http://www.nature.com/nature/authors/submissions/template/index.html\">now
        able to accept</a> Word 2007 (and Word 2008) files, but this might not necessarily
        be true for other publishers.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Should all papers be published in English?
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/should-all-papers-be-published-in-english/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw9j</id>\n        <published>2008-01-16T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T07:03:16.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>The <a href=\"https://web.archive.org/web/20120611092755/http://www.aerzteblatt.de/\">Deutsche
        \xC4rzteblatt</a> is the official journal of the German Medical Association,
        just as the <a href=\"https://web.archive.org/web/20120611092755/http://blogs.plos.org/mfenner/2008/01/16/should_all_papers_be_published_in_english/http.//ww.bmj.com\">British
        Medical Journal</a> (BMJ) and the <a href=\"https://web.archive.org/web/20120611092755/http://jama.ama-assn.org/\">Journal
        of the American Medical Association</a> (JAMA). Starting January 21, an <a
        href=\"https://web.archive.org/web/20120611092755/http://www.aerzteblatt-international.de/\">English
        language version</a> of the journal will be available.</p><p>The publisher
        and editors of the journal decided to make this step to have the journal articles
        better indexed in databases such as <a href=\"https://web.archive.org/web/20120611092755/http://www.pubmed.gov/\">PubMed</a>
        and available to more readers. This should lead to more citations of journal
        articles, resulting in a better Impact Factor and reputation of the journal.</p><p>100
        years ago, German was an important scientific language, but now only 2% of
        journals indexed in Medline are in German. I personally haven't written a
        scientific paper in German for many years. I sometimes regret that I can't
        use German (or French or Italian for that matter) to report by findings or
        express my ideas. But in the end it makes the exchange of ideas between scientists
        much easier if we can all use the same language. And Nature Network is a good
        example for this.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Science 2.0: the Scientific American perspective
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/science-2-0-the-scientific-american-perspective/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw9h</id>\n        <published>2008-01-13T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T19:29:18.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>M. Mitchell Waldrop has posted
        a draft version of an article called <a href=\"https://web.archive.org/web/20120611092539/http://www.sciam.com/article.cfm?id=science-2-point-0-great-new-tool-or-great-risk\">Science
        2.0: Great New Tool, or Great Risk?</a>. The article will appear in <a href=\"https://web.archive.org/web/20120611092539/http://www.sciam.com/\">Scientific
        American</a> (which, like the Nature Publishing Group, is owned by Macmillan).
        In this article he talks about the increasing use of Web 2.0 technologies
        in research. The largest part of the article is about Open Notebook Science
        and <a href=\"https://web.archive.org/web/20120611092539/http://openwetware.org/wiki/Main_Page\">OpenWetWare</a>
        in particular. But he also talks about science blogs and other Web 2.0 efforts
        such as Nature Network, which is mentioned briefly at the end of the article.</p><p>The
        draft article was posted online last week. In true Web 2.0 spirit, M. Mitchell
        Waldrop has invited readers to post comments and promised that he will use
        them for the final print version. I wrote a comment and suggested that the
        increasing role of Web 2.0 companies such as Google, Microsoft and Adobe in
        the online creation and distribution of science should be mentioned in the
        article.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Is Google Scholar use declining? ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/is-google-scholar-use-declining/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw9g</id>\n        <published>2008-01-12T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T19:25:47.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>I'm a regular reader of <a
        href=\"https://web.archive.org/web/20120611093258/http://www.techcrunch.com/\">TechCrunch</a>,
        a popular blog about internet products and companies. But somehow I missed
        the <a href=\"https://web.archive.org/web/20120611093258/http://www.techcrunch.com/2007/12/22/2007-in-numbers-igoogle-googles-homegrown-star-performer-this-year/\">article</a>
        just before christmas that talks about the popularity of different Google
        products. In this analysis, traffic for <a href=\"https://web.archive.org/web/20120611093258/http://scholar.google.com/\">Google
        Scholar</a> was down 32% compared to 2006.</p><p>I haven't seen this information
        reproduced somewhere else, but the number for most of the other Google products
        were higher than 2006, as expected. And I don't have the numbers of searches
        in Google Scholar compared to <a href=\"https://web.archive.org/web/20120611093258/http://www.ncbi.nlm.nih.gov/sites/entrez\">PubMed</a>
        (you would have to buy this information from companies like <a href=\"https://web.archive.org/web/20120611093258/http://www.comscore.com/\">comScore</a>).
        But does this indicate that there is something wrong with Google Scholar?
        As a PubMed user for 15 years, I still like to get search results chronologically
        and not by (perceived) relevance. And I like the detailed search options and
        integration with other databases.</p><p>Other search engines in this field
        include <a href=\"https://web.archive.org/web/20120611093258/http://scirus.com/\">Scirus</a>
        from Elsevier and <a href=\"https://web.archive.org/web/20120611093258/http://academic.live.com/\">Windows
        Live Academic Search</a> from Microsoft. Incidentally, TechCrunch (and others)
        <a href=\"https://web.archive.org/web/20120611093258/http://www.techcrunch.com/2008/01/08/microsoft-has-announced-a-takeover-bid-for-fast-search-transfer-priced-at-12-billion/\">reports</a>
        this week that Microsoft is about to acquire <a href=\"https://web.archive.org/web/20120611093258/http://www.fastsearch.com/\">Fast
        Search &amp; Transfer</a>, the Norvegian company that provides the search
        technology to Scirus.</p><p>Some big company names, but for me Pubmed is still
        the first stop when searching for journal articles. And PubMed will become
        more important as the NIH now <a href=\"https://web.archive.org/web/20120611093258/http://network.nature.com/blogs/user/mfenner/2007/12/26/mandatory-open-access-for-nih-funded-research-signed-into-law\">requires</a>
        the deposition of all NIH-funded research papers in PubMed Central.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Tired of Impact Factors? Try the SJR indicator
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/tired-of-impact-factors-try-the-sjr-indicator/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw1t</id>\n        <published>2008-01-07T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T07:02:17.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Picking the right journal
        is one of the most important decisions when you start to work on a paper.
        You probably have a gut feeling of the journals that are best suited for your
        paper in progress. To make this decision more objective, you can rely on the
        <a href=\"https://web.archive.org/web/20170910200523/http://scientific.thomson.com/free/essays/journalcitationreports/impactfactor/\">Impact
        Factor</a> of a journal. The Impact Factor is roughly the average number of
        citations per paper in a given journal and is published by \_<a href=\"https://web.archive.org/web/20170910200523/http://scientific.thomson.com/index.html\">Thomson
        Scientic</a>. Higher Impact Factors mean more prestigious journals. This information
        is also frequently used for job or grant applications.</p><p>Impact factors
        have been around for more than 40 years and they generally been very helpful.
        But there are two big problems:</p><h3 id=\"impact-factors-are-published-by-one-privately-owned-company\">Impact
        Factors are published by one privately owned company</h3><p>Given the importance
        of Impact Factors for many aspects of scientific publishing, it would be preferable
        if there were alternatives. And Impact Factors are not freely available, but
        must be purchased from Thomson Scientific.</p><h3 id=\"impact-factors-might-not-be-the-best-tool-to-measure-scientific-quality\">Impact
        Factors might not be the best tool to measure scientific quality</h3><p>Impact
        factors have several shortcomings. Because they are a convenient way to judge
        the scientific output of a person, organization, journal or country, they
        are often overused. They should for example not be used to compare journals
        in different fields, e.g. cell biology and particle physics. Measures like
        the <a href=\"https://web.archive.org/web/20170910200523/http://network.nature.com/blogs/user/mfenner/2007/08/17/do-you-know-your-hirsch-number\">Hirsch
        Number</a> might be a better tool to measure the scientific output of an individual
        scientist. And sometimes the judgement of your peers in the field is more
        important than simple numbers.</p><p>The <a href=\"https://web.archive.org/web/20170910200523/http://www.scimagojr.com/\">SCImago
        Journal Rank</a> indicator tries to overcome these two shortcomings. The index
        was created by the <a href=\"https://web.archive.org/web/20170910200523/http://www.scimago.es/\">SCImage
        Research Group</a>, located at several Spanish universities. The index uses
        information from the <a href=\"https://web.archive.org/web/20170910200523/http://www.scopus.com/\">Scopus</a>
        abstract and citation database of research literature owned by <a href=\"https://web.archive.org/web/20170910200523/http://www.elsevier.com/\">Elsevier</a>.</p><p>In
        contrast to the Impact Factor, the SJR indicator measures not simply the number
        of citations per paper. Citations from a journal with a higher SJR indicator
        lead to a higher SJR indicator for the cited journal (more details <a href=\"https://web.archive.org/web/20170910200523/http://www.scimagojr.com/SCImagoJournalRank.pdf\">here</a>).
        This approach is similar to PageRank (described in <a href=\"https://web.archive.org/web/20170910200523/http://infolab.stanford.edu/~backrub/google.html\">this</a>
        paper), the algorithm for web searches by Sergey Brin and Lawrence Page that
        made <a href=\"https://web.archive.org/web/20170910200523/http://www.google.com/\">Google</a>
        what it is today. <a href=\"https://web.archive.org/web/20170910200523/http://www.eigenfactor.org/\">Eigenfactor</a>
        is another scientific ranking tool that uses a PageRank algorithm.</p><p>Most
        of the time, journals with high Impact Factors have high SJR indicators. Nature
        and Science are still head to head. We will find unexpected results and discrepancies
        between the two over time. In my field of oncology, both the Journal of the
        NCI and Cancer Research are ranked higher than the Journal of Clinical Oncology.</p><p>You
        can read more about the SJR indicator in this <a href=\"https://web.archive.org/web/20170910200523/http://www.nature.com/news/2008/080102/full/451006a.html\">Nature
        News article</a>.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Mandatory open access for NIH-funded research
        signed into law ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/mandatory-open-access-for-nih-funded-research-signed-into-law/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw9f</id>\n        <published>2007-12-26T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T07:01:20.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>U.S. President Bush today
        signed into law the <a href=\"https://web.archive.org/web/20120611091849/http://thomas.loc.gov/cgi-bin/bdquery/z?d110%3Ah.r.02764\">federal
        spending bill</a> that includes provisions for NIH-funded research. Final,
        peer-reviewed manuscripts of NIH-funded research have to be publicly available
        at <a href=\"https://web.archive.org/web/20120611091849/http://www.pubmedcentral.nih.gov/\">PubMed
        Central</a> no later than 12 months after publication.</p><p>The Open Access
        mandate for NIH-funded research was voluntary since 2005. Fewer than 5% of
        research papers were actually made publicly available. The process and discusson
        about making this requirement mandatory as part of the Fiscal Year 2008 Labor,
        HHS, and Education Appropriations Bill was going on for many months (as reported
        previously by <a href=\"https://web.archive.org/web/20120611091849/http://network.nature.com/blogs/user/mfenner/2007/10/24/u-s-senate-passed-bill-with-nih-open-access-mandate\">me</a>
        and others), including a lobbying effort to stop this mandate called <a href=\"https://web.archive.org/web/20120611091849/http://network.nature.com/blogs/user/mfenner/2007/08/26/prism-lobbying-against-open-access\">PRISM</a>.</p><p>A
        large part of biomedical research is funded by the NIH and this change in
        NIH policy will probably have a big impact on how most biomedical journals
        do their <a href=\"https://web.archive.org/web/20120611091849/http://www.nature.com/nature/focus/accessdebate/index.html\">business</a>.
        A wonderful christmas present for all scientists.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Writing a paper with Buzzword ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/writing-a-paper-with-buzzword/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw9e</id>\n        <published>2007-12-20T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T19:23:04.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p><a href=\"https://web.archive.org/web/20120611091413/http://www.buzzword.com/\">Buzzword</a>
        is a free online word processor based on the Adobe Flash technology. I <a
        href=\"https://web.archive.org/web/20120611091413/http://network.nature.com/blogs/user/mfenner/2007/09/27/more-on-online-writing-tools-buzzword-is-different\">previously</a>
        wrote about Buzzword and how it could be used to write a scientific paper.
        The first impressions were positive, so I decided to write my next paper with
        Buzzword. This paper has been submitted this week. What did I like and dislike
        about Buzzword?</p><h3 id=\"good\">Good</h3><p>Most importantly, there is
        only one version of your manuscript. You and your coauthors can simultaneously
        work on different parts of the manuscript, the software saves all versions
        of the text. Buzzword is very pleasant to use, thanks to the elegant interface.
        Importing and exporting to Microsoft Word is possible. And Buzzword is free.</p><h3
        id=\"bad\">Bad</h3><p>Buzzword doesn't handle references. You can create footnotes,
        but for referencing papers, you have to use another software. That's what
        I did in the final stages of manuscript writing, switching to Microsoft Word
        and Endnote. Buzzword doesn't show you the changes between different versions
        of a manuscript. This makes it difficult to see the changes that your coauthors
        made. Because Buzzword is an online word processor, you can't use it without
        an internet connection. One of my coauthors had Buzzword crashing several
        times, probably because of a slow internet connection.</p><h3 id=\"conclusions\">Conclusions</h3><p>Manuscript
        writing with Buzzword is fun. But without support for references and better
        version management, it is not ready for prime time.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Frustrations of a scientist ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/frustrations-of-a-scientist/\" />\n\t\t<id>https://doi.org/10.53731/8zrmqsp-p0196jf</id>\n
        \       <published>2007-12-09T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-14T15:10:01.000+00:00</updated>\n
        \       <media:content url=\"\" medium=\"image\"/>\n        <content type=\"html\"><![CDATA[
        <p><img src=\"\"></p><p>We usually look forward to a well-written paper about
        central aspects of your research. But sometimes you are frustrated. Maybe
        someone has done (almost) the same experiments, but was quicker in getting
        the work published. Then you can at least publish your results, probably in
        a less prestigous journal, to confirm these findings.</p><p>But when the just
        published paper comes to the opposite conclusions, and has done all the right
        experiments, your work can become almost worthless. This just happened to
        me with a <a href=\"https://web.archive.org/web/20120611091452/http://www.nature.com/nm/journal/v13/n12/abs/nm1672.html\">paper</a>
        in the December issue of Nature Medicine about the role PPARgamma in osteoclastogenesis.
        The group of Ronald Evans used mice with a conditional knockout of PPARgamma
        in osteoclasts to study the role of this nuclear hormone receptor in bone
        diseases. Their elegant work clearly shows that PPARgamma promotes osteoclast
        differentiation and activation.</p><p>Unfortunately we have very different
        results in a tissue culture model of osteoclast differentiation, consistent
        with previous publications. But it is hard to argue with a mouse model. We
        will carefully look at the data to decide where we go from here. But for now
        it's just frustrating.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ How many authors makes a good paper? ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/how-many-authors-makes-a-good-paper/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw9b</id>\n        <published>2007-11-20T00:00:00.000+00:00</published>\n\t\t<updated>2023-09-07T14:06:36.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>A recent Nature <a href=\"https://doi.org/10.1038/450001a\"
        rel=\"noreferrer\">article</a>, repeated in a Nautilus <a href=\"https://web.archive.org/web/20120611104641/http://blogs.nature.com/nautilus/2007/10/accountability_of_authors.html\">blog
        post</a>, talks about author accountability. The article suggests that at
        least one author per collaborative group signs a statement with reference
        to Nature's <a href=\"https://web.archive.org/web/20120611104641/http://www.nature.com/authors/editorial_policies/index.html\">publication
        policies</a>. This policy would certainly help avoid <em>honorary authorship</em>,
        but it can be difficult to enforce in large research projects.</p>\n<p>I would
        like to make another suggestion. The quality of a research paper should not
        only be judged by the number of citations it receives (which improves the
        <a href=\"https://web.archive.org/web/20120611104641/http://network.nature.com/blogs/user/mfenner/2007/08/17/do-you-know-your-hirsch-number\">Hirsch
        number</a> of the author), but also by the number of authors. There are of
        course research projects that are only possible with large numbers of collaborators,
        but many biomedical papers probably only need 2-4 authors, but rather have
        5-8 authors.</p>\n<p>One good rule of thumb is a number of papers published
        per year. If that number is too high (e.g. more than 10), then the author
        has probably not contributed significantly to all those papers. Department
        heads often fall into this category. These rules can easily be applied when
        reviewing job or grant applications.</p>\n<p>One of the most <a href=\"https://web.archive.org/web/20120611104641/http://www.cmaj.ca/cgi/content/full/163/6/716\">famous
        examples</a> for authorship not perused is the <a href=\"https://web.archive.org/web/20120611104641/http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1849809\">1922
        CMAJ paper</a> about the action of pancreatic extracts on blood sugar in diabetics.
        John MacLeod was not a coauthor, but rather thanked in the acknowledgements.
        As head of the department he provided mainly logistical support. He still
        went on to <a href=\"https://www.nobelprize.org/prizes/medicine/1923/macleod/lecture/\"
        rel=\"noreferrer\">win</a> the Nobel Prize for the discovery of insulin the
        following year.</p>\n<h2 id=\"references\">References</h2>\n<p>Who is accountable?
        (2007). <em>Nature</em>, <em>450</em>(7166), 1\u20131. <a href=\"https://doi.org/10.1038/450001a\">https://doi.org/10.1038/450001a</a></p>\n<p>John
        Hoey. (2000). Who wrote this paper anyway?: The new Vancouver Group statement
        refines the definition of authorship. <em>Canadian Medical Association Journal</em>,
        <em>163</em>(6), 716.</p>\n<p>Banting, F. G., Best, C. H., Collip, J. B.,
        Campbell, W. R., &amp; Fletcher, A. A. (1963). 7. Pancreatic Extracts in the
        Treatment of Diabetes Mellitus: Preliminary Report. In <em>Selected Papers
        of Charles H. Best</em> (pp. 89\u2013100). University of Toronto Press. <a
        href=\"https://doi.org/10.3138/9781442656918-011\">https://doi.org/10.3138/9781442656918-011</a></p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Can a workshop improve your scientific writing?
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/can-a-workshop-improve-your-scientific-writing/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw9c</id>\n        <published>2007-11-16T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T19:18:05.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>How could you improve your
        scientific writing skills? Two months ago I <a href=\"https://front-matter.io/mfenner/books-about-scientific-writing\">talked</a>
        about books. Another idea would be a scientific writing workshop. This weekend
        I attended such a workshop, organized by Julia Klapproth and Barry Drees from
        <a href=\"https://web.archive.org/web/20120611104747/http://www.trilogywriting.com/\">Trilogy
        Writing &amp; Consulting</a>.</p><p>The workshop was organized as a 1\xBD
        day course with many group exercises. We learned about good scientific language,
        tables and graphs and other typical aspects of manuscript writing. Stuff you
        will also find in books such as <a href=\"https://web.archive.org/web/20120611104747/http://www.cambridge.org/catalogue/catalogue.asp?isbn=9780521823234\">this
        one</a>. But a workshop is certainly a better learning experience \u2013 and
        more fun.</p><p>To my surprise the most important lesson was something else.
        Good scientific writing always has a message, targeted towards the audience.
        This is probably obvious for anybody with basic experience in journalism.
        But it is easier said than done when the results of your experiments are complicated
        and not easily fit into a model. I will try much harder to keep this in mind,
        e.g. by making sure that the abstract and tables/figures can speak for themselves.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Your next paper could be computer-generated
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/your-next-paper-could-be-computer-generated/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw9a</id>\n        <published>2007-11-13T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T19:15:04.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Are you tired of writing a
        paper, based on real experiments? <a href=\"https://web.archive.org/web/20120611103729/http://pdos.csail.mit.edu/scigen/\">SciGen</a>
        could come to the rescue, at least if you do computer science research. SciGen
        is a program that creates random papers, complete with results, discussion,
        graphs and references. Some of these random papers have been accepted at conferences
        or even for <a href=\"https://web.archive.org/web/20120611103729/http://pdos.csail.mit.edu/scigen/sharif_paper.pdf\">publication</a>.</p><p>SciGen
        is of course a hoax. There are other famous hoaxes in science, including the
        1996 <a href=\"https://web.archive.org/web/20120611103729/http://www.physics.nyu.edu/faculty/sokal/index.html\">Alan
        Sokal</a> paper \u201CTransgressing the Boundaries: Towards a Transformative
        Hermeneutics of Quantum Gravity\u201D.</p><p>What do these hoaxes have in
        common? They randomly generate pseudo-scientific language. Important ingredients
        are buzzword frequently used in the field and standard phrases. If we look
        carefully, we find examples of this random-talk in our own work as well.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ A case for Goobledygook ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/a-case-for-goobledygook/\" />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw99</id>\n
        \       <published>2007-11-11T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T07:00:12.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Today I decided to rename
        my blog from <em><em>Publish or Perish 2.0</em></em> to <em><em>Goobledygook</em></em>.
        The old name explained the topics of this blog pretty well, so why the change
        after only 4 months of blogging on Nature Network? And there are already <a
        href=\"https://web.archive.org/web/20120611103739/http://www.technorati.com/blogs/tag/gobbledygook\">many
        blogs</a> with the same name.</p><p>I simply like the new name. The word Goobledygook
        was invented by the U.S. congressman Maury Maverick and used in a New York
        Times <a href=\"https://web.archive.org/web/20120611103739/http://select.nytimes.com/gst/abstract.html?res=F40A10F83855157B93C3AB178ED85F408485F9\">article</a>
        published May 21, 1944. Maury Maverick was fed up with the vague, pompous
        and repetitive language used in Washington at the time and invented this new
        word for it. He was fighting against the all too common use of Gobbledygook.
        The following text is from his New York Times article:</p><blockquote>Plain
        and simple speech appeals to everyone because it indicates clear thought and
        honest motives. Here is the point: anyone who is thinking clearly and honestly
        can express his thoughts in words which are understandable, and in very few
        of them. Let's write for the reader and not for ourselves. Make the writing
        do what it is intended to.</blockquote><p>This text might as well be from
        a recent editorial about scientific writing. We had a very lively <a href=\"https://web.archive.org/web/20120611103739/http://network.nature.com/forums/askthenatureeditor/567\">discussion</a>
        about this topic in the <em><em>Ask the Nature Editor</em></em> Forum. I first
        came across the word Gobbledygook when I <a href=\"https://web.archive.org/web/20120611103739/http://network.nature.com/blogs/user/mfenner/2007/10/14/do-you-know-the-flesch-score-of-your-papers\">wrote</a>
        about readability tools. The Nature Literacy Trust has created such a tool
        and called it <a href=\"https://web.archive.org/web/20120611103739/http://www.literacytrust.org.uk/campaign/SMOG.html\">SMOG</a>
        or Simplified Measure of Gobbledygook.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ New version of Papers software released
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/new-version-of-papers-software-released/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw98</id>\n        <published>2007-11-06T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T06:59:19.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p><a href=\"https://web.archive.org/web/20120611104710/http://mekentosj.com/papers/\">Papers</a>
        is Macintosh-only software to manage the PDF files of all the scientific papers
        you stored on your computer. I previously <a href=\"https://web.archive.org/web/20120611104710/http://blog.xartrials.com/2007/5/1/papers-itunes-for-your-scientific-papers\">wrote</a>
        about version 1.0 that appeared earlier this year.The new Version 1.5 is compatible
        with <a href=\"https://web.archive.org/web/20120611104710/http://www.apple.com/macosx/\">Leopard</a>,
        the latest release of the Macintosh operating system. The biggest improvement
        is support for search engine plugins. With previous versions, only PubMed
        searches were possible, but now you can also search Google Scholar, Web of
        Science and others.</p><p>Papers is a wonderful piece of software that helps
        to organize the clutter of PDF files on your hard drive. My wish for version
        2.0: integration of RSS feeds from journal table of contents or custom PubMed
        searches.</p><p>For more information, visit the <a href=\"https://web.archive.org/web/20120611104710/http://network.nature.com/group/papers\">Papers
        Group</a> on Nature Network.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ STIX: Fonts for electronic and print publishing
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/stix-fonts-for-electronic-and-print-publishing/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw97</id>\n        <published>2007-11-04T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T06:58:22.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>The STIX Project has finally
        <a href=\"https://web.archive.org/web/20120611104808/http://www.stixfonts.org/StixFontsPR103107FINAL.pdf\">released</a>
        a first beta version of their fonts. STIX stands for Scientific and Technical
        Information Exchange and the fonts were designed specifically for publishing
        scientific or mathematical texts. The <a href=\"https://web.archive.org/web/20120611104808/http://www.stixfonts.org/\">STIX
        Project</a> was started more than 10 years ago and is a collaboration of the
        American Chemical Society (ACS), the American Institute of Physics (AIP),
        the American Mathematical Society (AMS), the American Physical Society (APS),
        Elsevier, and the Institute of Electrical and Electronics Engineers (IEEE).
        A typical scientific text written with the STIXGeneral font looks like this:</p><p>In
        biomedical research we need (mostly greek) symbols, but for mathematicians
        and physicists the needs are far more complicated. The final version of the
        STIX fonts should be released soon, and the fonts will be freely available.
        I wrote previously about the lack of symbol font support in online writing
        tools such as <a href=\"https://web.archive.org/web/20120611104808/http://network.nature.com/blogs/user/mfenner/2007/09/09/could-you-write-your-next-paper-with-google-docs\">Google
        Docs</a> and <a href=\"https://web.archive.org/web/20120611104808/http://network.nature.com/blogs/user/mfenner/2007/09/27/more-on-online-writing-tools-buzzword-is-different\">Buzzword</a>.
        The STIX fonts should be a tremendous help for them.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Poor media coverage of cancer research:
        are blogs one answer? ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/poor-media-coverage-of-cancer-research-are-blogs-one-answer/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw96</id>\n        <published>2007-10-28T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T19:13:07.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Kathy Redmond wrote an <a
        href=\"https://web.archive.org/web/20120630134958/http://www.nature.com/ncponc/journal/v4/n11/full/ncponc0977.html\">editorial</a>
        in the November issue of <a href=\"https://web.archive.org/web/20120630134958/http://www.nature.com/ncponc/index.html\">Nature
        Clinical Practice Oncology</a> about the media coverage of cancer. She argues
        that this coverage is frequently of poor quality, reinforcing the myth of
        cancer as an automatic death sentence and the overemphasis on stories about
        wonder cures.</p><p>To improve this situation, the <a href=\"https://web.archive.org/web/20120630134958/http://www.cancerworld.org/cancerworld/home.aspx?id_sito=1&amp;id_stato=1\">European
        School of Oncology</a> \u2013 where Kathy Redmond is coordinator of the media
        program \u2013 last year started an annual <a href=\"https://web.archive.org/web/20120630134958/http://www.cancerworld.org/CancerWorld/moduleStaticPage.aspx?id=2629&amp;id_sito=1&amp;id_stato=1\">Best
        Cancer Reporter Award</a>. And two days ago, <em><em>ESO</em></em> organized
        a media forum entitled <a href=\"https://web.archive.org/web/20120630134958/http://www.cancerworld.org/CancerWorld/getStaticModFile.aspx?id=1720\">Cancer:
        Time for a Reality Check</a> in Rome. And <em><em>ESO</em></em> is partnering
        with <em><em>Nature Clinical Practice Oncology</em></em> to collect summaries
        of important research findings to journalists.</p><p>For those of us working
        in cancer research, it is important to remember to communicate our research
        findings not only in journal articles and scientific meetings. We probably
        have to do a much better job in talking to the media and the public. One example
        would be to start a blog about a particular area of cancer research or cancer
        patient care. The number of quality blogs in this area could be much higher,
        and some blogs even had to <a href=\"http://www.thecancerblog.com/\">close
        down</a>.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ U.S. Senate passed bill with NIH open access
        mandate ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/u-s-senate-passed-bill-with-nih-open-access-mandate/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw95</id>\n        <published>2007-10-24T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T06:57:31.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>The U.S. senate yesterday
        <a href=\"https://web.archive.org/web/20120630152845/http://www.senate.gov/pagelayout/legislative/a_three_sections_with_teasers/votes.htm\">passed</a>
        the FY2008 Labor, HHS, and Education Appropriations Bill. The bill includes
        provisions that make public access of all papers from NIH-funded research
        mandatory. Peter Suber <a href=\"https://web.archive.org/web/20120630152845/http://www.earlham.edu/~peters/fos/2007/10/oa-mandate-at-nih-passes-senate.html\">reports</a>
        that last-minute amendments to weaken these provisions were not included (the
        official U.S.Senate <a href=\"https://web.archive.org/web/20120630152845/http://www.senate.gov/\">website</a>
        hasn't been updated yet to include that information). The <a href=\"https://web.archive.org/web/20120630152845/http://network.nature.com/blogs/user/mfenner/2007/08/03/open-access-may-become-mandatory-for-nih-funded-research\">House
        of Representatives</a> passed this bill in July, and we now have to wait for
        the likely presidential veto.<br></p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Nature in Nazi Germany 70 years ago: no
        open access ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/nature-in-nazi-germany-70-years-ago-no-open-access/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw94</id>\n        <published>2007-10-23T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T18:57:17.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Uwe Hossfeld and Lennart Olsson
        have just added a <a href=\"https://web.archive.org/web/20120630155127/http://www.nature.com/nature/history/full/nature06242.html\">story</a>
        from a dark time in German science to the <a href=\"https://web.archive.org/web/20120630155127/http://www.nature.com/nature/history/index.html\">History
        of Nature</a> website. This article extends an earlier <a href=\"https://web.archive.org/web/20120630155127/http://www.nature.com/nature/journal/v443/n7109/full/443271a.html\">report</a>
        from September 2006 that uncovered the story of how <em><em>Nature</em></em>
        was banned in Germany in November 1937.</p><p>The arguments used by the German
        science minister Bernhard Rust at the time are not worth repeating \u2013
        they are ideological rather than scientific arguments. But the story is interesting
        for today's scientists because it serves as a reminder that free access to
        scientific knowledge means much more than the <a href=\"https://web.archive.org/web/20120630155127/http://www.nature.com/nature/focus/accessdebate/\">open
        access vs. closed access</a> debate.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ German Max Planck Society cancels licensing
        agreement with Springer ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/german-max-planck-society-cancels-licensing-agreement-with-springer/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw93</id>\n        <published>2007-10-22T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T06:55:09.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Last week the German Max Planck
        Society (MPG) <a href=\"https://web.archive.org/web/20120630152549/http://www.mpg.de/english/illustrationsDocumentation/documentation/pressReleases/2007/pressRelease20071022/index.html\">cancelled</a>
        their licensing agreement with Springer. Starting January 1st, MPG scientists
        no longer have access to the 1200 Springer journals through the <em><em>SpringerLink</em></em>
        interface.</p><p>This is an important announcement, because the MPG is one
        of the largest research organizations in Germany and Springer the second largest
        STM (Science, Technology, Medicine) publisher after Elsevier. Just a few weeks
        before this announcement, both the <a href=\"https://web.archive.org/web/20120630152549/http://network.nature.com/blogs/user/mfenner/2007/09/27/howard-hughes-medical-institute-pays-for-open-access-in-springer-journals\">Howard
        Hughes Medical Institute</a> and the <a href=\"https://web.archive.org/web/20120630152549/http://www.sub.uni-goettingen.de/ebene_2/oa_journals/springer.html.en\">University
        of G\xF6ttingen</a> announced that they will pay their authors for Open Access
        in Springer journals (<a href=\"https://web.archive.org/web/20120630152549/http://www.springer.com/dal/home/open+choice\">Springer
        Open Choice</a>).</p><p>Time will tell whether these announcements are coincidences
        or the part of a larger trend from a <em><em>subscriber-pays</em></em> to
        an <em><em>author-pays</em></em> model.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Do you know the Flesch score of your papers?
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/do-you-know-the-flesch-score-of-your-papers/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw92</id>\n        <published>2007-10-14T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T18:55:07.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>We just had a very interesting
        discussion in the <a href=\"https://web.archive.org/web/20120630154317/http://network.nature.com/forums/askthenatureeditor/567\">Ask
        the Nature Editor</a> Forum about scientific writing. Most people agreed that
        the quality of the writing in the end doesn't really influence the decision
        to accept or reject a paper. But good writing, especially in the first paragraph,
        certainly helps.</p><p>But what is good scientific writing? Two weeks ago
        I suggested a few good books on the subject in a <a href=\"https://web.archive.org/web/20120630154317/http://network.nature.com/blogs/user/mfenner/2007/09/30/books-about-scientific-writing\">blog
        post</a>. Once you have written the paper using the advice in these books,
        you can use a number of tools to measure the readability of your paper.</p><p><em><em>Flesch
        Reading Ease Score</em></em>:</p><blockquote>206.835 - 1.015 x ASL - 84.6
        x ASW</blockquote><p>ASL is average sentence length and ASW is average number
        of syllables per word. The Flesch Reading Ease Score can be between 0 and
        100, 100 being the most difficult.</p><p>The <em><em>Flesch-Kincaid Grade
        Level Test</em></em> is similar, but rates the text on a U.S. school grade
        level. Both Flesch scores are built into recent versions of Microsoft Word
        or you could use the Open Source application <a href=\"https://web.archive.org/web/20120630154317/http://flesh.sourceforge.net/\">Flesh</a>.
        Flesh is much easier to use than the Microsoft Word tool and will also open
        PDF files. Try to rewrite your manuscript if your Flesch Reading Ease Score
        is too low, e.g. below 30.</p><p>Readability is important not only for manuscripts.
        Informed consent forms for patients wishing to participate in clinical trials
        in Medicine are often <a href=\"https://web.archive.org/web/20120630154317/http://content.nejm.org/cgi/content/abstract/348/8/721\">difficult
        to read</a>. And a perspective article by Celeste Condit in the current <em><em>Nature
        Reviews Genetics</em></em> talks about <a href=\"https://web.archive.org/web/20120630154317/http://www.nature.com/nrg/journal/v8/n10/abs/nrg2201.html\">How
        geneticists can help reporters to get their story right</a>. She points out
        the importance of readability to communicate often highly technical material
        to lay people.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Adobe Share and Microsoft Office Live Workspace
        announced today ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/adobe-share-and-microsoft-office-live-workspace-announced-today/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw91</id>\n        <published>2007-10-01T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-29T20:35:18.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Both Adobe and Microsoft today
        announced free web-based solutions for document sharing. <a href=\"https://web.archive.org/web/20120630153745/http://share.adobe.com/\">Adobe
        Share</a> uses the Flash technology to display various document formats. <a
        href=\"https://web.archive.org/web/20120630153745/http://feeds.feedburner.com/~r/oreilly/radar/atom/~3/163539601/adobe_share_document_widget.html\">Tim
        O'Reilly</a> has a nice writeup of the new service.</p><p><a href=\"https://web.archive.org/web/20120630153745/http://workspace.officelive.com/\">Microsoft
        Office Live Workspace</a> allows the sharing of Microsoft Office documents.
        Just as with Adobe Share, and in contrast to <a href=\"https://web.archive.org/web/20120630153745/http://docs.google.com/\">Google
        Docs</a>, you can't directly edit documents online.</p><p>Why should a scientist
        care about all this? Because these are excellent tools to share your presentations
        and to collaborate on manuscripts you are writing. No more emailing Powerpoint,
        Excel, Word or PDF files back and forth. And with several major players (Microsoft,
        Google, Adobe and the smaller <a href=\"https://web.archive.org/web/20120630153745/http://www.zoho.com/\">Zoho</a>)
        offering web-based document sharing, this will soon become as commonplace
        as web-based email.</p><p>In related news, Adobe today also announced the
        acquisition of Buzzword, the online word processor that I wrote about <a href=\"https://web.archive.org/web/20120630153745/http://network.nature.com/blogs/user/mfenner/2007/09/27/more-on-online-writing-tools-buzzword-is-different\">last
        week</a>.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Notes of a scientist from RailsConf Europe
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/notes-of-a-scientist-from-railsconf-europe/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw8t</id>\n        <published>2007-09-30T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-01T05:30:17.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Earlier this
        month I attended <a href=\"https://web.archive.org/web/20120611101007/http://www.railsconfeurope.com/\">RailsConf
        Europe</a> in Berlin. RailsConf is a conference about <a href=\"https://web.archive.org/web/20120611101007/http://www.rubyonrails.org/\">Ruby
        on Rails</a>, a programming framework to produce websites. I'm a part-time
        Ruby on Rails programmer and had a very interesting conference. <a href=\"https://web.archive.org/web/20120611101007/http://chneukirchen.org/blog/archive/2007/09/a-railsconf-europe-07-diary.html\">Others</a>
        have already written about RailsConf, so I want to focus on how it was like
        from a scientist's perspective.</p><p>The topic was of course very different
        from say a meeting about RNA interference, but many things were surprisingly
        similar. But I found a few differences very interesting, and I believe a scientific
        meeting could learn from them.</p><p>Many of the talks were about ongoing
        work that hasn't been finished yet. Ruby on Rails is Open Source software,
        so there is less worry about intellectual property and people talked freely
        about their ideas and problems. This is in contrast to the typical meeting
        in my field (oncology), where only the most established researchers are not
        afraid to present data that have not yet been published or at least submitted.
        This of course brings us back to the Open Science discussion both on <a href=\"https://web.archive.org/web/20120611101007/http://network.nature.com/boston/news/blog/U66E7CD1A/2007/08/09/scifoo-ponderings-how-to-break-the-mold-in-science\">Nature
        Network</a> and elsewhere.</p><p>Partly because of this openness, but also
        because it was a technology meeting, the conference is much more accessible
        for those that couldn't make it to Berlin. Not only are the slides of most
        presentations <a href=\"https://web.archive.org/web/20120611101007/http://www.railsconfeurope.com/pub/w/61/presentations.html\">available
        for download</a>, but there are also numerous blog posts. We'll soon also
        see podcasts and videocasts (the keynote lecture is already <a href=\"https://web.archive.org/web/20120611101007/http://www.rubyinside.com/dhhs-keynote-at-railsconf-europe-2007-611.html\">available</a>).
        I'm a big podcast fan and I would <a href=\"https://web.archive.org/web/20120611101007/http://blog.xartrials.com/2007/6/6/asco_2007_meeting\">love
        to see more of this</a> from the conferences in my field.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Books about scientific writing ]]></title>\n\t\t<link
        href=\"https://blog.front-matter.io/posts/books-about-scientific-writing/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw8s</id>\n        <published>2007-09-30T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-15T14:19:29.000+00:00</updated>\n\t\t<category
        term=\"Book Review\"/>\n        <media:content url=\"https://blog.front-matter.io/content/images/2022/08/9780521878906.jpeg\"
        medium=\"image\"/>\n        <content type=\"html\"><![CDATA[ <p><img src=\"https://blog.front-matter.io/content/images/2022/08/9780521878906.jpeg\"></p><p>Last
        weekend I visited my brother-in-law in Cambridge (UK). In the Cambridge University
        Press bookstore I found the wonderful little book <em><em>How to Write and
        Illustrate a Scientific Paper</em></em> by Bj\xF6rn Gustavii (<a href=\"https://web.archive.org/web/20120611101312/http://www.cambridge.org/catalogue/catalogue.asp?isbn=9780521823234\">Cambridge
        University Press 2003</a>). On less than 150 pages B. Gustavii gives a good
        summary of the typical problems and their solutions. He encourages the reader
        to avoid unnecessary verbosity, use the active voice more often, draw less
        complicated charts and to be very careful with statistics.</p><p>A few years
        ago I bought an old copy of <em><em>Scientific Writing</em></em> by Lester
        S. King and Charles G. Roland (Journal of the American Medical Association
        1968). King and Roland encourage the reader to avoid unnecessary verbosity
        and use the active voice more often (they don't talk much about graphs and
        statistics). Scientific writing seemed to have almost the same problems 40
        years ago. This raises two interesting questions:</p><ul><li>Could the writing
        of the average scientific paper be improved and are we in need of these books?</li><li>Does
        the quality of the writing help in getting a paper accepted? In other words,
        should I make the effort and improve my writing skills or should I rather
        do experiments?</li></ul><p>Journal editors can probably better answer these
        questions. My guess would be that most people would answer these questions
        with <em><em>yes</em></em> and <em><em>no</em></em>. So we will continue to
        struggle with our writing skills, especially those of us who learned English
        as a second language, but it will not be that important in our career. I therefore
        rather list some other books about scientific writing that I own and can recommend:</p><ul><li><em><em>Medical
        Writing: a Prescription for Clarity</em></em> by Neville W. Goodman and Martin
        B. Edwards (Cambridge University Press 2006). Very detailed instructions about
        the use of the language. Includes many examples of bad scientific writing
        and suggestions for better alternatives.</li><li><em><em>The Elements of Style</em></em>
        by William Strunk Jr. and E.B. White (Logman 2000). The classic text from
        the beginning of the 20th century, not specific to scientific writing.</li><li><em><em>The
        Visual Display of Quantitative Information</em></em> by Edward R. Tufte (Graphics
        Press 2001). Another classic text and a beautiful book.</li><li><em><em>Clinical
        Epidemiology</em></em> by R. Brian Haynes, David L. Sackett, Gordon H. Guyatt
        and Peter Tugwell (Lippincott 2006). This epidemiology/statistics textbook
        has a small chapter about scientific writing. More importantly, it is very
        helpful in how to read a scientific paper and the statistics behind it.</li></ul><p>And
        I finish with an example for good scientific writing that is used a lot in
        the books mentioned above:</p><blockquote>We wish to suggest a structure for
        the salt of deoxyribose nucleic acid (D.N.A.). This structure has novel features
        which are of considerable biological interest\u2026</blockquote><p>This is
        of course the opening paragraph of the 1953 <a href=\"https://web.archive.org/web/20120611101312/http://www.nature.com/nature/dna50/watsoncrick.pdf\">Nature
        paper</a> by Watson and Crick. Which brings us back to Cambridge\u2026</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ More on online writing tools \u2013 Buzzword
        is different ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/more-on-online-writing-tools-buzzword-is-different/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw8w</id>\n        <published>2007-09-27T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T18:53:21.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>I recently <a href=\"https://web.archive.org/web/20120611101340/http://network.nature.com/blogs/user/mfenner/2007/09/09/could-you-write-your-next-paper-with-google-docs\">wrote
        about</a> the potential of Google Docs and Zoho Writer als online writing
        tools for scientists. <em><em><a href=\"https://web.archive.org/web/20120611101340/http://www.virtub.com/\">Buzzword</a></em></em>
        is another web-based writing tool and last week was opened for new users.
        Buzzword is different, because it is based on Adobe Flash, which makes for
        a much nicer user interface.</p><p>As expected, Buzzword doesn't handle references
        as flexible as Microsoft Word. But you can at least get similar functionality
        with endnotes. I expect many small changes before version 1.0, most importantly
        support for the Symbol font.</p><p>You should give Buzzword a try if online
        document sharing with a slick user interface is important to you.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Howard Hughes Medical Institute pays for
        Open Access in Springer journals ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/howard-hughes-medical-institute-pays-for-open-access-in-springer-journals/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw8v</id>\n        <published>2007-09-27T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-30T06:56:28.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>The Howard Hughes Medical
        Institute (HHMI) today <a href=\"https://web.archive.org/web/20120611101248/http://www.hhmi.org/news/springer20070927.html\">announced</a>
        that it will support Open Access in Springer journals through the Springer
        Open Choice program. HHMI earlier this year made a similar deal with Elsevier
        and last month became a BiomedCentral member (I wrote about this <a href=\"https://web.archive.org/web/20120611101248/http://network.nature.com/blogs/user/mfenner/2007/08/20/howard-hughes-medical-institute-hhmi-becomes-biomed-central-member\">here</a>).</p><p>In
        contrast to articles in Elsevier journals (which become freely available after
        6 months and Elsevier holds the copyright), articles in Springer journals
        will be available immediately and the author will retain the copyright.</p><p>I'm
        glad to see this agreement happen. It probably makes sense for Springer, HHMI
        and, most importantly, the involved scientists. Even more so now with the
        charged discussion about <a href=\"https://web.archive.org/web/20120611101248/http://network.nature.com/blogs/user/mfenner/2007/08/26/prism-lobbying-against-open-access\">PRISM</a>.</p>
        ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ You can now share Powerpoint presentations
        online with Google Presently ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/you-can-now-share-powerpoint-presentations-online-with-google-presently/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw8x</id>\n        <published>2007-09-19T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-01T05:29:29.000+00:00</updated>\n\t\t<category
        term=\"Meeting Report\"/>\n        <media:content url=\"\" medium=\"image\"/>\n
        \       <content type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>This Monday
        <a href=\"http://googleblog.blogspot.com/2007/09/our-feature-presentation.html\">Google</a>
        officially announced Presently, their web-based application for presentations,
        a.k.a. Microsoft Powerpoint clone.</p><p>Although it is possible to create
        presentations from scratch using Presently, most users will probably use it
        to upload their finished (or almost finished) Microsoft Powerpoint presentations
        (there is a 10 MB size limit). The presentations can then be shared either
        globally or to a restricted list of colleagues.</p><p>There are other online
        tools that can do similar things, most notably <a href=\"https://web.archive.org/web/20120611101530/http://show.zoho.com/\">Zoho
        Show</a> and <a href=\"https://web.archive.org/web/20120611101530/http://www.slideshare.net/\">Slideshare</a>.
        Zoho Show is similar to Google Presently, but Slideshare doesn't allow online
        editing of your presentation and currently you can't limit access to your
        presentation to just the people you want to.</p><p>Google Presently (and Zoho
        Show) are a great way to share your presentations for a lab meeting or conference.
        Email is just not the best tool for this, especially since presentations are
        usually large files. Did I mention that using either Google Presently and
        Zoho Show is free?</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Could you write your next paper within the
        manuscript submission system? ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/could-you-write-your-next-paper-within-the-manuscript-submission-system/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw8y</id>\n        <published>2007-09-16T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-03T05:06:13.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>Last week I <a href=\"http://network.nature.com/blogs/user/mfenner/2007/09/09/could-you-write-your-next-paper-with-google-docs\">wrote</a>
        about web-based writing tools. I believe that these tools are <em><em>almost</em></em>
        there and someone has to put the pieces together to make them work for writing
        a scientific paper.</p><p><a href=\"https://web.archive.org/web/20120611101031/http://www.ejpress.com/ejpress.shtml\">EJ
        Press System</a> by EJournal Press, <a href=\"https://web.archive.org/web/20120611101031/http://www.scholarone.com/products_manuscriptcentral_aboutMC.shtml\">Manuscript
        Central</a> by ScholarOne and <a href=\"https://web.archive.org/web/20120611101031/http://www.editorialmanager.com/\">Editiorial
        Manager</a> by Aries Systems are among the most popular web-based online submission
        systems. From a technical point of view, it would make a lot of sense if these
        submission systems are extended to also cover the paper writing process. The
        major advantage of web-based systems \u2013 in contrast to writing your paper
        in a traditional word processor such as Microsoft Word \u2013 is collaboration.
        And the actual paper submission becomes much easier both for the author and
        the publisher if the paper is already in the submission system. This could
        also streamline the peer-review process, as reviewers could (anonymously)
        write their comments directly into the online text.</p><p>An online paper
        writing tool could also make business sense. I believe that a large number
        of authors would consider such a system even with a fee of $25-50 per paper.
        This could generate enough revenue to cover the development and maintenance
        costs of such a system.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ OncologySTAT: free access to journal articles
        from Elsevier oncology journals ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/oncologystat-free-access-to-journal-articles-from-elsevier-oncology-journals/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw8z</id>\n        <published>2007-09-10T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-29T20:33:31.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p><a href=\"https://web.archive.org/web/20120611101437/http://www.oncologystat.com/\">OncologySTAT</a>
        is a new (it launched September 7) web portal by <a href=\"https://web.archive.org/web/20120611101437/http://http//us.elsevierhealth.com/\">Reed
        Elsevier</a> that offers, among many other things, full access to journal
        articles in Elsevier oncology journals.</p><p>Elsevier hopes to generate enough
        revenue from selling advertising on the web site to compensate for (potentially)
        lost journal sales. This approach has long become a business model for many
        newspapers and magazines, but I haven't seen this before in scientific and
        medical publishing.</p><p>As I work in the field of oncology, I will have
        a closer look at OncologySTAT in the coming weeks.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ Could you write your next paper with Google
        Docs? ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/could-you-write-your-next-paper-with-google-docs/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw90</id>\n        <published>2007-09-09T00:00:00.000+00:00</published>\n\t\t<updated>2022-08-13T11:51:17.000+00:00</updated>\n\t\t<category
        term=\"Feature\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p><a href=\"https://web.archive.org/web/20120611101232/http://docs.google.com/\">Google
        Docs</a> and <a href=\"https://web.archive.org/web/20120611101232/http://writer.zoho.com/\">Zoho
        Writer</a> are web-based writing tools that have gained many of the features
        of traditional word processors such as Microsoft Word. Looking at Google Docs
        as an example (Zoho Writer shares many of the strenghts and weaknesses), I
        wanted to find out if they are mature enough to write a scientific paper.</p><h3
        id=\"the-good\">The Good</h3><p>The major strength is collaboration. All documents
        are stored online, which makes it very easy for several people to work on
        a document simultaneously. Because all changes to the text are kept (with
        author and date), it is easy to go back to an older version. You can import
        and export documents in various formats, including .doc, .rtf and .pdf.</p><h3
        id=\"the-bad\">The Bad</h3><p>The obvious missing feature is lack of reference
        manager integration. Google Docs currently doesn't support footnotes or endnotes,
        so you can't roll your own references. Google Docs supports font formatting,
        but unfortunately that doesn't include the Symbol font \u2013 needed in almost
        all scientific documents. And Google Docs online works with an online internet
        connection, although offline support may come in the form of <a href=\"https://web.archive.org/web/20120611101232/http://gears.google.com/\">Google
        Gears</a>, Zoho Writer already supports Google Gears.</p><h3 id=\"the-summary\">The
        Summary</h3><p>Google Docs is <em><em>almost</em></em> ready to be an attractive
        tool for scientific writing. Some of the small problems are easily fixed in
        future updates. The big problem is integration of scientific references. But
        Google already has <a href=\"https://web.archive.org/web/20120611101232/http://scholar.google.com/\">Google
        Scholar</a>, maybe the two can be integrated?</p><p>For now, Google Docs can
        help with papers that have many active authors (e.g. a review article), but
        the final steps still have to be done with a word processor.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin
        Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n
        \   <entry>\n\t\t<title><![CDATA[ PRISM \u2013 lobbying against open access
        ]]></title>\n\t\t<link href=\"https://blog.front-matter.io/posts/prism-lobbying-against-open-access/\"
        />\n\t\t<id>https://doi.org/10.53731/r294649-6f79289-8cw8j</id>\n        <published>2007-08-26T00:00:00.000+00:00</published>\n\t\t<updated>2022-07-29T20:32:06.000+00:00</updated>\n\t\t<category
        term=\"News\"/>\n        <media:content url=\"\" medium=\"image\"/>\n        <content
        type=\"html\"><![CDATA[ <p><img src=\"\"></p><p>On <a href=\"https://web.archive.org/web/20120412202205/http://www.publishers.org/main/PressCenter/PRISMLaunch.htm\">August
        23</a>, the Partnership for Research Integrity in Science and Medicine or
        <a href=\"https://web.archive.org/web/20120412202205/http://www.prismcoalition.org/\">PRISM</a>
        was announced. PRISM is a lobbying organisation created by the Professional
        &amp; Scholarly Publishing Division (<a href=\"https://web.archive.org/web/20120412202205/http://www.pspcentral.org/\">PSP</a>)
        of the Association of American Publishers (<a href=\"https://web.archive.org/web/20120412202205/http://www.publishers.org/\">AAP</a>).
        The main purpose of PRISM appears to lobby legislators in Washington to not
        <a href=\"https://web.archive.org/web/20120412202205/http://network.nature.com/blogs/user/mfenner/2007/08/03/open-access-may-become-mandatory-for-nih-funded-research\">sign
        legislation</a> that would require public access to all scientific papers
        within 12 months after publication.</p><p>While there are many good arguments
        for or against this change in legislation, and you would expect many AAP members
        to oppose this measure, PRISM is different in that it is a pure lobbying effort
        \u2013 e.g. read <a href=\"https://web.archive.org/web/20120412202205/http://www.prismcoalition.org/myth.htm\">Myth
        vs. fact: Setting the Record Straight on Scholarly Journals</a>. The two main
        arguments used are:</p><ul><li>open access undermines the peer review process</li><li>requiring
        deposition in public repositories leads to government interference in scientific
        publishing</li></ul><p>These \u201Carguments\u201D were obviously created
        in a PR department, as they don't make sense to anybody involved in scientific
        publishing. The peer review process is not different in open access journals.
        And to call deposition of NIH-funded research papers in the NIH-managed PubMed
        Central \u201Cgovernment interference\u201D is difficult to understand.</p><p>PRISM
        might be successful in avoiding a change in U.S. legislation, but the strange
        logic used by PRISM could lead many scientists to think twice before submitting
        a paper to a journal that endorses the PRISM principles. Which in the end
        could be worse for the journal publisher than the proposed change in legislation.</p><p>Read
        more about PRISM in Peter Suber's <a href=\"https://web.archive.org/web/20120412202205/http://www.earlham.edu/~peters/fos/2007_08_19_fosblogarchive.html#5309199826835837381\">blog
        post</a>. And read the <a href=\"https://web.archive.org/web/20120412202205/http://network.nature.com/boston/news/blog/U66E7CD1A/2007/01/24/publishers-fight-open-access-with-high-profile-spin-doctor\">blog
        post</a> by Corie Lok about some background on the AAPs efforts against open
        access.</p> ]]></content>\n\t\t<author>\n\t\t\t<name>Martin Fenner</name>\n\t\t\t<uri>https://orcid.org/0000-0003-1419-2405</uri>\n\t\t</author>\n\t</entry>\n</feed>\n"
    headers:
      Accept-Ranges:
      - bytes
      Age:
      - '93288'
      Alt-Svc:
      - clear
      Cache-Control:
      - public, max-age=0
      Connection:
      - close
      Content-Length:
      - '2989658'
      Content-Type:
      - application/atom+xml; charset=utf-8
      Date:
      - Wed, 18 Oct 2023 11:04:35 GMT
      Ghost-Age:
      - '0'
      Ghost-Cache:
      - MISS
      Ghost-Fastly:
      - 'true'
      Server:
      - openresty
      Status:
      - 200 OK
      Vary:
      - Cookie
      Via:
      - 1.1 varnish
      X-Cache:
      - HIT
      X-Cache-Hits:
      - '1'
      X-Request-ID:
      - 34ebfe95-f9f5-43e1-a4b6-a4797746c120
      - 34ebfe95-f9f5-43e1-a4b6-a4797746c120
      X-Served-By:
      - cache-ams21055-AMS
      X-Timer:
      - S1697627076.719762,VS0,VE3
      etag:
      - W/"2d9e5a-vponrIrJNNeG49tiUMpPSjNA1Sw"
      x-request-id:
      - 34ebfe95-f9f5-43e1-a4b6-a4797746c120
      - 34ebfe95-f9f5-43e1-a4b6-a4797746c120
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept-Version:
      - v5.0
    method: GET
    uri: https://front-matter.ghost.io/ghost/api/content/posts/?page=1&limit=50&include=tags,authors&key=b099ebe9ce894979c77431e6d3
  response:
    body:
      string: "{\"posts\":[{\"id\":\"6526c60bf23c390001a8394c\",\"uuid\":\"e9d845a4-81e9-498f-b252-4493f9f42bc2\",\"title\":\"Generating
        Overlay blog posts\",\"slug\":\"generating-overlay-blog-posts\",\"html\":\"<p>On
        Monday the Rogue Scholar science blog archive <a href=\\\"https://doi.org/10.53731/ar11b-5ea39\\\"
        rel=\\\"noreferrer\\\">launched a dedicated API</a>. Today I am reporting
        on the first Jupyter notebook using that API to generate an overlay blog post.</p><blockquote>An&nbsp;<strong>overlay
        journal</strong>&nbsp;or&nbsp;<strong>overlay ejournal</strong>&nbsp;is a
        type of&nbsp;open access&nbsp;academic journal, almost always an online&nbsp;electronic
        journal&nbsp;(ejournal), that does not produce its own content, but selects
        from texts that are already freely available online.&nbsp;From <a href=\\\"https://en.wikipedia.org/wiki/Overlay_journal\\\"
        rel=\\\"noreferrer\\\">Wikipedia</a></blockquote><p>An <strong>overlay blog
        post</strong> applies the idea of an <strong>overlay journal</strong> to science
        blog posts, and the Rogue Scholar API \u2013 in combination with content that
        has an open license (<a href=\\\"https://creativecommons.org/licenses/by/4.0/legalcode\\\"
        rel=\\\"noreferrer\\\">CC-BY</a>) \u2013 makes that easy.</p><p>The Jupyter
        notebook that I started and <a href=\\\"https://github.com/front-matter/rogue-scholar-notebooks\\\">made
        available via GitHub</a> and <a href=\\\"https://doi.org/10.5281/zenodo.8433675\\\"
        rel=\\\"noreferrer\\\">Zenodo</a> fetches all blog posts using a search term
        and some other conditions (here written in English and published after 2010).
        I thought a good search term to try out the concept would be <strong>Retraction
        Watch</strong>, after the <a href=\\\"https://doi.org/10.13003/c23rw1d9\\\"
        rel=\\\"noreferrer\\\">announcement in September</a> that <em>Crossref has
        acquired the Retraction Watch database of expressions of concerns and retractions
        and has made it openly accessible to anyone who wants to use it.</em></p><p>The
        notebook includes this note:</p><div class=\\\"kg-card kg-callout-card kg-callout-card-blue\\\"><div
        class=\\\"kg-callout-emoji\\\">\U0001F4A1</div><div class=\\\"kg-callout-text\\\">We
        use the query&nbsp;retraction watch. We limit results to posts published since&nbsp;2010&nbsp;(the
        year Retraction Watch launched) and&nbsp;en&nbsp;as language. We retrieve
        the&nbsp;title,&nbsp;authors,&nbsp;publication date,&nbsp;abstract,&nbsp;blog
        name,&nbsp;doi&nbsp;and&nbsp;url.We sort the results in reverse chronological
        order (newest first).</div></div><p>The query for that search term returned
        17 blog posts included in Rogue Scholar (out of about 9,000 posts), and manual
        curation narrowed that list further down to 12 posts (visualized with <a href=\\\"https://mermaid.js.org/\\\"
        rel=\\\"noreferrer\\\">Mermaid</a>):</p><figure class=\\\"kg-card kg-image-card\\\"><img
        src=\\\"https://blog.front-matter.io/content/images/2023/10/mermaid-figure-1.png\\\"
        class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"2000\\\"
        height=\\\"190\\\" srcset=\\\"https://blog.front-matter.io/content/images/size/w600/2023/10/mermaid-figure-1.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/10/mermaid-figure-1.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/10/mermaid-figure-1.png
        1600w, https://blog.front-matter.io/content/images/size/w2400/2023/10/mermaid-figure-1.png
        2400w\\\" sizes=\\\"(min-width: 720px) 720px\\\"></figure><p>The notebook
        then generates a bibtex file of all 12 blog posts (easy as they all have DOIs)
        and generates a summary written in markdown using the title, author, blog
        name, publication date, and abstract.</p><h2 id=\\\"conclusions\\\">Conclusions</h2><p>The
        notebook needs some more fine-tuning, and I plan to publish the first overlay
        blog post next week. But notebooks are an interesting approach to automate
        the generating of overlay blog posts, open to everyone as the content of the
        Rogue Scholar API is freely available for reuse. I particularly like using
        both automation and manual curation using open source tools, which is a powerful
        combination</p><h2 id=\\\"references\\\">References</h2><p>Fenner, M. (2023).
        <em>Rogue Scholar has an API</em>. <a href=\\\"https://doi.org/10.53731/ar11b-5ea39\\\">https://doi.org/10.53731/ar11b-5ea39</a></p><p>Fenner,
        M. (2023). <em>front-matter/rogue-scholar-notebooks: Initial public release</em>
        (0.8) [Computer software]. Zenodo. <a href=\\\"https://doi.org/10.5281/ZENODO.8433675\\\">https://doi.org/10.5281/ZENODO.8433675</a></p><p>Crossref,
        Hendricks, G., Center for Scientific Integrity, &amp; Lammey, R. (2023). <em>Crossref
        acquires Retraction Watch data and opens it for the scientific community</em>.
        <a href=\\\"https://doi.org/10.13003/c23rw1d9\\\">https://doi.org/10.13003/c23rw1d9</a></p>\",\"comment_id\":\"6526c60bf23c390001a8394c\",\"feature_image\":\"https://images.unsplash.com/flagged/photo-1552425083-0117136f7d67?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=M3wxMTc3M3wwfDF8c2VhcmNofDIxfHxjYW5vcHl8ZW58MHx8fHwxNjk3MDQwMDk1fDA&ixlib=rb-4.0.3&q=80&w=2000\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2023-10-11T15:58:03.000+00:00\",\"updated_at\":\"2023-10-12T08:27:25.000+00:00\",\"published_at\":\"2023-10-11T16:40:31.000+00:00\",\"custom_excerpt\":\"On
        Monday the Rogue Scholar science blog archive launched a dedicated API. Today
        I am reporting on the first Jupyter notebook using that API to generate an
        overlay blog post.\",\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/gzrse-p5d35\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42bbc41e317003df48d4e\",\"name\":\"Feature\",\"slug\":\"feature\",\"description\":\"Features
        explore issues raised by news stories in more depth.\",\"feature_image\":\"https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fHJlc2VhcmNofGVufDB8fHx8MTYxODEyMzQxNQ&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/feature/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42bbc41e317003df48d4e\",\"name\":\"Feature\",\"slug\":\"feature\",\"description\":\"Features
        explore issues raised by news stories in more depth.\",\"feature_image\":\"https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fHJlc2VhcmNofGVufDB8fHx8MTYxODEyMzQxNQ&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/feature/\"},\"url\":\"https://blog.front-matter.io/posts/generating-overlay-blog-posts/\",\"excerpt\":\"On
        Monday the Rogue Scholar science blog archive launched a dedicated API. Today
        I am reporting on the first Jupyter notebook using that API to generate an
        overlay blog post.\",\"reading_time\":2,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":\"Photo
        by <a href=\\\"https://unsplash.com/@inset_agency?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Paul
        Knight</a> / <a href=\\\"https://unsplash.com/?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Unsplash</a>\"},{\"id\":\"6524026b509bba0001454cd2\",\"uuid\":\"532dfbe1-2040-4d6a-80cc-6becb907abc0\",\"title\":\"Rogue
        Scholar has an API\",\"slug\":\"rogue-scholar-has-an-api\",\"html\":\"<p>The
        Rogue Scholar science blog archive has launched a dedicated API today, publicly
        available at <code>https://api.rogue-scholar.org</code> and complementing
        the <a href=\\\"https://rogue-scholar.org\\\" rel=\\\"noreferrer\\\">website</a>.</p><p>Rogue
        Scholar had an API before but with two important limitations. </p><ul><li><strong>Serverless</strong>.
        The API at https://rogue-scholar.org/api uses <a href=\\\"https://www.serverless.com/\\\"
        rel=\\\"noreferrer\\\">serverless</a> technology, which isn't a good fit for
        long-running resource-intense processes.</li><li><strong>GitHub Actions</strong>.
        GitHub Actions are used for DOI registrations. They can be triggered at specific
        times, but <a href=\\\"https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows\\\"
        rel=\\\"noreferrer\\\">not more than once every 5 min</a>.</li></ul><p>The
        new API overcomes these limitations once it is fully implemented by the end
        of the year. The version released today implements HTTP <code>get</code>requests,
        supports anonymous users, and provides the same information that is also available
        via the Rogue Scholar <a href=\\\"https://rogue-scholar.org\\\" rel=\\\"noreferrer\\\">website</a>.
        The API is implemented as a Python <a href=\\\"https://quart.palletsprojects.com/en/latest/index.html\\\"
        rel=\\\"noreferrer\\\">Quart application</a> (an async Python web micro-framework
        heavily inspired by Flask), hosted on the <a href=\\\"https://fly.io\\\" rel=\\\"noreferrer\\\">fly.io</a>
        platform, and available as Open Source software via <a href=\\\"https://github.com/front-matter/rogue-scholar-api\\\"
        rel=\\\"noreferrer\\\">GitHub</a> , <a href=\\\"https://pypi.org/project/rogue-scholar-api/\\\"
        rel=\\\"noreferrer\\\">PyPi</a>, and <a href=\\\"https://doi.org/10.5281/ZENODO.8433679\\\"
        rel=\\\"noreferrer\\\">Zenodo</a>. More work is needed to allow users to run
        the API locally, as the API requires data from the database (Postgres) and
        search index (Typesense), which both also use Open Source software but need
        authentication for access. The simplest way to get started with the Rogue
        Scholar API is to use the <a href=\\\"https://api.rogue-scholar.org/openapi.json\\\"
        rel=\\\"noreferrer\\\">OpenAPI endpoint</a> with the <a href=\\\"https://api.rogue-scholar.org/docs\\\"
        rel=\\\"noreferrer\\\">Swagger UI</a>:</p><figure class=\\\"kg-card kg-image-card
        kg-card-hascaption\\\"><img src=\\\"https://blog.front-matter.io/content/images/2023/10/Bildschirmfoto-2023-10-09-um-16.24.07.png\\\"
        class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"2000\\\"
        height=\\\"1340\\\" srcset=\\\"https://blog.front-matter.io/content/images/size/w600/2023/10/Bildschirmfoto-2023-10-09-um-16.24.07.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/10/Bildschirmfoto-2023-10-09-um-16.24.07.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/10/Bildschirmfoto-2023-10-09-um-16.24.07.png
        1600w, https://blog.front-matter.io/content/images/2023/10/Bildschirmfoto-2023-10-09-um-16.24.07.png
        2086w\\\" sizes=\\\"(min-width: 720px) 720px\\\"><figcaption><a href=\\\"https://api.rogue-scholar.org/docs\\\"
        rel=\\\"noreferrer\\\"><span style=\\\"white-space: pre-wrap;\\\">Rogue Scholar
        API Swagger UI</span></a></figcaption></figure><p>In the coming weeks, I will
        work on improving the Rogue Scholar API in the following important areas:</p><h2
        id=\\\"integration-of-doi-registration\\\">Integration of DOI registration</h2><p>This
        is currently done via GitHub Actions and a <a href=\\\"https://rubygems.org/gems/commonmeta-ruby\\\"
        rel=\\\"noreferrer\\\">Ruby gem</a> automatically converts the blog post metadata
        into Crossref XML needed for DOI registration. This works fine but doesn't
        easily scale to 100s or more DOI registrations or updates per day, and is
        more difficult to integrate with other workflows compared to an internal API.
        The goal is to switch to the DOI registrations via a background task triggered
        by the API and using the Python <a href=\\\"https://pypi.org/project/commonmeta-py/\\\"
        rel=\\\"noreferrer\\\">metadata conversion library</a> that I wrote at the
        beginning of the year.</p><h2 id=\\\"conversion-of-blog-posts-to-epub-or-pdf\\\">Conversion
        of blog posts to ePub or PDF</h2><p>Converting the science blog posts archived
        in Rogue Scholar into ePub, PDF, or other formats using the <a href=\\\"https://pandoc.org/\\\"
        rel=\\\"noreferrer\\\">Pandoc</a> universal document converter would enable
        several interesting use cases, for example storing blog posts locally with
        a reference manager or generating collections by blog, author, or topic.</p><h2
        id=\\\"metadata-conversion\\\">Metadata conversion</h2><p>The API released
        today continues the Rogue Scholar integration with DOI content negotiation
        to convert blog post metadata into different formats such as BibTeX or formatted
        citations. We could offer <a href=\\\"https://github.com/front-matter/commonmeta-py\\\"
        rel=\\\"noreferrer\\\">additional metadata conversions</a> not currently implemented
        by DOI content negotiation such as <a href=\\\"https://schema.org/\\\" rel=\\\"noreferrer\\\">Schema.org</a>
        JSON-LD.</p><h2 id=\\\"data-science-using-science-blogs\\\">Data Science using
        science blogs</h2><p>Finally, the new API enables data scientists to explore
        science blogs in more detail. With close to 10,000 science blog posts from
        60 different blogs going as far back as 2005 and available as full-text with
        an open license (<a href=\\\"https://creativecommons.org/licenses/by/4.0/legalcode\\\"
        rel=\\\"noreferrer\\\">CC-BY</a>), many interesting questions can be explored.
        I will start with a Jupyter notebook that provides a more detailed analysis
        than the <a href=\\\"https://rogue-scholar.org/#stats\\\" rel=\\\"noreferrer\\\">Rogue
        Scholar stats page</a>, taking as inspiration the work of the <a href=\\\"https://doi.org/10.59349/zh4g1-q7e26\\\"
        rel=\\\"noreferrer\\\">Journal of Open Source Software</a>. I am particularly
        interested in the more than <a href=\\\"https://api.crossref.org/members/31795/works?filter=has-references:true\\\"
        rel=\\\"noreferrer\\\">750 blog posts that include references</a> in their
        metadata, as to the best of my knowledge that kind of bibliometric analysis
        has never been done.</p><h2 id=\\\"references\\\">References</h2><p>Fenner,
        M. (2023). <em>front-matter/rogue-scholar-api: Initial public release</em>
        (v0.6,2) [Computer software]. Zenodo. <a href=\\\"https://doi.org/10.5281/ZENODO.8433679\\\">https://doi.org/10.5281/ZENODO.8433679</a></p><p>Smith,
        A. M. (2023). <em>JOSS publishes 2000th paper</em>. Journal of Open Source
        Software Blog. <a href=\\\"https://doi.org/10.59349/zh4g1-q7e26\\\">https://doi.org/10.59349/zh4g1-q7e26</a></p>\",\"comment_id\":\"6524026b509bba0001454cd2\",\"feature_image\":\"https://images.unsplash.com/photo-1555952494-efd681c7e3f9?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=M3wxMTc3M3wwfDF8c2VhcmNofDM0fHxweXRob258ZW58MHx8fHwxNjk2ODU4Nzc5fDA&ixlib=rb-4.0.3&q=80&w=2000\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2023-10-09T13:38:51.000+00:00\",\"updated_at\":\"2023-10-12T08:11:37.000+00:00\",\"published_at\":\"2023-10-09T15:19:57.000+00:00\",\"custom_excerpt\":\"The
        Rogue Scholar science blog archive has launched a dedicated API today, publicly
        available at https://api.rogue-scholar.org and complementing the website.\",\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":null,\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42bbc41e317003df48d4e\",\"name\":\"Feature\",\"slug\":\"feature\",\"description\":\"Features
        explore issues raised by news stories in more depth.\",\"feature_image\":\"https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fHJlc2VhcmNofGVufDB8fHx8MTYxODEyMzQxNQ&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/feature/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42bbc41e317003df48d4e\",\"name\":\"Feature\",\"slug\":\"feature\",\"description\":\"Features
        explore issues raised by news stories in more depth.\",\"feature_image\":\"https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fHJlc2VhcmNofGVufDB8fHx8MTYxODEyMzQxNQ&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/feature/\"},\"url\":\"https://blog.front-matter.io/posts/rogue-scholar-has-an-api/\",\"excerpt\":\"The
        Rogue Scholar science blog archive has launched a dedicated API today, publicly
        available at https://api.rogue-scholar.org and complementing the website.\",\"reading_time\":3,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":\"Photo
        by <a href=\\\"https://unsplash.com/@hishahadat?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Shahadat
        Rahman</a> / <a href=\\\"https://unsplash.com/?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Unsplash</a>\"},{\"id\":\"651d174894e4e100013aeebf\",\"uuid\":\"609b3f6c-f8ee-4230-8468-4f01a40e7d0a\",\"title\":\"The
        rise of the (science) newsletter\",\"slug\":\"the-rise-of-the-science-newsletter\",\"html\":\"<p>Newsletters
        have been around forever, but their popularity has significantly increased
        in the past few years, also thanks to platforms such as <a href=\\\"https://ghost.org/\\\"
        rel=\\\"noreferrer\\\">Ghost</a>, <a href=\\\"https://medium.com/\\\" rel=\\\"noreferrer\\\">Medium</a>,
        and <a href=\\\"https://substack.com/\\\" rel=\\\"noreferrer\\\">Substack</a>.
        \ Which of course also includes science newsletters.</p><h2 id=\\\"failure-of-advertising-as-a-revenue-model\\\">Failure
        of advertising as a revenue model</h2><p>The most important driver of this
        trend is probably the realization that advertising is a poor revenue model
        for content published on the web, including blogs. Even more so for science
        content, which seldom draws a lot of traffic but rather typically caters to
        small, fragmented communities. This trend is only aggravated by the development
        of targeted advertising platforms and technologies, which don't respect the
        users' privacy and in turn led to legislation such as GDPR (<a href=\\\"https://en.wikipedia.org/wiki/General_Data_Protection_Regulation\\\"
        rel=\\\"noreferrer\\\">General Data Protection Regulation</a>), implemented
        in the European Union in May 2018. </p><h2 id=\\\"failure-of-twitter-and-social-media\\\">Failure
        of Twitter and social media</h2><p>A direct consequence of this <em>rat race
        </em>around advertising revenue and user privacy, made worse by a pandemic
        that dramatically changed how we interact online, is that social media are
        seeing the biggest changes in more than 10 years. Twitter changed ownership
        12 months ago and is no longer <em>the</em> place to communicate science,
        including finding out about new publications, science events, or science blog
        posts. One side effect of this development is that <a href=\\\"https://altmetrics.org/manifesto/\\\"
        rel=\\\"noreferrer\\\">altmetrics</a> have stopped being useful. Scientists
        have dramatically <a href=\\\"https://doi.org/10.1038/d41586-023-02554-0\\\"
        rel=\\\"noreferrer\\\">reduced their use of Twitter</a> or have moved to other
        social media platforms. And the visibility of posts on the platform formerly
        known as Twitter is now determined mainly by <a href=\\\"https://indieweb.org/algorithmic_feed\\\"
        rel=\\\"noreferrer\\\">algorithmic feeds</a> rather than their users. Facebook/Meta
        and Reddit have similar issues, and this is related to private organizations
        owning and controlling most popular social media platforms.</p><h2 id=\\\"newsletters-as-an-alternative\\\">Newsletters
        as an alternative</h2><p>Newsletters provide an <a href=\\\"https://ghost.org/resources/how-to-make-money-blogging/\\\"
        rel=\\\"noreferrer\\\">interesting alternative</a> to advertising and \\\"traditional\\\"
        social media. They are particularly promising for science blogs, as they can
        be easily combined with blogging platforms. Either as a single platform as
        with Ghost (used by this blog), Substack, or Medium, or integrated with the
        blogging platform, as several science blogs participating in Rogue Scholar
        are doing.</p><p>Newsletters can provide a revenue source that is more sustainable
        than advertising, and they reach users directly rather than depending on social
        media which currently are undergoing major changes.</p><h2 id=\\\"the-problems-with-newsletters\\\">The
        problems with newsletters</h2><p>Newsletters are not without problems. The
        biggest challenge I see is that they make it very easy to lock content behind
        a paywall. Which does not align well with the overall trend toward Open Access
        and scholarly content that is free to read and reuse.</p><p>Another challenge
        is that email is not always the best medium for scholarly communication. Email
        is fine for occasional newsletters, but doesn't really scale well. There are
        good reasons we have RSS readers and social media, and depending on newsletters
        only feels like a regression to how we communicated in the early 1990s.</p><h2
        id=\\\"conclusions\\\">Conclusions</h2><p>Newsletters are an evolving format
        that can nicely integrate with science blogs. For science blogs, it is important
        that the content remains free to read and reuse (ideally using a CC-BC license),
        and that the content remains also available via RSS feed and web page. This
        approach aligns with the <a href=\\\"https://doi.org/10.24343/C34W2H\\\" rel=\\\"noreferrer\\\">Principles
        of Open Scholarly Infrastructure</a>:</p><blockquote><strong>Revenue based
        on services, not data</strong>&nbsp;\u2013 data related to the running of
        the research enterprise should be a community property. Appropriate revenue
        sources might include value-added services, consulting, API Service Level
        Agreements or membership fees.</blockquote><p>Front Matter is offering two
        newsletters:</p><ul><li>The <strong>Front Matter newsletter</strong> distributes
        the blog posts of this blog, which currently focus on the Rogue Scholar science
        blog service and related topics. Recommended for all bloggers participating
        in the Rogue Scholar service. You can subscribe <a href=\\\"https://blog.front-matter.io/\\\"
        rel=\\\"noreferrer\\\">here</a>.</li><li>The <strong>Syldavia Gazette newsletter</strong>
        publishes summaries of interesting science blog posts found on the web, including
        an automated weekly digest of new blog posts archived in the Rogue Scholar
        science blog archive over the past seven days. You can subscribe <a href=\\\"https://syldavia-gazette.org/\\\"
        rel=\\\"noreferrer\\\">here</a>.</li></ul><p>Over the last two days I have
        reorganized the Front Matter newsletters into one technical newsletter (Front
        Matter) and one journalistic newsletter (Syldavia Gazette). In the process,
        I had to move the existing subscriptions around. Please unsubscribe if you
        now receive a Front Matter newsletter you no longer wish to receive.</p><p>The
        new format of the Syldavia Gazette newsletter (including the weekly Rogue
        Scholar digest) poses an interesting problem best described in the movie <em>Ghostbusters</em>:</p><figure
        class=\\\"kg-card kg-image-card\\\"><img src=\\\"https://media.tenor.com/2YAgdU9Ifo8AAAAC/dont-cross-the-streams-ghostbusters.gif\\\"
        class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"498\\\"
        height=\\\"206\\\"></figure><p>Rogue Scholar automatically archives all blog
        posts of participating science blogs. If the Syldavia Gazette publishes digests
        of Rogue Scholar blog posts, this could lead to an interesting loop. The solution
        was to implement a new feature in Rogue Scholar to only archive some blog
        posts using a filter. This of course is also useful for other use cases discussed
        several times where only some posts should be included in Rogue Scholar, archived,
        and assigned a DOI.</p><h2 id=\\\"references\\\">References</h2><p>Vidal Valero,
        M. (2023). Thousands of scientists are cutting back on Twitter, seeding angst
        and uncertainty. <em>Nature</em>, <em>620</em>(7974), 482\u2013484. <a href=\\\"https://doi.org/10.1038/d41586-023-02554-0\\\">https://doi.org/10.1038/d41586-023-02554-0</a></p><p>Bilder,
        G., Lin, J., &amp; Neylon, C. (2020). <em>The Principles of Open Scholarly
        Infrastructure</em>. <a href=\\\"https://doi.org/10.24343/C34W2H\\\">https://doi.org/10.24343/C34W2H</a></p><p>Fenner,
        M. (2023). <em>The Rogue Scholar weekly newsletter launches on Wednesday</em>.
        <a href=\\\"https://doi.org/10.53731/9cdnt-2k006\\\">https://doi.org/10.53731/9cdnt-2k006</a></p>\",\"comment_id\":\"651d174894e4e100013aeebf\",\"feature_image\":\"https://images.unsplash.com/photo-1518546488314-6ed28acc48e3?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=M3wxMTc3M3wwfDF8c2VhcmNofDI1fHxyaXNlfGVufDB8fHx8MTY5NjQwNTMyNnww&ixlib=rb-4.0.3&q=80&w=2000\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2023-10-04T07:42:00.000+00:00\",\"updated_at\":\"2023-10-04T17:40:14.000+00:00\",\"published_at\":\"2023-10-04T10:36:32.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":null,\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42bbc41e317003df48d4e\",\"name\":\"Feature\",\"slug\":\"feature\",\"description\":\"Features
        explore issues raised by news stories in more depth.\",\"feature_image\":\"https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fHJlc2VhcmNofGVufDB8fHx8MTYxODEyMzQxNQ&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/feature/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42bbc41e317003df48d4e\",\"name\":\"Feature\",\"slug\":\"feature\",\"description\":\"Features
        explore issues raised by news stories in more depth.\",\"feature_image\":\"https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fHJlc2VhcmNofGVufDB8fHx8MTYxODEyMzQxNQ&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/feature/\"},\"url\":\"https://blog.front-matter.io/posts/the-rise-of-the-science-newsletter/\",\"excerpt\":\"Newsletters
        have been around forever, but their popularity has significantly increased
        in the past few years, also thanks to platforms such as Ghost, Medium, and
        Substack. Which of course also includes science newsletters.\\n\\n\\nFailure
        of advertising as a revenue model\\n\\nThe most important driver of this trend
        is probably the realization that advertising is a poor revenue model for content
        published on the web, including blogs. Even more so for science content, which
        seldom draws a lot of traffic bu\",\"reading_time\":4,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":\"Photo
        by <a href=\\\"https://unsplash.com/@sutirtab?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">sutirta
        budiman</a> / <a href=\\\"https://unsplash.com/?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Unsplash</a>\"},{\"id\":\"651aebc3bdc3b90001605e56\",\"uuid\":\"78cd26b5-8e13-47d9-affd-7b9047bd3dab\",\"title\":\"Collecting
        metadata for science blog posts\",\"slug\":\"collecting-metadata\",\"html\":\"<p>Metadata
        are an important feature of every scholarly resource. For science blog posts
        \u2013 which are published with far fewer resources than for example journal
        articles or books \u2013 there is an additional requirement: make the metadata
        collection as painless as possible. In this post, I describe the lessons learned
        over the years, including recent work on the <a href=\\\"https://rogue-scholar.org\\\"
        rel=\\\"noreferrer\\\">Rogue Scholar science blog archive</a>.</p><h2 id=\\\"google-scholar-and-html-meta-tags\\\">Google
        Scholar and HTML meta tags</h2><p>Scholarly resources published on the web
        want to expose their metadata to make it easier to find them. One important
        driver is <a href=\\\"https://scholar.google.com/\\\" rel=\\\"noreferrer\\\">Google
        Scholar</a> and their <a href=\\\"https://scholar.google.com/intl/en/scholar/inclusion.html\\\"
        rel=\\\"noreferrer\\\">Inclusion Guidelines for Webmasters</a> are followed
        by most scholarly publishers and repositories. The guidelines rely heavily
        on <a href=\\\"https://developer.mozilla.org/en-US/docs/Web/HTML/Element/meta\\\"
        rel=\\\"noreferrer\\\">HTML meta tags</a>, in particular the <a href=\\\"https://div.div1.com.au/div-thoughts/div-commentaries/66-div-commentary-metadata\\\"
        rel=\\\"noreferrer\\\">Highwire Press and Dublin Core</a> subsets. One problem
        with HTML meta tags is that they can't easily describe structured content,
        such as multiple authors, each with a name and ORCID ID. The bigger problem
        for science blogs is that generating these tags is a lot of work, and not
        really supported by standard blogging platforms.</p><h2 id=\\\"schemaorg-and-google-dataset-search\\\">Schema.org
        and Google Dataset Search</h2><p><a href=\\\"https://schema.org/\\\" rel=\\\"noreferrer\\\">Schema.org</a>
        describes structured content on the internet. It overcomes the limitations
        of HTML meta tags and can easily describe structured content such as multiple
        authors, each having a given name, family name, identifier, and affiliation.
        And schema.org is heavily used by Google and other search engines. But while
        schema.org is essential for <a href=\\\"https://datasetsearch.research.google.com/\\\"
        rel=\\\"noreferrer\\\">Google Dataset Search</a> and <a href=\\\"https://doi.org/10.1038/s41597-019-0031-8\\\"
        rel=\\\"noreferrer\\\">discovery of datasets published on the internet</a>,
        it has seen little adoption to describe textual scholarly publications such
        as journal articles, conference proceedings, or books. One reason is that
        schema.org uses a very different approach from Google Scholar, another reason
        is that it is more difficult to implement.</p><p>I have used schema.org for
        many years to register DOIs with metadata for the <a href=\\\"https://datacite.org/blog/\\\"
        rel=\\\"noreferrer\\\">DataCite blog</a>. This approach worked well but was
        probably too complex to be adopted by a larger number of science blogs. One
        improvement was the combination of schema.org with HTML meta tags, but still
        required a lot of customization of each blog.</p><h2 id=\\\"rss-and-atom-feeds\\\">RSS
        and Atom Feeds</h2><p>Blogs provide a unique mechanism to distribute metadata
        and content: <a href=\\\"https://en.wikipedia.org/wiki/RSS\\\" rel=\\\"noreferrer\\\">RSS
        feeds</a>, and the related <a href=\\\"https://datatracker.ietf.org/doc/html/rfc4287\\\"
        rel=\\\"noreferrer\\\">Atom</a> and <a href=\\\"https://www.jsonfeed.org/\\\"
        rel=\\\"noreferrer\\\">JSON Feed</a> formats. These formats provide all the
        required and some of the recommended metadata needed for scholarly content,
        including title, authors, publication date, abstract, location (URL), and
        language. RSS and Atom have been around for more than 15 years (JSON Feed
        was <a href=\\\"https://www.jsonfeed.org/2017/05/17/announcing-json-feed.html\\\"
        rel=\\\"noreferrer\\\">announced</a> in 2017) and all blogging platforms support
        at least one of these formats.</p><p>RSS and related formats basically solved
        the challenge of metadata collection for science blogs, and therefore the
        Rogue Scholar science blog archive relies heavily on them. The experience
        collecting metadata and content from more than 50 different science blogs
        (using <a href=\\\"https://rogue-scholar.org/#stats\\\" rel=\\\"noreferrer\\\">11
        different blogging platforms</a>) over the past several months has been very
        positive.</p><p>One major challenge with RSS and related formats is that they
        are not very good at providing archival content as they focus on the most
        recent blog posts. Several popular blogging platforms (e.g. WordPress and
        Blogger) provide pagination to access older content, but other platforms (e.g.
        the static site generators Hugo and Jekyll) provide no built-in pagination
        of RSS feeds.</p><h2 id=\\\"blogging-platform-apis\\\">Blogging platform APIs</h2><p>RSS
        feeds are \\\"poor man's APIs\\\", e.g. they use the older XML serialization
        (RSS and Atom) instead of JSON serialization that dominates APIs today, have
        trouble accessing older content, and are read-only. </p><p>The next step in
        the evolution of metadata and content collection for science blogs is therefore
        to use existing JSON APIs, and in the last few weeks, the Rogue Scholar backend
        has been refactored to use these APIs if available. Ghost, WordPress (both
        self-hosted and WordPress.com), and Substack all provide nice JSON APIs so
        that the majority of Rogue Scholar blogs and blog posts are now retrieved
        via REST API calls. The early experience using these JSON APIs has been very
        encouraging and follows the fundamental principle of Rogue Scholar to not
        put a burden (technical, financial, or otherwise) on participating science
        blogs.</p><p>The use of blog APIs addresses another important problem: how
        are the DOIs registered by the Rogue Scholar service automatically added to
        the blogging platform? This issue is solved for several participating blogs
        using the Ghost platform and I am currently working on implementing this for
        blogs using WordPress, the most popular blogging platform on Rogue Scholar.</p><h2
        id=\\\"extracting-metadata-from-full-text-content\\\">Extracting metadata
        from full-text content</h2><p>One important limitation of using RSS feeds
        or blogging platform APIs is that they will only provide standard metadata,
        which sometimes might not be enough for scholarly content. I am currently
        exploring with one science blog extending the JSON Feed format with <a href=\\\"https://www.jsonfeed.org/version/1.1/\\\"
        rel=\\\"noreferrer\\\">extensions</a>, but that requires technical work by
        participating blogs and will probably scale poorly</p><p>A different approach
        that Rogue Scholar has followed for a few months takes advantage of the fact
        that all Rogue Scholar blog posts are available as full-text content with
        an open license (<a href=\\\"https://creativecommons.org/licenses/by/4.0/legalcode.en\\\"
        rel=\\\"noreferrer\\\">CC-BY</a>) that allows reuse. A good example of important
        metadata that are not part of RSS or REST API metadata but included in the
        full-text content is references. As they typically follow a well-known pattern
        (a <em>References</em> or <em>Bibliography</em> section followed by a list
        of references formatted with various citation styles and including a link),
        it is not too difficult to extract them and include them in the metadata registered
        with a DOI. </p><figure class=\\\"kg-card kg-image-card\\\"><img src=\\\"https://blog.front-matter.io/content/images/2023/10/article2-1-1-1.png\\\"
        class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"500\\\"
        height=\\\"722\\\"></figure><p>Rogue Scholar implemented this approach in
        <a href=\\\"https://doi.org/10.53731/6mkrk-dzh02\\\" rel=\\\"noreferrer\\\">June</a>.
        About <a href=\\\"ref.org/members/31795/works?filter=has-references:true\\\"
        rel=\\\"noreferrer\\\">10%</a> of Rogue Scholar blog posts now have their
        references registered with Crossref.</p><p>Other metadata that can be extracted
        from the full-text content describe funding information and <a href=\\\"https://www.crossref.org/documentation/schema-library/markup-guide-metadata-segments/relationships/\\\">relationships</a>,
        for example, these common use cases for science blogs:</p><ul><li><strong>IsIdenticalTo</strong>:
        The same content is cross-posted elsewhere, either on another blog or as a
        PDF in a repository,</li><li><strong>IsTranslationOf</strong>: The same content
        has been posted translated into another language,</li><li><strong>IsPreprintOf</strong>:
        The content has been published as a peer-reviewed paper in a journal,</li><li><strong>HasAward</strong>:
        The content has been funded as part of work on a research grant.</li></ul><p>I
        recently started piloting this approach with two other blogs, including relationship
        links in an <em>Acknowledgments</em> section, and converting them to Crossref
        DOI metadata. About <a href=\\\"https://www.crossref.org/members/prep/31795\\\"
        rel=\\\"noreferrer\\\">1%</a> of Rogue Scholar blog posts now include funding
        \ information and/or relationships.</p><figure class=\\\"kg-card kg-image-card
        kg-card-hascaption\\\"><img src=\\\"https://blog.front-matter.io/content/images/2023/10/Bildschirmfoto-2023-10-02-um-21.23.04.png\\\"
        class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"1550\\\"
        height=\\\"660\\\" srcset=\\\"https://blog.front-matter.io/content/images/size/w600/2023/10/Bildschirmfoto-2023-10-02-um-21.23.04.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/10/Bildschirmfoto-2023-10-02-um-21.23.04.png
        1000w, https://blog.front-matter.io/content/images/2023/10/Bildschirmfoto-2023-10-02-um-21.23.04.png
        1550w\\\" sizes=\\\"(min-width: 720px) 720px\\\"><figcaption><a href=\\\"https://doi.org/10.53731/r79v4e1-97aq74v-ag578\\\"
        rel=\\\"noreferrer\\\"><span style=\\\"white-space: pre-wrap;\\\">Acknowledgments
        and References sections</span></a><span style=\\\"white-space: pre-wrap;\\\">
        used to extract metadata.</span></figcaption></figure><h2 id=\\\"conclusions\\\">Conclusions</h2><p>Collecting
        metadata for science blogs can be challenging, and this blog post summarizes
        some of the important lessons learned. However, the experience is also encouraging,
        as collecting metadata does not have to be a frustrating and time-consuming
        experience. We have a number of complementary approaches at our disposal.
        Rogue Scholar is currently mostly processing RSS feeds and blog platform APIs,
        but we can also complement this approach with metadata from HTML meta tags
        and/or schema.org.</p><p>I am sure the last chapter of this story hasn't been
        written yet. At least two challenges remain: collecting metadata from blogs
        that are no longer active and only persist in archived form, and updating
        blog posts with registered DOIs that are written using static site generators
        hosted on platforms such as GitHub and GitLab. Twenty-five percent of Rogue
        Scholar blogs fall into the latter category and the solution probably involves
        some form of GitHub Action (or Gitlab CI/CD) that triggers a pull request.</p><h2
        id=\\\"references\\\">References</h2><p>Fenner, M., Crosas, M., Grethe, J.
        S., Kennedy, D., Hermjakob, H., Rocca-Serra, P., Durand, G., Berjon, R., Karcher,
        S., Martone, M., &amp; Clark, T. (2019). A data citation roadmap for scholarly
        data repositories. <em>Scientific Data</em>, <em>6</em>(1), Article 1. <a
        href=\\\"https://doi.org/10.1038/s41597-019-0031-8\\\">https://doi.org/10.1038/s41597-019-0031-8</a></p><p>Fenner,
        M. (2023). <em>Starting to include references in DOI metadata for blog posts</em>.
        <a href=\\\"https://doi.org/10.53731/6mkrk-dzh02\\\">https://doi.org/10.53731/6mkrk-dzh02</a></p>\",\"comment_id\":\"651aebc3bdc3b90001605e56\",\"feature_image\":\"https://blog.front-matter.io/content/images/2023/10/8071729256_19fe2e444c.jpg\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2023-10-02T16:11:47.000+00:00\",\"updated_at\":\"2023-10-02T20:02:56.000+00:00\",\"published_at\":\"2023-10-02T20:02:56.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":null,\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42bbc41e317003df48d4e\",\"name\":\"Feature\",\"slug\":\"feature\",\"description\":\"Features
        explore issues raised by news stories in more depth.\",\"feature_image\":\"https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fHJlc2VhcmNofGVufDB8fHx8MTYxODEyMzQxNQ&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/feature/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42bbc41e317003df48d4e\",\"name\":\"Feature\",\"slug\":\"feature\",\"description\":\"Features
        explore issues raised by news stories in more depth.\",\"feature_image\":\"https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fHJlc2VhcmNofGVufDB8fHx8MTYxODEyMzQxNQ&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/feature/\"},\"url\":\"https://blog.front-matter.io/posts/collecting-metadata/\",\"excerpt\":\"Metadata
        are an important feature of every scholarly resource. For science blog posts
        \u2013 which are published with far fewer resources than for example journal
        articles or books \u2013 there is an additional requirement: make the metadata
        collection as painless as possible. In this post, I describe the lessons learned
        over the years, including recent work on the Rogue Scholar science blog archive.\\n\\n\\nGoogle
        Scholar and HTML meta tags\\n\\nScholarly resources published on the web want
        to expose their metadat\",\"reading_time\":5,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":\"Photo
        from user cea via <a href=\\\"https://www.flickr.com/photos/centralasian/8071729256/\\\">Flickr</a>.\"},{\"id\":\"651173cd0538110001aae364\",\"uuid\":\"f74a9d32-0d7d-40ea-9c77-7f07ffaebbd1\",\"title\":\"Use
        cases for science blogs: grant-funded projects\",\"slug\":\"use-cases-for-science-blogs-grant-funded-projects\",\"html\":\"<p>The
        <a href=\\\"https://rogue-scholar.org\\\" rel=\\\"noreferrer\\\">Rogue Scholar
        science blog archive</a> is open to science blogs that want to be enhanced
        by adding long-term archiving, DOI registration, and full-text search. The
        currently 56 participating blogs represent a broad spectrum of topics, people,
        and communities. Today I want to go into more detail into one particular Rogue
        Scholar use case: science blogs for grant-funded projects.</p>\\n<p>Science
        blogs for grant-funded projects typically have the following features:</p>\\n<ul><li>Science
        blogs are part of the outreach activities of many grant-funded projects.</li><li>They
        complement other project outputs that include publications, presentations,
        datasets, and software.</li><li>Funders want to see the impact these outputs,
        including the blog, have on relevant communities.</li><li>Grant-funded projects
        are a time-limited activity of typically 24-36 months, but the impact ideally
        continues to grow past the funding period.</li></ul>\\n<p>From the above it
        becomes clear that grant-funded research that includes a blog as part of its
        outreach activities, has to think about two major issues:</p>\\n<ul><li>How
        to track the impact of the science blog in ways that can inform the project
        team and the funder? </li><li>How do we maintain the content of the science
        blog beyond the funding period?</li></ul>\\n<p>Rogue Scholar can help with
        this use case, and I have implemented this for Project THOR.</p>\\n<h2 id=\\\"project-thor\\\">Project
        THOR</h2>\\n<p>Project THOR \u2013 Technical and Human Infrastructure for
        Open Research is a research project funded by the the European Union\u2019s
        Horizon 2020 research and innovation programme under&nbsp;<a href=\\\"https://doi.org/10.3030/654039\\\">grant
        agreement No 654039</a> that was carried out between June 2015 and November
        2019. It had nine participating organizations and was coordinated by the British
        Library. I joined DataCite in August 2015 as Technical Director and was deeply
        involved in THOR. The <a href=\\\"https://doi.org/10.59350/e346f-2jg53\\\"
        rel=\\\"noreferrer\\\">goals of the project </a>were</p>\\n<blockquote>THOR
        will build on the services provided by ORCID and DataCite to ensure that every
        researcher, at any phase of their career, or at any institution, will have
        seamless and free access to Persistent Identifiers (PIDs) for their research
        artefacts and their work will be uniquely attributed to them.</blockquote>\\n<p>The
        project started a <a href=\\\"https://project-thor.eu/\\\" rel=\\\"noreferrer\\\">blog</a>
        to report on project activities and project outputs and published 66 blog
        posts during the 30-month project duration. The public project outputs are
        available via <a href=\\\"https://zenodo.org\\\" rel=\\\"noreferrer\\\">Zenodo</a>
        and in various publications.</p>\\n<p>Almost four years after the project
        ended, the blog is unfortunately no longer publicly accessible, and several
        key people involved in THOR have moved on to other projects, and organizations,
        or have retired. This is a typical story for grant-funded projects, but painful
        as THOR is about persistent identifiers and services. </p>\\n<p>Fast-forward
        to September 2023 and the launch of Rogue Scholar, and we can now make these
        changes:</p>\\n<ul><li><a href=\\\"https://rogue-scholar.org/blogs/thor\\\"
        rel=\\\"noreferrer\\\">Register the THOR blog with Rogue Scholar </a>and archive
        the full-text of all blog posts, available via search. A search for <a href=\\\"https://rogue-scholar.org/posts?page=1&amp;query=content+drift\\\"
        rel=\\\"noreferrer\\\">content drift</a> finds the blog post about the THOR
        final event where Herbert van de Sompel gave a keynote.</li><li>Register DOIs
        for all blog posts, with metadata that includes the abstract, authors (with
        ORCID ID), and funding information \u2013 the <a href=\\\"https://doi.org/10.3030/654039\\\"
        rel=\\\"noreferrer\\\">THOR grant</a>. This enables searching for outputs
        funded by THOR via Crossref or other services using Crossref and/or ORCID
        metadata</li><li>Have the DOIs point to archived versions of blog posts at
        the <a href=\\\"https://archive.org/\\\" rel=\\\"noreferrer\\\">Internet Archive</a>,
        enabling reading of the full text of all blog posts despite the blog no longer
        being publicly available.</li></ul>\\n<figure class=\\\"kg-card kg-image-card
        kg-card-hascaption\\\"><img src=\\\"https://blog.front-matter.io/content/images/2023/09/Bildschirmfoto-2023-09-25-um-14.52.11.png\\\"
        class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"1920\\\"
        height=\\\"1262\\\" srcset=\\\"https://blog.front-matter.io/content/images/size/w600/2023/09/Bildschirmfoto-2023-09-25-um-14.52.11.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/09/Bildschirmfoto-2023-09-25-um-14.52.11.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/09/Bildschirmfoto-2023-09-25-um-14.52.11.png
        1600w, https://blog.front-matter.io/content/images/2023/09/Bildschirmfoto-2023-09-25-um-14.52.11.png
        1920w\\\" sizes=\\\"(min-width: 720px) 720px\\\"><figcaption><span style=\\\"white-space:
        pre-wrap;\\\">Project THOR in </span><a href=\\\"https://rogue-scholar.org/blogs/thor\\\"
        rel=\\\"noreferrer\\\"><span style=\\\"white-space: pre-wrap;\\\">Rogue Scholar</span></a></figcaption></figure>\\n<p>The
        ideal time to think about including the blog of a grant-funded science project
        in Rogue Scholar is of course at the start of the project and not four years
        after the project has ended. Please <a href=\\\"mailto:info@front-matter.io\\\"
        rel=\\\"noreferrer\\\">reach out to Rogue Scholar</a> if you manage a blog
        for a grant-funded science project. The costs for automatically archiving
        all posts, indexing them for full-text search, and registering DOIs are very
        reasonable (a $1 per blog post one-time fee), with additional optional fees
        if you want training and/or reporting.</p>\\n<h2 id=\\\"references\\\">References</h2>\\n<p>Brown,
        J. (2015). <em>The next step for open science: A state-of-the-art identifier
        network</em>. <a href=\\\"https://doi.org/10.59350/e346f-2jg53\\\">https://doi.org/10.59350/e346f-2jg53</a></p>\\n<p>Fenner,
        M. (2015). <em>Thank you PLOS</em>. <a href=\\\"https://doi.org/10.53731/r294649-6f79289-8cvzn\\\">https://doi.org/10.53731/r294649-6f79289-8cvzn</a></p>\",\"comment_id\":\"651173cd0538110001aae364\",\"feature_image\":\"https://images.unsplash.com/photo-1517048676732-d65bc937f952?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=M3wxMTc3M3wwfDF8c2VhcmNofDI3fHxwcm9qZWN0fGVufDB8fHx8MTY5NTY0MjU4MHww&ixlib=rb-4.0.3&q=80&w=2000\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2023-09-25T11:49:33.000+00:00\",\"updated_at\":\"2023-09-25T13:42:56.000+00:00\",\"published_at\":\"2023-09-25T13:23:07.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/mh9a1-dw902\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"},\"url\":\"https://blog.front-matter.io/posts/use-cases-for-science-blogs-grant-funded-projects/\",\"excerpt\":\"The
        Rogue Scholar science blog archive is open to science blogs that want to be
        enhanced by adding long-term archiving, DOI registration, and full-text search.
        The currently 56 participating blogs represent a broad spectrum of topics,
        people, and communities. Today I want to go into more detail into one particular
        Rogue Scholar use case: science blogs for grant-funded projects.\\n\\n\\nScience
        blogs for grant-funded projects typically have the following features:\\n\\n\\n
        * Science blogs are part of the out\",\"reading_time\":3,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":\"Photo
        by <a href=\\\"https://unsplash.com/@dylandgillis?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Dylan
        Gillis</a> / <a href=\\\"https://unsplash.com/?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Unsplash</a>\"},{\"id\":\"650d58ae0538110001aae161\",\"uuid\":\"74cfb01d-2a6a-4d65-9cf0-e994a3db3428\",\"title\":\"DOI
        registration workflow for a science blog\",\"slug\":\"doi-registration-workflow-science-blog\",\"html\":\"<p>In
        previous blog posts such as the one <a href=\\\"https://doi.org/10.53731/gvb08-7kc16\\\"
        rel=\\\"noreferrer\\\">published earlier this week</a>, I discussed the various
        elements involved in registering a DOI for a science blog post. Briefly, the
        <a href=\\\"https://rogue-scholar.org\\\" rel=\\\"noreferrer\\\">Rogue Scholar</a>
        service takes advantage of the fact that blogs </p>\\n<ul><li>use RSS feeds
        (or the Atom or JSON Feed format) to distribute content and metadata at the
        time of publication, </li><li>these feeds contain the most important metadata
        needed for publication \u2013 such as title, authors, publication date, and
        </li><li>addition metadata (such as abstract and references) can be automatically
        extracted from the full-text content included in the feed.</li></ul>\\n<p>This
        basic workflow can be optimized in many ways, for example including funding
        information (watch out for a blog post next week), but one fundamental issue
        remains to be solved: how does the blog learn about the DOI registered for
        a new post, and automatically adds it to the blog?</p>\\n<h2 id=\\\"canonical-url\\\">Canonical
        URL</h2>\\n<p>As much as possible Rogue Scholar takes advantage of technologies
        that have existed for a long time and are not specific to scholarly content.
        That's why the service works with existing blogs that use standard blogging
        software - currently <a href=\\\"https://rogue-scholar.org/#stats\\\" rel=\\\"noreferrer\\\">eleven
        different platforms</a>, the most popular being Wordpress, Ghost, and Hugo.</p>\\n<p>These
        platforms don't know about DOIs without extra work, but they all know about
        a similar concept: <a href=\\\"https://developers.google.com/search/docs/crawling-indexing/canonicalization\\\"
        rel=\\\"noreferrer\\\">canonical URLs</a>. Wikipedia <a href=\\\"https://en.wikipedia.org/wiki/Canonical_link_element\\\"
        rel=\\\"noreferrer\\\">explains</a>:</p>\\n<blockquote>A&nbsp;<strong>canonical
        link element</strong>&nbsp;is an&nbsp;HTML element&nbsp;that helps&nbsp;webmasters&nbsp;prevent&nbsp;duplicate
        content&nbsp;issues in&nbsp;search engine optimization&nbsp;by specifying
        the \\\"canonical\\\" or \\\"preferred\\\" version of a web page. It is described
        in RFC 6596, which went live in April 2012.</blockquote>\\n<p>The problem
        canonical URLs are addressing is duplicate content at different locations
        that can confuse search engines such as Google or Bing. This is related to
        the problem persistent identifiers such as DOIs are addressing for the scholarly
        community: accessing content over long periods of time that may change its
        location on the web (its URL), with two inter-related strategies:</p>\\n<ul><li><strong>URL
        redirection</strong>. DOIs <a href=\\\"https://doi.org/10.5281/zenodo.1324300\\\"
        rel=\\\"noreferrer\\\">redirect to a target URL</a> that can be changed by
        the publisher,</li><li><strong>Persistence</strong>. The publisher of scholarly
        content makes an extra effort to make sure content doesn't disappear (<a href=\\\"https://doi.org/10.1371/journal.pone.0115253\\\"
        rel=\\\"noreferrer\\\">link rot</a>), or significantly change (<a href=\\\"Deane-Pratt,
        A. (2017). THhttps://doi.org/10.59350/p000s-pth40\\\" rel=\\\"noreferrer\\\">content
        drift</a>).</li></ul>\\n<p>Obviously, canonical URLs are not DOIs, but they
        provide a standard way for a science blog to add a DOI to a post.</p>\\n<h2
        id=\\\"backends\\\">Backends</h2>\\n<p>Science blogs provide a backend to
        store content and metadata, including the canonical URL. This can either be
        a database (as in the case of Wordpress or Ghost) or a file (as in the case
        of Hugo and many other <a href=\\\"https://jamstack.org/generators/\\\" rel=\\\"noreferrer\\\">static
        site generators</a>).</p>\\n<h3 id=\\\"wordpress\\\">Wordpress</h3>\\n<p>Wordpress
        doesn't know about canonical URLs out of the box, but they can be added via
        a plugin, the most popular for this being <a href=\\\"https://yoast.com/help/canonical-urls-in-yoast-seo/\\\"
        rel=\\\"noreferrer\\\">Yoast SEO</a> (which comes in free and paid versions).
        After installing and activating the plugin you can add a canonical URL in
        a new Yoast SEO section of the post editor:</p>\\n<figure class=\\\"kg-card
        kg-image-card\\\"><img src=\\\"https://blog.front-matter.io/content/images/2023/09/Bildschirmfoto-2023-09-22-um-13.25.21.png\\\"
        class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"1276\\\"
        height=\\\"444\\\" srcset=\\\"https://blog.front-matter.io/content/images/size/w600/2023/09/Bildschirmfoto-2023-09-22-um-13.25.21.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/09/Bildschirmfoto-2023-09-22-um-13.25.21.png
        1000w, https://blog.front-matter.io/content/images/2023/09/Bildschirmfoto-2023-09-22-um-13.25.21.png
        1276w\\\" sizes=\\\"(min-width: 720px) 720px\\\"></figure>\\n<p>Alternatively,
        you can <a href=\\\"https://redpishi.com/wordpress-tutorials/canonical-urls-in-wordpress/\\\"
        rel=\\\"noreferrer\\\">fiddle with your Wordpress configuration</a> to add
        a custom field for the canonical URL.</p>\\n<h3 id=\\\"ghost\\\">Ghost</h3>\\n<p>The
        Ghost blogging platform has a canonical URL field for every post, which you
        can access from the post settings sidebar:</p>\\n<figure class=\\\"kg-card
        kg-image-card\\\"><img src=\\\"https://blog.front-matter.io/content/images/2023/09/Bildschirmfoto-2023-09-22-um-13.33.03.png\\\"
        class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"1014\\\"
        height=\\\"544\\\" srcset=\\\"https://blog.front-matter.io/content/images/size/w600/2023/09/Bildschirmfoto-2023-09-22-um-13.33.03.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/09/Bildschirmfoto-2023-09-22-um-13.33.03.png
        1000w, https://blog.front-matter.io/content/images/2023/09/Bildschirmfoto-2023-09-22-um-13.33.03.png
        1014w\\\" sizes=\\\"(min-width: 720px) 720px\\\"></figure>\\n<h3 id=\\\"hugo\\\">Hugo</h3>\\n<p>Hugo
        and other Open Source static site generators give you a lot of flexibility
        with metadata. If you add a <code>canonicalUrl</code> field to the blog post
        Front Matter, you can reuse it for the canonical URL (with some <a href=\\\"https://blog.concannon.tech/tech-talk/hugo-canonical-url/\\\"
        rel=\\\"noreferrer\\\">additional work</a>).</p>\\n<p>The canonical URL or
        DOI is now stored with the blog post, but also exposed to web crawlers. The
        format is <code>&lt;link rel=\\\"canonical\\\" href=\\\"<a href=\\\"https://doi.org/10.53731/gvb08-7kc16\\\"
        rel=\\\"noreferrer noopener\\\"><code>https://doi.org/10.53731/gvb08-7kc16</code></a>\\\"&gt;</code>.</p>\\n<h2
        id=\\\"frontends\\\">Frontends</h2>\\n<p>To display the canonical URL aka
        DOI on your blog frontend, you have to modify your blog theme, the popular
        themes for Wordpress, Ghost, and Hugo don't really support displaying the
        canonical URL out of the box, as they are primarily intended for web crawlers
        and not humans.</p>\\n<p>You should follow the <a href=\\\"https://doi.org/10.13003/5jchdy\\\"
        rel=\\\"noreferrer\\\">Crossref DOI display guidelines</a>, when thinking
        about how to display the DOI for your blog post, i.e. always be displayed
        as a clickable full URL link. Rogue Scholar displays DOIs like this: </p>\\n<figure
        class=\\\"kg-card kg-image-card\\\"><img src=\\\"https://blog.front-matter.io/content/images/2023/09/Bildschirmfoto-2023-09-22-um-13.57.23.png\\\"
        class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"1104\\\"
        height=\\\"228\\\" srcset=\\\"https://blog.front-matter.io/content/images/size/w600/2023/09/Bildschirmfoto-2023-09-22-um-13.57.23.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/09/Bildschirmfoto-2023-09-22-um-13.57.23.png
        1000w, https://blog.front-matter.io/content/images/2023/09/Bildschirmfoto-2023-09-22-um-13.57.23.png
        1104w\\\" sizes=\\\"(min-width: 720px) 720px\\\"></figure>\\n<p>This blog
        (using the Ghost platform) displays DOIs like this in a sidebar: </p>\\n<figure
        class=\\\"kg-card kg-image-card\\\"><img src=\\\"https://blog.front-matter.io/content/images/2023/09/Bildschirmfoto-2023-09-22-um-13.59.54-1.png\\\"
        class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"460\\\"
        height=\\\"169\\\"></figure>\\n<h2 id=\\\"doi-registration-workflow\\\">DOI
        registration workflow</h2>\\n<p>The changes to the backend and frontend explained
        above are good enough for occasional blog posts or to get started with Rogue
        Scholar. After a blog post is published, Rogue Scholar will register a DOI
        <a href=\\\"https://doi.org/10.53731/gvb08-7kc16\\\" rel=\\\"noreferrer\\\">within
        30 minutes</a> and show that DOI on the <a href=\\\"https://rogue-scholar.org/blogs/andrewheiss\\\"
        rel=\\\"noreferrer\\\">website</a> or via <a href=\\\"https://rogue-scholar.org/api/blogs/tcw6w29\\\"
        rel=\\\"noreferrer\\\">API</a>. You can then copy/paste that DOI into your
        new canonical URL field. A simple improvement would be notifications of new
        DOI registrations by email, similar to what Crossref is sending to Front Matter
        as the Crossref member:</p>\\n<pre><code class=\\\"language-xml\\\">&lt;?xml
        version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?&gt;\\n&lt;doi_batch_diagnostic
        status=\\\"completed\\\" sp=\\\"ds5\\\"&gt;\\n   &lt;submission_id&gt;1590342900&lt;/submission_id&gt;\\n
        \  &lt;batch_id&gt;8a637b09-fda6-4980-baa1-147497683bd9&lt;/batch_id&gt;\\n
        \  &lt;record_diagnostic status=\\\"Success\\\"&gt;\\n      &lt;doi&gt;10.53731/w6nzs-jta75&lt;/doi&gt;\\n
        \     &lt;msg&gt;Successfully added&lt;/msg&gt;\\n      &lt;citations_diagnostic&gt;\\n
        \        &lt;citation key=\\\"ref1\\\" status=\\\"resolved_reference\\\"&gt;10.53731/gvb08-7kc16&lt;/citation&gt;\\n
        \        &lt;citation key=\\\"ref2\\\" status=\\\"resolved_reference\\\"&gt;Cite
        to nonCR doi: 10.5281/zenodo.1324300&lt;/citation&gt;\\n         &lt;citation
        key=\\\"ref3\\\" status=\\\"resolved_reference\\\"&gt;10.1371/journal.pone.0115253&lt;/citation&gt;\\n
        \        &lt;citation key=\\\"ref4\\\" status=\\\"resolved_reference\\\"&gt;10.59350/p000s-pth40&lt;/citation&gt;\\n
        \        &lt;citation key=\\\"ref5\\\" status=\\\"resolved_reference\\\"&gt;10.53731/r79x921-97aq74v-ag5a2&lt;/citation&gt;\\n
        \     &lt;/citations_diagnostic&gt;\\n   &lt;/record_diagnostic&gt;\\n   &lt;batch_data&gt;\\n
        \     &lt;record_count&gt;1&lt;/record_count&gt;\\n      &lt;success_count&gt;1&lt;/success_count&gt;\\n
        \     &lt;warning_count&gt;0&lt;/warning_count&gt;\\n      &lt;failure_count&gt;0&lt;/failure_count&gt;\\n
        \  &lt;/batch_data&gt;\\n&lt;/doi_batch_diagnostic&gt;</code></pre>\\n<p>But
        maybe including a clickable link to the DOI just registered and some basic
        metadata that were registered (as it takes a few hours until the metadata
        show up in the Crossref REST API).</p>\\n<p>For blogs with a more frequent
        publication frequency (e.g. weekly or daily) this workflow should be automated.
        One important consideration is whether the blog should know the DOI that will
        be registered in advance, avoiding the round trip with Rogue Scholar and Crossref,
        and allowing customizations of the DOI name, such as <code>10.53731/front-matter.2023-09-19</code>.
        The biggest advantage would be that the DOI name can be shared in advance
        of publication, e.g. for press releases, or to reference in other content.</p>\\n<p>While
        these considerations are reasonable and not new for DOIs in general, for the
        science blog use case the workflow should be simple and I want to follow these
        principles:</p>\\n<ul><li>Rogue Scholar DOIs will be generated as a short
        random 10-character string upon DOI registration. Rogue Scholar users or staff
        can't modify the DOI names that will be generated. Rogue Scholar DOIs are
        <a href=\\\"10.53731/r79x921-97aq74v-ag5a2\\\" rel=\\\"noreferrer\\\">cool
        DOIs</a>.</li><li>If you see a Rogue Scholar DOI, it can be used (immediately
        as a link, accessing the metadata after a few hours). Rogue Scholar is not
        offering DOIs that are not or not fully registered, i.e. DOIs for <a href=\\\"https://www.crossref.org/documentation/research-nexus/pending-publication\\\"
        rel=\\\"noreferrer\\\">pending publications</a> (Crossref) or <a href=\\\"https://support.datacite.org/docs/doi-states\\\"
        rel=\\\"noreferrer\\\">draft DOIs</a> (DataCite).</li><li>DOI registration
        happens with the Rogue Scholar service talking to the Crossref API, participating
        blogs don't need to install or develop functionality to generate Crossref
        metadata and/or interact with the Crossref API.</li></ul>\\n<p>The easiest
        architecture for automatically sending the registered DOI names back to the
        blog is using the blog API. I have this implemented for the blogs where Rogue
        Scholar has admin access to the blog API (this blog and two other blogs using
        the Ghost platform), and this updates the blog post immediately after DOI
        registration as part of the same GitHub Action. Most Rogue Scholar blogs have
        a write API, and in the case of static site generators, the underlying repository
        platform (typically GitHub or GitLab) has an API. If your blog is updated
        more than once a month and is hosted by Wordpress, Ghost, Hugo, or Jekyll,
        reach out to me if you want to participate in the DOI registration beta workflow.
        </p>\\n<h2 id=\\\"references\\\">References</h2>\\n<p>Fenner, M. (2023). <em>Streamlining
        the archiving of science blog posts</em>. <a href=\\\"https://doi.org/10.53731/gvb08-7kc16\\\">https://doi.org/10.53731/gvb08-7kc16</a></p>\\n<p>Wimalaratne,
        S., &amp; Fenner, M. (2018). <em>D2.1 Pid Resolution Services Best Practices</em>.
        <a href=\\\"https://doi.org/10.5281/ZENODO.1324300\\\">https://doi.org/10.5281/ZENODO.1324300</a></p>\\n<p>Klein,
        M., Sompel, H. V. de, Sanderson, R., Shankar, H., Balakireva, L., Zhou, K.,
        &amp; Tobin, R. (2014). Scholarly Context Not Found: One in Five Articles
        Suffers from Reference Rot. <em>PLOS ONE</em>, <em>9</em>(12), e115253. <a
        href=\\\"https://doi.org/10.1371/journal.pone.0115253\\\">https://doi.org/10.1371/journal.pone.0115253</a></p>\\n<p>Deane-Pratt,
        A. (2017). <em>THOR\u2019s last hurrah</em>. <a href=\\\"https://doi.org/10.59350/p000s-pth40\\\">https://doi.org/10.59350/p000s-pth40</a></p>\\n<p>Fenner,
        M. (2016). <em>Cool DOIs</em>. <a href=\\\"https://doi.org/10.53731/r79x921-97aq74v-ag5a2\\\">https://doi.org/10.53731/r79x921-97aq74v-ag5a2</a></p>\",\"comment_id\":\"650d58ae0538110001aae161\",\"feature_image\":\"https://images.unsplash.com/photo-1595126731003-755959b6baf8?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=M3wxMTc3M3wwfDF8c2VhcmNofDEyfHxyZWdpc3RyYXRpb258ZW58MHx8fHwxNjk1MzczNDkzfDA&ixlib=rb-4.0.3&q=80&w=2000\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2023-09-22T09:04:46.000+00:00\",\"updated_at\":\"2023-09-22T13:41:17.000+00:00\",\"published_at\":\"2023-09-22T13:15:45.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/w6nzs-jta75\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"},\"url\":\"https://blog.front-matter.io/posts/doi-registration-workflow-science-blog/\",\"excerpt\":\"In
        previous blog posts such as the one published earlier this week, I discussed
        the various elements involved in registering a DOI for a science blog post.
        Briefly, the Rogue Scholar service takes advantage of the fact that blogs\\n\\n\\n
        * use RSS feeds (or the Atom or JSON Feed format) to distribute content and
        metadata at the time of publication,\\n * these feeds contain the most important
        metadata needed for publication \u2013 such as title, authors, publication
        date, and\\n * addition metadata (such as ab\",\"reading_time\":6,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":\"Photo
        by <a href=\\\"https://unsplash.com/@tiffanytertipes?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Tiffany
        Tertipes</a> / <a href=\\\"https://unsplash.com/?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Unsplash</a>\"},{\"id\":\"6509473a4e05250001e02f74\",\"uuid\":\"0b337924-2d09-4252-9766-9b84e5e37dcd\",\"title\":\"Streamlining
        the archiving of science blog posts\",\"slug\":\"streamlining\",\"html\":\"<p>The
        <a href=\\\"https://rogue-scholar.org\\\" rel=\\\"noreferrer\\\">Rogue Scholar
        science blog</a> archive is adding important functionality to existing science
        blogs. The first step after a blog has signed up with Rogue Scholar is archiving
        the content. This is not only needed for long-term preservation but also enables
        full-text search and DOI registration with meaningful metadata. Rogue Scholar
        uses the blog feed (in RSS, Atom, or JSON Feed format) for this, which is
        updated the moment a blog post is published or updated. </p>\\n<p>The elegant
        approach would be to notify Rogue Scholar when this happens so that Rogue
        Scholar can fetch the updated content, using a technology called <a href=\\\"https://en.wikipedia.org/wiki/Webhook\\\"
        rel=\\\"noreferrer\\\">webhooks</a>. But one important principle of Rogue
        Scholar is simplicity, not requiring any additional technical work for the
        participating blogs unless absolutely necessary. This means that at least
        for the time being regular checks of the blog feed are more appropriate for
        Rogue Scholar, and with a small update yesterday this workflow has been greatly
        improved. </p>\\n<p>Rogue Scholar now checks all participating blogs for new
        or updated content every 10 minutes. When new or updated content is found,
        it is processed and stored in the Rogue Scholar Postgres database within a
        minute. This in turn triggers an update of full-text search index running
        in <a href=\\\"https://typesense.org/\\\" rel=\\\"noreferrer\\\">Typesense</a>
        which takes another minute. Rogue Scholar checks every 10 minutes whether
        a blog post is new or the metadata used for DOI registration have changed
        and triggers a DOI update. DOI registration consists of two parts:</p>\\n<ul><li>Registration
        of the DOI and URL in the DOI resolution service, so that <a href=\\\"https://doi.org/10.53731/xszpd-6z265\\\">https://doi.org/10.53731/xszpd-6z265</a>
        redirects to <a href=\\\"https://blog.front-matter.io/posts/releasing-commonmeta-py-v0-8/\\\">https://blog.front-matter.io/posts/releasing-commonmeta-py-v0-8/</a>.
        This happens within a few minutes.</li><li>Registration of DOI metadata, so
        that blog post metadata can be found via Crossref services. This happens within
        a few hours.</li></ul>\\n<p>While writing this blog post, I got two emails
        from Crossref telling me about new content registered with Crossref. There
        were two blog posts by Rogue Scholar blogs this morning published 4 and 11
        minutes before the DOIs were successfully registered, compared to the delay
        of several hours (and in a few cases even longer) before this update.</p>\\n<p>With
        this new workflow in place, another bottleneck now becomes more visible. Rogue
        Scholar and Crossref (and all the services that use Crossref metadata) now
        know about the DOIs registered for blog posts, but how do the participating
        blogs learn about this? For the special case where the blog has an API and
        Rogue Scholar is allowed to write to it (currently this blog and the <a href=\\\"https://upstream.force11.org\\\"
        rel=\\\"noreferrer\\\">Upstream</a> blog, which both use the Ghost blogging
        platform), this happens automatically as part of the DOI registration GitHub
        Action. </p>\\n<p>For all other blogs participating in Rogue Scholar that
        is still something I have to figure out, and the main challenge is again to
        come up with a workflow that doesn't require major technical work for the
        participating blogs. One strategy would be to come up with solutions for the
        individual blogging platforms, starting with Wordpress which is used by <a
        href=\\\"https://rogue-scholar.org/#stats\\\" rel=\\\"noreferrer\\\">42% of
        Rogue Scholar blogs</a>. Obviously, a solution for this issue is more important
        for blogs that are updated frequently than blogs that are updated only a few
        times per month. Stay tuned.</p>\\n<h2 id=\\\"references\\\">References</h2>\\n<p>Fenner,
        M. (2023). <em>Releasing commonmeta-py v0.8</em>. <a href=\\\"https://doi.org/10.53731/xszpd-6z265\\\">https://doi.org/10.53731/xszpd-6z265</a></p>\",\"comment_id\":\"6509473a4e05250001e02f74\",\"feature_image\":\"https://images.unsplash.com/photo-1476725994324-6f6833ea0631?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=M3wxMTc3M3wwfDF8c2VhcmNofDM1fHxmYXN0fGVufDB8fHx8MTY5NTEwNjkzN3ww&ixlib=rb-4.0.3&q=80&w=2000\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2023-09-19T07:01:14.000+00:00\",\"updated_at\":\"2023-09-19T08:35:56.000+00:00\",\"published_at\":\"2023-09-19T08:26:31.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/gvb08-7kc16\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"},\"url\":\"https://blog.front-matter.io/posts/streamlining/\",\"excerpt\":\"The
        Rogue Scholar science blog archive is adding important functionality to existing
        science blogs. The first step after a blog has signed up with Rogue Scholar
        is archiving the content. This is not only needed for long-term preservation
        but also enables full-text search and DOI registration with meaningful metadata.
        Rogue Scholar uses the blog feed (in RSS, Atom, or JSON Feed format) for this,
        which is updated the moment a blog post is published or updated.\\n\\n\\nThe
        elegant approach would be to no\",\"reading_time\":2,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":\"Photo
        by <a href=\\\"https://unsplash.com/@andersjilden?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Anders
        Jild\xE9n</a> / <a href=\\\"https://unsplash.com/?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Unsplash</a>\"},{\"id\":\"6500860835bff50001b796d0\",\"uuid\":\"68af6cb0-3cb0-4c76-af94-2c7d7c55a6c8\",\"title\":\"Releasing
        commonmeta-py v0.8\",\"slug\":\"releasing-commonmeta-py-v0-8\",\"html\":\"<p>Today
        I am happy to announce the release of <a href=\\\"https://pypi.org/project/commonmeta-py/\\\">commonmeta-py
        v0.8</a>, the next major release of the Python scholarly metadata conversion
        library. There are numerous changes in this release compared to v0.7.1 released
        in March, in particular:</p>\\n<ul><li>Added support for metadata conversions
        from the <a href=\\\"https://www.jsonfeed.org/\\\" rel=\\\"noreferrer\\\">JSON
        Feed</a> and <a href=\\\"https://inveniordm.docs.cern.ch/reference/metadata/\\\"
        rel=\\\"noreferrer\\\">InvenioRDM</a> formats.</li><li>Updated commonmeta
        JSON schema to v.10.1. The biggest changes are added support for file metadata
        and contributor roles.</li><li>Many bug fixes and small improvements.</li></ul>\\n<h2
        id=\\\"json-feed\\\">JSON Feed</h2>\\n<p><a href=\\\"https://www.jsonfeed.org/\\\"
        rel=\\\"noreferrer\\\">JSON Feed</a> is a syndication format for blogs and
        other periodical content and uses JSON instead of XML serialization used by
        the RSS and Atom formats. The <a href=\\\"https://rogue-scholar.org\\\" rel=\\\"noreferrer\\\">Rogue
        Scholar blog archive</a> that I started earlier this year makes heavy use
        of JSON Feed and uses it to convert blog post metadata to Crossref XML and
        then register DOIs for them. For the about 5,000 DOIs for blog posts that
        I have registered so far, I used <a href=\\\"https://github.com/features/actions\\\"
        rel=\\\"noreferrer\\\">GitHub Actions</a> and the <a href=\\\"https://doi.org/10.5281/ZENODO.7752775\\\"
        rel=\\\"noreferrer\\\">commonmeta-ruby</a> library. As the number of blog
        posts registered every day is constantly increasing, I need to refactor the
        Rogue Scholar backend to properly handle that, and I decided to build a dedicated
        Python API to replace the GitHub Actions workflow. This work will start in
        October, and adding JSON Feed support to commonmeta-py is an important step.</p>\\n<h2
        id=\\\"files-metadata\\\">Files metadata</h2>\\n<p>One big addition in commonmeta
        v0.10, and supported in the new release of commonmeta-py, is metadata for
        content associated with a scholarly resource. In the simplest case, this is
        a direct download link to a publication or software, but it can also mean
        download links to multiple files each with file size, file type, and checksum.
        The best implementation is currently the new InvenioRDM commonmeta-py format,
        but files metadata are also supported in the schema.org format, and partially
        in DataCite and Crossref formats. Files metadata are particularly important
        for automated machine access to content, whereas human users are typically
        first directed to a landing page with links to download content. To properly
        use this functionality, the content should be available with an open license
        such as <a href=\\\"mmons.org/licenses/by/4.0/\\\" rel=\\\"noreferrer\\\">CC-BY</a>,
        <a href=\\\"https://opensource.org/license/mit/\\\" rel=\\\"noreferrer\\\">MIT</a>,
        or <a href=\\\"https://creativecommons.org/share-your-work/public-domain/cc0/\\\"
        rel=\\\"noreferrer\\\">CC Zero</a> \u2013 licenses have been supported in
        commonmeta since the first release.</p>\\n<h2 id=\\\"contributor-roles\\\">Contributor
        roles</h2>\\n<p>Authorship of scholarly content has become more complex over
        the years, with many publications typically requiring multiple authors, often
        with dedicated roles. The Contributor Roles Taxonomy (CRediT), now <a href=\\\"https://credit.niso.org/\\\"
        rel=\\\"noreferrer\\\">hosted by NISO</a>, was started 10 years ago to address
        this complexity and has been adopted by an increasing number of publishers.
        One remaining problem is that CRediT was developed for text publications and
        has limited support for other publication types, e.g. datasets or software.
        Another problem is the different terminologies used. ORCID use <strong>contributor</strong>
        and has <a href=\\\"https://info.orcid.org/credit-for-research-contribution/\\\"
        rel=\\\"noreferrer\\\">added support for CRediT</a> in 2021. Crossref uses
        <strong>contributor</strong> and has <a href=\\\"https://www.crossref.org/documentation/schema-library/markup-guide-metadata-segments/contributors/\\\"
        rel=\\\"noreferrer\\\">defined different contributor roles</a> that are different
        from CRediT. DataCite (based on work in <a href=\\\"https://www.dublincore.org/specifications/dublin-core/dcmi-terms/elements11/contributor/\\\"
        rel=\\\"noreferrer\\\">Dublin Core</a>) uses the <a href=\\\"https://doi.org/10.14454/3W3Z-SA82\\\"
        rel=\\\"noreferrer\\\">concepts of <strong>creator</strong> and <strong>contributor</strong></a>,
        where creators are <em>the main researchers involved in producing the data,
        or the authors of the publication</em> whereas a contributor is <em>the institution
        or person responsible for collecting, managing, distributing, or otherwise
        contributing to the development of the resource. </em></p>\\n<p>A complex
        problem, but one important step forward would be to align these different
        taxonomies in commonmeta. Commonmeta v0.10 has therefore dropped the <strong>creator</strong>
        property in favor of <strong>contributor</strong>, added support for contributor
        roles from CRediT, Crossref, and DataCite, and added support for multiple
        contributor roles. The various metadata formats supported in commonmeta implementations
        such as <em>commonmeta-py</em> can then use a subset of these contributor
        roles. An example would be the <strong>editor</strong> role which is used
        in Crossref, DataCite, BibTeX, schema.org, and citation style language (CSL)
        metadata. Going forward commonmeta can consolidate these roles and add new
        roles needed for particular use cases and metadata formats, e.g. the <strong>maintainer</strong>
        role for software used by codemeta.</p>\\n<h2 id=\\\"references\\\">References</h2>\\n<p>Fenner,
        Martin. (2023). <em>Commonmeta-ruby</em> (v3.0.1) [Computer software]. Zenodo.
        <a href=\\\"https://doi.org/10.5281/ZENODO.7752775\\\">https://doi.org/10.5281/ZENODO.7752775</a></p>\\n<p>Fenner,
        M. (2021). <em>First InvenioRDM Long-Term Support (LTS) version released today\u202F
        and Front Matter is joining as a participating partner</em>. <a href=\\\"https://doi.org/10.53731/r8c26t1-97aq74v-ag66m\\\">https://doi.org/10.53731/r8c26t1-97aq74v-ag66m</a></p>\\n<p>Allen,
        L., Scott, J., Brand, A., Hlava, M., &amp; Altman, M. (2014). Publishing:
        Credit where credit is due. <em>Nature</em>, <em>508</em>(7496), 312\u2013313.
        <a href=\\\"https://doi.org/10.1038/508312a\\\">https://doi.org/10.1038/508312a</a></p>\\n<p>Hosseini,
        M., Kerridge, S., Allen, L., Kiermer, V., &amp; Holmes, K. L. (2023). <em>Enhancing
        Understanding and Adoption of the Contributor Roles Taxonomy (CRediT)</em>.
        <a href=\\\"https://doi.org/10.31222/osf.io/n6249\\\">https://doi.org/10.31222/osf.io/n6249</a></p>\\n<p>DataCite
        Metadata Working Group. (2021). <em>DataCite Metadata Schema Documentation
        for the Publication and Citation of Research Data and Other Research Outputs
        v4.4</em>. 82 pages. <a href=\\\"https://doi.org/10.14454/3W3Z-SA82\\\">https://doi.org/10.14454/3W3Z-SA82</a></p>\",\"comment_id\":\"6500860835bff50001b796d0\",\"feature_image\":\"https://images.unsplash.com/photo-1589794094880-be5a4daf3e11?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=M3wxMTc3M3wwfDF8c2VhcmNofDN8fGNvbW1vbnxlbnwwfHx8fDE2OTQ1MzMxNDB8MA&ixlib=rb-4.0.3&q=80&w=2000\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2023-09-12T15:38:48.000+00:00\",\"updated_at\":\"2023-09-12T17:43:03.000+00:00\",\"published_at\":\"2023-09-12T17:31:18.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/xszpd-6z265\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"},\"url\":\"https://blog.front-matter.io/posts/releasing-commonmeta-py-v0-8/\",\"excerpt\":\"Today
        I am happy to announce the release of commonmeta-py v0.8, the next major release
        of the Python scholarly metadata conversion library. There are numerous changes
        in this release compared to v0.7.1 released in March, in particular:\\n\\n\\n
        * Added support for metadata conversions from the JSON Feed and InvenioRDM
        formats.\\n * Updated commonmeta JSON schema to v.10.1. The biggest changes
        are added support for file metadata and contributor roles.\\n * Many bug fixes
        and small improvements.\\n\\n\\n\\nJSON Fee\",\"reading_time\":3,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":\"Photo
        by <a href=\\\"https://unsplash.com/@ekaterina221b?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Ekaterina
        Z.</a> / <a href=\\\"https://unsplash.com/?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Unsplash</a>\"},{\"id\":\"64f5d470fc96ff00012a5f7b\",\"uuid\":\"3968d002-1a87-4b56-85f4-8ebc32ac2751\",\"title\":\"New
        in Rogue Scholar: filter posts by language\",\"slug\":\"filter-posts-by-language\",\"html\":\"<p>The
        <a href=\\\"https://rogue-scholar.org\\\" rel=\\\"noreferrer\\\">Rogue Scholar
        science blog archive</a> received a small update today with the following
        changes: optionally filter blog posts by language, added support for all OECD
        fields of science and technology, and searching by DOI. And it passed another
        big milestone: more than 5,000 (<a href=\\\"https://rogue-scholar.org/de/posts\\\"
        rel=\\\"noreferrer\\\">5,483</a> today) blog posts are now archived.</p>\\n<h3
        id=\\\"filter-blog-posts-by-language\\\">Filter blog posts by language</h3>\\n<p>Rogue
        Scholar supports science blog posts in any language and the user interface
        supports English, Spanish, German, French, Portuguese, and Italian. Ninety
        percent of the archived blog posts are in English, the rest in German or Spanish.
        With the new filter you can limit search results to your preferred language,
        e.g. German:</p>\\n<figure class=\\\"kg-card kg-image-card\\\"><img src=\\\"https://blog.front-matter.io/content/images/2023/09/Bildschirmfoto-2023-09-04-um-15.10.17.png\\\"
        class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"1904\\\"
        height=\\\"914\\\" srcset=\\\"https://blog.front-matter.io/content/images/size/w600/2023/09/Bildschirmfoto-2023-09-04-um-15.10.17.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/09/Bildschirmfoto-2023-09-04-um-15.10.17.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/09/Bildschirmfoto-2023-09-04-um-15.10.17.png
        1600w, https://blog.front-matter.io/content/images/2023/09/Bildschirmfoto-2023-09-04-um-15.10.17.png
        1904w\\\" sizes=\\\"(min-width: 720px) 720px\\\"></figure>\\n<p>This new feature
        hopefully makes it easier to find content in languages other than English
        and encourages more non-English science blogs to join Rogue Scholar.</p>\\n<h3
        id=\\\"support-for-all-oecd-fields\\\">Support for all OECD fields</h3>\\n<p>Subject
        area classification is one important way to find interesting blogs and blog
        posts. Rogue Scholar started out with the six top-level categories of the
        widely used <a href=\\\"https://www.oecd.org/science/inno/38235147.pdf\\\"
        rel=\\\"noreferrer\\\">OECD Fields of Science and Technology</a>. This week
        I am adding all 43 second-level categories for a little bit more fine-grained
        detail. This makes it possible to identify two blogs included in the Rogue
        Scholar as chemistry blogs and two other blogs as writing about languages
        and literature.</p>\\n<figure class=\\\"kg-card kg-image-card\\\"><img src=\\\"https://blog.front-matter.io/content/images/2023/09/Bildschirmfoto-2023-09-04-um-15.28.10.png\\\"
        class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"2000\\\"
        height=\\\"557\\\" srcset=\\\"https://blog.front-matter.io/content/images/size/w600/2023/09/Bildschirmfoto-2023-09-04-um-15.28.10.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/09/Bildschirmfoto-2023-09-04-um-15.28.10.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/09/Bildschirmfoto-2023-09-04-um-15.28.10.png
        1600w, https://blog.front-matter.io/content/images/size/w2400/2023/09/Bildschirmfoto-2023-09-04-um-15.28.10.png
        2400w\\\" sizes=\\\"(min-width: 720px) 720px\\\"></figure>\\n<p>This is the
        first iteration of improved OECD fields of science support. Not all categories
        are already translated into all six supported languages, and the classification
        into a specific category is sometimes not easy. If you are responsible for
        a blog on Rogue Scholar, you can change the subject category in your admin
        dashboard. Future versions of this functionality will support multiple fields
        of science per blog, and support the (automated) classification of individual
        posts using machine learning.</p>\\n<h3 id=\\\"searching-by-doi\\\">Searching
        by DOI</h3>\\n<p>The full-text index was updated to support searching by DOI,
        either as identifier for a blog post or in the references. Searching for the
        Force11 Software Citation Principles (<a href=\\\"https://doi.org/10.7717/peerj-cs.86\\\"
        rel=\\\"noreferrer\\\">10.7717/peerj-cs.86</a>) for example returns 14 results
        from six different blogs:</p>\\n<figure class=\\\"kg-card kg-image-card\\\"><img
        src=\\\"https://blog.front-matter.io/content/images/2023/09/Bildschirmfoto-2023-09-04-um-15.30.49.png\\\"
        class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"1936\\\"
        height=\\\"1344\\\" srcset=\\\"https://blog.front-matter.io/content/images/size/w600/2023/09/Bildschirmfoto-2023-09-04-um-15.30.49.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/09/Bildschirmfoto-2023-09-04-um-15.30.49.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/09/Bildschirmfoto-2023-09-04-um-15.30.49.png
        1600w, https://blog.front-matter.io/content/images/2023/09/Bildschirmfoto-2023-09-04-um-15.30.49.png
        1936w\\\" sizes=\\\"(min-width: 720px) 720px\\\"></figure>\\n<p>This functionality
        will be further enhanced in the future by integrating with the Crossref <a
        href=\\\"https://www.crossref.org/services/cited-by/\\\" rel=\\\"noreferrer\\\">Cited-By</a>
        service to find citations of Rogue Scholar blog posts elsewhere.</p>\\n<h3
        id=\\\"references\\\">References</h3>\\n<p>Smith, A. M., Katz, D. S., Niemeyer,
        K. E., &amp; FORCE11 Software Citation Working Group. (2016). Software citation
        principles. <em>PeerJ Computer Science</em>, <em>2</em>, e86. <a href=\\\"https://doi.org/10.7717/peerj-cs.86\\\">https://doi.org/10.7717/peerj-cs.86</a></p>\",\"comment_id\":\"64f5d470fc96ff00012a5f7b\",\"feature_image\":\"https://images.unsplash.com/photo-1601520525445-1039c1fa232b?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=M3wxMTc3M3wwfDF8c2VhcmNofDh8fGxhbmd1YWdlfGVufDB8fHx8MTY5MzgzMjMwOXww&ixlib=rb-4.0.3&q=80&w=2000\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2023-09-04T12:58:24.000+00:00\",\"updated_at\":\"2023-09-04T13:48:20.000+00:00\",\"published_at\":\"2023-09-04T13:42:47.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/ggtnh-1as93\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"},\"url\":\"https://blog.front-matter.io/posts/filter-posts-by-language/\",\"excerpt\":\"The
        Rogue Scholar science blog archive received a small update today with the
        following changes: optionally filter blog posts by language, added support
        for all OECD fields of science and technology, and searching by DOI. And it
        passed another big milestone: more than 5,000 (5,483 today) blog posts are
        now archived.\\n\\n\\n\\nFilter blog posts by language\\n\\n\\nRogue Scholar
        supports science blog posts in any language and the user interface supports
        English, Spanish, German, French, Portuguese, and Italian\",\"reading_time\":2,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":\"Photo
        by <a href=\\\"https://unsplash.com/@lajaxx?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">JACQUELINE
        BRANDWAYN</a> / <a href=\\\"https://unsplash.com/?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Unsplash</a>\"},{\"id\":\"64ec5c8ae107b30001d69e20\",\"uuid\":\"64bba421-1a7b-4e96-bfcd-58ec6d6e57e0\",\"title\":\"Rogue
        Scholar is growing\",\"slug\":\"rogue-scholar-is-growing\",\"html\":\"<p>The
        <a href=\\\"https://rogue-scholar.org/\\\">Rogue Scholar science blog archive</a>
        continues to grow. It is closing in on 50 science blogs (currently <a href=\\\"https://rogue-scholar.org/blogs\\\">45</a>),
        3,000 blog posts (currently <a href=\\\"https://rogue-scholar.org/posts\\\">2,944</a>,
        of which <a href=\\\"https://api.crossref.org/members/31795/works\\\">2,775</a>
        have a DOI), and 250 (currently <a href=\\\"https://api.crossref.org/members/31795/works?filter=has-references:true\\\">212</a>)
        blog posts with references registered with Crossref. I have set up eleven
        Mastodon bots for Rogue Scholar blogs after <a href=\\\"https://doi.org/10.53731/f1mhr-wps22\\\">announcing
        the feature</a> last week. We have achieved 32% of our funding goal to pay
        for the archiving of all current Rogue Scholar blog posts.</p>\\n<figure class=\\\"kg-card
        kg-image-card\\\"><img src=\\\"https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-28-um-10.49.56.png\\\"
        class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"423\\\"
        height=\\\"290\\\"></figure>\\n<p>Also last week, Rogue Scholar added the
        first <a href=\\\"https://rogue-scholar.org/blogs/norbisley\\\">Spanish-language
        blog</a> and the first two blogs covering Chemistry (<a href=\\\"https://rogue-scholar.org/blogs/cwagen\\\">here</a>
        and <a href=\\\"https://rogue-scholar.org/blogs/rzepa\\\">here</a>). </p>\\n<h3
        id=\\\"whats-next\\\">What's next?</h3>\\n<p>We have done some preliminary
        work to explore the feasibility of storing blog posts as <a href=\\\"https://en.wikipedia.org/wiki/EPUB\\\">ePub</a>
        files. This is particularly interesting since <a href=\\\"https://forums.zotero.org/discussion/106716/available-for-beta-testing-updated-reader-with-epub-snapshot-support-and-new-annotation-types\\\">version
        7 of the Zotero reference manager</a> will support storing ePub files next
        to metadata, and already integrates nicely with Rogue Scholar: </p>\\n<figure
        class=\\\"kg-card kg-image-card kg-card-hascaption\\\"><img src=\\\"https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-28-um-12.28.10.png\\\"
        class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"1910\\\"
        height=\\\"1050\\\" srcset=\\\"https://blog.front-matter.io/content/images/size/w600/2023/08/Bildschirmfoto-2023-08-28-um-12.28.10.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/08/Bildschirmfoto-2023-08-28-um-12.28.10.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/08/Bildschirmfoto-2023-08-28-um-12.28.10.png
        1600w, https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-28-um-12.28.10.png
        1910w\\\" sizes=\\\"(min-width: 720px) 720px\\\"><figcaption><span>Zotero
        picks up references from a </span><a href=\\\"https://rogue-scholar.org/posts?page=1&amp;query=open+access\\\"
        rel=\\\"noreferrer\\\"><span>Rogue Scholar search</span></a><span>.</span></figcaption></figure>\\n<p>The
        preliminary work on ePub looks good but requires a major architectural change
        in the backend, which is planned for October.</p>\\n<p>Last week Rogue Scholar
        started launching Mastodon bots for the participating science blogs. This
        service is opt-in, i.e. the blog has to give Rogue Scholar permission to launch
        the bot and announce new blog posts (<a href=\\\"mailto:info@front-matter.io\\\">via
        email</a> is the easiest way). The information about the blog provided in
        Mastodon is exactly the same as on the <a href=\\\"https://rogue-scholar.org/blogs\\\">Rogue
        Scholar blogs</a> page.</p>\\n<figure class=\\\"kg-card kg-image-card\\\"><img
        src=\\\"https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-28-um-12.33.18.png\\\"
        class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"2000\\\"
        height=\\\"980\\\" srcset=\\\"https://blog.front-matter.io/content/images/size/w600/2023/08/Bildschirmfoto-2023-08-28-um-12.33.18.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/08/Bildschirmfoto-2023-08-28-um-12.33.18.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/08/Bildschirmfoto-2023-08-28-um-12.33.18.png
        1600w, https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-28-um-12.33.18.png
        2344w\\\" sizes=\\\"(min-width: 720px) 720px\\\"></figure>\\n<p>The information
        posted to the Fediverse by the bot when a new blog post is published is again
        very similar to what you see on the <a href=\\\"https://rogue-scholar.org/posts\\\">Rogue
        Scholar posts</a> page but allows direct interactions, e.g. like, boost, bookmark,
        or comment.</p>\\n<figure class=\\\"kg-card kg-image-card\\\"><img src=\\\"https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-28-um-12.44.08.png\\\"
        class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"2000\\\"
        height=\\\"1182\\\" srcset=\\\"https://blog.front-matter.io/content/images/size/w600/2023/08/Bildschirmfoto-2023-08-28-um-12.44.08.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/08/Bildschirmfoto-2023-08-28-um-12.44.08.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/08/Bildschirmfoto-2023-08-28-um-12.44.08.png
        1600w, https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-28-um-12.44.08.png
        2006w\\\" sizes=\\\"(min-width: 720px) 720px\\\"></figure>\\n<p>The Mastodon
        version 4.2.0 release planned for September enables searching of all public
        posts, and I will work on proper support for searching for the DOI of the
        blog post.</p>\\n<h3 id=\\\"what-you-can-do-with-the-rogue-scholar\\\">What
        you can do with the Rogue Scholar</h3>\\n<ul><li>If you write for a blog that
        you want to be included in the Rogue Scholar, sign up <a href=\\\"https://rogue-scholar.org/auth/signin\\\">here</a>.</li><li>If
        you like to read content via the Rogue Scholar, search for posts <a href=\\\"https://rogue-scholar.org/posts\\\">here</a>,
        follow one or more of the blogs via Mastodon <a href=\\\"https://rogue-scholar.social/directory\\\">here</a>,
        or follow the RSS/Atom feeds of participating blogs <a href=\\\"https://rogue-scholar.org/blogs\\\">here</a></li><li>If
        you want to support Rogue Scholar financially, donate <a href=\\\"https://ko-fi.com/rogue_scholar\\\">here</a>.</li><li>If
        you want to learn more about the Rogue Scholar, reach out to me via <a href=\\\"mailto:info@front-matter.io\\\">email</a>,
        <a href=\\\"https://hachyderm.io/@mfenner\\\">Mastodon</a>, or <a href=\\\"https://discord.gg/HvbD4dNPFh\\\">Discord</a>.</li></ul>\\n<h3
        id=\\\"references\\\">References</h3>\\n<p>Fenner, M. (2023). <em>Rogue Scholar
        joins the Fediverse</em>. <a href=\\\"https://doi.org/10.53731/f1mhr-wps22\\\">https://doi.org/10.53731/f1mhr-wps22</a></p>\",\"comment_id\":\"64ec5c8ae107b30001d69e20\",\"feature_image\":\"https://images.unsplash.com/photo-1590415024718-798cdaab96dd?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=M3wxMTc3M3wwfDF8c2VhcmNofDJ8fGdyb3d8ZW58MHx8fHwxNjkzMjExNzkwfDA&ixlib=rb-4.0.3&q=80&w=2000\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2023-08-28T08:36:26.000+00:00\",\"updated_at\":\"2023-08-28T15:53:06.000+00:00\",\"published_at\":\"2023-08-28T11:05:16.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/hv15p-dx796\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"},\"url\":\"https://blog.front-matter.io/posts/rogue-scholar-is-growing/\",\"excerpt\":\"The
        Rogue Scholar science blog archive continues to grow. It is closing in on
        50 science blogs (currently 45), 3,000 blog posts (currently 2,944, of which
        2,775 have a DOI), and 250 (currently 212) blog posts with references registered
        with Crossref. I have set up eleven Mastodon bots for Rogue Scholar blogs
        after announcing the feature last week. We have achieved 32% of our funding
        goal to pay for the archiving of all current Rogue Scholar blog posts.\\n\\n\\n\\nAlso
        last week, Rogue Scholar added the \",\"reading_time\":2,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":\"Photo
        by <a href=\\\"https://unsplash.com/@chetankolte56?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Chetan
        Kolte</a> / <a href=\\\"https://unsplash.com/?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Unsplash</a>\"},{\"id\":\"64e30c392b0a4f000195bc2f\",\"uuid\":\"3614b3ff-3353-4f81-990c-95ed2e0722ca\",\"title\":\"Rogue
        Scholar joins the Fediverse\",\"slug\":\"rogue-scholar-joins-fediverse\",\"html\":\"<p>Today
        I am happy to announce that the Rogue Scholar science blog archive has joined
        the <a href=\\\"https://en.wikipedia.org/wiki/Fediverse\\\">Fediverse</a>,
        the federated social network that communicates using the&nbsp;<a href=\\\"https://en.wikipedia.org/wiki/ActivityPub\\\">ActivityPub</a>&nbsp;protocol.
        I have launched a Mastodon instance at <a href=\\\" https://rogue-scholar.social\\\">Rogue
        Scholar Social</a> that accepts Science Blog bots as accounts, publishing
        summaries of blog posts.</p>\\n<figure class=\\\"kg-card kg-image-card kg-card-hascaption\\\"><img
        src=\\\"https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-21-um-09.25.37.png\\\"
        class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"2000\\\"
        height=\\\"1289\\\" srcset=\\\"https://blog.front-matter.io/content/images/size/w600/2023/08/Bildschirmfoto-2023-08-21-um-09.25.37.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/08/Bildschirmfoto-2023-08-21-um-09.25.37.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/08/Bildschirmfoto-2023-08-21-um-09.25.37.png
        1600w, https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-21-um-09.25.37.png
        2392w\\\" sizes=\\\"(min-width: 720px) 720px\\\"><figcaption><span>Local live
        feed at </span><a href=\\\"https://rogue-scholar.social/public/local\\\" rel=\\\"noreferrer\\\"><span>https://rogue-scholar.social/public/local</span></a></figcaption></figure>\\n<p>Science
        blogs are typically read by going to the blog homepage with a web browser
        or using an RSS reader. More recently, newsletters have also become popular.
        These three approaches (web, feed reader, and email) combine discovery and
        reading of content in different ways. The discovery part can be augmented
        by social media, and Twitter has played a central role in this for more than
        10 years. Unfortunately, Twitter (as we knew it) no longer exists, and we
        have to use other social media channels to discover interesting scholarly
        content.</p>\\n<p>In the past nine months, <a href=\\\"https://mastodon.social\\\">Mastodon</a>,
        has emerged as <a href=\\\"https://doi.org/10.1038/d41586-023-02554-0\\\">the
        most popular alternative to Twitter for scientists</a>. It is fundamentally
        different from Twitter, and other popular social media providers. It is based
        on a federated architecture (using the <a href=\\\"https://en.wikipedia.org/wiki/ActivityPub\\\">ActivityPub</a>
        protocol) and uses Open Source software (<a href=\\\"https://github.com/mastodon/mastodon\\\">available
        on GitHub</a>) so that everybody can install their own instance of Mastodon
        (<a href=\\\"https://github.com/BasixKOR/awesome-activitypub\\\">or other
        software using the ActivityPub protocol</a>). This flexibility and openness
        make using Mastodon harder to use but easier to customize to the needs of
        a science blog reader.</p>\\n<p>The Rogue Scholar Mastodon instance is different
        from most other Mastodon instances in that it is not open for new users to
        join. It doesn't have personal accounts, only bots for blogs that participate
        in the Rogue Scholar science blog archive. To create a Mastodon account for
        your blog, open your blog configuration in the Rogue Scholar dashboard (login
        via the sign in link on the <a href=\\\"https://rogue-scholar.org/\\\">Rogue
        Scholar homepage</a>) and enter a unique name (only lowercase letters and
        underscore are allowed). Account creation and posting messages for new blog
        posts are not automated yet, but there is nothing else for blog authors to
        do. </p>\\n<figure class=\\\"kg-card kg-image-card\\\"><img src=\\\"https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-21-um-09.59.49.png\\\"
        class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"1230\\\"
        height=\\\"1438\\\" srcset=\\\"https://blog.front-matter.io/content/images/size/w600/2023/08/Bildschirmfoto-2023-08-21-um-09.59.49.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/08/Bildschirmfoto-2023-08-21-um-09.59.49.png
        1000w, https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-21-um-09.59.49.png
        1230w\\\" sizes=\\\"(min-width: 720px) 720px\\\"></figure>\\n<p>As a science
        blog reader, go to the Rogue Scholar Mastodon instance profiles directory
        and subscribe to one or more science blogs participating in the Rogue Scholar
        Mastodon service.</p>\\n<figure class=\\\"kg-card kg-image-card\\\"><img src=\\\"https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-21-um-11.30.16.png\\\"
        class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"925\\\"
        height=\\\"839\\\" srcset=\\\"https://blog.front-matter.io/content/images/size/w600/2023/08/Bildschirmfoto-2023-08-21-um-11.30.16.png
        600w, https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-21-um-11.30.16.png
        925w\\\" sizes=\\\"(min-width: 720px) 720px\\\"></figure>\\n<p>Depending on
        your Mastodon client (here I use <a href=\\\"https://tapbots.com/ivory/mac/\\\">Ivory</a>
        for Mac) you see a summary of the latest blog post in your feed. Clicking
        on the link (the DOI) leads you to the full-text post, but you can also like,
        share or boost the blog post, or post a comment.</p>\\n<figure class=\\\"kg-card
        kg-image-card\\\"><img src=\\\"https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-21-um-11.36.39-1.png\\\"
        class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"1048\\\"
        height=\\\"531\\\" srcset=\\\"https://blog.front-matter.io/content/images/size/w600/2023/08/Bildschirmfoto-2023-08-21-um-11.36.39-1.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/08/Bildschirmfoto-2023-08-21-um-11.36.39-1.png
        1000w, https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-21-um-11.36.39-1.png
        1048w\\\" sizes=\\\"(min-width: 720px) 720px\\\"></figure>\\n<p>If you have
        problems configuring Mastodon for your blog in Rogue Scholar, or following
        a Rogue Scholar blog via Mastodon, <a href=\\\"mailto:info@front-matter.io\\\">send
        an email</a> or <a href=\\\"https://hachyderm.io/@mfenner\\\">ping me on Mastodon</a>.</p>\\n<p>The
        next steps in the next few weeks are:</p>\\n<ul><li>Refine the Rogue Scholar
        / Mastodon integration, including automation</li><li>Look into features currently
        missing but important for science blogs such as integration with full-text
        search and support for more metadata. The Rogue Scholar Mastodon instance
        is running the latest beta version of Mastodon (<a href=\\\"https://github.com/mastodon/mastodon/releases/tag/v4.2.0-beta1\\\">v4.2.0-beta1</a>),
        which displays more information in the preview card (blog name, publication
        date, and beginning of description):</li></ul>\\n<figure class=\\\"kg-card
        kg-image-card\\\"><img src=\\\"https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-21-um-12.01.34.png\\\"
        class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"573\\\"
        height=\\\"631\\\"></figure>\\n<h3 id=\\\"references\\\">References</h3>\\n<p>Vidal
        Valero, M. (2023). Thousands of scientists are cutting back on Twitter, seeding
        angst and uncertainty. <em>Nature</em>, <em>620</em>(7974), 482\u2013484.
        <a href=\\\"https://doi.org/10.1038/d41586-023-02554-0\\\">https://doi.org/10.1038/d41586-023-02554-0</a></p>\",\"comment_id\":\"64e30c392b0a4f000195bc2f\",\"feature_image\":\"https://images.unsplash.com/photo-1582213782179-e0d53f98f2ca?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=M3wxMTc3M3wwfDF8c2VhcmNofDF8fGpvaW58ZW58MHx8fHwxNjkyNjAxNTA1fDA&ixlib=rb-4.0.3&q=80&w=2000\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2023-08-21T07:03:21.000+00:00\",\"updated_at\":\"2023-08-21T11:21:06.000+00:00\",\"published_at\":\"2023-08-21T10:05:02.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/f1mhr-wps22\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"},\"url\":\"https://blog.front-matter.io/posts/rogue-scholar-joins-fediverse/\",\"excerpt\":\"Today
        I am happy to announce that the Rogue Scholar science blog archive has joined
        the Fediverse, the federated social network that communicates using the\_ActivityPub\_protocol.
        I have launched a Mastodon instance at Rogue Scholar Social that accepts Science
        Blog bots as accounts, publishing summaries of blog posts.\\n\\n\\n\\nScience
        blogs are typically read by going to the blog homepage with a web browser
        or using an RSS reader. More recently, newsletters have also become popular.
        These three approach\",\"reading_time\":3,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":\"Photo
        by <a href=\\\"https://unsplash.com/@hannahbusing?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Hannah
        Busing</a> / <a href=\\\"https://unsplash.com/?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Unsplash</a>\"},{\"id\":\"64db65232b0a4f000195bbaa\",\"uuid\":\"aff7a174-8d7b-45c0-b789-632c72ed408b\",\"title\":\"New
        Rogue Scholar milestone and funding drive\",\"slug\":\"new-rogue-scholar-milestone-and\",\"html\":\"<p>This
        week the Rogue Scholar science blog archive reached another big milestone:
        2,000 blog posts archived (2,242 as of today). This was achieved by adding
        new blogs (now 39) but, more importantly, by archiving older posts from the
        participating blogs. Twenty-one of the 39 science blogs now have all their
        posts archived at the Rogue Scholar, are included in the full-text search,
        and have (with two exceptions) DOIs and metadata registered for them. This
        was only possible via the financial contributions that Rogue Scholar received
        last week when I launched the new <a href=\\\"https://doi.org/10.53731/c09py-3we11\\\">financial
        support options</a>. Thank you Rogue Scholar supporters!</p>\\n<p>Reaching
        one milestone of course means setting up a new goal for the Rogue Scholar:
        5,000 posts from 50 science blogs. A big part of that is archiving all (about
        1,500) posts from the participating blogs not yet included in Rogue Scholar.
        This costs money (paying for database and file hosting, DOI registration,
        and development work needed), and many blogs included in Rogue Scholar are
        personal blogs and can't pay the $1 per post one-time fee that Rogue Scholar
        is charging (beyond 50 free posts per year) to support the Rogue Scholar infrastructure.
        I am therefore asking everyone who wants to support Rogue Scholar (as a blog
        author as well as a reader) for as little as $3 (the price of a coffee), to
        use the <a href=\\\"https://ko-fi.com/rogue_scholar\\\">Buy me a coffee</a>
        link in the Rogue Scholar menu bar, and contribute. All donations count towards
        a goal of $1500 and progress can be tracked on the <a href=\\\"https://ko-fi.com/rogue_scholar\\\">KO-fi
        Buy me a coffee page</a>:</p>\\n<figure class=\\\"kg-card kg-image-card\\\"><img
        src=\\\"https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-15-um-14.12.57.png\\\"
        class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"872\\\"
        height=\\\"594\\\" srcset=\\\"https://blog.front-matter.io/content/images/size/w600/2023/08/Bildschirmfoto-2023-08-15-um-14.12.57.png
        600w, https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-15-um-14.12.57.png
        872w\\\" sizes=\\\"(min-width: 720px) 720px\\\"></figure>\\n<h3 id=\\\"references\\\">References</h3>\\n<p>Fenner,
        M. (2023). <em>How to support Rogue Scholar?</em> <a href=\\\"https://doi.org/10.53731/c09py-3we11\\\">https://doi.org/10.53731/c09py-3we11</a></p>\",\"comment_id\":\"64db65232b0a4f000195bbaa\",\"feature_image\":\"https://images.unsplash.com/photo-1571334374861-5e51ddfc58ce?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=M3wxMTc3M3wwfDF8c2VhcmNofDJ8fG1pbGVzdG9uZXxlbnwwfHx8fDE2OTIxMDA2ODB8MA&ixlib=rb-4.0.3&q=80&w=2000\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2023-08-15T11:44:35.000+00:00\",\"updated_at\":\"2023-08-15T17:24:37.000+00:00\",\"published_at\":\"2023-08-15T12:20:29.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/gqvhe-je521\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":null,\"url\":\"https://blog.front-matter.io/posts/new-rogue-scholar-milestone-and/\",\"excerpt\":\"This
        week the Rogue Scholar science blog archive reached another big milestone:
        2,000 blog posts archived (2,242 as of today). This was achieved by adding
        new blogs (now 39) but, more importantly, by archiving older posts from the
        participating blogs. Twenty-one of the 39 science blogs now have all their
        posts archived at the Rogue Scholar, are included in the full-text search,
        and have (with two exceptions) DOIs and metadata registered for them. This
        was only possible via the financial contribu\",\"reading_time\":1,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":\"Photo
        by <a href=\\\"https://unsplash.com/@t_galler?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Thomas
        Galler</a> / <a href=\\\"https://unsplash.com/?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Unsplash</a>\"},{\"id\":\"64d0b4af12cdf20001f5eacd\",\"uuid\":\"c3f21136-dc1e-4e2b-a18c-fbe44dba130e\",\"title\":\"How
        to support Rogue Scholar?\",\"slug\":\"how-to-support-rogue-scholar\",\"html\":\"<p>The
        <a href=\\\"https://rogue-scholar.org\\\">Rogue Scholar science blog archive</a>
        adds important functionality to existing science blogs, namely archiving,
        full-text search, and DOI registration. While a lot of effort has gone into
        making Rogue Scholar as affordable as possible by using Open Source software,
        automation, and involving the community, it still costs money to build and
        run scholarly infrastructure, including scholarly infrastructure for science
        blogs.</p>\\n<p>We made a few fundamental decisions even before starting Rogue
        Scholar:</p>\\n<ul><li>Time-limited funds are used only for time-limited activities</li><li>Mission-consistent
        revenue generation</li><li>Revenue based on services, not data</li><li>Open
        source</li><li>Open data (within constraints of privacy laws)</li></ul>\\n<p>These
        principles of course come from the <a href=\\\"https://doi.org/10.24343/C34W2H\\\">Principles
        of Open Scholarly Infrastructure</a> (POSI). It is too early for Rogue Scholar
        for a<a href=\\\"https://openscholarlyinfrastructure.org/posse/\\\"> formal
        commitment to POSI</a>, because it only launched a few months ago, and has
        no formal governance structure in place. Rogue Scholar is run by Front Matter,
        a German organization <a href=\\\"https://doi.org/10.53731/r87krmh-97aq74v-ag5x0\\\">started
        by me in 2021</a>. Front Matter is not (yet) a non-profit under German law
        because the overhead of starting and running a non-profit in Germany is considerable.
        The topic of Rogue Scholar governance is important, but in this blog post
        I want to focus on one aspect of POSI.</p>\\n<h3 id=\\\"mission-consistent-revenue-generation\\\">Mission-consistent
        revenue generation</h3>\\n<p>Rogue Scholar helps blogs that publish their
        content under an open license. Creative Commons Attribution (<a href=\\\"https://creativecommons.org/licenses/by/4.0/legalcode\\\">CC-BY
        4.0</a>) is the appropriate license for scholarly publications, <a href=\\\"https://oaspa.org/why-cc-by/\\\">as
        explained by the Open Access Publishers Association</a> (OASPA). Therefore
        content is always free to read, share and adapt for users of Rogue Scholar,
        and I hope to see interesting services and other implementations evolve over
        time.</p>\\n<p>Consistent with the POSI principle <em>revenue based on services,
        not data</em>, I could see newsletters as a possible revenue source in the
        future, as long as content always remains accessible free of charge via webpage
        or RSS feed. Newsletters are a service that <a href=\\\"https://www.listenupih.com/ghost-post/\\\">has
        become popular with blogs in the past few years</a>, either to complement
        existent access models (good), unfortunately sometimes to restrict access
        (bad). Last <a href=\\\"https://doi.org/10.53731/9cdnt-2k006\\\">week I started</a>
        the <em>Rogue Scholar Digest</em> newsletter which sends weekly summaries
        of the Rogue Scholar posts the last seven days on Wednesdays. The newsletter
        is generated automatically without any manual curation of either the most
        interesting posts or posts about a particular topic, so it would not be appropriate
        to charge for it.</p>\\n<p>Advertising on science blogs is a revenue model
        that has been tried for many years but overall has failed to deliver. Maybe
        science content isn't popular enough unless published by a few very popular
        bloggers. In addition, it is a very annoying business model that goes with
        tracking users and clicks, hopefully something that you will never see with
        the Rogue Scholar.</p>\\n<p>Article Processing Charges (APC) as a cost model
        for journal articles are receiving a lot of criticism, for example in <a href=\\\"https://doi.org/10.59350/d1zfz-8cs77\\\">this
        blog post by Brembs</a>. It is critical to keep the costs for publishing scholarly
        content down and to be transparent about it. A good example is the Journal
        of Open Source Software (JOSS) which <a href=\\\"https://doi.org/10.59349/g4fz2-1cr36\\\">in
        2019 reported</a> a cost of about $100 per paper, paid for by grant funding.
        Rogue Scholar is looking at a cost of $1 per blog post in direct costs (compared
        to $2.71 for JOSS), but that does not include the costs of running a blogging
        platform or staff costs of editing papers (both paid by participating blogs)
        and developing the software platform (paid by Front Matter). </p>\\n<p>Many
        science blogs are written by individuals in their \\\"free\\\" time as academics
        or science journalists. It wouldn't be appropriate to charge them for participating
        in Rogue Scholar, which is why Rogue Scholar is free for up to 50 blog posts
        published a year. If you publish more than 50 posts (or once per week) as
        an individual or organization, I hope you have a revenue source for the time
        spent writing and editing those posts and are willing to pay Rogue Scholar
        a one-time fee of $1 per post.</p>\\n<p>What I am seeing with the about 40
        blogs participating in Rogue Scholar so far is that most of them will not
        publish more than 50 posts in 2023, but some blogs have been running for five,
        10, or more years, and have published 100s of posts before 2023. Archiving
        these older posts in Rogue Scholar is particularly important, as the risk
        of scholarly content disappearing <a href=\\\"https://doi.org/10.1371/journal.pone.0115253\\\">increases
        with time</a>. Based on the experience of archiving my own blog posts in Rogue
        Scholar going back until 2007, I am convinced that science blog posts older
        than two or three years are absolutely worth archiving.</p>\\n<h3 id=\\\"new-payment-options\\\">New
        payment options</h3>\\n<p>To align the Rogue Scholar with the <em>mission-consistent
        revenue generation </em>discussed in the previous paragraph, Rogue Scholar
        is launching two payment options today:</p>\\n<ul><li>Donations (one-time
        or monthly) of $3 or more if you want to support the Rogue Scholar as a reader.
        Follow the new <a href=\\\"https://ko-fi.com/rogue_scholar\\\">buy me a coffee</a>
        link in the navigation bar on top of all Rogue Scholar pages.</li></ul>\\n<figure
        class=\\\"kg-card kg-image-card\\\"><img src=\\\"https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-07-um-13.38.35.png\\\"
        class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"2000\\\"
        height=\\\"502\\\" srcset=\\\"https://blog.front-matter.io/content/images/size/w600/2023/08/Bildschirmfoto-2023-08-07-um-13.38.35.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/08/Bildschirmfoto-2023-08-07-um-13.38.35.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/08/Bildschirmfoto-2023-08-07-um-13.38.35.png
        1600w, https://blog.front-matter.io/content/images/size/w2400/2023/08/Bildschirmfoto-2023-08-07-um-13.38.35.png
        2400w\\\" sizes=\\\"(min-width: 720px) 720px\\\"></figure>\\n<ul><li>Follow
        the <a href=\\\"https://ko-fi.com/rogue_scholar/shop\\\">pay for more blog
        posts</a> link in the <a href=\\\"https://rogue-scholar.org/#pricing\\\">Rogue
        Scholar pricing section</a> to pay for archiving additional blog posts. Pay
        a one-time fee of $25 to archive 25 blog posts (including full-text search
        and DOI registration). This can be for your own blog or any other blog included
        in the Rogue Scholar, and can of course be multiples of 25 to archive more
        blog posts.</li></ul>\\n<figure class=\\\"kg-card kg-image-card\\\"><img src=\\\"https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-07-um-13.37.05.png\\\"
        class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"2000\\\"
        height=\\\"1101\\\" srcset=\\\"https://blog.front-matter.io/content/images/size/w600/2023/08/Bildschirmfoto-2023-08-07-um-13.37.05.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/08/Bildschirmfoto-2023-08-07-um-13.37.05.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/08/Bildschirmfoto-2023-08-07-um-13.37.05.png
        1600w, https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-07-um-13.37.05.png
        2376w\\\" sizes=\\\"(min-width: 720px) 720px\\\"></figure>\\n<p>The payments
        are handled by the <a href=\\\"https://ko-fi.com/\\\">Ko-fi</a> service (using
        Stripe and Paypal for payment processing). These new payment options make
        two important assumptions:</p>\\n<ul><li>Users are willing to donate money
        for something they feel is important, even if it adds no direct value. I hope
        that some individuals are willing to donate to Rogue Scholar, but realistically
        organizations involved in scholarly communication are more likely to give
        one-time or regular donations.</li><li>Separating the payment for archiving
        blog posts from blog owners allows more flexible funding sources, e.g. crowdfunding
        campaigns to preserve the content of a blog important in a particular community,
        or funders willing to support scholar infrastructure for science blogs.</li></ul>\\n<p>Please
        reach out in the comments or <a href=\\\"mailto:info@front-matter.io\\\">via
        email</a> if you have questions or feedback, or if you want to discuss funding
        the Rogue Scholar in other ways.</p>\\n<h3 id=\\\"references\\\">References</h3>\\n<p>Bilder
        G, Lin J, Neylon C. The Principles of Open Scholarly Infrastructure. Published
        online 2020. doi:<a href=\\\"https://doi.org/10.24343/C34W2H\\\">10.24343/C34W2H</a></p>\\n<p>Fenner
        M. Front Matter officially launches today. Published online August 2, 2021.
        doi:<a href=\\\"https://doi.org/10.53731/r87krmh-97aq74v-ag5x0\\\">10.53731/r87krmh-97aq74v-ag5x0</a></p>\\n<p>Redhead
        C. Why CC-BY? <em>OASPA</em>. Published online October 23, 2012. Accessed
        August 7, 2023. <a href=\\\"https://oaspa.org/why-cc-by/\\\">https://oaspa.org/why-cc-by/</a></p>\\n<p>Fenner
        M. The Rogue Scholar weekly newsletter launches on Wednesday. Published online
        July 31, 2023. doi:<a href=\\\"https://doi.org/10.53731/9cdnt-2k006\\\">10.53731/9cdnt-2k006</a></p>\\n<p>How
        to reach $4.2M ARR while pursuing a mission | Ghost\U0001F47B. <em>Listen
        Up IH</em>. Published online February 4, 2022. Accessed August 7, 2023. <a
        href=\\\"https://www.listenupih.com/ghost-post/\\\">https://www.listenupih.com/ghost-post/</a></p>\\n<p>Brembs
        B. Is Open Access headed for a cost explosion? Published online October 2,
        2019. doi:<a href=\\\"https://doi.org/10.59350/d1zfz-8cs77\\\">10.59350/d1zfz-8cs77</a></p>\\n<p>Katz
        DS, Barba LA, Niemeyer K, Smith AM. Cost models for running an online open
        journal. Published online June 4, 2019. doi:<a href=\\\"https://doi.org/10.59349/g4fz2-1cr36\\\">10.59349/g4fz2-1cr36</a></p>\\n<p>Klein
        M, Sompel HV de, Sanderson R, et al. Scholarly Context Not Found: One in Five
        Articles Suffers from Reference Rot. <em>PLOS ONE</em>. 2014;9(12):e115253.
        doi:<a href=\\\"https://doi.org/10.1371/journal.pone.0115253\\\">10.1371/journal.pone.0115253</a></p>\",\"comment_id\":\"64d0b4af12cdf20001f5eacd\",\"feature_image\":\"https://images.unsplash.com/photo-1579621970588-a35d0e7ab9b6?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=M3wxMTc3M3wwfDF8c2VhcmNofDU5fHxmaW5hbmNpYWwlMjBzdXBwb3J0fGVufDB8fHx8MTY5MTQwNzI5NHww&ixlib=rb-4.0.3&q=80&w=2000\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2023-08-07T09:09:03.000+00:00\",\"updated_at\":\"2023-08-07T13:34:57.000+00:00\",\"published_at\":\"2023-08-07T11:40:36.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/c09py-3we11\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42bbc41e317003df48d4e\",\"name\":\"Feature\",\"slug\":\"feature\",\"description\":\"Features
        explore issues raised by news stories in more depth.\",\"feature_image\":\"https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fHJlc2VhcmNofGVufDB8fHx8MTYxODEyMzQxNQ&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/feature/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42bbc41e317003df48d4e\",\"name\":\"Feature\",\"slug\":\"feature\",\"description\":\"Features
        explore issues raised by news stories in more depth.\",\"feature_image\":\"https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fHJlc2VhcmNofGVufDB8fHx8MTYxODEyMzQxNQ&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/feature/\"},\"url\":\"https://blog.front-matter.io/posts/how-to-support-rogue-scholar/\",\"excerpt\":\"The
        Rogue Scholar science blog archive adds important functionality to existing
        science blogs, namely archiving, full-text search, and DOI registration. While
        a lot of effort has gone into making Rogue Scholar as affordable as possible
        by using Open Source software, automation, and involving the community, it
        still costs money to build and run scholarly infrastructure, including scholarly
        infrastructure for science blogs.\\n\\n\\nWe made a few fundamental decisions
        even before starting Rogue Scholar:\\n\",\"reading_time\":5,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":\"Photo
        by <a href=\\\"https://unsplash.com/@micheile?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">micheile
        henderson</a> / <a href=\\\"https://unsplash.com/?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Unsplash</a>\"},{\"id\":\"64ca7451683b3a000114a148\",\"uuid\":\"89821b9e-029f-46f5-b7fe-8f8711132cd3\",\"title\":\"Improvements
        in Rogue Scholar: tags and images\",\"slug\":\"improvements-in-rogue-scholar-tags-and-images\",\"html\":\"<p>The
        Rogue Scholar science blog archive adds <a href=\\\"https://doi.org/10.53731/z9v2s-bh329\\\">important
        functionality</a> to existing blogs, namely long-term archiving, full-text
        search, and DOI registration. In this week's update, I focussed on improving
        functionality that is specific for blogs and not really found regularly with
        other formats for scholarly content.</p>\\n<h3 id=\\\"tags\\\">Tags</h3>\\n<p>Tags
        are a common way to categorize blog posts and help find content of interest.
        They are either used fairly flexibly, or with a predefined list, and posts
        can have zero, one, or multiple tags. The main reason tags exist is that most
        blogging platforms don't have good search functionality. As Rogue Scholar
        has a <a href=\\\"https://doi.org/10.53731/6r1dx-wdp04\\\">full-text search
        powered by Typesense</a>, tags are less important. They are still helpful,
        and this week they have been improved in the following ways:</p>\\n<ul><li>Tags
        have been normalized, removing any hashes, hyphens, and lowercase first letters,
        so that searching for <code>#Covid-19</code> will also find <code>COVID 19,</code>and
        searching for <code>Pre-Print</code>will also find <code>preprint</code>.</li><li>Tags
        for blog posts are now clickable, triggering a search with that tag (either
        for a given blog or all posts)</li><li>Pagination now supports tags, so that
        a search for the tag <code>Open Access</code> lets you paginate through the
        68 results on five pages.</li></ul>\\n<h3 id=\\\"feature-images\\\">Feature
        Images</h3>\\n<p>Optional <a href=\\\"https://wordpress.com/support/featured-images/\\\">Feature
        images</a> can highlight visual information in a blog post. Some blogging
        platforms, e.g. Ghost or Medium, use them prominently, but there is more than
        one way to implement them in RSS or Atom feeds. As Rogue Scholar has access
        to the full-text HTML, it is easy to pick a feature image if none exists already.
        Starting this week Rogue Scholar automatically displays the first image that
        is at least 100px wide found in the full-text.</p>\\n<figure class=\\\"kg-card
        kg-image-card\\\"><img src=\\\"https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-02-um-18.02.21.png\\\"
        class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"1948\\\"
        height=\\\"1270\\\" srcset=\\\"https://blog.front-matter.io/content/images/size/w600/2023/08/Bildschirmfoto-2023-08-02-um-18.02.21.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/08/Bildschirmfoto-2023-08-02-um-18.02.21.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/08/Bildschirmfoto-2023-08-02-um-18.02.21.png
        1600w, https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-02-um-18.02.21.png
        1948w\\\" sizes=\\\"(min-width: 720px) 720px\\\"></figure>\\n<p>Both new features
        are available now. Feedback via comments, Discourse, or email is always welcomed,
        as this is the first version of this functionality. Some images for example
        don't display properly because they were moved or because the browser complains
        about mixed (HTTPS and HTTP) content. </p>\\n<h3 id=\\\"references\\\">References</h3>\\n<p>Fenner
        M. The Rogue Scholar is now open for business. Published online April 4, 2023.
        doi:<a href=\\\"https://doi.org/10.53731/z9v2s-bh329\\\">10.53731/z9v2s-bh329</a></p>\\n<p>Fenner
        M. Rogue Scholar full-text search improvements. Published online July 10,
        2023. doi:<a href=\\\"https://doi.org/10.53731/6r1dx-wdp04\\\">10.53731/6r1dx-wdp04</a></p>\",\"comment_id\":\"64ca7451683b3a000114a148\",\"feature_image\":\"https://blog.front-matter.io/content/images/2023/08/Bildschirmfoto-2023-08-02-um-17.21.33.png\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2023-08-02T15:20:49.000+00:00\",\"updated_at\":\"2023-08-02T23:53:09.000+00:00\",\"published_at\":\"2023-08-02T16:10:51.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/7pqhx-z0y63\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"},\"url\":\"https://blog.front-matter.io/posts/improvements-in-rogue-scholar-tags-and-images/\",\"excerpt\":\"The
        Rogue Scholar science blog archive adds important functionality to existing
        blogs, namely long-term archiving, full-text search, and DOI registration.
        In this week's update, I focussed on improving functionality that is specific
        for blogs and not really found regularly with other formats for scholarly
        content.\\n\\n\\n\\nTags\\n\\n\\nTags are a common way to categorize blog
        posts and help find content of interest. They are either used fairly flexibly,
        or with a predefined list, and posts can have zero, on\",\"reading_time\":2,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":null},{\"id\":\"64c7d265affd0a00015c9e27\",\"uuid\":\"cd12ea0a-43ea-43d3-b9e4-f72e3efd13bf\",\"title\":\"The
        Rogue Scholar weekly newsletter launches on Wednesday\",\"slug\":\"rogue-scholar-weekly-newsletter\",\"html\":\"<p>The
        <a href=\\\"https://rogue-scholar.org\\\">Rogue Scholar</a> science blog archive
        is growing nicely, reaching more than 1,500 blog posts this week, and 5-10
        new posts every week. You can subscribe to all the blogs you are interested
        in via an RSS Reader and use various strategies to find and read interesting
        content, but some people prefer to receive regular email updates instead.
        That is why the Rogue Scholar is launching the Rogue Scholar Digest newsletter
        this week, publishing every Wednesday and containing summaries (title, publication
        date, blog name, author, and summary) with a link to the full-text post on
        the hosting blog.</p>\\n<p>These weekly emails are generated automatically
        using the Rogue Scholar API and the newsletter functionality of this blog.
        To subscribe to the Rogue Scholar weekly digest, click the subscribe link
        on this <a href=\\\"https://blog.front-matter.io/\\\">blog's homepage</a>
        and add your name and email. Signing up for the newsletter is free and you
        can cancel anytime.</p>\\n<figure class=\\\"kg-card kg-image-card\\\"><img
        src=\\\"https://blog.front-matter.io/content/images/2023/07/Bildschirmfoto-2023-07-31-um-17.39.25.png\\\"
        class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"1104\\\"
        height=\\\"1428\\\" srcset=\\\"https://blog.front-matter.io/content/images/size/w600/2023/07/Bildschirmfoto-2023-07-31-um-17.39.25.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/07/Bildschirmfoto-2023-07-31-um-17.39.25.png
        1000w, https://blog.front-matter.io/content/images/2023/07/Bildschirmfoto-2023-07-31-um-17.39.25.png
        1104w\\\" sizes=\\\"(min-width: 720px) 720px\\\"></figure>\\n<p>Once you have
        confirmed the account via email, sign in and change your email preferences
        to receive the weekly Rogue Scholar Digest (there are a few other newsletters
        you can subscribe to):</p>\\n<figure class=\\\"kg-card kg-image-card\\\"><img
        src=\\\"https://blog.front-matter.io/content/images/2023/07/Bildschirmfoto-2023-07-31-um-17.41.17.png\\\"
        class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"1026\\\"
        height=\\\"1222\\\" srcset=\\\"https://blog.front-matter.io/content/images/size/w600/2023/07/Bildschirmfoto-2023-07-31-um-17.41.17.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/07/Bildschirmfoto-2023-07-31-um-17.41.17.png
        1000w, https://blog.front-matter.io/content/images/2023/07/Bildschirmfoto-2023-07-31-um-17.41.17.png
        1026w\\\" sizes=\\\"(min-width: 720px) 720px\\\"></figure>\\n<p>A newsletter
        summarizing 5-10 posts is quickly scanned and interesting posts bookmarked
        for later reading, or stored in a reference manager for referencing later.
        When the Rogue Scholar archive grows further and the number of weekly new
        posts gets too large, I can start more specialized newsletters, e.g. by subject
        category (e.g. social sciences) or language.</p>\",\"comment_id\":\"64c7d265affd0a00015c9e27\",\"feature_image\":\"https://blog.front-matter.io/content/images/2023/07/Bildschirmfoto-2023-07-31-um-17.25.00.png\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2023-07-31T15:25:25.000+00:00\",\"updated_at\":\"2023-07-31T17:24:48.000+00:00\",\"published_at\":\"2023-07-31T15:53:42.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/9cdnt-2k006\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"},\"url\":\"https://blog.front-matter.io/posts/rogue-scholar-weekly-newsletter/\",\"excerpt\":\"The
        Rogue Scholar science blog archive is growing nicely, reaching more than 1,500
        blog posts this week, and 5-10 new posts every week. You can subscribe to
        all the blogs you are interested in via an RSS Reader and use various strategies
        to find and read interesting content, but some people prefer to receive regular
        email updates instead. That is why the Rogue Scholar is launching the Rogue
        Scholar Digest newsletter this week, publishing every Wednesday and containing
        summaries (title, publicati\",\"reading_time\":1,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":null},{\"id\":\"64b785978ebde70001a9a88c\",\"uuid\":\"d794068c-2229-49a0-83df-37fb0aa99811\",\"title\":\"Launching
        blog administration self-service in Rogue Scholar\",\"slug\":\"blog-administration-self-service\",\"html\":\"<p>This
        week I added blog administration self-service to the Rogue Scholar blog archive.
        This makes adding a blog to Rogue Scholar easier, faster, and cheaper.</p>\\n<p>To
        start blog administration please create an account with Rogue Scholar. Use
        the \\\"Sign In\\\" Link in the upper right corner to sign in or create an
        account with username and password, or sign in via Google or GitHub.</p>\\n<p>Once
        signed in, you can add your blog via the Dashboard page. You have to agree
        to the Rogue Scholar terms of service (which haven't changed since Rogue Scholar
        launched in April 2023):</p>\\n<ul><li>The blog is about science or scholarship.</li><li>The
        full text of blog posts is made available via an Atom (preferred), RSS, or
        JSON feed.</li><li>The full text of blog posts is made available under the
        Creative Commons Attribution 4.0 International License.</li></ul>\\n<p>The
        only required information is the URL of the Atom, RSS, or JSON Feed. The Atom
        format is preferred, as Atom supports multiple authors and author URLs, used
        for the ORCID ID in DOI registration.</p>\\n<p>A blog image (favicon) is optional
        and can be added if not included in the Blog feed. About half of the included
        blogs currently have a favicon:</p>\\n<figure class=\\\"kg-card kg-image-card\\\"><img
        src=\\\"https://blog.front-matter.io/content/images/2023/07/Bildschirmfoto-2023-07-19-um-09.27.07.png\\\"
        class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"2000\\\"
        height=\\\"764\\\" srcset=\\\"https://blog.front-matter.io/content/images/size/w600/2023/07/Bildschirmfoto-2023-07-19-um-09.27.07.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/07/Bildschirmfoto-2023-07-19-um-09.27.07.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/07/Bildschirmfoto-2023-07-19-um-09.27.07.png
        1600w, https://blog.front-matter.io/content/images/2023/07/Bildschirmfoto-2023-07-19-um-09.27.07.png
        2240w\\\" sizes=\\\"(min-width: 720px) 720px\\\"></figure>\\n<p>The category
        helps classify the blog and becomes more important as the number of blogs
        and blog posts included in Rogue Scholar increases. Currently, we use the
        six top-level categories of the <a href=\\\"https://www.oecd.org/science/inno/38235147.pdf\\\">OECD
        Fields of Science and Technology</a>.</p>\\n<p>Once submitted, Rogue Scholar
        automatically fetches additional information from the blog feed, e.g. blog
        home page, title, description, and language. There is a final manual approval
        step before the blog can go live on Rogue Scholar, and we might contact you
        with additional questions. The main issue that we found is incomplete author
        information in the feed. Once approved, Rogue Scholar starts archiving the
        full text of blog posts, adds them to the full-text search, and starts DOI
        registration of blog posts, all fully automated.</p>\\n<figure class=\\\"kg-card
        kg-image-card\\\"><img src=\\\"https://blog.front-matter.io/content/images/2023/07/Bildschirmfoto-2023-07-19-um-09.40.05.png\\\"
        class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"1930\\\"
        height=\\\"1392\\\" srcset=\\\"https://blog.front-matter.io/content/images/size/w600/2023/07/Bildschirmfoto-2023-07-19-um-09.40.05.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/07/Bildschirmfoto-2023-07-19-um-09.40.05.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/07/Bildschirmfoto-2023-07-19-um-09.40.05.png
        1600w, https://blog.front-matter.io/content/images/2023/07/Bildschirmfoto-2023-07-19-um-09.40.05.png
        1930w\\\" sizes=\\\"(min-width: 720px) 720px\\\"></figure>\\n<p>Of course,
        it is possible to register more than one blog, and three users have done so.
        Blogs already included in the Rogue Scholar have to be manually added, so
        please first create an account with Rogue Scholar.</p>\\n<p>In the past weeks,
        I have worked on translating the Rogue Scholar user interface. The currently
        supported languages are English and German, and I am particularly interested
        in including science blogs written in other languages. It is of course also
        possible to write individual posts in other languages, Rogue Scholar will
        automatically detect the language and display it if different from the preset
        language:</p>\\n<figure class=\\\"kg-card kg-image-card\\\"><img src=\\\"https://blog.front-matter.io/content/images/2023/07/Bildschirmfoto-2023-07-19-um-09.48.45.png\\\"
        class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"1652\\\"
        height=\\\"1260\\\" srcset=\\\"https://blog.front-matter.io/content/images/size/w600/2023/07/Bildschirmfoto-2023-07-19-um-09.48.45.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/07/Bildschirmfoto-2023-07-19-um-09.48.45.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/07/Bildschirmfoto-2023-07-19-um-09.48.45.png
        1600w, https://blog.front-matter.io/content/images/2023/07/Bildschirmfoto-2023-07-19-um-09.48.45.png
        1652w\\\" sizes=\\\"(min-width: 720px) 720px\\\"></figure>\\n<p>Once non-English
        language content in the Rogue Scholar becomes more common, we will also add
        a language option to the search interface.</p>\\n<p>Please <a href=\\\"mailto:info@front-matter.io\\\">reach
        to me</a> if you have feedback or questions, or if you need help adding your
        blog to the Rogue Scholar. The next feature I will be working on is a streamlined
        payment process for blogs with more than 50 posts per year (which are always
        free).</p>\",\"comment_id\":\"64b785978ebde70001a9a88c\",\"feature_image\":\"https://blog.front-matter.io/content/images/2023/07/Bildschirmfoto-2023-07-19-um-09.04.55-1.png\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2023-07-19T06:41:27.000+00:00\",\"updated_at\":\"2023-07-19T08:31:55.000+00:00\",\"published_at\":\"2023-07-19T08:00:38.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/vhw34-xxf63\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"},\"url\":\"https://blog.front-matter.io/posts/blog-administration-self-service/\",\"excerpt\":\"This
        week I added blog administration self-service to the Rogue Scholar blog archive.
        This makes adding a blog to Rogue Scholar easier, faster, and cheaper.\\n\\n\\nTo
        start blog administration please create an account with Rogue Scholar. Use
        the \\\"Sign In\\\" Link in the upper right corner to sign in or create an
        account with username and password, or sign in via Google or GitHub.\\n\\n\\nOnce
        signed in, you can add your blog via the Dashboard page. You have to agree
        to the Rogue Scholar terms of service (whic\",\"reading_time\":3,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":null},{\"id\":\"64abf3156ee93100018bb512\",\"uuid\":\"a5f038ef-47bd-4850-8aeb-1b79802640dc\",\"title\":\"Rogue
        Scholar full-text search improvements\",\"slug\":\"rogue-scholar-full-text-search-improvements\",\"html\":\"<p>Two
        weeks ago I <a href=\\\"https://doi.org/10.53731/80awr-zcc48\\\">added a first
        version of full-text search to the Rogue Scholar blog</a> archive. This was
        a good start, as blogs typically only have the timeline, tags, and metadata
        like titles and authors to help readers find relevant content. Today I launched
        an improved version of full-text search with these improvements:</p>\\n<ul><li>Sorting
        of search results by relevance</li><li>Support for fuzzy search or <a href=\\\"https://en.wikipedia.org/wiki/Approximate_string_matching\\\">approximate
        string matching</a></li><li>Added the backend for an updated search interface
        supporting faceted search and/or <a href=\\\"https://github.com/typesense/typesense-instantsearch-adapter\\\">InstantSearch</a></li></ul>\\n<p>Sorting
        by relevance helps with search terms that produce many hits, e.g. <a href=\\\"https://rogue-scholar.org/de/posts?page=1&amp;query=RDA\\\">RDA</a>
        (for Research Data Alliance). Fuzzy search helps with typos and synonyms,
        e.g. <a href=\\\"https://rogue-scholar.org/de/posts?page=1&amp;query=proprint\\\">Proprint</a>
        (for preprint), <a href=\\\"https://rogue-scholar.org/de/posts?page=1&amp;query=open+scholarship\\\">Open
        Scholarship</a> (which also finds blog posts about Open Science), or <a href=\\\"https://rogue-scholar.org/de/posts?page=1&amp;query=Iain+Hry\\\">Iain
        Hry</a>, which finds blog posts from or about Iain Hrynaszkiewicz (who works
        at the Public Library of Science).</p>\\n<p>These and further improvements
        in the future are of course only meaningful because the Rogue Scholar is a
        central archive of scholarly blogs, so users don't have to go to a long list
        of different places. And because the Rogue Scholar has archived the full text
        of these science blogs, rather than only metadata or abstracts.</p>\\n<p>While
        the initial implementation of the <a href=\\\"https://www.crunchydata.com/blog/postgres-full-text-search-a-search-engine-in-a-database\\\">full-text
        search built into the Postgres</a> database that powers the Rogue Scholar
        backend, this new version uses <a href=\\\"https://typesense.org/\\\">Typesense</a>,
        a dedicated open source search engine. Adding another layer of technology
        complicates the Rogue Scholar technology stack, but full-text search using
        the functionality built into Postgres also can be challenging for more complex
        use cases. Sorting search results by relevance for example is possible, but
        more difficult compared to a dedicated search engine such as Typesense.</p>\\n<p>Faceted
        search will become more important as the Rogue Scholar archive continues to
        grow, for example to allow filtering by language or subject area. <a href=\\\"https://www.algolia.com/doc/guides/building-search-ui/what-is-instantsearch/js/\\\">Instantsearch</a>
        \ is a popular open source library that supports search interfaces built directly
        into blogs, and that can take advantage of the Rogue Scholar full-text search.</p>\\n<h3
        id=\\\"references\\\">References</h3>\\n<p>Fenner M. Full-text search added
        to the Rogue Scholar science blog archive. Published online June 27, 2023.
        doi:<a href=\\\"https://doi.org/10.53731/80awr-zcc48\\\">10.53731/80awr-zcc48</a></p>\\n<p>Hrynaszkiewicz
        I, Norton ML, Vickers AJ, Altman DG. Preparing raw clinical data for publication:
        guidance for journal editors, authors, and peer reviewers. <em>BMJ</em>. 2010;340(jan28
        1):c181-c181. doi:<a href=\\\"https://doi.org/10.1136/bmj.c181\\\">10.1136/bmj.c181</a></p>\",\"comment_id\":\"64abf3156ee93100018bb512\",\"feature_image\":\"https://images.unsplash.com/photo-1472512946974-cc09a294e210?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=M3wxMTc3M3wwfDF8c2VhcmNofDI3fHxzZWFyY2h8ZW58MHx8fHwxNjg4OTkyNDk1fDA&ixlib=rb-4.0.3&q=80&w=2000\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2023-07-10T12:01:25.000+00:00\",\"updated_at\":\"2023-07-11T06:28:04.000+00:00\",\"published_at\":\"2023-07-10T13:10:53.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/6r1dx-wdp04\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"},\"url\":\"https://blog.front-matter.io/posts/rogue-scholar-full-text-search-improvements/\",\"excerpt\":\"Two
        weeks ago I added a first version of full-text search to the Rogue Scholar
        blog archive. This was a good start, as blogs typically only have the timeline,
        tags, and metadata like titles and authors to help readers find relevant content.
        Today I launched an improved version of full-text search with these improvements:\\n\\n\\n
        * Sorting of search results by relevance\\n * Support for fuzzy search or
        approximate string matching\\n * Added the backend for an updated search interface
        supporting faceted se\",\"reading_time\":2,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":\"Photo
        by <a href=\\\"https://unsplash.com/@saeedanathema?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">saeed
        mhmdi</a> / <a href=\\\"https://unsplash.com/?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Unsplash</a>\"},{\"id\":\"64a25ff7b544e10001aefe8a\",\"uuid\":\"d8c4565e-3a93-4a4d-8926-ad4dcaa843be\",\"title\":\"The
        Rogue Scholar archive reaches a milestone: 1000 searchable full-text science
        blog posts with DOIs\",\"slug\":\"the-rogue-scholar-milestone\",\"html\":\"<p>The
        Rogue Scholar science blog archive <a href=\\\"https://doi.org/10.53731/z9v2s-bh329\\\">launched
        in April</a> and I have been busy building out the core features of archiving
        the full-text of blog posts, establishing a full-text search, and registering
        DOIs and metadata for all posts. My announced goal was to complete this work
        by the end of the second quarter.</p>\\n<p>We now have July and I am happy
        to report that the core features are working and that the Rogue Scholar includes
        1,000 blog posts that are available via full-text search, with DOIs linking
        to the original post on one of 35 science blogs, marking an important milestone
        worth celebrating.</p>\\n<figure class=\\\"kg-card kg-image-card\\\"><img
        src=\\\"https://blog.front-matter.io/content/images/2023/07/Bildschirmfoto-2023-07-03-um-09.31.14-1.png\\\"
        class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"2000\\\"
        height=\\\"382\\\" srcset=\\\"https://blog.front-matter.io/content/images/size/w600/2023/07/Bildschirmfoto-2023-07-03-um-09.31.14-1.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/07/Bildschirmfoto-2023-07-03-um-09.31.14-1.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/07/Bildschirmfoto-2023-07-03-um-09.31.14-1.png
        1600w, https://blog.front-matter.io/content/images/2023/07/Bildschirmfoto-2023-07-03-um-09.31.14-1.png
        2396w\\\" sizes=\\\"(min-width: 720px) 720px\\\"><figcaption><a href=\\\"https://rogue-scholar.org/posts\\\"
        rel=\\\"noopener\\\"><span>Rogue Scholar blog posts</span></a></figcaption></figure>\\n<p>What
        is equally important is that this milestone has been reached without major
        technical work for the involved blogs. Rogue Scholar works with all blogging
        platforms that publish scholarly content and have an RSS or Atom feed with
        full-text content distributed under a Creative Commons Attribution (<a href=\\\"https://creativecommons.org/licenses/by/4.0/legalcode\\\">CC-BY
        4.0</a>) license \u2013 currently <a href=\\\"https://rogue-scholar.org/#stats\\\">nine
        different blogging platforms</a> from Wordpress, Blogger, and Ghost to several
        static site generators. The major issue was author names, usually resolved
        by configuration changes, e.g. in the Wordpress author profile.</p>\\n<p>And
        the implementation doesn't take any shortcuts, the DOI metadata include abstract,
        language, license, and (OECD Fields of Science) subject category for all posts,
        and author ORCID ID and references for some posts.</p>\\n<figure class=\\\"kg-card
        kg-image-card\\\"><img src=\\\"https://blog.front-matter.io/content/images/2023/07/Bildschirmfoto-2023-07-03-um-08.29.15.png\\\"
        class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"1876\\\"
        height=\\\"1226\\\" srcset=\\\"https://blog.front-matter.io/content/images/size/w600/2023/07/Bildschirmfoto-2023-07-03-um-08.29.15.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/07/Bildschirmfoto-2023-07-03-um-08.29.15.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/07/Bildschirmfoto-2023-07-03-um-08.29.15.png
        1600w, https://blog.front-matter.io/content/images/2023/07/Bildschirmfoto-2023-07-03-um-08.29.15.png
        1876w\\\" sizes=\\\"(min-width: 720px) 720px\\\"><figcaption><a href=\\\"https://www.crossref.org/members/prep/31795\\\"
        rel=\\\"noopener\\\"><span>Crossref Participation Reports</span></a><span>
        for blog posts registered by Front Matter</span></figcaption></figure>\\n<p>And
        that Rogue Scholar does this without major costs for the participating blogs
        (free for up to 50 posts per year, and a one-time fee of $1 per post thereafter),
        or for Front Matter hosting the blog archive (with monthly costs under $200
        plus $.25 per DOI registration). This is possible because Rogue Scholar follows
        three principles: using open source software (more details in another post),
        automation as much as possible, and community participation.</p>\\n<p>Reaching
        this milestone demonstrates that a central archive of science blogs with full-text
        content, and DOIs for all blog posts with relevant metadata is feasible, making
        an important contribution to <a href=\\\"https://doi.org/10.6084/M9.FIGSHARE.1314859\\\">Open
        Scholarly infrastructure</a>.</p>\\n<p>What comes next? Besides a lot of detailed
        work (e.g. working with six blogs registered with the Rogue Scholar that have
        RSS/Atom feeds with incomplete author metadata or no full-text RSS feed),
        the main goals for the next three months are:</p>\\n<ul><li>Improve the payment
        workflow, including automated payment processing and a sponsorship option
        for organizations wanting to support Rogue Scholar and/or specific blogs</li><li>Include
        more science blogs, more blog posts (so far I have included all posts from
        12 blogs), and improve the metadata (e.g. ORCID identifiers and references).
        In particular, I want to include blogs that publish posts in languages other
        than English (currently only <a href=\\\"https://rogue-scholar.org/#stats\\\">three
        of the 35 blogs</a>).</li><li>Build a community of Rogue Scholar bloggers
        and users. I have gotten a lot of feedback in the last few months but would
        like to better understand how people are currently using the Rogue Scholar
        or what can be improved. The starting point is the <a href=\\\"https://discord.gg/HvbD4dNPFh\\\">Rogue
        Scholar Discord</a> community, but there are also other feedback channels,
        including email, Mastodon, Zoom, and of course personal communications (you
        find me at the <a href=\\\"https://www.zbmed.de/en/networking/events/open-science-festival\\\">Open
        Science Festival Cologne</a> this week).</li></ul>\\n<h3 id=\\\"references\\\">References</h3>\\n<p>Fenner
        M. The Rogue Scholar: An Archive for Scholarly blogs. Published online January
        31, 2023. doi:<a href=\\\"https://doi.org/10.54900/bj4g7p2-2f0fn9b\\\">10.54900/bj4g7p2-2f0fn9b</a></p>\\n<p>Fenner
        M. The Rogue Scholar is now open for business. Published online April 4, 2023.
        doi:<a href=\\\"https://doi.org/10.53731/z9v2s-bh329\\\">10.53731/z9v2s-bh329</a></p>\\n<p>Fenner
        M. Starting to register DOIs for all blog posts included in the Rogue Scholar.
        Published online June 5, 2023. doi:<a href=\\\"https://doi.org/10.53731/m9fs5-nap05\\\">10.53731/m9fs5-nap05</a></p>\\n<p>Bilder
        G, Lin J, Neylon C. Principles for Open Scholarly Infrastructures-v1. Published
        online 2015:35186 Bytes. doi:<a href=\\\"https://doi.org/10.6084/M9.FIGSHARE.1314859\\\">10.6084/M9.FIGSHARE.1314859</a></p>\",\"comment_id\":\"64a25ff7b544e10001aefe8a\",\"feature_image\":\"https://blog.front-matter.io/content/images/2023/07/Bildschirmfoto-2023-07-03-um-09.31.14.png\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2023-07-03T05:43:19.000+00:00\",\"updated_at\":\"2023-07-04T15:36:44.000+00:00\",\"published_at\":\"2023-07-03T07:32:37.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/89zgc-ptr93\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"},\"url\":\"https://blog.front-matter.io/posts/the-rogue-scholar-milestone/\",\"excerpt\":\"The
        Rogue Scholar science blog archive launched in April and I have been busy
        building out the core features of archiving the full-text of blog posts, establishing
        a full-text search, and registering DOIs and metadata for all posts. My announced
        goal was to complete this work by the end of the second quarter.\\n\\n\\nWe
        now have July and I am happy to report that the core features are working
        and that the Rogue Scholar includes 1,000 blog posts that are available via
        full-text search, with DOIs linkin\",\"reading_time\":3,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":null},{\"id\":\"649ad2e33fa15900016f2cd0\",\"uuid\":\"a4460aa2-bbec-4773-a889-7addc6048da8\",\"title\":\"Full-text
        search added to the Rogue Scholar science blog archive\",\"slug\":\"full-text-search-added-to-the-rogue-scholar-science-blog-archive\",\"html\":\"<p>In
        January I started the <a href=\\\"https://rogue-scholar.org\\\">Rogue Scholar</a>
        blog archive with the slogan \\\"science blogging on steroids\\\", promising
        to enhance science blogs in important ways. Earlier this month I began <a
        href=\\\"https://doi.org/10.53731/m9fs5-nap05\\\">DOI registrations for blog
        posts</a>, and I am well on track to complete this for the included 35 blogs
        with more than 1,000 blog posts in the next few weeks. Another promise was
        the full-text search of blog posts, a functionality that is not typically
        part of blogging platforms, or that is implemented with only limited functionality.</p>\\n<p>Today,
        I am happy to announce the first version of full-text search for all Rogue
        Scholar content. Full-text search works either for specific blogs and does
        a much better job of finding relevant content compared to blogging platforms
        or generic web searches, e.g. this blog post describing the work of a group
        of researchers from the University of Geneva.</p>\\n<figure class=\\\"kg-card
        kg-image-card\\\"><img src=\\\"https://blog.front-matter.io/content/images/2023/06/Bildschirmfoto-2023-06-27-um-14.27.30.png\\\"
        class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"2000\\\"
        height=\\\"930\\\" srcset=\\\"https://blog.front-matter.io/content/images/size/w600/2023/06/Bildschirmfoto-2023-06-27-um-14.27.30.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/06/Bildschirmfoto-2023-06-27-um-14.27.30.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/06/Bildschirmfoto-2023-06-27-um-14.27.30.png
        1600w, https://blog.front-matter.io/content/images/size/w2400/2023/06/Bildschirmfoto-2023-06-27-um-14.27.30.png
        2400w\\\" sizes=\\\"(min-width: 720px) 720px\\\"></figure>\\n<p>Full-text
        search also works across all blogs included in the Rogue Scholar, something
        that would be much harder to accomplish otherwise. A good example are topics
        widely discussed in the blogosphere such as <a href=\\\"https://rogue-scholar.org/posts?query=covid\\\">COVID</a>,
        <a href=\\\"https://rogue-scholar.org/posts?query=climate+change\\\">climate
        change</a>, or <a href=\\\"https://rogue-scholar.org/posts?query=chatgpt\\\">ChatGPT</a>,
        but also more obscure content where we don't remember the source, for example,
        a blog post about the <a href=\\\"https://en.wikipedia.org/wiki/Tasmanian_devil\\\">Tasmanian
        Devil</a> (a carnivorous marsupial from Tasmania that is severely affected
        by a transmissible facial tumor that threatens the survival of the species).</p>\\n<figure
        class=\\\"kg-card kg-image-card\\\"><img src=\\\"https://blog.front-matter.io/content/images/2023/06/Bildschirmfoto-2023-06-27-um-14.39.04.png\\\"
        class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"2000\\\"
        height=\\\"926\\\" srcset=\\\"https://blog.front-matter.io/content/images/size/w600/2023/06/Bildschirmfoto-2023-06-27-um-14.39.04.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/06/Bildschirmfoto-2023-06-27-um-14.39.04.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/06/Bildschirmfoto-2023-06-27-um-14.39.04.png
        1600w, https://blog.front-matter.io/content/images/size/w2400/2023/06/Bildschirmfoto-2023-06-27-um-14.39.04.png
        2400w\\\" sizes=\\\"(min-width: 720px) 720px\\\"></figure>\\n<p>The first
        implementation of full-text search of course has some limitations, mainly:</p>\\n<ul><li>Author
        names not yet included (unless they also appear in the full-text)</li><li>No
        relevance sorting of results (they are always sorted by reverse publication
        date)</li><li>Improvements in the search user interface, either a faceted
        search interface powered by <a href=\\\"https://www.elastic.co/\\\">Elasticsearch</a>,
        or the floating modal search window made popular by Algolia and the <a href=\\\"https://github.com/algolia/instantsearch\\\">Instantsearch</a>
        open source library</li></ul>\\n<p>The Rogue Scholar full-text search is implemented
        with the <a href=\\\"https://supabase.com/blog/postgres-full-text-search-vs-the-rest\\\">Postgres
        database full-text search</a>, which is a nice alternative to a dedicated
        search index particularly if you don't need to search millions of documents.
        And the full-text search was only possible because all blogs participating
        in the Rogue Scholar agreed to a Creative Commons Attribution (<a href=\\\"https://creativecommons.org/licenses/by/4.0/legalcode\\\">CC-BY
        4.0</a>) license for all their posts.</p>\",\"comment_id\":\"649ad2e33fa15900016f2cd0\",\"feature_image\":\"https://blog.front-matter.io/content/images/2023/06/Bildschirmfoto-2023-06-27-um-14.23.30.png\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2023-06-27T12:15:31.000+00:00\",\"updated_at\":\"2023-06-27T20:14:32.000+00:00\",\"published_at\":\"2023-06-27T13:04:24.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/80awr-zcc48\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42bbc41e317003df48d4e\",\"name\":\"Feature\",\"slug\":\"feature\",\"description\":\"Features
        explore issues raised by news stories in more depth.\",\"feature_image\":\"https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fHJlc2VhcmNofGVufDB8fHx8MTYxODEyMzQxNQ&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/feature/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42bbc41e317003df48d4e\",\"name\":\"Feature\",\"slug\":\"feature\",\"description\":\"Features
        explore issues raised by news stories in more depth.\",\"feature_image\":\"https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fHJlc2VhcmNofGVufDB8fHx8MTYxODEyMzQxNQ&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/feature/\"},\"url\":\"https://blog.front-matter.io/posts/full-text-search-added-to-the-rogue-scholar-science-blog-archive/\",\"excerpt\":\"In
        January I started the Rogue Scholar blog archive with the slogan \\\"science
        blogging on steroids\\\", promising to enhance science blogs in important
        ways. Earlier this month I began DOI registrations for blog posts, and I am
        well on track to complete this for the included 35 blogs with more than 1,000
        blog posts in the next few weeks. Another promise was the full-text search
        of blog posts, a functionality that is not typically part of blogging platforms,
        or that is implemented with only limited f\",\"reading_time\":2,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":null},{\"id\":\"648c13c2bad6d80001bd072a\",\"uuid\":\"4661f359-14a8-4590-b431-d47ea443e290\",\"title\":\"Starting
        to include references in DOI metadata for blog posts\",\"slug\":\"starting-to-include-references-in-doi-metadata-for-blog-posts\",\"html\":\"<p>Two
        weeks ago I <a href=\\\"https://doi.org/10.53731/m9fs5-nap05\\\">started registering
        DOIs</a> for blog posts included in the Rogue Scholar blog archive. It is
        an automated process but involves a lot of manual checks. So far I have registered
        <a href=\\\"https://api.crossref.org/prefixes/10.59350/works\\\">231 blog
        posts</a> from 20 different science blogs, and I hope to finish the DOI registrations
        by the end of the month. Going forward these DOI registrations will happen
        automatically whenever one of the science blogs included in the Rogue Scholar
        publishes a new post. I do this by monitoring the RSS feeds of these blogs,
        which I also use to generate the DOI metadata.</p>\\n<p>The DOI registrations
        include required and recommended metadata, including</p>\\n<ul><li>Author
        ORCID ID if provided by the blog</li><li>Abstract</li><li>Language of the
        post</li><li>License (all Rogue Scholar blogs use the <a href=\\\"https://creativecommons.org/licenses/by/4.0/legalcode\\\">Creative
        Commons Attribution 4.0 license</a>)</li></ul>\\n<p>Because all Rogue Scholar
        blog posts are archived as full-text, we can extract additional metadata and
        register them with Crossref. The obvious first candidate is references, and
        today the Rogue Scholar has started to add them to the DOI metadata it registers
        with Crossref. The workflow for adding references follows the same principles
        I also use elsewhere for the Rogue Scholar:</p>\\n<ul><li>No particular technical
        effort is required for blog authors</li><li>Using open source software and
        open access content</li><li>The process should be simple and cheap</li></ul>\\n<p>The
        initial implementation uses the standard formatting for references: a section
        at the end of the text, starting with an HTML &lt;h2&gt;, &lt;h3&gt; or &lt;h4&gt;
        header and the word <strong>References</strong>, followed by a list of links
        that are either DOIs or generic URLs. This <a href=\\\"https://doi.org/10.53731/r795v41-97aq74v-ag4cd\\\">pattern
        is so common</a> that Crossref colleague Geoff Bilder uses it in presentations,
        and it is immediately recognized by most audiences:</p>\\n<figure class=\\\"kg-card
        kg-image-card\\\"><img src=\\\"https://blog.front-matter.io/content/images/2023/06/article2-1-1-1.png\\\"
        alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"500\\\" height=\\\"722\\\"></figure>\\n<p>Because
        some blogs have additional text after their references, I strip any text (and
        the included links) after an additional &lt;h2&gt;, &lt;h3&gt;, &lt;h4&gt;,
        or &lt;hr&gt; HTML tag. </p>\\n<p>You can use the Crossref API to find Rogue
        Scholar DOIs with references (four blog posts as I write this) using the query
        <a href=\\\"https://api.crossref.org/prefixes/10.59350/works?filter=has-references:true\\\">https://api.crossref.org/prefixes/10.59350/works?filter=has-references:true</a></p>\\n<p>When
        registering references I automatically check whether they resolve (using an
        HTTP HEAD request), to at least prevent typos or otherwise wrong DOIs/other
        URLs. I am not registering additional metadata for the references (e.g. the
        title), as this would dramatically increase the effort for blog authors, and
        that information is available in the original blog post.</p>\\n<p>About 5%
        of the so far about 450 Rogue Scholar blog posts have references (the registration
        of the references with Crossref is ongoing). I hope that including the references
        in the DOI metadata will encourage blog authors to include more references,
        and I am of course open to feedback regarding the best workflows. The references
        in Rogue Scholar posts are of course not limited to journal articles, preprints,
        or conference proceedings, but can also include datasets, software (such as
        the <a href=\\\"https://doi.org/10.5281/ZENODO.7752775\\\">software used to
        generate the Crossref metadata</a>), or anything with a URL that needs referencing.
        \ </p>\\n<p>Of course I am fully aware that including references is only part
        of the story. I assume that Rogue Scholar blog authors are also interested
        in citations of their blog posts, and thanks to the work by many organizations
        including Crossref and <a href=\\\"https://opencitations.net/\\\">OpenCitations</a>
        <a href=\\\"https://doi.org/10.53731/rc3j5sn-tzg61kj-7ztra\\\">Open Citation
        data has reached a critical milestone</a>. I will update the Rogue Scholar
        to display these citations in the coming months.</p>\\n<h2 id=\\\"references\\\">References</h2>\\n<p>Fenner
        M. <em>Starting to Register DOIs for All Blog Posts Included in the Rogue
        Scholar</em>. Feature; 2023. doi:<a href=\\\"https://doi.org/10.53731/m9fs5-nap05\\\">10.53731/m9fs5-nap05</a></p>\\n<p>Fenner
        M. <em>Reference Lists and Tables of Content</em>. Feature; 2016. doi:<a href=\\\"https://doi.org/10.53731/r795v41-97aq74v-ag4cd\\\">10.53731/r795v41-97aq74v-ag4cd</a></p>\\n<p>Fenner,
        Martin. commonmeta-ruby. Published online March 20, 2023. doi:<a href=\\\"https://doi.org/10.5281/ZENODO.7752775\\\">10.5281/ZENODO.7752775</a></p>\\n<p>Fenner
        M. <em>Open Citation Data Reach Critical Milestone</em>. Perspective; 2021.
        doi:<a href=\\\"https://doi.org/10.53731/rc3j5sn-tzg61kj-7ztra\\\">10.53731/rc3j5sn-tzg61kj-7ztra</a></p>\",\"comment_id\":\"648c13c2bad6d80001bd072a\",\"feature_image\":\"https://blog.front-matter.io/content/images/2023/06/article2-1-1.png\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2023-06-16T07:48:18.000+00:00\",\"updated_at\":\"2023-06-16T09:11:18.000+00:00\",\"published_at\":\"2023-06-16T09:11:18.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/6mkrk-dzh02\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":null,\"url\":\"https://blog.front-matter.io/posts/starting-to-include-references-in-doi-metadata-for-blog-posts/\",\"excerpt\":\"Two
        weeks ago I started registering DOIs for blog posts included in the Rogue
        Scholar blog archive. It is an automated process but involves a lot of manual
        checks. So far I have registered 231 blog posts from 20 different science
        blogs, and I hope to finish the DOI registrations by the end of the month.
        Going forward these DOI registrations will happen automatically whenever one
        of the science blogs included in the Rogue Scholar publishes a new post. I
        do this by monitoring the RSS feeds of thes\",\"reading_time\":3,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":\"Image
        by <a href=\\\"https://twitter.com/gbilder\\\">Geoff Bilder</a>.\"},{\"id\":\"647dd211e640890001564d5a\",\"uuid\":\"5c49994d-7b19-447b-b55f-47747189c21c\",\"title\":\"Starting
        to register DOIs for all blog posts included in the Rogue Scholar\",\"slug\":\"starting-to-register-dois-for-all-blog-posts-included-in-the-rogue-scholar\",\"html\":\"<p>The
        <a href=\\\"https://rogue-scholar.org/\\\">Rogue Scholar</a> archive of scholarly
        blogs has grown to 34 blogs with about 420 blog posts. In order to implement
        DOI registration for these blog posts, I needed two things:</p><ul><li>Content
        and metadata, ideally without requiring blogs to implement anything special.</li><li>A
        way to track the DOIs that have been registered</li></ul><p>Initial work on
        DOI registration for blog posts focussed on exposing the relevant metadata
        on the blog landing page, using schema.org and/or HTML meta tags. While this
        approach worked well for this and similar blogs, it was too complicated and
        didn't scale well for the large and diverse number of blogs the Rogue Scholar
        aims to cover. </p><p>Therefore I implemented a different workflow taking
        advantage of the fact that all blogs come with RSS feeds that include content
        and metadata. More work was needed because there are different formats for
        these feeds (multiple flavors of RSS, as well as <a href=\\\"https://en.wikipedia.org/wiki/Atom_(web_standard)\\\">Atom</a>,
        and the newer <a href=\\\"https://www.jsonfeed.org/\\\">JSON Feed</a>). Luckily,
        \_libraries in multiple programming languages exist to simplify the parsing
        of the various RSS Feed formats (I use the Javascript library <a href=\\\"https://www.npmjs.com/package/@extractus/feed-extractor\\\">feed-extractor</a>).</p><p>The
        main challenge with metadata for blog posts \u2013 and with DOI metadata more
        general \u2013 is author names. They might not be natural names (for example
        <strong>mfenner</strong> instead of <strong>Martin Fenner</strong>), might
        be names for organizations and not people, the blogging platform might not
        support multiple authors, and some work is required to include the ORCID author
        identifier (or ROR institutional. identifier). The Atom format supports an
        <strong>author URL</strong>, which can hold the ORCID ID (or ROR ID), and
        Wordpress can be enhanced with the popular <a href=\\\"https://wordpress.org/plugins/co-authors-plus/\\\">Co-Authors
        Plus</a> plugin to support multiple authors. </p><p>The other challenge with
        DOI registration is keeping track of the content that has already been registered,
        and for this I launched a database, with one record for each post. I need
        the database also to enable full-text search across all blog posts, something
        I will implement in the coming weeks. </p><p>Will all the required pieces
        coming together, I was finally able to start DOI registrations yesterday.
        You will easily detect blog posts with a DOI on the Rogue Scholar website
        (there is a DOI icon next to the title, and the underlying link to the blog
        post is a DOI):</p><figure class=\\\"kg-card kg-image-card\\\"><img src=\\\"https://blog.front-matter.io/content/images/2023/06/Bildschirmfoto-2023-06-05-um-14.58.49.png\\\"
        class=\\\"kg-image\\\" alt loading=\\\"lazy\\\" width=\\\"2000\\\" height=\\\"1046\\\"
        srcset=\\\"https://blog.front-matter.io/content/images/size/w600/2023/06/Bildschirmfoto-2023-06-05-um-14.58.49.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/06/Bildschirmfoto-2023-06-05-um-14.58.49.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/06/Bildschirmfoto-2023-06-05-um-14.58.49.png
        1600w, https://blog.front-matter.io/content/images/size/w2400/2023/06/Bildschirmfoto-2023-06-05-um-14.58.49.png
        2400w\\\" sizes=\\\"(min-width: 720px) 720px\\\"></figure><p>The process of
        DOI registration for all included blog posts should be concluded by the end
        of the month. There is more work needed to resolve issues with some author
        names, and DOI registration can be further automated (I am currently using
        GitHub Actions and a cronjob). </p><p>What also needs more work is getting
        the DOIs displayed on the blogs (the DOIs resolve to the blog post and not
        the Rogue Scholar archive). This is probably straightforward when using a
        static site generator, but requires more work when a database is involved
        (e.g. Wordpress). For Ghost blogs like this one, I found the <strong>canonical_url</strong>
        field to be a good place to store the DOI.</p>\",\"comment_id\":\"647dd211e640890001564d5a\",\"feature_image\":\"https://blog.front-matter.io/content/images/2023/06/Bildschirmfoto-2023-06-05-um-14.58.49-1.png\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2023-06-05T12:16:17.000+00:00\",\"updated_at\":\"2023-06-05T13:18:24.000+00:00\",\"published_at\":\"2023-06-05T13:18:24.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/m9fs5-nap05\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42bbc41e317003df48d4e\",\"name\":\"Feature\",\"slug\":\"feature\",\"description\":\"Features
        explore issues raised by news stories in more depth.\",\"feature_image\":\"https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fHJlc2VhcmNofGVufDB8fHx8MTYxODEyMzQxNQ&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/feature/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42bbc41e317003df48d4e\",\"name\":\"Feature\",\"slug\":\"feature\",\"description\":\"Features
        explore issues raised by news stories in more depth.\",\"feature_image\":\"https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fHJlc2VhcmNofGVufDB8fHx8MTYxODEyMzQxNQ&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/feature/\"},\"url\":\"https://blog.front-matter.io/posts/starting-to-register-dois-for-all-blog-posts-included-in-the-rogue-scholar/\",\"excerpt\":\"The
        Rogue Scholar archive of scholarly blogs has grown to 34 blogs with about
        420 blog posts. In order to implement DOI registration for these blog posts,
        I needed two things:\\n\\n * Content and metadata, ideally without requiring
        blogs to implement anything special.\\n * A way to track the DOIs that have
        been registered\\n\\nInitial work on DOI registration for blog posts focussed
        on exposing the relevant metadata on the blog landing page, using schema.org
        and/or HTML meta tags. While this approach work\",\"reading_time\":2,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":null},{\"id\":\"6463578467d0530001248ab6\",\"uuid\":\"3a12566b-c03d-4935-bc5f-94ab8db380b5\",\"title\":\"Does
        it compose?\",\"slug\":\"does-it-compose\",\"html\":\"<p>One question I have
        increasingly asked myself in the past few years. Meaning </p><blockquote>Can
        I run this open source software \_using Docker containers and a Docker Compose
        file?</blockquote><p>As the Docker project <a href=\\\"https://snyk.io/blog/the-docker-project-turns-10/\\\">turned
        ten this spring</a>, it has become standard practice to distribute open source
        software via Docker images and to provide a <a href=\\\"https://docs.docker.com/compose/\\\">Docker
        Compose</a> file to run the software together with other dependencies. The
        <a href=\\\"https://github.com/docker/awesome-compose\\\">Awesome Compose</a>
        project has collected many examples, and all you need is a <code>docker-compose.yml</code>file
        and a recent installation of Docker, e.g. <a href=\\\"https://www.docker.com/products/docker-desktop/\\\">Docker
        Desktop</a>. Be aware that Docker Compose has evolved over the years. It started
        out as a dedicated Python application but was later integrated into the Docker
        application (written in Go) as Compose V2.</p><p>Docker and Docker Compose
        allow you to run pretty complex applications without first addressing a long
        list of requirements (which might conflict with other software you have installed),
        or needing a long and complex build step where many things can go wrong. For
        example a self-hosted instance of Supabase (a hosted Postgres database with
        additional features) that I installed last week following <a href=\\\"https://supabase.com/docs/guides/self-hosting/docker\\\">these
        instructions</a>.</p><p>An important open source project that I am involved
        in is <a href=\\\"https://inveniordm.docs.cern.ch/\\\">InvenioRDM</a>, the
        turn-key research data management repository. InvenioRDM started in 2019,
        with a first production-suitable version in August 2021, and the <a href=\\\"https://inveniosoftware.org/products/rdm/#status\\\">next
        major goal </a>is to have the large and popular <a href=\\\"https://zenodo.org/\\\">Zenodo</a>
        repository running on top of InvenioRDM. Zenodo <a href=\\\"https://blog.zenodo.org/2023/05/08/2023-05-08-10years/\\\">turned
        ten last week</a>, a few weeks after Docker. Interestingly, my personal tenth
        anniversary was last year in May as I became a full-time software developer
        and left academic medicine as a medical doctor treating cancer patients in
        <a href=\\\"https://doi.org/10.53731/r294649-6f79289-8cw2j\\\">May 2012</a>.</p><p>Unfortunately,
        InvenioRDM \\\"doesn't compose\\\" yet. It is very close, but there are no
        ready-made Docker images to download, and the <a href=\\\"https://inveniordm.docs.cern.ch/install/\\\">installation
        instructions</a> start with installing a Python command-line tool (invenio-cli).
        So if you have 1-2 hours to play with InvenioRDM and get a first impression,
        there is no official solution from the InvenioRDM project yet. For this reason,
        I started the <a href=\\\"https://github.com/front-matter/docker-invenio-rdm\\\">docker-invenio-rdm</a>
        repository on Github. It contains a Docker Compose file that uses pre-built
        Docker images, and using that file with a <code>docker compose up</code>command
        on your local computer should give you a running InvenioRDM within 15 minutes:</p><figure
        class=\\\"kg-card kg-image-card\\\"><img src=\\\"https://blog.front-matter.io/content/images/2023/05/Bildschirmfoto-2023-05-11-um-10.37.55.png\\\"
        class=\\\"kg-image\\\" alt loading=\\\"lazy\\\" width=\\\"2000\\\" height=\\\"1210\\\"
        srcset=\\\"https://blog.front-matter.io/content/images/size/w600/2023/05/Bildschirmfoto-2023-05-11-um-10.37.55.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/05/Bildschirmfoto-2023-05-11-um-10.37.55.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/05/Bildschirmfoto-2023-05-11-um-10.37.55.png
        1600w, https://blog.front-matter.io/content/images/2023/05/Bildschirmfoto-2023-05-11-um-10.37.55.png
        2193w\\\" sizes=\\\"(min-width: 720px) 720px\\\"></figure><p>I started this
        recently and obviously want to move forward in two directions:</p><ul><li>fine-tune
        the initial configuration to provide a great initial experience with InvenioRDM,
        e.g. making it easy to <a href=\\\"https://inveniordm.docs.cern.ch/develop/topics/theming/\\\">theme</a>
        the InvenioRDM instance</li><li>make this an official part of the InvenioRDM
        project, extending the <a href=\\\"https://github.com/inveniosoftware/docker-invenio\\\">docker-invenio</a>
        GitHub repository that provides Docker base images for InvenioRDM and other
        projects using the Invenio software.</li></ul><p>But of course, Docker Compose
        is not the answer to all questions regarding running Docker-based infrastructure.
        For production environments, most people shy away from using Docker Compose.
        The reasons for that and the alternatives will be the topic of a future blog
        post (spoiler: there is exciting news).</p><p>Docker Compose also needs more
        work to be set up correctly for development environments. It is a common practice
        and a workflow I used while working at DataCite (where we launched Docker-based
        infrastructure in 2016), but for now, the easiest way to set up InvenioRDM
        development environments is using the <a href=\\\"https://inveniordm.docs.cern.ch/install/\\\">invenio-cli
        tool with a local development environment</a>.</p><p>Please reach out to me
        with feedback on running Docker Compose for InvenioRDM (use the <a href=\\\"https://github.com/front-matter/docker-invenio-rdm/discussions\\\">discussions</a>
        feature in the GitHub repo), or if you have questions about running InvenioRDM
        in production.</p>\",\"comment_id\":\"6463578467d0530001248ab6\",\"feature_image\":\"https://images.unsplash.com/photo-1523351964962-1ee5847816c3?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=M3wxMTc3M3wwfDF8c2VhcmNofDUzfHxjb250YWluZXJ8ZW58MHx8fHwxNjg0MjMyMTQ0fDA&ixlib=rb-4.0.3&q=80&w=2000\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2023-05-16T10:14:28.000+00:00\",\"updated_at\":\"2023-06-18T10:27:46.000+00:00\",\"published_at\":\"2023-05-16T11:36:56.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/4nwxn-frt36\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"},\"url\":\"https://blog.front-matter.io/posts/does-it-compose/\",\"excerpt\":\"One
        question I have increasingly asked myself in the past few years. Meaning\\n\\nCan
        I run this open source software \_using Docker containers and a Docker Compose
        file?\\n\\nAs the Docker project turned ten this spring, it has become standard
        practice to distribute open source software via Docker images and to provide
        a Docker Compose file to run the software together with other dependencies.
        The Awesome Compose project has collected many examples, and all you need
        is a docker-compose.ymlfile and a rec\",\"reading_time\":3,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":\"Photo
        by <a href=\\\"https://unsplash.com/@nickkarvounis?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Nick
        Karvounis</a> / <a href=\\\"https://unsplash.com/?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Unsplash</a>\"},{\"id\":\"643d5c67dc6b00003d79d9b7\",\"uuid\":\"8896cf4c-c97a-45f2-b422-a0334fcdb4bf\",\"title\":\"Dog
        food, persistent identifiers, and metadata\",\"slug\":\"dog-food-persistent-identifiers-and-metadata\",\"html\":\"<p>I
        am a big fan of dog food, and I <a href=\\\"https://doi.org/10.53731/r79vxn1-97aq74v-ag58n\\\">wrote
        about this topic</a> already seven years ago:</p><blockquote><a href=\\\"https://newrepublic.com/article/115349/dogfooding-tech-slang-working-out-glitches\\\">Eating
        your own dog food</a> is a slang term to describe that an organization should
        itself use the products and services it provides. </blockquote><p>One of the
        major projects I am working on right now is the <a href=\\\"https://rogue-scholar.org\\\">Rogue
        Scholar</a> science blog archive <a href=\\\"https://doi.org/10.53731/z9v2s-bh329\\\">that
        launched</a> at the beginning of the month. As part of this work \u2013 but
        also because I am very interested in this \u2013 I read a lot of science blogs.
        And today I released an update of the Rogue Scholar that makes this easier.</p><h3
        id=\\\"persistent-identifiers-for-science-blogs\\\">Persistent identifiers
        for science blogs</h3><p>People who know me know that I care about persistent
        identifiers for scholarly resources. I have worked for seven years for <a
        href=\\\"https://datacite.org\\\">DataCite</a>, a DOI registration to register
        datasets, software, and other non-textual resources. I was involved in the
        launch of <a href=\\\"https://orcid.org\\\">ORCID</a> (identifiers for researchers)
        in 2012 and <a href=\\\"https://ror.org\\\">ROR</a> (identifiers for research
        organizations) in 2019. So it shouldn't surprise anyone that I am officially
        announcing the Rogue Scholar identifier for science blogs today. Each blog
        that has registered with the Rogue Scholar is uniquely identified, e.g. </p><ul><li>Upstream
        <a href=\\\"https://rogue-scholar.org/pm0p222\\\">https://rogue-scholar.org/pm0p222</a>,</li><li>GigaBlog
        <a href=\\\"https://rogue-scholar.org/3ffcd46\\\">https://rogue-scholar.org/3ffcd46</a>,
        and of course</li><li>Front Matter <a href=\\\"https://rogue-scholar.org/f0m0e38\\\">https://rogue-scholar.org/f0m0e38</a></li></ul><p>Persistent
        identifiers should not have any semantic meaning (e.g. the blog name) in them,
        as names can change over time. And they should not be linked to a domain name,
        (e.g. upstream.force11.org) as those might also change. The Rogue Scholar
        identifier uses a 7-digit random string generated by the <a href=\\\"https://github.com/front-matter/base32-url\\\">base32
        algorithm</a> and a two-digit checksum (the Front Matter identifier for example
        was generated with the random number 16127113320). DataCite, ROR, and the
        repository <a href=\\\"https://zenodo.org\\\">Zenodo</a> use similarly constructed
        unique identifiers. Their main advantage over <a href=\\\"https://en.wikipedia.org/wiki/Universally_unique_identifier\\\">UUIDs</a>
        is that they are easier to handle because of their compact size \u2013 there
        are still more than three billion unique strings for the Rogue Scholar identifier.
        Finally, persistent identifiers should be actionable, which means expressed
        as URLs that a human or machine can follow.</p><p>Why did I not use International
        Standard Serial Numbers (<a href=\\\"https://www.issn.org/\\\">ISSNs</a>),
        well-established identifiers that also work for blogs (the Front Matter blog
        has ISSN <a href=\\\"https://portal.issn.org/resource/ISSN/2749-9952\\\">2749-9952</a>)?
        Why ISSN registration can be easy and cheap, registration can become an issue,
        especially for new blogs that are just beginning to publish. And ISSNs have
        only the most basic metadata (e.g. title, country). And why not use digital
        object identifiers (<a href=\\\"https://www.doi.org/\\\">DOIs</a>)? They have
        traditionally been used for scholarly outputs such as journal articles, datasets,
        and <a href=\\\"https://doi.org/10.53731/fezg09h-hgn1gzm\\\">blog posts</a>.
        While you can register DOIs for serials such as journals, conference proceedings,
        or blogs, there is currently no standard practice to do so.</p><h3 id=\\\"metadata-for-science-blogs\\\">Metadata
        for science blogs</h3><p>Persistent identifiers are not really useful without
        meaningful metadata. For science blogs, this means at least the following:</p><ul><li>Blog
        name</li><li>Blog short description</li><li>Blog URL</li><li>Alternate identifiers,
        e.g ISSN and/or DOI</li><li>Blog editor(s)</li><li>License for the content,
        e.g Creative Commons Attribution (<a href=\\\"https://creativecommons.org/licenses/by/4.0/\\\">CC-BY</a>)</li><li>Subject
        area(s) for the content, e.g. aligned with the <a href=\\\"https://en.wikipedia.org/wiki/Fields_of_Science_and_Technology\\\">OECD
        Fields of Science and Technology</a></li></ul><p>For the blogs participating
        in the Rogue Scholar, I am collecting this information and will make it available
        in the Rogue Scholar search. To not start from scratch, I am using the metadata
        available from most blogs via <a href=\\\"https://doi.org/10.53731/d6vdvbt-tffmezj\\\">RSS
        or Atom feed</a>. For some information, e.g. license or subject area, I need
        to ask additional questions to the blog editor.</p><p>RSS and Atom both use
        XML, rather than JSON, which is much more pleasant to work with. Therefore
        \u2013 after the initial conversion of RSS or Atom XML \u2013 I can use <a
        href=\\\"https://www.jsonfeed.org/\\\">JSON Feed</a> to describe blog metadata,
        and the format can be extended to the needs of the Rogue Scholar. To fetch
        the JSON Feed of a blog included in the Rogue Scholar, use the identifier.
        Either by appending <code>.json</code> to the identifier (e.g. <a href=\\\"https://rogue-scholar.org/h56tk29.json\\\">https://rogue-scholar.org/h56tk29.json</a>)
        or by entering the identifier (<a href=\\\"https://rogue-scholar.org/h56tk29.json\\\">https://rogue-scholar.org/h56tk29</a>)
        in your RSS reader. The reader will automatically find the JSON Feed via the
        link tag in the page header:</p><pre><code>&lt;link rel=\\\"alternate\\\"
        title=\\\"Jabberwocky Ecology\\\" type=\\\"application/feed+json\\\" href=\\\"https://rogue-scholar.org/h56tk29.json\\\"/&gt;</code></pre><p>The
        RSS Reader (assuming it supports JSON Feed, as most readers do) will subscribe
        you to the JSON Feed of the blog, simplifying the reading of science blogs.
        More work is needed to polish the RSS/Atom Feed conversion to JSON Feed done
        by the Rogue Scholar and streamline subscribing to multiple blogs at once,
        e.g. using <a href=\\\"https://doi.org/10.53731/wa7k5-v4t16\\\">OPML</a>.
        </p><p>JSON Feed can also be used for the metadata and content of blog posts,
        so again I don't need to use XML, e.g. Journal Article Tag Suite (<a href=\\\"https://jats.nlm.nih.gov/\\\">JATS</a>).
        For blog posts, I will continue to <a href=\\\"https://doi.org/10.53731/rb7xw01-97aq74v-ag7qh\\\">use
        DOIs</a>, as they work well, and I am making progress with Rogue Scholar integration
        (see for example this blog using DOIs already: <a href=\\\"https://rogue-scholar.org/f4wdg32\\\">https://rogue-scholar.org/f4wdg32</a>)</p><h3
        id=\\\"bringing-everything-together\\\">Bringing everything together</h3><p>How
        does the above help with finding, reading, sharing, or otherwise reusing science
        blogs? The work released today should make it easier to find interesting science
        blogs via the Rogue Scholar and subscribe to them via your RSS reader of choice.
        Over time we will hopefully see evolving community standards regarding blog
        persistent identifiers and metadata, following the <a href=\\\"https://www.go-fair.org/fair-principles/\\\">FAIR
        Principles</a>, while at the same time pushing hard for <a href=\\\"https://www.scienceeurope.org/our-priorities/open-access/diamond-open-access/\\\">Diamond
        Open Access</a>, keeping the cost and technical complexity affordable.</p>\",\"comment_id\":\"643d5c67dc6b00003d79d9b7\",\"feature_image\":\"https://images.unsplash.com/photo-1608408891486-f5cade977d19?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fGRvZyUyMGZvb2R8ZW58MHx8fHwxNjgxNzQyOTYy&ixlib=rb-4.0.3&q=80&w=2000\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2023-04-17T14:49:11.000+00:00\",\"updated_at\":\"2023-04-17T17:20:25.000+00:00\",\"published_at\":\"2023-04-17T17:08:26.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/nfa3v-h9q90\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42bbc41e317003df48d4e\",\"name\":\"Feature\",\"slug\":\"feature\",\"description\":\"Features
        explore issues raised by news stories in more depth.\",\"feature_image\":\"https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fHJlc2VhcmNofGVufDB8fHx8MTYxODEyMzQxNQ&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/feature/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42bbc41e317003df48d4e\",\"name\":\"Feature\",\"slug\":\"feature\",\"description\":\"Features
        explore issues raised by news stories in more depth.\",\"feature_image\":\"https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fHJlc2VhcmNofGVufDB8fHx8MTYxODEyMzQxNQ&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/feature/\"},\"url\":\"https://blog.front-matter.io/posts/dog-food-persistent-identifiers-and-metadata/\",\"excerpt\":\"I
        am a big fan of dog food, and I wrote about this topic already seven years
        ago:\\n\\nEating your own dog food is a slang term to describe that an organization
        should itself use the products and services it provides.\\n\\nOne of the major
        projects I am working on right now is the Rogue Scholar science blog archive
        that launched at the beginning of the month. As part of this work \u2013 but
        also because I am very interested in this \u2013 I read a lot of science blogs.
        And today I released an update of the Rogue \",\"reading_time\":4,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":\"Photo
        by <a href=\\\"https://unsplash.com/@mollys_life?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">M
        Burke</a> / <a href=\\\"https://unsplash.com/?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Unsplash</a>\"},{\"id\":\"6435410bd3ede1003daa0897\",\"uuid\":\"e8be7fec-731a-485a-94a5-ace33cfdbc7d\",\"title\":\"Feedback
        for science blog publishers\",\"slug\":\"feedback-for-blog-publishers\",\"html\":\"<p>The
        <a href=\\\"https://rogue-scholar.org/\\\">Rogue Scholar</a> science blog
        archive <a href=\\\"https://doi.org/10.53731/z9v2s-bh329\\\">launched last
        week</a>. Going forward the focus is on improving the service and adding more
        blogs. This includes giving blog authors feedback on how they can improve
        their RSS/Atom feeds \u2013 used by the Rogue Scholar to collect and archive
        the blog content.</p><h3 id=\\\"feedback-for-science-blog-publishers\\\">Feedback
        for science blog publishers</h3><p>A good starting point is author information,
        which often can be improved. The first step is to support multiple authors
        and support their full (given and family) names instead of usernames. It is
        useful to include ORCID author identifiers, best done by using the author
        website field of the blogging platform. This information can then be included
        in the blog <a href=\\\"https://www.rfc-editor.org/rfc/rfc4287\\\">Atom feed</a>,
        which works better for this than <a href=\\\"https://en.wikipedia.org/wiki/RSS\\\">RSS
        feeds</a>.</p><p>The blog (RSS or Atom) feed includes a link for each blog
        post but also an <strong>id</strong> (Atom) or <strong>guid</strong> (RSS).
        Ideally, this id/guid is globally unique, does not change over time, and can
        be used as a web link. <a href=\\\"https://ask.library.uic.edu/faq/345899\\\">DOIs</a>
        are a perfect fit for this id/guid field, and several blogs included in the
        Rogue Scholar do this already (<a href=\\\"https://rogue-scholar.org/blogs/f0m0e38\\\">this
        blog</a> but also <a href=\\\"https://rogue-scholar.org/blogs/pm0p222\\\">Upstream</a>).
        Many blogging platforms have a <a href=\\\"https://developer.wordpress.org/reference/functions/wp_get_canonical_url/\\\">canonical_url</a>
        field that can be used to store the DOI, separate from the URL.</p><p>Abstracts
        are useful for blog posts and widely supported. Unfortunately, there is no
        standard way to provide them in RSS or Atom feeds. A good practice is to use
        text and not HTML and to limit the total number of characters (the Rogue Scholar
        limits abstracts to 210 characters).</p><p>Feature images for blog posts are
        again widely used but there is no standard way to do this in RSS or Atom feeds.
        Examples of Rogue Scholar blogs using feature images are <a href=\\\"https://rogue-scholar.org/blogs/n6x4a73\\\">Chris
        Hartgerink</a>, <a href=\\\"https://rogue-scholar.org/blogs/h7bpg11\\\">OA.Works</a>
        and <a href=\\\"https://rogue-scholar.org/blogs/f4wdg32\\\">Syldavia Gazette</a>.</p><h3
        id=\\\"blog-statistics\\\">Blog statistics</h3><p>This week I added <a href=\\\"https://rogue-scholar.org/#stats\\\">basic
        statistics</a> for the Rogue Scholar that give preliminary insights into the
        kind of science blogs covered by the Rogue Scholar. The <strong>category</strong>
        is the top-level classification of the <a href=\\\"https://www.oecd.org/science/inno/38235147.pdf\\\">OECD
        Fields of Science and Technology</a>. Many blogs cover Natural Sciences, Engineering
        and Technology, Social Sciences \u2013 Health and Medical Sciences, Humanities,
        and Agricultural Sciences are covered less. Almost all currently included
        blogs are in the English <strong>language</strong>, please reach out if you
        manage a blog in another language. Knowing the blogging <strong>platform</strong>
        helps integrate the various RSS feeds into the Rogue Scholar, and the results
        are as expected. Wordpress is the most popular blogging platform, \_but science
        blogs also use a variety of other platforms, including Ghost, Medium, and
        Blogger. Another interesting key performance indicator (KPI) is the total
        number of blogs and blog posts included, but this needs more work as this
        information is not immediately available.</p><figure class=\\\"kg-card kg-image-card
        kg-card-hascaption\\\"><img src=\\\"https://blog.front-matter.io/content/images/2023/04/Bildschirmfoto-2023-04-11-um-13.19.27.png\\\"
        class=\\\"kg-image\\\" alt loading=\\\"lazy\\\" width=\\\"2000\\\" height=\\\"716\\\"
        srcset=\\\"https://blog.front-matter.io/content/images/size/w600/2023/04/Bildschirmfoto-2023-04-11-um-13.19.27.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/04/Bildschirmfoto-2023-04-11-um-13.19.27.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/04/Bildschirmfoto-2023-04-11-um-13.19.27.png
        1600w, https://blog.front-matter.io/content/images/2023/04/Bildschirmfoto-2023-04-11-um-13.19.27.png
        2152w\\\" sizes=\\\"(min-width: 720px) 720px\\\"><figcaption><a href=\\\"https://rogue-scholar.org/#stats\\\">Basic
        statistics for the Rogue Scholar</a></figcaption></figure><h3 id=\\\"usage-statistics\\\">Usage
        statistics</h3><p>The Usage Stats for the Rogue Scholar are publicly available
        <a href=\\\"https://plausible.io/rogue-scholar.org\\\">here</a>. The numbers
        are still small and don't cover individual posts, or usage numbers from the
        blog itself, both of which may come over time. The Rogue Scholar intentionally
        isn't collecting any personal information or using any cookies, but the available
        public information can give important insights (e.g. the countries or referer
        pages where users come from).</p><figure class=\\\"kg-card kg-image-card kg-card-hascaption\\\"><img
        src=\\\"https://blog.front-matter.io/content/images/2023/04/Bildschirmfoto-2023-04-11-um-13.18.09.png\\\"
        class=\\\"kg-image\\\" alt loading=\\\"lazy\\\" width=\\\"2000\\\" height=\\\"1146\\\"
        srcset=\\\"https://blog.front-matter.io/content/images/size/w600/2023/04/Bildschirmfoto-2023-04-11-um-13.18.09.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/04/Bildschirmfoto-2023-04-11-um-13.18.09.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/04/Bildschirmfoto-2023-04-11-um-13.18.09.png
        1600w, https://blog.front-matter.io/content/images/2023/04/Bildschirmfoto-2023-04-11-um-13.18.09.png
        2038w\\\" sizes=\\\"(min-width: 720px) 720px\\\"><figcaption><a href=\\\"https://plausible.io/rogue-scholar.org\\\">Daily
        traffic to the Rogue Scholar</a></figcaption></figure>\",\"comment_id\":\"6435410bd3ede1003daa0897\",\"feature_image\":\"https://blog.front-matter.io/content/images/2023/04/Bildschirmfoto-2023-04-11-um-13.14.02.png\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2023-04-11T11:14:19.000+00:00\",\"updated_at\":\"2023-04-14T20:50:32.000+00:00\",\"published_at\":\"2023-04-11T12:31:40.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/h4b6c-h1444\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42bbc41e317003df48d4e\",\"name\":\"Feature\",\"slug\":\"feature\",\"description\":\"Features
        explore issues raised by news stories in more depth.\",\"feature_image\":\"https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fHJlc2VhcmNofGVufDB8fHx8MTYxODEyMzQxNQ&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/feature/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42bbc41e317003df48d4e\",\"name\":\"Feature\",\"slug\":\"feature\",\"description\":\"Features
        explore issues raised by news stories in more depth.\",\"feature_image\":\"https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fHJlc2VhcmNofGVufDB8fHx8MTYxODEyMzQxNQ&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/feature/\"},\"url\":\"https://blog.front-matter.io/posts/feedback-for-blog-publishers/\",\"excerpt\":\"The
        Rogue Scholar science blog archive launched last week. Going forward the focus
        is on improving the service and adding more blogs. This includes giving blog
        authors feedback on how they can improve their RSS/Atom feeds \u2013 used
        by the Rogue Scholar to collect and archive the blog content.\\n\\n\\nFeedback
        for science blog publishers\\n\\nA good starting point is author information,
        which often can be improved. The first step is to support multiple authors
        and support their full (given and family) names i\",\"reading_time\":2,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":\"<a
        href=\\\"https://rogue-scholar.org/#stats\\\">Rogue Scholar statistics</a>\"},{\"id\":\"642bcfcd356ed7003d0e56aa\",\"uuid\":\"e1064eaa-0953-49c4-a5cc-adab72d5b985\",\"title\":\"The
        Rogue Scholar is now open for business\",\"slug\":\"rogue-scholar-open-for-business\",\"html\":\"<p>The
        <a href=\\\"https://rogue-scholar.org/\\\">Rogue Scholar</a> science blog
        archive launched with limited functionality on April 3rd. Interested science
        blogs can go to the sign-up page, provide some basic information via the <a
        href=\\\"https://jvinjjenjik.typeform.com/to/uxgAsHPl\\\">sign-up form</a>,
        and then will be added to the Rogue Scholar archive within two business days.
        </p><p>To be included in the service, your blog needs to:</p><ul><li>be about
        science or scholarship and written in English or German (more languages will
        follow later, reach out to me if you can help),</li><li>make the full-text
        content available via RSS feed and distributed under the terms of the Creative
        Commons Attribution license (<a href=\\\"https://creativecommons.org/licenses/by/4.0/legalcode\\\">CC-BY</a>).</li></ul><p>Blogs
        that have signed up for the service (more than twenty so far) are listed in
        the <a href=\\\"https://rogue-scholar.org/blogs\\\">Rogue Scholar catalog
        of science blogs</a> that <a href=\\\"https://doi.org/10.53731/n7vvs-h6995\\\">launched
        last week</a>. And since yesterday summaries of the latest fifteen blog posts
        of each blog are also available.</p><figure class=\\\"kg-card kg-image-card
        kg-card-hascaption\\\"><img src=\\\"https://blog.front-matter.io/content/images/2023/04/Bildschirmfoto-2023-04-04-um-10.12.58.png\\\"
        class=\\\"kg-image\\\" alt loading=\\\"lazy\\\" width=\\\"1882\\\" height=\\\"1428\\\"
        srcset=\\\"https://blog.front-matter.io/content/images/size/w600/2023/04/Bildschirmfoto-2023-04-04-um-10.12.58.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/04/Bildschirmfoto-2023-04-04-um-10.12.58.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/04/Bildschirmfoto-2023-04-04-um-10.12.58.png
        1600w, https://blog.front-matter.io/content/images/2023/04/Bildschirmfoto-2023-04-04-um-10.12.58.png
        1882w\\\" sizes=\\\"(min-width: 720px) 720px\\\"><figcaption><a href=\\\"https://rogue-scholar.org/blogs/pm0p222\\\">Blog
        posts displayed at the Rogue Scholar</a></figcaption></figure><p>These summaries
        (precisely the information you get in the RSS feed) serve two purposes:</p><ul><li>for
        readers: learn more about that particular science blog. Reading the full-text
        post or other blog posts is only one click away</li><li>for blog authors and
        Rogue Scholar staff: tweak the blog and/or Rogue Scholar if there are issues
        with archiving. </li></ul><p>The screenshot highlights several considerations
        when using the RSS Feed to archive a science blog in the Rogue Scholar:</p><ul><li>optional
        but desired metadata, e.g logo, description, and language for blogs or description,
        tags, and feature image for blog posts</li><li>handling authors, including
        full names instead of usernames, multiple authors, and author identifiers
        (ORCID)</li><li>handling DOIs, including exposing them in the RSS feed, and
        making sure no DOI exists for the post yet</li></ul><p>The Rogue Scholar is
        now open for business, and I hope the limited functionality (or <a href=\\\"https://www.zentao.pm/blog/mvp-minimum-viable-product-965.html\\\">minimum
        viable product</a>) launched this week makes it an attractive service for
        blog readers and authors to try out. The next big milestone is the launch
        of the full-text index for searching and archiving, and that is planned to
        happen within the next three months. Followed by DOI registration for blog
        posts.</p>\",\"comment_id\":\"642bcfcd356ed7003d0e56aa\",\"feature_image\":\"https://images.unsplash.com/photo-1575663620136-5ebbfcc2c597?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG9wZW4lMjBmb3IlMjBidXNpbmVzc3xlbnwwfHx8fDE2ODA1OTI3NTU&ixlib=rb-4.0.3&q=80&w=2000\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2023-04-04T07:20:45.000+00:00\",\"updated_at\":\"2023-04-04T09:31:14.000+00:00\",\"published_at\":\"2023-04-04T08:43:36.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/z9v2s-bh329\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"},\"url\":\"https://blog.front-matter.io/posts/rogue-scholar-open-for-business/\",\"excerpt\":\"The
        Rogue Scholar science blog archive launched with limited functionality on
        April 3rd. Interested science blogs can go to the sign-up page, provide some
        basic information via the sign-up form, and then will be added to the Rogue
        Scholar archive within two business days.\\n\\nTo be included in the service,
        your blog needs to:\\n\\n * be about science or scholarship and written in
        English or German (more languages will follow later, reach out to me if you
        can help),\\n * make the full-text content availab\",\"reading_time\":2,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":\"Photo
        by <a href=\\\"https://unsplash.com/@timmossholder?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Tim
        Mossholder</a> / <a href=\\\"https://unsplash.com/?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Unsplash</a>\"},{\"id\":\"64249e22356ed7003d0e5623\",\"uuid\":\"5b05c234-3b08-4e88-9531-03f6b4e75874\",\"title\":\"The
        Rogue Scholar releases its first catalog of science blogs\",\"slug\":\"rogue-scholar-releases-first-catalog\",\"html\":\"<p>The
        Rogue Scholar blog archive today released its <a href=\\\"https://rogue-scholar.org/blogs\\\">first
        catalog of science blogs</a>, a total of nineteen science blogs that signed
        up for the Rogue Scholar via <a href=\\\"https://jvinjjenjik.typeform.com/to/uxgAsHPl\\\">submission
        form</a> and met the inclusion criteria: </p><ul><li>The blog is about science
        and in English or German (more languages will follow later, reach out to me
        if you can help).</li><li>The full-text content is available via RSS feed
        and distributed using a Creative Commons Attribution license (<a href=\\\"https://creativecommons.org/licenses/by/4.0/legalcode\\\">CC-BY</a>).</li></ul><p>The
        Rogue Scholar will launch in the second quarter of this year, and this list
        of science blogs is an important step. The RSS feeds of the included blogs
        will be used to archive content and register DOIs, and they contain important
        information that I will include over time, including license, language, blog
        description, blog logo, contact person, and blogging platform.</p><figure
        class=\\\"kg-card kg-image-card kg-card-hascaption\\\"><img src=\\\"https://blog.front-matter.io/content/images/2023/03/Bildschirmfoto-2023-03-29-um-22.38.08.png\\\"
        class=\\\"kg-image\\\" alt loading=\\\"lazy\\\" width=\\\"2000\\\" height=\\\"841\\\"
        srcset=\\\"https://blog.front-matter.io/content/images/size/w600/2023/03/Bildschirmfoto-2023-03-29-um-22.38.08.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2023/03/Bildschirmfoto-2023-03-29-um-22.38.08.png
        1000w, https://blog.front-matter.io/content/images/size/w1600/2023/03/Bildschirmfoto-2023-03-29-um-22.38.08.png
        1600w, https://blog.front-matter.io/content/images/size/w2400/2023/03/Bildschirmfoto-2023-03-29-um-22.38.08.png
        2400w\\\" sizes=\\\"(min-width: 720px) 720px\\\"><figcaption>Subset of the
        blogs included in the first <a href=\\\"https://rogue-scholar.org/blogs\\\">Rogue
        Scholar catalog</a></figcaption></figure><p>The first Rogue Scholar catalog
        can be used as a starting point to find interesting science blogs, but more
        importantly, the catalog is available as an <a href=\\\"https://doi.org/10.53731/wa7k5-v4t16\\\">OPML
        file</a> for download and can be imported (and modified) into any blog reader.</p>\",\"comment_id\":\"64249e22356ed7003d0e5623\",\"feature_image\":\"https://images.unsplash.com/photo-1662582632158-7f0f6e9a617b?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDMzfHxjYXRhbG9nfGVufDB8fHx8MTY4MDEyMTQ2MQ&ixlib=rb-4.0.3&q=80&w=2000\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2023-03-29T20:22:58.000+00:00\",\"updated_at\":\"2023-04-04T09:22:41.000+00:00\",\"published_at\":\"2023-03-29T20:46:54.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/n7vvs-h6995\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"},\"url\":\"https://blog.front-matter.io/posts/rogue-scholar-releases-first-catalog/\",\"excerpt\":\"The
        Rogue Scholar blog archive today released its first catalog of science blogs,
        a total of nineteen science blogs that signed up for the Rogue Scholar via
        submission form and met the inclusion criteria:\\n\\n * The blog is about
        science and in English or German (more languages will follow later, reach
        out to me if you can help).\\n * The full-text content is available via RSS
        feed and distributed using a Creative Commons Attribution license (CC-BY).\\n\\nThe
        Rogue Scholar will launch in the second quart\",\"reading_time\":1,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":\"Photo
        by <a href=\\\"https://unsplash.com/@danielforsman?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Daniel
        Forsman</a> / <a href=\\\"https://unsplash.com/?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Unsplash</a>\"},{\"id\":\"641ac02dd13414003d462433\",\"uuid\":\"ad3c34f1-871c-45ce-9e6d-cf083ba826bc\",\"title\":\"Starting
        the Rogue Scholar OPML Feed\",\"slug\":\"starting-the-rogue-scholar-opml-feed\",\"html\":\"<p>While
        the launch of the <a href=\\\"https://rogue-scholar.org/\\\">Rogue Scholar</a>
        blog archive is still a few months away (happening in the second quarter of
        this year), I want to give an update on the ongoing work.</p><p>The <em>Rogue
        Scholar</em> blog archive will improve science blogs in important ways,<br>including
        full-text search, DOIs and metadata, and long-term archiving. The central
        piece of the underlying infrastructure is the <a href=\\\"https://inveniosoftware.org/products/rdm/\\\">InvenioRDM
        </a>open source repository software. Front Matter is one of the organizations
        helping with InvenioRDM development. For the <em>Rogue Scholar,</em> the specific
        work needed includes the following:</p><h3 id=\\\"support-for-rss-feeds\\\">Support
        for RSS Feeds</h3><p>All blogs provide RSS feeds, which will be central to
        automatically fetching metadata and content for the <em>Rogue Scholar</em>.
        RSS is not built into InvenioRDM and is not needed by most organizations planning
        to run InvenioRDM. I will therefore build a separate service for this functionality,
        integrating with InvenioRDM via its REST API. For a blog to be archived and
        indexed in the <em>Rogue Scholar</em>, users will use this RSS service, providing
        basic information such as RSS feed URL, language, license, and contact person
        \u2013 basically the information collected for the <em>Rogue Scholar</em>
        <a href=\\\"https://jvinjjenjik.typeform.com/to/uxgAsHPl?typeform-source=rogue-scholar.org\\\">waitlist</a>
        (feel free to sign up your blog if you haven't already).</p><p>Next Tuesday
        I will publish an <a href=\\\"https://en.wikipedia.org/wiki/OPML\\\">OPML</a>
        (Outline Processor Markup Language) file with all blogs on the <em>Rogue Scholar</em>
        waitlist. OPML is the standard for importing and exporting lists of blogs,
        e.g. when switching from one RSS reader to another. It is a natural fit for
        managing blogs in <em>Rogue Scholar</em>, and hopefully helps people sign
        up for interesting science blogs they want to read. If you are on the <em>Rogue
        Scholar </em>waitlist, please make sure your RSS Feed URL and Home Page URL
        are correct, and \u2013 if you haven't done so already \u2013 pick one (and
        only one) of the top-level categories from the <a href=\\\"https://www.oecd.org/science/inno/38235147.pdf\\\">OECD
        Fields of Science and Technology</a>:</p><ul><li>Natural Sciences</li><li>Engineering
        and Technology</li><li>Medical and Health Sciences</li><li>Agricultural Sciences</li><li>Social
        Sciences</li><li>Humanities</li></ul><p>The OPML file (and your RSS reader
        if you import that file) will group science blogs into these categories. Many
        blogs fall into more than one category, but that isn't supported by OPML.
        </p><h3 id=\\\"hosting-rogue-scholar-infrastructure\\\">Hosting Rogue Scholar
        infrastructure</h3><p>There are <a href=\\\"https://inveniordm.docs.cern.ch/install/\\\">several
        ways</a> to run InvenioRDM repository software, obviously depending on the
        resources available at the hosting organization, and the size and complexity
        of the repository. A small data repository for a university department has
        different needs than <a href=\\\"https://zenodo.org/\\\">Zenodo</a>, one of
        the most popular generalist repositories with almost three million records.
        The <em>Rogue Scholar</em> sits in the middle, a small to medium-sized repository,
        anticipating 2,000 to 20,000 blog posts twelve months after launch. InvenioRDM
        relies on <a href=\\\"https://www.docker.com/\\\">Docker</a> and Kubernetes
        for running production services. This makes sense for large instances such
        as Zenodo but adds unnecessary complexity to smaller instances such as the
        <em>Rogue Scholar</em>.</p><p>After a substantial amount of deliberation and
        discussion, I decided to use a different approach for the <em>Rogue Scholar</em>,
        and this might potentially be of interest to other organizations planning
        to use InvenioRDM:</p><ul><li>Using virtual machines instead of Docker containers</li><li>Automation
        of virtual machine building with <a href=\\\"https://www.packer.io/\\\">Packer</a>
        and <a href=\\\"https://www.ansible.com/\\\">Ansible</a></li><li>Hosting of
        virtual machines by cloud provider <a href=\\\"https://www.digitalocean.com/\\\">DigitalOcean</a>,
        fundamentally similar to hosting a Wordpress or Ghost blog</li><li>Making
        the automation generic to also work for other InvenioRDM instances, and other
        infrastructure providers, e.g. <a href=\\\"https://www.openstack.org/\\\">Openstack</a></li></ul><p>This
        will be the focus of my work in the next three months, and luckily I have
        learned a lot about infrastructure automation in my previous jobs at <a href=\\\"https://plos.org/\\\">PLOS</a>
        and <a href=\\\"https://datacite.org/\\\">DataCite</a>.</p><h3 id=\\\"support-for-crossref-doi-registration\\\">Support
        for Crossref DOI registration</h3><p>By default, InvenioRDM uses DataCite
        DOIs, but <em>Rogue Scholar</em> will use Crossref DOIs for blogs that don't
        already use DOIs. The Crossref pricing is much more favorable for startups
        such as Front Matter, and for annual DOI registration numbers that at least
        initially will be in the 100s or low 1000s. I spent a good part of January
        and February writing a Python scholarly metadata conversion library that I
        released two weeks ago (<a href=\\\"https://pypi.org/project/commonmeta-py/\\\">commonmeta-py</a>).
        Among other things, commonmeta-py can read and write Crossref metadata and
        can enable Crossref DOI registrations in InvenioRDM \u2013 which is written
        in Python (and Javascript for the frontend).</p><p>As always, reach out to
        me with questions and comments.</p>\",\"comment_id\":\"641ac02dd13414003d462433\",\"feature_image\":\"https://images.unsplash.com/photo-1611864581049-aca018410b97?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDQzfHxmZWVkfGVufDB8fHx8MTY3OTQ3NDc2NQ&ixlib=rb-4.0.3&q=80&w=2000\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2023-03-22T08:45:33.000+00:00\",\"updated_at\":\"2023-03-22T10:42:17.000+00:00\",\"published_at\":\"2023-03-22T10:42:17.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/wa7k5-v4t16\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":null,\"url\":\"https://blog.front-matter.io/posts/starting-the-rogue-scholar-opml-feed/\",\"excerpt\":\"While
        the launch of the Rogue Scholar blog archive is still a few months away (happening
        in the second quarter of this year), I want to give an update on the ongoing
        work.\\n\\nThe Rogue Scholar blog archive will improve science blogs in important
        ways,\\nincluding full-text search, DOIs and metadata, and long-term archiving.
        The central piece of the underlying infrastructure is the InvenioRDM open
        source repository software. Front Matter is one of the organizations helping
        with InvenioRDM development\",\"reading_time\":3,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":\"Photo
        by <a href=\\\"https://unsplash.com/@sigmund?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Sigmund</a>
        / <a href=\\\"https://unsplash.com/?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Unsplash</a>\"},{\"id\":\"641868a78e8933003d843beb\",\"uuid\":\"16e87351-cba7-4790-ba34-4daaa6597a8a\",\"title\":\"Announcing
        commonmeta-ruby\",\"slug\":\"announcing-commonmeta-ruby\",\"html\":\"<p>Following
        recent announcements of the <a href=\\\"https://commonmeta.org\\\">commonmeta</a>
        standard for scholarly metadata and a Python package that converts several
        metadata formats (<a href=\\\"https://github.com/front-matter/commonmeta-py\\\">commonmeta-py</a>),
        today I am happy to announce <a href=\\\"https://github.com/front-matter/commonmeta-ruby\\\">commonmeta-ruby</a>,
        a Ruby gem and command-line tool to convert scholarly metadata using commonmeta
        as the internal format. commonmeta-ruby is based on the <a href=\\\"https://github.com/datacite/bolognese\\\">bolognese
        Ruby library</a> that I started a few ago while working at DataCite, but is
        a major rewrite that uses commonmeta as its intermediary conversion format.</p><p>Originally
        planned for later this year, I decided to speed up the release as Ruby version
        2.x (currently 2.7.7) reaches its <a href=\\\"https://endoflife.date/ruby\\\">end
        of life</a> this month, and <a href=\\\"https://rubygems.org/gems/briard\\\">briard</a>
        (the fork I wrote to support additional metadata conversions such as <a href=\\\"https://citation-file-format.github.io/\\\">Citation
        File Format</a> and Crossref DOI registrations) didn't fully work with Ruby
        3.x. In addition to supporting Ruby 3.x and validating with the <a href=\\\"https://commonmeta.org/schema\\\">commonmeta
        JSON Schema</a>, commonmeta-ruby dropped support for DataCite XML. The DataCite
        REST API has always been a JSON API, and DOI registration using DataCite XML
        for many years has used JSON under the hood. Metadata conversion using XML
        is painful, and focussing on JSON metadata simplifies further development.</p><p>The
        next steps for commonmeta are:</p><ul><li>Refine the commonmeta-py and commonmeta-ruby
        libraries by adding tests and real-world implementations (such as the DOI
        registration for this blog post, which was done using commonmeta-ruby)</li><li>Work
        towards a commonmeta v1.0 JSON Schema</li><li>Add support for bibliographies
        (lists of resources) to commonmeta.</li><li>Commonmeta implementations in
        additional languages, in particular Javascript/Typescript.</li></ul>\",\"comment_id\":\"641868a78e8933003d843beb\",\"feature_image\":\"https://images.unsplash.com/photo-1676284572206-2501ff5c6956?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDUwfHxiaWtlJTIwbSVDMyVCQ25zdGVyfGVufDB8fHx8MTY3OTMyMTU4MA&ixlib=rb-4.0.3&q=80&w=2000\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2023-03-20T14:07:35.000+00:00\",\"updated_at\":\"2023-03-22T12:32:52.000+00:00\",\"published_at\":\"2023-03-20T14:54:00.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/fawv321-14359c4\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"},\"url\":\"https://blog.front-matter.io/posts/announcing-commonmeta-ruby/\",\"excerpt\":\"Following
        recent announcements of the commonmeta standard for scholarly metadata and
        a Python package that converts several metadata formats (commonmeta-py), today
        I am happy to announce commonmeta-ruby, a Ruby gem and command-line tool to
        convert scholarly metadata using commonmeta as the internal format. commonmeta-ruby
        is based on the bolognese Ruby library that I started a few ago while working
        at DataCite, but is a major rewrite that uses commonmeta as its intermediary
        conversion format.\\n\\nO\",\"reading_time\":1,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":\"Photo
        by <a href=\\\"https://unsplash.com/@twind71?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Thorsten
        Wind</a> / <a href=\\\"https://unsplash.com/?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Unsplash</a>\"},{\"id\":\"640a101fbb01d4003d11fc58\",\"uuid\":\"4674567e-2366-4f00-8734-b391cc35dc1a\",\"title\":\"Announcing
        Commonmeta\",\"slug\":\"announcing-commonmeta\",\"html\":\"<p>This week I
        launched <strong>Commonmeta</strong>, a new scholarly metadata standard described
        at <a href=\\\"https://commonmeta.org/\\\">https://commonmeta.org</a>. Commonmeta
        is the result of working on conversion tools for scholarly metadata for many
        years. One conclusion early on was that these conversions are many-to-many,
        so it becomes much easier to have an internal format that is the intermediate
        step for these conversions.</p><p>Commonmeta is inspired by two initiatives:
        <a href=\\\"https://codemeta.github.io/\\\">Codemeta</a> and <a href=\\\"https://commonmark.org\\\">Commonmark</a>.
        CodeMeta contributors are creating a minimal metadata schema for science software
        and code, in JSON and XML. The goal of CodeMeta is to create a concept vocabulary
        that can be used to standardize the exchange of software metadata across repositories
        and organizations. Commonmark is a strongly defined, highly compatible specification
        of Markdown, along with a suite of comprehensive tests to validate Markdown
        implementations against this specification. </p><p>These two specifications
        not only inspired the name but also the principles of how I want to see Commonmeta
        operate:</p><ul><li>driven by real-world implementations and not committees</li><li>features
        that focus on what is common in existing implementations/formats</li><li>a
        testable specification</li></ul><p>The website goes into a little bit more
        detail about why I didn't pick any the existing standards but instead came
        up with a new metadata standard. This is a familiar pattern made famous by
        the XKCD comic shown above.</p><p>As I want this to be driven by real-world
        implementations and not committees, I also in the last few weeks launched<a
        href=\\\"https://github.com/front-matter/commonmeta-py\\\"> commonmeta-py</a>,
        a Python implementation of the standard available on <a href=\\\"https://pypi.org/project/commonmeta-py/\\\">PyPi</a>.
        And in a few months, I hope to have tweaked the <a href=\\\"https://github.com/front-matter/briard\\\">Ruby
        Gem</a> that I originally wrote a few years ago to support Commonmeta as the
        internal format.</p><p>With testable specification, I mean both a JSON Schema
        to describe Commonmeta and many, many tests that validate the conversions
        with real-world data. The JSON Schema is available <a href=\\\"https://commonmeta.org/schema\\\">here</a>,
        and will become stable once it reaches version 1.0. commonmeta-py comes with
        lots of tests, but I hope to further improve the test coverage.</p><p>Please
        reach out to me if you want to help with Commonmeta, in particular, work on
        implementations in other languages, such as Javascript, PHP, or Java.</p>\",\"comment_id\":\"640a101fbb01d4003d11fc58\",\"feature_image\":\"https://blog.front-matter.io/content/images/2023/03/standards_2x.png\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2023-03-09T16:58:07.000+00:00\",\"updated_at\":\"2023-03-09T17:36:44.000+00:00\",\"published_at\":\"2023-03-09T17:36:44.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/cp7apdj-jk5f471\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"},\"url\":\"https://blog.front-matter.io/posts/announcing-commonmeta/\",\"excerpt\":\"This
        week I launched Commonmeta, a new scholarly metadata standard described at
        https://commonmeta.org. Commonmeta is the result of working on conversion
        tools for scholarly metadata for many years. One conclusion early on was that
        these conversions are many-to-many, so it becomes much easier to have an internal
        format that is the intermediate step for these conversions.\\n\\nCommonmeta
        is inspired by two initiatives: Codemeta and Commonmark. CodeMeta contributors
        are creating a minimal metadata sch\",\"reading_time\":2,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":\"How
        standards proliferate\",\"feature_image_caption\":\"<a href=\\\"https://xkcd.com/927/\\\">Image
        via XKCD</a>\"},{\"id\":\"63ea6985b3d553003d317d11\",\"uuid\":\"0e70924c-989b-4234-bc9f-d0e30ed28fbf\",\"title\":\"Talking
        about Talbot\",\"slug\":\"talking-about-talbot\",\"html\":\"<p><a href=\\\"https://github.com/front-matter/talbot\\\">Talbot</a>
        is a Python package I started working on at the end of 2022 and plan to release
        to the Python Package Index (<a href=\\\"https://pypi.org/\\\">PyPi</a>) in
        March. Talbot converts scholarly metadata in various formats, including Crossref,
        DataCite, Schema.org, BibTeX, RIS, and formatted citations \u2013 the complete
        list of supported formats is <a href=\\\"https://docs.front-matter.io/talbot#supported-metadata-formats\\\">here</a>.
        Talbot is a Python version of the <a href=\\\"https://github.com/datacite/bolognese\\\">Bolognese
        Ruby gem</a> that I worked on with my DataCite colleagues starting in 2018.
        After leaving DataCite in 2021 I <a href=\\\"https://doi.org/10.53731/rdv0jyq-vpb7a9j-zwqzg\\\">wrote
        a fork called Briard</a> that added important metadata conversions, namely
        writing Crossref XML for DOI registration and reading/writing Citation File
        Format (<a href=\\\"https://citation-file-format.github.io/\\\">CFF</a>) for
        software metadata.</p><p>Talbot, Bolognese, and Briard are all names for dog
        breeds, the naming convention I have used for most of the Open Source software
        I have written since releasing the Open Source software <a href=\\\"https://github.com/lagotto/lagotto\\\">Lagotto</a>
        for tracking article-level metrics in 2012.</p><p>My two main use cases for
        Talbot (and Bolognese) are <a href=\\\"https://citation.crosscite.org/docs.html\\\">DOI
        content negotiation</a>, using DOI metadata to generate metadata in other
        formats such as BibTeX or as formatted citation in one of the thousands of
        available citation styles. The Python version will enhance the <a href=\\\"https://inveniordm.docs.cern.ch/\\\">InvenioRDM</a>
        Open Source repository platform, e.g. adding RIS and Schema.org JSON-LD to
        the supported export formats. The other main use case is supporting DOI registration
        via multiple input formats. Since 2021 the Briard gem for example allows me
        to register DOIs for this blog as well as the <a href=\\\"https://upstream.force11.org/\\\">Force11
        Upstream blog</a> using metadata in Schema.org format. With Talbot I want
        to enable Crossref DOI registration in the InvenioRDM platform for use cases
        where this makes sense, e.g blog posts or preprints. Talbot will help register
        DOIs from RSS feeds as part of <a href=\\\"https://rogue-scholar.org/\\\">the
        Rogue Scholar </a>blog archive I am launching in Q2 2023. </p><p>One lesson
        learned with Bolognese/Briard is that the platform/language matters. The InvenioRDM
        backend is written in Python (the Frontend is in Javascript/React). And while
        Bolognese/Briard can be used via the command line or in environments such
        as GitHub Actions that use Docker-based microservices where the language doesn't
        really matter, having the scholarly metadata conversion available in a Python
        environment makes a huge difference. So I took the plunge of rewriting a fairly
        complex library in another language. I am fully aware that there are more
        languages used for writing scholarly infrastructure code, but for the next
        few years, Python addresses my needs and is hopefully useful to other infrastructure
        projects.</p><p>While the overall architecture for the evolving Talbot library
        looks rather similar to Briard, I am making some changes based on my experience
        over the last five years of working on generic scholarly metadata conversions:</p><ul><li><strong>JSON
        is the core serialization format</strong>. Metadata in XML format (e.g. DataCite,
        Crossref, JATS) are important, but no longer used internally for Talbot validation.
        I will instead migrate to JSON schema for metadata validations in Talbot.
        DataCite, Crossref, and InvenioRDM use Elasticsearch/OpenSearch and thus JSON
        to index metadata. DataCite XML is still widely used but deprecated for several
        years, as on submission the XML is converted to JSON internally.</li><li><strong>Type
        hints. </strong>Support for static typing is a trend in dynamic languages
        Javascript (where Typescript is very popular), Ruby (since Ruby 3.0), and
        also Python. Talbot uses type hints for linting and that helps with error
        checking.</li><li><strong>Support unstructured references</strong>. Before
        DataCite Metadata Schema 4.4 (released in April 2021), only references providing
        an identifier such as a DOI were supported. Crossref has always supported
        unstructured references, and an identifier isn't available unless content
        exists in digital form. In the first Talbot release, I take the \\\"fallback
        solution\\\" approach, providing unstructured metadata if a DOI or other persistent
        identifier for a reference doesn't exist.</li><li><strong>Author names are
        hard</strong>. One of the biggest challenges with scholarly metadata is author
        names. In formatted citations and BibTeX separate given and family names are
        important, and a single name field for both given and family names is a constant
        source of errors and frustrations. In Talbot I follow both Crossref and Citeproc
        JSON metadata in that you need either a single name or separate given and
        family names.</li><li><strong>Dates are hard</strong>. Dates are surprisingly
        hard in scholarly metadata. There are multiple kinds of dates not always used
        consistently, and incomplete dates such as year-only are very common. One
        approach to dealing with incomplete dates is encoding the parts year, month,
        and day separately, used by Citeproc JSON and Crossref in their REST API.
        The better solution is to use the ISO8601 standard that supports incomplete
        dates. Other challenges are approximate dates (e.g. <em>circa 1650</em>) and
        date ranges. These kinds of dates are supported via the Extended Date and
        Time Format (<a href=\\\"https://www.loc.gov/standards/datetime/\\\">EDTF</a>),
        but working with EDTF is hard in code.</li><li><strong>Idiosyncrasies and
        inconsistencies</strong>. There is always a balancing act between supporting
        a metadata standard thoughtfully and not getting lost in edge cases. DataCite
        metadata (via Dublin Core on which it is based) makes it hard to work with
        some of the bibliographic metadata common for books, articles, and other textual
        resources. For example page numbers or the journal name. Crossref metadata
        has the tendency to treat things differently depending on the content type,
        e.g. the ISSN. After working on Bolognese for five ideas I will make some
        changes to how to best support metadata across different formats. It is clear
        that there is no single overarching scholarly metadata format, the internal
        format used by Bolognese, Briard, and now Talbot is a pragmatic mix of the
        different implementations.</li></ul>\",\"comment_id\":\"63ea6985b3d553003d317d11\",\"feature_image\":\"https://blog.front-matter.io/content/images/2023/02/TalbotHound_Talbot_Shrewsbury_Book_1445.png\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2023-02-13T16:47:01.000+00:00\",\"updated_at\":\"2023-02-13T19:20:04.000+00:00\",\"published_at\":\"2023-02-13T19:19:08.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/br4gac1-1k9ptea\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42bbc41e317003df48d4e\",\"name\":\"Feature\",\"slug\":\"feature\",\"description\":\"Features
        explore issues raised by news stories in more depth.\",\"feature_image\":\"https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fHJlc2VhcmNofGVufDB8fHx8MTYxODEyMzQxNQ&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/feature/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42bbc41e317003df48d4e\",\"name\":\"Feature\",\"slug\":\"feature\",\"description\":\"Features
        explore issues raised by news stories in more depth.\",\"feature_image\":\"https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fHJlc2VhcmNofGVufDB8fHx8MTYxODEyMzQxNQ&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/feature/\"},\"url\":\"https://blog.front-matter.io/posts/talking-about-talbot/\",\"excerpt\":\"Talbot
        is a Python package I started working on at the end of 2022 and plan to release
        to the Python Package Index (PyPi) in March. Talbot converts scholarly metadata
        in various formats, including Crossref, DataCite, Schema.org, BibTeX, RIS,
        and formatted citations \u2013 the complete list of supported formats is here.
        Talbot is a Python version of the Bolognese Ruby gem that I worked on with
        my DataCite colleagues starting in 2018. After leaving DataCite in 2021 I
        wrote a fork called Briard that add\",\"reading_time\":4,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":\"A
        talbot hound\",\"feature_image_caption\":\"<a href=\\\"https://commons.wikimedia.org/wiki/File:TalbotHound_Talbot_Shrewsbury_Book_1445.png\\\">via
        Wikimedia Commons</a>\"},{\"id\":\"63e0dd6e35c7ab003d9cda81\",\"uuid\":\"73d26ac0-e897-4194-a363-b7754a52582c\",\"title\":\"Guidelines
        for Scholarly Blogs\",\"slug\":\"guidelines-for-scholarly-blogs\",\"html\":\"<p>These
        guidelines are recommendations for authors of scholarly blogs to help with
        long-term archiving, discoverability, and citation of blog content.<br>They
        are modeled after the publication <a href=\\\"https://doi.org/10.1038/s41597-019-0031-8\\\">A
        Data Citation Roadmap for Scholarly Data Repositories</a>, where many of the
        same guidelines apply, and where I was the first author and <a href=\\\"https://force11.org/group/data-citation-implementation-group/\\\">co-chair
        of the corresponding Force11 working group.</a></p><p>These guidelines focus
        on the required or recommended work for scholarly blog authors. For scholarly
        blog archives such as the <a href=\\\"https://rogue-scholar.org\\\">Rogue
        Scholar</a>, additional guidelines are in development.</p><!--kg-card-begin:
        html--><table>\\n<thead>\\n<tr>\\n<th>Level</th>\\n<th style=\\\"text-align:
        right\\\">#</th>\\n<th>Guideline</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td>Required</td>\\n<td
        style=\\\"text-align: right\\\">1</td>\\n<td>The full-text content <em>must</em>
        be made available via public RSS feed (in RSS, Atom or JSON Feed format).</td>\\n</tr>\\n<tr>\\n<td>Required</td>\\n<td
        style=\\\"text-align: right\\\">2</td>\\n<td>Each blog post in the RSS feed
        <em>must</em> have a title, author(s), and publication date.</td>\\n</tr>\\n<tr>\\n<td>Required</td>\\n<td
        style=\\\"text-align: right\\\">3</td>\\n<td>Each blog post <em>must</em>
        have a URL that resolves to a public landing page specific for that blog post.</td>\\n</tr>\\n<tr>\\n<td>Required</td>\\n<td
        style=\\\"text-align: right\\\">4</td>\\n<td>The full-text content <em>must</em>
        be made available via a Creative Commons Attribution (CC-BY) license.</td>\\n</tr>\\n<tr>\\n<td>Required</td>\\n<td
        style=\\\"text-align: right\\\">5</td>\\n<td>The blog must provide documentation
        about long-term archiving, discoverability, and citation.</td>\\n</tr>\\n<tr>\\n<td>Recommended</td>\\n<td
        style=\\\"text-align: right\\\">6</td>\\n<td>Each blog post in the RSS feed
        <em>should</em> have a persistent identifier, description, language, and last
        updated date.</td>\\n</tr>\\n<tr>\\n<td>Recommended</td>\\n<td style=\\\"text-align:
        right\\\">7</td>\\n<td>The landing page <em>should</em> include metadata required
        for citation, and ideally also metadata facilitating discovery, in human-readable
        and machine-readable format.</td>\\n</tr>\\n<tr>\\n<td>Recommended</td>\\n<td
        style=\\\"text-align: right\\\">8</td>\\n<td>The machine-readable metadata
        <em>should</em> use schema.org markup in JSON-LD format.</td>\\n</tr>\\n<tr>\\n<td>Recommended</td>\\n<td
        style=\\\"text-align: right\\\">9</td>\\n<td>Metadata <em>should</em> be made
        available via HTML meta tags to facilitate use by reference managers.</td>\\n</tr>\\n<tr>\\n<td>Recommended</td>\\n<td
        style=\\\"text-align: right\\\">10</td>\\n<td>Metadata <em>should</em> be
        made available for download in BibTeX and/or another standard bibliographic
        format.</td>\\n</tr>\\n</tbody>\\n</table><!--kg-card-end: html--><p>The requirement
        for full-text content via RSS feed and with a CC-BY license comes from the
        need to make archiving and indexing as simple (and cheap) as possible. Dealing
        with multiple licenses, private feeds, and private content adds an extra level
        of complexity and is not supportive of Open Science.</p><p>Metadata via HTML
        meta tags and JSON-LD (using schema.org markup) are two main strategies to
        embed metadata in web pages, to support reference managers but also indexers.
        Schema.org is simpler to work with, e.g. for more complex author information
        such as separate given and family names, author identifiers such as ORCID,
        and affiliation information. On the other hand, reference managers and Google
        Scholar currently use HTML meta tags, and it is sometimes easier to add this
        information to a blog.</p><p>Registration of DOIs as other persistent identifiers
        for blog posts is something that I want to provide via the Rogue Scholar archive,
        as the effort required is not trivial. The information required (mainly title,
        author(s), publication date, and URL) is readily available via the RSS feed.
        Of course, displaying these DOIs on the blog is recommended, and for the DOIs
        to resolve to the blog itself rather than the blog archive at the Rogue Scholar
        or elsewhere.</p><p>The recommended or optional metadata for science blog
        posts is of course a big topic that needs more discussion. Description, language,
        and last updated date seem desired and readily available. References used
        in blog posts would be fantastic to be included in the metadata, but there
        is currently no easy and standard way of doing this. For better discoverability,
        it would make sense to provide geo coordinates and/or temporal information,
        and all blogs would benefit from using subject classification such as the
        <a href=\\\"https://www.oecd.org/science/inno/38235147.pdf\\\">OECD Fields
        of Science and Technology</a>, but all this would require significantly more
        effort.</p><p>These guidelines are a work in progress and are made available
        as part of the <a href=\\\"https://docs.rogue-scholar.org/guidelines\\\">Rogue
        Scholar Documentation</a>. Feedback is greatly appreciated.</p>\",\"comment_id\":\"63e0dd6e35c7ab003d9cda81\",\"feature_image\":\"https://images.unsplash.com/photo-1584631277142-0ca0cfc76aec?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDZ8fGd1aWRlbGluZXxlbnwwfHx8fDE2NzU2ODM0NDc&ixlib=rb-4.0.3&q=80&w=2000\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2023-02-06T10:58:54.000+00:00\",\"updated_at\":\"2023-02-06T11:52:24.000+00:00\",\"published_at\":\"2023-02-06T11:52:24.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/a0d9m3n-n7r8h0m\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42bbc41e317003df48d4e\",\"name\":\"Feature\",\"slug\":\"feature\",\"description\":\"Features
        explore issues raised by news stories in more depth.\",\"feature_image\":\"https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fHJlc2VhcmNofGVufDB8fHx8MTYxODEyMzQxNQ&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/feature/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42bbc41e317003df48d4e\",\"name\":\"Feature\",\"slug\":\"feature\",\"description\":\"Features
        explore issues raised by news stories in more depth.\",\"feature_image\":\"https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fHJlc2VhcmNofGVufDB8fHx8MTYxODEyMzQxNQ&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/feature/\"},\"url\":\"https://blog.front-matter.io/posts/guidelines-for-scholarly-blogs/\",\"excerpt\":\"These
        guidelines are recommendations for authors of scholarly blogs to help with
        long-term archiving, discoverability, and citation of blog content.\\nThey
        are modeled after the publication A Data Citation Roadmap for Scholarly Data
        Repositories, where many of the same guidelines apply, and where I was the
        first author and co-chair of the corresponding Force11 working group.\\n\\nThese
        guidelines focus on the required or recommended work for scholarly blog authors.
        For scholarly blog archives such as \",\"reading_time\":2,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":\"Photo
        by <a href=\\\"https://unsplash.com/@ivalex?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Ivan
        Aleksic</a> / <a href=\\\"https://unsplash.com/?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Unsplash</a>\"},{\"id\":\"63d6ac0fc7c39e003cd2dfd5\",\"uuid\":\"732b0f8c-d035-4de7-8c5e-1899ea1fa4bd\",\"title\":\"Launching
        the Front Matter Gazette\",\"slug\":\"launching-the-front-matter-gazette\",\"html\":\"<p>On
        Wednesday this week I am launching the <em>Front Matter Gazette</em>, a weekly
        newsletter that highlights exciting science stories from around the web. The
        linked content highlighted in the newsletter is published elsewhere and is
        free to read whenever possible. The newsletter requires a paid subscription
        (<a href=\\\"https://blog.front-matter.io/#/portal/signup\\\">available here</a>),
        5 \u20AC/month or 50 \u20AC/year with a thirty-day free trial and free subscriptions
        on request. The subscription fees help pay for the curation effort \u2013
        finding and summarizing the most exciting science stories. </p><h3 id=\\\"why-do-we-need-to-highlight-the-most-interesting-science\\\">Why
        do we need to highlight the most interesting science?</h3><p>With the <em>Front
        Matter Gazette,</em> I try a new approach to addressing an old problem: information
        overload.</p><figure class=\\\"kg-card kg-embed-card kg-card-hascaption\\\"><iframe
        width=\\\"200\\\" height=\\\"150\\\" src=\\\"https://www.youtube.com/embed/LabqeJEOQyI?feature=oembed\\\"
        frameborder=\\\"0\\\" allow=\\\"accelerometer; autoplay; clipboard-write;
        encrypted-media; gyroscope; picture-in-picture; web-share\\\" allowfullscreen
        title=\\\"Web 2.0 Expo NY: Clay Shirky (shirky.com) It&#39;s Not Information
        Overload. It&#39;s Filter Failure.\\\"></iframe><figcaption>Web 2.0 Expo NY:
        Clay Shirky (shirky.com) It's Not Information Overload. It's Filter Failure.</figcaption></figure><p>The
        approach traditionally often used in science has been to use journals as a
        filter. There are many reasons why this approach has failed, described for
        example in <a href=\\\"https://asapbio.org/addressing-information-overload-in-scholarly-literature\\\">this
        2021 post on the ASAPbio blog</a> by Christine Ferguson and me. Three important
        limitations are:</p><ul><li><strong>Delays</strong>. The time from submission
        to publication for peer-reviewed journal articles can be significant, which
        causes critical issues in situations that need quick actions based on science
        such as in the COVID pandemic, but also for early career researchers.</li><li><strong>Focus
        on the journal article</strong>. Journal articles are the main channel of
        scientific communication in many disciplines, but large parts of scholarship
        focus on something else, for example, conference proceedings in computer science
        or books in the humanities. In addition, newer outputs of scholarship such
        as research data or software source code are left out or only captured <em>by
        proxy</em>, publishing journals with articles describing software or data.</li><li><strong>Not
        Open Science</strong>. Leaving the decision to what is important in science
        to journal publishers, often commercial, instead of the scientists themselves,
        is the wrong choice as other interests interfere, and marginalized communities
        and regions are left out not only of science publishing but also of what science
        is highlighted and promoted.</li></ul><p>Two alternative approaches to journals
        as a filter are <strong>automation</strong> and <strong>curation</strong>.
        In the ASAPbio blog post mentioned earlier, Christine and I discussed an automation
        approach we tried out in 2021, filtering relevant biomedical preprints by
        the attention they received on Twitter immediately after publication. We have
        not continued this activity beyond early 2022 for two reasons: a) I spent
        the first <a href=\\\"https://doi.org/10.53731/bkkzj8g-gd14mb6\\\">five months
        of 2022 in the hospital</a>, and b) in November 2022 I left Twitter and moved
        to <a href=\\\"https://hachyderm.io/@mfenner\\\">Mastodon</a> after the change
        in Twitter ownership.</p><p>There are many initiatives in this space that
        try to use computer algorithms to find the most relevant scholarly content,
        but Christine and I felt that this was only the first step and that <strong>curation</strong>
        was key to finding what is interesting and relevant. Curation is what journal
        editors have always done, and what is helped with peer review since it became
        increasingly required in the 1960s, but when curation is used to find what
        is interesting and relevant, and not what should be published, there is no
        longer a need to leave the curation exclusively up to journals.</p><p>An Open
        Science approach to curation has many elements, but a newsletter feels like
        a good fit. It is a low-tech approach that works even for the busiest scientists,
        and it can be combined with the automation approaches discussed earlier. And
        curated newsletters about Science and Scholarship work with preprints, research
        data, source code, and other forms of scholarship. A related activity, no
        longer so low-tech, is science podcasts, which arguably are currently more
        popular than science newsletters.</p><h3 id=\\\"and-who-is-going-to-pay-for-this\\\">And
        who is going to pay for this?</h3><p>There are two elephants in the room for
        paying for this activity: advertising and grant funding. Advertising is not
        only a frustrating experience for readers and authors, but also doesn't really
        work in a niche market such as science. The current issues at the German <a
        href=\\\"https://scienceblogs.de/\\\">scienceblogs.de</a> are only the latest
        example of the difficulties sustaining science blogging infrastructure.</p><p>Grant
        funding is a well-established strategy to pay for Open Science activities,
        but has two major limitations: a) it is not a good fit for the long tail of
        science (Front Matter for example is not (yet) a non-profit organization because
        the time and money required to start a non-profit in Germany are far from
        trivial), and b) grant funding likes to pay for innovation and research, getting
        funding for open scholarly infrastructure is much harder.</p><p>Of course
        Front Matter is open for startup funding for the <em>Front Matter Gazette</em>,
        but it should not be a requirement to get the <em>Gazette</em> started, and
        I can not promise any financial returns for an investment.</p><p>Paying even
        a small fee of 5 \u20AC per month for a useful Open Science resource can be
        a hurdle, as <a href=\\\"https://blog.impactstory.org/subscription-announcement\\\">Impactstory
        can attest</a>. That is why we offer a no-questions-asked fee waiver, and
        why we start the Gazette as an experiment where we don't know the outcome
        yet.</p><h3 id=\\\"will-the-front-matter-gazette-work\\\">Will the Front Matter
        Gazette work?</h3><p>Only time will tell whether the Gazette can attract enough
        readers to become a sustainable operation, and I will work on the Gazette
        until 2024 to make that call. The <a href=\\\"https;//ghost.org\\\">Ghost
        publishing platform</a> powering this blog since 2021 is for people who believe
        in this vision (mostly in domains other than science):</p><blockquote>Ghost
        is a powerful app for new-media creators to publish, share, and grow a business
        around their content. It comes with modern tools to build a website, publish
        content, send newsletters &amp; offer paid subscriptions to members. \u2013
        <a href=\\\"https://ghost.org/\\\">Ghost Homepage</a></blockquote><p>Future
        plans for the <em>Front Matter Gazette</em> in case of a successful start
        focus on expanding the coverage \u2013 five stories a week is not even the
        tip of the iceberg of what's happening every week in scholarship.</p><h3 id=\\\"what-is-the-relationship-to-the-rogue-scholar\\\">What
        is the relationship to the Rogue Scholar?</h3><p><a href=\\\"https://rogue-scholar.org/\\\">The
        Rogue Scholar</a> is a science blog archive that I am working on and plan
        to launch in Q2 2023. Making sure that science blogs can be found over time
        with the help of full-text search, DOIs plus metadata, and long-term archiving
        is the first critical step. Using this open content in creative ways is the
        next step, and curation is one important aspect that I try to start addressing
        with the <em>Front Matter Gazette</em>. The <em>Front Matter Gazette</em>
        will highlight all kinds of scholarly content, not just blogs, and not only
        content archived in the Rogue Scholar, but there are of course synergies that
        I will try to explore.</p><h3 id=\\\"what-is-in-the-first-issue-of-the-front-matter-gazette\\\">What
        is in the first issue of the Front Matter Gazette?</h3><p>In the February
        1st issue I will talk about Neanderthal families, ChatGPT in science publishing,
        the Tidyverse, eradicating an infectious disease, and medieval manuscripts.</p>\",\"comment_id\":\"63d6ac0fc7c39e003cd2dfd5\",\"feature_image\":\"https://images.unsplash.com/photo-1521134976835-9963f2185519?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDE2fHxqb3VybmFsfGVufDB8fHx8MTY3NTAxMzMwNA&ixlib=rb-4.0.3&q=80&w=2000\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2023-01-29T17:25:35.000+00:00\",\"updated_at\":\"2023-01-30T12:48:26.000+00:00\",\"published_at\":\"2023-01-30T12:48:26.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/88drdpz-znvdjr9\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"},\"url\":\"https://blog.front-matter.io/posts/launching-the-front-matter-gazette/\",\"excerpt\":\"On
        Wednesday this week I am launching the Front Matter Gazette, a weekly newsletter
        that highlights exciting science stories from around the web. The linked content
        highlighted in the newsletter is published elsewhere and is free to read whenever
        possible. The newsletter requires a paid subscription (available here), 5
        \u20AC/month or 50 \u20AC/year with a thirty-day free trial and free subscriptions
        on request. The subscription fees help pay for the curation effort \u2013
        finding and summarizing the most exci\",\"reading_time\":4,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":\"Photo
        by <a href=\\\"https://unsplash.com/@daria_shevtsova?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Daria
        Shevtsova</a> / <a href=\\\"https://unsplash.com/?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Unsplash</a>\"},{\"id\":\"63c889b63b62db003dc5eb9c\",\"uuid\":\"e7655903-0b0a-4e87-8b21-1650d05d2da8\",\"title\":\"Do
        we need to fix science blogs?\",\"slug\":\"need-to-fix-science-blogs\",\"html\":\"<p>Science
        blogs have been around for at least 20 years and have become an important
        part of science communication. So are there any fundamental issues that need
        fixing?</p>\\n<h3 id=\\\"barriers-to-entry\\\">Barriers to Entry</h3>\\n<p>Blogging
        platforms are mature at this point, and the technology is not imposing barriers
        to entry for most people. The user experience has greatly improved over the
        last few years and there are a number of affordable ways for hosting a blog
        that also work for science blogs, including free options such as <a href=\\\"https://pages.github.com/\\\">GitHub
        Pages</a>.</p>\\n<h3 id=\\\"open-access\\\">Open Access</h3>\\n<p>Science
        blogs have traditionally been free to read, but there is a general trend towards
        subscriptions for blogs (and related newsletters), as the advertising business
        model isn't really working for niche content such as most science. How to
        sustain science blogging in the long run is an unresolved question, and charging
        authors (beyond a nominal hosting fee) doesn't look like a path forward. Luckily
        the costs of publishing science blogs are very reasonable compared to journal
        publishing or hosting research data and code.</p>\\n<h3 id=\\\"missing-functionality\\\">Missing
        Functionality</h3>\\n<p>The basic functionality of formatted text with embedded
        figures and links is supported by many blogging platforms. The requirements
        of data-intensive science, e.g. interactive visualizations, can be a challenge,
        but that is also true for publishing journal articles. Interactive environments
        such as <a href=\\\"https://jupyter.org/\\\">Jupyter Notebooks</a> might be
        a better fit for these use cases. </p>\\n<p>Reference management is probably
        the biggest gap in science blogging, as handling more than a few references
        in standard ways is not easily done by hand.</p>\\n<h3 id=\\\"impact-or-credit\\\">Impact
        or Credit</h3>\\n<p>Unfortunately a lot of the activities of scholars are
        driven by perceived <em>Impact </em>or<em> Credit</em>, and science blogs
        typically don't score high in this regard \u2013 with the exception of some
        disciplines such as mathematics. There is probably no short-term solution,
        and I am not even sure it is a problem that needs fixing. </p>\\n<p>The long-term
        solution should focus on increasing the visibility and thus discoverability
        of science blogs to reach a larger audience. As I discussed in a <a href=\\\"https://doi.org/10.53731/br9f5xa-a556w2t\\\">previous
        post</a>, my preferred approach is a central repository for science blog content
        originally published in many different locations (the PubMed/PubMed Central)
        model.</p>\\n<h3 id=\\\"persistence\\\">Persistence</h3>\\n<p>This leaves
        persistence as the other main problem with science blogs besides discoverability
        that needs fixing. Link rot (the resource identified by a URI vanishes from
        the web) and content drift (the resource identified by a URI changes over
        time) are <a href=\\\"https://ceur-ws.org/Vol-3246/10_Paper3.pdf\\\">well-known
        problems with digital content</a>, from <a href=\\\"https://www.theverge.com/2021/5/21/22447690/link-rot-research-new-york-times-domain-hijacking\\\">newspapers</a>
        to scholarly content. There are mainly two approaches to address this problem:</p>\\n<ul><li><strong>Archiving</strong>
        using generic services such as the <a href=\\\"https://archive.org/\\\">Internet
        Archive</a> and specialized services such as <a href=\\\"https://www.softwareheritage.org/\\\">Software
        Heritage</a> for software source code or <a href=\\\"https://www.portico.org/\\\">Portico</a>
        for scholarly content.</li><li><strong>Persistent Identifiers</strong> by
        maintaining links independent of URL host and path, both of which may change
        over time. This <a href=\\\"https://doi.org/10.53731/r294649-6f79289-8cw1h\\\">blog
        post of mine</a> is almost 14 years old, and the URL has changed at least
        four times as I changed blogging platforms. Since 2021 the post has had a
        persistent identifier in form of a DOI, and that DOI will not change going
        forward, eventually pointing to an archive when I retire.</li></ul>\\n<p>Some
        science blog content is ephemeral and may not be worth archiving, but a lot
        of content is still worth reading years later (the <a href=\\\"ttps://doi.org/10.53731/r294649-6f79289-8cw1q\\\">first
        post of this blog</a> is more than 15 years old), even if only to provide
        historical context.</p>\\n<h3 id=\\\"conclusions\\\">Conclusions</h3>\\n<p>In
        summary, we don't need to <em>fix everything</em> with science blogs but rather
        focus on two aspects: discoverability and persistence. In doing that we also
        need to sort out better sustainability for science blogs, and as an added
        bonus improve their reference management.</p>\\n<p>Discoverability and persistence
        are an issue for all science blogs, and we are trying to fix them by launching
        the <a href=\\\"https://rogue-scholar.org/\\\">Rogue Scholar</a> in the second
        quarter of 2023. If you are managing a science blog and care about discoverability
        and persistence, sign up for the <a href=\\\"https://rogue-scholar.org/\\\">Rogue
        Scholar waitlist</a>. Particularly if your blog is no longer actively maintained,
        for example, blogs hosted by grant-funded projects that have ended or are
        ending soon.</p>\\n<p>Today I launched the <a href=\\\"https://docs.rogue-scholar.org\\\">Rogue
        Scholar Documentation</a> site, where I will document how to use the Rogue
        Scholar, e.g. what you can do to prepare your science blog for Rogue Scholar
        archiving. The site is written in markdown and hosted on GitHub, so feel free
        to ask questions or suggest additions via the links provided by the documentation
        site.</p>\\n<h3 id=\\\"references\\\">References</h3>\\n<p>Fenner, M. (2009).
        <em>Interview with Geoffrey Bilder</em>. <a href=\\\"https://doi.org/10.53731/r294649-6f79289-8cw1h\\\">https://doi.org/10.53731/r294649-6f79289-8cw1h</a></p>\\n<p>Fenner,
        M. (2007). <em>Open access may become mandatory for NIH-funded research</em>.
        <a href=\\\"https://doi.org/10.53731/r294649-6f79289-8cw1q\\\">https://doi.org/10.53731/r294649-6f79289-8cw1q</a></p>\",\"comment_id\":\"63c889b63b62db003dc5eb9c\",\"feature_image\":\"https://images.unsplash.com/photo-1585838017777-5003198884b5?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDMyfHxicm9rZW58ZW58MHx8fHwxNjc0NjUyMTEy&ixlib=rb-4.0.3&q=80&w=2000\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2023-01-19T00:07:18.000+00:00\",\"updated_at\":\"2023-09-07T21:26:13.000+00:00\",\"published_at\":\"2023-01-25T15:14:17.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/avg2ykg-gdxppcd\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42bbc41e317003df48d4e\",\"name\":\"Feature\",\"slug\":\"feature\",\"description\":\"Features
        explore issues raised by news stories in more depth.\",\"feature_image\":\"https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fHJlc2VhcmNofGVufDB8fHx8MTYxODEyMzQxNQ&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/feature/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42bbc41e317003df48d4e\",\"name\":\"Feature\",\"slug\":\"feature\",\"description\":\"Features
        explore issues raised by news stories in more depth.\",\"feature_image\":\"https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fHJlc2VhcmNofGVufDB8fHx8MTYxODEyMzQxNQ&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/feature/\"},\"url\":\"https://blog.front-matter.io/posts/need-to-fix-science-blogs/\",\"excerpt\":\"Science
        blogs have been around for at least 20 years and have become an important
        part of science communication. So are there any fundamental issues that need
        fixing?\\n\\n\\n\\nBarriers to Entry\\n\\n\\nBlogging platforms are mature
        at this point, and the technology is not imposing barriers to entry for most
        people. The user experience has greatly improved over the last few years and
        there are a number of affordable ways for hosting a blog that also work for
        science blogs, including free options such as GitH\",\"reading_time\":3,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":\"Photo
        by <a href=\\\"https://unsplash.com/ja/@kevinandrephotography?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Kevin
        Andre</a> / <a href=\\\"https://unsplash.com/?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Unsplash</a>\"},{\"id\":\"63c5681e376c9e003d27ea20\",\"uuid\":\"8911a1a8-8085-4ac0-a889-c5af7b8bbe26\",\"title\":\"RSS,
        Atom, JSON Feed\",\"slug\":\"rss-atom-jsonfeed\",\"html\":\"<p>As I discussed
        in a <a href=\\\"https://doi.org/10.53731/eyf75cj-jsgv26c\\\">recent post</a>,
        RSS is an essential building block for the upcoming <a href=\\\"https://rogue-scholar.org\\\">Rogue
        Scholar</a> Scholarly Blog Archive. RSS makes it easy to import blog posts
        (both metadata and content) automatically and is supported by all blogging
        platforms. This kind of automation is critical to keep the costs of running
        the Rogue Scholar low, allowing it to scale to cover a substantial number
        of science blog posts, and hopefully becoming an important Open Science resource.</p><p>But
        there are also challenges with using RSS:</p><ul><li>RSS is not a single standard
        but comes in multiple flavors: multiple versions of RSS, Atom, and the newer
        <a href=\\\"https://www.jsonfeed.org/\\\">JSON Feed</a>. Most libraries for
        consuming RSS (e.g. the Python <a href=\\\"https://github.com/kurtmckee/feedparser\\\">feedparser</a>)
        can handle RSS and Atom, and fewer tools (e.g. the Python <a href=\\\"https://pypi.org/project/reader/\\\">feeder</a>)
        also support the newer JSON Feed.</li><li>The Rogue Scholar will use the <a
        href=\\\"https://inveniordm.docs.cern.ch/\\\">InvenioRDM</a> open source platform,
        which uses <a href=\\\"https://opensearch.org/\\\">OpenSearch</a> to index
        content and metadata. OpenSearch \u2013 just like Elasticsearch on which it
        is based \u2013 works with JSON. Indexing and archiving science blogs therefore
        should first convert RSS and Atom feeds onto JSON, and JSON Feed, <a href=\\\"https://www.jsonfeed.org/mappingrssandatom/\\\">which
        has been mapped from RSS and Atom</a>, is the obvious choice.</li><li>Some
        blogs prefer to only publish summaries in their RSS feeds, there have been
        many discussions on this topic over the years. It would complicate the operation
        of the Rogue Scholar if full-text content has to retrieved by other means,
        and archiving full-text content is the primary goal for the Rogue Scholar.
        The Rogue Scholar needs one feed that provides the full-text content, it doesn't
        have to be the default blog feed.</li><li>Blogs, in particular personal blogs,
        may publish content that is out of the scope of the main science topics of
        the blog. Occasional out-of-scope posts, e.g. talking about major events such
        as job changes, sickness, or travel, are probably ok, and add a personal note.
        If this is frequently the case, and this has come up twice in initial Rogue
        Scholar discussions, it probably makes sense to provide a filtered RSS feed
        (e.g. using tags) with only a subset of posts.</li><li>Describing a blog and
        associated metadata (e.g. name, feed URL, language, license, contact) is not
        something that easily maps how InvenioRDM is modeled. The obvious choice would
        be <a href=\\\"https://inveniordm.web.cern.ch/communities\\\">communities</a>,
        but they can also be seen as a higher level of aggregation, e.g. all blog
        posts about biodiversity independent of the blog source. For now I will work
        with communities and enhance the InvenioRDM functionality where it also makes
        sense for other InvenioRDM use cases, of course coordinating with the InvenioRDM
        community.</li></ul><p>Two weeks ago I opened up the <a href=\\\"https://jvinjjenjik.typeform.com/to/uxgAsHPl\\\">waitlist</a>
        for the Rogue Scholar, and I am happy with the feedback I have received so
        far: sixteen submissions and a number of encouraging discussions. Consider
        adding your science blog to the waitlist, or learn more at the <a href=\\\"https://rogue-scholar.org\\\">Rogue
        Scholar</a> website. If you have questions, post them in the comments or join
        the <a href=\\\"https://discord.gg/wZcqPt4p\\\">Discord channel </a>(renamed
        from Front Matter to Rogue Scholar).</p><p>It has not escaped our notice that
        the specific use of RSS we have postulated immediately suggests a possible
        mechanism for the archiving and DOI registration of other scholarly content.</p>\",\"comment_id\":\"63c5681e376c9e003d27ea20\",\"feature_image\":\"https://images.unsplash.com/photo-1597092451116-27787c07901d?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDJ8fGFyY2hpdmV8ZW58MHx8fHwxNjczODg2NDI2&ixlib=rb-4.0.3&q=80&w=2000\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2023-01-16T15:07:10.000+00:00\",\"updated_at\":\"2023-01-16T17:06:53.000+00:00\",\"published_at\":\"2023-01-16T16:57:54.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/d6vdvbt-tffmezj\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42bbc41e317003df48d4e\",\"name\":\"Feature\",\"slug\":\"feature\",\"description\":\"Features
        explore issues raised by news stories in more depth.\",\"feature_image\":\"https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fHJlc2VhcmNofGVufDB8fHx8MTYxODEyMzQxNQ&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/feature/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42bbc41e317003df48d4e\",\"name\":\"Feature\",\"slug\":\"feature\",\"description\":\"Features
        explore issues raised by news stories in more depth.\",\"feature_image\":\"https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fHJlc2VhcmNofGVufDB8fHx8MTYxODEyMzQxNQ&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/feature/\"},\"url\":\"https://blog.front-matter.io/posts/rss-atom-jsonfeed/\",\"excerpt\":\"As
        I discussed in a recent post, RSS is an essential building block for the upcoming
        Rogue Scholar Scholarly Blog Archive. RSS makes it easy to import blog posts
        (both metadata and content) automatically and is supported by all blogging
        platforms. This kind of automation is critical to keep the costs of running
        the Rogue Scholar low, allowing it to scale to cover a substantial number
        of science blog posts, and hopefully becoming an important Open Science resource.\\n\\nBut
        there are also challenges \",\"reading_time\":2,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":\"Photo
        by <a href=\\\"https://unsplash.com/@ubahnverleih?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">C
        M</a> / <a href=\\\"https://unsplash.com/?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Unsplash</a>\"},{\"id\":\"63b2b71bf43f9b003d605ab6\",\"uuid\":\"b289d8e0-74fb-472c-a3e7-a55453572dc9\",\"title\":\"Sign
        up for the science blog archive waitlist\",\"slug\":\"science-blog-archive-waitlist\",\"html\":\"<p>The
        science blog archive that I have started to work on (<a href=\\\"https://doi.org/10.53731/eyf75cj-jsgv26c\\\">see
        previous posts</a>) finally has a name: the <em>Rogue Scholar</em>. I picked
        this name because I liked the description in the <a href=\\\"https://www.urbandictionary.com/define.php?term=rogue%20scholar\\\">Urban
        Dictionary</a>.</p><blockquote>A person with extensive knowledge pertaining
        to various subject matters that extends beyond formal education. This person
        often <strong>gathers</strong> knowledge from various sources, such as media,
        friends, casual reading or the internet.</blockquote><p>And I started a waitlist
        for people interested in having their science blog archived in the <em>Rogue
        Scholar</em>. There is still a lot of work to do, but I hope to launch the
        archive in the second quarter of 2023 with these core features:</p><ul><li>based
        on the <a href=\\\"https://inveniordm.docs.cern.ch/\\\">InvenioRDM</a> open
        source software, hosted by Front Matter</li><li>free to archive 50 blog posts
        per year. For larger blogs or a backfile of several years, the Rogue Scholar
        will charge a one-time fee of 1 \u20AC per blog post, and I have started to
        work on securing additional funding for this.</li><li>Full-text search of
        blog content, typically not available on self-hosted blogs</li><li>DOI registration
        for blog posts, facilitating discovery and integration of blogs into the scholarly
        record</li><li>free to read and reuse forever, using the Creative Commons
        Attribution (<a href=\\\"https://creativecommons.org/licenses/by/4.0/\\\">CC-BY</a>)
        license</li><li>initially support English and German language posts</li></ul><p>The
        form to sign up for the waitlist is available <a href=\\\"https://jvinjjenjik.typeform.com/to/uxgAsHPl\\\">here</a>.</p>\",\"comment_id\":\"63b2b71bf43f9b003d605ab6\",\"feature_image\":\"https://images.unsplash.com/photo-1577046823799-58b2d217d508?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDZ8fGhhcHB5JTIwbmV3JTIweWVhcnxlbnwwfHx8fDE2NzI2NTY4MzQ&ixlib=rb-4.0.3&q=80&w=2000\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2023-01-02T10:51:07.000+00:00\",\"updated_at\":\"2023-01-02T11:31:52.000+00:00\",\"published_at\":\"2023-01-02T11:31:52.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/cbvm43q-qdk3s1s\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"},\"url\":\"https://blog.front-matter.io/posts/science-blog-archive-waitlist/\",\"excerpt\":\"The
        science blog archive that I have started to work on (see previous posts) finally
        has a name: the Rogue Scholar. I picked this name because I liked the description
        in the Urban Dictionary.\\n\\nA person with extensive knowledge pertaining
        to various subject matters that extends beyond formal education. This person
        often gathers knowledge from various sources, such as media, friends, casual
        reading or the internet.\\n\\nAnd I started a waitlist for people interested
        in having their science blog archiv\",\"reading_time\":1,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":\"Photo
        by <a href=\\\"https://unsplash.com/@kellysikkema?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Kelly
        Sikkema</a> / <a href=\\\"https://unsplash.com/?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Unsplash</a>\"},{\"id\":\"63a2ef18f43f9b003d605821\",\"uuid\":\"25287b84-b597-4edb-92c8-a2c61e0ebbc4\",\"title\":\"Building
        Blocks for a Scholarly Blog Archive\",\"slug\":\"building-blocks\",\"html\":\"<p>Another
        follow-up post, extending three earlier posts (see references), on the Scholarly
        Blog Archive that Front Matter is building and that I plan to launch in the
        first half of 2023. I have been thinking about the building blocks that make
        this blog archive work:</p><h3 id=\\\"diamond-open-access\\\">Diamond Open
        Access</h3><blockquote>Diamond open access (OA) is an open access business
        model in which no fees are charged to either authors or readers. <a href=\\\"https://www.dfg.de/en/research_funding/announcements_proposals/2022/info_wissenschaft_22_26/index.html\\\">German
        Research Foundation</a></blockquote><p>Using this term sounds strange in the
        context of scholarly blog posts, but it means that scholarly blog infrastructure
        should be free to publish and free to read. One challenge with Open Access
        for publications, particularly in disciplines such as medicine and life sciences
        where there is a lot of money, is that there are no drivers for driving down
        cost, and subscription fees have often been converted to article processing
        charges (APC). And instead of technological advances making scholarly publishing
        cheaper over time, the costs for authors and readers (and their institutions
        and funders who ultimately pay for this) are only increasing.</p><p>There
        is of course already a lot of Diamond Open Access, and infrastructures for
        research data and research software also typically don't charge authors or
        readers. This causes other problems in terms of sustainable scholarly infrastructure
        and innovation, but I think it is an essential building block for the science
        blog archive Front Matter is building. A lot of work is needed in 2023 to
        come up with a strategy for sustaining the Front Matter science blog archive
        in the long run, all I can say now is that it will not use advertising.</p><h3
        id=\\\"creative-commons-license\\\">Creative Commons License</h3><p>For content
        that is free to read we need a license that specifies that. The blog archive
        needs clear conditions for what it can do with the content, and the same is
        true for downstream users and services. History tells us that licenses should
        be clear and simple, so for scholarly blog posts I will aim to use the <a
        href=\\\"https://creativecommons.org/licenses/by/4.0/legalcode\\\">Creative
        Commons Attribution 4.0 License</a> (CC-BY 4.0) for all content. </p><figure
        class=\\\"kg-card kg-image-card\\\"><img src=\\\"https://blog.front-matter.io/content/images/2022/12/cc-by.png\\\"
        class=\\\"kg-image\\\" alt loading=\\\"lazy\\\" width=\\\"250\\\" height=\\\"88\\\"></figure><h3
        id=\\\"central-blog-archive\\\">Central Blog Archive</h3><p>As I <a href=\\\"https://doi.org/10.53731/br9f5xa-a556w2t\\\">explained
        in a post last week</a>, a central blog archive for blog content published
        in many different places makes the most sense for science blog posts \u2013
        a model also used by <a href=\\\"https://www.ncbi.nlm.nih.gov/pmc/\\\">PubMed
        Central </a>for a free full-text archive of biomedical and life sciences journal
        articles. The <a href=\\\"https://inveniordm.docs.cern.ch/\\\">InvenioRDM</a>
        Open Source software is a good fit for this use case.</p><figure class=\\\"kg-card
        kg-image-card\\\"><img src=\\\"https://blog.front-matter.io/content/images/2022/12/Download--4--1.png\\\"
        class=\\\"kg-image\\\" alt loading=\\\"lazy\\\" width=\\\"372\\\" height=\\\"120\\\"></figure><p>Starting
        a science blog is straightforward. There are plenty of cheap and free options
        available from <a href=\\\"https://wordpress.org/\\\">Wordpress</a> to <a
        href=\\\"https://pages.github.com/\\\">GitHub Pages</a>. You might run your
        blog as part of a larger platform, together with collaborators, or all for
        yourself.</p><h3 id=\\\"digital-object-identifier-doi-and-metadata\\\">Digital
        Object Identifier (DOI) and Metadata</h3><p>DOIs are frequently used as persistent
        identifiers for scholarly content and are integrated into the InvenioRDM platform.
        The blog archive can either archive blog posts with DOIs, or it can issue
        DOIs for existing blogs not using DOIs. In the latter case it is important
        that the DOI resolves to the original content in the hosting blog platform,
        and redirects to the blog platform only when the original blog is no longer
        available. </p><p>DOIs (e.g. from DataCite or Crossref) have a required set
        of metadata that makes sense for scholarly blogs. Optional metadata that are
        desired for the blog archive are license (see above), abstract, subject area
        (using the 43 <a href=\\\"https://en.wikipedia.org/wiki/Fields_of_Science_and_Technology\\\">OECD
        Fields of Science and Technology</a>), keywords, language, and persistent
        identifiers for the blog (<a href=\\\"https://www.issn.org/\\\">ISSN</a>),
        author (<a href=\\\"https://orcid.org/\\\">ORCID</a>) and affiliated institution
        (<a href=\\\"https://ror.org/\\\">ROR</a>).</p><h3 id=\\\"rich-site-summary-rss\\\">Rich
        Site Summary (RSS)</h3><p><a href=\\\"https://en.wikipedia.org/wiki/RSS\\\">RSS</a>
        is the standard protocol for distributing and consuming blog content. It is
        actually a group of protocols (Atom and multiple flavors of the RSS format),
        but they have been around for so long that the popular tools and services
        support the various protocols. RSS will be the standard way how content is
        ingested by the blog archive, and probably also how in turn content in the
        central blog archive is consumed, e.g. as an automated feed of all new science
        blog posts in a particular subject area and language.</p><figure class=\\\"kg-card
        kg-image-card\\\"><img src=\\\"https://blog.front-matter.io/content/images/2022/12/images--1-.png\\\"
        class=\\\"kg-image\\\" alt loading=\\\"lazy\\\" width=\\\"128\\\" height=\\\"128\\\"></figure><p>Because
        RSS is so widely supported, other ways of registering content \u2013 e.g.
        via web form, API, or webhook \u2013 are less critical for the blog archive.
        Work is needed on the InvenioRDM software to add strong support for RSS feeds,
        but would allow the automation of a lot of the work needed to build and maintain
        the blog archive.</p><h3 id=\\\"markdown-and-pdf\\\">Markdown and PDF</h3><p><a
        href=\\\"https://daringfireball.net/projects/markdown/\\\">Markdown</a> is
        a markup language popular with many blogging platforms. It is typically used
        for editing blog posts and other documents in online environments but is not
        really used for consuming blog content via RSS. Markdown has<a href=\\\"https://pandoc.org/\\\">
        been extended</a> to support features needed for scholarly documents, e.g.
        tables and references, but the uptake of this added functionality in science
        blogs has been slow. </p><p>PDF is commonly used for reading scholarly publications.
        The workflows for submitting manuscripts to journals and preprint archives
        in PDF format are broken because it is tricky to extract structured documents
        from PDFs. The blog archive will support PDF as an output format at some point
        but is not a high priority. Blog posts are typically consumed via blog reader
        or email (if the blog produces a newsletter) rather than as PDF printed out
        on paper. There is work needed on the InvenioRDM platform to display full-text
        content rendered as HTML.</p><h3 id=\\\"curation-and-community\\\">Curation
        and Community</h3><p>Science blog posts typically see a lightweight review
        workflow before publication, and often receive feedback in the form of comments
        and/or social media mentions. For the Front Matter science blog archive, I
        want to keep that approach and not build any hurdles for inclusion. Some level
        of curation is needed, not only to check for quackery and hate speech but
        also to improve metadata that help with discovery, and to find blogs that
        should be included. Ideally we can build a community around the science blog
        archive, taking advantage of the <a href=\\\"https://inveniordm.web.cern.ch/communities\\\">communities</a>
        (focussing on different languages and subject areas) feature recently added
        to the InvenioRDM software.</p><h3 id=\\\"flashback\\\">Flashback?</h3><p>If
        reading this post feels like it is 2006 \u2013 the year <a href=\\\"https://en.wikipedia.org/wiki/James_Brown\\\">James
        Brown</a> (used for the feature image of this post) died \u2013 again with
        talk about blogs, RSS, Markdown, Creative Commons, and related technologies
        (I for example didn't mention Zotero, XML, or Wordpress), you are right. This
        is intentional, these technologies are not as sexy as using artificial intelligence
        or cryptocurrencies to drive this, but I want the Science Blog archive to
        become a scholarly resource that is useful, open, and inclusive.</p><h3 id=\\\"references\\\">References</h3><p>Fenner,
        M. (2022, September 28). Starting Work on the Front Matter Archive. <em>Front
        Matter</em>. <a href=\\\"https://doi.org/10.53731/9z6rz5d-djbay0y\\\">https://doi.org/10.53731/9z6rz5d-djbay0y</a></p><p>Fenner,
        M. (2022, December 12). Building an archive for scholarly blog posts. <em>Front
        Matter</em>. <a href=\\\"https://doi.org/10.53731/br9f5xa-a556w2t\\\">https://doi.org/10.53731/br9f5xa-a556w2t</a></p><p>Fenner,
        M. (2022, December 19). Launching the Front Matter Roadmap. <em>Front Matter</em>.
        <a href=\\\"https://doi.org/10.53731/cbdtfp1-1798beh\\\">https://doi.org/10.53731/cbdtfp1-1798beh</a></p><p>Fenner,
        M. (2010, October 6). Beyond the PDF \u2013 it is time for a workshop. <em>Front
        Matter</em>. <a href=\\\"https://doi.org/10.53731/r294649-6f79289-8cw7z\\\">https://doi.org/10.53731/r294649-6f79289-8cw7z</a></p><p>Fenner,
        M. (2013, June 19). Citations in Scholarly Markdown. <em>Front Matter</em>.
        <a href=\\\"https://doi.org/10.53731/r294649-6f79289-8cw1b\\\">https://doi.org/10.53731/r294649-6f79289-8cw1b</a></p>\",\"comment_id\":\"63a2ef18f43f9b003d605821\",\"feature_image\":\"https://blog.front-matter.io/content/images/2022/12/James_Brown_-55208420--1.jpeg\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2022-12-21T11:33:44.000+00:00\",\"updated_at\":\"2022-12-21T20:57:38.000+00:00\",\"published_at\":\"2022-12-21T14:23:47.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/eyf75cj-jsgv26c\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42bbc41e317003df48d4e\",\"name\":\"Feature\",\"slug\":\"feature\",\"description\":\"Features
        explore issues raised by news stories in more depth.\",\"feature_image\":\"https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fHJlc2VhcmNofGVufDB8fHx8MTYxODEyMzQxNQ&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/feature/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42bbc41e317003df48d4e\",\"name\":\"Feature\",\"slug\":\"feature\",\"description\":\"Features
        explore issues raised by news stories in more depth.\",\"feature_image\":\"https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fHJlc2VhcmNofGVufDB8fHx8MTYxODEyMzQxNQ&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/feature/\"},\"url\":\"https://blog.front-matter.io/posts/building-blocks/\",\"excerpt\":\"Another
        follow-up post, extending three earlier posts (see references), on the Scholarly
        Blog Archive that Front Matter is building and that I plan to launch in the
        first half of 2023. I have been thinking about the building blocks that make
        this blog archive work:\\n\\n\\nDiamond Open Access\\n\\nDiamond open access
        (OA) is an open access business model in which no fees are charged to either
        authors or readers. German Research Foundation\\n\\nUsing this term sounds
        strange in the context of scholarly blog po\",\"reading_time\":5,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":\"James
        Brown\",\"feature_image_caption\":\"<strong>James Brown</strong>. Photo by
        Roger Woolman, <a href=\\\"https://creativecommons.org/licenses/by/3.0\\\">CC
        BY 3.0</a>, via Wikimedia Commons\"},{\"id\":\"63a065635b7024003dd39b91\",\"uuid\":\"91ae440f-dba5-430f-bc16-57728819ccb8\",\"title\":\"Launching
        the Front Matter Roadmap\",\"slug\":\"front-matter-roadmap\",\"html\":\"<p>In
        a <a href=\\\"https://doi.org/10.53731/br9f5xa-a556w2t\\\">blog post last
        week</a> I talked about what I am currently working on, namely a) helping
        to make it easier (and safer) to run the <a href=\\\"https://inveniordm.docs.cern.ch/\\\">InvenioRDM</a>
        digital repository software in Docker container infrastructure, and b) working
        on converting the bolognese metadata conversion Ruby gem <a href=\\\"https://github.com/front-matter/talbot\\\">to
        Python</a> to enhance InvenioRDM functionality. </p><p>To get updates on this
        work you can follow the <a href=\\\"https://github.com/front-matter\\\">Front
        Matter GitHub repositories</a> \u2013 the work I am doing at Front Matter
        is mostly happening in public code repositories. But maybe you are really
        only interested in basic information, e.g. what I am working on, when it is
        ready, and providing some high-level input. There are several ways one can
        provide this high-level information, but usually, that is too much information
        for a blog like this one, and too much technical detail in a code repository.
        There are plenty of tools and services available for this typical <a href=\\\"https://www.atlassian.com/agile/product-management\\\">product
        management work</a>, but most of them are not a good fit more a small startup
        like Front Matter.</p><p>Today I am announcing four new (and related) ways
        you can follow the work Front Matter is doing, and provide feedback and other
        input:</p><ul><li>the <a href=\\\"https://feedback.front-matter.io/b/8mywxw07/feature-ideas\\\">Front
        Matter Ideas</a> Forum, where users can suggest features and improvements
        for Front Matter services \u2013 currently that is services planned to launch
        in 2023 like the Scholarly Blog Archive mentioned above,</li><li>the <a href=\\\"https://feedback.front-matter.io/roadmap\\\">Front
        Matter Roadmap</a> gives a high-level view (planned/in development/launched)
        of the work that Front Matter is doing,</li><li>the <a href=\\\"https://feedback.front-matter.io/announcements\\\">Front
        Matter Announcements</a> are a changelog of smaller achievements and bug fixes
        that don't make it into the Front Matter blog, and</li><li>the <a href=\\\"https://discord.gg/AZHDtKP3\\\">Front
        Matter Discord Server</a> for problems, ideas, and general discussions related
        to Front Matter.</li></ul><p>And of course, you can also interact with Front
        Matter via <a href=\\\"mailto:info@front-matter.io\\\">email</a> or <a href=\\\"https://hachyderm.io/@mfenner\\\">Mastodon</a>.
        You no longer find Front Matter or me personally on Twitter, as this has become
        a chaotic, unfriendly, and toxic place with an uncertain future.</p><p>With
        that, I wish all of you a peaceful and relaxing holiday season and a good
        start into 2023.</p>\",\"comment_id\":\"63a065635b7024003dd39b91\",\"feature_image\":\"https://blog.front-matter.io/content/images/2022/12/Bildschirm-foto-2022-12-19-um-15.16.52.png\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2022-12-19T13:21:39.000+00:00\",\"updated_at\":\"2022-12-19T14:20:17.000+00:00\",\"published_at\":\"2022-12-19T14:20:17.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/cbdtfp1-1798beh\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"},\"url\":\"https://blog.front-matter.io/posts/front-matter-roadmap/\",\"excerpt\":\"In
        a blog post last week I talked about what I am currently working on, namely
        a) helping to make it easier (and safer) to run the InvenioRDM digital repository
        software in Docker container infrastructure, and b) working on converting
        the bolognese metadata conversion Ruby gem to Python to enhance InvenioRDM
        functionality.\\n\\nTo get updates on this work you can follow the Front Matter
        GitHub repositories \u2013 the work I am doing at Front Matter is mostly happening
        in public code repositories. But may\",\"reading_time\":1,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":\"In
        a blog post last week I talked about what I am currently working on, namely
        a) helping to make it easier (and safer) to run the InvenioRDM digital repository
        software in Docker container infrastructure, and b) working on converting
        the bolognese metadata conversion Ruby gem to Python to enhance InvenioRDM
        functionality.\",\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":null},{\"id\":\"639702744774c5004dd5ed83\",\"uuid\":\"ea6d2d56-1efe-433c-937a-fb166da9cdd9\",\"title\":\"Building
        an archive for scholarly blog posts\",\"slug\":\"building-an-archive-for-scholarly-blog-posts\",\"html\":\"<p>This
        blog post is a follow-up to a post in September (Fenner 2022a), where I announced
        that I had started working on an archive for scholarly blog posts based on
        the <a href=\\\"https://inveniordm.docs.cern.ch/\\\">InvenioRDM</a> open-source
        repository software. In the last two months, I focussed on two activities
        \u2013 besides lots of physical therapy and other training following a stroke
        earlier this year (Fenner 2022b): helping to make it easier (and safer) to
        run InvenioRDM in Docker container infrastructure, and working on converting
        the bolognese metadata conversion Ruby gem (Fenner 2017) to Python (work in
        progress on <a href=\\\"https://github.com/front-matter/talbot\\\">GitHub</a>)
        to enhance InvenioRDM functionality. </p><p>Building an archive of scholarly
        blog posts faces the same fundamental challenges as repositories for other
        types of scholarly content, whether data, software, preprints, or journal
        articles. You have to collect metadata and content, and that approach only
        scales with standardization and open licenses.</p><p>Luckily we already know
        a lot about required and optional but desired scholarly metadata, and they
        are fundamentally not different for scholarly blog posts. This means we can
        take similar approaches as we have for example taken for research data:</p><figure
        class=\\\"kg-card kg-image-card kg-card-hascaption\\\"><img src=\\\"https://blog.front-matter.io/content/images/2022/12/guidelines-3.png\\\"
        class=\\\"kg-image\\\" alt loading=\\\"lazy\\\" width=\\\"815\\\" height=\\\"363\\\"
        srcset=\\\"https://blog.front-matter.io/content/images/size/w600/2022/12/guidelines-3.png
        600w, https://blog.front-matter.io/content/images/2022/12/guidelines-3.png
        815w\\\" sizes=\\\"(min-width: 720px) 720px\\\"><figcaption><strong>Guidelines
        for Repositories. </strong>Fenner et al. 2019.</figcaption></figure><p>Persistent
        identifiers for blog posts can be DOIs, as this blog is doing since earlier
        this year (Fenner 2022). The main advantage of using DOIs is registering standard
        metadata stored independently of the blogging platform, in case the platform
        changes or disappears (as has happened several times in the 15 years this
        blog exists). While there are several blogs using DOIs for their posts, they
        often fail in guideline #4: <em>the persistent identifier must be embedded
        in the landing page in machine-readable format. </em>This is important so
        that reference managers can capture the DOI and retrieve the associated metadata.</p><p>When
        the metadata are embedded directly in the blog post, schema.org markup in
        JSON-LD format (guideline #7) is much more convenient than HTML meta tags
        (guideline #8), but for the time being reference managers only work with the
        latter. The blogging platform used for this blog (<a href=\\\"https://ghost.org/\\\">https://ghost.org/</a>)
        has schema.org metadata built in, and there was only a small amount of work
        needed to expose all metadata needed (or desired) for DOI registration:</p><ul><li><a
        href=\\\"https://support.google.com/webmasters/answer/10347851\\\"><strong>Canonical
        URL</strong></a>: the DOI for the blog post</li><li><strong>License</strong>:
        the Creative Commons license for the content (this blog uses the <a href=\\\"https://creativecommons.org/licenses/by/4.0/legalcode\\\">Creative
        Commons Attribution 4.0 License</a>)</li><li><strong>ISSN</strong>: the Internal
        Standard Serial Number of this blog (2749-9952)</li></ul><p>An issue I have
        seen with schema.org metadata is that sometimes they are added by a script
        running in the browser instead of coming from the server, and this makes metadata
        harvesting unreliable. Multiple versions and different levels of granularity
        \u2013 a major challenge when working with data and software \u2013 luckily
        is not a major issue with scholarly blogs, in this regard, they behave similarly
        to preprints and journal articles.</p><h3 id=\\\"infrastructure-for-archiving-scientific-blog-posts\\\">Infrastructure
        for Archiving Scientific Blog Posts</h3><p>There are several possible approaches
        to building infrastructure for scholarly blog posts, and they all have well-known
        real-world examples:</p><ul><li><strong>A central repository</strong><br>A
        good example is the <a href=\\\"https://arxiv.org/\\\">ArXiv.org e-Print archive</a>,
        which hosts more than two million preprints in physics, mathematics, computer
        science, and some other fields, and is doing that for more than 25 years.
        All content and metadata are registered and stored in a central location (<a
        href=\\\"https://blog.arxiv.org/2022/02/17/new-arxiv-articles-are-now-automatically-assigned-dois/\\\">since
        earlier this year using DOIs</a>), and then distributed elsewhere, often domain-specific
        resources such as <a href=\\\"https://ui.adsabs.harvard.edu/\\\">ADS</a> (astrophysics)
        and <a href=\\\"https://inspirehep.net/\\\">InspireHEP</a> (high-energy physics).
        ArXiv is hosted by Cornell University.</li><li><strong>A central archive with
        content published in many places</strong><br><a href=\\\" https://pubmed.ncbi.nlm.nih.gov\\\">PubMed</a>
        (metadata) and <a href=\\\" https://www.ncbi.nlm.nih.gov\\\">PubMed Central</a>
        (metadata and content) are the main archives of biomedical and life sciences
        journal literature, again doing this for more than 25 years. The content with
        metadata is published in many different places but aggregated in PubMed/PubMed
        Central. Just like ADS and InspireHEP, PubMed and PubMed Central (and <a href=\\\"https://europepmc.org/\\\">Europe
        PMC</a>) are the central resources for scientists in the field to discover
        the relevant literature. PubMed uses the <a href=\\\"https://en.wikipedia.org/wiki/PubMed#PubMed_identifier\\\">PMID</a>,
        which can be mapped to the corresponding DOI as persistent identifier. For
        full-text content not included in PubMed Central, PubMed links out to publisher
        websites. PubMed is hosted by the <a href=\\\"https://www.nlm.nih.gov/\\\">National
        Library of Medicine</a> at the U.S. National Institutes of Health (NIH). NIH
        is the largest funder in the biomedical and life sciences, and its policies
        help PubMed Central host content.</li><li><strong>A central archive with content
        published elsewhere</strong><br>The repository <a href=\\\"https://zenodo.org/\\\">Zenodo</a>
        is the largest generic repository of scholarly content with more than 1.5
        million publications, and a million datasets, software, images, and presentations.
        Almost all content uses open licenses (either one of the Creative Commons
        licenses or <a href=\\\"https://opensource.org/licenses\\\">Open Source Initiative
        approved licenses</a> for software), facilitating the reuse of the content.
        Zenodo issues DOIs for its content, the DOI points to the Zenodo repository
        also for content originally registered elsewhere (e.g. software hosted on
        GitHub). Zenodo is particularly relevant for the planned blog posts archive,
        as the InvenioRDM software is based on Zenodo software and work is in progress
        for InvenioRDM to power Zenodo. Zenodo is hosted by <a href=\\\"https://home.cern/\\\">CERN</a>,
        the European Organization of Nuclear Research, the central resource for high-energy
        physics research.</li></ul><p>Based on the above, what makes sense for a scholarly
        blog post archive?</p><ul><li>Blogs are very decentralized based on their
        technology and 20-year history. While blogging platforms also have a long
        history (and Wordpress is the elephant in the room powering more than <a href=\\\"https://blog.hubspot.com/website/wordpress-stats\\\">40%
        of all websites</a>), a central blogging platform for science blogs similar
        to what ArXiv is doing in several fields is neither realistic nor desirable.</li><li>DOIs
        are a good fit as persistent identifiers for scholarly blogs. A lot of tools
        and services exist for them (including the InvenioRDM open source software),
        and the required and desired metadata for blogs are basically covered by DOI
        metadata (at least for Crossref and DataCite DOIs). Minor issues are that
        there is no dedicated content type for blog posts and that <strong>feature
        image</strong> metadata (supported by schema.org) would be beneficial.</li><li>The
        business models for DOI registrations need to be adapted to work better for
        scholarly blogs. A high fixed annual fee (DataCite) or a DOI pointing to a
        central archive instead of the original content (software in Zenodo) are hurdles
        for the long tail of independent science bloggers.</li><li>We need business
        models for sustainable science blogging infrastructure. Advertisements aren't
        working (the German platform scienceblogs.de is for example closing at the
        end of year) and individual readers paying for content might work for popular
        newsletters but doesn't align with Open Science practices. More work is needed,
        but one key element is cheap and simple infrastructure.</li><li>Existing blogging
        software (e.g. <a href=\\\"https://wordpress.org/\\\">Wordpress</a>, <a href=\\\"https://ghost.org/\\\">Ghost</a>,
        <a href=\\\"https://gohugo.io/\\\">Hugo</a>, or <a href=\\\"https://jekyllrb.com/\\\">Jekyll</a>)
        <em>almost</em> works for scholar blogs. Some minor changes (particularly
        around the canonical URL/persistent identifier) are required to improve the
        use in reference managers and archiving services.</li><li>We need a standard
        archiving format for scholarly blogs. <a href=\\\"https://jats.nlm.nih.gov/\\\">JATS</a>
        (Journal Article Tag Suite) is a standard for scholarly articles, but probably
        too heavy for blog posts. More work is needed and it should align with <a
        href=\\\"https://en.wikipedia.org/wiki/RSS\\\">RSS</a> (Really Simple Syndication),
        the 20-year-old standard for distributing content from blogs and similar sources.
        \_The biggest gap is maybe a standard way to describe links and references.</li><li>We
        need aggregation of science blog metadata and content in a central archive.
        This enables much easier discovery and long-term archiving, I still enjoy
        reading an interview I did with Geoff Bilder in 2009 (Fenner 2009), and the
        points he makes are still relevant. The blog posts had moved at least three
        times over the years and would have greatly benefitted from a DOI, standard
        archiving format, and a long-term archive as home.</li><li>I have started
        the work of building the infrastructure for archiving scholarly blogs, but
        I am fully aware that this is not only a technical challenge but even more
        so one of governance and community engagement. This needs much more work in
        2023 and onwards, and something I look forward to working on jointly with
        others.</li></ul><h3 id=\\\"references\\\">References</h3><p>Fenner, M. (2022a).
        <em>Starting Work on the Front Matter Archive</em> [Blog]. Front Matter. <a
        href=\\\"https://doi.org/10.53731/9z6rz5d-djbay0y\\\">https://doi.org/10.53731/9z6rz5d-djbay0y</a></p><p>Fenner,
        M. (2022b). <em>I spent the last five months in the hospital</em> [Blog].
        Front Matter. <a href=\\\"https://doi.org/10.53731/bkkzj8g-gd14mb6\\\">https://doi.org/10.53731/bkkzj8g-gd14mb6</a></p><p>Fenner,
        M. (2017). <em>Bolognese: A Ruby library for conversion of DOI Metadata</em>.
        DataCite. <a href=\\\"https://doi.org/10.5438/N138-Z3MK\\\">https://doi.org/10.5438/N138-Z3MK</a></p><p>Fenner,
        M., Crosas, M., Grethe, J. S., Kennedy, D., Hermjakob, H., Rocca-Serra, P.,
        Durand, G., Berjon, R., Karcher, S., Martone, M., &amp; Clark, T. (2019).
        A data citation roadmap for scholarly data repositories. <em>Scientific Data</em>,
        <em>6</em>(1), Article. <a href=\\\"https://doi.org/10.1038/s41597-019-0031-8\\\">https://doi.org/10.1038/s41597-019-0031-8</a></p><p>Fenner,
        M. (2022c). <em>DOI Registrations for all Ghost Blogs</em> [Blog]. Front Matter.
        <a href=\\\"https://doi.org/10.53731/fezg09h-hgn1gzm\\\">https://doi.org/10.53731/fezg09h-hgn1gzm</a></p><p>Fenner,
        M. (2009). <em>Interview with Geoffrey Bilder</em> [Blog]. Front Matter. <a
        href=\\\"https://doi.org/10.53731/r294649-6f79289-8cw1h\\\">https://doi.org/10.53731/r294649-6f79289-8cw1h</a></p>\",\"comment_id\":\"639702744774c5004dd5ed83\",\"feature_image\":\"https://blog.front-matter.io/content/images/2022/12/guidelines-4.png\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2022-12-12T10:29:08.000+00:00\",\"updated_at\":\"2023-06-28T13:39:53.000+00:00\",\"published_at\":\"2022-12-12T12:58:33.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/br9f5xa-a556w2t\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42bbc41e317003df48d4e\",\"name\":\"Feature\",\"slug\":\"feature\",\"description\":\"Features
        explore issues raised by news stories in more depth.\",\"feature_image\":\"https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fHJlc2VhcmNofGVufDB8fHx8MTYxODEyMzQxNQ&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/feature/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42bbc41e317003df48d4e\",\"name\":\"Feature\",\"slug\":\"feature\",\"description\":\"Features
        explore issues raised by news stories in more depth.\",\"feature_image\":\"https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fHJlc2VhcmNofGVufDB8fHx8MTYxODEyMzQxNQ&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/feature/\"},\"url\":\"https://blog.front-matter.io/posts/building-an-archive-for-scholarly-blog-posts/\",\"excerpt\":\"This
        blog post is a follow-up to a post in September (Fenner 2022a), where I announced
        that I had started working on an archive for scholarly blog posts based on
        the InvenioRDM open-source repository software. In the last two months, I
        focussed on two activities \u2013 besides lots of physical therapy and other
        training following a stroke earlier this year (Fenner 2022b): helping to make
        it easier (and safer) to run InvenioRDM in Docker container infrastructure,
        and working on converting the bolognes\",\"reading_time\":6,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":null},{\"id\":\"6334542a03f092003d16ca5b\",\"uuid\":\"728d6c13-05ae-4416-8827-b705a4b3abc7\",\"title\":\"Starting
        Work on the Front Matter Archive\",\"slug\":\"starting-work-on-the-front-matter-archive\",\"html\":\"<p>In
        August 2021 <a href=\\\"https://doi.org/10.53731/r8c26t1-97aq74v-ag66m\\\">I
        joined the InvenioRDM project</a> to help develop and host a modern repository
        platform for scholarly content. Things didn't exactly go as planned at the
        beginning of 2022, and I spent <a href=\\\"https://doi.org/10.53731/bkkzj8g-gd14mb6\\\">five
        months in the hospital</a> with serious personal health issues. Since returning
        home in early June, my health has improved considerably, and in September
        I was able to slowly start working again. This has worked well for me, so
        it is time to time to set goals for my work on the InvenioRDM project again.</p><h3
        id=\\\"announcing-the-front-matter-archive\\\">Announcing the Front Matter
        Archive</h3><blockquote>Front Matter will be launching a repository to host
        the full-text content of scholarly blogs in the first quarter of 2023. </blockquote><p>The
        starting point will be the over 450 blog posts that I have published <a href=\\\"https://doi.org/10.53731/bs60jms-sqaehsk\\\">over
        the last 15 years</a>, but the archive is of course open to content from all
        scholarly blogs. The goal is to both offer a useful resource for the scholarly
        community and to learn something about hosting InvenioRDM. An archive of scholarly
        blog posts is a good starting point, as blogs tend to change technology or
        location every few years, and older content then often becomes unavailable.
        Issuing DOIs for blog posts is part of the solution (e.g. this makes citing
        the blog posts much easier), but a stable long-term archive of the content
        is equally important. A challenge that scholarly blog posts share with many
        other often ephemeral scholarly resources, e.g. data and software.</p><h3
        id=\\\"setting-up-the-inveniordm-software\\\">Setting up the InvenioRDM Software</h3><p>The
        <a href=\\\"https://inveniosoftware.org/products/rdm/\\\">InvenioRDM</a> open-source
        software has seen a lot of work in the last several years and is currently
        at <a href=\\\"https://inveniordm.docs.cern.ch/releases/versions/version-v9.1.0/\\\">version
        9.1</a>. Several project partners are working on releasing a production version
        within the next twelve months, and the Caltech Library was the<a href=\\\"https://library.caltech.edu/blog/CaltechDATA-InvenioRDM\\\">
        first to do so last week</a>. Repository software is a complex piece of infrastructure,
        and a lot of work is expected for the proper configuration of the Front Matter
        Archive, including customization of the theme, authentication, etc.</p><h3
        id=\\\"running-the-front-matter-archive-in-a-kubernetes-cluster\\\">Running
        the Front Matter Archive in a Kubernetes Cluster</h3><p><a href=\\\"https://kubernetes.io/\\\">Kubernetes</a>
        in the last few years has become the de facto standard for deploying containerized
        applications such as InvenioRDM. Unfortunately running a Kubernetes cluster
        is not easy, but it will make things easier eventually (e.g. monitoring, scaling,
        and security), and it can be set up in a variety of environments from private
        clouds to public cloud providers. Front Matter will be using a managed Kubernetes
        cluster provided by <a href=\\\"https://www.digitalocean.com/\\\">Digitalocean</a>
        and provisioned by the infrastructure as code open source software tool <a
        href=\\\"https://www.terraform.io/\\\">Terraform</a>. Kubernetes will not
        host everything. At least in the initial version Front Matter will use hosted
        databases and hosted cloud object storage to store files and metadata, as
        Kubernetes (and containers) excel when running stateless applications, but
        more work is needed for <a href=\\\"https://cloud.google.com/kubernetes-engine/docs/how-to/stateful-apps\\\">stateful
        applications</a>.</p><h3 id=\\\"archiving-full-text-blog-content\\\">Archiving
        full-text Blog Content</h3><p>Front Matter will aim to archive blog posts
        via available APIs (as can be done with the Front Matter Blog), but we will
        have to take a flexible approach as full-text content will be provided in
        a variety of formats, e.g. RSS feeds. The initial focus will be on the <a
        href=\\\"https://ghost.org/\\\">Ghost</a> and <a href=\\\"https://wordpress.org/\\\">Wordpress</a>
        blogging platforms. We will help with issuing DOIs for this content and help
        to archive associated images. We are only interested in content with an open
        license (<a href=\\\"https://creativecommons.org/licenses/by/4.0/\\\">CC-BY</a>
        or <a href=\\\"https://creativecommons.org/publicdomain/zero/1.0/\\\">CCO</a>)
        to maximize the potential reuse of the blog archive.</p><h3 id=\\\"future-of-the-archive\\\">Future
        of the Archive</h3><p>After the initial setup of the blog archive, the focus
        will be on expanding content and on providing added value. Please reach out
        via email, Discord, or comments if you have scholarly blog content you want
        to be archived by Front Matter, or have suggestions for added functionality.
        One feature I want to see improved in InvenioRDM is better support for full-text
        HTML in addition to embedding PDF and other formats. In the coming months,
        I will also work on the cost model. There is a moderate cost to archive a
        blog post (mostly for ingesting content), but these costs would add up if
        blog posts are added by the thousands.</p>\",\"comment_id\":\"6334542a03f092003d16ca5b\",\"feature_image\":\"https://images.unsplash.com/photo-1628046902759-c94ab525fdaf?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDE1fHxhcmNoaXZlfGVufDB8fHx8MTY2NDM3NDk3OA&ixlib=rb-1.2.1&q=80&w=2000\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2022-09-28T14:03:22.000+00:00\",\"updated_at\":\"2022-09-28T16:11:52.000+00:00\",\"published_at\":\"2022-09-28T16:10:57.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/9z6rz5d-djbay0y\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"},\"url\":\"https://blog.front-matter.io/posts/starting-work-on-the-front-matter-archive/\",\"excerpt\":\"In
        August 2021 I joined the InvenioRDM project to help develop and host a modern
        repository platform for scholarly content. Things didn't exactly go as planned
        at the beginning of 2022, and I spent five months in the hospital with serious
        personal health issues. Since returning home in early June, my health has
        improved considerably, and in September I was able to slowly start working
        again. This has worked well for me, so it is time to time to set goals for
        my work on the InvenioRDM project aga\",\"reading_time\":3,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":\"Photo
        by <a href=\\\"https://unsplash.com/@unarchive?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Jeremy
        Bezanger</a> / <a href=\\\"https://unsplash.com/?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Unsplash</a>\"},{\"id\":\"630c96b3683f4b003d5cd484\",\"uuid\":\"57ec5c34-8f10-4130-adcd-f6ae0e6f18cf\",\"title\":\"Adding
        Feature Images to Blog Posts\",\"slug\":\"adding-feature-images\",\"html\":\"<p>Feature
        images are commonly used for blog posts, including on this blog. We can use
        our screenshots or photos or stock photos (ideally license free or with an
        open license) from sites like <a href=\\\"https://flickr.com/\\\">Flickr</a>,
        <a href=\\\"https://unsplash.com/\\\">Unsplash</a>, or <a href=\\\"https://www.pexels.com/\\\">Pexels</a>.
        More recently, we can also use artificial intelligence tools such as <a href=\\\"https://openai.com/dall-e-2/\\\">DALL\xB7E
        2</a> that generate images from a description in natural language.</p><p>As
        today is the launch of the first <a href=\\\"https://www.nasa.gov/specials/artemis-i/\\\">NASA
        mission</a> to the moon in fifty years, it seems appropriate to commemorate
        that historic event with a feature image showing a rocket, in this case with
        a garden gnome in the style of a Picasso painting generated by DALL\xB7E 2.
        I've added about a dozen feature images to this blog with various motives
        and styles all generated DALL\xB7E 2. The only thing they have in common is
        that they feature a garden gnome with an umbrella. Try to find them and tell
        me in the comments which one you like best.</p>\",\"comment_id\":\"630c96b3683f4b003d5cd484\",\"feature_image\":\"https://blog.front-matter.io/content/images/2022/08/DALL-E-2022-08-29-12.35.48---Picasso-painting-of-a-garden-gnome-with-an-umbrella-in-front-of-the-Artemis-launch-rocket.png\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2022-08-29T10:36:35.000+00:00\",\"updated_at\":\"2022-12-11T21:47:40.000+00:00\",\"published_at\":\"2022-08-29T11:08:23.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/c6dwz6z-zzz0b3q\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42bbc41e317003df48d4e\",\"name\":\"Feature\",\"slug\":\"feature\",\"description\":\"Features
        explore issues raised by news stories in more depth.\",\"feature_image\":\"https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fHJlc2VhcmNofGVufDB8fHx8MTYxODEyMzQxNQ&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/feature/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42bbc41e317003df48d4e\",\"name\":\"Feature\",\"slug\":\"feature\",\"description\":\"Features
        explore issues raised by news stories in more depth.\",\"feature_image\":\"https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fHJlc2VhcmNofGVufDB8fHx8MTYxODEyMzQxNQ&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/feature/\"},\"url\":\"https://blog.front-matter.io/posts/adding-feature-images/\",\"excerpt\":\"Feature
        images are commonly used for blog posts, including on this blog. We can use
        our screenshots or photos or stock photos (ideally license free or with an
        open license) from sites like Flickr, Unsplash, or Pexels. More recently,
        we can also use artificial intelligence tools such as DALL\xB7E 2 that generate
        images from a description in natural language.\\n\\nAs today is the launch
        of the first NASA mission to the moon in fifty years, it seems appropriate
        to commemorate that historic event with a fe\",\"reading_time\":1,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":null},{\"id\":\"6307a551683f4b003d5cd43b\",\"uuid\":\"f6fdb202-2a93-4f60-85b9-b92664f1d4d0\",\"title\":\"DOI
        Registrations for all Ghost Blogs\",\"slug\":\"doi-registrations-for-all-blog\",\"html\":\"<p>This
        blog since earlier this month is no longer using a <a href=\\\"https://doi.org/10.53731/cgdnpqv-vxss4fm\\\">JAMStack</a>
        setup but a regular Ghost setup using <a href=\\\"https://ghost.org/pricing/\\\">Ghost
        Pro </a>for hosting. The primary driver were the new native search and native
        comments, but I needed to do a little bit of work to keep the DOI registration
        working. This is done now, and an added benefit is that DOI registration is
        now straightforward for any blog that uses Ghost as a platform.</p><h3 id=\\\"requirements\\\">Requirements</h3><ul><li>An
        account to register DOIs with Crossref or DataCite</li><li>A Ghost blog that
        allows custom themes (e.g via <a href=\\\"https://ghost.org/pricing/\\\">Ghost
        Pro</a>, <a href=\\\"https://www.digitalpress.blog/pricing\\\">DigitalPress</a>,
        or self-hosted)</li></ul><h3 id=\\\"blog-configuration\\\">Blog Configuration</h3><p>We
        expose all metadata via schema.org upon publication, which is parsed and converted
        to Crossref or DataCite XML using a GitHub Action. All the metadata we need
        (e.g. author, title, and publication date) are already exposed as schema.org.
        The only required element missing is the DOI.</p><p>You can come up with your
        own unique DOI scheme, but it is easier (and <a href=\\\"https://blog.front-matter.io/posts/cool-dois/\\\">cooler</a>)
        using the <a href=\\\"https://rubygems.org/gems/briard\\\">briard Ruby gem</a>
        (version 2.4.2 and up) to generate a random DOI using your DOI prefix:</p><!--kg-card-begin:
        html--><code>briard encode 10.53731\\n  => https://doi.org/10.53731/cgdnpqv-vxss4fm\\n</code><!--kg-card-end:
        html--><p>This DOI is then entered in the post settings for the <a href=\\\"https://en.wikipedia.org/wiki/Canonical_link_element\\\">canonical
        URL</a>:</p><figure class=\\\"kg-card kg-image-card kg-card-hascaption\\\"><img
        src=\\\"https://blog.front-matter.io/content/images/2022/08/Bildschirm-foto-2022-08-29-um-13.28.01.png\\\"
        class=\\\"kg-image\\\" alt loading=\\\"lazy\\\" width=\\\"487\\\" height=\\\"102\\\"><figcaption>Canonical
        URL in Post -&gt; Post settings -&gt; Meta data</figcaption></figure><p>There
        are some optional metadata that you can add as well:</p><ul><li>The canonical
        URL should be displayed on each blog post:</li><li>The author ORCID, put the
        ID in the website settings of your author profile:</li><li>The license for
        the blog post content, put into a <strong>DCTERMS.license</strong> meta tag,
        and the ISSN:</li></ul><figure class=\\\"kg-card kg-image-card\\\"><img src=\\\"https://blog.front-matter.io/content/images/2022/08/Bildschirm-foto-2022-08-25-um-17.49.23.png\\\"
        class=\\\"kg-image\\\" alt loading=\\\"lazy\\\" width=\\\"579\\\" height=\\\"111\\\"></figure><figure
        class=\\\"kg-card kg-image-card\\\"><img src=\\\"https://blog.front-matter.io/content/images/2022/08/Bildschirm-foto-2022-08-25-um-17.51.43.png\\\"
        class=\\\"kg-image\\\" alt loading=\\\"lazy\\\" width=\\\"774\\\" height=\\\"62\\\"
        srcset=\\\"https://blog.front-matter.io/content/images/size/w600/2022/08/Bildschirm-foto-2022-08-25-um-17.51.43.png
        600w, https://blog.front-matter.io/content/images/2022/08/Bildschirm-foto-2022-08-25-um-17.51.43.png
        774w\\\" sizes=\\\"(min-width: 720px) 720px\\\"></figure><p>To make working
        with these small changes easier, I forked the official <strong>headline</strong>
        theme, and you can download my forked version (renamed <strong>schlagzeile</strong>)
        as ZIP file from its <a href=\\\"https://github.com/front-matter/schlagzeile\\\">GitHub
        page.</a> After uploading the theme to your Ghost site, activate <strong>schlagzeile</strong>
        in the settings:</p><figure class=\\\"kg-card kg-image-card\\\"><img src=\\\"https://blog.front-matter.io/content/images/2022/08/Bildschirm-foto-2022-08-25-um-17.59.09.png\\\"
        class=\\\"kg-image\\\" alt loading=\\\"lazy\\\" width=\\\"950\\\" height=\\\"421\\\"
        srcset=\\\"https://blog.front-matter.io/content/images/size/w600/2022/08/Bildschirm-foto-2022-08-25-um-17.59.09.png
        600w, https://blog.front-matter.io/content/images/2022/08/Bildschirm-foto-2022-08-25-um-17.59.09.png
        950w\\\" sizes=\\\"(min-width: 720px) 720px\\\"></figure><p>You can use the
        site design settings to add license information and ISSN for your blog:</p><figure
        class=\\\"kg-card kg-image-card\\\"><img src=\\\"https://blog.front-matter.io/content/images/2022/08/Bildschirm-foto-2022-08-25-um-18.02.05.png\\\"
        class=\\\"kg-image\\\" alt loading=\\\"lazy\\\" width=\\\"369\\\" height=\\\"269\\\"></figure><h3
        id=\\\"github-action\\\">GitHub Action</h3><p>Once the blog is configured
        as above, and you have a new post, use a GitHub Action to trigger the DOI
        registration. You can copy my <a href=\\\"https://github.com/front-matter/bloggable/blob/main/.github/workflows/webhook.yml\\\">webhook</a>
        GitHub Action and need to set these variables (for Crossref, similar variables
        for DataCite):</p><ul><li>CROSSREF_DEPOSITOR_NAME</li><li>CROSSREF_DEPOSITOR_EMAIL</li><li>CROSSREF_REGISTRANT</li><li>CROSSREF_USERNAME_WITH_ROLE</li><li>CROSSREF_PASSWORD</li></ul><p>You
        then trigger the workflow action by entering the path to the published blog
        post:</p><figure class=\\\"kg-card kg-image-card\\\"><img src=\\\"https://blog.front-matter.io/content/images/2022/08/Bildschirm-foto-2022-08-25-um-18.11.37.png\\\"
        class=\\\"kg-image\\\" alt loading=\\\"lazy\\\" width=\\\"473\\\" height=\\\"326\\\"></figure><p>If
        your blog doesn't publish more than weekly, this semi-automated workflow is
        probably ok (and takes under a minute). Reach out to me in the comments for
        further questions or feedback. </p><p>Not every scholarly blog is using Ghost,
        but I currently can't provide guidance for other blogging platforms, for example
        Wordpress.</p>\",\"comment_id\":\"6307a551683f4b003d5cd43b\",\"feature_image\":\"https://images.unsplash.com/photo-1554415707-6e8cfc93fe23?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDV8fHJlZ2lzdHJhdGlvbnxlbnwwfHx8fDE2NjE0NDU1MTA&ixlib=rb-1.2.1&q=80&w=2000\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2022-08-25T16:37:37.000+00:00\",\"updated_at\":\"2022-08-29T11:28:27.000+00:00\",\"published_at\":\"2022-08-25T16:39:40.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/fezg09h-hgn1gzm\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42bbc41e317003df48d4e\",\"name\":\"Feature\",\"slug\":\"feature\",\"description\":\"Features
        explore issues raised by news stories in more depth.\",\"feature_image\":\"https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fHJlc2VhcmNofGVufDB8fHx8MTYxODEyMzQxNQ&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/feature/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42bbc41e317003df48d4e\",\"name\":\"Feature\",\"slug\":\"feature\",\"description\":\"Features
        explore issues raised by news stories in more depth.\",\"feature_image\":\"https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fHJlc2VhcmNofGVufDB8fHx8MTYxODEyMzQxNQ&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/feature/\"},\"url\":\"https://blog.front-matter.io/posts/doi-registrations-for-all-blog/\",\"excerpt\":\"This
        blog since earlier this month is no longer using a JAMStack setup but a regular
        Ghost setup using Ghost Pro for hosting. The primary driver were the new native
        search and native comments, but I needed to do a little bit of work to keep
        the DOI registration working. This is done now, and an added benefit is that
        DOI registration is now straightforward for any blog that uses Ghost as a
        platform.\\n\\n\\nRequirements\\n\\n * An account to register DOIs with Crossref
        or DataCite\\n * A Ghost blog that allo\",\"reading_time\":3,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":\"Photo
        by <a href=\\\"https://unsplash.com/@chuklanov?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Avel
        Chuklanov</a> / <a href=\\\"https://unsplash.com/?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Unsplash</a>\"},{\"id\":\"62fcfa0b26a4b1003d2fa0e2\",\"uuid\":\"c1846ec7-688f-4ac9-9eb0-faec4e61543f\",\"title\":\"Now
        with native comments\",\"slug\":\"native-comments\",\"html\":\"<p>Since last
        year this blog is powered by the <a href=\\\"https://ghost.org/\\\">Ghost</a>
        open source blogging platform. Two important and long-standing shortcomings
        of the platform were search and comments, which I <a href=\\\"https://blog.front-matter.io/posts/front-matter-officially-launches-today/\\\">added</a>
        via integrating third-party tools (<a href=\\\"https://blog.front-matter.io/posts/full-text-search-front-matter-blog/\\\">Typesense</a>
        and <a href=\\\"https://www.discourse.org/\\\">Discourse</a>, respectively).</p><p>In
        the last several weeks Ghost team has worked hard to add these features to
        the core platform, described <a href=\\\"https://ghost.org/changelog/search/\\\">here</a>
        and <a href=\\\"https://ghost.org/changelog/native-comments/\\\">here</a>.
        These changes do not (yet) work well via the Ghost API, so I decided to drop
        my <a href=\\\"https://jamstack.org/\\\">Jamstack</a> setup with Ghost as
        a headless CMS backend and a <a href=\\\"https://github.com/front-matter/bloggable\\\">frontend</a>
        built with Next.js. Native comments and search are available now, more work
        is needed to register and display <a href=\\\"https://blog.front-matter.io/posts/the-front-matter-blog-now-uses-dois/\\\">DOIs
        for the blog posts</a>, based on schema.org metadata (which need minor tweaks,
        e.g. include the license of the blog content), and a Github Actions <a href=\\\"https://github.com/front-matter/bloggable/blob/main/.github/workflows/webhook.yml\\\">workflow</a>.</p><p>To
        use the new comments, you have to sign up as a Front Matter Blog member (signup
        links at the top and bottom of every page). Front Matter membership is free,
        is needed for commenting to control spam, and optionally includes a newsletter
        (each new blog post sent via email).</p><p>Of course, I am well aware that
        comments are not a technical problem, but a social problem. But building a
        community around the Front Matter blog is easier if commenting is easy and
        doesn't require signing up to an external service with unknown policies around
        handling personal data.</p>\",\"comment_id\":\"62fcfa0b26a4b1003d2fa0e2\",\"feature_image\":\"https://blog.front-matter.io/content/images/2022/08/Bildschirm-foto-2022-08-15-um-19.51.47.png\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2022-08-17T14:24:11.000+00:00\",\"updated_at\":\"2022-08-24T18:58:38.000+00:00\",\"published_at\":\"2022-08-17T14:56:06.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/cgdnpqv-vxss4fm\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"},\"url\":\"https://blog.front-matter.io/posts/native-comments/\",\"excerpt\":\"Since
        last year this blog is powered by the Ghost open source blogging platform.
        Two important and long-standing shortcomings of the platform were search and
        comments, which I added via integrating third-party tools (Typesense and Discourse,
        respectively).\\n\\nIn the last several weeks Ghost team has worked hard to
        add these features to the core platform, described here and here. These changes
        do not (yet) work well via the Ghost API, so I decided to drop my Jamstack
        setup with Ghost as a headless \",\"reading_time\":1,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":null},{\"id\":\"62f501fa50b5b4004d1dcaca\",\"uuid\":\"d17130b1-e29d-494b-a069-561175bce1dc\",\"title\":\"This
        blog turned 15 (years old) this month\",\"slug\":\"this-blog-turned-15-this-month\",\"html\":\"<p>The
        first post on this blog was published on August 3, 2007 (<a href=\\\"https://doi.org/10.53731/r294649-6f79289-8cw1q\\\">Open
        access may become mandatory for NIH-funded research</a>). This is post number
        465, and in the past 15 years the blog has seen changes in technology and
        hosting location \u2013 but I wrote all posts (with the exception of a few
        guest posts). The overall theme remained unchanged: technology used in scholarly
        communication. </p><p>Instead of a detailed analysis of recurring themes,
        or how scholarly communication has changed in the last 15 years, I want to
        pick one topic that continues to worry me, and has been the subject of multiple
        posts on this blog and elsewhere: the over-reliance on PDF as publishing format
        for scholarly articles.</p><p>This week I read two interesting articles related
        to climate change. One of them (<a href=\\\"https://doi.org/10.1038/s41558-022-01426-1\\\">Over
        half of known human pathogenic diseases can be aggravated by climate change</a>)
        did an impressive systematic review of the literature on the impacts of ten
        climatic hazards sensitive to greenhouse gas emissions on each known human
        pathogenic disease (in short: very scary). The second paper (<a href=\\\"https://doi.org/10.1073/pnas.2120584119\\\">Estimating
        the environmental impacts of 57,000 food products</a>) tried to estimate the
        environmental impact of more than 50K food products in the United Kingdom
        and Ireland (no big surprises, but again stressing that meat, fish, and cheese
        have a significant environmental impact).</p><p>Both articles are available
        online as full-text, but they come in PDF format. Fine for printing and then
        reading them (which I did), but in 2022 I expect to read papers on a tablet
        (which I use for almost all my reading) where the PDF letter or A4 size doesn't
        quite fit on the 10-inch screen. There are other problems with PDF (e.g. access
        to metadata such as references and using PDF as submission format, e.g. with
        preprints). These problems are not new and there are workarounds, but in the
        15 years of writing this blog \u2013 despite a lot of progress \u2013 scholarly
        communication continues to have an uneasy relationship with technology and
        is often stuck in the past. In contrast to many (but of course not all) other
        sectors.</p><p>This means there are many reasons to continue writing this
        blog. And since 2012, when I gave up my job as a medical doctor in a university
        hospital, I am working full-time on scholarly infrastructure, after recovering
        from the health issues I described in the last post (<a href=\\\"https://blog.front-matter.io/posts/i-spent-the-last-five-months-in-the-hospital\\\">I
        spent the last five months in the hospital</a>) with a focus on research data
        management.</p><p>Incidentally, August 3 saw another anniversary as Retraction
        Watch, the wonderful service tracking paper retractions turned 12 (<a href=\\\"https://retractionwatch.com/2022/08/03/happy-12th-birthday-retraction-watch-and-what-a-year-it-was/\\\">years
        old</a>). Congratulations Ivan and team!</p>\",\"comment_id\":\"62f501fa50b5b4004d1dcaca\",\"feature_image\":\"https://images.unsplash.com/photo-1555607124-8531c7c702d0?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDQzfHxiaXJ0aGRheXxlbnwwfHx8fDE2NjAyMjQwOTA&ixlib=rb-1.2.1&q=80&w=2000\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2022-08-11T13:19:54.000+00:00\",\"updated_at\":\"2022-08-14T14:09:25.000+00:00\",\"published_at\":\"2022-08-11T14:13:08.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/bs60jms-sqaehsk\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42bbc41e317003df48d4e\",\"name\":\"Feature\",\"slug\":\"feature\",\"description\":\"Features
        explore issues raised by news stories in more depth.\",\"feature_image\":\"https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fHJlc2VhcmNofGVufDB8fHx8MTYxODEyMzQxNQ&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/feature/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42bbc41e317003df48d4e\",\"name\":\"Feature\",\"slug\":\"feature\",\"description\":\"Features
        explore issues raised by news stories in more depth.\",\"feature_image\":\"https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fHJlc2VhcmNofGVufDB8fHx8MTYxODEyMzQxNQ&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/feature/\"},\"url\":\"https://blog.front-matter.io/posts/this-blog-turned-15-this-month/\",\"excerpt\":\"The
        first post on this blog was published on August 3, 2007 (Open access may become
        mandatory for NIH-funded research). This is post number 465, and in the past
        15 years the blog has seen changes in technology and hosting location \u2013
        but I wrote all posts (with the exception of a few guest posts). The overall
        theme remained unchanged: technology used in scholarly communication.\\n\\nInstead
        of a detailed analysis of recurring themes, or how scholarly communication
        has changed in the last 15 years, I \",\"reading_time\":2,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":\"Photo
        by <a href=\\\"https://unsplash.com/@englishmum?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Becky
        Fantham</a> / <a href=\\\"https://unsplash.com/?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\\\">Unsplash</a>\"},{\"id\":\"62d42bbd41e317003df48f23\",\"uuid\":\"62d8e394-15e5-4b65-81c5-cb6317b40e51\",\"title\":\"I
        spent the last five months in the hospital\",\"slug\":\"i-spent-the-last-five-months-in-the-hospital\",\"html\":\"<p>In
        January I woke up one day and couldn't move my right arm and leg properly.
        As I have high blood pressure, and my father had a stroke the exact day seven
        years ago, I worried that I might have a stroke and went to the emergency
        room of the local university hospital. My worries were confirmed and I was
        admitted to the stroke unit, spending the next six weeks in the hospital,
        including two stays in the intensive care unit because of complications (pneumonia
        and pulmonary embolism). </p><p>In March I was transferred to a rehab clinic
        where I spent the next three months training to walk and use my right arm
        again. I made good progress and was discharged home in early June, continuing
        with physiotherapy and ergotherapy from home. I feel much better now and for
        example took the train to Berlin last week to visit my mother.</p><p>I am
        very thankful for all the support I got from the doctors, nurses, and therapists
        at the hospital and rehab clinic, family and friends, and above all from my
        wife Petra. I am trained as a medical doctor specializing in internal medicine
        and cancer medicine, and that helped me better understand some of the things
        that happened to me. I hope to get back to work in September, but it will
        be much longer until my life is back to where it was before January. When
        I was feeling better after the first weeks in the hospital, I had a lot of
        time to think about what I wanted to do when I would get back home, and what
        priorities I want to set going forward. </p>\",\"comment_id\":\"62b2cd0609a96904e24bea50\",\"feature_image\":\"https://blog.front-matter.io/content/images/2022/07/IMG_5831-1.jpg\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2022-06-22T08:04:22.000+00:00\",\"updated_at\":\"2022-08-22T08:00:40.000+00:00\",\"published_at\":\"2022-07-28T11:45:56.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/bkkzj8g-gd14mb6\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"},\"url\":\"https://blog.front-matter.io/posts/i-spent-the-last-five-months-in-the-hospital/\",\"excerpt\":\"In
        January I woke up one day and couldn't move my right arm and leg properly.
        As I have high blood pressure, and my father had a stroke the exact day seven
        years ago, I worried that I might have a stroke and went to the emergency
        room of the local university hospital. My worries were confirmed and I was
        admitted to the stroke unit, spending the next six weeks in the hospital,
        including two stays in the intensive care unit because of complications (pneumonia
        and pulmonary embolism).\\n\\nIn March I w\",\"reading_time\":1,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":null},{\"id\":\"62d42bbd41e317003df48f21\",\"uuid\":\"defbb861-4454-4ca2-8b41-b94fc5fcfa1a\",\"title\":\"A
        new membership model for the Front Matter blog\",\"slug\":\"a-new-membership-model\",\"html\":\"<p>The
        Front Matter blog is launching a new membership model today. In August 2021
        this blog <a href=\\\"https://doi.org/10.53731/r8hb7h1-97aq74v-ag6ew\\\">started
        offering optional paid membership </a>via the <a href=\\\"https://www.buymeacoffee.com/\\\">Buy
        Me a Coffee</a> service. Unfortunately. two things happened: a) Paypal dropped
        supporting Buy Me a Coffee for membership payments at the end of last year,
        and b) there wasn't really any uptake of this support model, even if only
        charging $3 (or a cup of coffee) per month.</p><p>We are therefore doing two
        changes today:</p><ul><li>drop support for paid membership,</li><li>drop integration
        with Buy Me a Coffee and instead integrate with the built-in membership model
        of the Ghost blogging platform.</li></ul><p>Integrating with the built in
        membership of the Ghost blogging platform is not easy, as membership integration
        via official Ghost API calls is incomplete and this blog uses the popular
        <a href=\\\"https://jamstack.org/\\\">JAMstack</a> setup where backend (Ghost)
        and frontend (a custom open source solution built around Next.js) are separated
        into two separate services. We therefore need feedback by our users to iron
        out any glitches. The membership signup form is at the bottom of all category
        pages and the home page, and filling out the form triggers an email to confirm
        the membership. Users will then receive every blog post as email, as well
        as occasional emails from Front Matter staff.</p><p>For this convenience members
        allow Front Matter to track how many emails have been opened, helping Front
        Matter to collect feedback for the blog. Please report any issues you encounter
        to <a href=\\\"mailto:info@front-matter.io\\\">info@front-matter.io</a>.</p><p>We
        updated our <a href=\\\"https://blog.front-matter.io/pages/privacy-policy\\\">privacy
        policy</a> to reflect these changes. Most importantly, we are not tracking
        any personalized information without explicit user opt-in (for membership
        and/or authorship of blog posts). The usage stats of the Front Matter blog
        are collected by the <a href=\\\"https://plausible.io/\\\">Plausible Analytics</a>
        service and don't include any personal information such as IP addresses or
        detailed geographic information \u2013 in contrast to services such as the
        widely used Google Analytics which collects this and other personalized information
        (<a href=\\\"https://plausible.io/vs-google-analytics\\\">more background</a>).</p><p>We
        will continue to investigate other options to financially support this blogging
        platform. We are not interested in exclusive content only available to paying
        members, as this wouldn't align with Open Science principles. We are open
        to sponsorship and other suggestions.</p>\",\"comment_id\":\"61dbff2bbc59a908da86e39f\",\"feature_image\":\"https://blog.front-matter.io/content/images/2022/07/Bildschirmfoto-2022-01-14-um-16.43.39.png\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2022-01-10T09:40:59.000+00:00\",\"updated_at\":\"2022-07-30T16:11:30.000+00:00\",\"published_at\":\"2022-01-10T10:17:39.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/revzwnv-rpd913d-8drwz\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"},\"url\":\"https://blog.front-matter.io/posts/a-new-membership-model/\",\"excerpt\":\"The
        Front Matter blog is launching a new membership model today. In August 2021
        this blog started offering optional paid membership via the Buy Me a Coffee
        service. Unfortunately. two things happened: a) Paypal dropped supporting
        Buy Me a Coffee for membership payments at the end of last year, and b) there
        wasn't really any uptake of this support model, even if only charging $3 (or
        a cup of coffee) per month.\\n\\nWe are therefore doing two changes today:\\n\\n
        * drop support for paid membership,\\n * dro\",\"reading_time\":2,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":null},{\"id\":\"62d42bbd41e317003df48f1f\",\"uuid\":\"e6fbb566-367b-47c3-a2a9-5b0162313f4e\",\"title\":\"Starting
        2022 with a new feature: full-text search for the Front Matter blog\",\"slug\":\"full-text-search-front-matter-blog\",\"html\":\"<p>Fresh
        into 2022, the Front Matter blog today is launching an important new feature:
        a full-text search of all blog posts. An example query would be for <strong>reference
        manager.</strong></p><p>As the Front Matter blog has a lot of posts about
        reference managers, a tag would also have worked in this particular case,
        but tags are much less flexible and become overwhelming when used too frequently.</p><p>The
        reason that tags have historically been used heavily in blogging platforms
        is technical, not that they provide the best user interface to find blog content.
        Relational databases such as MySQL that power blogging platforms \_(including
        Front Matter) are not good at full-text search, and a separate tool is needed.
        Solr and Elasticsearch are two widely used tools to provide full-text search.
        They are not trivial to set up and thus not used very often for full-text
        search of blogs. A popular alternative is a hosted search platform such as
        <a href=\\\"https://algolia.com\\\">Algolia</a>. </p><p>The full-text search
        Front Matter is launching today is built using <a href=\\\"https://typesense.org/\\\">Typesense</a>,
        open source software that is much easier to set up and maintain than Elasticsearch,
        and with a pricing model that is a better fit for Front Matter than Algolia
        \u2013 either self-hosted or in this case hosted by Typesense.org with a fee
        based on size and number of nodes in the cluster, not the number of requests
        as with Algolia.</p><figure class=\\\"kg-card kg-image-card\\\"><img src=\\\"https://blog.front-matter.io/content/images/2022/07/Bildschirmfoto-2022-01-03-um-13.04.27.png\\\"
        class=\\\"kg-image\\\" alt loading=\\\"lazy\\\" width=\\\"1229\\\" height=\\\"743\\\"
        srcset=\\\"https://blog.front-matter.io/content/images/size/w600/2022/07/Bildschirmfoto-2022-01-03-um-13.04.27.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/07/Bildschirmfoto-2022-01-03-um-13.04.27.png
        1000w, https://blog.front-matter.io/content/images/2022/07/Bildschirmfoto-2022-01-03-um-13.04.27.png
        1229w\\\" sizes=\\\"(min-width: 720px) 720px\\\"></figure><p>The new search
        functionality includes a small refactoring of pagination and filtering by
        tags that now are powered by Typesense, and are linked to the URL in the browser
        to make it easy to share search results, e.g. <a href=\\\"https://blog.front-matter.io/?query=reference+manager&amp;page=2\\\">https://blog.front-matter.io/?query=reference+manager&amp;page=2</a>.
        Tags are used for eight high-level categories of related content displayed
        on top of each page, but there are no plans to generate lots of additional
        tags for each blog post, as the full-text search obsoletes that need. Indexing
        in Typesense happens every time a blog post is published or updated, with
        negligible overhead and fully automated. </p><p>Front Matter is not the only
        place you can search for Front Matter blog posts. As all blog posts and core
        metadata are registered with a Crossref DOI, you can also search <a href=\\\"https://search.crossref.org\\\">Crossref
        Metadata Search</a>, for example, <a href=\\\"https://search.crossref.org/?q=reference+manager+overview&amp;from_ui=yes\\\">https://search.crossref.org/?q=reference+manager+overview&amp;from_ui=yes</a>,
        or all the other places where you find indexed Crossref DOIs that includes
        Front Matter content.</p><p>As this is version 1.0 of Front Matter full-text
        search, we expect to make adjustments based on user feedback in the coming
        months, but the new feature is available as of today, so please start 2022
        searching away. A good starting point would be a quick search and read on
        a mobile phone while on a commuter train, assuming you are not locked down
        in a home office. </p><p>The new search functionality is part of the <strong>bloggable</strong>
        open source library that powers this blog and is <a href=\\\"https://github.com/front-matter/bloggable\\\">available
        via GitHub.</a></p><p><em>Update Jan 4, 2022: Added link to source code.</em></p>\",\"comment_id\":\"61d2af9a0638d704e96c111b\",\"feature_image\":\"https://blog.front-matter.io/content/images/2022/07/Bildschirmfoto-2022-01-03-um-12.47.12.png\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2022-01-03T08:11:06.000+00:00\",\"updated_at\":\"2022-07-30T16:13:58.000+00:00\",\"published_at\":\"2022-01-03T12:55:46.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/rejnyd0-ce6q0km-pr48v\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42bbc41e317003df48d4e\",\"name\":\"Feature\",\"slug\":\"feature\",\"description\":\"Features
        explore issues raised by news stories in more depth.\",\"feature_image\":\"https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fHJlc2VhcmNofGVufDB8fHx8MTYxODEyMzQxNQ&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/feature/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42bbc41e317003df48d4e\",\"name\":\"Feature\",\"slug\":\"feature\",\"description\":\"Features
        explore issues raised by news stories in more depth.\",\"feature_image\":\"https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fHJlc2VhcmNofGVufDB8fHx8MTYxODEyMzQxNQ&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/feature/\"},\"url\":\"https://blog.front-matter.io/posts/full-text-search-front-matter-blog/\",\"excerpt\":\"Fresh
        into 2022, the Front Matter blog today is launching an important new feature:
        a full-text search of all blog posts. An example query would be for reference
        manager.\\n\\nAs the Front Matter blog has a lot of posts about reference
        managers, a tag would also have worked in this particular case, but tags are
        much less flexible and become overwhelming when used too frequently.\\n\\nThe
        reason that tags have historically been used heavily in blogging platforms
        is technical, not that they provide the be\",\"reading_time\":2,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":null},{\"id\":\"62d42bbd41e317003df48f1e\",\"uuid\":\"9f6d28c4-57f7-4db9-ab78-395ad7205741\",\"title\":\"Improving
        software metadata conversion by adding CFF support\",\"slug\":\"improving-software-metadata-conversion\",\"html\":\"<p>In
        August GitHub added <a href=\\\"https://doi.org/10.53731/r9531p1-97aq74v-ag78v\\\">enhanced
        support for citation-file-format</a> (CFF) to all GitHub repositories. As
        you can see in the chart below (kindly provided by <a href=\\\"https://github.com/sdruskat\\\">Stephan
        Druskat</a> and based on GitHub queries for CFF files), this has led to a
        significant increase of repositories using CFF files and thus exposing software
        metadata that go beyond what GitHub provides via other means.</p><p>CFF support
        in GitHub provides an important building block that can be enhanced by a)
        making it easier to generate CFF files (text files using the <a href=\\\"https://en.wikipedia.org/wiki/YAML\\\">YAML</a>
        format and stored in the repository root folder), and b) converting the CFF
        into other metadata formats to make reuse easier elsewhere.</p><p>In 2017
        I started the metadata conversion library <a href=\\\"https://github.com/datacite/bolognese\\\">bolognese</a>
        that is heavily used internally by DataCite, focussing on the conversion of
        DOI metadata. During the <a href=\\\"https://doi.org/10.53731/rckvde5-tzg61kj-7zvc1\\\">Force2021
        hackathon</a> last week I expanded the bolognese library to support CFF conversion,
        and to allow the writing of DOI metadata in the Crossref XML format (not used
        for software metadata, but to <a href=\\\"https://doi.org/10.53731/rbjgna1-97aq74v-ag811\\\">register
        Crossref DOIs for this blog</a>). As these two changes are currently not a
        priority for the DataCite development team, it was easier to fork the bolognese
        software, so I started the <a href=\\\"https://rubygems.org/gems/briard\\\">briard
        Ruby gem</a>. For naming the new Ruby gem, I have continued the tradition
        I started almost 10 years ago of using dog breed names to name software libraries.</p><figure
        class=\\\"kg-card kg-image-card kg-card-hascaption\\\"><img src=\\\"https://blog.front-matter.io/content/images/2022/07/1024px-Briard_R_01_Puppy.jpeg\\\"
        class=\\\"kg-image\\\" alt loading=\\\"lazy\\\" width=\\\"1024\\\" height=\\\"685\\\"
        srcset=\\\"https://blog.front-matter.io/content/images/size/w600/2022/07/1024px-Briard_R_01_Puppy.jpeg
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/07/1024px-Briard_R_01_Puppy.jpeg
        1000w, https://blog.front-matter.io/content/images/2022/07/1024px-Briard_R_01_Puppy.jpeg
        1024w\\\" sizes=\\\"(min-width: 720px) 720px\\\"><figcaption>Briard dog. From
        https://commons.wikimedia.org/wiki/File:Briard_R_01_Puppy.jpg, using a CC
        BY SA license.</figcaption></figure><p>You can install briard via the command
        line with <code>gem install briard</code>, enabling reading and writing of
        CFF metadata via Ruby code or the command line:</p><p>Convert CFF metadata
        for the <strong>ruby-cff </strong>library into a formatted citation using
        the <strong>Vancouver</strong> citation style and the German language locale:
        </p><!--kg-card-begin: markdown--><pre><code>briard https://github.com/citation-file-format/ruby-cff
        -t citation --style vancouver --locale de\\n\\nHaines R, The Ruby Citation
        File Format Developers. Ruby CFF Library [Internet]. GitHub. GitHub; 2021.
        Verf\xFCgbar unter: https://github.com/citation-file-format/ruby-cff\\n</code></pre>\\n<!--kg-card-end:
        markdown--><p>Generate a CFF file from a GitHub repository archived in Zenodo
        with DOI metadata:</p><!--kg-card-begin: markdown--><pre><code>briard 10.5281/zenodo.5217599
        -t cff\\n\\n---\\ncff-version: 1.2.0\\nmessage: If you use Ruby CFF Library
        in your work, please cite it using the following\\n  metadata\\ndoi: https://doi.org/10.5281/zenodo.5217599\\nrepository-code:
        https://zenodo.org/record/5217599\\ntitle: Ruby CFF Library\\nauthors:\\n-
        given-names: Robert\\n  family-names: Haines\\n  orcid: https://orcid.org/0000-0002-9538-7919\\n
        \ affiliation: The University of Manchester, UK\\n- name: The Ruby Citation
        File Format Developers\\nabstract: This library provides a Ruby interface
        to manipulate Citation File Format\\n  files\\nversion: 0.9.0\\nkeywords:\\n-
        ruby\\n- credit\\n- software citation\\n- research software\\n- software sustainability\\n-
        metadata\\n- citation file format\\n- CFF\\ndate-released: '2021-08-18'\\nreferences:\\n
        \ identifiers:\\n  - type: url\\n    value: https://github.com/citation-file-format/ruby-cff/tree/v0.9.0\\n
        \ - type: doi\\n    value: 10.5281/zenodo.1184077\\n  - type: url\\n    value:
        https://zenodo.org/communities/zenodo\\n</code></pre>\\n<!--kg-card-end: markdown--><p>As
        a command-line tool, briard can be integrated with a number of workflows,
        including <a href=\\\"https://docs.github.com/en/actions\\\">GitHub Actions</a>
        used in GitHub software development workflows.</p><p>Ultimately the goal is
        to increase the adoption of richer metadata for open source software, which
        in turn will enable important use cases from discovery to academic credit.
        As of today, <a href=\\\"https://commons.datacite.org/doi.org?query=*&amp;resource-type=software\\\">251,633
        DataCite DOIs have been registered for software</a>, including <a href=\\\"https://commons.datacite.org/doi.org?query=client.uid%3Acern.zenodo&amp;resource-type=software\\\">218,810
        DOIs (87.0%) via the Zenodo repository</a>. The briard library makes it straightforward
        to convert the metadata for these software libraries into CFF files that can
        then be stored with the source code repository. A good starting point would
        be the GitHub/Zenodo integration, where we could add CFF files to the GitHub
        repository (if not yet existing) in addition to writing DOI metadata.</p><p>Obviously
        not all source code for software DOIs is stored in GitHub, and for this reason,
        Stephan Druskat and I started to look into how to add similar <a href=\\\"https://gitlab.com/sdruskat/gitlab\\\">software
        citation functionality to GitLab</a> in the Force2021 hackathon last week.
        </p><h3 id=\\\"references\\\">References</h3><p>Fenner M. A step forward for
        software citation: GitHub\u2019s enhanced software citation support. Published
        online August 24, 2021. doi:<a href=\\\"https://doi.org/10.53731/r9531p1-97aq74v-ag78v\\\">10.53731/r9531p1-97aq74v-ag78v</a></p><p>Fenner
        M. Join us for the Force2021 Hackathon. Published online November 16, 2021.
        doi:<a href=\\\"https://doi.org/10.53731/rckvde5-tzg61kj-7zvc1\\\">10.53731/rckvde5-tzg61kj-7zvc1</a></p><p>Fenner
        M. Registering content with Crossref or DataCite. Published online October
        22, 2021. doi:<a href=\\\"https://doi.org/10.53731/rbjgna1-97aq74v-ag811\\\">10.53731/rbjgna1-97aq74v-ag811</a></p><p>Fenner
        M. Briard. Published online December 16, 2021. doi:<a href=\\\"https://doi.org/10.5281/ZENODO.5785519\\\">10.5281/ZENODO.5785519</a></p>\",\"comment_id\":\"61bb04bd7dd9675265fe5ff0\",\"feature_image\":\"https://blog.front-matter.io/content/images/2022/07/cff_counts-1.png\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2021-12-16T09:19:57.000+00:00\",\"updated_at\":\"2023-07-03T10:10:29.000+00:00\",\"published_at\":\"2021-12-16T10:23:27.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/rdv0jyq-vpb7a9j-zwqzg\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42a7be1424c003158c328\",\"name\":\"News\",\"slug\":\"news\",\"description\":null,\"feature_image\":\"https://images.unsplash.com/photo-1546422904-90eab23c3d7e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fG5ld3N8ZW58MHx8fHwxNjYwNTk1NzUy&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/news/\"},\"url\":\"https://blog.front-matter.io/posts/improving-software-metadata-conversion/\",\"excerpt\":\"In
        August GitHub added enhanced support for citation-file-format (CFF) to all
        GitHub repositories. As you can see in the chart below (kindly provided by
        Stephan Druskat and based on GitHub queries for CFF files), this has led to
        a significant increase of repositories using CFF files and thus exposing software
        metadata that go beyond what GitHub provides via other means.\\n\\nCFF support
        in GitHub provides an important building block that can be enhanced by a)
        making it easier to generate CFF files (\",\"reading_time\":3,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":null},{\"id\":\"62d42bbd41e317003df48f1d\",\"uuid\":\"f5161e66-8088-46d5-8e06-f7e821629c7f\",\"title\":\"Join
        us for the Force2021 Hackathon\",\"slug\":\"join-us-for-the-force2021-hackathon\",\"html\":\"<p>The
        <a href=\\\"https://force2021.sched.com/\\\">Force2021 conference</a> will
        take place from December 7-9. The conference will be virtual, and <a href=\\\"https://www.eventbrite.com/e/force2021-tickets-94730321943\\\">registration</a>
        is free. And we will again be hosting a Force2021 hackathon, as co-located
        virtual event on December 6 and December 10. We will meet for four hours each
        (1 PM - 5 PM GMT) and will communicate via Zoom. Please check the tick box
        in the Force2021 registration form if you also want to participate in the
        hackathon, we will follow up with more logistics as we get closer to the event.
        </p><p>The overall theme of the hackathon is software citation, and it is
        coordinated by the Force11 Software Citation Implementation WG and <a href=\\\"https://scicodes.net/\\\">Scicodes</a>.
        This is a hackathon that is not only about code writing, but any collaborative
        activity around the overall theme. You can suggest a hackathon topic in the
        <a href=\\\"https://github.com/force11/force11-sciwg/issues\\\">Force11 Software
        Citation Implementation WG Issue Tracker</a>, but we make the final decision
        about topics and teams on December 6. Some ideas that have been expressed
        include:</p><ul><li>Improve Codemeta documentation and examples (add links
        to existing tools)</li><li>Update crosswalk between CITATION.cff and codemeta</li><li>Do
        crosswalk from BibLaTeX to codemeta</li><li>Improve citation style support
        in GitHub CFF implementation</li><li>Thinking session: tracking the impact
        of good metadata</li><li>if there will be a developer from SWH - Implement
        citation button for directories with codemeta or CFF (<a href=\\\"https://forge.softwareheritage.org/T3494\\\">T3494</a>)</li><li>Update
        the GitHub citable code guide <a href=\\\"https://guides.github.com/activities/citable-code/\\\">https://guides.github.com/activities/citable-code/</a>.</li><li>Write
        a GitHub Action to help authors keep their CFF files up to date (e.g., when
        a new release is published)</li><li>Write a GitHub Action (with configuration
        options) that allow people to follow best practices with their software citation
        practices (e.g., semantic versioning, archiving, generating metadata (Codemeta,
        CFF), ...)</li><li>Improve the codemeta generator tool</li><li>Discuss on
        how to have a support system for creating metadata/citation files</li><li>Get
        support for your metadata problems</li></ul><p>And please also join us for
        the main Force2021 conference. In particular on Tuesday December 7 at 5 PM
        UTC for the <a href=\\\"https://force2021.sched.com/event/pusm/deep-dive-software-citation\\\">Software
        citation deep dive</a> session.</p><p>Comment on the <a href=\\\"https://github.com/force11/force11-sciwg/issues\\\">Force11
        Software Citation Implementation WG Issue Tracker</a> or reach out to <a href=\\\"mailto:martin@front-matter.io\\\">me</a>
        if you have any comments or questions, and I hope to see many of you on December
        6.</p>\",\"comment_id\":\"6193db5c5d7e060ce47fed81\",\"feature_image\":\"https://blog.front-matter.io/content/images/2022/07/spoton12_hack-3.jpeg\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2021-11-16T16:25:00.000+00:00\",\"updated_at\":\"2023-09-05T20:48:51.000+00:00\",\"published_at\":\"2021-11-16T17:02:26.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/rckvde5-tzg61kj-7zvc1\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42bbc41e317003df48d48\",\"name\":\"Meeting
        Report\",\"slug\":\"meeting-report\",\"description\":\"Reports from conferences
        and workshops of interest to the scholarly community.\",\"feature_image\":\"https://images.unsplash.com/photo-1503428593586-e225b39bddfe?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDN8fGNvbmZlcmVuY2V8ZW58MHx8fHwxNjE4MTI0NDQw&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":\"#FFFFFF\",\"url\":\"https://blog.front-matter.io/tag/meeting-report/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42bbc41e317003df48d48\",\"name\":\"Meeting
        Report\",\"slug\":\"meeting-report\",\"description\":\"Reports from conferences
        and workshops of interest to the scholarly community.\",\"feature_image\":\"https://images.unsplash.com/photo-1503428593586-e225b39bddfe?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDN8fGNvbmZlcmVuY2V8ZW58MHx8fHwxNjE4MTI0NDQw&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":\"#FFFFFF\",\"url\":\"https://blog.front-matter.io/tag/meeting-report/\"},\"url\":\"https://blog.front-matter.io/posts/join-us-for-the-force2021-hackathon/\",\"excerpt\":\"The
        Force2021 conference will take place from December 7-9. The conference will
        be virtual, and registration is free. And we will again be hosting a Force2021
        hackathon, as co-located virtual event on December 6 and December 10. We will
        meet for four hours each (1 PM - 5 PM GMT) and will communicate via Zoom.
        Please check the tick box in the Force2021 registration form if you also want
        to participate in the hackathon, we will follow up with more logistics as
        we get closer to the event.\\n\\nThe over\",\"reading_time\":2,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":\"<em>Matias
        Piipari at the <a href=\\\"https://doi.org/10.53731/r294649-6f79289-8cw0s\\\">Spoton
        London 2012 hackathon</a>. Picture from </em><a href=\\\"http://www.flickr.com/photos/25467658@N00/8252989528/\\\"><em><em>Flickr</em></em></a><em>,
        taken by Lou Woodley.</em>\"},{\"id\":\"62d42bbd41e317003df48f1c\",\"uuid\":\"c023d7c2-a57a-4085-8bad-f265584b82bd\",\"title\":\"Dryad:
        Interview with Jen Gibson\",\"slug\":\"dryad-interview-jen-gibson\",\"html\":\"<p>In
        October Jen Gibson started as the new Executive Director for the Dryad Data
        Repository. I used the opportunity to ask Jen a few questions about Dryad,
        challenges with data sharing, and ideas about moving Dryad forward. I was
        particularly interested in the interview as I served on the Dryad Board of
        Directors from 2013 to 2016. In fact, one post on this blog is about a presentation
        I gave in 2013 (<a href=\\\"https://doi.org/10.53731/r294649-6f79289-8cw1x\\\">Metrics
        and attribution: my thoughts for the panel at the ORCID-Dryad symposium on
        research attribution</a>).</p><h3 id=\\\"1-can-you-describe-what-dryad-is\\\">1.
        Can you describe what Dryad is?</h3><p>Dryad is an open data publishing platform
        and community committed to the open availability and routine re-use of all
        research data. We\u2019re a generalist, curated data repository \u2013 working
        with researchers across disciplines to assemble details about their work and
        their data to increase its discoverability and use by others. We\u2019re a
        non-profit initiative working in partnership with other systems and communities
        working to advance open research.</p><h3 id=\\\"2-are-there-data-that-should-not-be-submitted-to-dryad\\\">2.
        Are there data that should not be submitted to Dryad?</h3><p>Dryad is designed
        to support openly accessible and fully re-usable data, and publishes under
        a Creative Commons Public Domain License (CC0). So, we\u2019re not able to
        publish data with incompatible licensing terms. We also don\u2019t accept
        datasets that contain personally identifiable human subject information or
        specific locations for endangered species \u2013 but our team of curators
        will work with researchers to see if the data can be made appropriate for
        sharing. </p><h3 id=\\\"3-are-there-limits-in-the-number-or-size-of-files-in-a-data-submission\\\">3.
        Are there limits in the number or size of files in a data submission?</h3><p>We
        can accept up to 300GB per dataset and thousands of files, but curators are
        looking for the most accessible file types and downloads to support re-use.
        So, we ask that files be small and zipped when possible. Users with files
        larger than 300GB are asked simply to contact us to coordinate. </p><h3 id=\\\"4-does-dryad-also-accept-software-submissions\\\">4.
        Does Dryad also accept software submissions?</h3><p>No, Dryad only publishes
        data. So, we\u2019ve partnered with <a href=\\\"https://zenodo.org\\\">Zenodo</a>
        so that users can load software and other supplementary information at the
        same time that they load data to Dryad. Software can then be made available
        under a different, more appropriate license and be given its own citation,
        but is also linked from the data publication at Dryad.</p><h3 id=\\\"5-does-a-data-submission-to-dryad-cost-money\\\">5.
        Does a data submission to Dryad cost money?</h3><p>Yes. Often the cost to
        researchers is covered or discounted through an arrangement with their institution,
        publisher, or funder. Where there is not yet an arrangement in place, the
        submitting researcher is asked to pay $120 \u2013 with overage fees if the
        data is larger than 300GB. Waivers are, of course, available. Publication
        fees, memberships, and partnerships with institutions, publishers and funders
        help cover our costs for data curation and long-term preservation.</p><h3
        id=\\\"6-what-are-the-main-challenges-for-authors\\\">6. What are the main
        challenges for authors?</h3><p>There are so many challenges for researchers
        with respect to open sharing of data \u2013 and they\u2019re different in
        every discipline. There are behaviour changes, and workflow changes and culture
        changes to overcome \u2013 although several disciplines have carved a path,
        including astronomy and ecology. I hope that the open data-sharing around
        COVID will help inspire more people to follow suit.</p><p>Dryad helps to overcome
        these challenges, of course. We help first of all by helping to make it <em>possible</em>
        to share data properly \u2013 openly, with a CC0 license, and second by making
        it <em>easy</em> to share data through our friendly user interface and our
        integrations with publishers and partners such as Zenodo. (With the terms
        \u2018possible, easy, rewarding and normative,\u2019 I\u2019m invoking Brian
        Nosek\u2019s <a href=\\\"https://www.cos.io/blog/strategy-for-culture-change\\\">Strategy
        for Culture Change</a>).</p><p>We\u2019re helping to make data sharing <em>rewarding</em>
        by standardising usage metrics (through <a href=\\\"https://makedatacount.org/\\\">Make
        Data Count</a> \u2013 an important, community-led initiative to develop metrics
        for open research data assessment) and encouraging citation, though these
        are just a couple of the pieces needed to put data and data sharing at the
        centre of research assessment.</p><p>Finally, what I\u2019m very much looking
        forward to doing with Dryad is supporting and building communities that share
        and re-use data to make this practice <em>normative</em>. Connecting people
        with people \u2013 and people with data \u2013 is key in nurturing and normalising
        the regular exchange and re-use of data. </p><h3 id=\\\"7-why-should-authors-submit-their-data-to-dryad\\\">7.
        Why should authors submit their data to Dryad?</h3><p>Authors whose communities
        don\u2019t already rely on a domain repository for data, such as WormBase
        or the Protein Data Bank, should publish their data with Dryad because:</p><ul><li>Our
        curation service increases the quality and discoverability of new data, by
        ensuring key descriptive information (metadata) is available alongside the
        data itself</li><li>Our curation service increases the integrity of new data,
        by ensuring it\u2019s readable and usable by other users</li><li>We put data
        in context, with links to publications, software, institutions, funders and
        more</li><li>Data published in Dryad is citable and accessible via a persistent
        DOI</li><li>As a non-profit and open-source initiative, our values are closely
        aligned with the research community</li><li>It\u2019s easy, and affordable
        </li></ul><h3 id=\\\"8-how-can-authors-give-feedback-eg-to-report-problems-or-request-features\\\">8.
        How can authors give feedback, e.g. to report problems or request features?</h3><p>We
        are an open source project and our work is driven by researchers' needs. Get
        in touch with the help desk to discuss feature needs with our product team
        or leave a ticket on our public <a href=\\\"https://github.com/CDL-Dryad/dryad-product-roadmap/projects/1\\\">Github
        product board</a>.</p><h3 id=\\\"9-what-did-you-do-before-starting-to-work-for-dryad\\\">9.
        What did you do before starting to work for Dryad?</h3><p>I\u2019ve worked
        in open research since 2005, when I joined <a href=\\\"https://sparcopen.org/\\\">SPARC</a>
        \u2013 the Scholarly Publishing and Academic Resources Coalition \u2013 to
        work on open-access advocacy and policy efforts. Immediately before Dryad
        I was a founding member of the team for eLife \u2013 the open-access journal
        for biology and medicine and initiative from three of the largest, most prestigious,
        private biomedical research funders to put science publishing back in the
        hands of science. I\u2019d say my main contributions so far have been in building
        communities (among librarians, open science advocates, students, early-career
        or late-stage researchers, and others), advocacy (for open research practice
        at different levels of practice and policy), and adoption strategies (for
        researchers in particular). </p><h3 id=\\\"10-do-you-want-to-talk-about-future-plans-for-dryad\\\">10.
        Do you want to talk about future plans for Dryad?</h3><p>Absolutely. Beyond
        my near-term objectives for optimising operations, I expect us to be:</p><ul><li>Leveraging
        support from institutions and expanding our membership program.</li><li>Working
        with our publisher partners to attract as much data as possible.</li><li>More
        actively diversifying our profile \u2013 specifically reaching out to different
        geographic and disciplinary communities.</li><li>Expanding our roadmap for
        modeling data publishing into the future, building on our progress over the
        last couple of years.</li></ul><p>Longer term, I\u2019m enthusiastic about
        the potential for pushing data to the forefront of discovery, and taking steps
        to facilitate re-use and extend credit. Like Make Data Count, Dryad is committed
        to making data a first-class citizen in research and research assessment,
        and I'll be really pleased if we\u2019re able to help properly reward researchers
        for their data publications. We\u2019re going to need to, to really accelerate
        discovery and build that open, global network for the exchange of research
        objects.</p>\",\"comment_id\":\"618e89ed5d7e060ce47fecc3\",\"feature_image\":\"https://blog.front-matter.io/content/images/2022/07/jgibson.png\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2021-11-12T15:36:13.000+00:00\",\"updated_at\":\"2022-08-15T18:56:27.000+00:00\",\"published_at\":\"2021-11-15T10:52:02.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/rceh7pn-tzg61kj-7zv63\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42bbc41e317003df48d49\",\"name\":\"Interview\",\"slug\":\"interview\",\"description\":\"Interviews
        with interesting people in scholarly communication.\",\"feature_image\":\"https://images.unsplash.com/photo-1497015455546-1da71faf8d06?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDV8fGludGVydmlld3xlbnwwfHx8fDE2MTgxMjM2Mjk&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":\"#FFFFFF\",\"url\":\"https://blog.front-matter.io/tag/interview/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42bbc41e317003df48d49\",\"name\":\"Interview\",\"slug\":\"interview\",\"description\":\"Interviews
        with interesting people in scholarly communication.\",\"feature_image\":\"https://images.unsplash.com/photo-1497015455546-1da71faf8d06?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDV8fGludGVydmlld3xlbnwwfHx8fDE2MTgxMjM2Mjk&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":\"#FFFFFF\",\"url\":\"https://blog.front-matter.io/tag/interview/\"},\"url\":\"https://blog.front-matter.io/posts/dryad-interview-jen-gibson/\",\"excerpt\":\"In
        October Jen Gibson started as the new Executive Director for the Dryad Data
        Repository. I used the opportunity to ask Jen a few questions about Dryad,
        challenges with data sharing, and ideas about moving Dryad forward. I was
        particularly interested in the interview as I served on the Dryad Board of
        Directors from 2013 to 2016. In fact, one post on this blog is about a presentation
        I gave in 2013 (Metrics and attribution: my thoughts for the panel at the
        ORCID-Dryad symposium on research attri\",\"reading_time\":4,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":\"Jennifer
        Gibson\"},{\"id\":\"62d42bbd41e317003df48f1b\",\"uuid\":\"d6f5881f-f358-4fd2-a960-d9cc54901b52\",\"title\":\"Open
        Citation Data reach critical Milestone\",\"slug\":\"open-citation-data-reach-critical-milestone\",\"html\":\"<p>Last
        Friday the OpenCitations blog <a href=\\\"https://opencitations.wordpress.com/2021/10/27/coverage-of-open-citation-data-approaches-parity-with-web-of-science-and-scopus/\\\">published
        a guest post</a> by <a href=\\\"mailto:albertomartin@ugr.es\\\">Alberto Mart\xEDn-Mart\xEDn</a>
        that describes the coverage by <a href=\\\"https://opencitations.net/index/coci\\\">COCI</a>
        and other open citation data compared to subscription citation indexes. This
        is an important blog post, as it changes how we think about citations and
        open metrics.</p><p><strong><strong><a href=\\\"https://opencitations.net/index/coci\\\">COCI</a></strong></strong>
        is the OpenCitations Index of Crossref open DOI-to-DOI citations, based on
        the open references made available by Crossref in the context of the Initiative
        for Open Citations (<a href=\\\"https://i4oc.org/\\\">I4OC</a>). As of October
        2021, 88% of the 56.9 million articles with references deposited with Crossref
        have open references.</p><figure class=\\\"kg-card kg-image-card kg-card-hascaption\\\"><img
        src=\\\"https://blog.front-matter.io/content/images/2022/07/Bildschirmfoto-2021-11-04-um-09.08.20.png\\\"
        class=\\\"kg-image\\\" alt loading=\\\"lazy\\\" width=\\\"820\\\" height=\\\"245\\\"
        srcset=\\\"https://blog.front-matter.io/content/images/size/w600/2022/07/Bildschirmfoto-2021-11-04-um-09.08.20.png
        600w, https://blog.front-matter.io/content/images/2022/07/Bildschirmfoto-2021-11-04-um-09.08.20.png
        820w\\\" sizes=\\\"(min-width: 720px) 720px\\\"><figcaption>via https://i4oc.org/#faqs</figcaption></figure><p>I4OC,
        together with Crossref members, Crossref, and OpenCitations has come a long
        way since it started in 2017, and I am proud that I played a small role in
        getting I4OC started. Please keep in mind that not all Crossref members submit
        references for their DOIs. Crossref has issued 128 million DOIs for scholarly
        content to date, including 91 million DOIs for journal articles. Also, Crossref
        is including these open references in its <a href=\\\"https://www.crossref.org/documentation/retrieve-metadata/rest-api/\\\">REST
        API</a>, but is currently not making the processed references (aggregating
        them by cited DOI) openly available. The Crossref REST API provides the citation
        count as <code>referenced-by-count</code>, to see the actual references you
        need to either be a Crossref member participating in the <a href=\\\"https://www.crossref.org/services/cited-by/\\\">Crossref
        cited-by service</a>, or use COCI and other open citation indexes.</p><p>With
        the number of open references closing in on 90%, this is now a good time to
        take a closer look at the coverage of these open citation data compared to
        other available citation indexes and compare the results to the situation
        in 2019. And this is exactly what Alberto Mart\xEDn-Mart\xEDn and colleagues
        have done. Their 2019 analysis was published in 2020 (<a href=\\\"https://doi.org/10.1007/s11192-020-03690-4\\\">Mart\xEDn-Mart\xEDn
        et al. 2020</a>) and looked at 2,515 highly-cited English-language documents
        published in 2006 from 252 subject categories, and the citations to these
        publications found in the following services:</p><ul><li><a href=\\\"https://scholar.google.com/\\\">Google
        Scholar</a></li><li><a href=\\\"https://academic.microsoft.com/\\\">Microsoft
        Academic</a></li><li><a href=\\\"https://www.scopus.com/\\\">Scopus</a></li><li><a
        href=\\\"https://www.digital-science.com/product/dimensions/\\\">Dimensions</a></li><li><a
        href=\\\"https://clarivate.libguides.com/webofscienceplatform/woscc\\\">Web
        of Science Core Collection (WoS)</a></li><li><a href=\\\"https://opencitations.net/index/coci\\\">COCI</a></li></ul><p>In
        the 2020 publication, Google Scholar found the most citations with 88%, and
        COCI found the least citations with 28% (and Microsoft Academic 60%, Scopus
        57%, Dimensions 54%, and WoS 52%). The new analysis done for COCI with August
        2021 Crossref data for the same 2,515 papers published in 2006, and for citing
        papers published until 2019 shows a significant difference, with COCI now
        covering 50% of citations, or 53% when combined with the <a href=\\\"https://doi.org/10.1371/journal.pbio.3000385\\\">NIH
        Open Citation Collection</a>, another index of open citations.</p><figure
        class=\\\"kg-card kg-image-card kg-card-hascaption\\\"><img src=\\\"https://blog.front-matter.io/content/images/2022/07/albertos-coci-post-final-fig-1.png\\\"
        class=\\\"kg-image\\\" alt loading=\\\"lazy\\\" width=\\\"1024\\\" height=\\\"1005\\\"
        srcset=\\\"https://blog.front-matter.io/content/images/size/w600/2022/07/albertos-coci-post-final-fig-1.png
        600w, https://blog.front-matter.io/content/images/size/w1000/2022/07/albertos-coci-post-final-fig-1.png
        1000w, https://blog.front-matter.io/content/images/2022/07/albertos-coci-post-final-fig-1.png
        1024w\\\" sizes=\\\"(min-width: 720px) 720px\\\"><figcaption><em><em>Percentage
        of citations found by each database, relative to all citations (first row),
        and relative to the number of citations found by the other databases (subsequent
        rows).</em> From the <a href=\\\"https://opencitations.wordpress.com/2021/10/27/coverage-of-open-citation-data-approaches-parity-with-web-of-science-and-scopus/\\\">OpenCitations
        blog</a>.</em></figcaption></figure><p>These findings change everything, as
        coverage by open citation indexes is now comparable to the commercial services
        Web of Science, Scopus and Dimensions. Microsoft announced in May that Microsoft
        Academic will <a href=\\\"https://www.microsoft.com/en-us/research/project/academic/articles/microsoft-academic-to-expand-horizons-with-community-driven-approach/\\\">retire
        at the end of 2021</a>. And Google Scholar plays a special role, as it has
        the best coverage, but no API access (free or paid), making it basically impossible
        to build services on top of Google Scholar. A rather unusual decision by Google
        (compare to e.g. Google Maps) that can only be explained by existing license
        agreements with publishers.</p><p>The analysis was done using 2,515 papers
        published in 2006, and there are small differences between service providers
        depending on the subject area. As this was an analysis based on Crossref DOIs,
        the analysis misses citing publications not registered with Crossref, or not
        making their references available to Crossref. And the analysis focused on
        coverage, not looking at other aspects of the services provided. More work
        needs to happen in the coming years on these topics.</p><p>But the main conclusion
        is very clear: open citation indexes are comparable in terms of coverage to
        subscription citation services, and the decision to use a subscription service
        should be based on convenience rather than coverage. I can't emphasize enough
        the importance of this critical milestone, and I congratulate Alberto Mart\xEDn-Mart\xEDn
        and his team on doing this work.</p><p>I would not be surprised to see comments
        and publications in the coming weeks and months arguing with these findings.
        This reminds me of a discussion we had about 15 years ago comparing the reliability
        of Wikipedia compared to the Encyclopedia Britannica, started by a study published
        in <em>Nature</em> (<a href=\\\"https://doi.org/10.1038/438900a\\\">Giles
        2015, Internet encyclopaedias go head to head</a>). I fully expect the final
        outcome here to be similar.</p><h3 id=\\\"references\\\">References</h3><p>Shotton
        D. Coverage of open citation data approaches parity with Web of Science and
        Scopus. OpenCitations blog. Published October 27, 2021. Accessed July 2, 2023.
        <a href=\\\"https://opencitations.wordpress.com/2021/10/27/coverage-of-open-citation-data-approaches-parity-with-web-of-science-and-scopus/\\\">https://opencitations.wordpress.com/2021/10/27/coverage-of-open-citation-data-approaches-parity-with-web-of-science-and-scopus/</a></p><p>Mart\xEDn-Mart\xEDn
        A, Thelwall M, Orduna-Malea E, Delgado L\xF3pez-C\xF3zar E. Google Scholar,
        Microsoft Academic, Scopus, Dimensions, Web of Science, and OpenCitations\u2019
        COCI: a multidisciplinary comparison of coverage via citations. <em>Scientometrics</em>.
        2021;126(1):871-906. doi:<a href=\\\"https://doi.org/10.1007/s11192-020-03690-4\\\">10.1007/s11192-020-03690-4</a></p><p>Giles
        J. Internet encyclopaedias go head to head. <em>Nature</em>. 2005;438(7070):900-901.
        doi:<a href=\\\"https://doi.org/10.1038/438900a\\\">10.1038/438900a</a></p>\",\"comment_id\":\"618391735d7e060ce47feb0a\",\"feature_image\":\"https://blog.front-matter.io/content/images/2022/07/Bildschirmfoto-2021-11-04-um-09.15.49.png\",\"featured\":false,\"visibility\":\"public\",\"created_at\":\"2021-11-04T07:53:23.000+00:00\",\"updated_at\":\"2023-07-02T06:09:28.000+00:00\",\"published_at\":\"2021-11-04T09:36:04.000+00:00\",\"custom_excerpt\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":\"https://doi.org/10.53731/rc3j5sn-tzg61kj-7ztra\",\"authors\":[{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"}],\"tags\":[{\"id\":\"62d42bbc41e317003df48d4e\",\"name\":\"Feature\",\"slug\":\"feature\",\"description\":\"Features
        explore issues raised by news stories in more depth.\",\"feature_image\":\"https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fHJlc2VhcmNofGVufDB8fHx8MTYxODEyMzQxNQ&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/feature/\"}],\"primary_author\":{\"id\":\"1\",\"name\":\"Martin
        Fenner\",\"slug\":\"martin\",\"profile_image\":\"https://www.gravatar.com/avatar/8adea77ad740876f5cb832f92d49f08d?s=250&r=x&d=mp\",\"cover_image\":null,\"bio\":null,\"website\":\"https://orcid.org/0000-0003-1419-2405\",\"location\":null,\"facebook\":null,\"twitter\":null,\"meta_title\":null,\"meta_description\":null,\"url\":\"https://blog.front-matter.io/author/martin/\"},\"primary_tag\":{\"id\":\"62d42bbc41e317003df48d4e\",\"name\":\"Feature\",\"slug\":\"feature\",\"description\":\"Features
        explore issues raised by news stories in more depth.\",\"feature_image\":\"https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fHJlc2VhcmNofGVufDB8fHx8MTYxODEyMzQxNQ&ixlib=rb-1.2.1&q=80&w=2000\",\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://blog.front-matter.io/tag/feature/\"},\"url\":\"https://blog.front-matter.io/posts/open-citation-data-reach-critical-milestone/\",\"excerpt\":\"Last
        Friday the OpenCitations blog published a guest post by Alberto Mart\xEDn-Mart\xEDn
        that describes the coverage by COCI and other open citation data compared
        to subscription citation indexes. This is an important blog post, as it changes
        how we think about citations and open metrics.\\n\\nCOCI is the OpenCitations
        Index of Crossref open DOI-to-DOI citations, based on the open references
        made available by Crossref in the context of the Initiative for Open Citations
        (I4OC). As of October 2021, 88% of t\",\"reading_time\":4,\"access\":true,\"comments\":true,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":null}],\"meta\":{\"pagination\":{\"page\":1,\"limit\":50,\"pages\":11,\"total\":507,\"next\":2,\"prev\":null}}}"
    headers:
      Accept-Ranges:
      - bytes
      Access-Control-Allow-Origin:
      - '*'
      Age:
      - '663'
      Alt-Svc:
      - clear
      Cache-Control:
      - public, max-age=0
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Length:
      - '97771'
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Wed, 18 Oct 2023 11:04:36 GMT
      Etag:
      - W/"6f944-oH6pFqF5F67SBU+JtrpH6ZyGUkE"
      Ghost-Age:
      - '0'
      Ghost-Cache:
      - MISS
      Ghost-Fastly:
      - 'true'
      Server:
      - openresty
      Status:
      - 200 OK
      Vary:
      - Accept-Version, Cookie, Accept-Encoding
      Via:
      - 1.1 varnish
      X-Cache:
      - HIT
      X-Cache-Hits:
      - '1'
      X-Request-ID:
      - 524d40c2-600f-4255-bb99-be0ed11ccc5f
      X-Served-By:
      - cache-ams21066-AMS
      X-Timer:
      - S1697627077.921200,VS0,VE1
      content-version:
      - v5.69
      x-request-id:
      - 524d40c2-600f-4255-bb99-be0ed11ccc5f
    status:
      code: 200
      message: OK
version: 1
