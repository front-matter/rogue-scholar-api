interactions:
- request:
    body: '{}'
    headers:
      accept:
      - application/vnd.pgrst.object+json
      accept-encoding:
      - gzip, deflate
      accept-profile:
      - public
      connection:
      - keep-alive
      content-length:
      - '2'
      content-profile:
      - public
      content-type:
      - application/json
      host:
      - db.rogue-scholar.org
      user-agent:
      - python-httpx/0.25.2
      x-client-info:
      - supabase-py/2.3.4
    method: GET
    uri: https://db.rogue-scholar.org/rest/v1/blogs?select=id%2C%20slug%2C%20feed_url%2C%20current_feed_url%2C%20home_page_url%2C%20archive_prefix%2C%20feed_format%2C%20created_at%2C%20updated_at%2C%20use_mastodon%2C%20generator%2C%20generator_raw%2C%20language%2C%20category%2C%20favicon%2C%20title%2C%20description%2C%20category%2C%20status%2C%20user_id%2C%20authors%2C%20plan%2C%20use_api%2C%20relative_url%2C%20filter%2C%20secure&slug=eq.tarleb
  response:
    content: '{"id":"7gyq558","slug":"tarleb","feed_url":"https://tarleb.com/index.xml","current_feed_url":null,"home_page_url":"https://tarleb.com/index.html","archive_prefix":"https://wayback.archive-it.org/22161/20231101171515/","feed_format":"application/rss+xml","created_at":1681948800,"updated_at":1679616000,"use_mastodon":false,"generator":"Quarto","generator_raw":"Quarto
      1.2.475","language":"en","category":"computerAndInformationSciences","favicon":null,"title":"tarleb","description":"tarleb''s
      blog","category":"computerAndInformationSciences","status":"active","user_id":"dead81b3-8a8b-45c9-85fe-f01bb3948c77","authors":null,"plan":"Starter","use_api":null,"relative_url":null,"filter":null,"secure":true}'
    headers:
      Access-Control-Allow-Origin:
      - '*'
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 8498645a3803cb01-DUS
      Connection:
      - keep-alive
      Content-Location:
      - /blogs?select=id%2C%20slug%2C%20feed_url%2C%20current_feed_url%2C%20home_page_url%2C%20archive_prefix%2C%20feed_format%2C%20created_at%2C%20updated_at%2C%20use_mastodon%2C%20generator%2C%20generator_raw%2C%20language%2C%20category%2C%20favicon%2C%20title%2C%20description%2C%20category%2C%20status%2C%20user_id%2C%20authors%2C%20plan%2C%20use_api%2C%20relative_url%2C%20filter%2C%20secure&slug=eq.tarleb
      Content-Profile:
      - public
      Content-Range:
      - 0-0/*
      Content-Type:
      - application/vnd.pgrst.object+json; charset=utf-8
      Date:
      - Mon, 22 Jan 2024 14:12:27 GMT
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      Via:
      - kong/2.8.1
      X-Kong-Proxy-Latency:
      - '0'
      X-Kong-Upstream-Latency:
      - '5'
      alt-svc:
      - h3=":443"; ma=86400
      sb-gateway-version:
      - '1'
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: null
    headers: {}
    method: GET
    uri: https://tarleb.com/index.xml
  response:
    body:
      string: "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<rss  xmlns:atom=\"http://www.w3.org/2005/Atom\"
        \n      xmlns:media=\"http://search.yahoo.com/mrss/\" \n      xmlns:content=\"http://purl.org/rss/1.0/modules/content/\"
        \n      xmlns:dc=\"http://purl.org/dc/elements/1.1/\" \n      version=\"2.0\">\n<channel>\n<title>tarleb</title>\n<link>https://tarleb.com/index.html</link>\n<atom:link
        href=\"https://tarleb.com/index.xml\" rel=\"self\" type=\"application/rss+xml\"/>\n<description>tarleb&#39;s
        blog</description>\n<generator>quarto-1.2.475</generator>\n<lastBuildDate>Fri,
        24 Mar 2023 00:00:00 GMT</lastBuildDate>\n<item>\n  <title>Typst Musings</title>\n
        \ <dc:creator>Albert Krewinkel</dc:creator>\n  <link>https://tarleb.com/posts/typst-musings/index.html</link>\n
        \ <description><![CDATA[ \n\n\n\n<p><a href=\"https://typst.app\">Typst</a>,
        the new writing tool, was open sourced a couple of days ago. This is right
        up my alley of course, and I have a couple of thoughts on it, which I share
        here.</p>\n<section id=\"what-is-it\" class=\"level2\">\n<h2 class=\"anchored\"
        data-anchor-id=\"what-is-it\">What is it?</h2>\n<p>Typst is a writing tool
        that\u2019s described as a LaTeX alternative: it takes plain-text markup as
        input and can produce nice looking PDFs from that. The open-sourcing of the
        code created a lot of excitement and interest, with the <a href=\"https://github.com/typst/typst\">GitHub
        repository</a> getting starred over 9,000 times in just a few days.</p>\n<p>The
        tool comes with fresh and interesting ideas, impressive technology, and a
        good bit of hype\u2014so let\u2019s take a closer look.</p>\n</section>\n<section
        id=\"how-does-it-work\" class=\"level2\">\n<h2 class=\"anchored\" data-anchor-id=\"how-does-it-work\">How
        does it work?</h2>\n<p>Typst is written in <a href=\"https://www.rust-lang.org/\">Rust</a>,
        a comparatively low-level programming language that fixes many shortcomings
        of other languages operating in the same domain. One interesting feature of
        Rust that Typst makes use of is compilation to web assembly, which allows
        us to run Rust programs in the browser. This is how Typst can do the blazing
        fast PDF generation <em>in the browser!</em></p>\n<p>Of course this only works
        if it is Rust all the way down, which has important consequences. My first
        thought when I looked at the code was that it suffered from some serious <a
        href=\"https://en.wikipedia.org/wiki/Not_invented_here\">nih</a> syndrome:
        basically the whole stack is built on libraries written by the Typst team,
        even when high-qualitify open source libraries were available and could have
        been used with Rust.</p>\n<p>But, while nih still seems relevant here and
        there, the majority of libraries make sense when viewed through the lens of
        wasm-compilation. My understanding is that it\u2019s not always easy to compile
        C libraries to wasm. And with a complex system like Typst, it is often essential
        to have full control over the underlying libraries. So I think most choices
        are quite reasonable.</p>\n</section>\n<section id=\"what-makes-it-popular\"
        class=\"level2\">\n<h2 class=\"anchored\" data-anchor-id=\"what-makes-it-popular\">What
        makes it popular?</h2>\n<p>The Typst announcements on sites like <a href=\"https://news.ycombinator.com/item?id=35250210\">Hacker
        News</a> and <a href=\"https://lobste.rs/s/ko1yjj/typst_new_markup_based_typesetting\">lobste.rs</a>
        ranked \u2116\u20091, and the tool was mentioned in basically every social
        media circle and chat that I happen to be part of. There\u2019s clearly <em>a
        lot</em> of interest in a modernized version of LaTeX. Good ol\u2019 TeX and
        it\u2019s children have been around for a long while, and have essentially
        held the monopoly on PDF production for typographically advanced documents
        (tools like HTML-to-PDF converters like <a href=\"https://weasyprint.org/\">WeasyPrint</a>
        notwithstanding).</p>\n<p>But the need for a nicer PDF generator is probably
        not the only reason why Typst gained so much traction. I believe that a lot
        of interest from the programmer community is fueled by the technological choices:
        Rust has the aura of a new and shiny tool that <a href=\"https://stackoverflow.blog/2023/01/26/comparing-tag-trends-with-our-most-loved-programming-languages/\">everyone
        would like to use</a>, <em>especially</em> the regulars on the aforementioned
        sites, who share an interest in the latest tools. An otherwise equivalent
        project written in a \u201Cboring\u201D language like Python would likely
        have sparked less interest.</p>\n<p>I find it also important to note that
        Typst comes with <em>extensive documentation</em> that makes it easy to dive
        right in. It is far too common in the programming world to release some cool
        new tool into the wild, while treating documentation as an unimportant afterthought.
        Yes, I\u2019m guilty of that, too. Even the best tool can be unusable when
        its docs are missing or sparse. Typst didn\u2019t make this mistake, and I
        think it paid off.</p>\n</section>\n<section id=\"personal-opinions\" class=\"level2\">\n<h2
        class=\"anchored\" data-anchor-id=\"personal-opinions\">Personal opinions</h2>\n<p>This
        wouldn\u2019t be a proper \u201Cold man shakes fist at the clouds\u201D tech
        blog post if it didn\u2019t come with a number of \u201CI see room for improvements\u201D
        comments. Here we go.</p>\n<section id=\"scripting\" class=\"level3\">\n<h3
        class=\"anchored\" data-anchor-id=\"scripting\">Scripting</h3>\n<p>One of
        my main concerns is the scripting language: It seems well designed, but I\u2019m
        not convinced that it was necessary to create a completely new language. I
        actually believe that something like Lua, which is established<sup>1</sup>
        but flexlible, would have worked well here. But what\u2019s more is that,
        if we accept that it was necessary to have a custom language, I would have
        preferred one that isn\u2019t Turing complete, i.e., one where we can be sure
        that document rendering will terminate. Something like <a href=\"https://dhall-lang.org/\">Dhall</a>.</p>\n<p>As
        it currently stands we can neither reuse pre-existing code, nor do we have
        a guarantee that the document will stop evaluating at some point. It feels
        like a missed opportunity.</p>\n</section>\n<section id=\"notebooks\" class=\"level3\">\n<h3
        class=\"anchored\" data-anchor-id=\"notebooks\">Notebooks</h3>\n<p>Notebooks
        are a great tool to improve reproducibility in science writing. The code for
        analyses is collocated with the descriptive text in a single place. The data
        is closely linked to the final tables and graphics. It is one of the great
        features of <a href=\"https://quarto.org/\">Quarto</a>, <a href=\"https://jupyter.org/\">Jupyter</a>,
        <a href=\"https://orgmode.org/\">Org</a>, <a href=\"https://stenci.la/\">Stencila</a>,
        Mathematica, and so on, which makes them well suited for scientific writing
        in fields like medicine, psychology, and the natural sciences.</p>\n<p>This
        could be an <a href=\"https://github.com/typst/typst/issues/117\">issue</a>
        for Typst, but I believe that it won\u2019t be a problem when Typst is used
        in combination with other tools. John MacFarlane (of <a href=\"https://commonmark.org\">CommonMark</a>
        and <a href=\"https://pandoc.org/\">pandoc</a> fame) has <a href=\"https://github.com/jgm/pandoc/issues/8713\">started
        work</a> on a Typst pandoc writer, which will convert existing Markdown documents
        to Typst, and could enable the use of Typst as PDF generator while still writing
        Markdown and Python code in Quarto.</p>\n</section>\n<section id=\"accessibility-and-metadata\"
        class=\"level3\">\n<h3 class=\"anchored\" data-anchor-id=\"accessibility-and-metadata\">Accessibility
        and metadata</h3>\n<p>It\u2019s good practice to make PDFs accessible, which
        requires adding semantic information to a PDF instead of \u201Cjust\u201D
        placing characters on a page. Accessibility is even a legal requirement for
        government-issued documents in many countries. There are standards like PDF/A-1a
        and PDF/UA that ensure people with disabilities can access the information
        contained in the PDF. This is currently not supperted in Typst. LaTeX is still
        trying to catch up there, too, while <a href=\"https://wiki.contextgarden.net/\">ConTeXt</a>
        and <a href=\"https://speedata.de/\">speedata</a> are doing well, for example.</p>\n</section>\n</section>\n<section
        id=\"predictions\" class=\"level2\">\n<h2 class=\"anchored\" data-anchor-id=\"predictions\">Predictions</h2>\n<p>I
        believe Typst will succeed, but not as a full-fledged writing tool. The greatest
        value I see is in the <strong>responsive, interactive, and even collaborative
        styling of PDFs</strong>. That feature is truly unique and sets Typst appart
        from all other software out there. The tool obviously has the potential to
        reach the critical mass of contributors to become a sustainable open source
        project, and the tech choices help to attract more developers. Last but not
        least, the app is shiny, works well, and makes people want to use it.</p>\n<p>At
        the same time, I believe that the Typst writing app won\u2019t take hold in
        scientific writing. Most of the current enthusiasm is contained to technical
        circles, and scientists don\u2019t have strong reasons to switch yet. To the
        contrary, journals expect paper submissions to be done in Word or LaTeX, not
        PDF. This won\u2019t change anytime soon. Typst will have to insert itself
        into the current publishing landscape, and that\u2019s not a trivial task.</p>\n<p>For
        example, <a href=\"https://sciflow.net/\">SciFlow</a> and <a href=\"https://overleaf.com/\">Overleaf</a>
        already exist, cover most of the market needs, have a solid headstart, and
        \u2013 this is the important part \u2013 are well aligned with the needs of
        science publishers. Any new tool has to compete with them. Also, let\u2019s
        not forget all the other tools that I mentioned above.</p>\n<p>Regardless,
        I\u2019m optimistic that Typst can carve out its own business niche to occupy.
        For example, hardly any of my points above matter in print publishing. An
        indie book publisher that allows authors to use Typst for layouting would
        be amazing.</p>\n<p>I hope that the Typst team\u2019s hard work will pay off,
        and I will continue to follow their progress with great interest.</p>\n</section>\n<section
        id=\"acknowledgements\" class=\"level2\">\n<h2 class=\"anchored\" data-anchor-id=\"acknowledgements\">Acknowledgements</h2>\n<p>Heart-felt
        thanks to <a href=\"https://hachyderm.io/@maegul\">@maegul@hachyderm.io</a>
        for the insightful feedback on an earlier version of this post, and to <a
        href=\"https://ilonasilverwood.github.io/\">Ilona Silverwood</a> for her skillful
        editing. This post became much better thanks to their input.</p>\n</section>\n<section
        id=\"updates\" class=\"level2\">\n<h2 class=\"anchored\" data-anchor-id=\"updates\">Updates</h2>\n<p>An
        earlier version listed <a href=\"https://www.authorea.com/\">Authorea</a>
        as an authoring tool, but the platform has shifted focus since I last looked
        at it, so I\u2019ve removed it.</p>\n\n\n</section>\n\n\n<div id=\"quarto-appendix\"
        class=\"default\"><section id=\"footnotes\" class=\"footnotes footnotes-end-of-document\"><h2
        class=\"anchored quarto-appendix-heading\">Footnotes</h2>\n\n<ol>\n<li id=\"fn1\"><p>I
        consider <a href=\"https://lua.org/\">Lua</a> to be <em>the</em> language
        of publishing tools. It fuels <a href=\"https://pandoc.org/\">pandoc</a>,
        <a href=\"https://quarto.org/\">Quarto</a>, <a href=\"https://wiki.contextgarden.net/\">ConTeXt</a>,
        <a href=\"http://luatex.org/\">LuaLaTeX</a>, <a href=\"https://speedata.de/\">speedata</a>,
        <a href=\"https://sile-typesetter.org/\">SILE</a>, and probably a few more.\u21A9\uFE0E</p></li>\n</ol>\n</section></div>
        ]]></description>\n  <category>PDF</category>\n  <guid>https://tarleb.com/posts/typst-musings/index.html</guid>\n
        \ <pubDate>Fri, 24 Mar 2023 00:00:00 GMT</pubDate>\n</item>\n<item>\n  <title>Auto-numbered
        list continuations</title>\n  <dc:creator>Albert Krewinkel</dc:creator>\n
        \ <link>https://tarleb.com/posts/list-continuation/index.html</link>\n  <description><![CDATA[
        \n\n\n\n<p>Pandoc\u2019s Markdown allows for \u201Cfancy lists\u201D, i.e.,
        lists with different styles used for the marker of ordered list items.</p>\n<p>E.g.,
        the list</p>\n<div class=\"sourceCode\" id=\"cb1\" style=\"background: #f1f3f5;\"><pre
        class=\"sourceCode markdown code-with-copy\"><code class=\"sourceCode markdown\"><span
        id=\"cb1-1\">(I)  primus</span>\n<span id=\"cb1-2\">(#)  secundus</span>\n<span
        id=\"cb1-3\">(#)  tertius</span></code></pre></div>\n<p>uses uppercase roman
        numerals and double parentheses for the markers. It gets rendered as</p>\n<blockquote
        class=\"blockquote\">\n<ol type=\"I\">\n<li>primus</li>\n<li>secundus</li>\n<li>tertius</li>\n</ol>\n</blockquote>\n<section
        id=\"continuations\" class=\"level2\">\n<h2 class=\"anchored\" data-anchor-id=\"continuations\">Continuations</h2>\n<p>The
        fancy lists feature also allows to continue lists after an intermediate paragraph:</p>\n<div
        class=\"sourceCode\" id=\"cb2\" style=\"background: #f1f3f5;\"><pre class=\"sourceCode
        markdown code-with-copy\"><code class=\"sourceCode markdown\"><span id=\"cb2-1\">i.
        \  one</span>\n<span id=\"cb2-2\">#.   another</span>\n<span id=\"cb2-3\"></span>\n<span
        id=\"cb2-4\">Interruption; not part of any list.</span>\n<span id=\"cb2-5\"></span>\n<span
        id=\"cb2-6\">iii. continue</span>\n<span id=\"cb2-7\">#.   keep counting</span></code></pre></div>\n<p>This
        becomes</p>\n<blockquote class=\"blockquote\">\n<ol type=\"i\">\n<li>one</li>\n<li>another</li>\n</ol>\n<p>Interruption;
        not part of any list.</p>\n<ol start=\"3\" type=\"i\">\n<li>continue</li>\n<li>keep
        counting</li>\n</ol>\n</blockquote>\n<p>While very convenient, this requires
        us to carefully keep book of the number of items in previous parts, or risk
        the item numbering to become inconsistent. Imagine having to find and update
        all other list parts after adding a single item somewhere. Tedious work, that
        gets tiresome quickly.</p>\n</section>\n<section id=\"convention\" class=\"level2\">\n<h2
        class=\"anchored\" data-anchor-id=\"convention\">Convention</h2>\n<p>Wanting
        none of this, we magicked a method that allows us to mark a list as a continuation.
        This way, we can search for those lists with a Lua filter and let pandoc do
        the counting and numbering for us.</p>\n<p>Our convention is this: any list
        that starts with a number of 90 or above is treated as the continuation of
        a previous list. Why 90? Because it\u2019s large, but still easy to express
        using roman numerals, should one be inclined to use those.</p>\n<div class=\"sourceCode\"
        id=\"cb3\" style=\"background: #f1f3f5;\"><pre class=\"sourceCode markdown
        code-with-copy\"><code class=\"sourceCode markdown\"><span id=\"cb3-1\">i.
        \ primus</span>\n<span id=\"cb3-2\">ii. secundus</span>\n<span id=\"cb3-3\"></span>\n<span
        id=\"cb3-4\">Lorem ipsum.</span>\n<span id=\"cb3-5\"></span>\n<span id=\"cb3-6\">xc.
        alius item</span>\n<span id=\"cb3-7\">#.  ut custodians iens</span></code></pre></div>\n</section>\n<section
        id=\"lua-doing-the-counting\" class=\"level2\">\n<h2 class=\"anchored\" data-anchor-id=\"lua-doing-the-counting\">Lua
        doing the counting</h2>\n<p>The next step is to let pandoc do the counting
        with the help of a Lua filter. In its simplest form, the filter will step
        through all ordered lists in the document, remember the number of items it
        has encountered, and renumber any list whose start is above our chosen threshold.</p>\n<div
        class=\"sourceCode\" id=\"cb4\" style=\"background: #f1f3f5;\"><pre class=\"sourceCode
        lua code-with-copy\"><code class=\"sourceCode lua\"><span id=\"cb4-1\"><span
        class=\"kw\" style=\"color: #003B4F;\">local</span> next_start <span class=\"op\"
        style=\"color: #5E5E5E;\">=</span> <span class=\"dv\" style=\"color: #AD0000;\">1</span></span>\n<span
        id=\"cb4-2\"></span>\n<span id=\"cb4-3\"><span class=\"kw\" style=\"color:
        #003B4F;\">function</span> OrderedList <span class=\"op\" style=\"color: #5E5E5E;\">(</span>ol<span
        class=\"op\" style=\"color: #5E5E5E;\">)</span></span>\n<span id=\"cb4-4\">
        \ <span class=\"cf\" style=\"color: #003B4F;\">if</span> ol<span class=\"op\"
        style=\"color: #5E5E5E;\">.</span>start <span class=\"op\" style=\"color:
        #5E5E5E;\">&gt;=</span> <span class=\"dv\" style=\"color: #AD0000;\">90</span>
        <span class=\"cf\" style=\"color: #003B4F;\">then</span></span>\n<span id=\"cb4-5\">
        \   ol<span class=\"op\" style=\"color: #5E5E5E;\">.</span>start <span class=\"op\"
        style=\"color: #5E5E5E;\">=</span> next_start</span>\n<span id=\"cb4-6\">
        \   next_start <span class=\"op\" style=\"color: #5E5E5E;\">=</span> next_start
        <span class=\"op\" style=\"color: #5E5E5E;\">+</span> <span class=\"op\" style=\"color:
        #5E5E5E;\">#</span>ol<span class=\"op\" style=\"color: #5E5E5E;\">.</span>content</span>\n<span
        id=\"cb4-7\">  <span class=\"cf\" style=\"color: #003B4F;\">else</span></span>\n<span
        id=\"cb4-8\">    next_start <span class=\"op\" style=\"color: #5E5E5E;\">=</span>
        <span class=\"op\" style=\"color: #5E5E5E;\">#</span>ol<span class=\"op\"
        style=\"color: #5E5E5E;\">.</span>content <span class=\"op\" style=\"color:
        #5E5E5E;\">+</span> <span class=\"dv\" style=\"color: #AD0000;\">1</span></span>\n<span
        id=\"cb4-9\">  <span class=\"cf\" style=\"color: #003B4F;\">end</span></span>\n<span
        id=\"cb4-10\">  <span class=\"cf\" style=\"color: #003B4F;\">return</span>
        ol</span>\n<span id=\"cb4-11\"><span class=\"kw\" style=\"color: #003B4F;\">end</span></span></code></pre></div>\n<p>Applied
        to the example above, the filter produces the desired result:</p>\n<blockquote
        class=\"blockquote\">\n<ol type=\"i\">\n<li>primus</li>\n<li>secundus</li>\n</ol>\n<p>Lorem
        ipsum.</p>\n<ol start=\"3\" type=\"i\">\n<li>alius item</li>\n<li>ut custodians
        iens</li>\n</ol>\n</blockquote>\n</section>\n<section id=\"refinements\" class=\"level2\">\n<h2
        class=\"anchored\" data-anchor-id=\"refinements\">Refinements</h2>\n<p>This
        is fairly good already. But what happens if there are <em>other</em> lists
        appearing in the intermediate blocks?</p>\n<pre><code>1. First item\n\n- Nested
        list:\n\n    a. alfa\n    b. bravo\n    c. charlie\n\nWhich list will be continued?\n\n99.
        ???</code></pre>\n<p>With the current state of our filter, the last item will
        be numbered <code>d.</code>, which is most likely not what we want. So let\u2019s
        make the filter sensitive to the list style; only a list with the matching
        style will be continued.</p>\n<p>The style and delimiter of ordered list markers
        can be accessed via the element\u2019s <code>style</code> and <code>delimiter</code>
        property, respectively. We use those values to construct a string key under
        which the start number of the next continuation is stored in table <code>next_starts</code>.</p>\n<div
        class=\"sourceCode\" id=\"cb6\" style=\"background: #f1f3f5;\"><pre class=\"sourceCode
        lua code-with-copy\"><code class=\"sourceCode lua\"><span id=\"cb6-1\"><span
        class=\"kw\" style=\"color: #003B4F;\">local</span> next_starts <span class=\"op\"
        style=\"color: #5E5E5E;\">=</span> <span class=\"op\" style=\"color: #5E5E5E;\">{}</span></span>\n<span
        id=\"cb6-2\"></span>\n<span id=\"cb6-3\"><span class=\"kw\" style=\"color:
        #003B4F;\">function</span> OrderedList <span class=\"op\" style=\"color: #5E5E5E;\">(</span>ol<span
        class=\"op\" style=\"color: #5E5E5E;\">)</span></span>\n<span id=\"cb6-4\">
        \ <span class=\"kw\" style=\"color: #003B4F;\">local</span> key <span class=\"op\"
        style=\"color: #5E5E5E;\">=</span> ol<span class=\"op\" style=\"color: #5E5E5E;\">.</span>style
        <span class=\"op\" style=\"color: #5E5E5E;\">..</span> <span class=\"st\"
        style=\"color: #20794D;\">'|'</span> <span class=\"op\" style=\"color: #5E5E5E;\">..</span>
        ol<span class=\"op\" style=\"color: #5E5E5E;\">.</span>delimiter</span>\n<span
        id=\"cb6-5\">  <span class=\"cf\" style=\"color: #003B4F;\">if</span> ol<span
        class=\"op\" style=\"color: #5E5E5E;\">.</span>start <span class=\"op\" style=\"color:
        #5E5E5E;\">&gt;=</span> <span class=\"dv\" style=\"color: #AD0000;\">90</span>
        <span class=\"cf\" style=\"color: #003B4F;\">then</span></span>\n<span id=\"cb6-6\">
        \   ol<span class=\"op\" style=\"color: #5E5E5E;\">.</span>start <span class=\"op\"
        style=\"color: #5E5E5E;\">=</span> next_starts<span class=\"op\" style=\"color:
        #5E5E5E;\">[</span>key<span class=\"op\" style=\"color: #5E5E5E;\">]</span>
        <span class=\"kw\" style=\"color: #003B4F;\">or</span> <span class=\"dv\"
        style=\"color: #AD0000;\">1</span></span>\n<span id=\"cb6-7\">    next_starts<span
        class=\"op\" style=\"color: #5E5E5E;\">[</span>key<span class=\"op\" style=\"color:
        #5E5E5E;\">]</span> <span class=\"op\" style=\"color: #5E5E5E;\">=</span>
        ol<span class=\"op\" style=\"color: #5E5E5E;\">.</span>start <span class=\"op\"
        style=\"color: #5E5E5E;\">+</span> <span class=\"op\" style=\"color: #5E5E5E;\">#</span>ol<span
        class=\"op\" style=\"color: #5E5E5E;\">.</span>content</span>\n<span id=\"cb6-8\">
        \ <span class=\"cf\" style=\"color: #003B4F;\">else</span></span>\n<span id=\"cb6-9\">
        \   next_starts<span class=\"op\" style=\"color: #5E5E5E;\">[</span>key<span
        class=\"op\" style=\"color: #5E5E5E;\">]</span> <span class=\"op\" style=\"color:
        #5E5E5E;\">=</span> <span class=\"op\" style=\"color: #5E5E5E;\">#</span>ol<span
        class=\"op\" style=\"color: #5E5E5E;\">.</span>content <span class=\"op\"
        style=\"color: #5E5E5E;\">+</span> <span class=\"dv\" style=\"color: #AD0000;\">1</span></span>\n<span
        id=\"cb6-10\">  <span class=\"cf\" style=\"color: #003B4F;\">end</span></span>\n<span
        id=\"cb6-11\"></span>\n<span id=\"cb6-12\">  <span class=\"cf\" style=\"color:
        #003B4F;\">return</span> ol</span>\n<span id=\"cb6-13\"><span class=\"kw\"
        style=\"color: #003B4F;\">end</span></span></code></pre></div>\n<p>This way
        we can keep track of multiple lists, distinguishing between lists by using
        the style of their markers. The above now gets output as</p>\n<blockquote
        class=\"blockquote\">\n<ol type=\"1\">\n<li>First item</li>\n</ol>\n<ul>\n<li><p>Nested
        list:</p>\n<ol type=\"a\">\n<li>alfa</li>\n<li>bravo</li>\n<li>charlie</li>\n</ol></li>\n</ul>\n<p>Which
        list will be continued?</p>\n<ol start=\"2\" type=\"1\">\n<li>???</li>\n</ol>\n</blockquote>\n<p>Just
        what we want. Happy list writing!</p>\n\n\n</section>\n\n ]]></description>\n
        \ <category>Markdown</category>\n  <category>pandoc</category>\n  <category>filter</category>\n
        \ <guid>https://tarleb.com/posts/list-continuation/index.html</guid>\n  <pubDate>Mon,
        28 Nov 2022 00:00:00 GMT</pubDate>\n</item>\n<item>\n  <title>Semantic line
        breaks</title>\n  <dc:creator>Albert Krewinkel</dc:creator>\n  <link>https://tarleb.com/posts/semantic-line-breaks/index.html</link>\n
        \ <description><![CDATA[ \n\n\n\n<p>Line breaks usually have no semantic meaning
        within a Markdown paragraph. However, using line breaks to mark the end of
        a sentece can help with productivity for various reasons.<sup>1</sup> Documents
        with one sentence per line are also called \u201Cventilated prose\u201D, and
        the <a href=\"https://writetheasciidocs.netlify.app\">Write the {Ascii}Docs</a>
        website has a <a href=\"https://writetheasciidocs.netlify.app/ventilated-prose\">good
        article on that topic</a>.</p>\n<p>A question came up in a Slack channel,
        asking whether it was possible to convert existing Markdown docs to this style.
        Naturally, the answer is \u201Cpandoc can do that\u201D, but that isn\u2019t
        obvious here.</p>\n<p>The solution that I came up with is centered around
        pandoc\u2019s <em>SoftBreak</em> AST element. Pandoc uses SoftBreak elements
        internally to mark the place where line breaks occured in the input, but only
        if those breaks should be treated like spaces in most situations. The way
        to make those breaks visible in the output is to call pandoc with <code>--wrap=preserve</code>
        \u2013 only then will a line break in the input result in a break in the output
        in the same location.</p>\n<pre><code>$ printf 'Hello\\npandoc' | pandoc --to=markdown\n\u21D2
        Hello pandoc\n\n$ printf 'Hello\\npandoc' | pandoc --to=markdown --wrap=preserve\n\u21D2
        Hello\n\u21D2 pandoc</code></pre>\n<p>We are going to use SoftBreak for semantic
        line breaks, so the first step is to get rid of the SoftBreak elements created
        during parsing. A Lua filter can do so with</p>\n<div class=\"sourceCode\"
        id=\"cb2\" style=\"background: #f1f3f5;\"><pre class=\"sourceCode lua code-with-copy\"><code
        class=\"sourceCode lua\"><span id=\"cb2-1\"><span class=\"cn\" style=\"color:
        #8f5902;\">S</span>oftBreak <span class=\"op\" style=\"color: #5E5E5E;\">=</span>
        <span class=\"kw\" style=\"color: #003B4F;\">function</span> <span class=\"op\"
        style=\"color: #5E5E5E;\">()</span> <span class=\"cf\" style=\"color: #003B4F;\">return</span>
        pandoc<span class=\"op\" style=\"color: #5E5E5E;\">.</span>Space<span class=\"op\"
        style=\"color: #5E5E5E;\">()</span> <span class=\"kw\" style=\"color: #003B4F;\">end</span></span></code></pre></div>\n<p>Then
        we check for strings that end with a period and are followed by a space. The
        space in such a combination is then turned into a SoftBreak.</p>\n<div class=\"sourceCode\"
        id=\"cb3\" style=\"background: #f1f3f5;\"><pre class=\"sourceCode lua code-with-copy\"><code
        class=\"sourceCode lua\"><span id=\"cb3-1\"><span class=\"kw\" style=\"color:
        #003B4F;\">local</span> <span class=\"kw\" style=\"color: #003B4F;\">function</span>
        semantic_line_feeds <span class=\"op\" style=\"color: #5E5E5E;\">(</span>el<span
        class=\"op\" style=\"color: #5E5E5E;\">)</span></span>\n<span id=\"cb3-2\">
        \ <span class=\"kw\" style=\"color: #003B4F;\">local</span> inlines <span
        class=\"op\" style=\"color: #5E5E5E;\">=</span> el<span class=\"op\" style=\"color:
        #5E5E5E;\">.</span>content</span>\n<span id=\"cb3-3\">  <span class=\"cf\"
        style=\"color: #003B4F;\">for</span> i <span class=\"op\" style=\"color: #5E5E5E;\">=</span>
        <span class=\"dv\" style=\"color: #AD0000;\">2</span><span class=\"op\" style=\"color:
        #5E5E5E;\">,</span> <span class=\"op\" style=\"color: #5E5E5E;\">#</span>inlines
        <span class=\"cf\" style=\"color: #003B4F;\">do</span></span>\n<span id=\"cb3-4\">
        \   <span class=\"cf\" style=\"color: #003B4F;\">if</span> inlines<span class=\"op\"
        style=\"color: #5E5E5E;\">[</span>i<span class=\"op\" style=\"color: #5E5E5E;\">].</span>t
        <span class=\"op\" style=\"color: #5E5E5E;\">==</span> <span class=\"st\"
        style=\"color: #20794D;\">'Space'</span> <span class=\"kw\" style=\"color:
        #003B4F;\">and</span></span>\n<span id=\"cb3-5\">       inlines<span class=\"op\"
        style=\"color: #5E5E5E;\">[</span>i<span class=\"op\" style=\"color: #5E5E5E;\">-</span><span
        class=\"dv\" style=\"color: #AD0000;\">1</span><span class=\"op\" style=\"color:
        #5E5E5E;\">].</span>t <span class=\"op\" style=\"color: #5E5E5E;\">==</span>
        <span class=\"st\" style=\"color: #20794D;\">'Str'</span> <span class=\"kw\"
        style=\"color: #003B4F;\">and</span></span>\n<span id=\"cb3-6\">       inlines<span
        class=\"op\" style=\"color: #5E5E5E;\">[</span>i<span class=\"op\" style=\"color:
        #5E5E5E;\">-</span><span class=\"dv\" style=\"color: #AD0000;\">1</span><span
        class=\"op\" style=\"color: #5E5E5E;\">].</span>text<span class=\"op\" style=\"color:
        #5E5E5E;\">:</span><span class=\"fu\" style=\"color: #4758AB;\">match</span>
        <span class=\"st\" style=\"color: #20794D;\">'%.$'</span> <span class=\"cf\"
        style=\"color: #003B4F;\">then</span></span>\n<span id=\"cb3-7\">      inlines<span
        class=\"op\" style=\"color: #5E5E5E;\">[</span>i<span class=\"op\" style=\"color:
        #5E5E5E;\">]</span> <span class=\"op\" style=\"color: #5E5E5E;\">=</span>
        pandoc<span class=\"op\" style=\"color: #5E5E5E;\">.</span>SoftBreak<span
        class=\"op\" style=\"color: #5E5E5E;\">()</span></span>\n<span id=\"cb3-8\">
        \   <span class=\"cf\" style=\"color: #003B4F;\">end</span></span>\n<span
        id=\"cb3-9\">  <span class=\"cf\" style=\"color: #003B4F;\">end</span></span>\n<span
        id=\"cb3-10\">  <span class=\"cf\" style=\"color: #003B4F;\">return</span>
        el</span>\n<span id=\"cb3-11\"><span class=\"kw\" style=\"color: #003B4F;\">end</span></span>\n<span
        id=\"cb3-12\"></span>\n<span id=\"cb3-13\"><span class=\"cf\" style=\"color:
        #003B4F;\">return</span> <span class=\"op\" style=\"color: #5E5E5E;\">{</span></span>\n<span
        id=\"cb3-14\">  <span class=\"co\" style=\"color: #5E5E5E;\">-- remove soft
        breaks inserted during parsing.</span></span>\n<span id=\"cb3-15\">  <span
        class=\"op\" style=\"color: #5E5E5E;\">{</span><span class=\"cn\" style=\"color:
        #8f5902;\">S</span>oftBreak <span class=\"op\" style=\"color: #5E5E5E;\">=</span>
        <span class=\"kw\" style=\"color: #003B4F;\">function</span> <span class=\"op\"
        style=\"color: #5E5E5E;\">()</span> <span class=\"cf\" style=\"color: #003B4F;\">return</span>
        pandoc<span class=\"op\" style=\"color: #5E5E5E;\">.</span>Space<span class=\"op\"
        style=\"color: #5E5E5E;\">()</span> <span class=\"kw\" style=\"color: #003B4F;\">end</span><span
        class=\"op\" style=\"color: #5E5E5E;\">},</span></span>\n<span id=\"cb3-16\">
        \ <span class=\"co\" style=\"color: #5E5E5E;\">-- insert semantic soft breaks</span></span>\n<span
        id=\"cb3-17\">  <span class=\"op\" style=\"color: #5E5E5E;\">{</span><span
        class=\"cn\" style=\"color: #8f5902;\">P</span>ara <span class=\"op\" style=\"color:
        #5E5E5E;\">=</span> semantic_line_feeds<span class=\"op\" style=\"color: #5E5E5E;\">,</span>
        <span class=\"cn\" style=\"color: #8f5902;\">P</span>lain <span class=\"op\"
        style=\"color: #5E5E5E;\">=</span> semantic_line_feeds<span class=\"op\" style=\"color:
        #5E5E5E;\">},</span></span>\n<span id=\"cb3-18\"><span class=\"op\" style=\"color:
        #5E5E5E;\">}</span></span></code></pre></div>\n<p>This filter can then be
        combined with the <code>--wrap=preserve</code> option to get the desired semantic
        line breaks.</p>\n<div class=\"sourceCode\" id=\"cb4\" style=\"background:
        #f1f3f5;\"><pre class=\"sourceCode bash code-with-copy\"><code class=\"sourceCode
        bash\"><span id=\"cb4-1\"><span class=\"bu\" style=\"color: null;\">printf</span>
        <span class=\"st\" style=\"color: #20794D;\">'This. And that.'</span> <span
        class=\"kw\" style=\"color: #003B4F;\">|</span> <span class=\"ex\" style=\"color:
        null;\">pandoc</span> <span class=\"at\" style=\"color: #657422;\">-L</span>
        semlf.lua <span class=\"at\" style=\"color: #657422;\">--wrap</span><span
        class=\"op\" style=\"color: #5E5E5E;\">=</span>preserve</span>\n<span id=\"cb4-2\"><span
        class=\"ex\" style=\"color: null;\">\u21D2</span> This.</span>\n<span id=\"cb4-3\"><span
        class=\"ex\" style=\"color: null;\">\u21D2</span> And that.</span></code></pre></div>\n<p>There,
        mission accomplished.<sup>2</sup></p>\n\n\n\n\n<div id=\"quarto-appendix\"
        class=\"default\"><section id=\"footnotes\" class=\"footnotes footnotes-end-of-document\"><h2
        class=\"anchored quarto-appendix-heading\">Footnotes</h2>\n\n<ol>\n<li id=\"fn1\"><p>It\u2019s
        not my cup of tea, but I can see why people might like the concept.\u21A9\uFE0E</p></li>\n<li
        id=\"fn2\"><p>There are some cases in which the filter does not give the correct
        result, for example when using American-style punctuation after quotes, or
        when a full sentence is emphasized. It should be possible to fix the filter
        for these edge cases, but it doesn\u2019t seem worth the effort: the presented
        solution should work fine for 95&nbsp;% of all use cases.\u21A9\uFE0E</p></li>\n</ol>\n</section></div>
        ]]></description>\n  <category>Markdown</category>\n  <category>pandoc</category>\n
        \ <guid>https://tarleb.com/posts/semantic-line-breaks/index.html</guid>\n
        \ <pubDate>Sun, 30 Oct 2022 00:00:00 GMT</pubDate>\n</item>\n<item>\n  <title>Install
        pandoc in custom Docker images</title>\n  <dc:creator>Albert Krewinkel</dc:creator>\n
        \ <link>https://tarleb.com/posts/tip-install-in-docker/index.html</link>\n
        \ <description><![CDATA[ \n\n\n\n<p>When pandoc is used in larger pipelines,
        e.g.&nbsp;in combination with <a href=\"https://sphinx-doc.org\">Sphinx</a>,
        it can be useful to pack everything up into one neat container. One option
        is to base the container on a pandoc image like <code>pandoc/core</code>,
        but this may be difficult due to other dependencies. In this case, the easiest
        option is to do this:</p>\n<div class=\"sourceCode\" id=\"cb1\" style=\"background:
        #f1f3f5;\"><pre class=\"sourceCode dockerfile code-with-copy\"><code class=\"sourceCode
        dockerfile\"><span id=\"cb1-1\"><span class=\"kw\" style=\"color: #003B4F;\">COPY</span>
        <span class=\"op\" style=\"color: #5E5E5E;\">--from=pandoc/minimal:2.19.2</span>
        /pandoc /usr/bin/pandoc</span></code></pre></div>\n<p>The snippet, when added
        to a Dockerfile, copies a statically compiled executable from an official
        build to <code>/usr/bin/pandoc</code>. The static pandoc binary can run on
        all Linux distributions, so it does not matter what distro the custom build
        is based on.</p>\n<p>The documentation for the <a href=\"https://hub.docker.com/r/pandoc/minimal\"
        class=\"uri\">https://hub.docker.com/r/pandoc/minimal</a> has more info, including
        a list of supported versions (tags).</p>\n\n\n\n ]]></description>\n  <category>pandoc</category>\n
        \ <category>tip</category>\n  <category>Docker</category>\n  <guid>https://tarleb.com/posts/tip-install-in-docker/index.html</guid>\n
        \ <pubDate>Wed, 07 Sep 2022 00:00:00 GMT</pubDate>\n</item>\n<item>\n  <title>Document
        font</title>\n  <dc:creator>Albert Krewinkel</dc:creator>\n  <link>https://tarleb.com/posts/tip-document-font/index.html</link>\n
        \ <description><![CDATA[ \n\n\n\n<p>Setting the document font this way works
        for ConTeXt, LaTeX, and HTML output. The fonts used in docx or odt output
        must be controlled with the reference document instead.</p>\n<p>The default
        LaTeX engine is pdflatex, which only supports TeX\u2019s own font format and
        cannot use the TrueType or OpenType fonts installed on the system. However,
        XeLaTeX was written with that in mind; switching to that engine allows to
        specify any font available on the system.</p>\n<p>A good source for free fonts
        is the <a href=\"https://fonts.google.com\">Google Fonts</a> repository.</p>\n\n\n\n
        ]]></description>\n  <category>pandoc</category>\n  <category>tip</category>\n
        \ <category>PDF</category>\n  <category>HTML</category>\n  <guid>https://tarleb.com/posts/tip-document-font/index.html</guid>\n
        \ <pubDate>Wed, 07 Sep 2022 00:00:00 GMT</pubDate>\n  <media:content url=\"https://tarleb.com/images/pandoc-logo.png\"
        medium=\"image\" type=\"image/png\" height=\"144\" width=\"144\"/>\n</item>\n<item>\n
        \ <title>Haskell usedata objects</title>\n  <dc:creator>Albert Krewinkel</dc:creator>\n
        \ <link>https://tarleb.com/posts/haskell-lua-objects/index.html</link>\n  <description><![CDATA[
        \n\n\n\n<p>When extending pandoc (or Quarto) with Lua filters, we interact
        with so-called Lua userdata objects. These objects are used to wrap document
        AST elements, making them accessible from Lua scripts. They mostly behave
        like normal Lua tables. This post is intended as a quick overview, listing
        interesting properties of userdata objects.</p>\n<section id=\"userdata-objects\"
        class=\"level2\">\n<h2 class=\"anchored\" data-anchor-id=\"userdata-objects\">Userdata
        objects</h2>\n<p>Haskell-generated userdata objects have three main components:
        a type <em>name</em>, <em>properties</em>, and <em>methods</em>:</p>\n<section
        id=\"type-name\" class=\"level3\">\n<h3 class=\"anchored\" data-anchor-id=\"type-name\">Type
        name</h3>\n<p>The <em>name</em> can be retrieved with <code>pandoc.utils.type</code>.
        It should be treated as a read-only constant. Internally, the <em>name</em>
        is used as a type tag, which is important when retrieving an object from a
        Lua script back into the main program. It is possible to access the name through
        the debug interface, e.g.,</p>\n<div class=\"sourceCode\" id=\"cb1\" style=\"background:
        #f1f3f5;\"><pre class=\"sourceCode lua code-with-copy\"><code class=\"sourceCode
        lua\"><span id=\"cb1-1\"><span class=\"kw\" style=\"color: #003B4F;\">function</span>
        typename <span class=\"op\" style=\"color: #5E5E5E;\">(</span>x<span class=\"op\"
        style=\"color: #5E5E5E;\">)</span></span>\n<span id=\"cb1-2\">  <span class=\"cf\"
        style=\"color: #003B4F;\">return</span> <span class=\"fu\" style=\"color:
        #4758AB;\">debug.getmetatable</span><span class=\"op\" style=\"color: #5E5E5E;\">(</span>x<span
        class=\"op\" style=\"color: #5E5E5E;\">).</span><span class=\"cn\" style=\"color:
        #8f5902;\">__</span>name</span>\n<span id=\"cb1-3\"><span class=\"kw\" style=\"color:
        #003B4F;\">end</span></span></code></pre></div>\n<p>The above <code>typename</code>
        function is actually a bit faster than <code>pandoc.utils.type</code>. It
        can improve performance when accessing this info in a tight loop, but its
        use is not recommended.</p>\n</section>\n<section id=\"properties\" class=\"level3\">\n<h3
        class=\"anchored\" data-anchor-id=\"properties\">Properties</h3>\n<p><em>Properties</em>,
        e.g., the <code>content</code> fields of <em>Para</em> elements, are \u201Clazy\u201D:
        the property value is marshaled to Lua when the property is accessed for the
        first time. We are usually interested in no more than one or two element properties,
        so this is a big performance improvement for most scripts. Lazy properties
        are especially useful with large objects like <em>Pandoc</em>, which would
        otherwise take a long time to marshal and unmarshal with all their child elements.</p>\n<p>However,
        this lazy marshaling is slower if all properties will be accessed anyway.
        If there are performance issues due to lazy properties, then please let me
        know, and I\u2019ll try to find a fix.</p>\n</section>\n<section id=\"methods\"
        class=\"level3\">\n<h3 class=\"anchored\" data-anchor-id=\"methods\">Methods</h3>\n<p><em>Methods</em>
        are wrapped Haskell functions: when calling a method, the arguments are unmarshaled
        back into Haskell objects, which are then passed to the wrapped function and
        processed in Haskell. The computation\u2019s result is then pushed back to
        Lua.</p>\n<p>This may sound weirdly complicated. While <em>it is</em> slow
        for very simple functions (like <code>pandoc.utils.type</code>), it\u2019s
        very fast and convenient for complex methods like <code>Pandoc:walk</code>:
        objects with lazy properties are fast to unmarshal, the main Haskell code
        is fast, and it frees us from having to re-implement Haskell algorithms in
        Lua.</p>\n</section>\n<section id=\"iterating\" class=\"level3\">\n<h3 class=\"anchored\"
        data-anchor-id=\"iterating\">Iterating</h3>\n<p>The properties and methods
        are listed when iterating with <code>pairs</code>. The iteration order is
        defined at compile time, with properties listed first, followed by methods.
        We usually try to keep each of these lists sorted alphabetically, but there
        may be exceptions.</p>\n<p>Calling <code>pairs</code> on a Haskell userdata
        object will always succeed, even if it has neither methods nor properties;
        the result will be the empty iterator in that case.</p>\n</section>\n<section
        id=\"aliases\" class=\"level3\">\n<h3 class=\"anchored\" data-anchor-id=\"aliases\">Aliases</h3>\n<p>Some
        objects also have property aliases: E.g., <code>div.classes</code> is really
        just an alias for <code>div.attr.classes</code>. Both entries point to the
        same list object. Aliases are not included in the iterator generated by <code>pairs</code>.
        See the internals on how to get a hold of them.</p>\n</section>\n<section
        id=\"list-behavior\" class=\"level3\">\n<h3 class=\"anchored\" data-anchor-id=\"list-behavior\">List
        behavior</h3>\n<p>Userdata objects can be made to behave like lists, but iterating
        over those \u201Clists\u201D is comparatively slow. That\u2019s why the only
        object that uses this feature is <code>PANDOC_VERSION</code>: for example,
        we can write <code>PANDOC_VERSION[2] &gt;= 19</code> to check <em>just</em>
        the major version.<sup>1</sup></p>\n</section>\n<section id=\"internals\"
        class=\"level3\">\n<h3 class=\"anchored\" data-anchor-id=\"internals\">Internals</h3>\n<p>Each
        type has a metatable, which defines its behavior. Most users should not need
        to access the metatable, so the <code>getmetatable</code> function returns
        <code>true</code> instead of the actual metatable when called on a Haskell
        userdata object. As we\u2019ve seen with type names, It\u2019s still possible
        to inspect the userdata metatable with the help of <code>debug.getmetatable</code>.</p>\n<p>The
        metatable has four interesting fields: <code>methods</code>, <code>aliases</code>,
        <code>getters</code>, and <code>setters</code>. The fields contain just what
        you\u2019d expect.</p>\n<p>E.g., we can inspect the list of aliases defined
        for Inline objects with</p>\n<div class=\"sourceCode\" id=\"cb2\" style=\"background:
        #f1f3f5;\"><pre class=\"sourceCode lua code-with-copy\"><code class=\"sourceCode
        lua\"><span id=\"cb2-1\"><span class=\"kw\" style=\"color: #003B4F;\">local</span>
        <span class=\"cn\" style=\"color: #8f5902;\">I</span>nlineMT <span class=\"op\"
        style=\"color: #5E5E5E;\">=</span> <span class=\"fu\" style=\"color: #4758AB;\">debug.getmetatable</span><span
        class=\"op\" style=\"color: #5E5E5E;\">(</span>pandoc<span class=\"op\" style=\"color:
        #5E5E5E;\">.</span>Str <span class=\"st\" style=\"color: #20794D;\">''</span><span
        class=\"op\" style=\"color: #5E5E5E;\">)</span></span>\n<span id=\"cb2-2\"><span
        class=\"cf\" style=\"color: #003B4F;\">for</span> name<span class=\"op\" style=\"color:
        #5E5E5E;\">,</span> keys <span class=\"kw\" style=\"color: #003B4F;\">in</span>
        <span class=\"fu\" style=\"color: #4758AB;\">pairs</span><span class=\"op\"
        style=\"color: #5E5E5E;\">(</span><span class=\"cn\" style=\"color: #8f5902;\">I</span>nlineMT<span
        class=\"op\" style=\"color: #5E5E5E;\">.</span>aliases<span class=\"op\" style=\"color:
        #5E5E5E;\">)</span> <span class=\"cf\" style=\"color: #003B4F;\">do</span></span>\n<span
        id=\"cb2-3\">  <span class=\"co\" style=\"color: #5E5E5E;\">-- print the alias
        name and the alias value</span></span>\n<span id=\"cb2-4\">  <span class=\"fu\"
        style=\"color: #4758AB;\">print</span><span class=\"op\" style=\"color: #5E5E5E;\">(</span>name<span
        class=\"op\" style=\"color: #5E5E5E;\">,</span> <span class=\"st\" style=\"color:
        #20794D;\">'is an alias for'</span><span class=\"op\" style=\"color: #5E5E5E;\">,</span>
        <span class=\"fu\" style=\"color: #4758AB;\">table.concat</span><span class=\"op\"
        style=\"color: #5E5E5E;\">(</span>keys<span class=\"op\" style=\"color: #5E5E5E;\">,</span>
        <span class=\"st\" style=\"color: #20794D;\">'.'</span><span class=\"op\"
        style=\"color: #5E5E5E;\">))</span></span>\n<span id=\"cb2-5\"><span class=\"cf\"
        style=\"color: #003B4F;\">end</span></span></code></pre></div>\n<p>Do not
        rely on the internal structure, and do not modify the metatable. Here be dragons.</p>\n\n\n</section>\n</section>\n\n\n<div
        id=\"quarto-appendix\" class=\"default\"><section id=\"footnotes\" class=\"footnotes
        footnotes-end-of-document\"><h2 class=\"anchored quarto-appendix-heading\">Footnotes</h2>\n\n<ol>\n<li
        id=\"fn1\"><p>This feature exists only to ensure backwards compatibility.
        It is better to do comparisons in like <code>PANDOC_VERSION &gt;= '2.19'</code>
        instead.\u21A9\uFE0E</p></li>\n</ol>\n</section></div> ]]></description>\n
        \ <category>Haskell</category>\n  <category>Lua</category>\n  <category>pandoc</category>\n
        \ <category>Quarto</category>\n  <guid>https://tarleb.com/posts/haskell-lua-objects/index.html</guid>\n
        \ <pubDate>Wed, 07 Sep 2022 00:00:00 GMT</pubDate>\n</item>\n<item>\n  <title>Generating
        a sitemap with Quarto</title>\n  <dc:creator>Albert Krewinkel</dc:creator>\n
        \ <link>https://tarleb.com/posts/quarto-sitemap/index.html</link>\n  <description><![CDATA[
        \n\n\n\n<p>Sitemaps are an easy way to list all pages that a search engine
        should crawl and index. Quarto supports the standard, XML based <a href=\"https://www.sitemaps.org/protocol.html\">Sitemap
        Protocol</a>, although that fact is a bit hidden in the docs.</p>\n<p>Quarto
        will automatically produce a sitemap if the website\u2019s URL is given as
        <code>site-url</code> property:</p>\n<div class=\"sourceCode\" id=\"cb1\"
        style=\"background: #f1f3f5;\"><pre class=\"sourceCode yaml code-with-copy\"><code
        class=\"sourceCode yaml\"><span id=\"cb1-1\"><span class=\"fu\" style=\"color:
        #4758AB;\">website</span><span class=\"kw\" style=\"color: #003B4F;\">:</span></span>\n<span
        id=\"cb1-2\"><span class=\"at\" style=\"color: #657422;\">  </span><span class=\"fu\"
        style=\"color: #4758AB;\">title</span><span class=\"kw\" style=\"color: #003B4F;\">:</span><span
        class=\"at\" style=\"color: #657422;\"> tarleb</span></span>\n<span id=\"cb1-3\"><span
        class=\"at\" style=\"color: #657422;\">  </span><span class=\"fu\" style=\"color:
        #4758AB;\">site-url</span><span class=\"kw\" style=\"color: #003B4F;\">:</span><span
        class=\"at\" style=\"color: #657422;\"> </span><span class=\"st\" style=\"color:
        #20794D;\">'https://tarleb.com'</span></span>\n<span id=\"cb1-4\"><span class=\"at\"
        style=\"color: #657422;\">  </span><span class=\"fu\" style=\"color: #4758AB;\">site-path</span><span
        class=\"kw\" style=\"color: #003B4F;\">:</span><span class=\"at\" style=\"color:
        #657422;\"> </span><span class=\"st\" style=\"color: #20794D;\">'/'</span></span></code></pre></div>\n<p>The
        URL will contain a colon <code>:</code>, which is why the YAML value must
        be put in quotes.</p>\n<p>You\u2019ll find the <code>sitemap.xml</code> file
        in your <code>_site</code> folder after re-rendering your pages with <code>quarto
        render</code>.</p>\n\n\n\n ]]></description>\n  <category>quarto</category>\n
        \ <guid>https://tarleb.com/posts/quarto-sitemap/index.html</guid>\n  <pubDate>Wed,
        24 Aug 2022 00:00:00 GMT</pubDate>\n</item>\n<item>\n  <title>Pandoc resources</title>\n
        \ <dc:creator>Albert Krewinkel</dc:creator>\n  <link>https://tarleb.com/posts/pandoc-resources/index.html</link>\n
        \ <description><![CDATA[ \n\n\n\n<p>These are the resources that I\u2019d
        want to have if I was to learn about <a href=\"https://pandoc.org/\">pandoc
        (the universal document converter)</a> all over again:</p>\n<section id=\"installing\"
        class=\"level2\">\n<h2 class=\"anchored\" data-anchor-id=\"installing\">Installing</h2>\n<dl>\n<dt><a
        href=\"https://github.com/jgm/pandoc/releases/latest\">latest release</a></dt>\n<dd>\nThe
        GitHub release page has installers for Windows, macOS, and Linux.\n</dd>\n<dt><a
        href=\"https://hub.docker.com/u/pandoc\">Docker images</a></dt>\n<dd>\n<p>There
        are three types of pandoc Docker images:</p>\n<ul>\n<li><a href=\"https://hub.docker.com/r/pandoc/minimal\">minimal</a>
        \u2013 very small, just the bare pandoc binary;</li>\n<li><a href=\"https://hub.docker.com/r/pandoc/core\">core</a>
        \u2013 includes pandoc-crossref and helpers programs, e.g. those used by pandoc
        for SVG image conversion;</li>\n<li><a href=\"https://hub.docker.com/r/pandoc/latex\">latex</a>
        \u2013 like core, plus TeXLive with all packages required by the default template.</li>\n</ul>\n<p>These
        images can be used as an alternative to a system-wide installation. The image
        repository descriptions also explain how the images can be used.</p>\n</dd>\n</dl>\n</section>\n<section
        id=\"documentation\" class=\"level2\">\n<h2 class=\"anchored\" data-anchor-id=\"documentation\">Documentation</h2>\n<dl>\n<dt><a
        href=\"https://pandoc.org/MANUAL.html\">manual</a></dt>\n<dd>\n<p>The <a href=\"https://pandoc.org/MANUAL.html\">official
        pandoc manual</a>. When in doubt, this should always be the first resource
        to check. It covers all command line options, defaults files settings, format
        extensions, etc.</p>\n<p>Note that this always documents the latest pandoc
        version. If something isn\u2019t working as documented, you may need to update.</p>\n</dd>\n<dt><a
        href=\"https://pandoc.org/faqs.html\">FAQs</a></dt>\n<dd>\nFrequently Asked
        Questions; click on the questions to see the answer.\n</dd>\n<dt><a href=\"https://github.com/jgm/pandoc/wiki\">Wiki</a></dt>\n<dd>\nPandoc\u2019s
        GitHub wiki; contains many additional resources, links, and tips.\n</dd>\n<dt><a
        href=\"https://pandoc.org/lua-filters\">Lua filters</a></dt>\n<dd>\nHow to
        modify a document programmatically; also documents all constructors and utility
        functions exposed by pandoc.\n</dd>\n<dt><a href=\"https://pandoc.org/custom-readers\">Custom
        reader</a></dt>\n<dd>\nInterface that allows to write parsers for otherwise
        unsupported formats.\n</dd>\n<dt><a href=\"https://pandoc.org/custom-writers\">Custom
        writers</a></dt>\n<dd>\nInterface that allows to use pandoc to convert to
        a custom output format.\n</dd>\n<dt>Format-specific documentation</dt>\n<dd>\n<p>The
        support for some formats is tune-able enough to warrant additional documentation.</p>\n<ul>\n<li><a
        href=\"https://pandoc.org/epub.html\">EPUB</a> \u2013 How to make an ebook</li>\n<li><a
        href=\"https://pandoc.org/org.html\">Org</a> \u2013 Emacs Org-mode</li>\n<li><a
        href=\"https://pandoc.org/jats.html\">JATS</a> \u2013 The Journal Article
        Tag Set</li>\n</ul>\n</dd>\n</dl>\n</section>\n<section id=\"getting-help\"
        class=\"level2\">\n<h2 class=\"anchored\" data-anchor-id=\"getting-help\">Getting
        help</h2>\n<p>Please make sure to search the web before posting.</p>\n<dl>\n<dt><a
        href=\"https://groups.google.com/g/pandoc-discuss\">pandoc-discuss</a></dt>\n<dd>\n<p>Official
        pandoc mailing list; usually the best way to get help. The main developers
        and many seasoned users lurk here and answer questions.</p>\n<p>The web interface
        makes it seem like a Google account is required to post, but this isn\u2019t
        so: Write a mail to <span class=\"obfuscated-mail-address\" data-user=\"pandoc-discuss+subscribe\"
        data-domain=\"googlegroups.com\"><em>obfuscated mail address</em></span> to
        subscribe to the list with any mail address.</p>\n</dd>\n<dt><a href=\"https://stackoverflow.com/tags/pandoc/\">StackOverflow</a></dt>\n<dd>\nPost
        here to reach a more programming oriented group of people. Please <em>do not</em>
        cross-post, many people that follow the <a href=\"https://stackoverflow.com/tags/pandoc/\">pandoc
        tag</a> have also subscribed to the mailing list.\n</dd>\n<dt><a href=\"https://tex.stackexchange.com/\">TeX/LaTeX
        Stack Exchange</a></dt>\n<dd>\nThis is a good place to ask for help when pandoc
        is used to generate PDFs via LaTeX. Be sure to include the (relevant parts)
        of the generated LaTeX output in your question, as most people there do not
        use pandoc. Some even seem to actively dislike it, so be prepared.\n</dd>\n</dl>\n</section>\n<section
        id=\"misc\" class=\"level2\">\n<h2 class=\"anchored\" data-anchor-id=\"misc\">Misc</h2>\n<dl>\n<dt><a
        href=\"https://fosstodon.org/@pandoc\">pandoc in the fediverse</a></dt>\n<dd>\nI
        use this Mastodon account to post small tips and updates.\n</dd>\n<dt><a href=\"https://quarto.org\">Quarto</a></dt>\n<dd>\nScientific
        and technical publishing system based on pandoc.\n</dd>\n<dt><a href=\"https://zettlr.com\">Zettlr</a></dt>\n<dd>\nMarkdown
        editor with \u201Czettelkasten\u201D functionality.\n</dd>\n</dl>\n</section>\n<section
        id=\"edits\" class=\"level2\">\n<h2 class=\"anchored\" data-anchor-id=\"edits\">Edits</h2>\n<ul>\n<li><em>2022-12-09</em>:
        Added Mastodon account in favor of Twitter; the account on the latter platform
        is no longer updated.</li>\n</ul>\n\n\n</section>\n\n ]]></description>\n
        \ <category>pandoc</category>\n  <guid>https://tarleb.com/posts/pandoc-resources/index.html</guid>\n
        \ <pubDate>Tue, 23 Aug 2022 00:00:00 GMT</pubDate>\n  <media:content url=\"https://tarleb.com/posts/pandoc-resources/pandoc.png\"
        medium=\"image\" type=\"image/png\" height=\"144\" width=\"144\"/>\n</item>\n<item>\n
        \ <title>Quarto Website with GitHub Actions</title>\n  <dc:creator>Albert
        Krewinkel</dc:creator>\n  <link>https://tarleb.com/posts/quarto-with-gh-pages/index.html</link>\n
        \ <description><![CDATA[ \n\n\n\n<p><a href=\"https://quarto.org\">Quarto</a>
        makes it very easy to publish a website via GitHub Pages: It is as simple
        as running <code>quarto publish gh-pages</code>. Here we explore a slightly
        different method that uses a GitHub Action to publish the website automatically
        every time it is updated.</p>\n<section id=\"classic-github-pages\" class=\"level2\">\n<h2
        class=\"anchored\" data-anchor-id=\"classic-github-pages\">Classic GitHub
        Pages</h2>\n<p>The classic way to publish a website via GitHub pages is to
        maintain a separate branch <code>gh-pages</code>. The branch is used to store
        the rendered HTML pages, and GitHub will publish the branch\u2019s contents
        as website everytime that branch is updated.</p>\n<p>Quarto uses this mechanism
        when called with</p>\n<div class=\"sourceCode\" id=\"cb1\" style=\"background:
        #f1f3f5;\"><pre class=\"sourceCode bash code-with-copy\"><code class=\"sourceCode
        bash\"><span id=\"cb1-1\"><span class=\"ex\" style=\"color: null;\">quarto</span>
        publish gh-pages</span></code></pre></div>\n<p>We can combine this with GitHub
        Actions easily, ensuring that the site is updated every time new content is
        pushed to the main branch.</p>\n<div class=\"sourceCode\" id=\"cb2\" style=\"background:
        #f1f3f5;\"><pre class=\"sourceCode yaml code-with-copy\"><code class=\"sourceCode
        yaml\"><span id=\"cb2-1\"><span class=\"co\" style=\"color: #5E5E5E;\"># file:
        .github/workflows/publish.yml</span></span>\n<span id=\"cb2-2\"><span class=\"fu\"
        style=\"color: #4758AB;\">name</span><span class=\"kw\" style=\"color: #003B4F;\">:</span><span
        class=\"at\" style=\"color: #657422;\"> Publish Website</span></span>\n<span
        id=\"cb2-3\"></span>\n<span id=\"cb2-4\"><span class=\"co\" style=\"color:
        #5E5E5E;\"># Allow one concurrent deployment</span></span>\n<span id=\"cb2-5\"><span
        class=\"fu\" style=\"color: #4758AB;\">concurrency</span><span class=\"kw\"
        style=\"color: #003B4F;\">:</span></span>\n<span id=\"cb2-6\"><span class=\"at\"
        style=\"color: #657422;\">  </span><span class=\"fu\" style=\"color: #4758AB;\">group</span><span
        class=\"kw\" style=\"color: #003B4F;\">:</span><span class=\"at\" style=\"color:
        #657422;\"> </span><span class=\"st\" style=\"color: #20794D;\">\"pages\"</span></span>\n<span
        id=\"cb2-7\"><span class=\"at\" style=\"color: #657422;\">  </span><span class=\"fu\"
        style=\"color: #4758AB;\">cancel-in-progress</span><span class=\"kw\" style=\"color:
        #003B4F;\">:</span><span class=\"at\" style=\"color: #657422;\"> </span><span
        class=\"ch\" style=\"color: #20794D;\">true</span></span>\n<span id=\"cb2-8\"></span>\n<span
        id=\"cb2-9\"><span class=\"fu\" style=\"color: #4758AB;\">on</span><span class=\"kw\"
        style=\"color: #003B4F;\">:</span></span>\n<span id=\"cb2-10\"><span class=\"at\"
        style=\"color: #657422;\">  </span><span class=\"fu\" style=\"color: #4758AB;\">push</span><span
        class=\"kw\" style=\"color: #003B4F;\">:</span></span>\n<span id=\"cb2-11\"><span
        class=\"at\" style=\"color: #657422;\">    </span><span class=\"fu\" style=\"color:
        #4758AB;\">branches</span><span class=\"kw\" style=\"color: #003B4F;\">:</span><span
        class=\"at\" style=\"color: #657422;\"> </span><span class=\"kw\" style=\"color:
        #003B4F;\">[</span><span class=\"st\" style=\"color: #20794D;\">'main'</span><span
        class=\"kw\" style=\"color: #003B4F;\">]</span></span>\n<span id=\"cb2-12\"></span>\n<span
        id=\"cb2-13\"><span class=\"fu\" style=\"color: #4758AB;\">jobs</span><span
        class=\"kw\" style=\"color: #003B4F;\">:</span></span>\n<span id=\"cb2-14\"><span
        class=\"at\" style=\"color: #657422;\">  </span><span class=\"fu\" style=\"color:
        #4758AB;\">quarto-publish</span><span class=\"kw\" style=\"color: #003B4F;\">:</span></span>\n<span
        id=\"cb2-15\"><span class=\"at\" style=\"color: #657422;\">    </span><span
        class=\"fu\" style=\"color: #4758AB;\">name</span><span class=\"kw\" style=\"color:
        #003B4F;\">:</span><span class=\"at\" style=\"color: #657422;\"> Publish with
        Quarto</span></span>\n<span id=\"cb2-16\"><span class=\"at\" style=\"color:
        #657422;\">    </span><span class=\"fu\" style=\"color: #4758AB;\">runs-on</span><span
        class=\"kw\" style=\"color: #003B4F;\">:</span><span class=\"at\" style=\"color:
        #657422;\"> ubuntu-latest</span></span>\n<span id=\"cb2-17\"><span class=\"at\"
        style=\"color: #657422;\">    </span><span class=\"fu\" style=\"color: #4758AB;\">steps</span><span
        class=\"kw\" style=\"color: #003B4F;\">:</span></span>\n<span id=\"cb2-18\"><span
        class=\"at\" style=\"color: #657422;\">      </span><span class=\"kw\" style=\"color:
        #003B4F;\">-</span><span class=\"at\" style=\"color: #657422;\"> </span><span
        class=\"fu\" style=\"color: #4758AB;\">name</span><span class=\"kw\" style=\"color:
        #003B4F;\">:</span><span class=\"at\" style=\"color: #657422;\"> Checkout
        repository</span></span>\n<span id=\"cb2-19\"><span class=\"at\" style=\"color:
        #657422;\">        </span><span class=\"fu\" style=\"color: #4758AB;\">uses</span><span
        class=\"kw\" style=\"color: #003B4F;\">:</span><span class=\"at\" style=\"color:
        #657422;\"> actions/checkout@v3</span></span>\n<span id=\"cb2-20\"><span class=\"at\"
        style=\"color: #657422;\">      </span><span class=\"kw\" style=\"color: #003B4F;\">-</span><span
        class=\"at\" style=\"color: #657422;\"> </span><span class=\"fu\" style=\"color:
        #4758AB;\">name</span><span class=\"kw\" style=\"color: #003B4F;\">:</span><span
        class=\"at\" style=\"color: #657422;\"> Install Quarto</span></span>\n<span
        id=\"cb2-21\"><span class=\"at\" style=\"color: #657422;\">        </span><span
        class=\"fu\" style=\"color: #4758AB;\">uses</span><span class=\"kw\" style=\"color:
        #003B4F;\">:</span><span class=\"at\" style=\"color: #657422;\"> quarto-dev/quarto-actions/setup@v2</span></span>\n<span
        id=\"cb2-22\"><span class=\"at\" style=\"color: #657422;\">      </span><span
        class=\"kw\" style=\"color: #003B4F;\">-</span><span class=\"at\" style=\"color:
        #657422;\"> </span><span class=\"fu\" style=\"color: #4758AB;\">name</span><span
        class=\"kw\" style=\"color: #003B4F;\">:</span><span class=\"at\" style=\"color:
        #657422;\"> Publish to GitHub Pages</span></span>\n<span id=\"cb2-23\"><span
        class=\"at\" style=\"color: #657422;\">        </span><span class=\"fu\" style=\"color:
        #4758AB;\">uses</span><span class=\"kw\" style=\"color: #003B4F;\">:</span><span
        class=\"at\" style=\"color: #657422;\"> quarto-dev/quarto-actions/publish@v2</span></span>\n<span
        id=\"cb2-24\"><span class=\"at\" style=\"color: #657422;\">        </span><span
        class=\"fu\" style=\"color: #4758AB;\">with</span><span class=\"kw\" style=\"color:
        #003B4F;\">:</span></span>\n<span id=\"cb2-25\"><span class=\"at\" style=\"color:
        #657422;\">          </span><span class=\"fu\" style=\"color: #4758AB;\">target</span><span
        class=\"kw\" style=\"color: #003B4F;\">:</span><span class=\"at\" style=\"color:
        #657422;\"> gh-pages</span></span></code></pre></div>\n<p>The <code>quart-dev/quart-actions/publish</code>
        action calls <code>quarto publish</code> internally. This is short, to the
        point, and won\u2019t interfere with local calls to <code>quarto publish gh-pages</code>.</p>\n</section>\n<section
        id=\"actions-only-pages-beta\" class=\"level2\">\n<h2 class=\"anchored\" data-anchor-id=\"actions-only-pages-beta\">Actions-only
        Pages (Beta)</h2>\n<p>GitHub recently added support for GitHub Pages that
        do not require an extra <code>gh-pages</code> branch. Instead, the website
        is compiled and pushed directly from an action.</p>\n<p>This takes slightly
        more code to set up, as the action must be granted the necessary permissions.
        However, it is still fairly short and quick to do.</p>\n<div class=\"sourceCode\"
        id=\"cb3\" style=\"background: #f1f3f5;\"><pre class=\"sourceCode yaml code-with-copy\"><code
        class=\"sourceCode yaml\"><span id=\"cb3-1\"><span class=\"co\" style=\"color:
        #5E5E5E;\"># file: .github/workflows/publish.yml</span></span>\n<span id=\"cb3-2\"><span
        class=\"fu\" style=\"color: #4758AB;\">name</span><span class=\"kw\" style=\"color:
        #003B4F;\">:</span><span class=\"at\" style=\"color: #657422;\"> Publish Website</span></span>\n<span
        id=\"cb3-3\"></span>\n<span id=\"cb3-4\"><span class=\"co\" style=\"color:
        #5E5E5E;\"># Allow one concurrent deployment</span></span>\n<span id=\"cb3-5\"><span
        class=\"fu\" style=\"color: #4758AB;\">concurrency</span><span class=\"kw\"
        style=\"color: #003B4F;\">:</span></span>\n<span id=\"cb3-6\"><span class=\"at\"
        style=\"color: #657422;\">  </span><span class=\"fu\" style=\"color: #4758AB;\">group</span><span
        class=\"kw\" style=\"color: #003B4F;\">:</span><span class=\"at\" style=\"color:
        #657422;\"> </span><span class=\"st\" style=\"color: #20794D;\">\"pages\"</span></span>\n<span
        id=\"cb3-7\"><span class=\"at\" style=\"color: #657422;\">  </span><span class=\"fu\"
        style=\"color: #4758AB;\">cancel-in-progress</span><span class=\"kw\" style=\"color:
        #003B4F;\">:</span><span class=\"at\" style=\"color: #657422;\"> </span><span
        class=\"ch\" style=\"color: #20794D;\">true</span></span>\n<span id=\"cb3-8\"></span>\n<span
        id=\"cb3-9\"><span class=\"co\" style=\"color: #5E5E5E;\"># Sets permissions
        of the GITHUB_TOKEN to allow deployment to GitHub Pages</span></span>\n<span
        id=\"cb3-10\"><span class=\"fu\" style=\"color: #4758AB;\">permissions</span><span
        class=\"kw\" style=\"color: #003B4F;\">:</span></span>\n<span id=\"cb3-11\"><span
        class=\"at\" style=\"color: #657422;\">  </span><span class=\"fu\" style=\"color:
        #4758AB;\">contents</span><span class=\"kw\" style=\"color: #003B4F;\">:</span><span
        class=\"at\" style=\"color: #657422;\"> read</span></span>\n<span id=\"cb3-12\"><span
        class=\"at\" style=\"color: #657422;\">  </span><span class=\"fu\" style=\"color:
        #4758AB;\">pages</span><span class=\"kw\" style=\"color: #003B4F;\">:</span><span
        class=\"at\" style=\"color: #657422;\"> write</span></span>\n<span id=\"cb3-13\"><span
        class=\"at\" style=\"color: #657422;\">  </span><span class=\"fu\" style=\"color:
        #4758AB;\">id-token</span><span class=\"kw\" style=\"color: #003B4F;\">:</span><span
        class=\"at\" style=\"color: #657422;\"> write</span></span>\n<span id=\"cb3-14\"></span>\n<span
        id=\"cb3-15\"><span class=\"fu\" style=\"color: #4758AB;\">on</span><span
        class=\"kw\" style=\"color: #003B4F;\">:</span></span>\n<span id=\"cb3-16\"><span
        class=\"at\" style=\"color: #657422;\">  </span><span class=\"fu\" style=\"color:
        #4758AB;\">push</span><span class=\"kw\" style=\"color: #003B4F;\">:</span></span>\n<span
        id=\"cb3-17\"><span class=\"at\" style=\"color: #657422;\">    </span><span
        class=\"fu\" style=\"color: #4758AB;\">branches</span><span class=\"kw\" style=\"color:
        #003B4F;\">:</span><span class=\"at\" style=\"color: #657422;\"> </span><span
        class=\"kw\" style=\"color: #003B4F;\">[</span><span class=\"st\" style=\"color:
        #20794D;\">'main'</span><span class=\"kw\" style=\"color: #003B4F;\">]</span></span>\n<span
        id=\"cb3-18\"></span>\n<span id=\"cb3-19\"><span class=\"fu\" style=\"color:
        #4758AB;\">jobs</span><span class=\"kw\" style=\"color: #003B4F;\">:</span></span>\n<span
        id=\"cb3-20\"><span class=\"at\" style=\"color: #657422;\">  </span><span
        class=\"fu\" style=\"color: #4758AB;\">quarto</span><span class=\"kw\" style=\"color:
        #003B4F;\">:</span></span>\n<span id=\"cb3-21\"><span class=\"at\" style=\"color:
        #657422;\">    </span><span class=\"fu\" style=\"color: #4758AB;\">runs-on</span><span
        class=\"kw\" style=\"color: #003B4F;\">:</span><span class=\"at\" style=\"color:
        #657422;\"> ubuntu-latest</span></span>\n<span id=\"cb3-22\"><span class=\"at\"
        style=\"color: #657422;\">    </span><span class=\"fu\" style=\"color: #4758AB;\">environment</span><span
        class=\"kw\" style=\"color: #003B4F;\">:</span></span>\n<span id=\"cb3-23\"><span
        class=\"at\" style=\"color: #657422;\">      </span><span class=\"fu\" style=\"color:
        #4758AB;\">name</span><span class=\"kw\" style=\"color: #003B4F;\">:</span><span
        class=\"at\" style=\"color: #657422;\"> github-pages</span></span>\n<span
        id=\"cb3-24\"><span class=\"at\" style=\"color: #657422;\">      </span><span
        class=\"fu\" style=\"color: #4758AB;\">url</span><span class=\"kw\" style=\"color:
        #003B4F;\">:</span><span class=\"at\" style=\"color: #657422;\"> ${{ steps.deployment.outputs.page_url
        }}</span></span>\n<span id=\"cb3-25\"><span class=\"at\" style=\"color: #657422;\">
        \   </span><span class=\"fu\" style=\"color: #4758AB;\">steps</span><span
        class=\"kw\" style=\"color: #003B4F;\">:</span></span>\n<span id=\"cb3-26\"><span
        class=\"at\" style=\"color: #657422;\">      </span><span class=\"kw\" style=\"color:
        #003B4F;\">-</span><span class=\"at\" style=\"color: #657422;\"> </span><span
        class=\"fu\" style=\"color: #4758AB;\">name</span><span class=\"kw\" style=\"color:
        #003B4F;\">:</span><span class=\"at\" style=\"color: #657422;\"> Checkout
        repository</span></span>\n<span id=\"cb3-27\"><span class=\"at\" style=\"color:
        #657422;\">        </span><span class=\"fu\" style=\"color: #4758AB;\">uses</span><span
        class=\"kw\" style=\"color: #003B4F;\">:</span><span class=\"at\" style=\"color:
        #657422;\"> actions/checkout@v3</span></span>\n<span id=\"cb3-28\"><span class=\"at\"
        style=\"color: #657422;\">      </span><span class=\"kw\" style=\"color: #003B4F;\">-</span><span
        class=\"at\" style=\"color: #657422;\"> </span><span class=\"fu\" style=\"color:
        #4758AB;\">name</span><span class=\"kw\" style=\"color: #003B4F;\">:</span><span
        class=\"at\" style=\"color: #657422;\"> Install Quarto</span></span>\n<span
        id=\"cb3-29\"><span class=\"at\" style=\"color: #657422;\">        </span><span
        class=\"fu\" style=\"color: #4758AB;\">uses</span><span class=\"kw\" style=\"color:
        #003B4F;\">:</span><span class=\"at\" style=\"color: #657422;\"> quarto-dev/quarto-actions/setup@v2</span></span>\n<span
        id=\"cb3-30\"><span class=\"at\" style=\"color: #657422;\">      </span><span
        class=\"kw\" style=\"color: #003B4F;\">-</span><span class=\"at\" style=\"color:
        #657422;\"> </span><span class=\"fu\" style=\"color: #4758AB;\">name</span><span
        class=\"kw\" style=\"color: #003B4F;\">:</span><span class=\"at\" style=\"color:
        #657422;\"> Setup Pages</span></span>\n<span id=\"cb3-31\"><span class=\"at\"
        style=\"color: #657422;\">        </span><span class=\"fu\" style=\"color:
        #4758AB;\">uses</span><span class=\"kw\" style=\"color: #003B4F;\">:</span><span
        class=\"at\" style=\"color: #657422;\"> actions/configure-pages@v1</span></span>\n<span
        id=\"cb3-32\"><span class=\"at\" style=\"color: #657422;\">      </span><span
        class=\"kw\" style=\"color: #003B4F;\">-</span><span class=\"at\" style=\"color:
        #657422;\"> </span><span class=\"fu\" style=\"color: #4758AB;\">name</span><span
        class=\"kw\" style=\"color: #003B4F;\">:</span><span class=\"at\" style=\"color:
        #657422;\"> Render Website</span></span>\n<span id=\"cb3-33\"><span class=\"at\"
        style=\"color: #657422;\">        </span><span class=\"fu\" style=\"color:
        #4758AB;\">run</span><span class=\"kw\" style=\"color: #003B4F;\">:</span><span
        class=\"at\" style=\"color: #657422;\"> quarto render</span></span>\n<span
        id=\"cb3-34\"><span class=\"at\" style=\"color: #657422;\">      </span><span
        class=\"kw\" style=\"color: #003B4F;\">-</span><span class=\"at\" style=\"color:
        #657422;\"> </span><span class=\"fu\" style=\"color: #4758AB;\">name</span><span
        class=\"kw\" style=\"color: #003B4F;\">:</span><span class=\"at\" style=\"color:
        #657422;\"> Upload artifact</span></span>\n<span id=\"cb3-35\"><span class=\"at\"
        style=\"color: #657422;\">        </span><span class=\"fu\" style=\"color:
        #4758AB;\">uses</span><span class=\"kw\" style=\"color: #003B4F;\">:</span><span
        class=\"at\" style=\"color: #657422;\"> actions/upload-pages-artifact@v1</span></span>\n<span
        id=\"cb3-36\"><span class=\"at\" style=\"color: #657422;\">        </span><span
        class=\"fu\" style=\"color: #4758AB;\">with</span><span class=\"kw\" style=\"color:
        #003B4F;\">:</span></span>\n<span id=\"cb3-37\"><span class=\"at\" style=\"color:
        #657422;\">          </span><span class=\"fu\" style=\"color: #4758AB;\">path</span><span
        class=\"kw\" style=\"color: #003B4F;\">:</span><span class=\"at\" style=\"color:
        #657422;\"> </span><span class=\"st\" style=\"color: #20794D;\">'_site'</span></span>\n<span
        id=\"cb3-38\"><span class=\"at\" style=\"color: #657422;\">      </span><span
        class=\"kw\" style=\"color: #003B4F;\">-</span><span class=\"at\" style=\"color:
        #657422;\"> </span><span class=\"fu\" style=\"color: #4758AB;\">name</span><span
        class=\"kw\" style=\"color: #003B4F;\">:</span><span class=\"at\" style=\"color:
        #657422;\"> Deploy to GitHub Pages</span></span>\n<span id=\"cb3-39\"><span
        class=\"at\" style=\"color: #657422;\">        </span><span class=\"fu\" style=\"color:
        #4758AB;\">id</span><span class=\"kw\" style=\"color: #003B4F;\">:</span><span
        class=\"at\" style=\"color: #657422;\"> deployment</span></span>\n<span id=\"cb3-40\"><span
        class=\"at\" style=\"color: #657422;\">        </span><span class=\"fu\" style=\"color:
        #4758AB;\">uses</span><span class=\"kw\" style=\"color: #003B4F;\">:</span><span
        class=\"at\" style=\"color: #657422;\"> actions/deploy-pages@main</span></span></code></pre></div>\n<p>Now
        we must change the setting to use the new publishing workflow:</p>\n<p>Under
        <em>Settings</em> \u2192 <em>Pages</em> \u2192 <em>Build and deployment</em>
        the source must be switched to \u201CGitHub Action\u201D:</p>\n<div class=\"quarto-figure
        quarto-figure-center\">\n<figure class=\"figure\">\n<p><img src=\"https://tarleb.com/posts/quarto-with-gh-pages/pages-settings.png\"
        class=\"img-fluid figure-img\"></p>\n<p></p><figcaption class=\"figure-caption\">Required
        setting to enable the new method</figcaption><p></p>\n</figure>\n</div>\n<p>The
        <code>gh-pages</code> branch is no longer needed and can be deleted.</p>\n</section>\n<section
        id=\"trade-offs\" class=\"level2\">\n<h2 class=\"anchored\" data-anchor-id=\"trade-offs\">Trade-offs</h2>\n<p>The
        branch-based method for GitHub pages always felt slightly inelegant. I prefer
        the new method, as it does not require an extra branch and feels much cleaner.
        We lose the ability to update the website via <code>quarto publish</code>,
        but as I usually rely on GitHub Actions to perform the updates, it doesn\u2019t
        affect me much: <code>git push</code> has the same effect. However, it seems
        important to be aware of this trade-off.</p>\n\n\n</section>\n\n ]]></description>\n
        \ <category>quarto</category>\n  <guid>https://tarleb.com/posts/quarto-with-gh-pages/index.html</guid>\n
        \ <pubDate>Mon, 08 Aug 2022 00:00:00 GMT</pubDate>\n  <media:content url=\"https://tarleb.com/posts/quarto-with-gh-pages/pages-settings.png\"
        medium=\"image\" type=\"image/png\" height=\"93\" width=\"144\"/>\n</item>\n<item>\n
        \ <title>Santa\u2019s Little Lua Scripts</title>\n  <dc:creator>Albert Krewinkel</dc:creator>\n
        \ <link>https://tarleb.com/posts/santas-little-lua-scripts/index.html</link>\n
        \ <description><![CDATA[ \n\n\n\n<p>Santa sighted deeply as worry and uncertainty
        gave way, leaving a feeling of relieve and accomplishment. The year was one
        of the worst he\u2019d seen so far. Large numbers of his helpers were moving
        from the North Pole to Antarctica to satisfy their ambient temperature preferences.
        There would be many telecommuting Elves this year, and each helper enjoyed
        additional autonomy. Tying everything together was a challenge. But he had
        succeeded: the wishes processing program was finished, and the elves would
        be able to help Santa from the comfort of their new homes.</p>\n<section id=\"wishes\"
        class=\"level2\">\n<h2 class=\"anchored\" data-anchor-id=\"wishes\">Wishes</h2>\n<p>The
        part of the wishes system that Santa had been working on was focused on classic
        toys: wooden bricks, dolls, and train sets.</p>\n<div class=\"sourceCode\"
        id=\"cb1\" style=\"background: #f1f3f5;\"><pre class=\"sourceCode haskell
        code-with-copy\"><code class=\"sourceCode haskell\"><span id=\"cb1-1\"><span
        class=\"kw\" style=\"color: #003B4F;\">data</span> <span class=\"dt\" style=\"color:
        #AD0000;\">Toy</span> <span class=\"ot\" style=\"color: #003B4F;\">=</span>
        <span class=\"dt\" style=\"color: #AD0000;\">Bricks</span> <span class=\"op\"
        style=\"color: #5E5E5E;\">|</span> <span class=\"dt\" style=\"color: #AD0000;\">TrainSet</span>
        <span class=\"op\" style=\"color: #5E5E5E;\">|</span> <span class=\"dt\" style=\"color:
        #AD0000;\">Doll</span> <span class=\"kw\" style=\"color: #003B4F;\">deriving</span>
        <span class=\"dt\" style=\"color: #AD0000;\">Show</span></span></code></pre></div>\n<p>The
        system also kept track of basic data about the children:</p>\n<div class=\"sourceCode\"
        id=\"cb2\" style=\"background: #f1f3f5;\"><pre class=\"sourceCode haskell
        code-with-copy\"><code class=\"sourceCode haskell\"><span id=\"cb2-1\"><span
        class=\"kw\" style=\"color: #003B4F;\">data</span> <span class=\"dt\" style=\"color:
        #AD0000;\">Behavior</span> <span class=\"ot\" style=\"color: #003B4F;\">=</span>
        <span class=\"dt\" style=\"color: #AD0000;\">Nice</span> <span class=\"op\"
        style=\"color: #5E5E5E;\">|</span> <span class=\"dt\" style=\"color: #AD0000;\">Naughty</span>
        <span class=\"kw\" style=\"color: #003B4F;\">deriving</span> (<span class=\"dt\"
        style=\"color: #AD0000;\">Eq</span>, <span class=\"dt\" style=\"color: #AD0000;\">Show</span>)</span>\n<span
        id=\"cb2-2\"></span>\n<span id=\"cb2-3\"><span class=\"kw\" style=\"color:
        #003B4F;\">data</span> <span class=\"dt\" style=\"color: #AD0000;\">Child</span>
        <span class=\"ot\" style=\"color: #003B4F;\">=</span> <span class=\"dt\" style=\"color:
        #AD0000;\">Child</span></span>\n<span id=\"cb2-4\">  {<span class=\"ot\" style=\"color:
        #003B4F;\"> childName     ::</span> <span class=\"dt\" style=\"color: #AD0000;\">Text</span></span>\n<span
        id=\"cb2-5\">  ,<span class=\"ot\" style=\"color: #003B4F;\"> childBehavior
        ::</span> <span class=\"dt\" style=\"color: #AD0000;\">Behavior</span></span>\n<span
        id=\"cb2-6\">  } <span class=\"kw\" style=\"color: #003B4F;\">deriving</span>
        (<span class=\"dt\" style=\"color: #AD0000;\">Show</span>)</span></code></pre></div>\n<p>Children
        and toys were tied together in a wish.</p>\n<div class=\"sourceCode\" id=\"cb3\"
        style=\"background: #f1f3f5;\"><pre class=\"sourceCode haskell code-with-copy\"><code
        class=\"sourceCode haskell\"><span id=\"cb3-1\"><span class=\"kw\" style=\"color:
        #003B4F;\">data</span> <span class=\"dt\" style=\"color: #AD0000;\">Wish</span>
        <span class=\"ot\" style=\"color: #003B4F;\">=</span> <span class=\"dt\" style=\"color:
        #AD0000;\">Wish</span></span>\n<span id=\"cb3-2\">  {<span class=\"ot\" style=\"color:
        #003B4F;\"> wishingChild ::</span> <span class=\"dt\" style=\"color: #AD0000;\">Child</span></span>\n<span
        id=\"cb3-3\">  ,<span class=\"ot\" style=\"color: #003B4F;\"> wishedToy    ::</span>
        <span class=\"dt\" style=\"color: #AD0000;\">Toy</span></span>\n<span id=\"cb3-4\">
        \ } <span class=\"kw\" style=\"color: #003B4F;\">deriving</span> (<span class=\"dt\"
        style=\"color: #AD0000;\">Show</span>)</span></code></pre></div>\n<p>It was
        most elegant. The problem for Santa was that the Elves, being independent
        and autonomous workers, needed to access and process the data in very custom
        ways. Unfortunately for him, very few Elves had a Haskell build environment
        installed, so he had to distribute the binary. Writing a completely custom
        processing language seemed like an enormous rabbit hole.</p>\n</section>\n<section
        id=\"lua\" class=\"level2\">\n<h2 class=\"anchored\" data-anchor-id=\"lua\">Lua</h2>\n<p>Fortunately,
        Santa had a better idea: <a href=\"https://lua.org/\">Lua</a>, an embeddable
        scripting language. He had been using it for some projects<sup>1</sup> and
        also made use of it in <a href=\"https://pandoc.org/lua-filters.html\">pandoc</a>,
        which he used to answer his mails. Santa would just need to expose the relevant
        parts of the Haskell system, so the Elves could access and script it as their
        hearts desired. He looked for a library, found <a href=\"https://github.com/hslua/hslua\">HsLua</a>,
        and got to work.</p>\n</section>\n<section id=\"exposing-data\" class=\"level2\">\n<h2
        class=\"anchored\" data-anchor-id=\"exposing-data\">Exposing data</h2>\n<p>Lua
        has a simple, yet powerful, stack-based <a href=\"https://www.lua.org/manual/5.4/manual.html#4\">API</a>.
        The first step towards exposing Haskell data was to push them to the Lua stack.
        Keeping things simple, Santa chose strings to represent toys:</p>\n<div class=\"sourceCode\"
        id=\"cb4\" style=\"background: #f1f3f5;\"><pre class=\"sourceCode haskell
        code-with-copy\"><code class=\"sourceCode haskell\"><span id=\"cb4-1\"><span
        class=\"ot\" style=\"color: #003B4F;\">pushToy ::</span> <span class=\"dt\"
        style=\"color: #AD0000;\">Toy</span> <span class=\"ot\" style=\"color: #003B4F;\">-&gt;</span>
        <span class=\"dt\" style=\"color: #AD0000;\">Lua</span> ()</span>\n<span id=\"cb4-2\">pushToy
        <span class=\"ot\" style=\"color: #003B4F;\">=</span> pushString <span class=\"op\"
        style=\"color: #5E5E5E;\">.</span> <span class=\"fu\" style=\"color: #4758AB;\">show</span></span></code></pre></div>\n<p>Lua
        offers only a single construct to structure data: tables. So that\u2019s what
        Child and Wish were represented with.</p>\n<div class=\"sourceCode\" id=\"cb5\"
        style=\"background: #f1f3f5;\"><pre class=\"sourceCode haskell code-with-copy\"><code
        class=\"sourceCode haskell\"><span id=\"cb5-1\"><span class=\"ot\" style=\"color:
        #003B4F;\">pushChild ::</span> <span class=\"dt\" style=\"color: #AD0000;\">Child</span>
        <span class=\"ot\" style=\"color: #003B4F;\">-&gt;</span> <span class=\"dt\"
        style=\"color: #AD0000;\">Lua</span> ()</span>\n<span id=\"cb5-2\">pushChild
        (<span class=\"dt\" style=\"color: #AD0000;\">Child</span> name behavior)
        <span class=\"ot\" style=\"color: #003B4F;\">=</span> <span class=\"kw\" style=\"color:
        #003B4F;\">do</span></span>\n<span id=\"cb5-3\">  <span class=\"co\" style=\"color:
        #5E5E5E;\">-- create new Lua table on the stack</span></span>\n<span id=\"cb5-4\">
        \ newtable</span>\n<span id=\"cb5-5\">  <span class=\"co\" style=\"color:
        #5E5E5E;\">-- push string to stack</span></span>\n<span id=\"cb5-6\">  pushText
        name</span>\n<span id=\"cb5-7\">  <span class=\"co\" style=\"color: #5E5E5E;\">--
        table now in position 2; assign string to field in table</span></span>\n<span
        id=\"cb5-8\">  setfield (nth <span class=\"dv\" style=\"color: #AD0000;\">2</span>)
        <span class=\"st\" style=\"color: #20794D;\">\"name\"</span></span>\n<span
        id=\"cb5-9\"></span>\n<span id=\"cb5-10\">  <span class=\"co\" style=\"color:
        #5E5E5E;\">-- push boolean to stack</span></span>\n<span id=\"cb5-11\">  pushBool
        (behavior <span class=\"op\" style=\"color: #5E5E5E;\">==</span> <span class=\"dt\"
        style=\"color: #AD0000;\">Nice</span>)</span>\n<span id=\"cb5-12\">  setfield
        (nth <span class=\"dv\" style=\"color: #AD0000;\">2</span>) <span class=\"st\"
        style=\"color: #20794D;\">\"nice\"</span></span>\n<span id=\"cb5-13\"></span>\n<span
        id=\"cb5-14\"><span class=\"ot\" style=\"color: #003B4F;\">pushWish ::</span>
        <span class=\"dt\" style=\"color: #AD0000;\">Wish</span> <span class=\"ot\"
        style=\"color: #003B4F;\">-&gt;</span> <span class=\"dt\" style=\"color: #AD0000;\">Lua</span>
        ()</span>\n<span id=\"cb5-15\">pushWish (<span class=\"dt\" style=\"color:
        #AD0000;\">Wish</span> child toy) <span class=\"ot\" style=\"color: #003B4F;\">=</span>
        <span class=\"kw\" style=\"color: #003B4F;\">do</span></span>\n<span id=\"cb5-16\">
        \ newtable</span>\n<span id=\"cb5-17\">  pushChild child</span>\n<span id=\"cb5-18\">
        \ setfield (nth <span class=\"dv\" style=\"color: #AD0000;\">2</span>) <span
        class=\"st\" style=\"color: #20794D;\">\"child\"</span></span>\n<span id=\"cb5-19\">
        \ pushToy toy</span>\n<span id=\"cb5-20\">  setfield (nth <span class=\"dv\"
        style=\"color: #AD0000;\">2</span>) <span class=\"st\" style=\"color: #20794D;\">\"toy\"</span></span></code></pre></div>\n</section>\n<section
        id=\"running-scripts\" class=\"level2\">\n<h2 class=\"anchored\" data-anchor-id=\"running-scripts\">Running
        scripts</h2>\n<p>Santa\u2019s goal for now was to allow his Elves to filter
        the list of wishes so each finds the ones relevant to them. For example, if
        an Elf only cares about wishes for train sets from children who were nice,
        then they should be able to use a script to filter those wishes out.</p>\n<div
        class=\"sourceCode\" id=\"cb6\" style=\"background: #f1f3f5;\"><pre class=\"sourceCode
        lua code-with-copy\"><code class=\"sourceCode lua\"><span id=\"cb6-1\"><span
        class=\"cf\" style=\"color: #003B4F;\">return</span> <span class=\"kw\" style=\"color:
        #003B4F;\">function</span> <span class=\"op\" style=\"color: #5E5E5E;\">(</span>wish<span
        class=\"op\" style=\"color: #5E5E5E;\">)</span></span>\n<span id=\"cb6-2\">
        \ <span class=\"cf\" style=\"color: #003B4F;\">return</span> wish<span class=\"op\"
        style=\"color: #5E5E5E;\">.</span>child<span class=\"op\" style=\"color: #5E5E5E;\">.</span>nice
        <span class=\"kw\" style=\"color: #003B4F;\">and</span></span>\n<span id=\"cb6-3\">
        \   wish<span class=\"op\" style=\"color: #5E5E5E;\">.</span>toy <span class=\"op\"
        style=\"color: #5E5E5E;\">==</span> <span class=\"st\" style=\"color: #20794D;\">'TrainSet'</span></span>\n<span
        id=\"cb6-4\"><span class=\"kw\" style=\"color: #003B4F;\">end</span></span></code></pre></div>\n<p>The
        script returns a (lambda) function that serves as a predicate for wishes.
        The function can be thought of having the type <code>Wish -&gt; IO Bool</code>.
        Santa needed to turn the Lua lambda function into an actual Haskell function
        <code>runPredicate :: Wish -&gt; Lua Bool</code>. If Santa assumed that the
        lambda function was at the top of the Lua stack, then he could push a <code>Wish</code>
        value to the Lua stack, call the function, and retrieve the result value from
        the stack.</p>\n<div class=\"sourceCode\" id=\"cb7\" style=\"background: #f1f3f5;\"><pre
        class=\"sourceCode haskell code-with-copy\"><code class=\"sourceCode haskell\"><span
        id=\"cb7-1\"><span class=\"ot\" style=\"color: #003B4F;\">runPredicate ::</span>
        <span class=\"dt\" style=\"color: #AD0000;\">Wish</span> <span class=\"ot\"
        style=\"color: #003B4F;\">-&gt;</span> <span class=\"dt\" style=\"color: #AD0000;\">Lua</span>
        <span class=\"dt\" style=\"color: #AD0000;\">Bool</span></span>\n<span id=\"cb7-2\">runPredicate
        wish <span class=\"ot\" style=\"color: #003B4F;\">=</span> <span class=\"kw\"
        style=\"color: #003B4F;\">do</span></span>\n<span id=\"cb7-3\">  <span class=\"co\"
        style=\"color: #5E5E5E;\">-- Assume filter function is at the top of the stack;</span></span>\n<span
        id=\"cb7-4\">  <span class=\"co\" style=\"color: #5E5E5E;\">-- create a copy
        so we can re-use it.</span></span>\n<span id=\"cb7-5\">  pushvalue top</span>\n<span
        id=\"cb7-6\">  pushWish wish</span>\n<span id=\"cb7-7\">  <span class=\"co\"
        style=\"color: #5E5E5E;\">-- Call the function. There is one argument on the
        stack,</span></span>\n<span id=\"cb7-8\">  <span class=\"co\" style=\"color:
        #5E5E5E;\">-- and we expect one result to be returned.</span></span>\n<span
        id=\"cb7-9\">  call (<span class=\"dt\" style=\"color: #AD0000;\">NumArgs</span>
        <span class=\"dv\" style=\"color: #AD0000;\">1</span>) (<span class=\"dt\"
        style=\"color: #AD0000;\">NumResults</span> <span class=\"dv\" style=\"color:
        #AD0000;\">1</span>)</span>\n<span id=\"cb7-10\">  toboolean top <span class=\"op\"
        style=\"color: #5E5E5E;\">&lt;*</span> pop <span class=\"dv\" style=\"color:
        #AD0000;\">1</span></span></code></pre></div>\n<p>What remained was loading
        the Elves\u2019 script files. Santa did this with <a href=\"https://hackage.haskell.org/package/hslua/docs/Foreign-Lua-Core.html#v:dofile\"><code>dofile</code></a>
        of type <code>FilePath -&gt; Lua Status</code>. The predicate then ends up
        on the top of the Lua stack, and can be called through <code>runPredicate</code>,
        e.g.&nbsp;to select a subset of wishes via <a href=\"https://hackage.haskell.org/package/base/docs/Control-Monad.html#v:filterM\"><code>filterM</code></a>.</p>\n<div
        class=\"sourceCode\" id=\"cb8\" style=\"background: #f1f3f5;\"><pre class=\"sourceCode
        haskell code-with-copy\"><code class=\"sourceCode haskell\"><span id=\"cb8-1\"><span
        class=\"ot\" style=\"color: #003B4F;\">main ::</span> <span class=\"dt\" style=\"color:
        #AD0000;\">IO</span> ()</span>\n<span id=\"cb8-2\">main <span class=\"ot\"
        style=\"color: #003B4F;\">=</span> <span class=\"kw\" style=\"color: #003B4F;\">do</span></span>\n<span
        id=\"cb8-3\">  filterFile <span class=\"ot\" style=\"color: #003B4F;\">&lt;-</span>
        <span class=\"fu\" style=\"color: #4758AB;\">fmap</span> (<span class=\"op\"
        style=\"color: #5E5E5E;\">!!</span> <span class=\"dv\" style=\"color: #AD0000;\">0</span>)
        getArgs <span class=\"co\" style=\"color: #5E5E5E;\">-- get first argument</span></span>\n<span
        id=\"cb8-4\">  result <span class=\"ot\" style=\"color: #003B4F;\">&lt;-</span>
        run <span class=\"op\" style=\"color: #5E5E5E;\">$</span> <span class=\"kw\"
        style=\"color: #003B4F;\">do</span></span>\n<span id=\"cb8-5\">    _status
        <span class=\"ot\" style=\"color: #003B4F;\">&lt;-</span> dofile filterFile</span>\n<span
        id=\"cb8-6\">    filterM runPredicate wishes</span>\n<span id=\"cb8-7\">  <span
        class=\"fu\" style=\"color: #4758AB;\">print</span> result</span></code></pre></div>\n<p>Santa
        tested his creation on a short list of wishes</p>\n<div class=\"sourceCode\"
        id=\"cb9\" style=\"background: #f1f3f5;\"><pre class=\"sourceCode haskell
        code-with-copy\"><code class=\"sourceCode haskell\"><span id=\"cb9-1\"><span
        class=\"ot\" style=\"color: #003B4F;\">wishes ::</span> [<span class=\"dt\"
        style=\"color: #AD0000;\">Wish</span>]</span>\n<span id=\"cb9-2\">wishes <span
        class=\"ot\" style=\"color: #003B4F;\">=</span></span>\n<span id=\"cb9-3\">
        \ [ <span class=\"dt\" style=\"color: #AD0000;\">Wish</span> (<span class=\"dt\"
        style=\"color: #AD0000;\">Child</span> <span class=\"st\" style=\"color: #20794D;\">\"Theodor\"</span>
        <span class=\"dt\" style=\"color: #AD0000;\">Nice</span>) <span class=\"dt\"
        style=\"color: #AD0000;\">Bricks</span></span>\n<span id=\"cb9-4\">  , <span
        class=\"dt\" style=\"color: #AD0000;\">Wish</span> (<span class=\"dt\" style=\"color:
        #AD0000;\">Child</span> <span class=\"st\" style=\"color: #20794D;\">\"Philine\"</span>
        <span class=\"dt\" style=\"color: #AD0000;\">Nice</span>) <span class=\"dt\"
        style=\"color: #AD0000;\">TrainSet</span></span>\n<span id=\"cb9-5\">  , <span
        class=\"dt\" style=\"color: #AD0000;\">Wish</span> (<span class=\"dt\" style=\"color:
        #AD0000;\">Child</span> <span class=\"st\" style=\"color: #20794D;\">\"Steve\"</span>
        <span class=\"dt\" style=\"color: #AD0000;\">Naughty</span>) <span class=\"dt\"
        style=\"color: #AD0000;\">Doll</span></span>\n<span id=\"cb9-6\">  ]</span></code></pre></div>\n<p>by
        running <code>runhaskell wish-filter predicate.lua</code>. To his uttermost
        satisfaction, the terminal echoed the right information back to him.</p>\n<pre><code>[Wish
        {wishingChild = Child {childName = \"Philine\", childBehavior = Nice}, wishedToy
        = TrainSet}]</code></pre>\n<p>He reclined in his chair, shut down his device,
        and enjoyed a double chocolate chip cookie of which he felt very deserving
        now.</p>\n<hr>\n<p>Santa\u2019s full code, as presented here, is available
        as part of the examples at <a href=\"https://github.com/hslua/hslua\" class=\"uri\">https://github.com/hslua/hslua</a>.</p>\n\n\n</section>\n\n\n<div
        id=\"quarto-appendix\" class=\"default\"><section id=\"footnotes\" class=\"footnotes
        footnotes-end-of-document\"><h2 class=\"anchored quarto-appendix-heading\">Footnotes</h2>\n\n<ol>\n<li
        id=\"fn1\"><p>Santa learned about Lua from his game-devs. Now he uses it to
        keep his security teams on their toes with <a href=\"https://nmap.org\">nmap</a>
        and <a href=\"https://wireshark.org/\">Wireshark</a>; many of the North Pole\u2019s
        servers contain custom Lua scripts, too (<a href=\"https://redis.io/commands/eval\">redis</a>,
        <a href=\"https://github.com/openresty\">nginx/OpenResty</a>, <a href=\"https://www.haproxy.com/blog/5-ways-to-extend-haproxy-with-lua/\">HAProxy</a>,
        <a href=\"https://doc.powerdns.com/authoritative/lua-records/index.html\">PowerDNS</a>).\u21A9\uFE0E</p></li>\n</ol>\n</section></div>
        ]]></description>\n  <category>lua</category>\n  <category>hslua</category>\n
        \ <category>example</category>\n  <guid>https://tarleb.com/posts/santas-little-lua-scripts/index.html</guid>\n
        \ <pubDate>Sun, 06 Dec 2020 00:00:00 GMT</pubDate>\n</item>\n<item>\n  <title>PDF
        Version of the Lua Manual</title>\n  <dc:creator>Albert Krewinkel</dc:creator>\n
        \ <link>https://tarleb.com/posts/pdf-of-the-lua-manual/index.html</link>\n
        \ <description><![CDATA[ \n\n\n\n<p>A question came up on the Lua mailing
        list, asking whether there was a PDF version of the <a href=\"https://lua.org/manual/5.4/manual.html\">Lua
        manual</a>. This is, of course, the home domain of pandoc, and I got nerd-sniped
        into producing a PDF (and ePUB) version of the manual.</p>\n<p>This is a good
        opportunity to showcase some pandoc features. The post describes the process
        of going from an HTML web page to a PDF file via LaTeX and pandoc. We will
        see how to</p>\n<ol type=\"1\">\n<li>quickly convert documents with pandoc;</li>\n<li>use
        Lua filters to improve the result by modifying the document; and</li>\n<li>fine-tune
        the output by setting appropriate pandoc options.</li>\n</ol>\n<section id=\"invoking-pandoc\"
        class=\"level2\">\n<h2 class=\"anchored\" data-anchor-id=\"invoking-pandoc\">Invoking
        pandoc</h2>\n<p>The first step is to call pandoc on the Lua manual website.
        Even when keeping everything bare-bones, the result is already decent:</p>\n<pre><code>pandoc
        --pdf-engine=xelatex --output=lua-manual.pdf \\\n    \"https://lua.org/manual/5.4/manual.html\"</code></pre>\n<p>Produces</p>\n<div
        class=\"quarto-figure quarto-figure-center\">\n<figure class=\"figure\">\n<p><img
        src=\"https://tarleb.com/posts/pdf-of-the-lua-manual/lua-refman-naive.png\"
        class=\"img-fluid figure-img\"></p>\n<p></p><figcaption class=\"figure-caption\">First
        page of unoptimized PDF</figcaption><p></p>\n</figure>\n</div>\n<p>This requires
        a somewhat recent version of pandoc as well as XeLaTeX to be installed. It
        is possible to forgo the trouble of installing the requirements by using the
        <em>pandoc/latex</em> Docker image:</p>\n<pre><code>docker run --rm -v \"$PWD\":/data
        -u $(id -u):$(id -g) pandoc/latex:2.9.2.1 \\\n    --pdf-engine=xelatex --output=lua-manual.pdf
        \\\n    \"https://lua.org/manual/5.4/manual.html\"</code></pre>\n</section>\n<section
        id=\"replacing-characters\" class=\"level2\">\n<h2 class=\"anchored\" data-anchor-id=\"replacing-characters\">Replacing
        characters</h2>\n<p>The above commands will produce warnings about characters
        which are unavailable in the default fonts. We don\u2019t want characters
        to go missing, of course, so let\u2019s fix that first. The warnings are:</p>\n<pre><code>[WARNING]
        Missing character: There is no \u2264 (U+2264) in font [lmmono10-regular]:!\n[WARNING]
        Missing character: There is no \u2264 (U+2264) in font [lmmono10-regular]:!\n[WARNING]
        Missing character: There is no \u03C0 (U+03C0) in font [lmroman10-italic]:mapping=tex-text;!</code></pre>\n<p>Searching
        the page for <code>\u2264</code> shows that it is used in inline code, while
        <code>\u03C0</code> occurs as emphasized character in the description of <code>math.pi</code>.
        We could, of course, search for a font which has the appropriate glyphs and
        instruct pandoc/LaTeX to use it. But we\u2019ll go a different route.</p>\n<p>A
        good way to improve the result of a converstion is to use a pandoc <a href=\"https://pandoc.org/lua-filters.html\">Lua
        filter</a>. We create a file called <code>beautify-manual.lua</code> and pass
        it to pandoc via the <code>--lua-filter=beautify-manual.lua</code> command
        line option.</p>\n<p>Handling <code>\u2264</code> is straight forward, we
        just replace the char with the slightly uglier looking ASCII sequence <code>&lt;=</code>
        in all code elements.</p>\n<div class=\"sourceCode\" id=\"cb4\" style=\"background:
        #f1f3f5;\"><pre class=\"sourceCode lua code-with-copy\"><code class=\"sourceCode
        lua\"><span id=\"cb4-1\"><span class=\"kw\" style=\"color: #003B4F;\">function</span>
        Code <span class=\"op\" style=\"color: #5E5E5E;\">(</span>c<span class=\"op\"
        style=\"color: #5E5E5E;\">)</span></span>\n<span id=\"cb4-2\">  c<span class=\"op\"
        style=\"color: #5E5E5E;\">.</span>text <span class=\"op\" style=\"color: #5E5E5E;\">=</span>
        c<span class=\"op\" style=\"color: #5E5E5E;\">.</span>text<span class=\"op\"
        style=\"color: #5E5E5E;\">:</span><span class=\"fu\" style=\"color: #4758AB;\">gsub</span><span
        class=\"op\" style=\"color: #5E5E5E;\">(</span><span class=\"st\" style=\"color:
        #20794D;\">'\u2264'</span><span class=\"op\" style=\"color: #5E5E5E;\">,</span>
        <span class=\"st\" style=\"color: #20794D;\">'&lt;='</span><span class=\"op\"
        style=\"color: #5E5E5E;\">)</span></span>\n<span id=\"cb4-3\">  <span class=\"cf\"
        style=\"color: #003B4F;\">return</span> c</span>\n<span id=\"cb4-4\"><span
        class=\"kw\" style=\"color: #003B4F;\">end</span></span></code></pre></div>\n<p>While
        there is no italics version <code>\u03C0</code> in the default font, there
        <em>is</em> such a glyph in the default math font. Pandoc\u2019s internal
        representation for <em>\u03C0</em> is <code>Emph [Str \"\u03C0\"]</code>,
        which we replace with a math element holding the same content.</p>\n<div class=\"sourceCode\"
        id=\"cb5\" style=\"background: #f1f3f5;\"><pre class=\"sourceCode lua code-with-copy\"><code
        class=\"sourceCode lua\"><span id=\"cb5-1\"><span class=\"kw\" style=\"color:
        #003B4F;\">function</span> Emph <span class=\"op\" style=\"color: #5E5E5E;\">(</span>e<span
        class=\"op\" style=\"color: #5E5E5E;\">)</span></span>\n<span id=\"cb5-2\">
        \ <span class=\"kw\" style=\"color: #003B4F;\">local</span> s <span class=\"op\"
        style=\"color: #5E5E5E;\">=</span> e<span class=\"op\" style=\"color: #5E5E5E;\">.</span>content<span
        class=\"op\" style=\"color: #5E5E5E;\">[</span><span class=\"dv\" style=\"color:
        #AD0000;\">1</span><span class=\"op\" style=\"color: #5E5E5E;\">]</span></span>\n<span
        id=\"cb5-3\">  <span class=\"cf\" style=\"color: #003B4F;\">if</span> <span
        class=\"op\" style=\"color: #5E5E5E;\">#</span>e<span class=\"op\" style=\"color:
        #5E5E5E;\">.</span>content <span class=\"op\" style=\"color: #5E5E5E;\">==</span>
        <span class=\"dv\" style=\"color: #AD0000;\">1</span> <span class=\"kw\" style=\"color:
        #003B4F;\">and</span> s<span class=\"op\" style=\"color: #5E5E5E;\">.</span>tag
        <span class=\"op\" style=\"color: #5E5E5E;\">==</span> <span class=\"st\"
        style=\"color: #20794D;\">'Str'</span> <span class=\"kw\" style=\"color: #003B4F;\">and</span>
        s<span class=\"op\" style=\"color: #5E5E5E;\">.</span>text <span class=\"op\"
        style=\"color: #5E5E5E;\">==</span> <span class=\"st\" style=\"color: #20794D;\">'\u03C0'</span>
        <span class=\"cf\" style=\"color: #003B4F;\">then</span></span>\n<span id=\"cb5-4\">
        \   <span class=\"cf\" style=\"color: #003B4F;\">return</span> pandoc<span
        class=\"op\" style=\"color: #5E5E5E;\">.</span>Math<span class=\"op\" style=\"color:
        #5E5E5E;\">(</span><span class=\"st\" style=\"color: #20794D;\">'InlineMath'</span><span
        class=\"op\" style=\"color: #5E5E5E;\">,</span> <span class=\"st\" style=\"color:
        #20794D;\">'\u03C0'</span><span class=\"op\" style=\"color: #5E5E5E;\">)</span></span>\n<span
        id=\"cb5-5\">  <span class=\"cf\" style=\"color: #003B4F;\">end</span></span>\n<span
        id=\"cb5-6\"><span class=\"kw\" style=\"color: #003B4F;\">end</span></span></code></pre></div>\n<p>The
        document now compiles without warnings, and all characters are properly included.</p>\n</section>\n<section
        id=\"add-table-of-contents\" class=\"level2\">\n<h2 class=\"anchored\" data-anchor-id=\"add-table-of-contents\">Add
        Table of Contents</h2>\n<p>The Lua manual is long, often used as a reference,
        and, in its HTML version, comes with a table of contents on a separate page.
        The PDF, for it to be useful as a reference, should have a table of contents
        as well. Pandoc can be told to generate a table of contents by adding the
        <code>--toc</code> command line flag. The toc depth is controlled via <code>--toc-depth</code>;
        <code>2</code> is a good setting here. However, in this case, the result is
        neither pleasing nor informative:</p>\n<div class=\"quarto-figure quarto-figure-center\">\n<figure
        class=\"figure\">\n<p><img src=\"https://tarleb.com/posts/pdf-of-the-lua-manual/bad-toc.png\"
        class=\"img-fluid figure-img\"></p>\n<p></p><figcaption class=\"figure-caption\">Bad
        looking table of contents</figcaption><p></p>\n</figure>\n</div>\n<p>Something
        is terribly wrong. By inspecting the parsed document by running <code>pandoc
        --to=native \u2026</code>, we see that all <em>Header</em>s contain a <em>Span</em>.
        That span holds the actual contents. Apparently LaTeX does not like this and
        omits the content of the span when generating the toc.</p>\n<p>The span also
        has the id used by links to the header. Numbered sections start with the section
        number, which we\u2019d rather produce via pandoc.</p>\n<div class=\"sourceCode\"
        id=\"cb6\" style=\"background: #f1f3f5;\"><pre class=\"sourceCode lua code-with-copy\"><code
        class=\"sourceCode lua\"><span id=\"cb6-1\"><span class=\"kw\" style=\"color:
        #003B4F;\">function</span> Header <span class=\"op\" style=\"color: #5E5E5E;\">(</span>h<span
        class=\"op\" style=\"color: #5E5E5E;\">)</span></span>\n<span id=\"cb6-2\">
        \ <span class=\"co\" style=\"color: #5E5E5E;\">-- Unnumbered sections have
        the main contents as the first element.</span></span>\n<span id=\"cb6-3\">
        \ <span class=\"co\" style=\"color: #5E5E5E;\">-- Numbered sections start
        with the number and an em-dash, so</span></span>\n<span id=\"cb6-4\">  <span
        class=\"co\" style=\"color: #5E5E5E;\">-- the Span is the fifth element (Lua
        multipass).</span></span>\n<span id=\"cb6-5\">  <span class=\"kw\" style=\"color:
        #003B4F;\">local</span> span</span>\n<span id=\"cb6-6\">  <span class=\"cf\"
        style=\"color: #003B4F;\">if</span> h<span class=\"op\" style=\"color: #5E5E5E;\">.</span>content<span
        class=\"op\" style=\"color: #5E5E5E;\">[</span><span class=\"dv\" style=\"color:
        #AD0000;\">1</span><span class=\"op\" style=\"color: #5E5E5E;\">].</span>tag
        <span class=\"op\" style=\"color: #5E5E5E;\">==</span> <span class=\"st\"
        style=\"color: #20794D;\">'Str'</span> <span class=\"kw\" style=\"color: #003B4F;\">and</span>
        h<span class=\"op\" style=\"color: #5E5E5E;\">.</span>content<span class=\"op\"
        style=\"color: #5E5E5E;\">[</span><span class=\"dv\" style=\"color: #AD0000;\">1</span><span
        class=\"op\" style=\"color: #5E5E5E;\">].</span>text<span class=\"op\" style=\"color:
        #5E5E5E;\">:</span><span class=\"fu\" style=\"color: #4758AB;\">match</span>
        <span class=\"st\" style=\"color: #20794D;\">'[%d%.]+'</span> <span class=\"cf\"
        style=\"color: #003B4F;\">then</span></span>\n<span id=\"cb6-7\">    span
        <span class=\"op\" style=\"color: #5E5E5E;\">=</span> h<span class=\"op\"
        style=\"color: #5E5E5E;\">.</span>content<span class=\"op\" style=\"color:
        #5E5E5E;\">[</span><span class=\"dv\" style=\"color: #AD0000;\">5</span><span
        class=\"op\" style=\"color: #5E5E5E;\">]</span></span>\n<span id=\"cb6-8\">
        \ <span class=\"cf\" style=\"color: #003B4F;\">else</span></span>\n<span id=\"cb6-9\">
        \   span <span class=\"op\" style=\"color: #5E5E5E;\">=</span> h<span class=\"op\"
        style=\"color: #5E5E5E;\">.</span>content<span class=\"op\" style=\"color:
        #5E5E5E;\">[</span><span class=\"dv\" style=\"color: #AD0000;\">1</span><span
        class=\"op\" style=\"color: #5E5E5E;\">]</span></span>\n<span id=\"cb6-10\">
        \   h<span class=\"op\" style=\"color: #5E5E5E;\">.</span>classes<span class=\"op\"
        style=\"color: #5E5E5E;\">:</span><span class=\"fu\" style=\"color: #4758AB;\">insert</span><span
        class=\"op\" style=\"color: #5E5E5E;\">(</span><span class=\"st\" style=\"color:
        #20794D;\">'unnumbered'</span><span class=\"op\" style=\"color: #5E5E5E;\">)</span></span>\n<span
        id=\"cb6-11\">  <span class=\"cf\" style=\"color: #003B4F;\">end</span></span>\n<span
        id=\"cb6-12\"></span>\n<span id=\"cb6-13\">  h<span class=\"op\" style=\"color:
        #5E5E5E;\">.</span>identifier <span class=\"op\" style=\"color: #5E5E5E;\">=</span>
        span<span class=\"op\" style=\"color: #5E5E5E;\">.</span>identifier</span>\n<span
        id=\"cb6-14\">  h<span class=\"op\" style=\"color: #5E5E5E;\">.</span>content
        <span class=\"op\" style=\"color: #5E5E5E;\">=</span> span<span class=\"op\"
        style=\"color: #5E5E5E;\">.</span>content</span>\n<span id=\"cb6-15\"></span>\n<span
        id=\"cb6-16\">  <span class=\"cf\" style=\"color: #003B4F;\">return</span>
        h</span>\n<span id=\"cb6-17\"><span class=\"kw\" style=\"color: #003B4F;\">end</span></span></code></pre></div>\n<p>The
        filter also removes the section numbering. We add it back by passing <code>--number-sections</code>
        to pandoc.</p>\n<div class=\"quarto-figure quarto-figure-center\">\n<figure
        class=\"figure\">\n<p><img src=\"https://tarleb.com/posts/pdf-of-the-lua-manual/less-bad-toc.png\"
        class=\"img-fluid figure-img\"></p>\n<p></p><figcaption class=\"figure-caption\">less-bad
        table of contents</figcaption><p></p>\n</figure>\n</div>\n<p>Not bad.</p>\n</section>\n<section
        id=\"improve-title-and-metadata\" class=\"level2\">\n<h2 class=\"anchored\"
        data-anchor-id=\"improve-title-and-metadata\">Improve title and metadata</h2>\n<p>The
        PDF is already quite usable, let\u2019s prettify it a bit more: It would be
        important to properly list the authors in the title and metadata, remove the
        unnecessary first header, and maybe add the Lua logo to the title. All this
        is easiest when acting on the full document.</p>\n<div class=\"sourceCode\"
        id=\"cb7\" style=\"background: #f1f3f5;\"><pre class=\"sourceCode lua code-with-copy\"><code
        class=\"sourceCode lua\"><span id=\"cb7-1\"><span class=\"kw\" style=\"color:
        #003B4F;\">function</span> Pandoc <span class=\"op\" style=\"color: #5E5E5E;\">(</span>doc<span
        class=\"op\" style=\"color: #5E5E5E;\">)</span></span>\n<span id=\"cb7-2\">
        \ <span class=\"co\" style=\"color: #5E5E5E;\">-- comma separated authors</span></span>\n<span
        id=\"cb7-3\">  <span class=\"kw\" style=\"color: #003B4F;\">local</span> authors
        <span class=\"op\" style=\"color: #5E5E5E;\">=</span> doc<span class=\"op\"
        style=\"color: #5E5E5E;\">.</span>blocks<span class=\"op\" style=\"color:
        #5E5E5E;\">[</span><span class=\"dv\" style=\"color: #AD0000;\">2</span><span
        class=\"op\" style=\"color: #5E5E5E;\">]</span></span>\n<span id=\"cb7-4\">
        \ authors<span class=\"op\" style=\"color: #5E5E5E;\">.</span>content<span
        class=\"op\" style=\"color: #5E5E5E;\">:</span><span class=\"fu\" style=\"color:
        #4758AB;\">remove</span><span class=\"op\" style=\"color: #5E5E5E;\">(</span><span
        class=\"dv\" style=\"color: #AD0000;\">1</span><span class=\"op\" style=\"color:
        #5E5E5E;\">)</span>  <span class=\"co\" style=\"color: #5E5E5E;\">-- remove
        'by'</span></span>\n<span id=\"cb7-5\">  doc<span class=\"op\" style=\"color:
        #5E5E5E;\">.</span>meta<span class=\"op\" style=\"color: #5E5E5E;\">.</span>author
        <span class=\"op\" style=\"color: #5E5E5E;\">=</span> pandoc<span class=\"op\"
        style=\"color: #5E5E5E;\">.</span>List<span class=\"op\" style=\"color: #5E5E5E;\">()</span></span>\n<span
        id=\"cb7-6\">  <span class=\"cf\" style=\"color: #003B4F;\">for</span> author
        <span class=\"kw\" style=\"color: #003B4F;\">in</span> pandoc<span class=\"op\"
        style=\"color: #5E5E5E;\">.</span>utils<span class=\"op\" style=\"color: #5E5E5E;\">.</span>stringify<span
        class=\"op\" style=\"color: #5E5E5E;\">(</span>authors<span class=\"op\" style=\"color:
        #5E5E5E;\">):</span><span class=\"fu\" style=\"color: #4758AB;\">gmatch</span>
        <span class=\"st\" style=\"color: #20794D;\">'[^,]+'</span> <span class=\"cf\"
        style=\"color: #003B4F;\">do</span></span>\n<span id=\"cb7-7\">    doc<span
        class=\"op\" style=\"color: #5E5E5E;\">.</span>meta<span class=\"op\" style=\"color:
        #5E5E5E;\">.</span>author<span class=\"op\" style=\"color: #5E5E5E;\">:</span><span
        class=\"fu\" style=\"color: #4758AB;\">insert</span><span class=\"op\" style=\"color:
        #5E5E5E;\">(</span>author<span class=\"op\" style=\"color: #5E5E5E;\">)</span></span>\n<span
        id=\"cb7-8\">  <span class=\"cf\" style=\"color: #003B4F;\">end</span></span>\n<span
        id=\"cb7-9\"></span>\n<span id=\"cb7-10\">  <span class=\"co\" style=\"color:
        #5E5E5E;\">-- Remove unnecessary blocks</span></span>\n<span id=\"cb7-11\">
        \ doc<span class=\"op\" style=\"color: #5E5E5E;\">.</span>blocks<span class=\"op\"
        style=\"color: #5E5E5E;\">:</span><span class=\"fu\" style=\"color: #4758AB;\">remove</span><span
        class=\"op\" style=\"color: #5E5E5E;\">(</span><span class=\"dv\" style=\"color:
        #AD0000;\">4</span><span class=\"op\" style=\"color: #5E5E5E;\">)</span> <span
        class=\"co\" style=\"color: #5E5E5E;\">-- menubar</span></span>\n<span id=\"cb7-12\">
        \ doc<span class=\"op\" style=\"color: #5E5E5E;\">.</span>blocks<span class=\"op\"
        style=\"color: #5E5E5E;\">:</span><span class=\"fu\" style=\"color: #4758AB;\">remove</span><span
        class=\"op\" style=\"color: #5E5E5E;\">(</span><span class=\"dv\" style=\"color:
        #AD0000;\">2</span><span class=\"op\" style=\"color: #5E5E5E;\">)</span> <span
        class=\"co\" style=\"color: #5E5E5E;\">-- authors paragraph</span></span>\n<span
        id=\"cb7-13\">  doc<span class=\"op\" style=\"color: #5E5E5E;\">.</span>blocks<span
        class=\"op\" style=\"color: #5E5E5E;\">:</span><span class=\"fu\" style=\"color:
        #4758AB;\">remove</span><span class=\"op\" style=\"color: #5E5E5E;\">(</span><span
        class=\"dv\" style=\"color: #AD0000;\">1</span><span class=\"op\" style=\"color:
        #5E5E5E;\">)</span> <span class=\"co\" style=\"color: #5E5E5E;\">-- title
        header</span></span>\n<span id=\"cb7-14\"></span>\n<span id=\"cb7-15\">  <span
        class=\"co\" style=\"color: #5E5E5E;\">-- add subtitle image</span></span>\n<span
        id=\"cb7-16\">  doc<span class=\"op\" style=\"color: #5E5E5E;\">.</span>meta<span
        class=\"op\" style=\"color: #5E5E5E;\">.</span>subtitle <span class=\"op\"
        style=\"color: #5E5E5E;\">=</span> pandoc<span class=\"op\" style=\"color:
        #5E5E5E;\">.</span>MetaInlines<span class=\"op\" style=\"color: #5E5E5E;\">{</span></span>\n<span
        id=\"cb7-17\">    pandoc<span class=\"op\" style=\"color: #5E5E5E;\">.</span>RawInline<span
        class=\"op\" style=\"color: #5E5E5E;\">(</span><span class=\"st\" style=\"color:
        #20794D;\">'latex'</span><span class=\"op\" style=\"color: #5E5E5E;\">,</span>
        <span class=\"st\" style=\"color: #20794D;\">'</span><span class=\"sc\" style=\"color:
        #5E5E5E;\">\\\\</span><span class=\"st\" style=\"color: #20794D;\">vspace{1em}'</span><span
        class=\"op\" style=\"color: #5E5E5E;\">),</span></span>\n<span id=\"cb7-18\">
        \   pandoc<span class=\"op\" style=\"color: #5E5E5E;\">.</span>Image<span
        class=\"op\" style=\"color: #5E5E5E;\">(</span><span class=\"st\" style=\"color:
        #20794D;\">\"Lua logo\"</span><span class=\"op\" style=\"color: #5E5E5E;\">,</span>
        <span class=\"co\" style=\"color: #5E5E5E;\">-- \"https://www.lua.org/images/lua-logo.gif\")</span></span>\n<span
        id=\"cb7-19\">  <span class=\"op\" style=\"color: #5E5E5E;\">}</span></span>\n<span
        id=\"cb7-20\">  <span class=\"cf\" style=\"color: #003B4F;\">return</span>
        doc</span>\n<span id=\"cb7-21\"><span class=\"kw\" style=\"color: #003B4F;\">end</span></span></code></pre></div>\n</section>\n<section
        id=\"final-touch\" class=\"level2\">\n<h2 class=\"anchored\" data-anchor-id=\"final-touch\">Final
        touch</h2>\n<p>Finally, we may want the PDF to add a little more visible structure,
        e.g., starting top-level sections on their own page.</p>\n<p>The command used
        by pandoc to create the top level headings can be controlled with the <code>--top-level-division</code>
        option. Setting that option to <code>chapter</code> ensures that each major
        section starts on a new page. However, the default document class used by
        LaTeX doesn\u2019t allow chapters, so a different class has to be set with
        <code>--variable documentclass=report</code>.</p>\n</section>\n<section id=\"summary\"
        class=\"level2\">\n<h2 class=\"anchored\" data-anchor-id=\"summary\">Summary</h2>\n<p>For
        completeness, <a href=\"lua-manual-cleanup.lua\">here is the complete filter</a>,
        and this is the full pandoc command used to generate the PDF:</p>\n<div class=\"sourceCode\"
        id=\"cb8\" style=\"background: #f1f3f5;\"><pre class=\"sourceCode bash code-with-copy\"><code
        class=\"sourceCode bash\"><span id=\"cb8-1\"><span class=\"ex\" style=\"color:
        null;\">pandoc</span> <span class=\"dt\" style=\"color: #AD0000;\">\\</span></span>\n<span
        id=\"cb8-2\">  <span class=\"at\" style=\"color: #657422;\">--toc</span> <span
        class=\"dt\" style=\"color: #AD0000;\">\\</span></span>\n<span id=\"cb8-3\">
        \ <span class=\"at\" style=\"color: #657422;\">--toc-depth</span><span class=\"op\"
        style=\"color: #5E5E5E;\">=</span>2 <span class=\"dt\" style=\"color: #AD0000;\">\\</span></span>\n<span
        id=\"cb8-4\">  <span class=\"at\" style=\"color: #657422;\">--metadata</span><span
        class=\"op\" style=\"color: #5E5E5E;\">=</span>documentclass=report <span
        class=\"dt\" style=\"color: #AD0000;\">\\</span></span>\n<span id=\"cb8-5\">
        \ <span class=\"at\" style=\"color: #657422;\">--pdf-engine</span><span class=\"op\"
        style=\"color: #5E5E5E;\">=</span>xelatex <span class=\"dt\" style=\"color:
        #AD0000;\">\\</span></span>\n<span id=\"cb8-6\">  <span class=\"at\" style=\"color:
        #657422;\">--lua-filter</span><span class=\"op\" style=\"color: #5E5E5E;\">=</span>lua-manual-cleanup.lua
        <span class=\"dt\" style=\"color: #AD0000;\">\\</span></span>\n<span id=\"cb8-7\">
        \ <span class=\"at\" style=\"color: #657422;\">--number-sections</span> <span
        class=\"dt\" style=\"color: #AD0000;\">\\</span></span>\n<span id=\"cb8-8\">
        \ <span class=\"at\" style=\"color: #657422;\">--top-level-division</span><span
        class=\"op\" style=\"color: #5E5E5E;\">=</span>chapter <span class=\"dt\"
        style=\"color: #AD0000;\">\\</span></span>\n<span id=\"cb8-9\">  <span class=\"at\"
        style=\"color: #657422;\">--output</span><span class=\"op\" style=\"color:
        #5E5E5E;\">=</span>lua-5.4-manual.pdf <span class=\"dt\" style=\"color: #AD0000;\">\\</span></span>\n<span
        id=\"cb8-10\">  <span class=\"st\" style=\"color: #20794D;\">\"https://lua.org/manual/5.4/manual.html\"</span></span></code></pre></div>\n<p>One
        of the big advantages of pandoc is that it offers a lot of freedom. Since
        we already cleaned the content up, we can now also create other formats, like
        an ebook, just by changing the name of the output file. The final results
        are available below:</p>\n<ul>\n<li><a href=\"lua-5.4-manual.pdf\">Lua 5.4
        manual (PDF)</a></li>\n<li><a href=\"lua-5.4-manual.epub\">Lua 5.4 manual
        (EPUB)</a></li>\n</ul>\n\n\n</section>\n\n ]]></description>\n  <category>pandoc</category>\n
        \ <category>lua</category>\n  <category>pdf</category>\n  <guid>https://tarleb.com/posts/pdf-of-the-lua-manual/index.html</guid>\n
        \ <pubDate>Sat, 11 Jul 2020 00:00:00 GMT</pubDate>\n  <media:content url=\"https://tarleb.com/posts/pdf-of-the-lua-manual/lua-refman-naive.png\"
        medium=\"image\" type=\"image/png\" height=\"186\" width=\"144\"/>\n</item>\n<item>\n
        \ <title>Extending pandoc with Lua</title>\n  <dc:creator>Albert Krewinkel</dc:creator>\n
        \ <link>https://tarleb.com/posts/extending-pandoc-with-lua/index.html</link>\n
        \ <description><![CDATA[ \n\n\n\n<p>My first exposure to Lua has been as a
        pandoc user, and adding new Lua features to pandoc turned Lua into one of
        my favorite languages. In this post I will take a look at <a href=\"https://pandoc.org/\">pandoc</a>,
        the universal document converter, and explore how one can script and extend
        it with Lua. Pandoc includes a Lua interpreter since 2012, but the integration
        of Lua has been expanded significantly with the latest 2.0 release. My hope
        for this article is to highlight the beauty of these systems.</p>\n<section
        id=\"the-universal-document-converter\" class=\"level2\">\n<h2 class=\"anchored\"
        data-anchor-id=\"the-universal-document-converter\">The universal document
        converter</h2>\n<p><a href=\"https://pandoc.org/\">Pandoc</a> \u2013 written
        and maintained by <a href=\"https://johnmacfarlane.net\">John MacFarlane</a>
        \u2013 is an relatively old project. It has grown considerably since the first
        version was published in 2006: at the time of writing, pandoc can read 27
        different document formats and dialects, and can write 49 formats. Besides
        serving as a one-off document conversions tool, pandoc also frequently features
        as the central part of publishing pipelines. For example, Pandoc is used in
        <a href=\"https://github.com/mfenner/jekyll-pandoc\">static</a> <a href=\"https://jaspervdj.be/hakyll/\">site
        generators</a> and is frequently used <a href=\"https://programminghistorian.org/lessons/sustainable-authorship-in-plain-text-using-pandoc-and-markdown\">by
        academic writers</a>, due also to its excellent support for citations.</p>\n<p>As
        a brief example, consider the following commands which transform Markdown
        input into docx, HTML, or PDF:</p>\n<div class=\"sourceCode\" id=\"cb1\" style=\"background:
        #f1f3f5;\"><pre class=\"sourceCode bash code-with-copy\"><code class=\"sourceCode
        bash\"><span id=\"cb1-1\"><span class=\"co\" style=\"color: #5E5E5E;\"># command
        to convert a markdown file to docx</span></span>\n<span id=\"cb1-2\"><span
        class=\"ex\" style=\"color: null;\">pandoc</span> input-file.md <span class=\"at\"
        style=\"color: #657422;\">--output</span><span class=\"op\" style=\"color:
        #5E5E5E;\">=</span>output-file.docx</span>\n<span id=\"cb1-3\"></span>\n<span
        id=\"cb1-4\"><span class=\"co\" style=\"color: #5E5E5E;\"># convert to HTML</span></span>\n<span
        id=\"cb1-5\"><span class=\"ex\" style=\"color: null;\">pandoc</span> input-file.md
        <span class=\"at\" style=\"color: #657422;\">--standalone</span> <span class=\"at\"
        style=\"color: #657422;\">--output</span><span class=\"op\" style=\"color:
        #5E5E5E;\">=</span>output-file.html</span>\n<span id=\"cb1-6\"></span>\n<span
        id=\"cb1-7\"><span class=\"co\" style=\"color: #5E5E5E;\"># convert to PDF
        (via LaTeX)</span></span>\n<span id=\"cb1-8\"><span class=\"ex\" style=\"color:
        null;\">pandoc</span> input-file.md <span class=\"at\" style=\"color: #657422;\">--output</span><span
        class=\"op\" style=\"color: #5E5E5E;\">=</span>output-file.pdf</span></code></pre></div>\n<p>Many
        conversion tasks need to alter the default behavior or require special conversion
        features. This highlights the importance of good customization support for
        a conversion tool, one of the areas in which Lua shines.</p>\n<p>Pandoc is
        unusual for a Lua-extendable program, in that it is written in Haskell. Using
        Haskell is very productive, but is less suitable as an extension language:
        its concepts are often alien to users of other languages, and shipping a full
        Haskell interpreter with pandoc would result in considerable bloat. Lua is
        an excellent choice here, as it is lightweight, simple, and beautiful. It
        should be noted, however, that <a href=\"https://github.com/hslua\">bridging
        Haskell and Lua</a> is its own can of worms and worth a separate blog post.</p>\n</section>\n<section
        id=\"pandocs-document-ast\" class=\"level2\">\n<h2 class=\"anchored\" data-anchor-id=\"pandocs-document-ast\">Pandoc\u2019s
        document AST</h2>\n<p>An important factor in pandoc\u2019s immense transformation
        powers is its use of a unifying document representation: Every input is parsed
        into this document AST, which is then rendered in the desired output format.
        While a direct conversion between any of <em>n</em> input and <em>m</em> output
        formats would require <em>n </em> m* converters, using an intermediate representation
        reduces complexity to <em>n + m</em>.</p>\n<p>There are additional advantages
        to this: as we\u2019ll see, it becomes much simpler to work with a unified
        document representation than it would be to work with any of the input or
        output formats directly.</p>\n<p>There are four main types in pandoc\u2019s
        document model: inlines, blocks, document metadata, and the full document.</p>\n<ul>\n<li><p>Inline
        elements represent text and text markup. Examples are <em>Space</em> for inter-word
        spaces, <em>Str</em> for (usually non-whitespace) text, and <em>Emph</em>
        for emphasized text.</p></li>\n<li><p>Blocks are elements like paragraphs,
        lists, code listings, and headers. They are usually rendered in lines or blocks
        of their own; many block elements contain lists of inline elements.</p></li>\n<li><p>Meta
        information is a simple mapping from string keys to meta values. Meta values
        can be thought of as a special JSON or YAML object.</p></li>\n<li><p>Last
        but not least, the <em>Pandoc</em> type represents a full document. A <em>Pandoc</em>
        element consists of a lists of block elements, plus additional document metadata.</p></li>\n</ul>\n<p>Pandoc\u2019s
        Lua features revolve around modifying or converting these elements. The oldest
        use of Lua in pandoc enables the conversion of AST elements into strings as
        to output any document format.</p>\n</section>\n<section id=\"custom-writers\"
        class=\"level2\">\n<h2 class=\"anchored\" data-anchor-id=\"custom-writers\">Custom
        writers</h2>\n<p>Users can define custom writers in Lua to render any document
        format. Each of the aforementioned AST elements is transformed to a string
        by calling a Lua function of the same name as the element. E.g., this example
        demonstrates how emphasized text can be rendered as HTML:</p>\n<div class=\"sourceCode\"
        id=\"cb2\" style=\"background: #f1f3f5;\"><pre class=\"sourceCode lua code-with-copy\"><code
        class=\"sourceCode lua\"><span id=\"cb2-1\"><span class=\"kw\" style=\"color:
        #003B4F;\">function</span> Emph<span class=\"op\" style=\"color: #5E5E5E;\">(</span>content_string<span
        class=\"op\" style=\"color: #5E5E5E;\">)</span></span>\n<span id=\"cb2-2\">
        \ <span class=\"cf\" style=\"color: #003B4F;\">return</span> <span class=\"st\"
        style=\"color: #20794D;\">'&lt;em&gt;'</span> <span class=\"op\" style=\"color:
        #5E5E5E;\">..</span> content_string <span class=\"op\" style=\"color: #5E5E5E;\">..</span>
        <span class=\"st\" style=\"color: #20794D;\">'&lt;/em&gt;'</span></span>\n<span
        id=\"cb2-3\"><span class=\"kw\" style=\"color: #003B4F;\">end</span></span></code></pre></div>\n<p>A
        full custom writer is defined by specifying functions for all document AST
        elements. Example writers using this method include <a href=\"https://github.com/lilydjwg/2bbcode\">2bbcode</a>
        by <a href=\"https://github.com/lilydjwg\">@lilydjwg (\u4F9D \u4E91)</a>,
        as well as pandoc\u2019s <code>sample.lua</code>. The latter is a well documented
        starting point for authors of new custom writers. The file can be produced
        by calling <code>pandoc --print-default-data-file=sample.lua</code>.</p>\n<p>The
        <a href=\"https://pandoc-scholar.github.io/\">pandoc-scholar</a> project serves
        as an example for the power offered by custom writers. It is a publishing
        tool intended to <a href=\"https://doi.org/10.7717/peerj-cs.112\">help authors
        of scholarly articles</a> and was created with custom Lua writers. The tool
        leans on the custom writers feature in ways that writers were not intended
        to be used, which resulted in the development of lua filters.</p>\n</section>\n<section
        id=\"filters\" class=\"level2\">\n<h2 class=\"anchored\" data-anchor-id=\"filters\">Filters</h2>\n<p>An
        additional benefit of a unified document type is that the document can be
        modified programmatically, regardless of which input and output format is
        chosen. Pandoc provides two interfaces for this.</p>\n<section id=\"json-filters\"
        class=\"level3\">\n<h3 class=\"anchored\" data-anchor-id=\"json-filters\">JSON
        Filters</h3>\n<p>The first \u2013 very flexible \u2013 method is based on
        JSON. Pandoc can serialize the document to JSON; other programs <a href=\"https://pandoc.org/filters.html\">can
        read and modify</a> the document. The resulting document JSON is passed back
        to pandoc, thus allowing users to use any programming language capable of
        parsing JSON to alter the document. Many libraries for various languages have
        been implemented, including <a href=\"https://hackage.haskell.org/package/pandoc-types\">Haskell</a>,
        <a href=\"http://scorreia.com/software/panflute/\">Python</a>, <a href=\"https://heerdebeer.org/Software/markdown/paru/\">Ruby</a>,
        and <a href=\"https://www.npmjs.com/package/pandoc-filter\">JavaScript</a>.</p>\n<p>The
        flexibility of JSON filters can also be a disadvantage, as it requires additional
        software and usually the full installation of a scripting language\u2019s
        ecosystem. Pandoc is designed to work on all major platforms and without any
        dependencies on other libraries and binaries. Depending on additional software
        can be problematic, especially for non-technical users.</p>\n</section>\n<section
        id=\"lua-filters\" class=\"level3\">\n<h3 class=\"anchored\" data-anchor-id=\"lua-filters\">Lua
        filters</h3>\n<p>The <a href=\"https://pandoc.org/lua-filters.html\">Lua filter</a>
        system added in pandoc 2.0 not only solves the portability issue of JSON filters,
        but also offers better performance and more functionality. Document elements
        can be selectively serialized to Lua tables, modified using the full power
        of Lua, and will then be transferred back, thus replacing the previous values.</p>\n<p>Lua
        filters operate by calling filter functions on each element of the specified
        name. I.e., if a Lua filter contains a function with the same name as an AST
        element, then this function is called for all elements of the respective type.
        The serialized element is passed as input to the filter function, and the
        function\u2019s return value is deserialized and used to replace the input
        element. This method is as simple as it is flexible, and fits well with the
        concept of immutability which is prevalent in Haskell programs: pandoc ignores
        modifications to the serialized object itself, it will just use the filter
        function\u2019s return value.</p>\n<p>The following example filter transforms
        all text set in small caps into emphasized text:</p>\n<div class=\"sourceCode\"
        id=\"cb3\" style=\"background: #f1f3f5;\"><pre class=\"sourceCode lua code-with-copy\"><code
        class=\"sourceCode lua\"><span id=\"cb3-1\"><span class=\"kw\" style=\"color:
        #003B4F;\">function</span> SmallCaps <span class=\"op\" style=\"color: #5E5E5E;\">(</span>element<span
        class=\"op\" style=\"color: #5E5E5E;\">)</span></span>\n<span id=\"cb3-2\">
        \ <span class=\"cf\" style=\"color: #003B4F;\">return</span> pandoc<span class=\"op\"
        style=\"color: #5E5E5E;\">.</span>Emph<span class=\"op\" style=\"color: #5E5E5E;\">(</span>element<span
        class=\"op\" style=\"color: #5E5E5E;\">.</span>content<span class=\"op\" style=\"color:
        #5E5E5E;\">)</span></span>\n<span id=\"cb3-3\"><span class=\"kw\" style=\"color:
        #003B4F;\">end</span></span></code></pre></div>\n<p>The element constructor
        functions in module pandoc, like <code>pandoc.Emph</code> in the above example,
        are also the central step when transforming elements from their pandoc-internal
        representation to Lua values. This ensures consistency in the way element
        values are produced, whether during serialization or through a constructor
        call in the filter script. The current implementation uses only strings, tables,
        and some metatables when constructing element values, with the goal of marking
        these values easy and flexible to use.</p>\n</section>\n</section>\n<section
        id=\"lua-filter-example-macro-expander\" class=\"level2\">\n<h2 class=\"anchored\"
        data-anchor-id=\"lua-filter-example-macro-expander\">Lua filter example: macro
        expander</h2>\n<p>Below is the code for a simple macro expander using pandoc\u2019s
        Lua filter functionality. The expander replaces all macro occurrences in the
        given document. Macro definitions are hard-coded into the filter, but could
        as well be read from an external file.</p>\n<div class=\"sourceCode\" id=\"cb4\"
        style=\"background: #f1f3f5;\"><pre class=\"sourceCode lua code-with-copy\"><code
        class=\"sourceCode lua\"><span id=\"cb4-1\"><span class=\"co\" style=\"color:
        #5E5E5E;\">-- file: macro-expander.lua</span></span>\n<span id=\"cb4-2\"></span>\n<span
        id=\"cb4-3\"><span class=\"co\" style=\"color: #5E5E5E;\">-- Macro substitutions:
        contains macro identifier as</span></span>\n<span id=\"cb4-4\"><span class=\"co\"
        style=\"color: #5E5E5E;\">-- keys and the expanded inlines as values.</span></span>\n<span
        id=\"cb4-5\"><span class=\"kw\" style=\"color: #003B4F;\">local</span> macro_substs
        <span class=\"op\" style=\"color: #5E5E5E;\">=</span> <span class=\"op\" style=\"color:
        #5E5E5E;\">{</span></span>\n<span id=\"cb4-6\">  <span class=\"op\" style=\"color:
        #5E5E5E;\">[</span><span class=\"st\" style=\"color: #20794D;\">'{{hello}}'</span><span
        class=\"op\" style=\"color: #5E5E5E;\">]</span> <span class=\"op\" style=\"color:
        #5E5E5E;\">=</span> pandoc<span class=\"op\" style=\"color: #5E5E5E;\">.</span>Emph<span
        class=\"op\" style=\"color: #5E5E5E;\">{</span>pandoc<span class=\"op\" style=\"color:
        #5E5E5E;\">.</span>Str <span class=\"st\" style=\"color: #20794D;\">\"Hello,
        World!\"</span><span class=\"op\" style=\"color: #5E5E5E;\">}</span></span>\n<span
        id=\"cb4-7\"><span class=\"op\" style=\"color: #5E5E5E;\">}</span></span>\n<span
        id=\"cb4-8\"></span>\n<span id=\"cb4-9\"><span class=\"co\" style=\"color:
        #5E5E5E;\">-- Replace string with macro expansion, if any.</span></span>\n<span
        id=\"cb4-10\"><span class=\"kw\" style=\"color: #003B4F;\">function</span>
        Str <span class=\"op\" style=\"color: #5E5E5E;\">(</span>s<span class=\"op\"
        style=\"color: #5E5E5E;\">)</span></span>\n<span id=\"cb4-11\">  <span class=\"cf\"
        style=\"color: #003B4F;\">return</span> macro_substs<span class=\"op\" style=\"color:
        #5E5E5E;\">[</span>s<span class=\"op\" style=\"color: #5E5E5E;\">.</span>text<span
        class=\"op\" style=\"color: #5E5E5E;\">]</span> <span class=\"kw\" style=\"color:
        #003B4F;\">or</span> s</span>\n<span id=\"cb4-12\"><span class=\"kw\" style=\"color:
        #003B4F;\">end</span></span></code></pre></div>\n<p>The heart of the macro
        expander is the function <code>Str</code>. It is called on all simple strings
        in the document. The return value of this function is then read back into
        pandoc, replacing the original <code>Str</code> value.</p>\n<p>Assume a Markdown
        file <code>greeting.md</code>:</p>\n<pre><code>Greeting: {{hello}}</code></pre>\n<p>We
        can apply the macro expander by calling</p>\n<div class=\"sourceCode\" id=\"cb6\"
        style=\"background: #f1f3f5;\"><pre class=\"sourceCode bash code-with-copy\"><code
        class=\"sourceCode bash\"><span id=\"cb6-1\"><span class=\"ex\" style=\"color:
        null;\">pandoc</span> <span class=\"at\" style=\"color: #657422;\">--lua-filter</span>
        macro-expander.lua greeting.md</span></code></pre></div>\n<p>resulting in
        the expected expansion:</p>\n<blockquote class=\"blockquote\">\n<p>\nGreeting:
        <em>Hello, World!</em>\n</p>\n</blockquote>\n<p>The function <code>Str</code>
        could be shortened further by dropping the trailing <code>or s</code>:</p>\n<div
        class=\"sourceCode\" id=\"cb7\" style=\"background: #f1f3f5;\"><pre class=\"sourceCode
        lua code-with-copy\"><code class=\"sourceCode lua\"><span id=\"cb7-1\"><span
        class=\"kw\" style=\"color: #003B4F;\">function</span> Str <span class=\"op\"
        style=\"color: #5E5E5E;\">(</span>s<span class=\"op\" style=\"color: #5E5E5E;\">)</span>
        <span class=\"cf\" style=\"color: #003B4F;\">return</span> macro_substs<span
        class=\"op\" style=\"color: #5E5E5E;\">[</span>s<span class=\"op\" style=\"color:
        #5E5E5E;\">.</span>text<span class=\"op\" style=\"color: #5E5E5E;\">]</span>
        <span class=\"kw\" style=\"color: #003B4F;\">end</span></span></code></pre></div>\n<p>This
        is a convenience feature of pandoc filters: if the function returns no value
        (or <code>nil</code>), the original value is kept unchanged. This makes filter
        functions easier to write and speeds up filtering, as unchanged elements don\u2019t
        need to be deserialized again.</p>\n</section>\n<section id=\"whats-good-and-whats-next\"
        class=\"level2\">\n<h2 class=\"anchored\" data-anchor-id=\"whats-good-and-whats-next\">What\u2019s
        good, and what\u2019s next</h2>\n<p>Using pandoc with Lua is a fast, flexible,
        and platform independent way of augmenting pandoc with additional functionality.
        For me personally, having the full power of Lua at ones finger tips proved
        to be a lot of fun, while opening unexpected document processing possibilities.</p>\n<p>Pandoc
        and its Lua subsystem are under constant development. E.g., the next versions
        will feature more utility functions exposed via Lua modules. There is constant
        work to make more and more internal functions available. The next big goal
        is to grant scripting access to all format-output functions. However, this
        requires some changes to pandoc\u2019s internals. It remains a long way for
        pandoc to become a fully Lua-scriptable publishing platform.</p>\n<p>If you
        want to learn more about Lua filters, the <a href=\"https://pandoc.org/lua-filters.html\">Lua
        filter docs</a> is a good place to start. It includes up-to-date examples
        of Lua scripts, as well as a reference of all modules and functions accessible
        via Lua. Pandoc\u2019s <a href=\"https://pandoc.org/MANUAL.html\">user manual</a>
        is a good resource to learn about all of pandoc features and its command line
        options.</p>\n<p><a href=\"https://groups.google.com/forum/#!forum/pandoc-discuss\">Feedback</a>
        is always welcome!</p>\n</section>\n<section id=\"acknowledgements\" class=\"level2\">\n<h2
        class=\"anchored\" data-anchor-id=\"acknowledgements\">Acknowledgements</h2>\n<p>A
        big thank you to Jennifer K\xF6nig, Birgit Pohl, and John MacFarlane for their
        feedback on an earlier version of this post, and to all pandoc contributors
        and users, who make working on this project incredibly fun.</p>\n\n\n</section>\n\n
        ]]></description>\n  <category>pandoc</category>\n  <category>lua</category>\n
        \ <category>pandoc-filter</category>\n  <guid>https://tarleb.com/posts/extending-pandoc-with-lua/index.html</guid>\n
        \ <pubDate>Sat, 23 Dec 2017 00:00:00 GMT</pubDate>\n</item>\n<item>\n  <title>MetaNook2014
        \u2013 Command Line Talk</title>\n  <dc:creator>Albert Krewinkel</dc:creator>\n
        \ <link>https://tarleb.com/posts/nook-2014/index.html</link>\n  <description><![CDATA[
        \n\n\n\n<p>Last night was the night of this year\u2019s MetaNook. It was the
        fourth time that the local hackers, most notably <a href=\"https://metameute.de\">MetaMeute</a>
        and <a href=\"https://chaotikum.org\">Chaotikum</a>, joined forces to organize
        a night full of beginner-friendly introductions, advanced tech talks, and
        project presentations.</p>\n<p>My <a href=\"https://github.com/tarleb/shell-talk\">talk
        contribution</a> this year was a brief introduction in the \u201Cmagic\u201D
        of the command-line. The talk slides are adapted to the topic in that the
        presentation must be given from the command line. Each slide is just a function,
        the whole presentation environment is held together by scripts and other shell-equivalences
        of duckt-tape. Feedback from the thirty or-so attendees was mostly positive.</p>\n<p>It
        was a very fun experience over all, as usual.</p>\n\n\n\n ]]></description>\n
        \ <category>talk</category>\n  <category>command-line</category>\n  <guid>https://tarleb.com/posts/nook-2014/index.html</guid>\n
        \ <pubDate>Sat, 22 Nov 2014 00:00:00 GMT</pubDate>\n</item>\n<item>\n  <title>rt6_redirect:
        source isn\u2019t a valid nexthop for redirect target</title>\n  <dc:creator>Albert
        Krewinkel</dc:creator>\n  <link>https://tarleb.com/posts/rt6_redirect/index.html</link>\n
        \ <description><![CDATA[ \n\n\n\n<p>The zeitkraut server is configured to
        work with IPv6. For quite some time now, I\u2019ve been seeing some strange
        errors in my log files. If you\u2019ve been noticing something similar, here
        is what\u2019s going on and how to prevent the messages from appearing.</p>\n<section
        id=\"the-problem\" class=\"level2\">\n<h2 class=\"anchored\" data-anchor-id=\"the-problem\">The
        Problem</h2>\n<p>Everything works as expected, except for some weird messages
        in the logs:</p>\n<pre><code>rt6_redirect: source isn't a valid nexthop for
        redirect target</code></pre>\n<p>Not even <a href=\"https://startpage.com\">startpage</a>
        was of much help. Searching for the above line only lists only some <a href=\"http://ubuntuforums.org/archive/index.php/t-1947743.html\">unanswered</a>
        <a href=\"http://board.gulli.com/thread/1699675-rt6-redirect-source-isn-t-a-valid-nexthop/\">forum</a>
        questions and the kernel source code which is producing the message. Oh, and
        a somewhat unhelpful blog entry <a href=\"https://www.kernel-error.de/kernel-error-blog/189-rt6-redirect-source-isn-t-a-valid-nexthop-for-redirect-target\">telling</a>
        people to always use their routers link local address when routing. This is
        useless advice in my case, I don\u2019t <em>have</em> a link-local address
        of the router, only it\u2019s global address.</p>\n</section>\n<section id=\"the-cause\"
        class=\"level2\">\n<h2 class=\"anchored\" data-anchor-id=\"the-cause\">The
        Cause</h2>\n<p>I found a way to stop the message from appearing in my logs.
        On the way, I learned a bit more about IPv6 and improved server security on
        the way.</p>\n<p>IPv6 contains functionality to tell a computer about better
        routes to the target destination. A router may send ICMPv6 redirect packages
        (type 137 to be specific), informing neighboring computers about more effective
        ways to reach their targets. This makes the most sense when applied within
        an environment heavily relying on auto-configuration \u2013 like a dynamic
        internal company or home network. It makes a lot less sense for servers very
        stable network topologies.</p>\n<p>Attackers may try to exploit the redirect
        functionality by including themselves into the route to the target. The specification
        for those redirects includes some security-measures, requiring the attacker
        to correctly guess the server\u2019s current next hop. If the attackers get
        it wrong, the Linux kernel refuses to use the new routing information. This
        is most-likely what happens when you see the above log messages.</p>\n</section>\n<section
        id=\"the-solution\" class=\"level2\">\n<h2 class=\"anchored\" data-anchor-id=\"the-solution\">The
        Solution</h2>\n<p>Long talk short, the solution is to disable IPv6 redirecting:</p>\n<pre><code>sudo
        sysctl net.ipv6.conf.all.accept_redirects=0</code></pre>\n<p>My server is
        not a router, so there is no need to accept any kind of route changing messages
        from external sources. We can simply disable redirects, using above command.
        The change can be made permanent by setting the value in <code>/etc/sysctl.conf</code>.
        In fact, we can disable routing for both IPv4 and IPv6. Be careful though,
        you might happen to be in a network environment requiring you to accept redirect
        commands for some reason.</p>\n<p>If you are on Debian or similar distribution
        like Ubuntu, change the following lines in <code>/etc/sysctl.conf</code> from</p>\n<pre><code>#
        Do not accept ICMP redirects (prevent MITM attacks)\n#net.ipv4.conf.all.accept_redirects
        = 0\n#net.ipv6.conf.all.accept_redirects = 0\n# _or_\n# Accept ICMP redirects
        only for gateways listed in our default\n# gateway list (enabled by default)\n#
        net.ipv4.conf.all.secure_redirects = 1\n#\n# Do not send ICMP redirects (we
        are not a router)\n#net.ipv4.conf.all.send_redirects = 0\n#\n# Do not accept
        IP source route packets (we are not a router)\n#net.ipv4.conf.all.accept_source_route
        = 0\n#net.ipv6.conf.all.accept_source_route = 0</code></pre>\n<p>to</p>\n<pre><code>#
        Do not accept ICMP redirects (prevent MITM attacks)\nnet.ipv4.conf.all.accept_redirects
        = 0\nnet.ipv6.conf.all.accept_redirects = 0\n#\n# Do not send ICMP redirects
        (we are not a router)\nnet.ipv4.conf.all.send_redirects = 0\n#\n# Do not accept
        IP source route packets (we are not a router)\nnet.ipv4.conf.all.accept_source_route
        = 0\nnet.ipv6.conf.all.accept_source_route = 0</code></pre>\n<p>Running <code>sudo
        sysctl -p</code> loads the new settings.</p>\n</section>\n<section id=\"alternative-solution\"
        class=\"level2\">\n<h2 class=\"anchored\" data-anchor-id=\"alternative-solution\">Alternative
        Solution</h2>\n<p>Completely disabling redirects in the kernel should keep
        you reasonably secure. However, if you need redirects within your internal
        network, you could also block redirect packages reaching you through external
        interfaces. E.g., to block redirect packages coming in on eth1, one would
        issue</p>\n<pre><code>sudo ip6tables -A -i eth1 -p icmpv6 --icmpv6-type 137
        -j DROP</code></pre>\n<p>However, firewall configuration is a complex topic,
        so I\u2019m not going to go into details here.</p>\n<p>If you have any questions,
        corrections or comments on the matter, please drop me a line.</p>\n\n\n</section>\n\n
        ]]></description>\n  <category>security</category>\n  <category>sysadmin</category>\n
        \ <guid>https://tarleb.com/posts/rt6_redirect/index.html</guid>\n  <pubDate>Fri,
        01 Aug 2014 00:00:00 GMT</pubDate>\n</item>\n<item>\n  <title>How to configure
        zsh with vi bindings and nice shortcuts</title>\n  <dc:creator>Albert Krewinkel</dc:creator>\n
        \ <link>https://tarleb.com/posts/howto-zsh-vi-style/index.html</link>\n  <description><![CDATA[
        \n\n\n\n<p>Having a good working environment is vital for feeling comfortable
        being productive. This extends to computational tools and the <a href=\"https://en.wikipedia.org/wiki/command%20shell\">command
        shell</a> is an integral part of the daily work for many of us. It\u2019s
        a good idea to configure the shell\u2019s interface to be efficient and pleasant
        to use. Here we see how <code class=\"verbatim\">zsh</code>, arguably the
        best shell around, can be configured to suit the needs of people used to vi
        key bindings (which are arguably arguably superior and more ergonomical than
        the default emacs-style bindings)<sup>1</sup>.</p>\n<section id=\"using-vi-bindings-in-the-shell\"
        class=\"level2\">\n<h2 class=\"anchored\" data-anchor-id=\"using-vi-bindings-in-the-shell\">Using
        vi-bindings in the shell</h2>\n<p>The first step towards nice vi key bindings
        is almost too easy: The red pill takes the form of</p>\n<div class=\"sourceCode\"
        id=\"cb1\" style=\"background: #f1f3f5;\"><pre class=\"sourceCode bash code-with-copy\"><code
        class=\"sourceCode bash\"><span id=\"cb1-1\"><span class=\"ex\" style=\"color:
        null;\">bindkey</span> <span class=\"at\" style=\"color: #657422;\">-v</span></span></code></pre></div>\n<p>Type
        it into your prompt (and add it to your <code class=\"verbatim\">.zshrc</code>
        file) and emacs bindings are going bye-bye. <code class=\"verbatim\">Escape</code>
        will bring you to normal-mode, while <code>i</code>, <code>a</code>, <code>o</code>
        etc. will bring you back to insert-mode, just as with your favorite editor.
        Use <code>j</code> and <code>k</code> in normal-mode to go through your history
        and move around within the line with <code>h</code>, <code>l</code>, <code>w</code>,
        <code>b</code> and the like.</p>\n<p>This is a good start, let\u2019s see
        how we can bring it from \u201Cthis is nice\u201D to \u201Cthat\u2019s just
        awesome\u201D.</p>\n<p>First, we may want to keep some of the default key
        bindings in insert-mode since we\u2019ve grown accustomed to them. No missing
        out, let\u2019s put them back in:</p>\n<div class=\"sourceCode\" id=\"cb2\"
        style=\"background: #f1f3f5;\"><pre class=\"sourceCode bash code-with-copy\"><code
        class=\"sourceCode bash\"><span id=\"cb2-1\"><span class=\"co\" style=\"color:
        #5E5E5E;\"># Kill input from the current point to the end of line with Ctrl-k</span></span>\n<span
        id=\"cb2-2\"><span class=\"ex\" style=\"color: null;\">bindkey</span> <span
        class=\"st\" style=\"color: #20794D;\">'^k'</span> kill-line</span>\n<span
        id=\"cb2-3\"><span class=\"co\" style=\"color: #5E5E5E;\"># Search the history
        incremantally with Ctrl-r</span></span>\n<span id=\"cb2-4\"><span class=\"ex\"
        style=\"color: null;\">bindkey</span> <span class=\"st\" style=\"color: #20794D;\">'^r'</span>
        history-incremental-search-backward</span>\n<span id=\"cb2-5\"><span class=\"co\"
        style=\"color: #5E5E5E;\"># Insert and go through the \"last words\" of previous
        commands with Meta-.</span></span>\n<span id=\"cb2-6\"><span class=\"co\"
        style=\"color: #5E5E5E;\"># (or Escape-. for that matter).</span></span>\n<span
        id=\"cb2-7\"><span class=\"ex\" style=\"color: null;\">bindkey</span> <span
        class=\"st\" style=\"color: #20794D;\">'^[.'</span> insert-last-word</span>\n<span
        id=\"cb2-8\"><span class=\"co\" style=\"color: #5E5E5E;\"># Show the man-page
        or other helpful infos with Meta-h</span></span>\n<span id=\"cb2-9\"><span
        class=\"ex\" style=\"color: null;\">bindkey</span> <span class=\"st\" style=\"color:
        #20794D;\">'^[h'</span> run-help</span></code></pre></div>\n<p>You can take
        a look at the key bindings defined for emacs-mode by typing <code>bindkey
        -M emacs -L</code> and reuse the bindings you like. See the <code>zshzle</code>
        manpage for more pre-defined widgets for which you could define bindings.</p>\n</section>\n<section
        id=\"configuring-the-prompt-to-show-the-current-editing-mode\" class=\"level2\">\n<h2
        class=\"anchored\" data-anchor-id=\"configuring-the-prompt-to-show-the-current-editing-mode\">Configuring
        the prompt to show the current editing mode</h2>\n<p>So the key bindings are
        quite usable now, but it\u2019s a bit unfortunate that it is impossible to
        see if the shell is in insert- or normal-mode. There should be a mode indicator
        right in the shell prompt!</p>\n<div class=\"sourceCode\" id=\"cb3\" style=\"background:
        #f1f3f5;\"><pre class=\"sourceCode bash code-with-copy\"><code class=\"sourceCode
        bash\"><span id=\"cb3-1\"><span class=\"co\" style=\"color: #5E5E5E;\"># You
        may already have those in your .zshrc somewhere</span></span>\n<span id=\"cb3-2\"><span
        class=\"ex\" style=\"color: null;\">autoload</span> <span class=\"at\" style=\"color:
        #657422;\">-U</span> promptinit <span class=\"kw\" style=\"color: #003B4F;\">&amp;&amp;</span>
        <span class=\"ex\" style=\"color: null;\">promptinit</span></span>\n<span
        id=\"cb3-3\"><span class=\"ex\" style=\"color: null;\">autoload</span> <span
        class=\"at\" style=\"color: #657422;\">-U</span> colors     <span class=\"kw\"
        style=\"color: #003B4F;\">&amp;&amp;</span> <span class=\"ex\" style=\"color:
        null;\">colors</span></span>\n<span id=\"cb3-4\"></span>\n<span id=\"cb3-5\"><span
        class=\"ex\" style=\"color: null;\">setopt</span> prompt_subst</span>\n<span
        id=\"cb3-6\"></span>\n<span id=\"cb3-7\"><span class=\"co\" style=\"color:
        #5E5E5E;\"># Set the colors to your liking</span></span>\n<span id=\"cb3-8\"><span
        class=\"bu\" style=\"color: null;\">local</span> <span class=\"va\" style=\"color:
        #111111;\">vi_normal_marker</span><span class=\"op\" style=\"color: #5E5E5E;\">=</span><span
        class=\"st\" style=\"color: #20794D;\">\"[%{</span><span class=\"va\" style=\"color:
        #111111;\">$fg</span><span class=\"st\" style=\"color: #20794D;\">[green]%}%BN%b%{</span><span
        class=\"va\" style=\"color: #111111;\">$reset_color</span><span class=\"st\"
        style=\"color: #20794D;\">%}]\"</span></span>\n<span id=\"cb3-9\"><span class=\"bu\"
        style=\"color: null;\">local</span> <span class=\"va\" style=\"color: #111111;\">vi_insert_marker</span><span
        class=\"op\" style=\"color: #5E5E5E;\">=</span><span class=\"st\" style=\"color:
        #20794D;\">\"[%{</span><span class=\"va\" style=\"color: #111111;\">$fg</span><span
        class=\"st\" style=\"color: #20794D;\">[cyan]%}%BI%b%{</span><span class=\"va\"
        style=\"color: #111111;\">$reset_color</span><span class=\"st\" style=\"color:
        #20794D;\">%}]\"</span></span>\n<span id=\"cb3-10\"><span class=\"bu\" style=\"color:
        null;\">local</span> <span class=\"va\" style=\"color: #111111;\">vi_unknown_marker</span><span
        class=\"op\" style=\"color: #5E5E5E;\">=</span><span class=\"st\" style=\"color:
        #20794D;\">\"[%{</span><span class=\"va\" style=\"color: #111111;\">$fg</span><span
        class=\"st\" style=\"color: #20794D;\">[red]%}%BU%b%{</span><span class=\"va\"
        style=\"color: #111111;\">$reset_color</span><span class=\"st\" style=\"color:
        #20794D;\">%}]\"</span></span>\n<span id=\"cb3-11\"><span class=\"bu\" style=\"color:
        null;\">local</span> <span class=\"va\" style=\"color: #111111;\">vi_mode</span><span
        class=\"op\" style=\"color: #5E5E5E;\">=</span><span class=\"st\" style=\"color:
        #20794D;\">\"</span><span class=\"va\" style=\"color: #111111;\">$vi_insert_marker</span><span
        class=\"st\" style=\"color: #20794D;\">\"</span></span>\n<span id=\"cb3-12\"><span
        class=\"fu\" style=\"color: #4758AB;\">vi_mode_indicator ()</span> <span class=\"kw\"
        style=\"color: #003B4F;\">{</span></span>\n<span id=\"cb3-13\">  <span class=\"cf\"
        style=\"color: #003B4F;\">case</span> <span class=\"va\" style=\"color: #111111;\">${KEYMAP}</span>
        <span class=\"kw\" style=\"color: #003B4F;\">in</span></span>\n<span id=\"cb3-14\">
        \   <span class=\"kw\" style=\"color: #003B4F;\">(</span><span class=\"ss\"
        style=\"color: #20794D;\">vicmd</span><span class=\"kw\" style=\"color: #003B4F;\">)</span>
        \     <span class=\"bu\" style=\"color: null;\">echo</span> <span class=\"va\"
        style=\"color: #111111;\">$vi_normal_marker</span> <span class=\"cf\" style=\"color:
        #003B4F;\">;;</span></span>\n<span id=\"cb3-15\">    <span class=\"kw\" style=\"color:
        #003B4F;\">(</span><span class=\"ss\" style=\"color: #20794D;\">main</span><span
        class=\"kw\" style=\"color: #003B4F;\">|</span><span class=\"ss\" style=\"color:
        #20794D;\">viins</span><span class=\"kw\" style=\"color: #003B4F;\">)</span>
        <span class=\"bu\" style=\"color: null;\">echo</span> <span class=\"va\" style=\"color:
        #111111;\">$vi_insert_marker</span> <span class=\"cf\" style=\"color: #003B4F;\">;;</span></span>\n<span
        id=\"cb3-16\">    <span class=\"kw\" style=\"color: #003B4F;\">(</span><span
        class=\"pp\" style=\"color: #AD0000;\">*</span><span class=\"kw\" style=\"color:
        #003B4F;\">)</span>          <span class=\"bu\" style=\"color: null;\">echo</span>
        <span class=\"va\" style=\"color: #111111;\">$vi_unknown_marker</span> <span
        class=\"cf\" style=\"color: #003B4F;\">;;</span></span>\n<span id=\"cb3-17\">
        \ <span class=\"cf\" style=\"color: #003B4F;\">esac</span></span>\n<span id=\"cb3-18\"><span
        class=\"kw\" style=\"color: #003B4F;\">}</span></span>\n<span id=\"cb3-19\"></span>\n<span
        id=\"cb3-20\"><span class=\"co\" style=\"color: #5E5E5E;\"># Reset mode-marker
        and prompt whenever the keymap changes</span></span>\n<span id=\"cb3-21\"><span
        class=\"kw\" style=\"color: #003B4F;\">function</span><span class=\"fu\" style=\"color:
        #4758AB;\"> zle-line-init</span> <span class=\"ex\" style=\"color: null;\">zle-keymap-select</span>
        {</span>\n<span id=\"cb3-22\">  <span class=\"va\" style=\"color: #111111;\">vi_mode</span><span
        class=\"op\" style=\"color: #5E5E5E;\">=</span><span class=\"st\" style=\"color:
        #20794D;\">\"</span><span class=\"va\" style=\"color: #111111;\">$(</span><span
        class=\"ex\" style=\"color: null;\">vi_mode_indicator</span><span class=\"va\"
        style=\"color: #111111;\">)</span><span class=\"st\" style=\"color: #20794D;\">\"</span></span>\n<span
        id=\"cb3-23\">  <span class=\"ex\" style=\"color: null;\">zle</span> reset-prompt</span>\n<span
        id=\"cb3-24\"><span class=\"er\" style=\"color: #AD0000;\">}</span></span>\n<span
        id=\"cb3-25\"><span class=\"ex\" style=\"color: null;\">zle</span> <span class=\"at\"
        style=\"color: #657422;\">-N</span> zle-line-init</span>\n<span id=\"cb3-26\"><span
        class=\"ex\" style=\"color: null;\">zle</span> <span class=\"at\" style=\"color:
        #657422;\">-N</span> zle-keymap-select</span>\n<span id=\"cb3-27\"></span>\n<span
        id=\"cb3-28\"><span class=\"co\" style=\"color: #5E5E5E;\"># Multiline-prompts
        don't quite work with reset-prompt; we work around this by</span></span>\n<span
        id=\"cb3-29\"><span class=\"co\" style=\"color: #5E5E5E;\"># printing the
        first line(s) via a precmd which is executed before the prompt</span></span>\n<span
        id=\"cb3-30\"><span class=\"co\" style=\"color: #5E5E5E;\"># is printed.  The
        following can be integrated into PROMPT for single-line</span></span>\n<span
        id=\"cb3-31\"><span class=\"co\" style=\"color: #5E5E5E;\"># prompts.</span></span>\n<span
        id=\"cb3-32\"><span class=\"co\" style=\"color: #5E5E5E;\">#</span></span>\n<span
        id=\"cb3-33\"><span class=\"co\" style=\"color: #5E5E5E;\"># Colorize freely</span></span>\n<span
        id=\"cb3-34\"><span class=\"bu\" style=\"color: null;\">local</span> <span
        class=\"va\" style=\"color: #111111;\">user_host</span><span class=\"op\"
        style=\"color: #5E5E5E;\">=</span><span class=\"st\" style=\"color: #20794D;\">'%B%n%b@%m'</span></span>\n<span
        id=\"cb3-35\"><span class=\"bu\" style=\"color: null;\">local</span> <span
        class=\"va\" style=\"color: #111111;\">current_dir</span><span class=\"op\"
        style=\"color: #5E5E5E;\">=</span><span class=\"st\" style=\"color: #20794D;\">'%~'</span></span>\n<span
        id=\"cb3-36\"><span class=\"fu\" style=\"color: #4758AB;\">precmd ()</span>
        <span class=\"ex\" style=\"color: null;\">print</span> <span class=\"at\"
        style=\"color: #657422;\">-rP</span> <span class=\"st\" style=\"color: #20794D;\">\"</span><span
        class=\"va\" style=\"color: #111111;\">${user_host}</span><span class=\"st\"
        style=\"color: #20794D;\"> </span><span class=\"va\" style=\"color: #111111;\">${current_dir}</span><span
        class=\"st\" style=\"color: #20794D;\">\"</span></span>\n<span id=\"cb3-37\"></span>\n<span
        id=\"cb3-38\"><span class=\"bu\" style=\"color: null;\">local</span> <span
        class=\"va\" style=\"color: #111111;\">return_code</span><span class=\"op\"
        style=\"color: #5E5E5E;\">=</span><span class=\"st\" style=\"color: #20794D;\">\"%(?..%{</span><span
        class=\"va\" style=\"color: #111111;\">$fg</span><span class=\"st\" style=\"color:
        #20794D;\">[red]%}%? %{</span><span class=\"va\" style=\"color: #111111;\">$reset_color</span><span
        class=\"st\" style=\"color: #20794D;\">%})\"</span></span>\n<span id=\"cb3-39\"><span
        class=\"va\" style=\"color: #111111;\">PROMPT</span><span class=\"op\" style=\"color:
        #5E5E5E;\">=</span><span class=\"st\" style=\"color: #20794D;\">'${return_code}${vi_mode}
        %# '</span></span></code></pre></div>\n<p>This gives a prompt in the style
        of</p>\n<pre><code>user@host /current/working/path\n[I] %</code></pre>\n<p>where
        <code>[I]</code> is the insert-mode indicator and is changed to <code>[N]</code>
        when normal-mode is activated. Neat, isn\u2019t it?</p>\n</section>\n<section
        id=\"single--and-multi-key-shortcuts\" class=\"level2\">\n<h2 class=\"anchored\"
        data-anchor-id=\"single--and-multi-key-shortcuts\">Single- and multi-key shortcuts</h2>\n<p>This
        is all nice and dandy, but it\u2019s not quite like vim yet. How about those
        sweet bindings where pressing <code>jj</code> in quick succession brings us
        to normal-mode without having to press <code>Esc</code>? Setting it up is
        easy as pie.</p>\n<div class=\"sourceCode\" id=\"cb5\" style=\"background:
        #f1f3f5;\"><pre class=\"sourceCode bash code-with-copy\"><code class=\"sourceCode
        bash\"><span id=\"cb5-1\"><span class=\"co\" style=\"color: #5E5E5E;\"># Time
        in which two keys have to be pressed in order to be recognized as a</span></span>\n<span
        id=\"cb5-2\"><span class=\"co\" style=\"color: #5E5E5E;\"># single command
        (in centiseconds, set to 0.4 sec by default -- may be</span></span>\n<span
        id=\"cb5-3\"><span class=\"co\" style=\"color: #5E5E5E;\"># modified as needed).</span></span>\n<span
        id=\"cb5-4\"><span class=\"bu\" style=\"color: null;\">export</span> <span
        class=\"va\" style=\"color: #111111;\">KEYTIMEOUT</span><span class=\"op\"
        style=\"color: #5E5E5E;\">=</span>40</span>\n<span id=\"cb5-5\"><span class=\"ex\"
        style=\"color: null;\">bindkey</span> <span class=\"st\" style=\"color: #20794D;\">'jj'</span>
        vi-cmd-mode</span></code></pre></div>\n<p>We can also add two-key bindings
        to jump to the start and end of the line:</p>\n<div class=\"sourceCode\" id=\"cb6\"
        style=\"background: #f1f3f5;\"><pre class=\"sourceCode bash code-with-copy\"><code
        class=\"sourceCode bash\"><span id=\"cb6-1\"><span class=\"co\" style=\"color:
        #5E5E5E;\"># Bind to both possible orders in which the keys could be pressed.</span></span>\n<span
        id=\"cb6-2\"><span class=\"co\" style=\"color: #5E5E5E;\"># Move all the way
        to the left</span></span>\n<span id=\"cb6-3\"><span class=\"ex\" style=\"color:
        null;\">bindkey</span> <span class=\"st\" style=\"color: #20794D;\">';l'</span>
        end-of-line</span>\n<span id=\"cb6-4\"><span class=\"ex\" style=\"color: null;\">bindkey</span>
        <span class=\"st\" style=\"color: #20794D;\">'l;'</span> end-of-line</span>\n<span
        id=\"cb6-5\"><span class=\"co\" style=\"color: #5E5E5E;\"># Move all the way
        to the right</span></span>\n<span id=\"cb6-6\"><span class=\"ex\" style=\"color:
        null;\">bindkey</span> <span class=\"st\" style=\"color: #20794D;\">';h'</span>
        beginning-of-line</span>\n<span id=\"cb6-7\"><span class=\"ex\" style=\"color:
        null;\">bindkey</span> <span class=\"st\" style=\"color: #20794D;\">'h;'</span>
        beginning-of-line</span></code></pre></div>\n<p>Jumping to the beginning of
        the line is now as easy as pressing <code>;</code> and <code>h</code> at the
        same time. No need to switch to normal-mode and your fingers don\u2019t leave
        the your keyboard\u2019s home-row. Try it, it\u2019s great!</p>\n</section>\n<section
        id=\"more\" class=\"level2\">\n<h2 class=\"anchored\" data-anchor-id=\"more\">More</h2>\n<p>Customizations
        like this can make it much more pleasant to use the command line and boost
        your productivity. If the above is still not enough, here are some more ideas:</p>\n<ul>\n<li>Define
        custom keymaps, e.g.&nbsp;to control other programs such as <code>mpc</code>
        or <code>tmux</code>.</li>\n<li>Switch to said keymaps via some nice bindings.</li>\n<li>Show
        the status of version control systems and build environments in the prompt.</li>\n</ul>\n<p>If
        you don\u2019t feel like doing all the work yourself, I can heartly reommend
        you take a look at <a href=\"http://ohmyz.sh\">oh-my-zsh</a>. It offers a
        great collection of ideas to build on and some really cool ready-to-use plugins.
        Have fun!</p>\n\n\n</section>\n\n\n<div id=\"quarto-appendix\" class=\"default\"><section
        id=\"footnotes\" class=\"footnotes footnotes-end-of-document\"><h2 class=\"anchored
        quarto-appendix-heading\">Footnotes</h2>\n\n<ol>\n<li id=\"fn1\"><p>Emacs
        is a great program which I\u2019ve been using for years and continue to use
        daily, but vi bindings just make good things better. Thanks to <a href=\"https://gitorious.org/evil/pages/Home\">evil</a>,
        that\u2019s not a problem.\u21A9\uFE0E</p></li>\n</ol>\n</section></div> ]]></description>\n
        \ <category>command-line</category>\n  <category>key bindings</category>\n
        \ <guid>https://tarleb.com/posts/howto-zsh-vi-style/index.html</guid>\n  <pubDate>Sun,
        29 Jun 2014 00:00:00 GMT</pubDate>\n</item>\n<item>\n  <title>Exploring HTTP
        Headers with netcat</title>\n  <dc:creator>Albert Krewinkel</dc:creator>\n
        \ <link>https://tarleb.com/posts/exploring-http-headers/index.html</link>\n
        \ <description><![CDATA[ \n\n\n\n<p>One of the many great things about free
        and open source software and the whole GNU/Linux ecosystem are the simple
        yet powerful tools available. The possibilities enabled by almost trivial
        programs are incredible. A very positive side effect this has on me is that
        I like to go and explore technologies with the tools at my disposal. My latest
        experiments revolved around the HTTP protocol, specifically HTTP headers,
        and very basic open source networking tools.</p>\n<section id=\"the-hypertext-transfer-protocol\"
        class=\"level2\">\n<h2 class=\"anchored\" data-anchor-id=\"the-hypertext-transfer-protocol\">The
        HyperText Transfer Protocol</h2>\n<p>Webservers on the internet sending a
        website to a browser use the HyperText Transfer Protocol (HTTP) to do so.
        Along with the HTML data for the page itself, the server answer includes additional
        information: Response code, cookies, and how the browser or proxy server should
        handle the contents is transfered within the <em>HTTP header</em>. The ability
        of the headers to control state on the client side is what makes them so interesting
        and the reason why we are going to have a closer look at them.</p>\n</section>\n<section
        id=\"communicating-with-netcat\" class=\"level2\">\n<h2 class=\"anchored\"
        data-anchor-id=\"communicating-with-netcat\">Communicating with <code>netcat</code></h2>\n<p>Instead
        of building our own HTTP client and server implementations \u2013 that would
        be total overkill \u2013 we restrict the goal to a simple networking tool
        that can be made to receive, send and alter basic HTTP commands: <code>netcat</code>,
        the self-described TCP/IP swiss army knife, combined with basic shell scripts.</p>\n<p>We
        start by setting up a basic echoing server which sends everything back the
        same way it was received.</p>\n<pre class=\"shell\"><code>nc -l -p 8042 -e
        '/bin/cat'</code></pre>\n<p>Pointing the browser at <code>http://localhost:8042</code>,
        then killing the <code>netcat</code> process manually by hitting <code>Control-C</code>,
        we can see the headers we sent within our browser. Everything that is send
        to our simple server is put through the <code>cat</code> program, which just
        passes it on to STDOUT, which is then sent back to the connecting browser.
        The process has to be terminated manually, as it doesn\u2019t know when to
        stop listening for more input. It\u2019s crude, yet effective.</p>\n</section>\n<section
        id=\"shell-scripting-for-more-advanced-features\" class=\"level2\">\n<h2 class=\"anchored\"
        data-anchor-id=\"shell-scripting-for-more-advanced-features\">Shell Scripting
        for more advanced features</h2>\n<p>The above is neither comfortable to use
        nor very good to toy with, so we replace <code>cat</code> with a script of
        our own, we\u2019ll call it <code>exploring-http.sh</code>:</p>\n<pre class=\"shell\"><code>#!/bin/sh\n\n#
        Keep reading everything until we hit the first empty line\nread_headers ()\n{\n
        \   read i\n    while [ -n \"$i\" ] &amp;&amp;\n          [ \"$(echo -n \"\\r\\n\")\"
        != \"$i\" ] &amp;&amp;\n          [ \"$(echo -n \"\\n\")\" != \"$i\" ]\n    do\n
        \       echo \"$i\"\n        read i\n    done\n}\nrequest_headers=\"$(read_headers)\"\n\n#
        Get some response headers ready\nresponse_headers ()\n{\n    printf \"HTTP/1.1
        200 OK\\r\\n\"\n    printf \"Content-Type: text/plain\\r\\n\"\n    printf
        \"\\r\\n\"\n}\n\n# Send the response\nrespond ()\n{\n    local response_headers=\"$(response_headers)\"\n
        \   echo \"${response_headers}\"\n    echo \"Browser Request Headers\"\n    echo
        \"=======================\"\n    echo \"$request_headers\"\n    echo \"\\r\\n\"\n
        \   echo \"Server Response Headers\"\n    echo \"=======================\"\n
        \   echo \"${response_headers}\"\n}\n\nrespond</code></pre>\n<p>The request
        send by the browser is read till we reach the first black line, signaling
        the end of the request header. This time, we follow the protocol by prefixing
        the content with very simple response headers before sending it back to the
        browser. We also don\u2019t have to manually terminate our <code>netcat</code>
        server, it terminates after answering to the request. Starting it again after
        each request is tedious, so we automate it and put it into a loop, restarting
        the server immediately once it terminates.</p>\n<pre class=\"shell\"><code>sh
        -c 'while true; do nc -l -p 8042 -e exploring-http.sh; done'</code></pre>\n<p>Now
        we are free to experiment with HTTP headers and the way browser and server
        interact. For example, we can let the server add a <code>Last-Modified</code>
        header, the content of which should be sent back by the browser in the next
        request:</p>\n<pre class=\"shell\"><code>response_headers ()\n{\n    printf
        \"HTTP/1.1 200 OK\\r\\n\"\n    printf \"Content-Type: text/plain\\r\\n\"\n
        \   printf \"Last-Modified: $(date --rfc-2822)\\r\\n\"\n    printf \"\\r\\n\"\n}</code></pre>\n<p>Reloading
        twice, and the browser request will change to send an additional <code>If-Modified-Since</code>
        header.</p>\n</section>\n<section id=\"etags\" class=\"level2\">\n<h2 class=\"anchored\"
        data-anchor-id=\"etags\">ETags</h2>\n<p>The functionality of ETags, designed
        to communicate caching of old files, can be used follow users around without
        the need of cookies. Let\u2019s see if we can do this with our little server.</p>\n<p>The
        function generating the response headers is modified to extract any ETag supplied
        by the browser. If none exists, we generate a new one by hashing the number
        of nanoseconds passed since the beginning of the UNIX epoche. The parsed or
        newly generated etag is then sent back to the browser. We also add a few header
        to make sure the conents isn\u2019t cached. As a result, we should be able
        to track a user through his or her browser cache.</p>\n<pre class=\"shell\"><code>response_headers
        ()\n{\n    local etag\n    etag=$(echo \"${request_headers}\" | sed -ne 's/^\\(If-None-Match:
        \"\\([a-f0-9]*\\)\".*\\)/\\2/gp')\n    printf \"HTTP/1.1 200 OK\\r\\n\"\n
        \   printf \"Content-Type: text/plain\\r\\n\"\n    printf \"Last-Modified:
        $(date --rfc-2822)\\r\\n\"\n    printf \"ETag: \\\"${etag:-$(date +%s%N |
        md5sum | cut -d' ' -f1)}\\\"\\r\\n\"\n    printf \"Expires: Tue, 01 Jan 2013
        00:00:01 GMT\\r\\n\"\n    printf \"Cache-Control: max-age=0\\r\\n\"\n    printf
        \"Connection: keep-alive\\r\\n\"\n    printf \"\\r\\n\"\n}</code></pre>\n<p>We
        can test this by reloading our test page twice and\u2026 it works! We can
        reload as often as we want, the ETag header sent by the browser will not change
        unless we clear the browser\u2019s cache. A stealthy kind of user tracking
        can be simulated with just a few lines of shell script.</p>\n</section>\n<section
        id=\"conclusion\" class=\"level2\">\n<h2 class=\"anchored\" data-anchor-id=\"conclusion\">Conclusion</h2>\n<p>Even
        though we used nothing but simple command line tools and shell scripting,
        we managed to build a simple server and to experiment with the ways in which
        stateless servers and stateful browseres can effect each other through HTTP
        headers. Standard UNIX tools are very powerful by themselves; together with
        a tool like <code>netcat</code>, power and fun extend even into experiments
        with networking and default protocols.</p>\n\n\n</section>\n\n ]]></description>\n
        \ <category>command-line</category>\n  <category>network</category>\n  <guid>https://tarleb.com/posts/exploring-http-headers/index.html</guid>\n
        \ <pubDate>Tue, 05 Nov 2013 00:00:00 GMT</pubDate>\n</item>\n<item>\n  <title>Russian
        Process Roulette</title>\n  <dc:creator>Albert Krewinkel</dc:creator>\n  <link>https://tarleb.com/posts/russian-process-roulette/index.html</link>\n
        \ <description><![CDATA[ \n\n\n\n<p>A couple of friends and I just discussed
        the idea of Russian Process Roulette: Everybody starts a little program which
        kills processes at random. The winner is the one whose computer remains usable
        the longest. Is this crazy? Yes. Immature? Sure. Fun? Definitely. Adviced
        against to actually play unless the consequences are fully understood? That
        too.</p>\n<p>Playing the game is as simple as starting a command like the
        following:</p>\n<pre class=\"shell\"><code>while sleep 600; do kill -9 $(tr
        -cd \"[:digit:]\" &lt; /dev/urandom | head -c5); done</code></pre>\n<p>This
        one-liner will wake up every 10 minutes, generate a random 5-digit number
        and then kill the process with the corresponding process ID. It will run forever,
        until it is either stopped, kills itself or has successfully crashed the user\u2019s
        session.</p>\n<p>Of course, there are some problems with this code. The time
        at which the next process will be killed is predictable, making it easier
        to prepare for the eventuality of a dying process. Worse, the range of random
        process ids (0 to 99999) is about three times as large as the actual range
        of process ids on a typical linux system (0 to 32768). This lowers the chance
        of hitting a valid process ID quite a bit. So let\u2019s put our scripting-fu
        to some misguided use and \u201Coptimize\u201D the code.</p>\n<p>The first
        step is to write a function which gives uniformly distributed random numbers
        below a threshold.</p>\n<pre class=\"shell\"><code>random_number_below ()
        {\n  local upperbound=$1\n  local candidate=$(( $1 + 1 ))\n  local maxlen=$(printf
        $upperbound | wc -c)\n  while [ $candidate -gt $upperbound ]\n  do\n      candidate=$(tr
        -cd '[:digit:]' &lt; /dev/urandom | head -c \"$maxlen\" )\n  done\n  echo
        $candidate\n}</code></pre>\n<p>Our random number generator is very very wasteful
        in terms of processor cycles. Even more, if the output of <code>/dev/urandom</code>
        is truly random, the function were not even guaranteed to terminate in any
        specified time frame. But given the nature of the application we have in mind,
        both caveats are completely acceptable here. Candidate numbers are generated
        by reading random characters from the systems urandom device, throwing away
        every character that isn\u2019t a digit. After this, the candidate number
        is checked to make sure we haven\u2019t generated a number greater than the
        specified upper bound. If that should be the case, we run the whole procedure
        again. Otherwise, the random number is returned. While wasteful, this function
        produces an unbiased uniform distribution on the interval [0, upperbound].</p>\n<p>The
        second problem, regarding the range of possible process identifiers, is easier
        to fix. A little bit of searching reveals that the largest possible process
        identifier can be read from the file <code>/proc/sys/kernel/pid_max</code>.
        With this functionality in our hands, we can now write a \u201Cbetter\u201D
        Russian Process Roulette script.</p>\n<pre class=\"shell\"><code>while sleep
        $(random_number_below 999)\ndo\n    local maxpid=$(cat /proc/sys/kernel/pid_max)\n
        \   kill -9 $(random_number_below \"$maxpid\")\ndone</code></pre>\n<p>We should
        (<em>probably not</em>) run this as <code>root</code>, thereby making sure
        no process is safe from our \u201Cprocess gun\u201D.</p>\n<p>While the result
        of our efforts isn\u2019t necessarily useful, it is still a nice exercises
        in shell scripting. Our game remains destructive and immature, but the execution
        is slightly more sophisticated. Hope you like it.</p>\n\n\n\n ]]></description>\n
        \ <category>command-line</category>\n  <category>nonsense</category>\n  <guid>https://tarleb.com/posts/russian-process-roulette/index.html</guid>\n
        \ <pubDate>Fri, 27 Sep 2013 00:00:00 GMT</pubDate>\n</item>\n<item>\n  <title>Avoid
        Mail Harvesting through Address Munging</title>\n  <dc:creator>Albert Krewinkel</dc:creator>\n
        \ <link>https://tarleb.com/posts/avoiding-spam/index.html</link>\n  <description><![CDATA[
        \n\n\n\n<p>Spam just doesn\u2019t die. Every major mail provider has really
        good spam filters in place, as do the common mail clients. Nontheless, there
        seem to be enough people reading \u2013 and acting on \u2013 spam mail to
        make it a profitable business. No matter how much we hate it, we need to deal
        with spam.</p>\n<p>Better than having a good spam filter is not to be spammed
        in the first place. Since nobody can sent me unsolicited bulk mail if they
        don\u2019t know my mail address, keeping the mail address as private as possible
        is the way to go here. But what if we <em>want</em> our e-mail address to
        be public for other people to reach us? Adding minor obstacles to make it
        just a bit more difficult for spammers to get the address can be enough.</p>\n<section
        id=\"address-munging\" class=\"level2\">\n<h2 class=\"anchored\" data-anchor-id=\"address-munging\">Address
        Munging</h2>\n<p>The usual way for spammers to collect email addresses is
        to crawl websites and to harvest everything that looks like a valid mail address.
        A common defense is <a href=\"https://en.wikipedia.org/wiki/Address_munging\">address
        munging</a>, i.e.&nbsp;resolving to bogus comments, additional markup, images
        or javascript to hide mail addresses from automatic harvesters. I find the
        use of images or javascript problematic for various reasons and just dislike
        unnecessary comments. Luckily, HTML5 and CSS3 make it really easy to mangle
        addresses without using either of these methods.</p>\n</section>\n<section
        id=\"obfuscating-an-address-with-html5-css3\" class=\"level2\">\n<h2 class=\"anchored\"
        data-anchor-id=\"obfuscating-an-address-with-html5-css3\">Obfuscating an Address
        with HTML5 &amp; CSS3</h2>\n<p>Our approach here leverages the HTML5 <a href=\"http://www.w3.org/TR/html5/dom.html#embedding-custom-non-visible-data-with-the-data-*-attributes\"><code>data-*</code></a>
        attributes as well as the <a href=\"https://developer.mozilla.org/en-US/docs/Web/CSS/::before\"><code>::before</code></a>
        and <a href=\"https://developer.mozilla.org/en-US/docs/Web/CSS/::after\"><code>::after</code></a>
        pseudo-elements. The mail address is divided and stored in custom data attributes
        and displayed as pseudo-elements. The address is kept in the markup, the presentation
        is handled in the style sheet:</p>\n<p>HTML:</p>\n<div class=\"sourceCode\"
        id=\"cb1\" style=\"background: #f1f3f5;\"><pre class=\"sourceCode html code-with-copy\"><code
        class=\"sourceCode html\"><span id=\"cb1-1\"><span class=\"kw\" style=\"color:
        #003B4F;\">&lt;span</span> <span class=\"er\" style=\"color: #AD0000;\">data-user</span><span
        class=\"ot\" style=\"color: #003B4F;\">=</span><span class=\"st\" style=\"color:
        #20794D;\">\"john.doe\"</span></span>\n<span id=\"cb1-2\"><span class=\"ot\"
        style=\"color: #003B4F;\">      data-domain=</span><span class=\"st\" style=\"color:
        #20794D;\">\"example.com\"</span></span>\n<span id=\"cb1-3\"><span class=\"ot\"
        style=\"color: #003B4F;\">      class=</span><span class=\"st\" style=\"color:
        #20794D;\">\"obfuscated-mail-address\"</span><span class=\"kw\" style=\"color:
        #003B4F;\">&gt;</span><span class=\"co\" style=\"color: #5E5E5E;\">&lt;!--</span></span>\n<span
        id=\"cb1-4\"><span class=\"co\" style=\"color: #5E5E5E;\">--&gt;</span>@<span
        class=\"kw\" style=\"color: #003B4F;\">&lt;span&gt;</span>obfuscated email
        address<span class=\"kw\" style=\"color: #003B4F;\">&lt;/span&gt;&lt;/span&gt;</span></span></code></pre></div>\n<p>CSS:</p>\n<div
        class=\"sourceCode\" id=\"cb2\" style=\"background: #f1f3f5;\"><pre class=\"sourceCode
        css code-with-copy\"><code class=\"sourceCode css\"><span id=\"cb2-1\"><span
        class=\"fu\" style=\"color: #4758AB;\">.obfuscated-mail-address</span><span
        class=\"in\" style=\"color: #5E5E5E;\">::before</span> {</span>\n<span id=\"cb2-2\">
        \ <span class=\"kw\" style=\"color: #003B4F;\">content</span>: <span class=\"fu\"
        style=\"color: #4758AB;\">attr(</span>data-user<span class=\"fu\" style=\"color:
        #4758AB;\">)</span><span class=\"op\" style=\"color: #5E5E5E;\">;</span></span>\n<span
        id=\"cb2-3\">}</span>\n<span id=\"cb2-4\"><span class=\"fu\" style=\"color:
        #4758AB;\">.obfuscated-mail-address</span><span class=\"in\" style=\"color:
        #5E5E5E;\">::after</span> {</span>\n<span id=\"cb2-5\">  <span class=\"kw\"
        style=\"color: #003B4F;\">content</span>: <span class=\"fu\" style=\"color:
        #4758AB;\">attr(</span>data-domain<span class=\"fu\" style=\"color: #4758AB;\">)</span><span
        class=\"op\" style=\"color: #5E5E5E;\">;</span></span>\n<span id=\"cb2-6\">}</span>\n<span
        id=\"cb2-7\"><span class=\"fu\" style=\"color: #4758AB;\">.obfuscated-email-address</span>
        <span class=\"op\" style=\"color: #5E5E5E;\">&gt;</span> <span class=\"op\"
        style=\"color: #5E5E5E;\">*</span> {</span>\n<span id=\"cb2-8\">  <span class=\"kw\"
        style=\"color: #003B4F;\">display</span>: <span class=\"dv\" style=\"color:
        #AD0000;\">none</span><span class=\"op\" style=\"color: #5E5E5E;\">;</span></span>\n<span
        id=\"cb2-9\">}</span></code></pre></div>\n<p>The result is readable, but can
        be neither selected nor copied:</p>\n<p><span class=\"obfuscated-mail-address
        dont-touch\" data-user=\"john.doe\" data-domain=\"example.com\"><!--\n--><span>obfuscated
        email address</span></span></p>\n<p>The nested <code>&lt;span&gt;</code> and
        its styling could be omitted, without changing the presentation in most browsers.
        We use it to ensures that everything fails gracefully in browsers with limited
        CSS support. To see why this matters, have a look at this page in a text browser
        like <em>w3m</em> or <em>links</em>.</p>\n</section>\n<section id=\"drawbacks\"
        class=\"level2\">\n<h2 class=\"anchored\" data-anchor-id=\"drawbacks\">Drawbacks</h2>\n<p>The
        biggest advantage of this method is also it\u2019s biggest disadvantage: The
        semantics are broken. The classic markup-code</p>\n<div class=\"sourceCode\"
        id=\"cb3\" style=\"background: #f1f3f5;\"><pre class=\"sourceCode html code-with-copy\"><code
        class=\"sourceCode html\"><span id=\"cb3-1\"><span class=\"kw\" style=\"color:
        #003B4F;\">&lt;a</span> <span class=\"er\" style=\"color: #AD0000;\">href</span><span
        class=\"ot\" style=\"color: #003B4F;\">=</span><span class=\"st\" style=\"color:
        #20794D;\">\"mailto:me@example.com\"</span><span class=\"kw\" style=\"color:
        #003B4F;\">&gt;</span>John Doe<span class=\"kw\" style=\"color: #003B4F;\">&lt;/a&gt;</span></span></code></pre></div>\n<p>is
        rendered as <a href=\"mailto:me@example.com\">John Doe</a> and makes it very
        clear, to machines and humans alike, that <em>John Doe</em> can be reached
        at <em>me@example.com</em>. Address munging, like the above, preserves this
        meaning for humans, but takes it away for machines. For better and for worse,
        browsers, search engines, and spam bots will not be aware of the meaning of
        the obfuscated address.</p>\n<p>These effects can be alleviated by resolving
        to additional javascript:</p>\n<div class=\"sourceCode\" id=\"cb4\" style=\"background:
        #f1f3f5;\"><pre class=\"sourceCode javascript code-with-copy\"><code class=\"sourceCode
        javascript\"><span id=\"cb4-1\"><span class=\"co\" style=\"color: #5E5E5E;\">//
        convert obfuscated mail addresses into clickable \"mailto:\" links</span></span>\n<span
        id=\"cb4-2\"><span class=\"fu\" style=\"color: #4758AB;\">jQuery</span>(<span
        class=\"st\" style=\"color: #20794D;\">\"document\"</span>)<span class=\"op\"
        style=\"color: #5E5E5E;\">.</span><span class=\"fu\" style=\"color: #4758AB;\">ready</span>(<span
        class=\"kw\" style=\"color: #003B4F;\">function</span>($) {</span>\n<span
        id=\"cb4-3\">  <span class=\"kw\" style=\"color: #003B4F;\">var</span> mailAddressClass
        <span class=\"op\" style=\"color: #5E5E5E;\">=</span> <span class=\"st\" style=\"color:
        #20794D;\">\"obfuscated-mail-address\"</span><span class=\"op\" style=\"color:
        #5E5E5E;\">;</span></span>\n<span id=\"cb4-4\">  <span class=\"fu\" style=\"color:
        #4758AB;\">$</span>(<span class=\"st\" style=\"color: #20794D;\">\".\"</span><span
        class=\"op\" style=\"color: #5E5E5E;\">+</span>mailAddressClass)<span class=\"op\"
        style=\"color: #5E5E5E;\">.</span><span class=\"fu\" style=\"color: #4758AB;\">each</span>(<span
        class=\"kw\" style=\"color: #003B4F;\">function</span>() {</span>\n<span id=\"cb4-5\">
        \   <span class=\"kw\" style=\"color: #003B4F;\">var</span> address <span
        class=\"op\" style=\"color: #5E5E5E;\">=</span> <span class=\"fu\" style=\"color:
        #4758AB;\">$</span>(<span class=\"kw\" style=\"color: #003B4F;\">this</span>)<span
        class=\"op\" style=\"color: #5E5E5E;\">.</span><span class=\"fu\" style=\"color:
        #4758AB;\">attr</span>(<span class=\"st\" style=\"color: #20794D;\">\"data-user\"</span>)
        <span class=\"op\" style=\"color: #5E5E5E;\">+</span> <span class=\"st\" style=\"color:
        #20794D;\">\"@\"</span> <span class=\"op\" style=\"color: #5E5E5E;\">+</span>
        <span class=\"fu\" style=\"color: #4758AB;\">$</span>(<span class=\"kw\" style=\"color:
        #003B4F;\">this</span>)<span class=\"op\" style=\"color: #5E5E5E;\">.</span><span
        class=\"fu\" style=\"color: #4758AB;\">attr</span>(<span class=\"st\" style=\"color:
        #20794D;\">\"data-domain\"</span>)<span class=\"op\" style=\"color: #5E5E5E;\">;</span></span>\n<span
        id=\"cb4-6\">    <span class=\"fu\" style=\"color: #4758AB;\">$</span>(<span
        class=\"kw\" style=\"color: #003B4F;\">this</span>)<span class=\"op\" style=\"color:
        #5E5E5E;\">.</span><span class=\"fu\" style=\"color: #4758AB;\">html</span>(<span
        class=\"fu\" style=\"color: #4758AB;\">$</span>(<span class=\"st\" style=\"color:
        #20794D;\">\"&lt;a href=</span><span class=\"sc\" style=\"color: #5E5E5E;\">\\\"</span><span
        class=\"st\" style=\"color: #20794D;\">mailto:\"</span> <span class=\"op\"
        style=\"color: #5E5E5E;\">+</span> address <span class=\"op\" style=\"color:
        #5E5E5E;\">+</span> <span class=\"st\" style=\"color: #20794D;\">\"</span><span
        class=\"sc\" style=\"color: #5E5E5E;\">\\\"</span><span class=\"st\" style=\"color:
        #20794D;\">&gt;\"</span> <span class=\"op\" style=\"color: #5E5E5E;\">+</span>
        address <span class=\"op\" style=\"color: #5E5E5E;\">+</span> <span class=\"st\"
        style=\"color: #20794D;\">\"&lt;/a&gt;\"</span><span class=\"op\" style=\"color:
        #5E5E5E;\">,</span> {}))<span class=\"op\" style=\"color: #5E5E5E;\">;</span></span>\n<span
        id=\"cb4-7\">    <span class=\"fu\" style=\"color: #4758AB;\">$</span>(<span
        class=\"kw\" style=\"color: #003B4F;\">this</span>)<span class=\"op\" style=\"color:
        #5E5E5E;\">.</span><span class=\"fu\" style=\"color: #4758AB;\">removeClass</span>(mailAddressClass)<span
        class=\"op\" style=\"color: #5E5E5E;\">;</span></span>\n<span id=\"cb4-8\">
        \ })<span class=\"op\" style=\"color: #5E5E5E;\">;</span></span>\n<span id=\"cb4-9\">})<span
        class=\"op\" style=\"color: #5E5E5E;\">;</span></span></code></pre></div>\n<p>The
        webpage is still usable with JavaScript turned off, and even fails gracefully
        on text-only browsers. If JavaScript is available, the obfuscated links offer
        the same experience as properly coded <code>&lt;a href=\"mailto:...\"&gt;...&lt;/a&gt;</code>
        links: <span class=\"obfuscated-mail-address\" data-user=\"john.doe\" data-domain=\"example.com\">@</span>.
        I believe this to be a very good trade-off between usability and safety from
        harvesters.</p>\n\n\n</section>\n\n ]]></description>\n  <category>html</category>\n
        \ <category>css</category>\n  <category>javascript</category>\n  <guid>https://tarleb.com/posts/avoiding-spam/index.html</guid>\n
        \ <pubDate>Sun, 25 Aug 2013 00:00:00 GMT</pubDate>\n</item>\n</channel>\n</rss>\n"
    headers:
      Accept-Ranges:
      - bytes
      Access-Control-Allow-Origin:
      - '*'
      Age:
      - '259'
      Cache-Control:
      - max-age=600
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Length:
      - '39350'
      Content-Type:
      - application/xml
      Date:
      - Mon, 22 Jan 2024 14:12:28 GMT
      Etag:
      - W/"64205d75-291df"
      Expires:
      - Wed, 03 Jan 2024 02:27:14 GMT
      Last-Modified:
      - Sun, 26 Mar 2023 14:57:57 GMT
      Server:
      - GitHub.com
      Vary:
      - Accept-Encoding
      Via:
      - 1.1 varnish
      X-Cache:
      - HIT
      X-Cache-Hits:
      - '1'
      X-Fastly-Request-ID:
      - 599839c176611dd01ba2ff75c7f5904e13512372
      X-GitHub-Request-Id:
      - AA0A:34B254:125D405:12A4AB0:6594C3AA
      X-Served-By:
      - cache-ams21043-AMS
      X-Timer:
      - S1705932748.014729,VS0,VE26
      x-proxy-cache:
      - MISS
    status:
      code: 200
      message: OK
- request:
    body: '{"authors": [{"name": "Albert Krewinkel"}], "blog_name": "tarleb", "blog_slug":
      "tarleb", "content_text": "[Typst](https://typst.app), the new writing tool,
      was open sourced a\ncouple of days ago. This is right up my alley of course,
      and I have a\ncouple of thoughts on it, which I share here.\n\n::: {#what-is-it
      .section .level2}\n## What is it? {#what-is-it .anchored anchor-id=\"what-is-it\"}\n\nTypst
      is a writing tool that''s described as a LaTeX alternative: it\ntakes plain-text
      markup as input and can produce nice looking PDFs from\nthat. The open-sourcing
      of the code created a lot of excitement and\ninterest, with the [GitHub repository](https://github.com/typst/typst)\ngetting
      starred over 9,000 times in just a few days.\n\nThe tool comes with fresh and
      interesting ideas, impressive technology,\nand a good bit of hype---so let''s
      take a closer look.\n:::\n\n::: {#how-does-it-work .section .level2}\n## How
      does it work? {#how-does-it-work .anchored anchor-id=\"how-does-it-work\"}\n\nTypst
      is written in [Rust](https://www.rust-lang.org/), a comparatively\nlow-level
      programming language that fixes many shortcomings of other\nlanguages operating
      in the same domain. One interesting feature of Rust\nthat Typst makes use of
      is compilation to web assembly, which allows us\nto run Rust programs in the
      browser. This is how Typst can do the\nblazing fast PDF generation *in the browser!*\n\nOf
      course this only works if it is Rust all the way down, which has\nimportant
      consequences. My first thought when I looked at the code was\nthat it suffered
      from some serious\n[nih](https://en.wikipedia.org/wiki/Not_invented_here) syndrome:\nbasically
      the whole stack is built on libraries written by the Typst\nteam, even when
      high-qualitify open source libraries were available and\ncould have been used
      with Rust.\n\nBut, while nih still seems relevant here and there, the majority
      of\nlibraries make sense when viewed through the lens of wasm-compilation.\nMy
      understanding is that it''s not always easy to compile C libraries to\nwasm.
      And with a complex system like Typst, it is often essential to\nhave full control
      over the underlying libraries. So I think most choices\nare quite reasonable.\n:::\n\n:::
      {#what-makes-it-popular .section .level2}\n## What makes it popular? {#what-makes-it-popular
      .anchored anchor-id=\"what-makes-it-popular\"}\n\nThe Typst announcements on
      sites like [Hacker\nNews](https://news.ycombinator.com/item?id=35250210) and\n[lobste.rs](https://lobste.rs/s/ko1yjj/typst_new_markup_based_typesetting)\nranked
      \u2116\u20091, and the tool was mentioned in basically every social media\ncircle
      and chat that I happen to be part of. There''s clearly *a lot* of\ninterest
      in a modernized version of LaTeX. Good ol'' TeX and it''s\nchildren have been
      around for a long while, and have essentially held\nthe monopoly on PDF production
      for typographically advanced documents\n(tools like HTML-to-PDF converters like\n[WeasyPrint](https://weasyprint.org/)
      notwithstanding).\n\nBut the need for a nicer PDF generator is probably not
      the only reason\nwhy Typst gained so much traction. I believe that a lot of
      interest from\nthe programmer community is fueled by the technological choices:
      Rust\nhas the aura of a new and shiny tool that [everyone would like to\nuse](https://stackoverflow.blog/2023/01/26/comparing-tag-trends-with-our-most-loved-programming-languages/),\n*especially*
      the regulars on the aforementioned sites, who share an\ninterest in the latest
      tools. An otherwise equivalent project written in\na \"boring\" language like
      Python would likely have sparked less interest.\n\nI find it also important
      to note that Typst comes with *extensive\ndocumentation* that makes it easy
      to dive right in. It is far too common\nin the programming world to release
      some cool new tool into the wild,\nwhile treating documentation as an unimportant
      afterthought. Yes, I''m\nguilty of that, too. Even the best tool can be unusable
      when its docs\nare missing or sparse. Typst didn''t make this mistake, and I
      think it\npaid off.\n:::\n\n::: {#personal-opinions .section .level2}\n## Personal
      opinions {#personal-opinions .anchored anchor-id=\"personal-opinions\"}\n\nThis
      wouldn''t be a proper \"old man shakes fist at the clouds\" tech blog\npost
      if it didn''t come with a number of \"I see room for improvements\"\ncomments.
      Here we go.\n\n::: {#scripting .section .level3}\n### Scripting {#scripting
      .anchored anchor-id=\"scripting\"}\n\nOne of my main concerns is the scripting
      language: It seems well\ndesigned, but I''m not convinced that it was necessary
      to create a\ncompletely new language. I actually believe that something like
      Lua,\nwhich is established^1^ but flexlible, would have worked well here. But\nwhat''s
      more is that, if we accept that it was necessary to have a custom\nlanguage,
      I would have preferred one that isn''t Turing complete, i.e.,\none where we
      can be sure that document rendering will terminate.\nSomething like [Dhall](https://dhall-lang.org/).\n\nAs
      it currently stands we can neither reuse pre-existing code, nor do we\nhave
      a guarantee that the document will stop evaluating at some point.\nIt feels
      like a missed opportunity.\n:::\n\n::: {#notebooks .section .level3}\n### Notebooks
      {#notebooks .anchored anchor-id=\"notebooks\"}\n\nNotebooks are a great tool
      to improve reproducibility in science\nwriting. The code for analyses is collocated
      with the descriptive text\nin a single place. The data is closely linked to
      the final tables and\ngraphics. It is one of the great features of\n[Quarto](https://quarto.org/),
      [Jupyter](https://jupyter.org/),\n[Org](https://orgmode.org/), [Stencila](https://stenci.la/),\nMathematica,
      and so on, which makes them well suited for scientific\nwriting in fields like
      medicine, psychology, and the natural sciences.\n\nThis could be an [issue](https://github.com/typst/typst/issues/117)
      for\nTypst, but I believe that it won''t be a problem when Typst is used in\ncombination
      with other tools. John MacFarlane (of\n[CommonMark](https://commonmark.org)
      and [pandoc](https://pandoc.org/)\nfame) has [started work](https://github.com/jgm/pandoc/issues/8713)
      on a\nTypst pandoc writer, which will convert existing Markdown documents to\nTypst,
      and could enable the use of Typst as PDF generator while still\nwriting Markdown
      and Python code in Quarto.\n:::\n\n::: {#accessibility-and-metadata .section
      .level3}\n### Accessibility and metadata {#accessibility-and-metadata .anchored
      anchor-id=\"accessibility-and-metadata\"}\n\nIt''s good practice to make PDFs
      accessible, which requires adding\nsemantic information to a PDF instead of
      \"just\" placing characters on a\npage. Accessibility is even a legal requirement
      for government-issued\ndocuments in many countries. There are standards like
      PDF/A-1a and\nPDF/UA that ensure people with disabilities can access the information\ncontained
      in the PDF. This is currently not supperted in Typst. LaTeX is\nstill trying
      to catch up there, too, while\n[ConTeXt](https://wiki.contextgarden.net/) and\n[speedata](https://speedata.de/)
      are doing well, for example.\n:::\n:::\n\n::: {#predictions .section .level2}\n##
      Predictions {#predictions .anchored anchor-id=\"predictions\"}\n\nI believe
      Typst will succeed, but not as a full-fledged writing tool.\nThe greatest value
      I see is in the **responsive, interactive, and even\ncollaborative styling of
      PDFs**. That feature is truly unique and sets\nTypst appart from all other software
      out there. The tool obviously has\nthe potential to reach the critical mass
      of contributors to become a\nsustainable open source project, and the tech choices
      help to attract\nmore developers. Last but not least, the app is shiny, works
      well, and\nmakes people want to use it.\n\nAt the same time, I believe that
      the Typst writing app won''t take hold\nin scientific writing. Most of the current
      enthusiasm is contained to\ntechnical circles, and scientists don''t have strong
      reasons to switch\nyet. To the contrary, journals expect paper submissions to
      be done in\nWord or LaTeX, not PDF. This won''t change anytime soon. Typst will
      have\nto insert itself into the current publishing landscape, and that''s not
      a\ntrivial task.\n\nFor example, [SciFlow](https://sciflow.net/) and\n[Overleaf](https://overleaf.com/)
      already exist, cover most of the\nmarket needs, have a solid headstart, and
      -- this is the important part\n-- are well aligned with the needs of science
      publishers. Any new tool\nhas to compete with them. Also, let''s not forget
      all the other tools\nthat I mentioned above.\n\nRegardless, I''m optimistic
      that Typst can carve out its own business\nniche to occupy. For example, hardly
      any of my points above matter in\nprint publishing. An indie book publisher
      that allows authors to use\nTypst for layouting would be amazing.\n\nI hope
      that the Typst team''s hard work will pay off, and I will continue\nto follow
      their progress with great interest.\n:::\n\n::: {#acknowledgements .section
      .level2}\n## Acknowledgements {#acknowledgements .anchored anchor-id=\"acknowledgements\"}\n\nHeart-felt
      thanks to\n[@maegul@hachyderm.io](https://hachyderm.io/@maegul) for the insightful\nfeedback
      on an earlier version of this post, and to [Ilona\nSilverwood](https://ilonasilverwood.github.io/)
      for her skillful\nediting. This post became much better thanks to their input.\n:::\n\n:::
      {#updates .section .level2}\n## Updates {#updates .anchored anchor-id=\"updates\"}\n\nAn
      earlier version listed [Authorea](https://www.authorea.com/) as an\nauthoring
      tool, but the platform has shifted focus since I last looked\nat it, so I''ve
      removed it.\n:::\n\n::: {#quarto-appendix .default}\n::: {#footnotes .section
      .footnotes .footnotes-end-of-document}\n## Footnotes {#footnotes .anchored .quarto-appendix-heading}\n\n1.  :::
      {#fn1}\n    I consider [Lua](https://lua.org/) to be *the* language of\n    publishing
      tools. It fuels [pandoc](https://pandoc.org/),\n    [Quarto](https://quarto.org/),\n    [ConTeXt](https://wiki.contextgarden.net/),\n    [LuaLaTeX](http://luatex.org/),
      [speedata](https://speedata.de/),\n    [SILE](https://sile-typesetter.org/),
      and probably a few more.\u21a9\ufe0e\n    :::\n:::\n:::\n", "images": [], "updated_at":
      1679616000, "published_at": 1679616000, "image": null, "language": "en", "category":
      "computerAndInformationSciences", "reference": [], "relationships": [], "summary":
      "Typst, the new writing tool, was open sourced a couple of days ago. This is
      right up my alley of course, and I have a couple of thoughts on it, which I
      share here. What is it?   Typst is a writing tool that\u2019s described as a
      LaTeX alternative: it takes plain-text markup as input and can produce nice
      looking PDFs from that.\n", "tags": ["PDF"], "title": "Typst Musings", "url":
      "https://tarleb.com/posts/typst-musings", "guid": "https://tarleb.com/posts/typst-musings/index.html",
      "archive_url": "https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/typst-musings"}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      accept-profile:
      - public
      connection:
      - keep-alive
      content-length:
      - '10982'
      content-profile:
      - public
      content-type:
      - application/json
      host:
      - db.rogue-scholar.org
      prefer:
      - return=representation,resolution=merge-duplicates
      user-agent:
      - python-httpx/0.25.2
      x-client-info:
      - supabase-py/2.3.4
    method: POST
    uri: https://db.rogue-scholar.org/rest/v1/posts?on_conflict=guid
  response:
    content: "[{\"url\":\"https://tarleb.com/posts/typst-musings\",\"title\":\"Typst
      Musings\",\"summary\":\"Typst, the new writing tool, was open sourced a couple
      of days ago. This is right up my alley of course, and I have a couple of thoughts
      on it, which I share here. What is it?   Typst is a writing tool that\u2019s
      described as a LaTeX alternative: it takes plain-text markup as input and can
      produce nice looking PDFs from that.\\n\",\"image\":null,\"tags\":[\"PDF\"],\"language\":\"en\",\"authors\":[{\"name\":
      \"Albert Krewinkel\"}],\"doi\":\"https://doi.org/10.59350/y2akn-caz06\",\"id\":\"b98948a9-9fcf-4580-a446-7354f2c7e6cd\",\"reference\":[],\"updated_at\":1679616000,\"published_at\":1679616000,\"blog_name\":\"tarleb\",\"indexed_at\":1700475385,\"indexed\":true,\"images\":[],\"blog_slug\":\"tarleb\",\"content_text\":\"[Typst](https://typst.app),
      the new writing tool, was open sourced a\\ncouple of days ago. This is right
      up my alley of course, and I have a\\ncouple of thoughts on it, which I share
      here.\\n\\n::: {#what-is-it .section .level2}\\n## What is it? {#what-is-it
      .anchored anchor-id=\\\"what-is-it\\\"}\\n\\nTypst is a writing tool that's
      described as a LaTeX alternative: it\\ntakes plain-text markup as input and
      can produce nice looking PDFs from\\nthat. The open-sourcing of the code created
      a lot of excitement and\\ninterest, with the [GitHub repository](https://github.com/typst/typst)\\ngetting
      starred over 9,000 times in just a few days.\\n\\nThe tool comes with fresh
      and interesting ideas, impressive technology,\\nand a good bit of hype---so
      let's take a closer look.\\n:::\\n\\n::: {#how-does-it-work .section .level2}\\n##
      How does it work? {#how-does-it-work .anchored anchor-id=\\\"how-does-it-work\\\"}\\n\\nTypst
      is written in [Rust](https://www.rust-lang.org/), a comparatively\\nlow-level
      programming language that fixes many shortcomings of other\\nlanguages operating
      in the same domain. One interesting feature of Rust\\nthat Typst makes use of
      is compilation to web assembly, which allows us\\nto run Rust programs in the
      browser. This is how Typst can do the\\nblazing fast PDF generation *in the
      browser!*\\n\\nOf course this only works if it is Rust all the way down, which
      has\\nimportant consequences. My first thought when I looked at the code was\\nthat
      it suffered from some serious\\n[nih](https://en.wikipedia.org/wiki/Not_invented_here)
      syndrome:\\nbasically the whole stack is built on libraries written by the Typst\\nteam,
      even when high-qualitify open source libraries were available and\\ncould have
      been used with Rust.\\n\\nBut, while nih still seems relevant here and there,
      the majority of\\nlibraries make sense when viewed through the lens of wasm-compilation.\\nMy
      understanding is that it's not always easy to compile C libraries to\\nwasm.
      And with a complex system like Typst, it is often essential to\\nhave full control
      over the underlying libraries. So I think most choices\\nare quite reasonable.\\n:::\\n\\n:::
      {#what-makes-it-popular .section .level2}\\n## What makes it popular? {#what-makes-it-popular
      .anchored anchor-id=\\\"what-makes-it-popular\\\"}\\n\\nThe Typst announcements
      on sites like [Hacker\\nNews](https://news.ycombinator.com/item?id=35250210)
      and\\n[lobste.rs](https://lobste.rs/s/ko1yjj/typst_new_markup_based_typesetting)\\nranked
      \u2116\u20091, and the tool was mentioned in basically every social media\\ncircle
      and chat that I happen to be part of. There's clearly *a lot* of\\ninterest
      in a modernized version of LaTeX. Good ol' TeX and it's\\nchildren have been
      around for a long while, and have essentially held\\nthe monopoly on PDF production
      for typographically advanced documents\\n(tools like HTML-to-PDF converters
      like\\n[WeasyPrint](https://weasyprint.org/) notwithstanding).\\n\\nBut the
      need for a nicer PDF generator is probably not the only reason\\nwhy Typst gained
      so much traction. I believe that a lot of interest from\\nthe programmer community
      is fueled by the technological choices: Rust\\nhas the aura of a new and shiny
      tool that [everyone would like to\\nuse](https://stackoverflow.blog/2023/01/26/comparing-tag-trends-with-our-most-loved-programming-languages/),\\n*especially*
      the regulars on the aforementioned sites, who share an\\ninterest in the latest
      tools. An otherwise equivalent project written in\\na \\\"boring\\\" language
      like Python would likely have sparked less interest.\\n\\nI find it also important
      to note that Typst comes with *extensive\\ndocumentation* that makes it easy
      to dive right in. It is far too common\\nin the programming world to release
      some cool new tool into the wild,\\nwhile treating documentation as an unimportant
      afterthought. Yes, I'm\\nguilty of that, too. Even the best tool can be unusable
      when its docs\\nare missing or sparse. Typst didn't make this mistake, and I
      think it\\npaid off.\\n:::\\n\\n::: {#personal-opinions .section .level2}\\n##
      Personal opinions {#personal-opinions .anchored anchor-id=\\\"personal-opinions\\\"}\\n\\nThis
      wouldn't be a proper \\\"old man shakes fist at the clouds\\\" tech blog\\npost
      if it didn't come with a number of \\\"I see room for improvements\\\"\\ncomments.
      Here we go.\\n\\n::: {#scripting .section .level3}\\n### Scripting {#scripting
      .anchored anchor-id=\\\"scripting\\\"}\\n\\nOne of my main concerns is the scripting
      language: It seems well\\ndesigned, but I'm not convinced that it was necessary
      to create a\\ncompletely new language. I actually believe that something like
      Lua,\\nwhich is established^1^ but flexlible, would have worked well here. But\\nwhat's
      more is that, if we accept that it was necessary to have a custom\\nlanguage,
      I would have preferred one that isn't Turing complete, i.e.,\\none where we
      can be sure that document rendering will terminate.\\nSomething like [Dhall](https://dhall-lang.org/).\\n\\nAs
      it currently stands we can neither reuse pre-existing code, nor do we\\nhave
      a guarantee that the document will stop evaluating at some point.\\nIt feels
      like a missed opportunity.\\n:::\\n\\n::: {#notebooks .section .level3}\\n###
      Notebooks {#notebooks .anchored anchor-id=\\\"notebooks\\\"}\\n\\nNotebooks
      are a great tool to improve reproducibility in science\\nwriting. The code for
      analyses is collocated with the descriptive text\\nin a single place. The data
      is closely linked to the final tables and\\ngraphics. It is one of the great
      features of\\n[Quarto](https://quarto.org/), [Jupyter](https://jupyter.org/),\\n[Org](https://orgmode.org/),
      [Stencila](https://stenci.la/),\\nMathematica, and so on, which makes them well
      suited for scientific\\nwriting in fields like medicine, psychology, and the
      natural sciences.\\n\\nThis could be an [issue](https://github.com/typst/typst/issues/117)
      for\\nTypst, but I believe that it won't be a problem when Typst is used in\\ncombination
      with other tools. John MacFarlane (of\\n[CommonMark](https://commonmark.org)
      and [pandoc](https://pandoc.org/)\\nfame) has [started work](https://github.com/jgm/pandoc/issues/8713)
      on a\\nTypst pandoc writer, which will convert existing Markdown documents to\\nTypst,
      and could enable the use of Typst as PDF generator while still\\nwriting Markdown
      and Python code in Quarto.\\n:::\\n\\n::: {#accessibility-and-metadata .section
      .level3}\\n### Accessibility and metadata {#accessibility-and-metadata .anchored
      anchor-id=\\\"accessibility-and-metadata\\\"}\\n\\nIt's good practice to make
      PDFs accessible, which requires adding\\nsemantic information to a PDF instead
      of \\\"just\\\" placing characters on a\\npage. Accessibility is even a legal
      requirement for government-issued\\ndocuments in many countries. There are standards
      like PDF/A-1a and\\nPDF/UA that ensure people with disabilities can access the
      information\\ncontained in the PDF. This is currently not supperted in Typst.
      LaTeX is\\nstill trying to catch up there, too, while\\n[ConTeXt](https://wiki.contextgarden.net/)
      and\\n[speedata](https://speedata.de/) are doing well, for example.\\n:::\\n:::\\n\\n:::
      {#predictions .section .level2}\\n## Predictions {#predictions .anchored anchor-id=\\\"predictions\\\"}\\n\\nI
      believe Typst will succeed, but not as a full-fledged writing tool.\\nThe greatest
      value I see is in the **responsive, interactive, and even\\ncollaborative styling
      of PDFs**. That feature is truly unique and sets\\nTypst appart from all other
      software out there. The tool obviously has\\nthe potential to reach the critical
      mass of contributors to become a\\nsustainable open source project, and the
      tech choices help to attract\\nmore developers. Last but not least, the app
      is shiny, works well, and\\nmakes people want to use it.\\n\\nAt the same time,
      I believe that the Typst writing app won't take hold\\nin scientific writing.
      Most of the current enthusiasm is contained to\\ntechnical circles, and scientists
      don't have strong reasons to switch\\nyet. To the contrary, journals expect
      paper submissions to be done in\\nWord or LaTeX, not PDF. This won't change
      anytime soon. Typst will have\\nto insert itself into the current publishing
      landscape, and that's not a\\ntrivial task.\\n\\nFor example, [SciFlow](https://sciflow.net/)
      and\\n[Overleaf](https://overleaf.com/) already exist, cover most of the\\nmarket
      needs, have a solid headstart, and -- this is the important part\\n-- are well
      aligned with the needs of science publishers. Any new tool\\nhas to compete
      with them. Also, let's not forget all the other tools\\nthat I mentioned above.\\n\\nRegardless,
      I'm optimistic that Typst can carve out its own business\\nniche to occupy.
      For example, hardly any of my points above matter in\\nprint publishing. An
      indie book publisher that allows authors to use\\nTypst for layouting would
      be amazing.\\n\\nI hope that the Typst team's hard work will pay off, and I
      will continue\\nto follow their progress with great interest.\\n:::\\n\\n:::
      {#acknowledgements .section .level2}\\n## Acknowledgements {#acknowledgements
      .anchored anchor-id=\\\"acknowledgements\\\"}\\n\\nHeart-felt thanks to\\n[@maegul@hachyderm.io](https://hachyderm.io/@maegul)
      for the insightful\\nfeedback on an earlier version of this post, and to [Ilona\\nSilverwood](https://ilonasilverwood.github.io/)
      for her skillful\\nediting. This post became much better thanks to their input.\\n:::\\n\\n:::
      {#updates .section .level2}\\n## Updates {#updates .anchored anchor-id=\\\"updates\\\"}\\n\\nAn
      earlier version listed [Authorea](https://www.authorea.com/) as an\\nauthoring
      tool, but the platform has shifted focus since I last looked\\nat it, so I've
      removed it.\\n:::\\n\\n::: {#quarto-appendix .default}\\n::: {#footnotes .section
      .footnotes .footnotes-end-of-document}\\n## Footnotes {#footnotes .anchored
      .quarto-appendix-heading}\\n\\n1.  ::: {#fn1}\\n    I consider [Lua](https://lua.org/)
      to be *the* language of\\n    publishing tools. It fuels [pandoc](https://pandoc.org/),\\n
      \   [Quarto](https://quarto.org/),\\n    [ConTeXt](https://wiki.contextgarden.net/),\\n
      \   [LuaLaTeX](http://luatex.org/), [speedata](https://speedata.de/),\\n    [SILE](https://sile-typesetter.org/),
      and probably a few more.\u21A9\uFE0E\\n    :::\\n:::\\n:::\\n\",\"relationships\":[],\"archive_url\":\"https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/typst-musings\",\"guid\":\"https://tarleb.com/posts/typst-musings/index.html\",\"updated\":false,\"category\":\"computerAndInformationSciences\"}]"
    headers:
      Access-Control-Allow-Origin:
      - '*'
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 849864655ddf1638-DUS
      Connection:
      - keep-alive
      Content-Profile:
      - public
      Content-Range:
      - '*/*'
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Mon, 22 Jan 2024 14:12:29 GMT
      Preference-Applied:
      - resolution=merge-duplicates
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      Via:
      - kong/2.8.1
      X-Kong-Proxy-Latency:
      - '0'
      X-Kong-Upstream-Latency:
      - '6'
      alt-svc:
      - h3=":443"; ma=86400
      sb-gateway-version:
      - '1'
    http_version: HTTP/1.1
    status_code: 201
- request:
    body: '{"indexed": true}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      accept-profile:
      - public
      connection:
      - keep-alive
      content-length:
      - '17'
      content-profile:
      - public
      content-type:
      - application/json
      host:
      - db.rogue-scholar.org
      prefer:
      - return=representation
      user-agent:
      - python-httpx/0.25.2
      x-client-info:
      - supabase-py/2.3.4
    method: PATCH
    uri: https://db.rogue-scholar.org/rest/v1/posts?id=eq.b98948a9-9fcf-4580-a446-7354f2c7e6cd
  response:
    content: "[{\"url\":\"https://tarleb.com/posts/typst-musings\",\"title\":\"Typst
      Musings\",\"summary\":\"Typst, the new writing tool, was open sourced a couple
      of days ago. This is right up my alley of course, and I have a couple of thoughts
      on it, which I share here. What is it?   Typst is a writing tool that\u2019s
      described as a LaTeX alternative: it takes plain-text markup as input and can
      produce nice looking PDFs from that.\\n\",\"image\":null,\"tags\":[\"PDF\"],\"language\":\"en\",\"authors\":[{\"name\":
      \"Albert Krewinkel\"}],\"doi\":\"https://doi.org/10.59350/y2akn-caz06\",\"id\":\"b98948a9-9fcf-4580-a446-7354f2c7e6cd\",\"reference\":[],\"updated_at\":1679616000,\"published_at\":1679616000,\"blog_name\":\"tarleb\",\"indexed_at\":1700475385,\"indexed\":true,\"images\":[],\"blog_slug\":\"tarleb\",\"content_text\":\"[Typst](https://typst.app),
      the new writing tool, was open sourced a\\ncouple of days ago. This is right
      up my alley of course, and I have a\\ncouple of thoughts on it, which I share
      here.\\n\\n::: {#what-is-it .section .level2}\\n## What is it? {#what-is-it
      .anchored anchor-id=\\\"what-is-it\\\"}\\n\\nTypst is a writing tool that's
      described as a LaTeX alternative: it\\ntakes plain-text markup as input and
      can produce nice looking PDFs from\\nthat. The open-sourcing of the code created
      a lot of excitement and\\ninterest, with the [GitHub repository](https://github.com/typst/typst)\\ngetting
      starred over 9,000 times in just a few days.\\n\\nThe tool comes with fresh
      and interesting ideas, impressive technology,\\nand a good bit of hype---so
      let's take a closer look.\\n:::\\n\\n::: {#how-does-it-work .section .level2}\\n##
      How does it work? {#how-does-it-work .anchored anchor-id=\\\"how-does-it-work\\\"}\\n\\nTypst
      is written in [Rust](https://www.rust-lang.org/), a comparatively\\nlow-level
      programming language that fixes many shortcomings of other\\nlanguages operating
      in the same domain. One interesting feature of Rust\\nthat Typst makes use of
      is compilation to web assembly, which allows us\\nto run Rust programs in the
      browser. This is how Typst can do the\\nblazing fast PDF generation *in the
      browser!*\\n\\nOf course this only works if it is Rust all the way down, which
      has\\nimportant consequences. My first thought when I looked at the code was\\nthat
      it suffered from some serious\\n[nih](https://en.wikipedia.org/wiki/Not_invented_here)
      syndrome:\\nbasically the whole stack is built on libraries written by the Typst\\nteam,
      even when high-qualitify open source libraries were available and\\ncould have
      been used with Rust.\\n\\nBut, while nih still seems relevant here and there,
      the majority of\\nlibraries make sense when viewed through the lens of wasm-compilation.\\nMy
      understanding is that it's not always easy to compile C libraries to\\nwasm.
      And with a complex system like Typst, it is often essential to\\nhave full control
      over the underlying libraries. So I think most choices\\nare quite reasonable.\\n:::\\n\\n:::
      {#what-makes-it-popular .section .level2}\\n## What makes it popular? {#what-makes-it-popular
      .anchored anchor-id=\\\"what-makes-it-popular\\\"}\\n\\nThe Typst announcements
      on sites like [Hacker\\nNews](https://news.ycombinator.com/item?id=35250210)
      and\\n[lobste.rs](https://lobste.rs/s/ko1yjj/typst_new_markup_based_typesetting)\\nranked
      \u2116\u20091, and the tool was mentioned in basically every social media\\ncircle
      and chat that I happen to be part of. There's clearly *a lot* of\\ninterest
      in a modernized version of LaTeX. Good ol' TeX and it's\\nchildren have been
      around for a long while, and have essentially held\\nthe monopoly on PDF production
      for typographically advanced documents\\n(tools like HTML-to-PDF converters
      like\\n[WeasyPrint](https://weasyprint.org/) notwithstanding).\\n\\nBut the
      need for a nicer PDF generator is probably not the only reason\\nwhy Typst gained
      so much traction. I believe that a lot of interest from\\nthe programmer community
      is fueled by the technological choices: Rust\\nhas the aura of a new and shiny
      tool that [everyone would like to\\nuse](https://stackoverflow.blog/2023/01/26/comparing-tag-trends-with-our-most-loved-programming-languages/),\\n*especially*
      the regulars on the aforementioned sites, who share an\\ninterest in the latest
      tools. An otherwise equivalent project written in\\na \\\"boring\\\" language
      like Python would likely have sparked less interest.\\n\\nI find it also important
      to note that Typst comes with *extensive\\ndocumentation* that makes it easy
      to dive right in. It is far too common\\nin the programming world to release
      some cool new tool into the wild,\\nwhile treating documentation as an unimportant
      afterthought. Yes, I'm\\nguilty of that, too. Even the best tool can be unusable
      when its docs\\nare missing or sparse. Typst didn't make this mistake, and I
      think it\\npaid off.\\n:::\\n\\n::: {#personal-opinions .section .level2}\\n##
      Personal opinions {#personal-opinions .anchored anchor-id=\\\"personal-opinions\\\"}\\n\\nThis
      wouldn't be a proper \\\"old man shakes fist at the clouds\\\" tech blog\\npost
      if it didn't come with a number of \\\"I see room for improvements\\\"\\ncomments.
      Here we go.\\n\\n::: {#scripting .section .level3}\\n### Scripting {#scripting
      .anchored anchor-id=\\\"scripting\\\"}\\n\\nOne of my main concerns is the scripting
      language: It seems well\\ndesigned, but I'm not convinced that it was necessary
      to create a\\ncompletely new language. I actually believe that something like
      Lua,\\nwhich is established^1^ but flexlible, would have worked well here. But\\nwhat's
      more is that, if we accept that it was necessary to have a custom\\nlanguage,
      I would have preferred one that isn't Turing complete, i.e.,\\none where we
      can be sure that document rendering will terminate.\\nSomething like [Dhall](https://dhall-lang.org/).\\n\\nAs
      it currently stands we can neither reuse pre-existing code, nor do we\\nhave
      a guarantee that the document will stop evaluating at some point.\\nIt feels
      like a missed opportunity.\\n:::\\n\\n::: {#notebooks .section .level3}\\n###
      Notebooks {#notebooks .anchored anchor-id=\\\"notebooks\\\"}\\n\\nNotebooks
      are a great tool to improve reproducibility in science\\nwriting. The code for
      analyses is collocated with the descriptive text\\nin a single place. The data
      is closely linked to the final tables and\\ngraphics. It is one of the great
      features of\\n[Quarto](https://quarto.org/), [Jupyter](https://jupyter.org/),\\n[Org](https://orgmode.org/),
      [Stencila](https://stenci.la/),\\nMathematica, and so on, which makes them well
      suited for scientific\\nwriting in fields like medicine, psychology, and the
      natural sciences.\\n\\nThis could be an [issue](https://github.com/typst/typst/issues/117)
      for\\nTypst, but I believe that it won't be a problem when Typst is used in\\ncombination
      with other tools. John MacFarlane (of\\n[CommonMark](https://commonmark.org)
      and [pandoc](https://pandoc.org/)\\nfame) has [started work](https://github.com/jgm/pandoc/issues/8713)
      on a\\nTypst pandoc writer, which will convert existing Markdown documents to\\nTypst,
      and could enable the use of Typst as PDF generator while still\\nwriting Markdown
      and Python code in Quarto.\\n:::\\n\\n::: {#accessibility-and-metadata .section
      .level3}\\n### Accessibility and metadata {#accessibility-and-metadata .anchored
      anchor-id=\\\"accessibility-and-metadata\\\"}\\n\\nIt's good practice to make
      PDFs accessible, which requires adding\\nsemantic information to a PDF instead
      of \\\"just\\\" placing characters on a\\npage. Accessibility is even a legal
      requirement for government-issued\\ndocuments in many countries. There are standards
      like PDF/A-1a and\\nPDF/UA that ensure people with disabilities can access the
      information\\ncontained in the PDF. This is currently not supperted in Typst.
      LaTeX is\\nstill trying to catch up there, too, while\\n[ConTeXt](https://wiki.contextgarden.net/)
      and\\n[speedata](https://speedata.de/) are doing well, for example.\\n:::\\n:::\\n\\n:::
      {#predictions .section .level2}\\n## Predictions {#predictions .anchored anchor-id=\\\"predictions\\\"}\\n\\nI
      believe Typst will succeed, but not as a full-fledged writing tool.\\nThe greatest
      value I see is in the **responsive, interactive, and even\\ncollaborative styling
      of PDFs**. That feature is truly unique and sets\\nTypst appart from all other
      software out there. The tool obviously has\\nthe potential to reach the critical
      mass of contributors to become a\\nsustainable open source project, and the
      tech choices help to attract\\nmore developers. Last but not least, the app
      is shiny, works well, and\\nmakes people want to use it.\\n\\nAt the same time,
      I believe that the Typst writing app won't take hold\\nin scientific writing.
      Most of the current enthusiasm is contained to\\ntechnical circles, and scientists
      don't have strong reasons to switch\\nyet. To the contrary, journals expect
      paper submissions to be done in\\nWord or LaTeX, not PDF. This won't change
      anytime soon. Typst will have\\nto insert itself into the current publishing
      landscape, and that's not a\\ntrivial task.\\n\\nFor example, [SciFlow](https://sciflow.net/)
      and\\n[Overleaf](https://overleaf.com/) already exist, cover most of the\\nmarket
      needs, have a solid headstart, and -- this is the important part\\n-- are well
      aligned with the needs of science publishers. Any new tool\\nhas to compete
      with them. Also, let's not forget all the other tools\\nthat I mentioned above.\\n\\nRegardless,
      I'm optimistic that Typst can carve out its own business\\nniche to occupy.
      For example, hardly any of my points above matter in\\nprint publishing. An
      indie book publisher that allows authors to use\\nTypst for layouting would
      be amazing.\\n\\nI hope that the Typst team's hard work will pay off, and I
      will continue\\nto follow their progress with great interest.\\n:::\\n\\n:::
      {#acknowledgements .section .level2}\\n## Acknowledgements {#acknowledgements
      .anchored anchor-id=\\\"acknowledgements\\\"}\\n\\nHeart-felt thanks to\\n[@maegul@hachyderm.io](https://hachyderm.io/@maegul)
      for the insightful\\nfeedback on an earlier version of this post, and to [Ilona\\nSilverwood](https://ilonasilverwood.github.io/)
      for her skillful\\nediting. This post became much better thanks to their input.\\n:::\\n\\n:::
      {#updates .section .level2}\\n## Updates {#updates .anchored anchor-id=\\\"updates\\\"}\\n\\nAn
      earlier version listed [Authorea](https://www.authorea.com/) as an\\nauthoring
      tool, but the platform has shifted focus since I last looked\\nat it, so I've
      removed it.\\n:::\\n\\n::: {#quarto-appendix .default}\\n::: {#footnotes .section
      .footnotes .footnotes-end-of-document}\\n## Footnotes {#footnotes .anchored
      .quarto-appendix-heading}\\n\\n1.  ::: {#fn1}\\n    I consider [Lua](https://lua.org/)
      to be *the* language of\\n    publishing tools. It fuels [pandoc](https://pandoc.org/),\\n
      \   [Quarto](https://quarto.org/),\\n    [ConTeXt](https://wiki.contextgarden.net/),\\n
      \   [LuaLaTeX](http://luatex.org/), [speedata](https://speedata.de/),\\n    [SILE](https://sile-typesetter.org/),
      and probably a few more.\u21A9\uFE0E\\n    :::\\n:::\\n:::\\n\",\"relationships\":[],\"archive_url\":\"https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/typst-musings\",\"guid\":\"https://tarleb.com/posts/typst-musings/index.html\",\"updated\":false,\"category\":\"computerAndInformationSciences\"}]"
    headers:
      Access-Control-Allow-Origin:
      - '*'
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 84986465de611638-DUS
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Profile:
      - public
      Content-Range:
      - 0-0/*
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Mon, 22 Jan 2024 14:12:29 GMT
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      Via:
      - kong/2.8.1
      X-Kong-Proxy-Latency:
      - '0'
      X-Kong-Upstream-Latency:
      - '3'
      alt-svc:
      - h3=":443"; ma=86400
      sb-gateway-version:
      - '1'
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: '{"authors": [{"name": "Albert Krewinkel"}], "blog_name": "tarleb", "blog_slug":
      "tarleb", "content_text": "Pandoc''s Markdown allows for \"fancy lists\", i.e.,
      lists with different\nstyles used for the marker of ordered list items.\n\nE.g.,
      the list\n\n::: {#cb1 .sourceCode style=\"background: #f1f3f5;\"}\n``` {.sourceCode
      .markdown .code-with-copy}\n(I)  primus\n(#)  secundus\n(#)  tertius\n```\n:::\n\nuses
      uppercase roman numerals and double parentheses for the markers. It\ngets rendered
      as\n\n> I.  primus\n> II. secundus\n> III. tertius\n\n::: {#continuations .section
      .level2}\n## Continuations {#continuations .anchored anchor-id=\"continuations\"}\n\nThe
      fancy lists feature also allows to continue lists after an\nintermediate paragraph:\n\n:::
      {#cb2 .sourceCode style=\"background: #f1f3f5;\"}\n``` {.sourceCode .markdown
      .code-with-copy}\ni.   one\n#.   another\n\nInterruption; not part of any list.\n\niii.
      continue\n#.   keep counting\n```\n:::\n\nThis becomes\n\n> i.  one\n> ii. another\n>\n>
      Interruption; not part of any list.\n>\n> iii. continue\n> iv. keep counting\n\nWhile
      very convenient, this requires us to carefully keep book of the\nnumber of items
      in previous parts, or risk the item numbering to become\ninconsistent. Imagine
      having to find and update all other list parts\nafter adding a single item somewhere.
      Tedious work, that gets tiresome\nquickly.\n:::\n\n::: {#convention .section
      .level2}\n## Convention {#convention .anchored anchor-id=\"convention\"}\n\nWanting
      none of this, we magicked a method that allows us to mark a list\nas a continuation.
      This way, we can search for those lists with a Lua\nfilter and let pandoc do
      the counting and numbering for us.\n\nOur convention is this: any list that
      starts with a number of 90 or\nabove is treated as the continuation of a previous
      list. Why 90? Because\nit''s large, but still easy to express using roman numerals,
      should one\nbe inclined to use those.\n\n::: {#cb3 .sourceCode style=\"background:
      #f1f3f5;\"}\n``` {.sourceCode .markdown .code-with-copy}\ni.  primus\nii. secundus\n\nLorem
      ipsum.\n\nxc. alius item\n#.  ut custodians iens\n```\n:::\n:::\n\n::: {#lua-doing-the-counting
      .section .level2}\n## Lua doing the counting {#lua-doing-the-counting .anchored
      anchor-id=\"lua-doing-the-counting\"}\n\nThe next step is to let pandoc do the
      counting with the help of a Lua\nfilter. In its simplest form, the filter will
      step through all ordered\nlists in the document, remember the number of items
      it has encountered,\nand renumber any list whose start is above our chosen threshold.\n\n:::
      {#cb4 .sourceCode style=\"background: #f1f3f5;\"}\n``` {.sourceCode .lua .code-with-copy}\nlocal
      next_start = 1\n\nfunction OrderedList (ol)\n  if ol.start >= 90 then\n    ol.start
      = next_start\n    next_start = next_start + #ol.content\n  else\n    next_start
      = #ol.content + 1\n  end\n  return ol\nend\n```\n:::\n\nApplied to the example
      above, the filter produces the desired result:\n\n> i.  primus\n> ii. secundus\n>\n>
      Lorem ipsum.\n>\n> iii. alius item\n> iv. ut custodians iens\n:::\n\n::: {#refinements
      .section .level2}\n## Refinements {#refinements .anchored anchor-id=\"refinements\"}\n\nThis
      is fairly good already. But what happens if there are *other* lists\nappearing
      in the intermediate blocks?\n\n    1. First item\n\n    - Nested list:\n\n        a.
      alfa\n        b. bravo\n        c. charlie\n\n    Which list will be continued?\n\n    99.
      ???\n\nWith the current state of our filter, the last item will be numbered\n`d.`,
      which is most likely not what we want. So let''s make the filter\nsensitive
      to the list style; only a list with the matching style will be\ncontinued.\n\nThe
      style and delimiter of ordered list markers can be accessed via the\nelement''s
      `style` and `delimiter` property, respectively. We use those\nvalues to construct
      a string key under which the start number of the\nnext continuation is stored
      in table `next_starts`.\n\n::: {#cb6 .sourceCode style=\"background: #f1f3f5;\"}\n```
      {.sourceCode .lua .code-with-copy}\nlocal next_starts = {}\n\nfunction OrderedList
      (ol)\n  local key = ol.style .. ''|'' .. ol.delimiter\n  if ol.start >= 90 then\n    ol.start
      = next_starts[key] or 1\n    next_starts[key] = ol.start + #ol.content\n  else\n    next_starts[key]
      = #ol.content + 1\n  end\n\n  return ol\nend\n```\n:::\n\nThis way we can keep
      track of multiple lists, distinguishing between\nlists by using the style of
      their markers. The above now gets output as\n\n> 1.  First item\n>\n> - Nested
      list:\n>\n>   a.  alfa\n>   b.  bravo\n>   c.  charlie\n>\n> Which list will
      be continued?\n>\n> 2.  ???\n\nJust what we want. Happy list writing!\n:::\n",
      "images": [], "updated_at": 1669593600, "published_at": 1669593600, "image":
      null, "language": "en", "category": "computerAndInformationSciences", "reference":
      [], "relationships": [], "summary": "Pandoc\u2019s Markdown allows for \u201cfancy
      lists\u201d, i.e., lists with different styles used for the marker of ordered
      list items. E.g., the list (I)  primus (#)  secundus (#)  tertius  uses uppercase
      roman numerals and double parentheses for the markers. It gets rendered as primus
      secundus tertius Continuations   The fancy lists feature also allows to continue
      lists after an intermediate paragraph: i.   one #.   another Interruption;\n",
      "tags": ["Markdown", "Pandoc", "Filter"], "title": "Auto-numbered list continuations",
      "url": "https://tarleb.com/posts/list-continuation", "guid": "https://tarleb.com/posts/list-continuation/index.html",
      "archive_url": "https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/list-continuation"}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      accept-profile:
      - public
      connection:
      - keep-alive
      content-length:
      - '5642'
      content-profile:
      - public
      content-type:
      - application/json
      host:
      - db.rogue-scholar.org
      prefer:
      - return=representation,resolution=merge-duplicates
      user-agent:
      - python-httpx/0.25.2
      x-client-info:
      - supabase-py/2.3.4
    method: POST
    uri: https://db.rogue-scholar.org/rest/v1/posts?on_conflict=guid
  response:
    content: "[{\"url\":\"https://tarleb.com/posts/list-continuation\",\"title\":\"Auto-numbered
      list continuations\",\"summary\":\"Pandoc\u2019s Markdown allows for \u201Cfancy
      lists\u201D, i.e., lists with different styles used for the marker of ordered
      list items. E.g., the list (I)  primus (#)  secundus (#)  tertius  uses uppercase
      roman numerals and double parentheses for the markers. It gets rendered as primus
      secundus tertius Continuations   The fancy lists feature also allows to continue
      lists after an intermediate paragraph: i.   one #.   another Interruption;\\n\",\"image\":null,\"tags\":[\"Markdown\",\"Pandoc\",\"Filter\"],\"language\":\"en\",\"authors\":[{\"name\":
      \"Albert Krewinkel\"}],\"doi\":\"https://doi.org/10.59350/5kh1q-kv634\",\"id\":\"4fb04d8c-7e8b-4597-a917-ebd71b2f2d35\",\"reference\":[],\"updated_at\":1669593600,\"published_at\":1669593600,\"blog_name\":\"tarleb\",\"indexed_at\":1700476101,\"indexed\":true,\"images\":[],\"blog_slug\":\"tarleb\",\"content_text\":\"Pandoc's
      Markdown allows for \\\"fancy lists\\\", i.e., lists with different\\nstyles
      used for the marker of ordered list items.\\n\\nE.g., the list\\n\\n::: {#cb1
      .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n``` {.sourceCode .markdown
      .code-with-copy}\\n(I)  primus\\n(#)  secundus\\n(#)  tertius\\n```\\n:::\\n\\nuses
      uppercase roman numerals and double parentheses for the markers. It\\ngets rendered
      as\\n\\n> I.  primus\\n> II. secundus\\n> III. tertius\\n\\n::: {#continuations
      .section .level2}\\n## Continuations {#continuations .anchored anchor-id=\\\"continuations\\\"}\\n\\nThe
      fancy lists feature also allows to continue lists after an\\nintermediate paragraph:\\n\\n:::
      {#cb2 .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n``` {.sourceCode .markdown
      .code-with-copy}\\ni.   one\\n#.   another\\n\\nInterruption; not part of any
      list.\\n\\niii. continue\\n#.   keep counting\\n```\\n:::\\n\\nThis becomes\\n\\n>
      i.  one\\n> ii. another\\n>\\n> Interruption; not part of any list.\\n>\\n>
      iii. continue\\n> iv. keep counting\\n\\nWhile very convenient, this requires
      us to carefully keep book of the\\nnumber of items in previous parts, or risk
      the item numbering to become\\ninconsistent. Imagine having to find and update
      all other list parts\\nafter adding a single item somewhere. Tedious work, that
      gets tiresome\\nquickly.\\n:::\\n\\n::: {#convention .section .level2}\\n##
      Convention {#convention .anchored anchor-id=\\\"convention\\\"}\\n\\nWanting
      none of this, we magicked a method that allows us to mark a list\\nas a continuation.
      This way, we can search for those lists with a Lua\\nfilter and let pandoc do
      the counting and numbering for us.\\n\\nOur convention is this: any list that
      starts with a number of 90 or\\nabove is treated as the continuation of a previous
      list. Why 90? Because\\nit's large, but still easy to express using roman numerals,
      should one\\nbe inclined to use those.\\n\\n::: {#cb3 .sourceCode style=\\\"background:
      #f1f3f5;\\\"}\\n``` {.sourceCode .markdown .code-with-copy}\\ni.  primus\\nii.
      secundus\\n\\nLorem ipsum.\\n\\nxc. alius item\\n#.  ut custodians iens\\n```\\n:::\\n:::\\n\\n:::
      {#lua-doing-the-counting .section .level2}\\n## Lua doing the counting {#lua-doing-the-counting
      .anchored anchor-id=\\\"lua-doing-the-counting\\\"}\\n\\nThe next step is to
      let pandoc do the counting with the help of a Lua\\nfilter. In its simplest
      form, the filter will step through all ordered\\nlists in the document, remember
      the number of items it has encountered,\\nand renumber any list whose start
      is above our chosen threshold.\\n\\n::: {#cb4 .sourceCode style=\\\"background:
      #f1f3f5;\\\"}\\n``` {.sourceCode .lua .code-with-copy}\\nlocal next_start =
      1\\n\\nfunction OrderedList (ol)\\n  if ol.start >= 90 then\\n    ol.start =
      next_start\\n    next_start = next_start + #ol.content\\n  else\\n    next_start
      = #ol.content + 1\\n  end\\n  return ol\\nend\\n```\\n:::\\n\\nApplied to the
      example above, the filter produces the desired result:\\n\\n> i.  primus\\n>
      ii. secundus\\n>\\n> Lorem ipsum.\\n>\\n> iii. alius item\\n> iv. ut custodians
      iens\\n:::\\n\\n::: {#refinements .section .level2}\\n## Refinements {#refinements
      .anchored anchor-id=\\\"refinements\\\"}\\n\\nThis is fairly good already. But
      what happens if there are *other* lists\\nappearing in the intermediate blocks?\\n\\n
      \   1. First item\\n\\n    - Nested list:\\n\\n        a. alfa\\n        b.
      bravo\\n        c. charlie\\n\\n    Which list will be continued?\\n\\n    99.
      ???\\n\\nWith the current state of our filter, the last item will be numbered\\n`d.`,
      which is most likely not what we want. So let's make the filter\\nsensitive
      to the list style; only a list with the matching style will be\\ncontinued.\\n\\nThe
      style and delimiter of ordered list markers can be accessed via the\\nelement's
      `style` and `delimiter` property, respectively. We use those\\nvalues to construct
      a string key under which the start number of the\\nnext continuation is stored
      in table `next_starts`.\\n\\n::: {#cb6 .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n```
      {.sourceCode .lua .code-with-copy}\\nlocal next_starts = {}\\n\\nfunction OrderedList
      (ol)\\n  local key = ol.style .. '|' .. ol.delimiter\\n  if ol.start >= 90 then\\n
      \   ol.start = next_starts[key] or 1\\n    next_starts[key] = ol.start + #ol.content\\n
      \ else\\n    next_starts[key] = #ol.content + 1\\n  end\\n\\n  return ol\\nend\\n```\\n:::\\n\\nThis
      way we can keep track of multiple lists, distinguishing between\\nlists by using
      the style of their markers. The above now gets output as\\n\\n> 1.  First item\\n>\\n>
      - Nested list:\\n>\\n>   a.  alfa\\n>   b.  bravo\\n>   c.  charlie\\n>\\n>
      Which list will be continued?\\n>\\n> 2.  ???\\n\\nJust what we want. Happy
      list writing!\\n:::\\n\",\"relationships\":[],\"archive_url\":\"https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/list-continuation\",\"guid\":\"https://tarleb.com/posts/list-continuation/index.html\",\"updated\":false,\"category\":\"computerAndInformationSciences\"}]"
    headers:
      Access-Control-Allow-Origin:
      - '*'
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 849864662ec91638-DUS
      Connection:
      - keep-alive
      Content-Profile:
      - public
      Content-Range:
      - '*/*'
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Mon, 22 Jan 2024 14:12:29 GMT
      Preference-Applied:
      - resolution=merge-duplicates
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      Via:
      - kong/2.8.1
      X-Kong-Proxy-Latency:
      - '0'
      X-Kong-Upstream-Latency:
      - '7'
      alt-svc:
      - h3=":443"; ma=86400
      sb-gateway-version:
      - '1'
    http_version: HTTP/1.1
    status_code: 201
- request:
    body: '{"indexed": true}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      accept-profile:
      - public
      connection:
      - keep-alive
      content-length:
      - '17'
      content-profile:
      - public
      content-type:
      - application/json
      host:
      - db.rogue-scholar.org
      prefer:
      - return=representation
      user-agent:
      - python-httpx/0.25.2
      x-client-info:
      - supabase-py/2.3.4
    method: PATCH
    uri: https://db.rogue-scholar.org/rest/v1/posts?id=eq.4fb04d8c-7e8b-4597-a917-ebd71b2f2d35
  response:
    content: "[{\"url\":\"https://tarleb.com/posts/list-continuation\",\"title\":\"Auto-numbered
      list continuations\",\"summary\":\"Pandoc\u2019s Markdown allows for \u201Cfancy
      lists\u201D, i.e., lists with different styles used for the marker of ordered
      list items. E.g., the list (I)  primus (#)  secundus (#)  tertius  uses uppercase
      roman numerals and double parentheses for the markers. It gets rendered as primus
      secundus tertius Continuations   The fancy lists feature also allows to continue
      lists after an intermediate paragraph: i.   one #.   another Interruption;\\n\",\"image\":null,\"tags\":[\"Markdown\",\"Pandoc\",\"Filter\"],\"language\":\"en\",\"authors\":[{\"name\":
      \"Albert Krewinkel\"}],\"doi\":\"https://doi.org/10.59350/5kh1q-kv634\",\"id\":\"4fb04d8c-7e8b-4597-a917-ebd71b2f2d35\",\"reference\":[],\"updated_at\":1669593600,\"published_at\":1669593600,\"blog_name\":\"tarleb\",\"indexed_at\":1700476101,\"indexed\":true,\"images\":[],\"blog_slug\":\"tarleb\",\"content_text\":\"Pandoc's
      Markdown allows for \\\"fancy lists\\\", i.e., lists with different\\nstyles
      used for the marker of ordered list items.\\n\\nE.g., the list\\n\\n::: {#cb1
      .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n``` {.sourceCode .markdown
      .code-with-copy}\\n(I)  primus\\n(#)  secundus\\n(#)  tertius\\n```\\n:::\\n\\nuses
      uppercase roman numerals and double parentheses for the markers. It\\ngets rendered
      as\\n\\n> I.  primus\\n> II. secundus\\n> III. tertius\\n\\n::: {#continuations
      .section .level2}\\n## Continuations {#continuations .anchored anchor-id=\\\"continuations\\\"}\\n\\nThe
      fancy lists feature also allows to continue lists after an\\nintermediate paragraph:\\n\\n:::
      {#cb2 .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n``` {.sourceCode .markdown
      .code-with-copy}\\ni.   one\\n#.   another\\n\\nInterruption; not part of any
      list.\\n\\niii. continue\\n#.   keep counting\\n```\\n:::\\n\\nThis becomes\\n\\n>
      i.  one\\n> ii. another\\n>\\n> Interruption; not part of any list.\\n>\\n>
      iii. continue\\n> iv. keep counting\\n\\nWhile very convenient, this requires
      us to carefully keep book of the\\nnumber of items in previous parts, or risk
      the item numbering to become\\ninconsistent. Imagine having to find and update
      all other list parts\\nafter adding a single item somewhere. Tedious work, that
      gets tiresome\\nquickly.\\n:::\\n\\n::: {#convention .section .level2}\\n##
      Convention {#convention .anchored anchor-id=\\\"convention\\\"}\\n\\nWanting
      none of this, we magicked a method that allows us to mark a list\\nas a continuation.
      This way, we can search for those lists with a Lua\\nfilter and let pandoc do
      the counting and numbering for us.\\n\\nOur convention is this: any list that
      starts with a number of 90 or\\nabove is treated as the continuation of a previous
      list. Why 90? Because\\nit's large, but still easy to express using roman numerals,
      should one\\nbe inclined to use those.\\n\\n::: {#cb3 .sourceCode style=\\\"background:
      #f1f3f5;\\\"}\\n``` {.sourceCode .markdown .code-with-copy}\\ni.  primus\\nii.
      secundus\\n\\nLorem ipsum.\\n\\nxc. alius item\\n#.  ut custodians iens\\n```\\n:::\\n:::\\n\\n:::
      {#lua-doing-the-counting .section .level2}\\n## Lua doing the counting {#lua-doing-the-counting
      .anchored anchor-id=\\\"lua-doing-the-counting\\\"}\\n\\nThe next step is to
      let pandoc do the counting with the help of a Lua\\nfilter. In its simplest
      form, the filter will step through all ordered\\nlists in the document, remember
      the number of items it has encountered,\\nand renumber any list whose start
      is above our chosen threshold.\\n\\n::: {#cb4 .sourceCode style=\\\"background:
      #f1f3f5;\\\"}\\n``` {.sourceCode .lua .code-with-copy}\\nlocal next_start =
      1\\n\\nfunction OrderedList (ol)\\n  if ol.start >= 90 then\\n    ol.start =
      next_start\\n    next_start = next_start + #ol.content\\n  else\\n    next_start
      = #ol.content + 1\\n  end\\n  return ol\\nend\\n```\\n:::\\n\\nApplied to the
      example above, the filter produces the desired result:\\n\\n> i.  primus\\n>
      ii. secundus\\n>\\n> Lorem ipsum.\\n>\\n> iii. alius item\\n> iv. ut custodians
      iens\\n:::\\n\\n::: {#refinements .section .level2}\\n## Refinements {#refinements
      .anchored anchor-id=\\\"refinements\\\"}\\n\\nThis is fairly good already. But
      what happens if there are *other* lists\\nappearing in the intermediate blocks?\\n\\n
      \   1. First item\\n\\n    - Nested list:\\n\\n        a. alfa\\n        b.
      bravo\\n        c. charlie\\n\\n    Which list will be continued?\\n\\n    99.
      ???\\n\\nWith the current state of our filter, the last item will be numbered\\n`d.`,
      which is most likely not what we want. So let's make the filter\\nsensitive
      to the list style; only a list with the matching style will be\\ncontinued.\\n\\nThe
      style and delimiter of ordered list markers can be accessed via the\\nelement's
      `style` and `delimiter` property, respectively. We use those\\nvalues to construct
      a string key under which the start number of the\\nnext continuation is stored
      in table `next_starts`.\\n\\n::: {#cb6 .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n```
      {.sourceCode .lua .code-with-copy}\\nlocal next_starts = {}\\n\\nfunction OrderedList
      (ol)\\n  local key = ol.style .. '|' .. ol.delimiter\\n  if ol.start >= 90 then\\n
      \   ol.start = next_starts[key] or 1\\n    next_starts[key] = ol.start + #ol.content\\n
      \ else\\n    next_starts[key] = #ol.content + 1\\n  end\\n\\n  return ol\\nend\\n```\\n:::\\n\\nThis
      way we can keep track of multiple lists, distinguishing between\\nlists by using
      the style of their markers. The above now gets output as\\n\\n> 1.  First item\\n>\\n>
      - Nested list:\\n>\\n>   a.  alfa\\n>   b.  bravo\\n>   c.  charlie\\n>\\n>
      Which list will be continued?\\n>\\n> 2.  ???\\n\\nJust what we want. Happy
      list writing!\\n:::\\n\",\"relationships\":[],\"archive_url\":\"https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/list-continuation\",\"guid\":\"https://tarleb.com/posts/list-continuation/index.html\",\"updated\":false,\"category\":\"computerAndInformationSciences\"}]"
    headers:
      Access-Control-Allow-Origin:
      - '*'
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 84986466af531638-DUS
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Profile:
      - public
      Content-Range:
      - 0-0/*
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Mon, 22 Jan 2024 14:12:29 GMT
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      Via:
      - kong/2.8.1
      X-Kong-Proxy-Latency:
      - '0'
      X-Kong-Upstream-Latency:
      - '3'
      alt-svc:
      - h3=":443"; ma=86400
      sb-gateway-version:
      - '1'
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: '{"authors": [{"name": "Albert Krewinkel"}], "blog_name": "tarleb", "blog_slug":
      "tarleb", "content_text": "Line breaks usually have no semantic meaning within
      a Markdown\nparagraph. However, using line breaks to mark the end of a sentece
      can\nhelp with productivity for various reasons.^1^ Documents with one\nsentence
      per line are also called \"ventilated prose\", and the [Write the\n{Ascii}Docs](https://writetheasciidocs.netlify.app)
      website has a [good\narticle on that\ntopic](https://writetheasciidocs.netlify.app/ventilated-prose).\n\nA
      question came up in a Slack channel, asking whether it was possible to\nconvert
      existing Markdown docs to this style. Naturally, the answer is\n\"pandoc can
      do that\", but that isn''t obvious here.\n\nThe solution that I came up with
      is centered around pandoc''s *SoftBreak*\nAST element. Pandoc uses SoftBreak
      elements internally to mark the place\nwhere line breaks occured in the input,
      but only if those breaks should\nbe treated like spaces in most situations.
      The way to make those breaks\nvisible in the output is to call pandoc with `--wrap=preserve`
      -- only\nthen will a line break in the input result in a break in the output
      in\nthe same location.\n\n    $ printf ''Hello\\npandoc'' | pandoc --to=markdown\n    \u21d2
      Hello pandoc\n\n    $ printf ''Hello\\npandoc'' | pandoc --to=markdown --wrap=preserve\n    \u21d2
      Hello\n    \u21d2 pandoc\n\nWe are going to use SoftBreak for semantic line
      breaks, so the first\nstep is to get rid of the SoftBreak elements created during
      parsing. A\nLua filter can do so with\n\n::: {#cb2 .sourceCode style=\"background:
      #f1f3f5;\"}\n``` {.sourceCode .lua .code-with-copy}\nSoftBreak = function ()
      return pandoc.Space() end\n```\n:::\n\nThen we check for strings that end with
      a period and are followed by a\nspace. The space in such a combination is then
      turned into a SoftBreak.\n\n::: {#cb3 .sourceCode style=\"background: #f1f3f5;\"}\n```
      {.sourceCode .lua .code-with-copy}\nlocal function semantic_line_feeds (el)\n  local
      inlines = el.content\n  for i = 2, #inlines do\n    if inlines[i].t == ''Space''
      and\n       inlines[i-1].t == ''Str'' and\n       inlines[i-1].text:match ''%.$''
      then\n      inlines[i] = pandoc.SoftBreak()\n    end\n  end\n  return el\nend\n\nreturn
      {\n  -- remove soft breaks inserted during parsing.\n  {SoftBreak = function
      () return pandoc.Space() end},\n  -- insert semantic soft breaks\n  {Para =
      semantic_line_feeds, Plain = semantic_line_feeds},\n}\n```\n:::\n\nThis filter
      can then be combined with the `--wrap=preserve` option to\nget the desired semantic
      line breaks.\n\n::: {#cb4 .sourceCode style=\"background: #f1f3f5;\"}\n``` {.sourceCode
      .bash .code-with-copy}\nprintf ''This. And that.'' | pandoc -L semlf.lua --wrap=preserve\n\u21d2
      This.\n\u21d2 And that.\n```\n:::\n\nThere, mission accomplished.^2^\n\n:::
      {#quarto-appendix .default}\n::: {#footnotes .section .footnotes .footnotes-end-of-document}\n##
      Footnotes {#footnotes .anchored .quarto-appendix-heading}\n\n1.  ::: {#fn1}\n    It''s
      not my cup of tea, but I can see why people might like the\n    concept.\u21a9\ufe0e\n    :::\n\n2.  :::
      {#fn2}\n    There are some cases in which the filter does not give the correct\n    result,
      for example when using American-style punctuation after\n    quotes, or when
      a full sentence is emphasized. It should be possible\n    to fix the filter
      for these edge cases, but it doesn''t seem worth\n    the effort: the presented
      solution should work fine for 95\u00a0% of all\n    use cases.\u21a9\ufe0e\n    :::\n:::\n:::\n",
      "images": [], "updated_at": 1667088000, "published_at": 1667088000, "image":
      null, "language": "en", "category": "computerAndInformationSciences", "reference":
      [], "relationships": [], "summary": "Line breaks usually have no semantic meaning
      within a Markdown paragraph. However, using line breaks to mark the end of a
      sentece can help with productivity for various reasons.\n<sup>\n 1\n</sup>\nDocuments
      with one sentence per line are also called \u201cventilated prose\u201d, and
      the Write the {Ascii}Docs website has a good article on that topic.\n", "tags":
      ["Markdown", "Pandoc"], "title": "Semantic line breaks", "url": "https://tarleb.com/posts/semantic-line-breaks",
      "guid": "https://tarleb.com/posts/semantic-line-breaks/index.html", "archive_url":
      "https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/semantic-line-breaks"}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      accept-profile:
      - public
      connection:
      - keep-alive
      content-length:
      - '4403'
      content-profile:
      - public
      content-type:
      - application/json
      host:
      - db.rogue-scholar.org
      prefer:
      - return=representation,resolution=merge-duplicates
      user-agent:
      - python-httpx/0.25.2
      x-client-info:
      - supabase-py/2.3.4
    method: POST
    uri: https://db.rogue-scholar.org/rest/v1/posts?on_conflict=guid
  response:
    content: "[{\"url\":\"https://tarleb.com/posts/semantic-line-breaks\",\"title\":\"Semantic
      line breaks\",\"summary\":\"Line breaks usually have no semantic meaning within
      a Markdown paragraph. However, using line breaks to mark the end of a sentece
      can help with productivity for various reasons.\\n<sup>\\n 1\\n</sup>\\nDocuments
      with one sentence per line are also called \u201Cventilated prose\u201D, and
      the Write the {Ascii}Docs website has a good article on that topic.\\n\",\"image\":null,\"tags\":[\"Markdown\",\"Pandoc\"],\"language\":\"en\",\"authors\":[{\"name\":
      \"Albert Krewinkel\"}],\"doi\":\"https://doi.org/10.59350/8e6np-4ep92\",\"id\":\"7d384846-aee9-4cf2-a0df-9ebaa4d4f955\",\"reference\":[],\"updated_at\":1667088000,\"published_at\":1667088000,\"blog_name\":\"tarleb\",\"indexed_at\":1700476624,\"indexed\":true,\"images\":[],\"blog_slug\":\"tarleb\",\"content_text\":\"Line
      breaks usually have no semantic meaning within a Markdown\\nparagraph. However,
      using line breaks to mark the end of a sentece can\\nhelp with productivity
      for various reasons.^1^ Documents with one\\nsentence per line are also called
      \\\"ventilated prose\\\", and the [Write the\\n{Ascii}Docs](https://writetheasciidocs.netlify.app)
      website has a [good\\narticle on that\\ntopic](https://writetheasciidocs.netlify.app/ventilated-prose).\\n\\nA
      question came up in a Slack channel, asking whether it was possible to\\nconvert
      existing Markdown docs to this style. Naturally, the answer is\\n\\\"pandoc
      can do that\\\", but that isn't obvious here.\\n\\nThe solution that I came
      up with is centered around pandoc's *SoftBreak*\\nAST element. Pandoc uses SoftBreak
      elements internally to mark the place\\nwhere line breaks occured in the input,
      but only if those breaks should\\nbe treated like spaces in most situations.
      The way to make those breaks\\nvisible in the output is to call pandoc with
      `--wrap=preserve` -- only\\nthen will a line break in the input result in a
      break in the output in\\nthe same location.\\n\\n    $ printf 'Hello\\\\npandoc'
      | pandoc --to=markdown\\n    \u21D2 Hello pandoc\\n\\n    $ printf 'Hello\\\\npandoc'
      | pandoc --to=markdown --wrap=preserve\\n    \u21D2 Hello\\n    \u21D2 pandoc\\n\\nWe
      are going to use SoftBreak for semantic line breaks, so the first\\nstep is
      to get rid of the SoftBreak elements created during parsing. A\\nLua filter
      can do so with\\n\\n::: {#cb2 .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n```
      {.sourceCode .lua .code-with-copy}\\nSoftBreak = function () return pandoc.Space()
      end\\n```\\n:::\\n\\nThen we check for strings that end with a period and are
      followed by a\\nspace. The space in such a combination is then turned into a
      SoftBreak.\\n\\n::: {#cb3 .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n```
      {.sourceCode .lua .code-with-copy}\\nlocal function semantic_line_feeds (el)\\n
      \ local inlines = el.content\\n  for i = 2, #inlines do\\n    if inlines[i].t
      == 'Space' and\\n       inlines[i-1].t == 'Str' and\\n       inlines[i-1].text:match
      '%.$' then\\n      inlines[i] = pandoc.SoftBreak()\\n    end\\n  end\\n  return
      el\\nend\\n\\nreturn {\\n  -- remove soft breaks inserted during parsing.\\n
      \ {SoftBreak = function () return pandoc.Space() end},\\n  -- insert semantic
      soft breaks\\n  {Para = semantic_line_feeds, Plain = semantic_line_feeds},\\n}\\n```\\n:::\\n\\nThis
      filter can then be combined with the `--wrap=preserve` option to\\nget the desired
      semantic line breaks.\\n\\n::: {#cb4 .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n```
      {.sourceCode .bash .code-with-copy}\\nprintf 'This. And that.' | pandoc -L semlf.lua
      --wrap=preserve\\n\u21D2 This.\\n\u21D2 And that.\\n```\\n:::\\n\\nThere, mission
      accomplished.^2^\\n\\n::: {#quarto-appendix .default}\\n::: {#footnotes .section
      .footnotes .footnotes-end-of-document}\\n## Footnotes {#footnotes .anchored
      .quarto-appendix-heading}\\n\\n1.  ::: {#fn1}\\n    It's not my cup of tea,
      but I can see why people might like the\\n    concept.\u21A9\uFE0E\\n    :::\\n\\n2.
      \ ::: {#fn2}\\n    There are some cases in which the filter does not give the
      correct\\n    result, for example when using American-style punctuation after\\n
      \   quotes, or when a full sentence is emphasized. It should be possible\\n
      \   to fix the filter for these edge cases, but it doesn't seem worth\\n    the
      effort: the presented solution should work fine for 95\_% of all\\n    use cases.\u21A9\uFE0E\\n
      \   :::\\n:::\\n:::\\n\",\"relationships\":[],\"archive_url\":\"https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/semantic-line-breaks\",\"guid\":\"https://tarleb.com/posts/semantic-line-breaks/index.html\",\"updated\":false,\"category\":\"computerAndInformationSciences\"}]"
    headers:
      Access-Control-Allow-Origin:
      - '*'
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 849864671fe71638-DUS
      Connection:
      - keep-alive
      Content-Profile:
      - public
      Content-Range:
      - '*/*'
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Mon, 22 Jan 2024 14:12:29 GMT
      Preference-Applied:
      - resolution=merge-duplicates
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      Via:
      - kong/2.8.1
      X-Kong-Proxy-Latency:
      - '0'
      X-Kong-Upstream-Latency:
      - '6'
      alt-svc:
      - h3=":443"; ma=86400
      sb-gateway-version:
      - '1'
    http_version: HTTP/1.1
    status_code: 201
- request:
    body: '{"indexed": true}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      accept-profile:
      - public
      connection:
      - keep-alive
      content-length:
      - '17'
      content-profile:
      - public
      content-type:
      - application/json
      host:
      - db.rogue-scholar.org
      prefer:
      - return=representation
      user-agent:
      - python-httpx/0.25.2
      x-client-info:
      - supabase-py/2.3.4
    method: PATCH
    uri: https://db.rogue-scholar.org/rest/v1/posts?id=eq.7d384846-aee9-4cf2-a0df-9ebaa4d4f955
  response:
    content: "[{\"url\":\"https://tarleb.com/posts/semantic-line-breaks\",\"title\":\"Semantic
      line breaks\",\"summary\":\"Line breaks usually have no semantic meaning within
      a Markdown paragraph. However, using line breaks to mark the end of a sentece
      can help with productivity for various reasons.\\n<sup>\\n 1\\n</sup>\\nDocuments
      with one sentence per line are also called \u201Cventilated prose\u201D, and
      the Write the {Ascii}Docs website has a good article on that topic.\\n\",\"image\":null,\"tags\":[\"Markdown\",\"Pandoc\"],\"language\":\"en\",\"authors\":[{\"name\":
      \"Albert Krewinkel\"}],\"doi\":\"https://doi.org/10.59350/8e6np-4ep92\",\"id\":\"7d384846-aee9-4cf2-a0df-9ebaa4d4f955\",\"reference\":[],\"updated_at\":1667088000,\"published_at\":1667088000,\"blog_name\":\"tarleb\",\"indexed_at\":1700476624,\"indexed\":true,\"images\":[],\"blog_slug\":\"tarleb\",\"content_text\":\"Line
      breaks usually have no semantic meaning within a Markdown\\nparagraph. However,
      using line breaks to mark the end of a sentece can\\nhelp with productivity
      for various reasons.^1^ Documents with one\\nsentence per line are also called
      \\\"ventilated prose\\\", and the [Write the\\n{Ascii}Docs](https://writetheasciidocs.netlify.app)
      website has a [good\\narticle on that\\ntopic](https://writetheasciidocs.netlify.app/ventilated-prose).\\n\\nA
      question came up in a Slack channel, asking whether it was possible to\\nconvert
      existing Markdown docs to this style. Naturally, the answer is\\n\\\"pandoc
      can do that\\\", but that isn't obvious here.\\n\\nThe solution that I came
      up with is centered around pandoc's *SoftBreak*\\nAST element. Pandoc uses SoftBreak
      elements internally to mark the place\\nwhere line breaks occured in the input,
      but only if those breaks should\\nbe treated like spaces in most situations.
      The way to make those breaks\\nvisible in the output is to call pandoc with
      `--wrap=preserve` -- only\\nthen will a line break in the input result in a
      break in the output in\\nthe same location.\\n\\n    $ printf 'Hello\\\\npandoc'
      | pandoc --to=markdown\\n    \u21D2 Hello pandoc\\n\\n    $ printf 'Hello\\\\npandoc'
      | pandoc --to=markdown --wrap=preserve\\n    \u21D2 Hello\\n    \u21D2 pandoc\\n\\nWe
      are going to use SoftBreak for semantic line breaks, so the first\\nstep is
      to get rid of the SoftBreak elements created during parsing. A\\nLua filter
      can do so with\\n\\n::: {#cb2 .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n```
      {.sourceCode .lua .code-with-copy}\\nSoftBreak = function () return pandoc.Space()
      end\\n```\\n:::\\n\\nThen we check for strings that end with a period and are
      followed by a\\nspace. The space in such a combination is then turned into a
      SoftBreak.\\n\\n::: {#cb3 .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n```
      {.sourceCode .lua .code-with-copy}\\nlocal function semantic_line_feeds (el)\\n
      \ local inlines = el.content\\n  for i = 2, #inlines do\\n    if inlines[i].t
      == 'Space' and\\n       inlines[i-1].t == 'Str' and\\n       inlines[i-1].text:match
      '%.$' then\\n      inlines[i] = pandoc.SoftBreak()\\n    end\\n  end\\n  return
      el\\nend\\n\\nreturn {\\n  -- remove soft breaks inserted during parsing.\\n
      \ {SoftBreak = function () return pandoc.Space() end},\\n  -- insert semantic
      soft breaks\\n  {Para = semantic_line_feeds, Plain = semantic_line_feeds},\\n}\\n```\\n:::\\n\\nThis
      filter can then be combined with the `--wrap=preserve` option to\\nget the desired
      semantic line breaks.\\n\\n::: {#cb4 .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n```
      {.sourceCode .bash .code-with-copy}\\nprintf 'This. And that.' | pandoc -L semlf.lua
      --wrap=preserve\\n\u21D2 This.\\n\u21D2 And that.\\n```\\n:::\\n\\nThere, mission
      accomplished.^2^\\n\\n::: {#quarto-appendix .default}\\n::: {#footnotes .section
      .footnotes .footnotes-end-of-document}\\n## Footnotes {#footnotes .anchored
      .quarto-appendix-heading}\\n\\n1.  ::: {#fn1}\\n    It's not my cup of tea,
      but I can see why people might like the\\n    concept.\u21A9\uFE0E\\n    :::\\n\\n2.
      \ ::: {#fn2}\\n    There are some cases in which the filter does not give the
      correct\\n    result, for example when using American-style punctuation after\\n
      \   quotes, or when a full sentence is emphasized. It should be possible\\n
      \   to fix the filter for these edge cases, but it doesn't seem worth\\n    the
      effort: the presented solution should work fine for 95\_% of all\\n    use cases.\u21A9\uFE0E\\n
      \   :::\\n:::\\n:::\\n\",\"relationships\":[],\"archive_url\":\"https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/semantic-line-breaks\",\"guid\":\"https://tarleb.com/posts/semantic-line-breaks/index.html\",\"updated\":false,\"category\":\"computerAndInformationSciences\"}]"
    headers:
      Access-Control-Allow-Origin:
      - '*'
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 8498646788471638-DUS
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Profile:
      - public
      Content-Range:
      - 0-0/*
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Mon, 22 Jan 2024 14:12:30 GMT
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      Via:
      - kong/2.8.1
      X-Kong-Proxy-Latency:
      - '1'
      X-Kong-Upstream-Latency:
      - '4'
      alt-svc:
      - h3=":443"; ma=86400
      sb-gateway-version:
      - '1'
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: '{"authors": [{"name": "Albert Krewinkel"}], "blog_name": "tarleb", "blog_slug":
      "tarleb", "content_text": "When pandoc is used in larger pipelines, e.g.\u00a0in
      combination with\n[Sphinx](https://sphinx-doc.org), it can be useful to pack
      everything up\ninto one neat container. One option is to base the container
      on a pandoc\nimage like `pandoc/core`, but this may be difficult due to other\ndependencies.
      In this case, the easiest option is to do this:\n\n::: {#cb1 .sourceCode style=\"background:
      #f1f3f5;\"}\n``` {.sourceCode .dockerfile .code-with-copy}\nCOPY --from=pandoc/minimal:2.19.2
      /pandoc /usr/bin/pandoc\n```\n:::\n\nThe snippet, when added to a Dockerfile,
      copies a statically compiled\nexecutable from an official build to `/usr/bin/pandoc`.
      The static\npandoc binary can run on all Linux distributions, so it does not
      matter\nwhat distro the custom build is based on.\n\nThe documentation for the
      <https://hub.docker.com/r/pandoc/minimal> has\nmore info, including a list of
      supported versions (tags).\n", "images": [], "updated_at": 1662508800, "published_at":
      1662508800, "image": null, "language": "en", "category": "computerAndInformationSciences",
      "reference": [], "relationships": [], "summary": "When pandoc is used in larger
      pipelines, e.g.\u00a0in combination with Sphinx, it can be useful to pack everything
      up into one neat container. One option is to base the container on a pandoc
      image like pandoc/core, but this may be difficult due to other dependencies.\n",
      "tags": ["Pandoc", "Tip", "Docker"], "title": "Install pandoc in custom Docker
      images", "url": "https://tarleb.com/posts/tip-install-in-docker", "guid": "https://tarleb.com/posts/tip-install-in-docker/index.html",
      "archive_url": "https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/tip-install-in-docker"}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      accept-profile:
      - public
      connection:
      - keep-alive
      content-length:
      - '1822'
      content-profile:
      - public
      content-type:
      - application/json
      host:
      - db.rogue-scholar.org
      prefer:
      - return=representation,resolution=merge-duplicates
      user-agent:
      - python-httpx/0.25.2
      x-client-info:
      - supabase-py/2.3.4
    method: POST
    uri: https://db.rogue-scholar.org/rest/v1/posts?on_conflict=guid
  response:
    content: "[{\"url\":\"https://tarleb.com/posts/tip-install-in-docker\",\"title\":\"Install
      pandoc in custom Docker images\",\"summary\":\"When pandoc is used in larger
      pipelines, e.g.\_in combination with Sphinx, it can be useful to pack everything
      up into one neat container. One option is to base the container on a pandoc
      image like pandoc/core, but this may be difficult due to other dependencies.\\n\",\"image\":null,\"tags\":[\"Pandoc\",\"Tip\",\"Docker\"],\"language\":\"en\",\"authors\":[{\"name\":
      \"Albert Krewinkel\"}],\"doi\":\"https://doi.org/10.59350/39qcq-65b52\",\"id\":\"e848e36a-a036-4d6f-88ca-c8fa89d0c8c6\",\"reference\":[],\"updated_at\":1662508800,\"published_at\":1662508800,\"blog_name\":\"tarleb\",\"indexed_at\":1700478242,\"indexed\":true,\"images\":[],\"blog_slug\":\"tarleb\",\"content_text\":\"When
      pandoc is used in larger pipelines, e.g.\_in combination with\\n[Sphinx](https://sphinx-doc.org),
      it can be useful to pack everything up\\ninto one neat container. One option
      is to base the container on a pandoc\\nimage like `pandoc/core`, but this may
      be difficult due to other\\ndependencies. In this case, the easiest option is
      to do this:\\n\\n::: {#cb1 .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n```
      {.sourceCode .dockerfile .code-with-copy}\\nCOPY --from=pandoc/minimal:2.19.2
      /pandoc /usr/bin/pandoc\\n```\\n:::\\n\\nThe snippet, when added to a Dockerfile,
      copies a statically compiled\\nexecutable from an official build to `/usr/bin/pandoc`.
      The static\\npandoc binary can run on all Linux distributions, so it does not
      matter\\nwhat distro the custom build is based on.\\n\\nThe documentation for
      the <https://hub.docker.com/r/pandoc/minimal> has\\nmore info, including a list
      of supported versions (tags).\\n\",\"relationships\":[],\"archive_url\":\"https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/tip-install-in-docker\",\"guid\":\"https://tarleb.com/posts/tip-install-in-docker/index.html\",\"updated\":false,\"category\":\"computerAndInformationSciences\"}]"
    headers:
      Access-Control-Allow-Origin:
      - '*'
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 84986467f8af1638-DUS
      Connection:
      - keep-alive
      Content-Profile:
      - public
      Content-Range:
      - '*/*'
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Mon, 22 Jan 2024 14:12:30 GMT
      Preference-Applied:
      - resolution=merge-duplicates
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      Via:
      - kong/2.8.1
      X-Kong-Proxy-Latency:
      - '1'
      X-Kong-Upstream-Latency:
      - '4'
      alt-svc:
      - h3=":443"; ma=86400
      sb-gateway-version:
      - '1'
    http_version: HTTP/1.1
    status_code: 201
- request:
    body: '{"indexed": true}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      accept-profile:
      - public
      connection:
      - keep-alive
      content-length:
      - '17'
      content-profile:
      - public
      content-type:
      - application/json
      host:
      - db.rogue-scholar.org
      prefer:
      - return=representation
      user-agent:
      - python-httpx/0.25.2
      x-client-info:
      - supabase-py/2.3.4
    method: PATCH
    uri: https://db.rogue-scholar.org/rest/v1/posts?id=eq.e848e36a-a036-4d6f-88ca-c8fa89d0c8c6
  response:
    content: "[{\"url\":\"https://tarleb.com/posts/tip-install-in-docker\",\"title\":\"Install
      pandoc in custom Docker images\",\"summary\":\"When pandoc is used in larger
      pipelines, e.g.\_in combination with Sphinx, it can be useful to pack everything
      up into one neat container. One option is to base the container on a pandoc
      image like pandoc/core, but this may be difficult due to other dependencies.\\n\",\"image\":null,\"tags\":[\"Pandoc\",\"Tip\",\"Docker\"],\"language\":\"en\",\"authors\":[{\"name\":
      \"Albert Krewinkel\"}],\"doi\":\"https://doi.org/10.59350/39qcq-65b52\",\"id\":\"e848e36a-a036-4d6f-88ca-c8fa89d0c8c6\",\"reference\":[],\"updated_at\":1662508800,\"published_at\":1662508800,\"blog_name\":\"tarleb\",\"indexed_at\":1700478242,\"indexed\":true,\"images\":[],\"blog_slug\":\"tarleb\",\"content_text\":\"When
      pandoc is used in larger pipelines, e.g.\_in combination with\\n[Sphinx](https://sphinx-doc.org),
      it can be useful to pack everything up\\ninto one neat container. One option
      is to base the container on a pandoc\\nimage like `pandoc/core`, but this may
      be difficult due to other\\ndependencies. In this case, the easiest option is
      to do this:\\n\\n::: {#cb1 .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n```
      {.sourceCode .dockerfile .code-with-copy}\\nCOPY --from=pandoc/minimal:2.19.2
      /pandoc /usr/bin/pandoc\\n```\\n:::\\n\\nThe snippet, when added to a Dockerfile,
      copies a statically compiled\\nexecutable from an official build to `/usr/bin/pandoc`.
      The static\\npandoc binary can run on all Linux distributions, so it does not
      matter\\nwhat distro the custom build is based on.\\n\\nThe documentation for
      the <https://hub.docker.com/r/pandoc/minimal> has\\nmore info, including a list
      of supported versions (tags).\\n\",\"relationships\":[],\"archive_url\":\"https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/tip-install-in-docker\",\"guid\":\"https://tarleb.com/posts/tip-install-in-docker/index.html\",\"updated\":false,\"category\":\"computerAndInformationSciences\"}]"
    headers:
      Access-Control-Allow-Origin:
      - '*'
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 84986468690d1638-DUS
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Profile:
      - public
      Content-Range:
      - 0-0/*
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Mon, 22 Jan 2024 14:12:30 GMT
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      Via:
      - kong/2.8.1
      X-Kong-Proxy-Latency:
      - '0'
      X-Kong-Upstream-Latency:
      - '4'
      alt-svc:
      - h3=":443"; ma=86400
      sb-gateway-version:
      - '1'
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: '{"authors": [{"name": "Albert Krewinkel"}], "blog_name": "tarleb", "blog_slug":
      "tarleb", "content_text": "Setting the document font this way works for ConTeXt,
      LaTeX, and HTML\noutput. The fonts used in docx or odt output must be controlled
      with the\nreference document instead.\n\nThe default LaTeX engine is pdflatex,
      which only supports TeX''s own font\nformat and cannot use the TrueType or OpenType
      fonts installed on the\nsystem. However, XeLaTeX was written with that in mind;
      switching to\nthat engine allows to specify any font available on the system.\n\nA
      good source for free fonts is the [Google\nFonts](https://fonts.google.com)
      repository.\n", "images": [], "updated_at": 1662508800, "published_at": 1662508800,
      "image": "https://tarleb.com/images/pandoc-logo.png", "language": "en", "category":
      "computerAndInformationSciences", "reference": [], "relationships": [], "summary":
      "Setting the document font this way works for ConTeXt, LaTeX, and HTML output.
      The fonts used in docx or odt output must be controlled with the reference document
      instead. The default LaTeX engine is pdflatex, which only supports TeX\u2019s
      own font format and cannot use the TrueType or OpenType fonts installed on the
      system. However, XeLaTeX was written with that in mind; switching to that engine
      allows to specify any font available on the system.\n", "tags": ["Pandoc", "Tip",
      "PDF", "HTML"], "title": "Document font", "url": "https://tarleb.com/posts/tip-document-font",
      "guid": "https://tarleb.com/posts/tip-document-font/index.html", "archive_url":
      "https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/tip-document-font"}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      accept-profile:
      - public
      connection:
      - keep-alive
      content-length:
      - '1649'
      content-profile:
      - public
      content-type:
      - application/json
      host:
      - db.rogue-scholar.org
      prefer:
      - return=representation,resolution=merge-duplicates
      user-agent:
      - python-httpx/0.25.2
      x-client-info:
      - supabase-py/2.3.4
    method: POST
    uri: https://db.rogue-scholar.org/rest/v1/posts?on_conflict=guid
  response:
    content: "[{\"url\":\"https://tarleb.com/posts/tip-document-font\",\"title\":\"Document
      font\",\"summary\":\"Setting the document font this way works for ConTeXt, LaTeX,
      and HTML output. The fonts used in docx or odt output must be controlled with
      the reference document instead. The default LaTeX engine is pdflatex, which
      only supports TeX\u2019s own font format and cannot use the TrueType or OpenType
      fonts installed on the system. However, XeLaTeX was written with that in mind;
      switching to that engine allows to specify any font available on the system.\\n\",\"image\":\"https://tarleb.com/images/pandoc-logo.png\",\"tags\":[\"Pandoc\",\"Tip\",\"PDF\",\"HTML\"],\"language\":\"en\",\"authors\":[{\"name\":
      \"Albert Krewinkel\"}],\"doi\":\"https://doi.org/10.59350/wrx9v-s4w60\",\"id\":\"08423165-ffe1-47a4-a2d8-e902a6d82bcc\",\"reference\":[],\"updated_at\":1662508800,\"published_at\":1662508800,\"blog_name\":\"tarleb\",\"indexed_at\":1700477071,\"indexed\":true,\"images\":[],\"blog_slug\":\"tarleb\",\"content_text\":\"Setting
      the document font this way works for ConTeXt, LaTeX, and HTML\\noutput. The
      fonts used in docx or odt output must be controlled with the\\nreference document
      instead.\\n\\nThe default LaTeX engine is pdflatex, which only supports TeX's
      own font\\nformat and cannot use the TrueType or OpenType fonts installed on
      the\\nsystem. However, XeLaTeX was written with that in mind; switching to\\nthat
      engine allows to specify any font available on the system.\\n\\nA good source
      for free fonts is the [Google\\nFonts](https://fonts.google.com) repository.\\n\",\"relationships\":[],\"archive_url\":\"https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/tip-document-font\",\"guid\":\"https://tarleb.com/posts/tip-document-font/index.html\",\"updated\":false,\"category\":\"computerAndInformationSciences\"}]"
    headers:
      Access-Control-Allow-Origin:
      - '*'
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 84986468c9981638-DUS
      Connection:
      - keep-alive
      Content-Profile:
      - public
      Content-Range:
      - '*/*'
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Mon, 22 Jan 2024 14:12:30 GMT
      Preference-Applied:
      - resolution=merge-duplicates
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      Via:
      - kong/2.8.1
      X-Kong-Proxy-Latency:
      - '0'
      X-Kong-Upstream-Latency:
      - '4'
      alt-svc:
      - h3=":443"; ma=86400
      sb-gateway-version:
      - '1'
    http_version: HTTP/1.1
    status_code: 201
- request:
    body: '{"indexed": true}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      accept-profile:
      - public
      connection:
      - keep-alive
      content-length:
      - '17'
      content-profile:
      - public
      content-type:
      - application/json
      host:
      - db.rogue-scholar.org
      prefer:
      - return=representation
      user-agent:
      - python-httpx/0.25.2
      x-client-info:
      - supabase-py/2.3.4
    method: PATCH
    uri: https://db.rogue-scholar.org/rest/v1/posts?id=eq.08423165-ffe1-47a4-a2d8-e902a6d82bcc
  response:
    content: "[{\"url\":\"https://tarleb.com/posts/tip-document-font\",\"title\":\"Document
      font\",\"summary\":\"Setting the document font this way works for ConTeXt, LaTeX,
      and HTML output. The fonts used in docx or odt output must be controlled with
      the reference document instead. The default LaTeX engine is pdflatex, which
      only supports TeX\u2019s own font format and cannot use the TrueType or OpenType
      fonts installed on the system. However, XeLaTeX was written with that in mind;
      switching to that engine allows to specify any font available on the system.\\n\",\"image\":\"https://tarleb.com/images/pandoc-logo.png\",\"tags\":[\"Pandoc\",\"Tip\",\"PDF\",\"HTML\"],\"language\":\"en\",\"authors\":[{\"name\":
      \"Albert Krewinkel\"}],\"doi\":\"https://doi.org/10.59350/wrx9v-s4w60\",\"id\":\"08423165-ffe1-47a4-a2d8-e902a6d82bcc\",\"reference\":[],\"updated_at\":1662508800,\"published_at\":1662508800,\"blog_name\":\"tarleb\",\"indexed_at\":1700477071,\"indexed\":true,\"images\":[],\"blog_slug\":\"tarleb\",\"content_text\":\"Setting
      the document font this way works for ConTeXt, LaTeX, and HTML\\noutput. The
      fonts used in docx or odt output must be controlled with the\\nreference document
      instead.\\n\\nThe default LaTeX engine is pdflatex, which only supports TeX's
      own font\\nformat and cannot use the TrueType or OpenType fonts installed on
      the\\nsystem. However, XeLaTeX was written with that in mind; switching to\\nthat
      engine allows to specify any font available on the system.\\n\\nA good source
      for free fonts is the [Google\\nFonts](https://fonts.google.com) repository.\\n\",\"relationships\":[],\"archive_url\":\"https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/tip-document-font\",\"guid\":\"https://tarleb.com/posts/tip-document-font/index.html\",\"updated\":false,\"category\":\"computerAndInformationSciences\"}]"
    headers:
      Access-Control-Allow-Origin:
      - '*'
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 849864693a341638-DUS
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Profile:
      - public
      Content-Range:
      - 0-0/*
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Mon, 22 Jan 2024 14:12:30 GMT
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      Via:
      - kong/2.8.1
      X-Kong-Proxy-Latency:
      - '0'
      X-Kong-Upstream-Latency:
      - '3'
      alt-svc:
      - h3=":443"; ma=86400
      sb-gateway-version:
      - '1'
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: '{"authors": [{"name": "Albert Krewinkel"}], "blog_name": "tarleb", "blog_slug":
      "tarleb", "content_text": "When extending pandoc (or Quarto) with Lua filters,
      we interact with\nso-called Lua userdata objects. These objects are used to
      wrap document\nAST elements, making them accessible from Lua scripts. They mostly\nbehave
      like normal Lua tables. This post is intended as a quick\noverview, listing
      interesting properties of userdata objects.\n\n::: {#userdata-objects .section
      .level2}\n## Userdata objects {#userdata-objects .anchored anchor-id=\"userdata-objects\"}\n\nHaskell-generated
      userdata objects have three main components: a type\n*name*, *properties*, and
      *methods*:\n\n::: {#type-name .section .level3}\n### Type name {#type-name .anchored
      anchor-id=\"type-name\"}\n\nThe *name* can be retrieved with `pandoc.utils.type`.
      It should be\ntreated as a read-only constant. Internally, the *name* is used
      as a\ntype tag, which is important when retrieving an object from a Lua script\nback
      into the main program. It is possible to access the name through\nthe debug
      interface, e.g.,\n\n::: {#cb1 .sourceCode style=\"background: #f1f3f5;\"}\n```
      {.sourceCode .lua .code-with-copy}\nfunction typename (x)\n  return debug.getmetatable(x).__name\nend\n```\n:::\n\nThe
      above `typename` function is actually a bit faster than\n`pandoc.utils.type`.
      It can improve performance when accessing this info\nin a tight loop, but its
      use is not recommended.\n:::\n\n::: {#properties .section .level3}\n### Properties
      {#properties .anchored anchor-id=\"properties\"}\n\n*Properties*, e.g., the
      `content` fields of *Para* elements, are \"lazy\":\nthe property value is marshaled
      to Lua when the property is accessed for\nthe first time. We are usually interested
      in no more than one or two\nelement properties, so this is a big performance
      improvement for most\nscripts. Lazy properties are especially useful with large
      objects like\n*Pandoc*, which would otherwise take a long time to marshal and\nunmarshal
      with all their child elements.\n\nHowever, this lazy marshaling is slower if
      all properties will be\naccessed anyway. If there are performance issues due
      to lazy properties,\nthen please let me know, and I''ll try to find a fix.\n:::\n\n:::
      {#methods .section .level3}\n### Methods {#methods .anchored anchor-id=\"methods\"}\n\n*Methods*
      are wrapped Haskell functions: when calling a method, the\narguments are unmarshaled
      back into Haskell objects, which are then\npassed to the wrapped function and
      processed in Haskell. The\ncomputation''s result is then pushed back to Lua.\n\nThis
      may sound weirdly complicated. While *it is* slow for very simple\nfunctions
      (like `pandoc.utils.type`), it''s very fast and convenient for\ncomplex methods
      like `Pandoc:walk`: objects with lazy properties are\nfast to unmarshal, the
      main Haskell code is fast, and it frees us from\nhaving to re-implement Haskell
      algorithms in Lua.\n:::\n\n::: {#iterating .section .level3}\n### Iterating
      {#iterating .anchored anchor-id=\"iterating\"}\n\nThe properties and methods
      are listed when iterating with `pairs`. The\niteration order is defined at compile
      time, with properties listed\nfirst, followed by methods. We usually try to
      keep each of these lists\nsorted alphabetically, but there may be exceptions.\n\nCalling
      `pairs` on a Haskell userdata object will always succeed, even\nif it has neither
      methods nor properties; the result will be the empty\niterator in that case.\n:::\n\n:::
      {#aliases .section .level3}\n### Aliases {#aliases .anchored anchor-id=\"aliases\"}\n\nSome
      objects also have property aliases: E.g., `div.classes` is really\njust an alias
      for `div.attr.classes`. Both entries point to the same\nlist object. Aliases
      are not included in the iterator generated by\n`pairs`. See the internals on
      how to get a hold of them.\n:::\n\n::: {#list-behavior .section .level3}\n###
      List behavior {#list-behavior .anchored anchor-id=\"list-behavior\"}\n\nUserdata
      objects can be made to behave like lists, but iterating over\nthose \"lists\"
      is comparatively slow. That''s why the only object that\nuses this feature is
      `PANDOC_VERSION`: for example, we can write\n`PANDOC_VERSION[2] >= 19` to check
      *just* the major version.^1^\n:::\n\n::: {#internals .section .level3}\n###
      Internals {#internals .anchored anchor-id=\"internals\"}\n\nEach type has a
      metatable, which defines its behavior. Most users should\nnot need to access
      the metatable, so the `getmetatable` function returns\n`true` instead of the
      actual metatable when called on a Haskell userdata\nobject. As we''ve seen with
      type names, It''s still possible to inspect\nthe userdata metatable with the
      help of `debug.getmetatable`.\n\nThe metatable has four interesting fields:
      `methods`, `aliases`,\n`getters`, and `setters`. The fields contain just what
      you''d expect.\n\nE.g., we can inspect the list of aliases defined for Inline
      objects with\n\n::: {#cb2 .sourceCode style=\"background: #f1f3f5;\"}\n``` {.sourceCode
      .lua .code-with-copy}\nlocal InlineMT = debug.getmetatable(pandoc.Str '''')\nfor
      name, keys in pairs(InlineMT.aliases) do\n  -- print the alias name and the
      alias value\n  print(name, ''is an alias for'', table.concat(keys, ''.''))\nend\n```\n:::\n\nDo
      not rely on the internal structure, and do not modify the metatable.\nHere be
      dragons.\n:::\n:::\n\n::: {#quarto-appendix .default}\n::: {#footnotes .section
      .footnotes .footnotes-end-of-document}\n## Footnotes {#footnotes .anchored .quarto-appendix-heading}\n\n1.  :::
      {#fn1}\n    This feature exists only to ensure backwards compatibility. It is\n    better
      to do comparisons in like `PANDOC_VERSION >= ''2.19''`\n    instead.\u21a9\ufe0e\n    :::\n:::\n:::\n",
      "images": [], "updated_at": 1662508800, "published_at": 1662508800, "image":
      null, "language": "en", "category": "computerAndInformationSciences", "reference":
      [], "relationships": [], "summary": "When extending pandoc (or Quarto) with
      Lua filters, we interact with so-called Lua userdata objects. These objects
      are used to wrap document AST elements, making them accessible from Lua scripts.
      They mostly behave like normal Lua tables. This post is intended as a quick
      overview, listing interesting properties of userdata objects.\n", "tags": ["Haskell",
      "Lua", "Pandoc", "Quarto"], "title": "Haskell usedata objects", "url": "https://tarleb.com/posts/haskell-lua-objects",
      "guid": "https://tarleb.com/posts/haskell-lua-objects/index.html", "archive_url":
      "https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/haskell-lua-objects"}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      accept-profile:
      - public
      connection:
      - keep-alive
      content-length:
      - '6538'
      content-profile:
      - public
      content-type:
      - application/json
      host:
      - db.rogue-scholar.org
      prefer:
      - return=representation,resolution=merge-duplicates
      user-agent:
      - python-httpx/0.25.2
      x-client-info:
      - supabase-py/2.3.4
    method: POST
    uri: https://db.rogue-scholar.org/rest/v1/posts?on_conflict=guid
  response:
    content: "[{\"url\":\"https://tarleb.com/posts/haskell-lua-objects\",\"title\":\"Haskell
      usedata objects\",\"summary\":\"When extending pandoc (or Quarto) with Lua filters,
      we interact with so-called Lua userdata objects. These objects are used to wrap
      document AST elements, making them accessible from Lua scripts. They mostly
      behave like normal Lua tables. This post is intended as a quick overview, listing
      interesting properties of userdata objects.\\n\",\"image\":null,\"tags\":[\"Haskell\",\"Lua\",\"Pandoc\",\"Quarto\"],\"language\":\"en\",\"authors\":[{\"name\":
      \"Albert Krewinkel\"}],\"doi\":\"https://doi.org/10.59350/21yba-wsc17\",\"id\":\"b5e8c157-247d-4901-ad08-7c752c554db4\",\"reference\":[],\"updated_at\":1662508800,\"published_at\":1662508800,\"blog_name\":\"tarleb\",\"indexed_at\":1700477578,\"indexed\":true,\"images\":[],\"blog_slug\":\"tarleb\",\"content_text\":\"When
      extending pandoc (or Quarto) with Lua filters, we interact with\\nso-called
      Lua userdata objects. These objects are used to wrap document\\nAST elements,
      making them accessible from Lua scripts. They mostly\\nbehave like normal Lua
      tables. This post is intended as a quick\\noverview, listing interesting properties
      of userdata objects.\\n\\n::: {#userdata-objects .section .level2}\\n## Userdata
      objects {#userdata-objects .anchored anchor-id=\\\"userdata-objects\\\"}\\n\\nHaskell-generated
      userdata objects have three main components: a type\\n*name*, *properties*,
      and *methods*:\\n\\n::: {#type-name .section .level3}\\n### Type name {#type-name
      .anchored anchor-id=\\\"type-name\\\"}\\n\\nThe *name* can be retrieved with
      `pandoc.utils.type`. It should be\\ntreated as a read-only constant. Internally,
      the *name* is used as a\\ntype tag, which is important when retrieving an object
      from a Lua script\\nback into the main program. It is possible to access the
      name through\\nthe debug interface, e.g.,\\n\\n::: {#cb1 .sourceCode style=\\\"background:
      #f1f3f5;\\\"}\\n``` {.sourceCode .lua .code-with-copy}\\nfunction typename (x)\\n
      \ return debug.getmetatable(x).__name\\nend\\n```\\n:::\\n\\nThe above `typename`
      function is actually a bit faster than\\n`pandoc.utils.type`. It can improve
      performance when accessing this info\\nin a tight loop, but its use is not recommended.\\n:::\\n\\n:::
      {#properties .section .level3}\\n### Properties {#properties .anchored anchor-id=\\\"properties\\\"}\\n\\n*Properties*,
      e.g., the `content` fields of *Para* elements, are \\\"lazy\\\":\\nthe property
      value is marshaled to Lua when the property is accessed for\\nthe first time.
      We are usually interested in no more than one or two\\nelement properties, so
      this is a big performance improvement for most\\nscripts. Lazy properties are
      especially useful with large objects like\\n*Pandoc*, which would otherwise
      take a long time to marshal and\\nunmarshal with all their child elements.\\n\\nHowever,
      this lazy marshaling is slower if all properties will be\\naccessed anyway.
      If there are performance issues due to lazy properties,\\nthen please let me
      know, and I'll try to find a fix.\\n:::\\n\\n::: {#methods .section .level3}\\n###
      Methods {#methods .anchored anchor-id=\\\"methods\\\"}\\n\\n*Methods* are wrapped
      Haskell functions: when calling a method, the\\narguments are unmarshaled back
      into Haskell objects, which are then\\npassed to the wrapped function and processed
      in Haskell. The\\ncomputation's result is then pushed back to Lua.\\n\\nThis
      may sound weirdly complicated. While *it is* slow for very simple\\nfunctions
      (like `pandoc.utils.type`), it's very fast and convenient for\\ncomplex methods
      like `Pandoc:walk`: objects with lazy properties are\\nfast to unmarshal, the
      main Haskell code is fast, and it frees us from\\nhaving to re-implement Haskell
      algorithms in Lua.\\n:::\\n\\n::: {#iterating .section .level3}\\n### Iterating
      {#iterating .anchored anchor-id=\\\"iterating\\\"}\\n\\nThe properties and methods
      are listed when iterating with `pairs`. The\\niteration order is defined at
      compile time, with properties listed\\nfirst, followed by methods. We usually
      try to keep each of these lists\\nsorted alphabetically, but there may be exceptions.\\n\\nCalling
      `pairs` on a Haskell userdata object will always succeed, even\\nif it has neither
      methods nor properties; the result will be the empty\\niterator in that case.\\n:::\\n\\n:::
      {#aliases .section .level3}\\n### Aliases {#aliases .anchored anchor-id=\\\"aliases\\\"}\\n\\nSome
      objects also have property aliases: E.g., `div.classes` is really\\njust an
      alias for `div.attr.classes`. Both entries point to the same\\nlist object.
      Aliases are not included in the iterator generated by\\n`pairs`. See the internals
      on how to get a hold of them.\\n:::\\n\\n::: {#list-behavior .section .level3}\\n###
      List behavior {#list-behavior .anchored anchor-id=\\\"list-behavior\\\"}\\n\\nUserdata
      objects can be made to behave like lists, but iterating over\\nthose \\\"lists\\\"
      is comparatively slow. That's why the only object that\\nuses this feature is
      `PANDOC_VERSION`: for example, we can write\\n`PANDOC_VERSION[2] >= 19` to check
      *just* the major version.^1^\\n:::\\n\\n::: {#internals .section .level3}\\n###
      Internals {#internals .anchored anchor-id=\\\"internals\\\"}\\n\\nEach type
      has a metatable, which defines its behavior. Most users should\\nnot need to
      access the metatable, so the `getmetatable` function returns\\n`true` instead
      of the actual metatable when called on a Haskell userdata\\nobject. As we've
      seen with type names, It's still possible to inspect\\nthe userdata metatable
      with the help of `debug.getmetatable`.\\n\\nThe metatable has four interesting
      fields: `methods`, `aliases`,\\n`getters`, and `setters`. The fields contain
      just what you'd expect.\\n\\nE.g., we can inspect the list of aliases defined
      for Inline objects with\\n\\n::: {#cb2 .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n```
      {.sourceCode .lua .code-with-copy}\\nlocal InlineMT = debug.getmetatable(pandoc.Str
      '')\\nfor name, keys in pairs(InlineMT.aliases) do\\n  -- print the alias name
      and the alias value\\n  print(name, 'is an alias for', table.concat(keys, '.'))\\nend\\n```\\n:::\\n\\nDo
      not rely on the internal structure, and do not modify the metatable.\\nHere
      be dragons.\\n:::\\n:::\\n\\n::: {#quarto-appendix .default}\\n::: {#footnotes
      .section .footnotes .footnotes-end-of-document}\\n## Footnotes {#footnotes .anchored
      .quarto-appendix-heading}\\n\\n1.  ::: {#fn1}\\n    This feature exists only
      to ensure backwards compatibility. It is\\n    better to do comparisons in like
      `PANDOC_VERSION >= '2.19'`\\n    instead.\u21A9\uFE0E\\n    :::\\n:::\\n:::\\n\",\"relationships\":[],\"archive_url\":\"https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/haskell-lua-objects\",\"guid\":\"https://tarleb.com/posts/haskell-lua-objects/index.html\",\"updated\":false,\"category\":\"computerAndInformationSciences\"}]"
    headers:
      Access-Control-Allow-Origin:
      - '*'
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 84986469bae71638-DUS
      Connection:
      - keep-alive
      Content-Profile:
      - public
      Content-Range:
      - '*/*'
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Mon, 22 Jan 2024 14:12:30 GMT
      Preference-Applied:
      - resolution=merge-duplicates
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      Via:
      - kong/2.8.1
      X-Kong-Proxy-Latency:
      - '1'
      X-Kong-Upstream-Latency:
      - '3'
      alt-svc:
      - h3=":443"; ma=86400
      sb-gateway-version:
      - '1'
    http_version: HTTP/1.1
    status_code: 201
- request:
    body: '{"indexed": true}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      accept-profile:
      - public
      connection:
      - keep-alive
      content-length:
      - '17'
      content-profile:
      - public
      content-type:
      - application/json
      host:
      - db.rogue-scholar.org
      prefer:
      - return=representation
      user-agent:
      - python-httpx/0.25.2
      x-client-info:
      - supabase-py/2.3.4
    method: PATCH
    uri: https://db.rogue-scholar.org/rest/v1/posts?id=eq.b5e8c157-247d-4901-ad08-7c752c554db4
  response:
    content: "[{\"url\":\"https://tarleb.com/posts/haskell-lua-objects\",\"title\":\"Haskell
      usedata objects\",\"summary\":\"When extending pandoc (or Quarto) with Lua filters,
      we interact with so-called Lua userdata objects. These objects are used to wrap
      document AST elements, making them accessible from Lua scripts. They mostly
      behave like normal Lua tables. This post is intended as a quick overview, listing
      interesting properties of userdata objects.\\n\",\"image\":null,\"tags\":[\"Haskell\",\"Lua\",\"Pandoc\",\"Quarto\"],\"language\":\"en\",\"authors\":[{\"name\":
      \"Albert Krewinkel\"}],\"doi\":\"https://doi.org/10.59350/21yba-wsc17\",\"id\":\"b5e8c157-247d-4901-ad08-7c752c554db4\",\"reference\":[],\"updated_at\":1662508800,\"published_at\":1662508800,\"blog_name\":\"tarleb\",\"indexed_at\":1700477578,\"indexed\":true,\"images\":[],\"blog_slug\":\"tarleb\",\"content_text\":\"When
      extending pandoc (or Quarto) with Lua filters, we interact with\\nso-called
      Lua userdata objects. These objects are used to wrap document\\nAST elements,
      making them accessible from Lua scripts. They mostly\\nbehave like normal Lua
      tables. This post is intended as a quick\\noverview, listing interesting properties
      of userdata objects.\\n\\n::: {#userdata-objects .section .level2}\\n## Userdata
      objects {#userdata-objects .anchored anchor-id=\\\"userdata-objects\\\"}\\n\\nHaskell-generated
      userdata objects have three main components: a type\\n*name*, *properties*,
      and *methods*:\\n\\n::: {#type-name .section .level3}\\n### Type name {#type-name
      .anchored anchor-id=\\\"type-name\\\"}\\n\\nThe *name* can be retrieved with
      `pandoc.utils.type`. It should be\\ntreated as a read-only constant. Internally,
      the *name* is used as a\\ntype tag, which is important when retrieving an object
      from a Lua script\\nback into the main program. It is possible to access the
      name through\\nthe debug interface, e.g.,\\n\\n::: {#cb1 .sourceCode style=\\\"background:
      #f1f3f5;\\\"}\\n``` {.sourceCode .lua .code-with-copy}\\nfunction typename (x)\\n
      \ return debug.getmetatable(x).__name\\nend\\n```\\n:::\\n\\nThe above `typename`
      function is actually a bit faster than\\n`pandoc.utils.type`. It can improve
      performance when accessing this info\\nin a tight loop, but its use is not recommended.\\n:::\\n\\n:::
      {#properties .section .level3}\\n### Properties {#properties .anchored anchor-id=\\\"properties\\\"}\\n\\n*Properties*,
      e.g., the `content` fields of *Para* elements, are \\\"lazy\\\":\\nthe property
      value is marshaled to Lua when the property is accessed for\\nthe first time.
      We are usually interested in no more than one or two\\nelement properties, so
      this is a big performance improvement for most\\nscripts. Lazy properties are
      especially useful with large objects like\\n*Pandoc*, which would otherwise
      take a long time to marshal and\\nunmarshal with all their child elements.\\n\\nHowever,
      this lazy marshaling is slower if all properties will be\\naccessed anyway.
      If there are performance issues due to lazy properties,\\nthen please let me
      know, and I'll try to find a fix.\\n:::\\n\\n::: {#methods .section .level3}\\n###
      Methods {#methods .anchored anchor-id=\\\"methods\\\"}\\n\\n*Methods* are wrapped
      Haskell functions: when calling a method, the\\narguments are unmarshaled back
      into Haskell objects, which are then\\npassed to the wrapped function and processed
      in Haskell. The\\ncomputation's result is then pushed back to Lua.\\n\\nThis
      may sound weirdly complicated. While *it is* slow for very simple\\nfunctions
      (like `pandoc.utils.type`), it's very fast and convenient for\\ncomplex methods
      like `Pandoc:walk`: objects with lazy properties are\\nfast to unmarshal, the
      main Haskell code is fast, and it frees us from\\nhaving to re-implement Haskell
      algorithms in Lua.\\n:::\\n\\n::: {#iterating .section .level3}\\n### Iterating
      {#iterating .anchored anchor-id=\\\"iterating\\\"}\\n\\nThe properties and methods
      are listed when iterating with `pairs`. The\\niteration order is defined at
      compile time, with properties listed\\nfirst, followed by methods. We usually
      try to keep each of these lists\\nsorted alphabetically, but there may be exceptions.\\n\\nCalling
      `pairs` on a Haskell userdata object will always succeed, even\\nif it has neither
      methods nor properties; the result will be the empty\\niterator in that case.\\n:::\\n\\n:::
      {#aliases .section .level3}\\n### Aliases {#aliases .anchored anchor-id=\\\"aliases\\\"}\\n\\nSome
      objects also have property aliases: E.g., `div.classes` is really\\njust an
      alias for `div.attr.classes`. Both entries point to the same\\nlist object.
      Aliases are not included in the iterator generated by\\n`pairs`. See the internals
      on how to get a hold of them.\\n:::\\n\\n::: {#list-behavior .section .level3}\\n###
      List behavior {#list-behavior .anchored anchor-id=\\\"list-behavior\\\"}\\n\\nUserdata
      objects can be made to behave like lists, but iterating over\\nthose \\\"lists\\\"
      is comparatively slow. That's why the only object that\\nuses this feature is
      `PANDOC_VERSION`: for example, we can write\\n`PANDOC_VERSION[2] >= 19` to check
      *just* the major version.^1^\\n:::\\n\\n::: {#internals .section .level3}\\n###
      Internals {#internals .anchored anchor-id=\\\"internals\\\"}\\n\\nEach type
      has a metatable, which defines its behavior. Most users should\\nnot need to
      access the metatable, so the `getmetatable` function returns\\n`true` instead
      of the actual metatable when called on a Haskell userdata\\nobject. As we've
      seen with type names, It's still possible to inspect\\nthe userdata metatable
      with the help of `debug.getmetatable`.\\n\\nThe metatable has four interesting
      fields: `methods`, `aliases`,\\n`getters`, and `setters`. The fields contain
      just what you'd expect.\\n\\nE.g., we can inspect the list of aliases defined
      for Inline objects with\\n\\n::: {#cb2 .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n```
      {.sourceCode .lua .code-with-copy}\\nlocal InlineMT = debug.getmetatable(pandoc.Str
      '')\\nfor name, keys in pairs(InlineMT.aliases) do\\n  -- print the alias name
      and the alias value\\n  print(name, 'is an alias for', table.concat(keys, '.'))\\nend\\n```\\n:::\\n\\nDo
      not rely on the internal structure, and do not modify the metatable.\\nHere
      be dragons.\\n:::\\n:::\\n\\n::: {#quarto-appendix .default}\\n::: {#footnotes
      .section .footnotes .footnotes-end-of-document}\\n## Footnotes {#footnotes .anchored
      .quarto-appendix-heading}\\n\\n1.  ::: {#fn1}\\n    This feature exists only
      to ensure backwards compatibility. It is\\n    better to do comparisons in like
      `PANDOC_VERSION >= '2.19'`\\n    instead.\u21A9\uFE0E\\n    :::\\n:::\\n:::\\n\",\"relationships\":[],\"archive_url\":\"https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/haskell-lua-objects\",\"guid\":\"https://tarleb.com/posts/haskell-lua-objects/index.html\",\"updated\":false,\"category\":\"computerAndInformationSciences\"}]"
    headers:
      Access-Control-Allow-Origin:
      - '*'
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 8498646a4bc31638-DUS
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Profile:
      - public
      Content-Range:
      - 0-0/*
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Mon, 22 Jan 2024 14:12:30 GMT
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      Via:
      - kong/2.8.1
      X-Kong-Proxy-Latency:
      - '0'
      X-Kong-Upstream-Latency:
      - '4'
      alt-svc:
      - h3=":443"; ma=86400
      sb-gateway-version:
      - '1'
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: '{"authors": [{"name": "Albert Krewinkel"}], "blog_name": "tarleb", "blog_slug":
      "tarleb", "content_text": "Sitemaps are an easy way to list all pages that a
      search engine should\ncrawl and index. Quarto supports the standard, XML based
      [Sitemap\nProtocol](https://www.sitemaps.org/protocol.html), although that fact
      is\na bit hidden in the docs.\n\nQuarto will automatically produce a sitemap
      if the website''s URL is\ngiven as `site-url` property:\n\n::: {#cb1 .sourceCode
      style=\"background: #f1f3f5;\"}\n``` {.sourceCode .yaml .code-with-copy}\nwebsite:\n  title:
      tarleb\n  site-url: ''https://tarleb.com''\n  site-path: ''/''\n```\n:::\n\nThe
      URL will contain a colon `:`, which is why the YAML value must be\nput in quotes.\n\nYou''ll
      find the `sitemap.xml` file in your `_site` folder after\nre-rendering your
      pages with `quarto render`.\n", "images": [], "updated_at": 1661299200, "published_at":
      1661299200, "image": null, "language": "en", "category": "computerAndInformationSciences",
      "reference": [], "relationships": [], "summary": "Sitemaps are an easy way to
      list all pages that a search engine should crawl and index. Quarto supports
      the standard, XML based Sitemap Protocol, although that fact is a bit hidden
      in the docs.  Quarto will automatically produce a sitemap if the website\u2019s
      URL is given as site-url property: website:   title: tarleb   site-url: ''https://tarleb.com''   site-path:
      ''/''  The URL will contain a colon :, which is why the YAML value must be put
      in quotes.\n", "tags": ["Quarto"], "title": "Generating a sitemap with Quarto",
      "url": "https://tarleb.com/posts/quarto-sitemap", "guid": "https://tarleb.com/posts/quarto-sitemap/index.html",
      "archive_url": "https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/quarto-sitemap"}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      accept-profile:
      - public
      connection:
      - keep-alive
      content-length:
      - '1784'
      content-profile:
      - public
      content-type:
      - application/json
      host:
      - db.rogue-scholar.org
      prefer:
      - return=representation,resolution=merge-duplicates
      user-agent:
      - python-httpx/0.25.2
      x-client-info:
      - supabase-py/2.3.4
    method: POST
    uri: https://db.rogue-scholar.org/rest/v1/posts?on_conflict=guid
  response:
    content: "[{\"url\":\"https://tarleb.com/posts/quarto-sitemap\",\"title\":\"Generating
      a sitemap with Quarto\",\"summary\":\"Sitemaps are an easy way to list all pages
      that a search engine should crawl and index. Quarto supports the standard, XML
      based Sitemap Protocol, although that fact is a bit hidden in the docs.  Quarto
      will automatically produce a sitemap if the website\u2019s URL is given as site-url
      property: website:   title: tarleb   site-url: 'https://tarleb.com'   site-path:
      '/'  The URL will contain a colon :, which is why the YAML value must be put
      in quotes.\\n\",\"image\":null,\"tags\":[\"Quarto\"],\"language\":\"en\",\"authors\":[{\"name\":
      \"Albert Krewinkel\"}],\"doi\":\"https://doi.org/10.59350/2fb2f-hb753\",\"id\":\"7b6162e7-1b3b-46b9-bcf3-523193e440a0\",\"reference\":[],\"updated_at\":1661299200,\"published_at\":1661299200,\"blog_name\":\"tarleb\",\"indexed_at\":1700478929,\"indexed\":true,\"images\":[],\"blog_slug\":\"tarleb\",\"content_text\":\"Sitemaps
      are an easy way to list all pages that a search engine should\\ncrawl and index.
      Quarto supports the standard, XML based [Sitemap\\nProtocol](https://www.sitemaps.org/protocol.html),
      although that fact is\\na bit hidden in the docs.\\n\\nQuarto will automatically
      produce a sitemap if the website's URL is\\ngiven as `site-url` property:\\n\\n:::
      {#cb1 .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n``` {.sourceCode .yaml
      .code-with-copy}\\nwebsite:\\n  title: tarleb\\n  site-url: 'https://tarleb.com'\\n
      \ site-path: '/'\\n```\\n:::\\n\\nThe URL will contain a colon `:`, which is
      why the YAML value must be\\nput in quotes.\\n\\nYou'll find the `sitemap.xml`
      file in your `_site` folder after\\nre-rendering your pages with `quarto render`.\\n\",\"relationships\":[],\"archive_url\":\"https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/quarto-sitemap\",\"guid\":\"https://tarleb.com/posts/quarto-sitemap/index.html\",\"updated\":false,\"category\":\"computerAndInformationSciences\"}]"
    headers:
      Access-Control-Allow-Origin:
      - '*'
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 8498646aac221638-DUS
      Connection:
      - keep-alive
      Content-Profile:
      - public
      Content-Range:
      - '*/*'
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Mon, 22 Jan 2024 14:12:30 GMT
      Preference-Applied:
      - resolution=merge-duplicates
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      Via:
      - kong/2.8.1
      X-Kong-Proxy-Latency:
      - '0'
      X-Kong-Upstream-Latency:
      - '4'
      alt-svc:
      - h3=":443"; ma=86400
      sb-gateway-version:
      - '1'
    http_version: HTTP/1.1
    status_code: 201
- request:
    body: '{"indexed": true}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      accept-profile:
      - public
      connection:
      - keep-alive
      content-length:
      - '17'
      content-profile:
      - public
      content-type:
      - application/json
      host:
      - db.rogue-scholar.org
      prefer:
      - return=representation
      user-agent:
      - python-httpx/0.25.2
      x-client-info:
      - supabase-py/2.3.4
    method: PATCH
    uri: https://db.rogue-scholar.org/rest/v1/posts?id=eq.7b6162e7-1b3b-46b9-bcf3-523193e440a0
  response:
    content: "[{\"url\":\"https://tarleb.com/posts/quarto-sitemap\",\"title\":\"Generating
      a sitemap with Quarto\",\"summary\":\"Sitemaps are an easy way to list all pages
      that a search engine should crawl and index. Quarto supports the standard, XML
      based Sitemap Protocol, although that fact is a bit hidden in the docs.  Quarto
      will automatically produce a sitemap if the website\u2019s URL is given as site-url
      property: website:   title: tarleb   site-url: 'https://tarleb.com'   site-path:
      '/'  The URL will contain a colon :, which is why the YAML value must be put
      in quotes.\\n\",\"image\":null,\"tags\":[\"Quarto\"],\"language\":\"en\",\"authors\":[{\"name\":
      \"Albert Krewinkel\"}],\"doi\":\"https://doi.org/10.59350/2fb2f-hb753\",\"id\":\"7b6162e7-1b3b-46b9-bcf3-523193e440a0\",\"reference\":[],\"updated_at\":1661299200,\"published_at\":1661299200,\"blog_name\":\"tarleb\",\"indexed_at\":1700478929,\"indexed\":true,\"images\":[],\"blog_slug\":\"tarleb\",\"content_text\":\"Sitemaps
      are an easy way to list all pages that a search engine should\\ncrawl and index.
      Quarto supports the standard, XML based [Sitemap\\nProtocol](https://www.sitemaps.org/protocol.html),
      although that fact is\\na bit hidden in the docs.\\n\\nQuarto will automatically
      produce a sitemap if the website's URL is\\ngiven as `site-url` property:\\n\\n:::
      {#cb1 .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n``` {.sourceCode .yaml
      .code-with-copy}\\nwebsite:\\n  title: tarleb\\n  site-url: 'https://tarleb.com'\\n
      \ site-path: '/'\\n```\\n:::\\n\\nThe URL will contain a colon `:`, which is
      why the YAML value must be\\nput in quotes.\\n\\nYou'll find the `sitemap.xml`
      file in your `_site` folder after\\nre-rendering your pages with `quarto render`.\\n\",\"relationships\":[],\"archive_url\":\"https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/quarto-sitemap\",\"guid\":\"https://tarleb.com/posts/quarto-sitemap/index.html\",\"updated\":false,\"category\":\"computerAndInformationSciences\"}]"
    headers:
      Access-Control-Allow-Origin:
      - '*'
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 8498646b1cf81638-DUS
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Profile:
      - public
      Content-Range:
      - 0-0/*
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Mon, 22 Jan 2024 14:12:30 GMT
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      Via:
      - kong/2.8.1
      X-Kong-Proxy-Latency:
      - '1'
      X-Kong-Upstream-Latency:
      - '2'
      alt-svc:
      - h3=":443"; ma=86400
      sb-gateway-version:
      - '1'
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: '{"authors": [{"name": "Albert Krewinkel"}], "blog_name": "tarleb", "blog_slug":
      "tarleb", "content_text": "These are the resources that I''d want to have if
      I was to learn about\n[pandoc (the universal document converter)](https://pandoc.org/)
      all\nover again:\n\n::: {#installing .section .level2}\n## Installing {#installing
      .anchored anchor-id=\"installing\"}\n\n[latest release](https://github.com/jgm/pandoc/releases/latest)\n:   The
      GitHub release page has installers for Windows, macOS, and\n    Linux.\n\n[Docker
      images](https://hub.docker.com/u/pandoc)\n\n:   There are three types of pandoc
      Docker images:\n\n    - [minimal](https://hub.docker.com/r/pandoc/minimal) --
      very small,\n      just the bare pandoc binary;\n    - [core](https://hub.docker.com/r/pandoc/core)
      -- includes\n      pandoc-crossref and helpers programs, e.g. those used by
      pandoc\n      for SVG image conversion;\n    - [latex](https://hub.docker.com/r/pandoc/latex)
      -- like core, plus\n      TeXLive with all packages required by the default
      template.\n\n    These images can be used as an alternative to a system-wide\n    installation.
      The image repository descriptions also explain how the\n    images can be used.\n:::\n\n:::
      {#documentation .section .level2}\n## Documentation {#documentation .anchored
      anchor-id=\"documentation\"}\n\n[manual](https://pandoc.org/MANUAL.html)\n\n:   The
      [official pandoc manual](https://pandoc.org/MANUAL.html). When\n    in doubt,
      this should always be the first resource to check. It\n    covers all command
      line options, defaults files settings, format\n    extensions, etc.\n\n    Note
      that this always documents the latest pandoc version. If\n    something isn''t
      working as documented, you may need to update.\n\n[FAQs](https://pandoc.org/faqs.html)\n:   Frequently
      Asked Questions; click on the questions to see the\n    answer.\n\n[Wiki](https://github.com/jgm/pandoc/wiki)\n:   Pandoc''s
      GitHub wiki; contains many additional resources, links, and\n    tips.\n\n[Lua
      filters](https://pandoc.org/lua-filters)\n:   How to modify a document programmatically;
      also documents all\n    constructors and utility functions exposed by pandoc.\n\n[Custom
      reader](https://pandoc.org/custom-readers)\n:   Interface that allows to write
      parsers for otherwise unsupported\n    formats.\n\n[Custom writers](https://pandoc.org/custom-writers)\n:   Interface
      that allows to use pandoc to convert to a custom output\n    format.\n\nFormat-specific
      documentation\n\n:   The support for some formats is tune-able enough to warrant\n    additional
      documentation.\n\n    - [EPUB](https://pandoc.org/epub.html) -- How to make
      an ebook\n    - [Org](https://pandoc.org/org.html) -- Emacs Org-mode\n    -
      [JATS](https://pandoc.org/jats.html) -- The Journal Article Tag\n      Set\n:::\n\n:::
      {#getting-help .section .level2}\n## Getting help {#getting-help .anchored anchor-id=\"getting-help\"}\n\nPlease
      make sure to search the web before posting.\n\n[pandoc-discuss](https://groups.google.com/g/pandoc-discuss)\n\n:   Official
      pandoc mailing list; usually the best way to get help. The\n    main developers
      and many seasoned users lurk here and answer\n    questions.\n\n    The web
      interface makes it seem like a Google account is required to\n    post, but
      this isn''t so: Write a mail to [*obfuscated mail\n    address*]{.obfuscated-mail-address
      user=\"pandoc-discuss+subscribe\"\n    domain=\"googlegroups.com\"} to subscribe
      to the list with any mail\n    address.\n\n[StackOverflow](https://stackoverflow.com/tags/pandoc/)\n:   Post
      here to reach a more programming oriented group of people.\n    Please *do not*
      cross-post, many people that follow the [pandoc\n    tag](https://stackoverflow.com/tags/pandoc/)
      have also subscribed to\n    the mailing list.\n\n[TeX/LaTeX Stack Exchange](https://tex.stackexchange.com/)\n:   This
      is a good place to ask for help when pandoc is used to generate\n    PDFs via
      LaTeX. Be sure to include the (relevant parts) of the\n    generated LaTeX output
      in your question, as most people there do not\n    use pandoc. Some even seem
      to actively dislike it, so be prepared.\n:::\n\n::: {#misc .section .level2}\n##
      Misc {#misc .anchored anchor-id=\"misc\"}\n\n[pandoc in the fediverse](https://fosstodon.org/@pandoc)\n:   I
      use this Mastodon account to post small tips and updates.\n\n[Quarto](https://quarto.org)\n:   Scientific
      and technical publishing system based on pandoc.\n\n[Zettlr](https://zettlr.com)\n:   Markdown
      editor with \"zettelkasten\" functionality.\n:::\n\n::: {#edits .section .level2}\n##
      Edits {#edits .anchored anchor-id=\"edits\"}\n\n- *2022-12-09*: Added Mastodon
      account in favor of Twitter; the account\n  on the latter platform is no longer
      updated.\n:::\n", "images": [], "updated_at": 1661212800, "published_at": 1661212800,
      "image": "https://tarleb.com/posts/pandoc-resources/pandoc.png", "language":
      "en", "category": "computerAndInformationSciences", "reference": [], "relationships":
      [], "summary": "These are the resources that I\u2019d want to have if I was
      to learn about pandoc (the universal document converter) all over again: Installing  latest
      release The GitHub release page has installers for Windows, macOS, and Linux.
      Docker images  There are three types of pandoc Docker images: minimal \u2013
      very small, just the bare pandoc binary; core \u2013 includes pandoc-crossref
      and helpers programs, e.g. those used by pandoc for SVG image conversion;\n",
      "tags": ["Pandoc"], "title": "Pandoc resources", "url": "https://tarleb.com/posts/pandoc-resources",
      "guid": "https://tarleb.com/posts/pandoc-resources/index.html", "archive_url":
      "https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/pandoc-resources"}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      accept-profile:
      - public
      connection:
      - keep-alive
      content-length:
      - '5716'
      content-profile:
      - public
      content-type:
      - application/json
      host:
      - db.rogue-scholar.org
      prefer:
      - return=representation,resolution=merge-duplicates
      user-agent:
      - python-httpx/0.25.2
      x-client-info:
      - supabase-py/2.3.4
    method: POST
    uri: https://db.rogue-scholar.org/rest/v1/posts?on_conflict=guid
  response:
    content: "[{\"url\":\"https://tarleb.com/posts/pandoc-resources\",\"title\":\"Pandoc
      resources\",\"summary\":\"These are the resources that I\u2019d want to have
      if I was to learn about pandoc (the universal document converter) all over again:
      Installing  latest release The GitHub release page has installers for Windows,
      macOS, and Linux. Docker images  There are three types of pandoc Docker images:
      minimal \u2013 very small, just the bare pandoc binary; core \u2013 includes
      pandoc-crossref and helpers programs, e.g. those used by pandoc for SVG image
      conversion;\\n\",\"image\":\"https://tarleb.com/posts/pandoc-resources/pandoc.png\",\"tags\":[\"Pandoc\"],\"language\":\"en\",\"authors\":[{\"name\":
      \"Albert Krewinkel\"}],\"doi\":\"https://doi.org/10.59350/q1z4x-nbq45\",\"id\":\"3ceb36e6-eb5d-4f47-9b1f-db12a204e802\",\"reference\":[],\"updated_at\":1661212800,\"published_at\":1661212800,\"blog_name\":\"tarleb\",\"indexed_at\":1700479379,\"indexed\":true,\"images\":[],\"blog_slug\":\"tarleb\",\"content_text\":\"These
      are the resources that I'd want to have if I was to learn about\\n[pandoc (the
      universal document converter)](https://pandoc.org/) all\\nover again:\\n\\n:::
      {#installing .section .level2}\\n## Installing {#installing .anchored anchor-id=\\\"installing\\\"}\\n\\n[latest
      release](https://github.com/jgm/pandoc/releases/latest)\\n:   The GitHub release
      page has installers for Windows, macOS, and\\n    Linux.\\n\\n[Docker images](https://hub.docker.com/u/pandoc)\\n\\n:
      \  There are three types of pandoc Docker images:\\n\\n    - [minimal](https://hub.docker.com/r/pandoc/minimal)
      -- very small,\\n      just the bare pandoc binary;\\n    - [core](https://hub.docker.com/r/pandoc/core)
      -- includes\\n      pandoc-crossref and helpers programs, e.g. those used by
      pandoc\\n      for SVG image conversion;\\n    - [latex](https://hub.docker.com/r/pandoc/latex)
      -- like core, plus\\n      TeXLive with all packages required by the default
      template.\\n\\n    These images can be used as an alternative to a system-wide\\n
      \   installation. The image repository descriptions also explain how the\\n
      \   images can be used.\\n:::\\n\\n::: {#documentation .section .level2}\\n##
      Documentation {#documentation .anchored anchor-id=\\\"documentation\\\"}\\n\\n[manual](https://pandoc.org/MANUAL.html)\\n\\n:
      \  The [official pandoc manual](https://pandoc.org/MANUAL.html). When\\n    in
      doubt, this should always be the first resource to check. It\\n    covers all
      command line options, defaults files settings, format\\n    extensions, etc.\\n\\n
      \   Note that this always documents the latest pandoc version. If\\n    something
      isn't working as documented, you may need to update.\\n\\n[FAQs](https://pandoc.org/faqs.html)\\n:
      \  Frequently Asked Questions; click on the questions to see the\\n    answer.\\n\\n[Wiki](https://github.com/jgm/pandoc/wiki)\\n:
      \  Pandoc's GitHub wiki; contains many additional resources, links, and\\n    tips.\\n\\n[Lua
      filters](https://pandoc.org/lua-filters)\\n:   How to modify a document programmatically;
      also documents all\\n    constructors and utility functions exposed by pandoc.\\n\\n[Custom
      reader](https://pandoc.org/custom-readers)\\n:   Interface that allows to write
      parsers for otherwise unsupported\\n    formats.\\n\\n[Custom writers](https://pandoc.org/custom-writers)\\n:
      \  Interface that allows to use pandoc to convert to a custom output\\n    format.\\n\\nFormat-specific
      documentation\\n\\n:   The support for some formats is tune-able enough to warrant\\n
      \   additional documentation.\\n\\n    - [EPUB](https://pandoc.org/epub.html)
      -- How to make an ebook\\n    - [Org](https://pandoc.org/org.html) -- Emacs
      Org-mode\\n    - [JATS](https://pandoc.org/jats.html) -- The Journal Article
      Tag\\n      Set\\n:::\\n\\n::: {#getting-help .section .level2}\\n## Getting
      help {#getting-help .anchored anchor-id=\\\"getting-help\\\"}\\n\\nPlease make
      sure to search the web before posting.\\n\\n[pandoc-discuss](https://groups.google.com/g/pandoc-discuss)\\n\\n:
      \  Official pandoc mailing list; usually the best way to get help. The\\n    main
      developers and many seasoned users lurk here and answer\\n    questions.\\n\\n
      \   The web interface makes it seem like a Google account is required to\\n
      \   post, but this isn't so: Write a mail to [*obfuscated mail\\n    address*]{.obfuscated-mail-address
      user=\\\"pandoc-discuss+subscribe\\\"\\n    domain=\\\"googlegroups.com\\\"}
      to subscribe to the list with any mail\\n    address.\\n\\n[StackOverflow](https://stackoverflow.com/tags/pandoc/)\\n:
      \  Post here to reach a more programming oriented group of people.\\n    Please
      *do not* cross-post, many people that follow the [pandoc\\n    tag](https://stackoverflow.com/tags/pandoc/)
      have also subscribed to\\n    the mailing list.\\n\\n[TeX/LaTeX Stack Exchange](https://tex.stackexchange.com/)\\n:
      \  This is a good place to ask for help when pandoc is used to generate\\n    PDFs
      via LaTeX. Be sure to include the (relevant parts) of the\\n    generated LaTeX
      output in your question, as most people there do not\\n    use pandoc. Some
      even seem to actively dislike it, so be prepared.\\n:::\\n\\n::: {#misc .section
      .level2}\\n## Misc {#misc .anchored anchor-id=\\\"misc\\\"}\\n\\n[pandoc in
      the fediverse](https://fosstodon.org/@pandoc)\\n:   I use this Mastodon account
      to post small tips and updates.\\n\\n[Quarto](https://quarto.org)\\n:   Scientific
      and technical publishing system based on pandoc.\\n\\n[Zettlr](https://zettlr.com)\\n:
      \  Markdown editor with \\\"zettelkasten\\\" functionality.\\n:::\\n\\n::: {#edits
      .section .level2}\\n## Edits {#edits .anchored anchor-id=\\\"edits\\\"}\\n\\n-
      *2022-12-09*: Added Mastodon account in favor of Twitter; the account\\n  on
      the latter platform is no longer updated.\\n:::\\n\",\"relationships\":[],\"archive_url\":\"https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/pandoc-resources\",\"guid\":\"https://tarleb.com/posts/pandoc-resources/index.html\",\"updated\":false,\"category\":\"computerAndInformationSciences\"}]"
    headers:
      Access-Control-Allow-Origin:
      - '*'
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 8498646b9d931638-DUS
      Connection:
      - keep-alive
      Content-Profile:
      - public
      Content-Range:
      - '*/*'
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Mon, 22 Jan 2024 14:12:30 GMT
      Preference-Applied:
      - resolution=merge-duplicates
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      Via:
      - kong/2.8.1
      X-Kong-Proxy-Latency:
      - '0'
      X-Kong-Upstream-Latency:
      - '4'
      alt-svc:
      - h3=":443"; ma=86400
      sb-gateway-version:
      - '1'
    http_version: HTTP/1.1
    status_code: 201
- request:
    body: '{"indexed": true}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      accept-profile:
      - public
      connection:
      - keep-alive
      content-length:
      - '17'
      content-profile:
      - public
      content-type:
      - application/json
      host:
      - db.rogue-scholar.org
      prefer:
      - return=representation
      user-agent:
      - python-httpx/0.25.2
      x-client-info:
      - supabase-py/2.3.4
    method: PATCH
    uri: https://db.rogue-scholar.org/rest/v1/posts?id=eq.3ceb36e6-eb5d-4f47-9b1f-db12a204e802
  response:
    content: "[{\"url\":\"https://tarleb.com/posts/pandoc-resources\",\"title\":\"Pandoc
      resources\",\"summary\":\"These are the resources that I\u2019d want to have
      if I was to learn about pandoc (the universal document converter) all over again:
      Installing  latest release The GitHub release page has installers for Windows,
      macOS, and Linux. Docker images  There are three types of pandoc Docker images:
      minimal \u2013 very small, just the bare pandoc binary; core \u2013 includes
      pandoc-crossref and helpers programs, e.g. those used by pandoc for SVG image
      conversion;\\n\",\"image\":\"https://tarleb.com/posts/pandoc-resources/pandoc.png\",\"tags\":[\"Pandoc\"],\"language\":\"en\",\"authors\":[{\"name\":
      \"Albert Krewinkel\"}],\"doi\":\"https://doi.org/10.59350/q1z4x-nbq45\",\"id\":\"3ceb36e6-eb5d-4f47-9b1f-db12a204e802\",\"reference\":[],\"updated_at\":1661212800,\"published_at\":1661212800,\"blog_name\":\"tarleb\",\"indexed_at\":1700479379,\"indexed\":true,\"images\":[],\"blog_slug\":\"tarleb\",\"content_text\":\"These
      are the resources that I'd want to have if I was to learn about\\n[pandoc (the
      universal document converter)](https://pandoc.org/) all\\nover again:\\n\\n:::
      {#installing .section .level2}\\n## Installing {#installing .anchored anchor-id=\\\"installing\\\"}\\n\\n[latest
      release](https://github.com/jgm/pandoc/releases/latest)\\n:   The GitHub release
      page has installers for Windows, macOS, and\\n    Linux.\\n\\n[Docker images](https://hub.docker.com/u/pandoc)\\n\\n:
      \  There are three types of pandoc Docker images:\\n\\n    - [minimal](https://hub.docker.com/r/pandoc/minimal)
      -- very small,\\n      just the bare pandoc binary;\\n    - [core](https://hub.docker.com/r/pandoc/core)
      -- includes\\n      pandoc-crossref and helpers programs, e.g. those used by
      pandoc\\n      for SVG image conversion;\\n    - [latex](https://hub.docker.com/r/pandoc/latex)
      -- like core, plus\\n      TeXLive with all packages required by the default
      template.\\n\\n    These images can be used as an alternative to a system-wide\\n
      \   installation. The image repository descriptions also explain how the\\n
      \   images can be used.\\n:::\\n\\n::: {#documentation .section .level2}\\n##
      Documentation {#documentation .anchored anchor-id=\\\"documentation\\\"}\\n\\n[manual](https://pandoc.org/MANUAL.html)\\n\\n:
      \  The [official pandoc manual](https://pandoc.org/MANUAL.html). When\\n    in
      doubt, this should always be the first resource to check. It\\n    covers all
      command line options, defaults files settings, format\\n    extensions, etc.\\n\\n
      \   Note that this always documents the latest pandoc version. If\\n    something
      isn't working as documented, you may need to update.\\n\\n[FAQs](https://pandoc.org/faqs.html)\\n:
      \  Frequently Asked Questions; click on the questions to see the\\n    answer.\\n\\n[Wiki](https://github.com/jgm/pandoc/wiki)\\n:
      \  Pandoc's GitHub wiki; contains many additional resources, links, and\\n    tips.\\n\\n[Lua
      filters](https://pandoc.org/lua-filters)\\n:   How to modify a document programmatically;
      also documents all\\n    constructors and utility functions exposed by pandoc.\\n\\n[Custom
      reader](https://pandoc.org/custom-readers)\\n:   Interface that allows to write
      parsers for otherwise unsupported\\n    formats.\\n\\n[Custom writers](https://pandoc.org/custom-writers)\\n:
      \  Interface that allows to use pandoc to convert to a custom output\\n    format.\\n\\nFormat-specific
      documentation\\n\\n:   The support for some formats is tune-able enough to warrant\\n
      \   additional documentation.\\n\\n    - [EPUB](https://pandoc.org/epub.html)
      -- How to make an ebook\\n    - [Org](https://pandoc.org/org.html) -- Emacs
      Org-mode\\n    - [JATS](https://pandoc.org/jats.html) -- The Journal Article
      Tag\\n      Set\\n:::\\n\\n::: {#getting-help .section .level2}\\n## Getting
      help {#getting-help .anchored anchor-id=\\\"getting-help\\\"}\\n\\nPlease make
      sure to search the web before posting.\\n\\n[pandoc-discuss](https://groups.google.com/g/pandoc-discuss)\\n\\n:
      \  Official pandoc mailing list; usually the best way to get help. The\\n    main
      developers and many seasoned users lurk here and answer\\n    questions.\\n\\n
      \   The web interface makes it seem like a Google account is required to\\n
      \   post, but this isn't so: Write a mail to [*obfuscated mail\\n    address*]{.obfuscated-mail-address
      user=\\\"pandoc-discuss+subscribe\\\"\\n    domain=\\\"googlegroups.com\\\"}
      to subscribe to the list with any mail\\n    address.\\n\\n[StackOverflow](https://stackoverflow.com/tags/pandoc/)\\n:
      \  Post here to reach a more programming oriented group of people.\\n    Please
      *do not* cross-post, many people that follow the [pandoc\\n    tag](https://stackoverflow.com/tags/pandoc/)
      have also subscribed to\\n    the mailing list.\\n\\n[TeX/LaTeX Stack Exchange](https://tex.stackexchange.com/)\\n:
      \  This is a good place to ask for help when pandoc is used to generate\\n    PDFs
      via LaTeX. Be sure to include the (relevant parts) of the\\n    generated LaTeX
      output in your question, as most people there do not\\n    use pandoc. Some
      even seem to actively dislike it, so be prepared.\\n:::\\n\\n::: {#misc .section
      .level2}\\n## Misc {#misc .anchored anchor-id=\\\"misc\\\"}\\n\\n[pandoc in
      the fediverse](https://fosstodon.org/@pandoc)\\n:   I use this Mastodon account
      to post small tips and updates.\\n\\n[Quarto](https://quarto.org)\\n:   Scientific
      and technical publishing system based on pandoc.\\n\\n[Zettlr](https://zettlr.com)\\n:
      \  Markdown editor with \\\"zettelkasten\\\" functionality.\\n:::\\n\\n::: {#edits
      .section .level2}\\n## Edits {#edits .anchored anchor-id=\\\"edits\\\"}\\n\\n-
      *2022-12-09*: Added Mastodon account in favor of Twitter; the account\\n  on
      the latter platform is no longer updated.\\n:::\\n\",\"relationships\":[],\"archive_url\":\"https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/pandoc-resources\",\"guid\":\"https://tarleb.com/posts/pandoc-resources/index.html\",\"updated\":false,\"category\":\"computerAndInformationSciences\"}]"
    headers:
      Access-Control-Allow-Origin:
      - '*'
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 8498646c1e131638-DUS
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Profile:
      - public
      Content-Range:
      - 0-0/*
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Mon, 22 Jan 2024 14:12:30 GMT
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      Via:
      - kong/2.8.1
      X-Kong-Proxy-Latency:
      - '0'
      X-Kong-Upstream-Latency:
      - '3'
      alt-svc:
      - h3=":443"; ma=86400
      sb-gateway-version:
      - '1'
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: '{"authors": [{"name": "Albert Krewinkel"}], "blog_name": "tarleb", "blog_slug":
      "tarleb", "content_text": "[Quarto](https://quarto.org) makes it very easy to
      publish a website via\nGitHub Pages: It is as simple as running `quarto publish
      gh-pages`. Here\nwe explore a slightly different method that uses a GitHub Action
      to\npublish the website automatically every time it is updated.\n\n::: {#classic-github-pages
      .section .level2}\n## Classic GitHub Pages {#classic-github-pages .anchored
      anchor-id=\"classic-github-pages\"}\n\nThe classic way to publish a website
      via GitHub pages is to maintain a\nseparate branch `gh-pages`. The branch is
      used to store the rendered\nHTML pages, and GitHub will publish the branch''s
      contents as website\neverytime that branch is updated.\n\nQuarto uses this mechanism
      when called with\n\n::: {#cb1 .sourceCode style=\"background: #f1f3f5;\"}\n```
      {.sourceCode .bash .code-with-copy}\nquarto publish gh-pages\n```\n:::\n\nWe
      can combine this with GitHub Actions easily, ensuring that the site\nis updated
      every time new content is pushed to the main branch.\n\n::: {#cb2 .sourceCode
      style=\"background: #f1f3f5;\"}\n``` {.sourceCode .yaml .code-with-copy}\n#
      file: .github/workflows/publish.yml\nname: Publish Website\n\n# Allow one concurrent
      deployment\nconcurrency:\n  group: \"pages\"\n  cancel-in-progress: true\n\non:\n  push:\n    branches:
      [''main'']\n\njobs:\n  quarto-publish:\n    name: Publish with Quarto\n    runs-on:
      ubuntu-latest\n    steps:\n      - name: Checkout repository\n        uses:
      actions/checkout@v3\n      - name: Install Quarto\n        uses: quarto-dev/quarto-actions/setup@v2\n      -
      name: Publish to GitHub Pages\n        uses: quarto-dev/quarto-actions/publish@v2\n        with:\n          target:
      gh-pages\n```\n:::\n\nThe `quart-dev/quart-actions/publish` action calls `quarto
      publish`\ninternally. This is short, to the point, and won''t interfere with
      local\ncalls to `quarto publish gh-pages`.\n:::\n\n::: {#actions-only-pages-beta
      .section .level2}\n## Actions-only Pages (Beta) {#actions-only-pages-beta .anchored
      anchor-id=\"actions-only-pages-beta\"}\n\nGitHub recently added support for
      GitHub Pages that do not require an\nextra `gh-pages` branch. Instead, the website
      is compiled and pushed\ndirectly from an action.\n\nThis takes slightly more
      code to set up, as the action must be granted\nthe necessary permissions. However,
      it is still fairly short and quick\nto do.\n\n::: {#cb3 .sourceCode style=\"background:
      #f1f3f5;\"}\n``` {.sourceCode .yaml .code-with-copy}\n# file: .github/workflows/publish.yml\nname:
      Publish Website\n\n# Allow one concurrent deployment\nconcurrency:\n  group:
      \"pages\"\n  cancel-in-progress: true\n\n# Sets permissions of the GITHUB_TOKEN
      to allow deployment to GitHub Pages\npermissions:\n  contents: read\n  pages:
      write\n  id-token: write\n\non:\n  push:\n    branches: [''main'']\n\njobs:\n  quarto:\n    runs-on:
      ubuntu-latest\n    environment:\n      name: github-pages\n      url: ${{ steps.deployment.outputs.page_url
      }}\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v3\n      -
      name: Install Quarto\n        uses: quarto-dev/quarto-actions/setup@v2\n      -
      name: Setup Pages\n        uses: actions/configure-pages@v1\n      - name: Render
      Website\n        run: quarto render\n      - name: Upload artifact\n        uses:
      actions/upload-pages-artifact@v1\n        with:\n          path: ''_site''\n      -
      name: Deploy to GitHub Pages\n        id: deployment\n        uses: actions/deploy-pages@main\n```\n:::\n\nNow
      we must change the setting to use the new publishing workflow:\n\nUnder *Settings*
      \u2192 *Pages* \u2192 *Build and deployment* the source must be\nswitched to
      \"GitHub Action\":\n\n::: {.quarto-figure .quarto-figure-center}\n<figure class=\"figure\">\n<p><img\nsrc=\"https://tarleb.com/posts/quarto-with-gh-pages/pages-settings.png\"\nclass=\"img-fluid
      figure-img\" /></p>\n<figcaption>Required setting to enable the new method</figcaption>\n</figure>\n:::\n\nThe
      `gh-pages` branch is no longer needed and can be deleted.\n:::\n\n::: {#trade-offs
      .section .level2}\n## Trade-offs {#trade-offs .anchored anchor-id=\"trade-offs\"}\n\nThe
      branch-based method for GitHub pages always felt slightly inelegant.\nI prefer
      the new method, as it does not require an extra branch and\nfeels much cleaner.
      We lose the ability to update the website via\n`quarto publish`, but as I usually
      rely on GitHub Actions to perform the\nupdates, it doesn''t affect me much:
      `git push` has the same effect.\nHowever, it seems important to be aware of
      this trade-off.\n:::\n", "images": [{"src": "https://tarleb.com/posts/quarto-with-gh-pages/pages-settings.png"},
      {"src": "https://tarleb.com/posts/quarto-with-gh-pages/pages-settings.png",
      "alt": "Required setting to enable the new method"}], "updated_at": 1659916800,
      "published_at": 1659916800, "image": "https://tarleb.com/posts/quarto-with-gh-pages/pages-settings.png",
      "language": "en", "category": "computerAndInformationSciences", "reference":
      [], "relationships": [], "summary": "Quarto makes it very easy to publish a
      website via GitHub Pages: It is as simple as running quarto publish gh-pages.
      Here we explore a slightly different method that uses a GitHub Action to publish
      the website automatically every time it is updated. Classic GitHub Pages   The
      classic way to publish a website via GitHub pages is to maintain a separate
      branch gh-pages.\n", "tags": ["Quarto"], "title": "Quarto Website with GitHub
      Actions", "url": "https://tarleb.com/posts/quarto-with-gh-pages", "guid": "https://tarleb.com/posts/quarto-with-gh-pages/index.html",
      "archive_url": "https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/quarto-with-gh-pages"}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      accept-profile:
      - public
      connection:
      - keep-alive
      content-length:
      - '5765'
      content-profile:
      - public
      content-type:
      - application/json
      host:
      - db.rogue-scholar.org
      prefer:
      - return=representation,resolution=merge-duplicates
      user-agent:
      - python-httpx/0.25.2
      x-client-info:
      - supabase-py/2.3.4
    method: POST
    uri: https://db.rogue-scholar.org/rest/v1/posts?on_conflict=guid
  response:
    content: "[{\"url\":\"https://tarleb.com/posts/quarto-with-gh-pages\",\"title\":\"Quarto
      Website with GitHub Actions\",\"summary\":\"Quarto makes it very easy to publish
      a website via GitHub Pages: It is as simple as running quarto publish gh-pages.
      Here we explore a slightly different method that uses a GitHub Action to publish
      the website automatically every time it is updated. Classic GitHub Pages   The
      classic way to publish a website via GitHub pages is to maintain a separate
      branch gh-pages.\\n\",\"image\":\"https://tarleb.com/posts/quarto-with-gh-pages/pages-settings.png\",\"tags\":[\"Quarto\"],\"language\":\"en\",\"authors\":[{\"name\":
      \"Albert Krewinkel\"}],\"doi\":\"https://doi.org/10.59350/kgags-r7165\",\"id\":\"92141755-62a9-4409-9638-d01f721d4357\",\"reference\":[],\"updated_at\":1659916800,\"published_at\":1659916800,\"blog_name\":\"tarleb\",\"indexed_at\":1700479992,\"indexed\":true,\"images\":[{\"src\":
      \"https://tarleb.com/posts/quarto-with-gh-pages/pages-settings.png\"}, {\"alt\":
      \"Required setting to enable the new method\", \"src\": \"https://tarleb.com/posts/quarto-with-gh-pages/pages-settings.png\"}],\"blog_slug\":\"tarleb\",\"content_text\":\"[Quarto](https://quarto.org)
      makes it very easy to publish a website via\\nGitHub Pages: It is as simple
      as running `quarto publish gh-pages`. Here\\nwe explore a slightly different
      method that uses a GitHub Action to\\npublish the website automatically every
      time it is updated.\\n\\n::: {#classic-github-pages .section .level2}\\n## Classic
      GitHub Pages {#classic-github-pages .anchored anchor-id=\\\"classic-github-pages\\\"}\\n\\nThe
      classic way to publish a website via GitHub pages is to maintain a\\nseparate
      branch `gh-pages`. The branch is used to store the rendered\\nHTML pages, and
      GitHub will publish the branch's contents as website\\neverytime that branch
      is updated.\\n\\nQuarto uses this mechanism when called with\\n\\n::: {#cb1
      .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n``` {.sourceCode .bash .code-with-copy}\\nquarto
      publish gh-pages\\n```\\n:::\\n\\nWe can combine this with GitHub Actions easily,
      ensuring that the site\\nis updated every time new content is pushed to the
      main branch.\\n\\n::: {#cb2 .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n```
      {.sourceCode .yaml .code-with-copy}\\n# file: .github/workflows/publish.yml\\nname:
      Publish Website\\n\\n# Allow one concurrent deployment\\nconcurrency:\\n  group:
      \\\"pages\\\"\\n  cancel-in-progress: true\\n\\non:\\n  push:\\n    branches:
      ['main']\\n\\njobs:\\n  quarto-publish:\\n    name: Publish with Quarto\\n    runs-on:
      ubuntu-latest\\n    steps:\\n      - name: Checkout repository\\n        uses:
      actions/checkout@v3\\n      - name: Install Quarto\\n        uses: quarto-dev/quarto-actions/setup@v2\\n
      \     - name: Publish to GitHub Pages\\n        uses: quarto-dev/quarto-actions/publish@v2\\n
      \       with:\\n          target: gh-pages\\n```\\n:::\\n\\nThe `quart-dev/quart-actions/publish`
      action calls `quarto publish`\\ninternally. This is short, to the point, and
      won't interfere with local\\ncalls to `quarto publish gh-pages`.\\n:::\\n\\n:::
      {#actions-only-pages-beta .section .level2}\\n## Actions-only Pages (Beta) {#actions-only-pages-beta
      .anchored anchor-id=\\\"actions-only-pages-beta\\\"}\\n\\nGitHub recently added
      support for GitHub Pages that do not require an\\nextra `gh-pages` branch. Instead,
      the website is compiled and pushed\\ndirectly from an action.\\n\\nThis takes
      slightly more code to set up, as the action must be granted\\nthe necessary
      permissions. However, it is still fairly short and quick\\nto do.\\n\\n::: {#cb3
      .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n``` {.sourceCode .yaml .code-with-copy}\\n#
      file: .github/workflows/publish.yml\\nname: Publish Website\\n\\n# Allow one
      concurrent deployment\\nconcurrency:\\n  group: \\\"pages\\\"\\n  cancel-in-progress:
      true\\n\\n# Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub
      Pages\\npermissions:\\n  contents: read\\n  pages: write\\n  id-token: write\\n\\non:\\n
      \ push:\\n    branches: ['main']\\n\\njobs:\\n  quarto:\\n    runs-on: ubuntu-latest\\n
      \   environment:\\n      name: github-pages\\n      url: ${{ steps.deployment.outputs.page_url
      }}\\n    steps:\\n      - name: Checkout repository\\n        uses: actions/checkout@v3\\n
      \     - name: Install Quarto\\n        uses: quarto-dev/quarto-actions/setup@v2\\n
      \     - name: Setup Pages\\n        uses: actions/configure-pages@v1\\n      -
      name: Render Website\\n        run: quarto render\\n      - name: Upload artifact\\n
      \       uses: actions/upload-pages-artifact@v1\\n        with:\\n          path:
      '_site'\\n      - name: Deploy to GitHub Pages\\n        id: deployment\\n        uses:
      actions/deploy-pages@main\\n```\\n:::\\n\\nNow we must change the setting to
      use the new publishing workflow:\\n\\nUnder *Settings* \u2192 *Pages* \u2192
      *Build and deployment* the source must be\\nswitched to \\\"GitHub Action\\\":\\n\\n:::
      {.quarto-figure .quarto-figure-center}\\n<figure class=\\\"figure\\\">\\n<p><img\\nsrc=\\\"https://tarleb.com/posts/quarto-with-gh-pages/pages-settings.png\\\"\\nclass=\\\"img-fluid
      figure-img\\\" /></p>\\n<figcaption>Required setting to enable the new method</figcaption>\\n</figure>\\n:::\\n\\nThe
      `gh-pages` branch is no longer needed and can be deleted.\\n:::\\n\\n::: {#trade-offs
      .section .level2}\\n## Trade-offs {#trade-offs .anchored anchor-id=\\\"trade-offs\\\"}\\n\\nThe
      branch-based method for GitHub pages always felt slightly inelegant.\\nI prefer
      the new method, as it does not require an extra branch and\\nfeels much cleaner.
      We lose the ability to update the website via\\n`quarto publish`, but as I usually
      rely on GitHub Actions to perform the\\nupdates, it doesn't affect me much:
      `git push` has the same effect.\\nHowever, it seems important to be aware of
      this trade-off.\\n:::\\n\",\"relationships\":[],\"archive_url\":\"https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/quarto-with-gh-pages\",\"guid\":\"https://tarleb.com/posts/quarto-with-gh-pages/index.html\",\"updated\":false,\"category\":\"computerAndInformationSciences\"}]"
    headers:
      Access-Control-Allow-Origin:
      - '*'
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 8498646c7e6c1638-DUS
      Connection:
      - keep-alive
      Content-Profile:
      - public
      Content-Range:
      - '*/*'
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Mon, 22 Jan 2024 14:12:30 GMT
      Preference-Applied:
      - resolution=merge-duplicates
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      Via:
      - kong/2.8.1
      X-Kong-Proxy-Latency:
      - '0'
      X-Kong-Upstream-Latency:
      - '4'
      alt-svc:
      - h3=":443"; ma=86400
      sb-gateway-version:
      - '1'
    http_version: HTTP/1.1
    status_code: 201
- request:
    body: '{"indexed": true}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      accept-profile:
      - public
      connection:
      - keep-alive
      content-length:
      - '17'
      content-profile:
      - public
      content-type:
      - application/json
      host:
      - db.rogue-scholar.org
      prefer:
      - return=representation
      user-agent:
      - python-httpx/0.25.2
      x-client-info:
      - supabase-py/2.3.4
    method: PATCH
    uri: https://db.rogue-scholar.org/rest/v1/posts?id=eq.92141755-62a9-4409-9638-d01f721d4357
  response:
    content: "[{\"url\":\"https://tarleb.com/posts/quarto-with-gh-pages\",\"title\":\"Quarto
      Website with GitHub Actions\",\"summary\":\"Quarto makes it very easy to publish
      a website via GitHub Pages: It is as simple as running quarto publish gh-pages.
      Here we explore a slightly different method that uses a GitHub Action to publish
      the website automatically every time it is updated. Classic GitHub Pages   The
      classic way to publish a website via GitHub pages is to maintain a separate
      branch gh-pages.\\n\",\"image\":\"https://tarleb.com/posts/quarto-with-gh-pages/pages-settings.png\",\"tags\":[\"Quarto\"],\"language\":\"en\",\"authors\":[{\"name\":
      \"Albert Krewinkel\"}],\"doi\":\"https://doi.org/10.59350/kgags-r7165\",\"id\":\"92141755-62a9-4409-9638-d01f721d4357\",\"reference\":[],\"updated_at\":1659916800,\"published_at\":1659916800,\"blog_name\":\"tarleb\",\"indexed_at\":1700479992,\"indexed\":true,\"images\":[{\"src\":
      \"https://tarleb.com/posts/quarto-with-gh-pages/pages-settings.png\"}, {\"alt\":
      \"Required setting to enable the new method\", \"src\": \"https://tarleb.com/posts/quarto-with-gh-pages/pages-settings.png\"}],\"blog_slug\":\"tarleb\",\"content_text\":\"[Quarto](https://quarto.org)
      makes it very easy to publish a website via\\nGitHub Pages: It is as simple
      as running `quarto publish gh-pages`. Here\\nwe explore a slightly different
      method that uses a GitHub Action to\\npublish the website automatically every
      time it is updated.\\n\\n::: {#classic-github-pages .section .level2}\\n## Classic
      GitHub Pages {#classic-github-pages .anchored anchor-id=\\\"classic-github-pages\\\"}\\n\\nThe
      classic way to publish a website via GitHub pages is to maintain a\\nseparate
      branch `gh-pages`. The branch is used to store the rendered\\nHTML pages, and
      GitHub will publish the branch's contents as website\\neverytime that branch
      is updated.\\n\\nQuarto uses this mechanism when called with\\n\\n::: {#cb1
      .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n``` {.sourceCode .bash .code-with-copy}\\nquarto
      publish gh-pages\\n```\\n:::\\n\\nWe can combine this with GitHub Actions easily,
      ensuring that the site\\nis updated every time new content is pushed to the
      main branch.\\n\\n::: {#cb2 .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n```
      {.sourceCode .yaml .code-with-copy}\\n# file: .github/workflows/publish.yml\\nname:
      Publish Website\\n\\n# Allow one concurrent deployment\\nconcurrency:\\n  group:
      \\\"pages\\\"\\n  cancel-in-progress: true\\n\\non:\\n  push:\\n    branches:
      ['main']\\n\\njobs:\\n  quarto-publish:\\n    name: Publish with Quarto\\n    runs-on:
      ubuntu-latest\\n    steps:\\n      - name: Checkout repository\\n        uses:
      actions/checkout@v3\\n      - name: Install Quarto\\n        uses: quarto-dev/quarto-actions/setup@v2\\n
      \     - name: Publish to GitHub Pages\\n        uses: quarto-dev/quarto-actions/publish@v2\\n
      \       with:\\n          target: gh-pages\\n```\\n:::\\n\\nThe `quart-dev/quart-actions/publish`
      action calls `quarto publish`\\ninternally. This is short, to the point, and
      won't interfere with local\\ncalls to `quarto publish gh-pages`.\\n:::\\n\\n:::
      {#actions-only-pages-beta .section .level2}\\n## Actions-only Pages (Beta) {#actions-only-pages-beta
      .anchored anchor-id=\\\"actions-only-pages-beta\\\"}\\n\\nGitHub recently added
      support for GitHub Pages that do not require an\\nextra `gh-pages` branch. Instead,
      the website is compiled and pushed\\ndirectly from an action.\\n\\nThis takes
      slightly more code to set up, as the action must be granted\\nthe necessary
      permissions. However, it is still fairly short and quick\\nto do.\\n\\n::: {#cb3
      .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n``` {.sourceCode .yaml .code-with-copy}\\n#
      file: .github/workflows/publish.yml\\nname: Publish Website\\n\\n# Allow one
      concurrent deployment\\nconcurrency:\\n  group: \\\"pages\\\"\\n  cancel-in-progress:
      true\\n\\n# Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub
      Pages\\npermissions:\\n  contents: read\\n  pages: write\\n  id-token: write\\n\\non:\\n
      \ push:\\n    branches: ['main']\\n\\njobs:\\n  quarto:\\n    runs-on: ubuntu-latest\\n
      \   environment:\\n      name: github-pages\\n      url: ${{ steps.deployment.outputs.page_url
      }}\\n    steps:\\n      - name: Checkout repository\\n        uses: actions/checkout@v3\\n
      \     - name: Install Quarto\\n        uses: quarto-dev/quarto-actions/setup@v2\\n
      \     - name: Setup Pages\\n        uses: actions/configure-pages@v1\\n      -
      name: Render Website\\n        run: quarto render\\n      - name: Upload artifact\\n
      \       uses: actions/upload-pages-artifact@v1\\n        with:\\n          path:
      '_site'\\n      - name: Deploy to GitHub Pages\\n        id: deployment\\n        uses:
      actions/deploy-pages@main\\n```\\n:::\\n\\nNow we must change the setting to
      use the new publishing workflow:\\n\\nUnder *Settings* \u2192 *Pages* \u2192
      *Build and deployment* the source must be\\nswitched to \\\"GitHub Action\\\":\\n\\n:::
      {.quarto-figure .quarto-figure-center}\\n<figure class=\\\"figure\\\">\\n<p><img\\nsrc=\\\"https://tarleb.com/posts/quarto-with-gh-pages/pages-settings.png\\\"\\nclass=\\\"img-fluid
      figure-img\\\" /></p>\\n<figcaption>Required setting to enable the new method</figcaption>\\n</figure>\\n:::\\n\\nThe
      `gh-pages` branch is no longer needed and can be deleted.\\n:::\\n\\n::: {#trade-offs
      .section .level2}\\n## Trade-offs {#trade-offs .anchored anchor-id=\\\"trade-offs\\\"}\\n\\nThe
      branch-based method for GitHub pages always felt slightly inelegant.\\nI prefer
      the new method, as it does not require an extra branch and\\nfeels much cleaner.
      We lose the ability to update the website via\\n`quarto publish`, but as I usually
      rely on GitHub Actions to perform the\\nupdates, it doesn't affect me much:
      `git push` has the same effect.\\nHowever, it seems important to be aware of
      this trade-off.\\n:::\\n\",\"relationships\":[],\"archive_url\":\"https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/quarto-with-gh-pages\",\"guid\":\"https://tarleb.com/posts/quarto-with-gh-pages/index.html\",\"updated\":false,\"category\":\"computerAndInformationSciences\"}]"
    headers:
      Access-Control-Allow-Origin:
      - '*'
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 8498646cfee71638-DUS
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Profile:
      - public
      Content-Range:
      - 0-0/*
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Mon, 22 Jan 2024 14:12:30 GMT
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      Via:
      - kong/2.8.1
      X-Kong-Proxy-Latency:
      - '1'
      X-Kong-Upstream-Latency:
      - '3'
      alt-svc:
      - h3=":443"; ma=86400
      sb-gateway-version:
      - '1'
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: '{"authors": [{"name": "Albert Krewinkel"}], "blog_name": "tarleb", "blog_slug":
      "tarleb", "content_text": "Santa sighted deeply as worry and uncertainty gave
      way, leaving a\nfeeling of relieve and accomplishment. The year was one of the
      worst\nhe''d seen so far. Large numbers of his helpers were moving from the\nNorth
      Pole to Antarctica to satisfy their ambient temperature\npreferences. There
      would be many telecommuting Elves this year, and each\nhelper enjoyed additional
      autonomy. Tying everything together was a\nchallenge. But he had succeeded:
      the wishes processing program was\nfinished, and the elves would be able to
      help Santa from the comfort of\ntheir new homes.\n\n::: {#wishes .section .level2}\n##
      Wishes {#wishes .anchored anchor-id=\"wishes\"}\n\nThe part of the wishes system
      that Santa had been working on was focused\non classic toys: wooden bricks,
      dolls, and train sets.\n\n::: {#cb1 .sourceCode style=\"background: #f1f3f5;\"}\n```
      {.sourceCode .haskell .code-with-copy}\ndata Toy = Bricks | TrainSet | Doll
      deriving Show\n```\n:::\n\nThe system also kept track of basic data about the
      children:\n\n::: {#cb2 .sourceCode style=\"background: #f1f3f5;\"}\n``` {.sourceCode
      .haskell .code-with-copy}\ndata Behavior = Nice | Naughty deriving (Eq, Show)\n\ndata
      Child = Child\n  { childName     :: Text\n  , childBehavior :: Behavior\n  }
      deriving (Show)\n```\n:::\n\nChildren and toys were tied together in a wish.\n\n:::
      {#cb3 .sourceCode style=\"background: #f1f3f5;\"}\n``` {.sourceCode .haskell
      .code-with-copy}\ndata Wish = Wish\n  { wishingChild :: Child\n  , wishedToy    ::
      Toy\n  } deriving (Show)\n```\n:::\n\nIt was most elegant. The problem for Santa
      was that the Elves, being\nindependent and autonomous workers, needed to access
      and process the\ndata in very custom ways. Unfortunately for him, very few Elves
      had a\nHaskell build environment installed, so he had to distribute the binary.\nWriting
      a completely custom processing language seemed like an enormous\nrabbit hole.\n:::\n\n:::
      {#lua .section .level2}\n## Lua {#lua .anchored anchor-id=\"lua\"}\n\nFortunately,
      Santa had a better idea: [Lua](https://lua.org/), an\nembeddable scripting language.
      He had been using it for some projects^1^\nand also made use of it in\n[pandoc](https://pandoc.org/lua-filters.html),
      which he used to answer\nhis mails. Santa would just need to expose the relevant
      parts of the\nHaskell system, so the Elves could access and script it as their
      hearts\ndesired. He looked for a library, found\n[HsLua](https://github.com/hslua/hslua),
      and got to work.\n:::\n\n::: {#exposing-data .section .level2}\n## Exposing
      data {#exposing-data .anchored anchor-id=\"exposing-data\"}\n\nLua has a simple,
      yet powerful, stack-based\n[API](https://www.lua.org/manual/5.4/manual.html#4).
      The first step\ntowards exposing Haskell data was to push them to the Lua stack.
      Keeping\nthings simple, Santa chose strings to represent toys:\n\n::: {#cb4
      .sourceCode style=\"background: #f1f3f5;\"}\n``` {.sourceCode .haskell .code-with-copy}\npushToy
      :: Toy -> Lua ()\npushToy = pushString . show\n```\n:::\n\nLua offers only a
      single construct to structure data: tables. So that''s\nwhat Child and Wish
      were represented with.\n\n::: {#cb5 .sourceCode style=\"background: #f1f3f5;\"}\n```
      {.sourceCode .haskell .code-with-copy}\npushChild :: Child -> Lua ()\npushChild
      (Child name behavior) = do\n  -- create new Lua table on the stack\n  newtable\n  --
      push string to stack\n  pushText name\n  -- table now in position 2; assign
      string to field in table\n  setfield (nth 2) \"name\"\n\n  -- push boolean to
      stack\n  pushBool (behavior == Nice)\n  setfield (nth 2) \"nice\"\n\npushWish
      :: Wish -> Lua ()\npushWish (Wish child toy) = do\n  newtable\n  pushChild child\n  setfield
      (nth 2) \"child\"\n  pushToy toy\n  setfield (nth 2) \"toy\"\n```\n:::\n:::\n\n:::
      {#running-scripts .section .level2}\n## Running scripts {#running-scripts .anchored
      anchor-id=\"running-scripts\"}\n\nSanta''s goal for now was to allow his Elves
      to filter the list of wishes\nso each finds the ones relevant to them. For example,
      if an Elf only\ncares about wishes for train sets from children who were nice,
      then they\nshould be able to use a script to filter those wishes out.\n\n:::
      {#cb6 .sourceCode style=\"background: #f1f3f5;\"}\n``` {.sourceCode .lua .code-with-copy}\nreturn
      function (wish)\n  return wish.child.nice and\n    wish.toy == ''TrainSet''\nend\n```\n:::\n\nThe
      script returns a (lambda) function that serves as a predicate for\nwishes. The
      function can be thought of having the type\n`Wish -> IO Bool`. Santa needed
      to turn the Lua lambda function into an\nactual Haskell function `runPredicate
      :: Wish -> Lua Bool`. If Santa\nassumed that the lambda function was at the
      top of the Lua stack, then\nhe could push a `Wish` value to the Lua stack, call
      the function, and\nretrieve the result value from the stack.\n\n::: {#cb7 .sourceCode
      style=\"background: #f1f3f5;\"}\n``` {.sourceCode .haskell .code-with-copy}\nrunPredicate
      :: Wish -> Lua Bool\nrunPredicate wish = do\n  -- Assume filter function is
      at the top of the stack;\n  -- create a copy so we can re-use it.\n  pushvalue
      top\n  pushWish wish\n  -- Call the function. There is one argument on the stack,\n  --
      and we expect one result to be returned.\n  call (NumArgs 1) (NumResults 1)\n  toboolean
      top <* pop 1\n```\n:::\n\nWhat remained was loading the Elves'' script files.
      Santa did this with\n[`dofile`](https://hackage.haskell.org/package/hslua/docs/Foreign-Lua-Core.html#v:dofile)\nof
      type `FilePath -> Lua Status`. The predicate then ends up on the top\nof the
      Lua stack, and can be called through `runPredicate`, e.g.\u00a0to\nselect a
      subset of wishes via\n[`filterM`](https://hackage.haskell.org/package/base/docs/Control-Monad.html#v:filterM).\n\n:::
      {#cb8 .sourceCode style=\"background: #f1f3f5;\"}\n``` {.sourceCode .haskell
      .code-with-copy}\nmain :: IO ()\nmain = do\n  filterFile <- fmap (!! 0) getArgs
      -- get first argument\n  result <- run $ do\n    _status <- dofile filterFile\n    filterM
      runPredicate wishes\n  print result\n```\n:::\n\nSanta tested his creation on
      a short list of wishes\n\n::: {#cb9 .sourceCode style=\"background: #f1f3f5;\"}\n```
      {.sourceCode .haskell .code-with-copy}\nwishes :: [Wish]\nwishes =\n  [ Wish
      (Child \"Theodor\" Nice) Bricks\n  , Wish (Child \"Philine\" Nice) TrainSet\n  ,
      Wish (Child \"Steve\" Naughty) Doll\n  ]\n```\n:::\n\nby running `runhaskell
      wish-filter predicate.lua`. To his uttermost\nsatisfaction, the terminal echoed
      the right information back to him.\n\n    [Wish {wishingChild = Child {childName
      = \"Philine\", childBehavior = Nice}, wishedToy = TrainSet}]\n\nHe reclined
      in his chair, shut down his device, and enjoyed a double\nchocolate chip cookie
      of which he felt very deserving now.\n\n------------------------------------------------------------------------\n\nSanta''s
      full code, as presented here, is available as part of the\nexamples at <https://github.com/hslua/hslua>.\n:::\n\n:::
      {#quarto-appendix .default}\n::: {#footnotes .section .footnotes .footnotes-end-of-document}\n##
      Footnotes {#footnotes .anchored .quarto-appendix-heading}\n\n1.  ::: {#fn1}\n    Santa
      learned about Lua from his game-devs. Now he uses it to keep\n    his security
      teams on their toes with [nmap](https://nmap.org) and\n    [Wireshark](https://wireshark.org/);
      many of the North Pole''s\n    servers contain custom Lua scripts, too\n    ([redis](https://redis.io/commands/eval),\n    [nginx/OpenResty](https://github.com/openresty),\n    [HAProxy](https://www.haproxy.com/blog/5-ways-to-extend-haproxy-with-lua/),\n    [PowerDNS](https://doc.powerdns.com/authoritative/lua-records/index.html)).\u21a9\ufe0e\n    :::\n:::\n:::\n",
      "images": [], "updated_at": 1607212800, "published_at": 1607212800, "image":
      null, "language": "en", "category": "computerAndInformationSciences", "reference":
      [], "relationships": [], "summary": "Santa sighted deeply as worry and uncertainty
      gave way, leaving a feeling of relieve and accomplishment. The year was one
      of the worst he\u2019d seen so far. Large numbers of his helpers were moving
      from the North Pole to Antarctica to satisfy their ambient temperature preferences.
      There would be many telecommuting Elves this year, and each helper enjoyed additional
      autonomy. Tying everything together was a challenge.\n", "tags": ["Lua", "Hslua",
      "Example"], "title": "Santa\u2019s Little Lua Scripts", "url": "https://tarleb.com/posts/santas-little-lua-scripts",
      "guid": "https://tarleb.com/posts/santas-little-lua-scripts/index.html", "archive_url":
      "https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/santas-little-lua-scripts"}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      accept-profile:
      - public
      connection:
      - keep-alive
      content-length:
      - '8707'
      content-profile:
      - public
      content-type:
      - application/json
      host:
      - db.rogue-scholar.org
      prefer:
      - return=representation,resolution=merge-duplicates
      user-agent:
      - python-httpx/0.25.2
      x-client-info:
      - supabase-py/2.3.4
    method: POST
    uri: https://db.rogue-scholar.org/rest/v1/posts?on_conflict=guid
  response:
    content: "[{\"url\":\"https://tarleb.com/posts/santas-little-lua-scripts\",\"title\":\"Santa\u2019s
      Little Lua Scripts\",\"summary\":\"Santa sighted deeply as worry and uncertainty
      gave way, leaving a feeling of relieve and accomplishment. The year was one
      of the worst he\u2019d seen so far. Large numbers of his helpers were moving
      from the North Pole to Antarctica to satisfy their ambient temperature preferences.
      There would be many telecommuting Elves this year, and each helper enjoyed additional
      autonomy. Tying everything together was a challenge.\\n\",\"image\":null,\"tags\":[\"Lua\",\"Hslua\",\"Example\"],\"language\":\"en\",\"authors\":[{\"name\":
      \"Albert Krewinkel\"}],\"doi\":\"https://doi.org/10.59350/qd6tj-kcb18\",\"id\":\"83343fed-2939-46d6-afa3-9f512ff3c3f8\",\"reference\":[],\"updated_at\":1607212800,\"published_at\":1607212800,\"blog_name\":\"tarleb\",\"indexed_at\":1700480580,\"indexed\":true,\"images\":[],\"blog_slug\":\"tarleb\",\"content_text\":\"Santa
      sighted deeply as worry and uncertainty gave way, leaving a\\nfeeling of relieve
      and accomplishment. The year was one of the worst\\nhe'd seen so far. Large
      numbers of his helpers were moving from the\\nNorth Pole to Antarctica to satisfy
      their ambient temperature\\npreferences. There would be many telecommuting Elves
      this year, and each\\nhelper enjoyed additional autonomy. Tying everything together
      was a\\nchallenge. But he had succeeded: the wishes processing program was\\nfinished,
      and the elves would be able to help Santa from the comfort of\\ntheir new homes.\\n\\n:::
      {#wishes .section .level2}\\n## Wishes {#wishes .anchored anchor-id=\\\"wishes\\\"}\\n\\nThe
      part of the wishes system that Santa had been working on was focused\\non classic
      toys: wooden bricks, dolls, and train sets.\\n\\n::: {#cb1 .sourceCode style=\\\"background:
      #f1f3f5;\\\"}\\n``` {.sourceCode .haskell .code-with-copy}\\ndata Toy = Bricks
      | TrainSet | Doll deriving Show\\n```\\n:::\\n\\nThe system also kept track
      of basic data about the children:\\n\\n::: {#cb2 .sourceCode style=\\\"background:
      #f1f3f5;\\\"}\\n``` {.sourceCode .haskell .code-with-copy}\\ndata Behavior =
      Nice | Naughty deriving (Eq, Show)\\n\\ndata Child = Child\\n  { childName     ::
      Text\\n  , childBehavior :: Behavior\\n  } deriving (Show)\\n```\\n:::\\n\\nChildren
      and toys were tied together in a wish.\\n\\n::: {#cb3 .sourceCode style=\\\"background:
      #f1f3f5;\\\"}\\n``` {.sourceCode .haskell .code-with-copy}\\ndata Wish = Wish\\n
      \ { wishingChild :: Child\\n  , wishedToy    :: Toy\\n  } deriving (Show)\\n```\\n:::\\n\\nIt
      was most elegant. The problem for Santa was that the Elves, being\\nindependent
      and autonomous workers, needed to access and process the\\ndata in very custom
      ways. Unfortunately for him, very few Elves had a\\nHaskell build environment
      installed, so he had to distribute the binary.\\nWriting a completely custom
      processing language seemed like an enormous\\nrabbit hole.\\n:::\\n\\n::: {#lua
      .section .level2}\\n## Lua {#lua .anchored anchor-id=\\\"lua\\\"}\\n\\nFortunately,
      Santa had a better idea: [Lua](https://lua.org/), an\\nembeddable scripting
      language. He had been using it for some projects^1^\\nand also made use of it
      in\\n[pandoc](https://pandoc.org/lua-filters.html), which he used to answer\\nhis
      mails. Santa would just need to expose the relevant parts of the\\nHaskell system,
      so the Elves could access and script it as their hearts\\ndesired. He looked
      for a library, found\\n[HsLua](https://github.com/hslua/hslua), and got to work.\\n:::\\n\\n:::
      {#exposing-data .section .level2}\\n## Exposing data {#exposing-data .anchored
      anchor-id=\\\"exposing-data\\\"}\\n\\nLua has a simple, yet powerful, stack-based\\n[API](https://www.lua.org/manual/5.4/manual.html#4).
      The first step\\ntowards exposing Haskell data was to push them to the Lua stack.
      Keeping\\nthings simple, Santa chose strings to represent toys:\\n\\n::: {#cb4
      .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n``` {.sourceCode .haskell
      .code-with-copy}\\npushToy :: Toy -> Lua ()\\npushToy = pushString . show\\n```\\n:::\\n\\nLua
      offers only a single construct to structure data: tables. So that's\\nwhat Child
      and Wish were represented with.\\n\\n::: {#cb5 .sourceCode style=\\\"background:
      #f1f3f5;\\\"}\\n``` {.sourceCode .haskell .code-with-copy}\\npushChild :: Child
      -> Lua ()\\npushChild (Child name behavior) = do\\n  -- create new Lua table
      on the stack\\n  newtable\\n  -- push string to stack\\n  pushText name\\n  --
      table now in position 2; assign string to field in table\\n  setfield (nth 2)
      \\\"name\\\"\\n\\n  -- push boolean to stack\\n  pushBool (behavior == Nice)\\n
      \ setfield (nth 2) \\\"nice\\\"\\n\\npushWish :: Wish -> Lua ()\\npushWish (Wish
      child toy) = do\\n  newtable\\n  pushChild child\\n  setfield (nth 2) \\\"child\\\"\\n
      \ pushToy toy\\n  setfield (nth 2) \\\"toy\\\"\\n```\\n:::\\n:::\\n\\n::: {#running-scripts
      .section .level2}\\n## Running scripts {#running-scripts .anchored anchor-id=\\\"running-scripts\\\"}\\n\\nSanta's
      goal for now was to allow his Elves to filter the list of wishes\\nso each finds
      the ones relevant to them. For example, if an Elf only\\ncares about wishes
      for train sets from children who were nice, then they\\nshould be able to use
      a script to filter those wishes out.\\n\\n::: {#cb6 .sourceCode style=\\\"background:
      #f1f3f5;\\\"}\\n``` {.sourceCode .lua .code-with-copy}\\nreturn function (wish)\\n
      \ return wish.child.nice and\\n    wish.toy == 'TrainSet'\\nend\\n```\\n:::\\n\\nThe
      script returns a (lambda) function that serves as a predicate for\\nwishes.
      The function can be thought of having the type\\n`Wish -> IO Bool`. Santa needed
      to turn the Lua lambda function into an\\nactual Haskell function `runPredicate
      :: Wish -> Lua Bool`. If Santa\\nassumed that the lambda function was at the
      top of the Lua stack, then\\nhe could push a `Wish` value to the Lua stack,
      call the function, and\\nretrieve the result value from the stack.\\n\\n:::
      {#cb7 .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n``` {.sourceCode .haskell
      .code-with-copy}\\nrunPredicate :: Wish -> Lua Bool\\nrunPredicate wish = do\\n
      \ -- Assume filter function is at the top of the stack;\\n  -- create a copy
      so we can re-use it.\\n  pushvalue top\\n  pushWish wish\\n  -- Call the function.
      There is one argument on the stack,\\n  -- and we expect one result to be returned.\\n
      \ call (NumArgs 1) (NumResults 1)\\n  toboolean top <* pop 1\\n```\\n:::\\n\\nWhat
      remained was loading the Elves' script files. Santa did this with\\n[`dofile`](https://hackage.haskell.org/package/hslua/docs/Foreign-Lua-Core.html#v:dofile)\\nof
      type `FilePath -> Lua Status`. The predicate then ends up on the top\\nof the
      Lua stack, and can be called through `runPredicate`, e.g.\_to\\nselect a subset
      of wishes via\\n[`filterM`](https://hackage.haskell.org/package/base/docs/Control-Monad.html#v:filterM).\\n\\n:::
      {#cb8 .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n``` {.sourceCode .haskell
      .code-with-copy}\\nmain :: IO ()\\nmain = do\\n  filterFile <- fmap (!! 0) getArgs
      -- get first argument\\n  result <- run $ do\\n    _status <- dofile filterFile\\n
      \   filterM runPredicate wishes\\n  print result\\n```\\n:::\\n\\nSanta tested
      his creation on a short list of wishes\\n\\n::: {#cb9 .sourceCode style=\\\"background:
      #f1f3f5;\\\"}\\n``` {.sourceCode .haskell .code-with-copy}\\nwishes :: [Wish]\\nwishes
      =\\n  [ Wish (Child \\\"Theodor\\\" Nice) Bricks\\n  , Wish (Child \\\"Philine\\\"
      Nice) TrainSet\\n  , Wish (Child \\\"Steve\\\" Naughty) Doll\\n  ]\\n```\\n:::\\n\\nby
      running `runhaskell wish-filter predicate.lua`. To his uttermost\\nsatisfaction,
      the terminal echoed the right information back to him.\\n\\n    [Wish {wishingChild
      = Child {childName = \\\"Philine\\\", childBehavior = Nice}, wishedToy = TrainSet}]\\n\\nHe
      reclined in his chair, shut down his device, and enjoyed a double\\nchocolate
      chip cookie of which he felt very deserving now.\\n\\n------------------------------------------------------------------------\\n\\nSanta's
      full code, as presented here, is available as part of the\\nexamples at <https://github.com/hslua/hslua>.\\n:::\\n\\n:::
      {#quarto-appendix .default}\\n::: {#footnotes .section .footnotes .footnotes-end-of-document}\\n##
      Footnotes {#footnotes .anchored .quarto-appendix-heading}\\n\\n1.  ::: {#fn1}\\n
      \   Santa learned about Lua from his game-devs. Now he uses it to keep\\n    his
      security teams on their toes with [nmap](https://nmap.org) and\\n    [Wireshark](https://wireshark.org/);
      many of the North Pole's\\n    servers contain custom Lua scripts, too\\n    ([redis](https://redis.io/commands/eval),\\n
      \   [nginx/OpenResty](https://github.com/openresty),\\n    [HAProxy](https://www.haproxy.com/blog/5-ways-to-extend-haproxy-with-lua/),\\n
      \   [PowerDNS](https://doc.powerdns.com/authoritative/lua-records/index.html)).\u21A9\uFE0E\\n
      \   :::\\n:::\\n:::\\n\",\"relationships\":[],\"archive_url\":\"https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/santas-little-lua-scripts\",\"guid\":\"https://tarleb.com/posts/santas-little-lua-scripts/index.html\",\"updated\":false,\"category\":\"computerAndInformationSciences\"}]"
    headers:
      Access-Control-Allow-Origin:
      - '*'
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 8498646d6f5b1638-DUS
      Connection:
      - keep-alive
      Content-Profile:
      - public
      Content-Range:
      - '*/*'
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Mon, 22 Jan 2024 14:12:30 GMT
      Preference-Applied:
      - resolution=merge-duplicates
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      Via:
      - kong/2.8.1
      X-Kong-Proxy-Latency:
      - '0'
      X-Kong-Upstream-Latency:
      - '3'
      alt-svc:
      - h3=":443"; ma=86400
      sb-gateway-version:
      - '1'
    http_version: HTTP/1.1
    status_code: 201
- request:
    body: '{"indexed": true}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      accept-profile:
      - public
      connection:
      - keep-alive
      content-length:
      - '17'
      content-profile:
      - public
      content-type:
      - application/json
      host:
      - db.rogue-scholar.org
      prefer:
      - return=representation
      user-agent:
      - python-httpx/0.25.2
      x-client-info:
      - supabase-py/2.3.4
    method: PATCH
    uri: https://db.rogue-scholar.org/rest/v1/posts?id=eq.83343fed-2939-46d6-afa3-9f512ff3c3f8
  response:
    content: "[{\"url\":\"https://tarleb.com/posts/santas-little-lua-scripts\",\"title\":\"Santa\u2019s
      Little Lua Scripts\",\"summary\":\"Santa sighted deeply as worry and uncertainty
      gave way, leaving a feeling of relieve and accomplishment. The year was one
      of the worst he\u2019d seen so far. Large numbers of his helpers were moving
      from the North Pole to Antarctica to satisfy their ambient temperature preferences.
      There would be many telecommuting Elves this year, and each helper enjoyed additional
      autonomy. Tying everything together was a challenge.\\n\",\"image\":null,\"tags\":[\"Lua\",\"Hslua\",\"Example\"],\"language\":\"en\",\"authors\":[{\"name\":
      \"Albert Krewinkel\"}],\"doi\":\"https://doi.org/10.59350/qd6tj-kcb18\",\"id\":\"83343fed-2939-46d6-afa3-9f512ff3c3f8\",\"reference\":[],\"updated_at\":1607212800,\"published_at\":1607212800,\"blog_name\":\"tarleb\",\"indexed_at\":1700480580,\"indexed\":true,\"images\":[],\"blog_slug\":\"tarleb\",\"content_text\":\"Santa
      sighted deeply as worry and uncertainty gave way, leaving a\\nfeeling of relieve
      and accomplishment. The year was one of the worst\\nhe'd seen so far. Large
      numbers of his helpers were moving from the\\nNorth Pole to Antarctica to satisfy
      their ambient temperature\\npreferences. There would be many telecommuting Elves
      this year, and each\\nhelper enjoyed additional autonomy. Tying everything together
      was a\\nchallenge. But he had succeeded: the wishes processing program was\\nfinished,
      and the elves would be able to help Santa from the comfort of\\ntheir new homes.\\n\\n:::
      {#wishes .section .level2}\\n## Wishes {#wishes .anchored anchor-id=\\\"wishes\\\"}\\n\\nThe
      part of the wishes system that Santa had been working on was focused\\non classic
      toys: wooden bricks, dolls, and train sets.\\n\\n::: {#cb1 .sourceCode style=\\\"background:
      #f1f3f5;\\\"}\\n``` {.sourceCode .haskell .code-with-copy}\\ndata Toy = Bricks
      | TrainSet | Doll deriving Show\\n```\\n:::\\n\\nThe system also kept track
      of basic data about the children:\\n\\n::: {#cb2 .sourceCode style=\\\"background:
      #f1f3f5;\\\"}\\n``` {.sourceCode .haskell .code-with-copy}\\ndata Behavior =
      Nice | Naughty deriving (Eq, Show)\\n\\ndata Child = Child\\n  { childName     ::
      Text\\n  , childBehavior :: Behavior\\n  } deriving (Show)\\n```\\n:::\\n\\nChildren
      and toys were tied together in a wish.\\n\\n::: {#cb3 .sourceCode style=\\\"background:
      #f1f3f5;\\\"}\\n``` {.sourceCode .haskell .code-with-copy}\\ndata Wish = Wish\\n
      \ { wishingChild :: Child\\n  , wishedToy    :: Toy\\n  } deriving (Show)\\n```\\n:::\\n\\nIt
      was most elegant. The problem for Santa was that the Elves, being\\nindependent
      and autonomous workers, needed to access and process the\\ndata in very custom
      ways. Unfortunately for him, very few Elves had a\\nHaskell build environment
      installed, so he had to distribute the binary.\\nWriting a completely custom
      processing language seemed like an enormous\\nrabbit hole.\\n:::\\n\\n::: {#lua
      .section .level2}\\n## Lua {#lua .anchored anchor-id=\\\"lua\\\"}\\n\\nFortunately,
      Santa had a better idea: [Lua](https://lua.org/), an\\nembeddable scripting
      language. He had been using it for some projects^1^\\nand also made use of it
      in\\n[pandoc](https://pandoc.org/lua-filters.html), which he used to answer\\nhis
      mails. Santa would just need to expose the relevant parts of the\\nHaskell system,
      so the Elves could access and script it as their hearts\\ndesired. He looked
      for a library, found\\n[HsLua](https://github.com/hslua/hslua), and got to work.\\n:::\\n\\n:::
      {#exposing-data .section .level2}\\n## Exposing data {#exposing-data .anchored
      anchor-id=\\\"exposing-data\\\"}\\n\\nLua has a simple, yet powerful, stack-based\\n[API](https://www.lua.org/manual/5.4/manual.html#4).
      The first step\\ntowards exposing Haskell data was to push them to the Lua stack.
      Keeping\\nthings simple, Santa chose strings to represent toys:\\n\\n::: {#cb4
      .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n``` {.sourceCode .haskell
      .code-with-copy}\\npushToy :: Toy -> Lua ()\\npushToy = pushString . show\\n```\\n:::\\n\\nLua
      offers only a single construct to structure data: tables. So that's\\nwhat Child
      and Wish were represented with.\\n\\n::: {#cb5 .sourceCode style=\\\"background:
      #f1f3f5;\\\"}\\n``` {.sourceCode .haskell .code-with-copy}\\npushChild :: Child
      -> Lua ()\\npushChild (Child name behavior) = do\\n  -- create new Lua table
      on the stack\\n  newtable\\n  -- push string to stack\\n  pushText name\\n  --
      table now in position 2; assign string to field in table\\n  setfield (nth 2)
      \\\"name\\\"\\n\\n  -- push boolean to stack\\n  pushBool (behavior == Nice)\\n
      \ setfield (nth 2) \\\"nice\\\"\\n\\npushWish :: Wish -> Lua ()\\npushWish (Wish
      child toy) = do\\n  newtable\\n  pushChild child\\n  setfield (nth 2) \\\"child\\\"\\n
      \ pushToy toy\\n  setfield (nth 2) \\\"toy\\\"\\n```\\n:::\\n:::\\n\\n::: {#running-scripts
      .section .level2}\\n## Running scripts {#running-scripts .anchored anchor-id=\\\"running-scripts\\\"}\\n\\nSanta's
      goal for now was to allow his Elves to filter the list of wishes\\nso each finds
      the ones relevant to them. For example, if an Elf only\\ncares about wishes
      for train sets from children who were nice, then they\\nshould be able to use
      a script to filter those wishes out.\\n\\n::: {#cb6 .sourceCode style=\\\"background:
      #f1f3f5;\\\"}\\n``` {.sourceCode .lua .code-with-copy}\\nreturn function (wish)\\n
      \ return wish.child.nice and\\n    wish.toy == 'TrainSet'\\nend\\n```\\n:::\\n\\nThe
      script returns a (lambda) function that serves as a predicate for\\nwishes.
      The function can be thought of having the type\\n`Wish -> IO Bool`. Santa needed
      to turn the Lua lambda function into an\\nactual Haskell function `runPredicate
      :: Wish -> Lua Bool`. If Santa\\nassumed that the lambda function was at the
      top of the Lua stack, then\\nhe could push a `Wish` value to the Lua stack,
      call the function, and\\nretrieve the result value from the stack.\\n\\n:::
      {#cb7 .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n``` {.sourceCode .haskell
      .code-with-copy}\\nrunPredicate :: Wish -> Lua Bool\\nrunPredicate wish = do\\n
      \ -- Assume filter function is at the top of the stack;\\n  -- create a copy
      so we can re-use it.\\n  pushvalue top\\n  pushWish wish\\n  -- Call the function.
      There is one argument on the stack,\\n  -- and we expect one result to be returned.\\n
      \ call (NumArgs 1) (NumResults 1)\\n  toboolean top <* pop 1\\n```\\n:::\\n\\nWhat
      remained was loading the Elves' script files. Santa did this with\\n[`dofile`](https://hackage.haskell.org/package/hslua/docs/Foreign-Lua-Core.html#v:dofile)\\nof
      type `FilePath -> Lua Status`. The predicate then ends up on the top\\nof the
      Lua stack, and can be called through `runPredicate`, e.g.\_to\\nselect a subset
      of wishes via\\n[`filterM`](https://hackage.haskell.org/package/base/docs/Control-Monad.html#v:filterM).\\n\\n:::
      {#cb8 .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n``` {.sourceCode .haskell
      .code-with-copy}\\nmain :: IO ()\\nmain = do\\n  filterFile <- fmap (!! 0) getArgs
      -- get first argument\\n  result <- run $ do\\n    _status <- dofile filterFile\\n
      \   filterM runPredicate wishes\\n  print result\\n```\\n:::\\n\\nSanta tested
      his creation on a short list of wishes\\n\\n::: {#cb9 .sourceCode style=\\\"background:
      #f1f3f5;\\\"}\\n``` {.sourceCode .haskell .code-with-copy}\\nwishes :: [Wish]\\nwishes
      =\\n  [ Wish (Child \\\"Theodor\\\" Nice) Bricks\\n  , Wish (Child \\\"Philine\\\"
      Nice) TrainSet\\n  , Wish (Child \\\"Steve\\\" Naughty) Doll\\n  ]\\n```\\n:::\\n\\nby
      running `runhaskell wish-filter predicate.lua`. To his uttermost\\nsatisfaction,
      the terminal echoed the right information back to him.\\n\\n    [Wish {wishingChild
      = Child {childName = \\\"Philine\\\", childBehavior = Nice}, wishedToy = TrainSet}]\\n\\nHe
      reclined in his chair, shut down his device, and enjoyed a double\\nchocolate
      chip cookie of which he felt very deserving now.\\n\\n------------------------------------------------------------------------\\n\\nSanta's
      full code, as presented here, is available as part of the\\nexamples at <https://github.com/hslua/hslua>.\\n:::\\n\\n:::
      {#quarto-appendix .default}\\n::: {#footnotes .section .footnotes .footnotes-end-of-document}\\n##
      Footnotes {#footnotes .anchored .quarto-appendix-heading}\\n\\n1.  ::: {#fn1}\\n
      \   Santa learned about Lua from his game-devs. Now he uses it to keep\\n    his
      security teams on their toes with [nmap](https://nmap.org) and\\n    [Wireshark](https://wireshark.org/);
      many of the North Pole's\\n    servers contain custom Lua scripts, too\\n    ([redis](https://redis.io/commands/eval),\\n
      \   [nginx/OpenResty](https://github.com/openresty),\\n    [HAProxy](https://www.haproxy.com/blog/5-ways-to-extend-haproxy-with-lua/),\\n
      \   [PowerDNS](https://doc.powerdns.com/authoritative/lua-records/index.html)).\u21A9\uFE0E\\n
      \   :::\\n:::\\n:::\\n\",\"relationships\":[],\"archive_url\":\"https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/santas-little-lua-scripts\",\"guid\":\"https://tarleb.com/posts/santas-little-lua-scripts/index.html\",\"updated\":false,\"category\":\"computerAndInformationSciences\"}]"
    headers:
      Access-Control-Allow-Origin:
      - '*'
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 8498646ddfc51638-DUS
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Profile:
      - public
      Content-Range:
      - 0-0/*
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Mon, 22 Jan 2024 14:12:31 GMT
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      Via:
      - kong/2.8.1
      X-Kong-Proxy-Latency:
      - '0'
      X-Kong-Upstream-Latency:
      - '3'
      alt-svc:
      - h3=":443"; ma=86400
      sb-gateway-version:
      - '1'
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: '{"authors": [{"name": "Albert Krewinkel"}], "blog_name": "tarleb", "blog_slug":
      "tarleb", "content_text": "A question came up on the Lua mailing list, asking
      whether there was a\nPDF version of the [Lua manual](https://lua.org/manual/5.4/manual.html).\nThis
      is, of course, the home domain of pandoc, and I got nerd-sniped\ninto producing
      a PDF (and ePUB) version of the manual.\n\nThis is a good opportunity to showcase
      some pandoc features. The post\ndescribes the process of going from an HTML
      web page to a PDF file via\nLaTeX and pandoc. We will see how to\n\n1.  quickly
      convert documents with pandoc;\n2.  use Lua filters to improve the result by
      modifying the document; and\n3.  fine-tune the output by setting appropriate
      pandoc options.\n\n::: {#invoking-pandoc .section .level2}\n## Invoking pandoc
      {#invoking-pandoc .anchored anchor-id=\"invoking-pandoc\"}\n\nThe first step
      is to call pandoc on the Lua manual website. Even when\nkeeping everything bare-bones,
      the result is already decent:\n\n    pandoc --pdf-engine=xelatex --output=lua-manual.pdf
      \\\n        \"https://lua.org/manual/5.4/manual.html\"\n\nProduces\n\n::: {.quarto-figure
      .quarto-figure-center}\n<figure class=\"figure\">\n<p><img\nsrc=\"https://tarleb.com/posts/pdf-of-the-lua-manual/lua-refman-naive.png\"\nclass=\"img-fluid
      figure-img\" /></p>\n<figcaption>First page of unoptimized PDF</figcaption>\n</figure>\n:::\n\nThis
      requires a somewhat recent version of pandoc as well as XeLaTeX to\nbe installed.
      It is possible to forgo the trouble of installing the\nrequirements by using
      the *pandoc/latex* Docker image:\n\n    docker run --rm -v \"$PWD\":/data -u
      $(id -u):$(id -g) pandoc/latex:2.9.2.1 \\\n        --pdf-engine=xelatex --output=lua-manual.pdf
      \\\n        \"https://lua.org/manual/5.4/manual.html\"\n:::\n\n::: {#replacing-characters
      .section .level2}\n## Replacing characters {#replacing-characters .anchored
      anchor-id=\"replacing-characters\"}\n\nThe above commands will produce warnings
      about characters which are\nunavailable in the default fonts. We don''t want
      characters to go\nmissing, of course, so let''s fix that first. The warnings
      are:\n\n    [WARNING] Missing character: There is no \u2264 (U+2264) in font
      [lmmono10-regular]:!\n    [WARNING] Missing character: There is no \u2264 (U+2264)
      in font [lmmono10-regular]:!\n    [WARNING] Missing character: There is no \u03c0
      (U+03C0) in font [lmroman10-italic]:mapping=tex-text;!\n\nSearching the page
      for `\u2264` shows that it is used in inline code, while\n`\u03c0` occurs as
      emphasized character in the description of `math.pi`. We\ncould, of course,
      search for a font which has the appropriate glyphs and\ninstruct pandoc/LaTeX
      to use it. But we''ll go a different route.\n\nA good way to improve the result
      of a converstion is to use a pandoc\n[Lua filter](https://pandoc.org/lua-filters.html).
      We create a file\ncalled `beautify-manual.lua` and pass it to pandoc via the\n`--lua-filter=beautify-manual.lua`
      command line option.\n\nHandling `\u2264` is straight forward, we just replace
      the char with the\nslightly uglier looking ASCII sequence `<=` in all code elements.\n\n:::
      {#cb4 .sourceCode style=\"background: #f1f3f5;\"}\n``` {.sourceCode .lua .code-with-copy}\nfunction
      Code (c)\n  c.text = c.text:gsub(''\u2264'', ''<='')\n  return c\nend\n```\n:::\n\nWhile
      there is no italics version `\u03c0` in the default font, there *is*\nsuch a
      glyph in the default math font. Pandoc''s internal representation\nfor *\u03c0*
      is `Emph [Str \"\u03c0\"]`, which we replace with a math element\nholding the
      same content.\n\n::: {#cb5 .sourceCode style=\"background: #f1f3f5;\"}\n```
      {.sourceCode .lua .code-with-copy}\nfunction Emph (e)\n  local s = e.content[1]\n  if
      #e.content == 1 and s.tag == ''Str'' and s.text == ''\u03c0'' then\n    return
      pandoc.Math(''InlineMath'', ''\u03c0'')\n  end\nend\n```\n:::\n\nThe document
      now compiles without warnings, and all characters are\nproperly included.\n:::\n\n:::
      {#add-table-of-contents .section .level2}\n## Add Table of Contents {#add-table-of-contents
      .anchored anchor-id=\"add-table-of-contents\"}\n\nThe Lua manual is long, often
      used as a reference, and, in its HTML\nversion, comes with a table of contents
      on a separate page. The PDF, for\nit to be useful as a reference, should have
      a table of contents as well.\nPandoc can be told to generate a table of contents
      by adding the `--toc`\ncommand line flag. The toc depth is controlled via `--toc-depth`;
      `2` is\na good setting here. However, in this case, the result is neither\npleasing
      nor informative:\n\n::: {.quarto-figure .quarto-figure-center}\n<figure class=\"figure\">\n<p><img
      src=\"https://tarleb.com/posts/pdf-of-the-lua-manual/bad-toc.png\"\nclass=\"img-fluid
      figure-img\" /></p>\n<figcaption>Bad looking table of contents</figcaption>\n</figure>\n:::\n\nSomething
      is terribly wrong. By inspecting the parsed document by\nrunning `pandoc --to=native
      \u2026`, we see that all *Header*s contain a\n*Span*. That span holds the actual
      contents. Apparently LaTeX does not\nlike this and omits the content of the
      span when generating the toc.\n\nThe span also has the id used by links to the
      header. Numbered sections\nstart with the section number, which we''d rather
      produce via pandoc.\n\n::: {#cb6 .sourceCode style=\"background: #f1f3f5;\"}\n```
      {.sourceCode .lua .code-with-copy}\nfunction Header (h)\n  -- Unnumbered sections
      have the main contents as the first element.\n  -- Numbered sections start with
      the number and an em-dash, so\n  -- the Span is the fifth element (Lua multipass).\n  local
      span\n  if h.content[1].tag == ''Str'' and h.content[1].text:match ''[%d%.]+''
      then\n    span = h.content[5]\n  else\n    span = h.content[1]\n    h.classes:insert(''unnumbered'')\n  end\n\n  h.identifier
      = span.identifier\n  h.content = span.content\n\n  return h\nend\n```\n:::\n\nThe
      filter also removes the section numbering. We add it back by passing\n`--number-sections`
      to pandoc.\n\n::: {.quarto-figure .quarto-figure-center}\n<figure class=\"figure\">\n<p><img\nsrc=\"https://tarleb.com/posts/pdf-of-the-lua-manual/less-bad-toc.png\"\nclass=\"img-fluid
      figure-img\" /></p>\n<figcaption>less-bad table of contents</figcaption>\n</figure>\n:::\n\nNot
      bad.\n:::\n\n::: {#improve-title-and-metadata .section .level2}\n## Improve
      title and metadata {#improve-title-and-metadata .anchored anchor-id=\"improve-title-and-metadata\"}\n\nThe
      PDF is already quite usable, let''s prettify it a bit more: It would\nbe important
      to properly list the authors in the title and metadata,\nremove the unnecessary
      first header, and maybe add the Lua logo to the\ntitle. All this is easiest
      when acting on the full document.\n\n::: {#cb7 .sourceCode style=\"background:
      #f1f3f5;\"}\n``` {.sourceCode .lua .code-with-copy}\nfunction Pandoc (doc)\n  --
      comma separated authors\n  local authors = doc.blocks[2]\n  authors.content:remove(1)  --
      remove ''by''\n  doc.meta.author = pandoc.List()\n  for author in pandoc.utils.stringify(authors):gmatch
      ''[^,]+'' do\n    doc.meta.author:insert(author)\n  end\n\n  -- Remove unnecessary
      blocks\n  doc.blocks:remove(4) -- menubar\n  doc.blocks:remove(2) -- authors
      paragraph\n  doc.blocks:remove(1) -- title header\n\n  -- add subtitle image\n  doc.meta.subtitle
      = pandoc.MetaInlines{\n    pandoc.RawInline(''latex'', ''\\\\vspace{1em}''),\n    pandoc.Image(\"Lua
      logo\", -- \"https://www.lua.org/images/lua-logo.gif\")\n  }\n  return doc\nend\n```\n:::\n:::\n\n:::
      {#final-touch .section .level2}\n## Final touch {#final-touch .anchored anchor-id=\"final-touch\"}\n\nFinally,
      we may want the PDF to add a little more visible structure,\ne.g., starting
      top-level sections on their own page.\n\nThe command used by pandoc to create
      the top level headings can be\ncontrolled with the `--top-level-division` option.
      Setting that option\nto `chapter` ensures that each major section starts on
      a new page.\nHowever, the default document class used by LaTeX doesn''t allow\nchapters,
      so a different class has to be set with\n`--variable documentclass=report`.\n:::\n\n:::
      {#summary .section .level2}\n## Summary {#summary .anchored anchor-id=\"summary\"}\n\nFor
      completeness, [here is the complete filter](lua-manual-cleanup.lua),\nand this
      is the full pandoc command used to generate the PDF:\n\n::: {#cb8 .sourceCode
      style=\"background: #f1f3f5;\"}\n``` {.sourceCode .bash .code-with-copy}\npandoc
      \\\n  --toc \\\n  --toc-depth=2 \\\n  --metadata=documentclass=report \\\n  --pdf-engine=xelatex
      \\\n  --lua-filter=lua-manual-cleanup.lua \\\n  --number-sections \\\n  --top-level-division=chapter
      \\\n  --output=lua-5.4-manual.pdf \\\n  \"https://lua.org/manual/5.4/manual.html\"\n```\n:::\n\nOne
      of the big advantages of pandoc is that it offers a lot of freedom.\nSince we
      already cleaned the content up, we can now also create other\nformats, like
      an ebook, just by changing the name of the output file.\nThe final results are
      available below:\n\n- [Lua 5.4 manual (PDF)](lua-5.4-manual.pdf)\n- [Lua 5.4
      manual (EPUB)](lua-5.4-manual.epub)\n:::\n", "images": [{"src": "https://tarleb.com/posts/pdf-of-the-lua-manual/lua-refman-naive.png"},
      {"src": "https://tarleb.com/posts/pdf-of-the-lua-manual/bad-toc.png"}, {"src":
      "https://tarleb.com/posts/pdf-of-the-lua-manual/less-bad-toc.png"}, {"src":
      "https://tarleb.com/posts/pdf-of-the-lua-manual/lua-refman-naive.png", "alt":
      "First page of unoptimized PDF"}, {"src": "https://tarleb.com/posts/pdf-of-the-lua-manual/bad-toc.png",
      "alt": "Bad looking table of contents"}, {"src": "https://tarleb.com/posts/pdf-of-the-lua-manual/less-bad-toc.png",
      "alt": "less-bad table of contents"}], "updated_at": 1594425600, "published_at":
      1594425600, "image": "https://tarleb.com/posts/pdf-of-the-lua-manual/lua-refman-naive.png",
      "language": "en", "category": "computerAndInformationSciences", "reference":
      [], "relationships": [], "summary": "A question came up on the Lua mailing list,
      asking whether there was a PDF version of the Lua manual. This is, of course,
      the home domain of pandoc, and I got nerd-sniped into producing a PDF (and ePUB)
      version of the manual. This is a good opportunity to showcase some pandoc features.
      The post describes the process of going from an HTML web page to a PDF file
      via LaTeX and pandoc. We will see how to quickly convert documents with pandoc;\n",
      "tags": ["Pandoc", "Lua", "Pdf"], "title": "PDF Version of the Lua Manual",
      "url": "https://tarleb.com/posts/pdf-of-the-lua-manual", "guid": "https://tarleb.com/posts/pdf-of-the-lua-manual/index.html",
      "archive_url": "https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/pdf-of-the-lua-manual"}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      accept-profile:
      - public
      connection:
      - keep-alive
      content-length:
      - '10617'
      content-profile:
      - public
      content-type:
      - application/json
      host:
      - db.rogue-scholar.org
      prefer:
      - return=representation,resolution=merge-duplicates
      user-agent:
      - python-httpx/0.25.2
      x-client-info:
      - supabase-py/2.3.4
    method: POST
    uri: https://db.rogue-scholar.org/rest/v1/posts?on_conflict=guid
  response:
    content: "[{\"url\":\"https://tarleb.com/posts/pdf-of-the-lua-manual\",\"title\":\"PDF
      Version of the Lua Manual\",\"summary\":\"A question came up on the Lua mailing
      list, asking whether there was a PDF version of the Lua manual. This is, of
      course, the home domain of pandoc, and I got nerd-sniped into producing a PDF
      (and ePUB) version of the manual. This is a good opportunity to showcase some
      pandoc features. The post describes the process of going from an HTML web page
      to a PDF file via LaTeX and pandoc. We will see how to quickly convert documents
      with pandoc;\\n\",\"image\":\"https://tarleb.com/posts/pdf-of-the-lua-manual/lua-refman-naive.png\",\"tags\":[\"Pandoc\",\"Lua\",\"Pdf\"],\"language\":\"en\",\"authors\":[{\"name\":
      \"Albert Krewinkel\"}],\"doi\":\"https://doi.org/10.59350/kk38t-bfj47\",\"id\":\"0578c708-1102-42b5-b43f-f2a830b218d5\",\"reference\":[],\"updated_at\":1594425600,\"published_at\":1594425600,\"blog_name\":\"tarleb\",\"indexed_at\":1700481179,\"indexed\":true,\"images\":[{\"src\":
      \"https://tarleb.com/posts/pdf-of-the-lua-manual/lua-refman-naive.png\"}, {\"src\":
      \"https://tarleb.com/posts/pdf-of-the-lua-manual/bad-toc.png\"}, {\"src\": \"https://tarleb.com/posts/pdf-of-the-lua-manual/less-bad-toc.png\"},
      {\"alt\": \"First page of unoptimized PDF\", \"src\": \"https://tarleb.com/posts/pdf-of-the-lua-manual/lua-refman-naive.png\"},
      {\"alt\": \"Bad looking table of contents\", \"src\": \"https://tarleb.com/posts/pdf-of-the-lua-manual/bad-toc.png\"},
      {\"alt\": \"less-bad table of contents\", \"src\": \"https://tarleb.com/posts/pdf-of-the-lua-manual/less-bad-toc.png\"}],\"blog_slug\":\"tarleb\",\"content_text\":\"A
      question came up on the Lua mailing list, asking whether there was a\\nPDF version
      of the [Lua manual](https://lua.org/manual/5.4/manual.html).\\nThis is, of course,
      the home domain of pandoc, and I got nerd-sniped\\ninto producing a PDF (and
      ePUB) version of the manual.\\n\\nThis is a good opportunity to showcase some
      pandoc features. The post\\ndescribes the process of going from an HTML web
      page to a PDF file via\\nLaTeX and pandoc. We will see how to\\n\\n1.  quickly
      convert documents with pandoc;\\n2.  use Lua filters to improve the result by
      modifying the document; and\\n3.  fine-tune the output by setting appropriate
      pandoc options.\\n\\n::: {#invoking-pandoc .section .level2}\\n## Invoking pandoc
      {#invoking-pandoc .anchored anchor-id=\\\"invoking-pandoc\\\"}\\n\\nThe first
      step is to call pandoc on the Lua manual website. Even when\\nkeeping everything
      bare-bones, the result is already decent:\\n\\n    pandoc --pdf-engine=xelatex
      --output=lua-manual.pdf \\\\\\n        \\\"https://lua.org/manual/5.4/manual.html\\\"\\n\\nProduces\\n\\n:::
      {.quarto-figure .quarto-figure-center}\\n<figure class=\\\"figure\\\">\\n<p><img\\nsrc=\\\"https://tarleb.com/posts/pdf-of-the-lua-manual/lua-refman-naive.png\\\"\\nclass=\\\"img-fluid
      figure-img\\\" /></p>\\n<figcaption>First page of unoptimized PDF</figcaption>\\n</figure>\\n:::\\n\\nThis
      requires a somewhat recent version of pandoc as well as XeLaTeX to\\nbe installed.
      It is possible to forgo the trouble of installing the\\nrequirements by using
      the *pandoc/latex* Docker image:\\n\\n    docker run --rm -v \\\"$PWD\\\":/data
      -u $(id -u):$(id -g) pandoc/latex:2.9.2.1 \\\\\\n        --pdf-engine=xelatex
      --output=lua-manual.pdf \\\\\\n        \\\"https://lua.org/manual/5.4/manual.html\\\"\\n:::\\n\\n:::
      {#replacing-characters .section .level2}\\n## Replacing characters {#replacing-characters
      .anchored anchor-id=\\\"replacing-characters\\\"}\\n\\nThe above commands will
      produce warnings about characters which are\\nunavailable in the default fonts.
      We don't want characters to go\\nmissing, of course, so let's fix that first.
      The warnings are:\\n\\n    [WARNING] Missing character: There is no \u2264 (U+2264)
      in font [lmmono10-regular]:!\\n    [WARNING] Missing character: There is no
      \u2264 (U+2264) in font [lmmono10-regular]:!\\n    [WARNING] Missing character:
      There is no \u03C0 (U+03C0) in font [lmroman10-italic]:mapping=tex-text;!\\n\\nSearching
      the page for `\u2264` shows that it is used in inline code, while\\n`\u03C0`
      occurs as emphasized character in the description of `math.pi`. We\\ncould,
      of course, search for a font which has the appropriate glyphs and\\ninstruct
      pandoc/LaTeX to use it. But we'll go a different route.\\n\\nA good way to improve
      the result of a converstion is to use a pandoc\\n[Lua filter](https://pandoc.org/lua-filters.html).
      We create a file\\ncalled `beautify-manual.lua` and pass it to pandoc via the\\n`--lua-filter=beautify-manual.lua`
      command line option.\\n\\nHandling `\u2264` is straight forward, we just replace
      the char with the\\nslightly uglier looking ASCII sequence `<=` in all code
      elements.\\n\\n::: {#cb4 .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n```
      {.sourceCode .lua .code-with-copy}\\nfunction Code (c)\\n  c.text = c.text:gsub('\u2264',
      '<=')\\n  return c\\nend\\n```\\n:::\\n\\nWhile there is no italics version
      `\u03C0` in the default font, there *is*\\nsuch a glyph in the default math
      font. Pandoc's internal representation\\nfor *\u03C0* is `Emph [Str \\\"\u03C0\\\"]`,
      which we replace with a math element\\nholding the same content.\\n\\n::: {#cb5
      .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n``` {.sourceCode .lua .code-with-copy}\\nfunction
      Emph (e)\\n  local s = e.content[1]\\n  if #e.content == 1 and s.tag == 'Str'
      and s.text == '\u03C0' then\\n    return pandoc.Math('InlineMath', '\u03C0')\\n
      \ end\\nend\\n```\\n:::\\n\\nThe document now compiles without warnings, and
      all characters are\\nproperly included.\\n:::\\n\\n::: {#add-table-of-contents
      .section .level2}\\n## Add Table of Contents {#add-table-of-contents .anchored
      anchor-id=\\\"add-table-of-contents\\\"}\\n\\nThe Lua manual is long, often
      used as a reference, and, in its HTML\\nversion, comes with a table of contents
      on a separate page. The PDF, for\\nit to be useful as a reference, should have
      a table of contents as well.\\nPandoc can be told to generate a table of contents
      by adding the `--toc`\\ncommand line flag. The toc depth is controlled via `--toc-depth`;
      `2` is\\na good setting here. However, in this case, the result is neither\\npleasing
      nor informative:\\n\\n::: {.quarto-figure .quarto-figure-center}\\n<figure class=\\\"figure\\\">\\n<p><img
      src=\\\"https://tarleb.com/posts/pdf-of-the-lua-manual/bad-toc.png\\\"\\nclass=\\\"img-fluid
      figure-img\\\" /></p>\\n<figcaption>Bad looking table of contents</figcaption>\\n</figure>\\n:::\\n\\nSomething
      is terribly wrong. By inspecting the parsed document by\\nrunning `pandoc --to=native
      \u2026`, we see that all *Header*s contain a\\n*Span*. That span holds the actual
      contents. Apparently LaTeX does not\\nlike this and omits the content of the
      span when generating the toc.\\n\\nThe span also has the id used by links to
      the header. Numbered sections\\nstart with the section number, which we'd rather
      produce via pandoc.\\n\\n::: {#cb6 .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n```
      {.sourceCode .lua .code-with-copy}\\nfunction Header (h)\\n  -- Unnumbered sections
      have the main contents as the first element.\\n  -- Numbered sections start
      with the number and an em-dash, so\\n  -- the Span is the fifth element (Lua
      multipass).\\n  local span\\n  if h.content[1].tag == 'Str' and h.content[1].text:match
      '[%d%.]+' then\\n    span = h.content[5]\\n  else\\n    span = h.content[1]\\n
      \   h.classes:insert('unnumbered')\\n  end\\n\\n  h.identifier = span.identifier\\n
      \ h.content = span.content\\n\\n  return h\\nend\\n```\\n:::\\n\\nThe filter
      also removes the section numbering. We add it back by passing\\n`--number-sections`
      to pandoc.\\n\\n::: {.quarto-figure .quarto-figure-center}\\n<figure class=\\\"figure\\\">\\n<p><img\\nsrc=\\\"https://tarleb.com/posts/pdf-of-the-lua-manual/less-bad-toc.png\\\"\\nclass=\\\"img-fluid
      figure-img\\\" /></p>\\n<figcaption>less-bad table of contents</figcaption>\\n</figure>\\n:::\\n\\nNot
      bad.\\n:::\\n\\n::: {#improve-title-and-metadata .section .level2}\\n## Improve
      title and metadata {#improve-title-and-metadata .anchored anchor-id=\\\"improve-title-and-metadata\\\"}\\n\\nThe
      PDF is already quite usable, let's prettify it a bit more: It would\\nbe important
      to properly list the authors in the title and metadata,\\nremove the unnecessary
      first header, and maybe add the Lua logo to the\\ntitle. All this is easiest
      when acting on the full document.\\n\\n::: {#cb7 .sourceCode style=\\\"background:
      #f1f3f5;\\\"}\\n``` {.sourceCode .lua .code-with-copy}\\nfunction Pandoc (doc)\\n
      \ -- comma separated authors\\n  local authors = doc.blocks[2]\\n  authors.content:remove(1)
      \ -- remove 'by'\\n  doc.meta.author = pandoc.List()\\n  for author in pandoc.utils.stringify(authors):gmatch
      '[^,]+' do\\n    doc.meta.author:insert(author)\\n  end\\n\\n  -- Remove unnecessary
      blocks\\n  doc.blocks:remove(4) -- menubar\\n  doc.blocks:remove(2) -- authors
      paragraph\\n  doc.blocks:remove(1) -- title header\\n\\n  -- add subtitle image\\n
      \ doc.meta.subtitle = pandoc.MetaInlines{\\n    pandoc.RawInline('latex', '\\\\\\\\vspace{1em}'),\\n
      \   pandoc.Image(\\\"Lua logo\\\", -- \\\"https://www.lua.org/images/lua-logo.gif\\\")\\n
      \ }\\n  return doc\\nend\\n```\\n:::\\n:::\\n\\n::: {#final-touch .section .level2}\\n##
      Final touch {#final-touch .anchored anchor-id=\\\"final-touch\\\"}\\n\\nFinally,
      we may want the PDF to add a little more visible structure,\\ne.g., starting
      top-level sections on their own page.\\n\\nThe command used by pandoc to create
      the top level headings can be\\ncontrolled with the `--top-level-division` option.
      Setting that option\\nto `chapter` ensures that each major section starts on
      a new page.\\nHowever, the default document class used by LaTeX doesn't allow\\nchapters,
      so a different class has to be set with\\n`--variable documentclass=report`.\\n:::\\n\\n:::
      {#summary .section .level2}\\n## Summary {#summary .anchored anchor-id=\\\"summary\\\"}\\n\\nFor
      completeness, [here is the complete filter](lua-manual-cleanup.lua),\\nand this
      is the full pandoc command used to generate the PDF:\\n\\n::: {#cb8 .sourceCode
      style=\\\"background: #f1f3f5;\\\"}\\n``` {.sourceCode .bash .code-with-copy}\\npandoc
      \\\\\\n  --toc \\\\\\n  --toc-depth=2 \\\\\\n  --metadata=documentclass=report
      \\\\\\n  --pdf-engine=xelatex \\\\\\n  --lua-filter=lua-manual-cleanup.lua \\\\\\n
      \ --number-sections \\\\\\n  --top-level-division=chapter \\\\\\n  --output=lua-5.4-manual.pdf
      \\\\\\n  \\\"https://lua.org/manual/5.4/manual.html\\\"\\n```\\n:::\\n\\nOne
      of the big advantages of pandoc is that it offers a lot of freedom.\\nSince
      we already cleaned the content up, we can now also create other\\nformats, like
      an ebook, just by changing the name of the output file.\\nThe final results
      are available below:\\n\\n- [Lua 5.4 manual (PDF)](lua-5.4-manual.pdf)\\n- [Lua
      5.4 manual (EPUB)](lua-5.4-manual.epub)\\n:::\\n\",\"relationships\":[],\"archive_url\":\"https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/pdf-of-the-lua-manual\",\"guid\":\"https://tarleb.com/posts/pdf-of-the-lua-manual/index.html\",\"updated\":false,\"category\":\"computerAndInformationSciences\"}]"
    headers:
      Access-Control-Allow-Origin:
      - '*'
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 8498646e485d1638-DUS
      Connection:
      - keep-alive
      Content-Profile:
      - public
      Content-Range:
      - '*/*'
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Mon, 22 Jan 2024 14:12:31 GMT
      Preference-Applied:
      - resolution=merge-duplicates
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      Via:
      - kong/2.8.1
      X-Kong-Proxy-Latency:
      - '0'
      X-Kong-Upstream-Latency:
      - '5'
      alt-svc:
      - h3=":443"; ma=86400
      sb-gateway-version:
      - '1'
    http_version: HTTP/1.1
    status_code: 201
- request:
    body: '{"indexed": true}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      accept-profile:
      - public
      connection:
      - keep-alive
      content-length:
      - '17'
      content-profile:
      - public
      content-type:
      - application/json
      host:
      - db.rogue-scholar.org
      prefer:
      - return=representation
      user-agent:
      - python-httpx/0.25.2
      x-client-info:
      - supabase-py/2.3.4
    method: PATCH
    uri: https://db.rogue-scholar.org/rest/v1/posts?id=eq.0578c708-1102-42b5-b43f-f2a830b218d5
  response:
    content: "[{\"url\":\"https://tarleb.com/posts/pdf-of-the-lua-manual\",\"title\":\"PDF
      Version of the Lua Manual\",\"summary\":\"A question came up on the Lua mailing
      list, asking whether there was a PDF version of the Lua manual. This is, of
      course, the home domain of pandoc, and I got nerd-sniped into producing a PDF
      (and ePUB) version of the manual. This is a good opportunity to showcase some
      pandoc features. The post describes the process of going from an HTML web page
      to a PDF file via LaTeX and pandoc. We will see how to quickly convert documents
      with pandoc;\\n\",\"image\":\"https://tarleb.com/posts/pdf-of-the-lua-manual/lua-refman-naive.png\",\"tags\":[\"Pandoc\",\"Lua\",\"Pdf\"],\"language\":\"en\",\"authors\":[{\"name\":
      \"Albert Krewinkel\"}],\"doi\":\"https://doi.org/10.59350/kk38t-bfj47\",\"id\":\"0578c708-1102-42b5-b43f-f2a830b218d5\",\"reference\":[],\"updated_at\":1594425600,\"published_at\":1594425600,\"blog_name\":\"tarleb\",\"indexed_at\":1700481179,\"indexed\":true,\"images\":[{\"src\":
      \"https://tarleb.com/posts/pdf-of-the-lua-manual/lua-refman-naive.png\"}, {\"src\":
      \"https://tarleb.com/posts/pdf-of-the-lua-manual/bad-toc.png\"}, {\"src\": \"https://tarleb.com/posts/pdf-of-the-lua-manual/less-bad-toc.png\"},
      {\"alt\": \"First page of unoptimized PDF\", \"src\": \"https://tarleb.com/posts/pdf-of-the-lua-manual/lua-refman-naive.png\"},
      {\"alt\": \"Bad looking table of contents\", \"src\": \"https://tarleb.com/posts/pdf-of-the-lua-manual/bad-toc.png\"},
      {\"alt\": \"less-bad table of contents\", \"src\": \"https://tarleb.com/posts/pdf-of-the-lua-manual/less-bad-toc.png\"}],\"blog_slug\":\"tarleb\",\"content_text\":\"A
      question came up on the Lua mailing list, asking whether there was a\\nPDF version
      of the [Lua manual](https://lua.org/manual/5.4/manual.html).\\nThis is, of course,
      the home domain of pandoc, and I got nerd-sniped\\ninto producing a PDF (and
      ePUB) version of the manual.\\n\\nThis is a good opportunity to showcase some
      pandoc features. The post\\ndescribes the process of going from an HTML web
      page to a PDF file via\\nLaTeX and pandoc. We will see how to\\n\\n1.  quickly
      convert documents with pandoc;\\n2.  use Lua filters to improve the result by
      modifying the document; and\\n3.  fine-tune the output by setting appropriate
      pandoc options.\\n\\n::: {#invoking-pandoc .section .level2}\\n## Invoking pandoc
      {#invoking-pandoc .anchored anchor-id=\\\"invoking-pandoc\\\"}\\n\\nThe first
      step is to call pandoc on the Lua manual website. Even when\\nkeeping everything
      bare-bones, the result is already decent:\\n\\n    pandoc --pdf-engine=xelatex
      --output=lua-manual.pdf \\\\\\n        \\\"https://lua.org/manual/5.4/manual.html\\\"\\n\\nProduces\\n\\n:::
      {.quarto-figure .quarto-figure-center}\\n<figure class=\\\"figure\\\">\\n<p><img\\nsrc=\\\"https://tarleb.com/posts/pdf-of-the-lua-manual/lua-refman-naive.png\\\"\\nclass=\\\"img-fluid
      figure-img\\\" /></p>\\n<figcaption>First page of unoptimized PDF</figcaption>\\n</figure>\\n:::\\n\\nThis
      requires a somewhat recent version of pandoc as well as XeLaTeX to\\nbe installed.
      It is possible to forgo the trouble of installing the\\nrequirements by using
      the *pandoc/latex* Docker image:\\n\\n    docker run --rm -v \\\"$PWD\\\":/data
      -u $(id -u):$(id -g) pandoc/latex:2.9.2.1 \\\\\\n        --pdf-engine=xelatex
      --output=lua-manual.pdf \\\\\\n        \\\"https://lua.org/manual/5.4/manual.html\\\"\\n:::\\n\\n:::
      {#replacing-characters .section .level2}\\n## Replacing characters {#replacing-characters
      .anchored anchor-id=\\\"replacing-characters\\\"}\\n\\nThe above commands will
      produce warnings about characters which are\\nunavailable in the default fonts.
      We don't want characters to go\\nmissing, of course, so let's fix that first.
      The warnings are:\\n\\n    [WARNING] Missing character: There is no \u2264 (U+2264)
      in font [lmmono10-regular]:!\\n    [WARNING] Missing character: There is no
      \u2264 (U+2264) in font [lmmono10-regular]:!\\n    [WARNING] Missing character:
      There is no \u03C0 (U+03C0) in font [lmroman10-italic]:mapping=tex-text;!\\n\\nSearching
      the page for `\u2264` shows that it is used in inline code, while\\n`\u03C0`
      occurs as emphasized character in the description of `math.pi`. We\\ncould,
      of course, search for a font which has the appropriate glyphs and\\ninstruct
      pandoc/LaTeX to use it. But we'll go a different route.\\n\\nA good way to improve
      the result of a converstion is to use a pandoc\\n[Lua filter](https://pandoc.org/lua-filters.html).
      We create a file\\ncalled `beautify-manual.lua` and pass it to pandoc via the\\n`--lua-filter=beautify-manual.lua`
      command line option.\\n\\nHandling `\u2264` is straight forward, we just replace
      the char with the\\nslightly uglier looking ASCII sequence `<=` in all code
      elements.\\n\\n::: {#cb4 .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n```
      {.sourceCode .lua .code-with-copy}\\nfunction Code (c)\\n  c.text = c.text:gsub('\u2264',
      '<=')\\n  return c\\nend\\n```\\n:::\\n\\nWhile there is no italics version
      `\u03C0` in the default font, there *is*\\nsuch a glyph in the default math
      font. Pandoc's internal representation\\nfor *\u03C0* is `Emph [Str \\\"\u03C0\\\"]`,
      which we replace with a math element\\nholding the same content.\\n\\n::: {#cb5
      .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n``` {.sourceCode .lua .code-with-copy}\\nfunction
      Emph (e)\\n  local s = e.content[1]\\n  if #e.content == 1 and s.tag == 'Str'
      and s.text == '\u03C0' then\\n    return pandoc.Math('InlineMath', '\u03C0')\\n
      \ end\\nend\\n```\\n:::\\n\\nThe document now compiles without warnings, and
      all characters are\\nproperly included.\\n:::\\n\\n::: {#add-table-of-contents
      .section .level2}\\n## Add Table of Contents {#add-table-of-contents .anchored
      anchor-id=\\\"add-table-of-contents\\\"}\\n\\nThe Lua manual is long, often
      used as a reference, and, in its HTML\\nversion, comes with a table of contents
      on a separate page. The PDF, for\\nit to be useful as a reference, should have
      a table of contents as well.\\nPandoc can be told to generate a table of contents
      by adding the `--toc`\\ncommand line flag. The toc depth is controlled via `--toc-depth`;
      `2` is\\na good setting here. However, in this case, the result is neither\\npleasing
      nor informative:\\n\\n::: {.quarto-figure .quarto-figure-center}\\n<figure class=\\\"figure\\\">\\n<p><img
      src=\\\"https://tarleb.com/posts/pdf-of-the-lua-manual/bad-toc.png\\\"\\nclass=\\\"img-fluid
      figure-img\\\" /></p>\\n<figcaption>Bad looking table of contents</figcaption>\\n</figure>\\n:::\\n\\nSomething
      is terribly wrong. By inspecting the parsed document by\\nrunning `pandoc --to=native
      \u2026`, we see that all *Header*s contain a\\n*Span*. That span holds the actual
      contents. Apparently LaTeX does not\\nlike this and omits the content of the
      span when generating the toc.\\n\\nThe span also has the id used by links to
      the header. Numbered sections\\nstart with the section number, which we'd rather
      produce via pandoc.\\n\\n::: {#cb6 .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n```
      {.sourceCode .lua .code-with-copy}\\nfunction Header (h)\\n  -- Unnumbered sections
      have the main contents as the first element.\\n  -- Numbered sections start
      with the number and an em-dash, so\\n  -- the Span is the fifth element (Lua
      multipass).\\n  local span\\n  if h.content[1].tag == 'Str' and h.content[1].text:match
      '[%d%.]+' then\\n    span = h.content[5]\\n  else\\n    span = h.content[1]\\n
      \   h.classes:insert('unnumbered')\\n  end\\n\\n  h.identifier = span.identifier\\n
      \ h.content = span.content\\n\\n  return h\\nend\\n```\\n:::\\n\\nThe filter
      also removes the section numbering. We add it back by passing\\n`--number-sections`
      to pandoc.\\n\\n::: {.quarto-figure .quarto-figure-center}\\n<figure class=\\\"figure\\\">\\n<p><img\\nsrc=\\\"https://tarleb.com/posts/pdf-of-the-lua-manual/less-bad-toc.png\\\"\\nclass=\\\"img-fluid
      figure-img\\\" /></p>\\n<figcaption>less-bad table of contents</figcaption>\\n</figure>\\n:::\\n\\nNot
      bad.\\n:::\\n\\n::: {#improve-title-and-metadata .section .level2}\\n## Improve
      title and metadata {#improve-title-and-metadata .anchored anchor-id=\\\"improve-title-and-metadata\\\"}\\n\\nThe
      PDF is already quite usable, let's prettify it a bit more: It would\\nbe important
      to properly list the authors in the title and metadata,\\nremove the unnecessary
      first header, and maybe add the Lua logo to the\\ntitle. All this is easiest
      when acting on the full document.\\n\\n::: {#cb7 .sourceCode style=\\\"background:
      #f1f3f5;\\\"}\\n``` {.sourceCode .lua .code-with-copy}\\nfunction Pandoc (doc)\\n
      \ -- comma separated authors\\n  local authors = doc.blocks[2]\\n  authors.content:remove(1)
      \ -- remove 'by'\\n  doc.meta.author = pandoc.List()\\n  for author in pandoc.utils.stringify(authors):gmatch
      '[^,]+' do\\n    doc.meta.author:insert(author)\\n  end\\n\\n  -- Remove unnecessary
      blocks\\n  doc.blocks:remove(4) -- menubar\\n  doc.blocks:remove(2) -- authors
      paragraph\\n  doc.blocks:remove(1) -- title header\\n\\n  -- add subtitle image\\n
      \ doc.meta.subtitle = pandoc.MetaInlines{\\n    pandoc.RawInline('latex', '\\\\\\\\vspace{1em}'),\\n
      \   pandoc.Image(\\\"Lua logo\\\", -- \\\"https://www.lua.org/images/lua-logo.gif\\\")\\n
      \ }\\n  return doc\\nend\\n```\\n:::\\n:::\\n\\n::: {#final-touch .section .level2}\\n##
      Final touch {#final-touch .anchored anchor-id=\\\"final-touch\\\"}\\n\\nFinally,
      we may want the PDF to add a little more visible structure,\\ne.g., starting
      top-level sections on their own page.\\n\\nThe command used by pandoc to create
      the top level headings can be\\ncontrolled with the `--top-level-division` option.
      Setting that option\\nto `chapter` ensures that each major section starts on
      a new page.\\nHowever, the default document class used by LaTeX doesn't allow\\nchapters,
      so a different class has to be set with\\n`--variable documentclass=report`.\\n:::\\n\\n:::
      {#summary .section .level2}\\n## Summary {#summary .anchored anchor-id=\\\"summary\\\"}\\n\\nFor
      completeness, [here is the complete filter](lua-manual-cleanup.lua),\\nand this
      is the full pandoc command used to generate the PDF:\\n\\n::: {#cb8 .sourceCode
      style=\\\"background: #f1f3f5;\\\"}\\n``` {.sourceCode .bash .code-with-copy}\\npandoc
      \\\\\\n  --toc \\\\\\n  --toc-depth=2 \\\\\\n  --metadata=documentclass=report
      \\\\\\n  --pdf-engine=xelatex \\\\\\n  --lua-filter=lua-manual-cleanup.lua \\\\\\n
      \ --number-sections \\\\\\n  --top-level-division=chapter \\\\\\n  --output=lua-5.4-manual.pdf
      \\\\\\n  \\\"https://lua.org/manual/5.4/manual.html\\\"\\n```\\n:::\\n\\nOne
      of the big advantages of pandoc is that it offers a lot of freedom.\\nSince
      we already cleaned the content up, we can now also create other\\nformats, like
      an ebook, just by changing the name of the output file.\\nThe final results
      are available below:\\n\\n- [Lua 5.4 manual (PDF)](lua-5.4-manual.pdf)\\n- [Lua
      5.4 manual (EPUB)](lua-5.4-manual.epub)\\n:::\\n\",\"relationships\":[],\"archive_url\":\"https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/pdf-of-the-lua-manual\",\"guid\":\"https://tarleb.com/posts/pdf-of-the-lua-manual/index.html\",\"updated\":false,\"category\":\"computerAndInformationSciences\"}]"
    headers:
      Access-Control-Allow-Origin:
      - '*'
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 8498646ed93b1638-DUS
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Profile:
      - public
      Content-Range:
      - 0-0/*
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Mon, 22 Jan 2024 14:12:31 GMT
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      Via:
      - kong/2.8.1
      X-Kong-Proxy-Latency:
      - '0'
      X-Kong-Upstream-Latency:
      - '3'
      alt-svc:
      - h3=":443"; ma=86400
      sb-gateway-version:
      - '1'
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: '{"authors": [{"name": "Albert Krewinkel"}], "blog_name": "tarleb", "blog_slug":
      "tarleb", "content_text": "My first exposure to Lua has been as a pandoc user,
      and adding new Lua\nfeatures to pandoc turned Lua into one of my favorite languages.
      In this\npost I will take a look at [pandoc](https://pandoc.org/), the universal\ndocument
      converter, and explore how one can script and extend it with\nLua. Pandoc includes
      a Lua interpreter since 2012, but the integration\nof Lua has been expanded
      significantly with the latest 2.0 release. My\nhope for this article is to highlight
      the beauty of these systems.\n\n::: {#the-universal-document-converter .section
      .level2}\n## The universal document converter {#the-universal-document-converter
      .anchored anchor-id=\"the-universal-document-converter\"}\n\n[Pandoc](https://pandoc.org/)
      -- written and maintained by [John\nMacFarlane](https://johnmacfarlane.net)
      -- is an relatively old project.\nIt has grown considerably since the first
      version was published in 2006:\nat the time of writing, pandoc can read 27 different
      document formats\nand dialects, and can write 49 formats. Besides serving as
      a one-off\ndocument conversions tool, pandoc also frequently features as the\ncentral
      part of publishing pipelines. For example, Pandoc is used in\n[static](https://github.com/mfenner/jekyll-pandoc)
      [site\ngenerators](https://jaspervdj.be/hakyll/) and is frequently used [by\nacademic\nwriters](https://programminghistorian.org/lessons/sustainable-authorship-in-plain-text-using-pandoc-and-markdown),\ndue
      also to its excellent support for citations.\n\nAs a brief example, consider
      the following commands which transform\nMarkdown input into docx, HTML, or PDF:\n\n:::
      {#cb1 .sourceCode style=\"background: #f1f3f5;\"}\n``` {.sourceCode .bash .code-with-copy}\n#
      command to convert a markdown file to docx\npandoc input-file.md --output=output-file.docx\n\n#
      convert to HTML\npandoc input-file.md --standalone --output=output-file.html\n\n#
      convert to PDF (via LaTeX)\npandoc input-file.md --output=output-file.pdf\n```\n:::\n\nMany
      conversion tasks need to alter the default behavior or require\nspecial conversion
      features. This highlights the importance of good\ncustomization support for
      a conversion tool, one of the areas in which\nLua shines.\n\nPandoc is unusual
      for a Lua-extendable program, in that it is written in\nHaskell. Using Haskell
      is very productive, but is less suitable as an\nextension language: its concepts
      are often alien to users of other\nlanguages, and shipping a full Haskell interpreter
      with pandoc would\nresult in considerable bloat. Lua is an excellent choice
      here, as it is\nlightweight, simple, and beautiful. It should be noted, however,
      that\n[bridging Haskell and Lua](https://github.com/hslua) is its own can of\nworms
      and worth a separate blog post.\n:::\n\n::: {#pandocs-document-ast .section
      .level2}\n## Pandoc''s document AST {#pandocs-document-ast .anchored anchor-id=\"pandocs-document-ast\"}\n\nAn
      important factor in pandoc''s immense transformation powers is its use\nof a
      unifying document representation: Every input is parsed into this\ndocument
      AST, which is then rendered in the desired output format. While\na direct conversion
      between any of *n* input and *m* output formats\nwould require *n* m\\* converters,
      using an intermediate representation\nreduces complexity to *n + m*.\n\nThere
      are additional advantages to this: as we''ll see, it becomes much\nsimpler to
      work with a unified document representation than it would be\nto work with any
      of the input or output formats directly.\n\nThere are four main types in pandoc''s
      document model: inlines, blocks,\ndocument metadata, and the full document.\n\n-
      Inline elements represent text and text markup. Examples are *Space*\n  for
      inter-word spaces, *Str* for (usually non-whitespace) text, and\n  *Emph* for
      emphasized text.\n\n- Blocks are elements like paragraphs, lists, code listings,
      and\n  headers. They are usually rendered in lines or blocks of their own;\n  many
      block elements contain lists of inline elements.\n\n- Meta information is a
      simple mapping from string keys to meta values.\n  Meta values can be thought
      of as a special JSON or YAML object.\n\n- Last but not least, the *Pandoc* type
      represents a full document. A\n  *Pandoc* element consists of a lists of block
      elements, plus\n  additional document metadata.\n\nPandoc''s Lua features revolve
      around modifying or converting these\nelements. The oldest use of Lua in pandoc
      enables the conversion of AST\nelements into strings as to output any document
      format.\n:::\n\n::: {#custom-writers .section .level2}\n## Custom writers {#custom-writers
      .anchored anchor-id=\"custom-writers\"}\n\nUsers can define custom writers in
      Lua to render any document format.\nEach of the aforementioned AST elements
      is transformed to a string by\ncalling a Lua function of the same name as the
      element. E.g., this\nexample demonstrates how emphasized text can be rendered
      as HTML:\n\n::: {#cb2 .sourceCode style=\"background: #f1f3f5;\"}\n``` {.sourceCode
      .lua .code-with-copy}\nfunction Emph(content_string)\n  return ''<em>'' .. content_string
      .. ''</em>''\nend\n```\n:::\n\nA full custom writer is defined by specifying
      functions for all document\nAST elements. Example writers using this method
      include\n[2bbcode](https://github.com/lilydjwg/2bbcode) by [@lilydjwg (\u4f9d\n\u4e91)](https://github.com/lilydjwg),
      as well as pandoc''s `sample.lua`. The\nlatter is a well documented starting
      point for authors of new custom\nwriters. The file can be produced by calling\n`pandoc
      --print-default-data-file=sample.lua`.\n\nThe [pandoc-scholar](https://pandoc-scholar.github.io/)
      project serves\nas an example for the power offered by custom writers. It is
      a\npublishing tool intended to [help authors of scholarly\narticles](https://doi.org/10.7717/peerj-cs.112)
      and was created with\ncustom Lua writers. The tool leans on the custom writers
      feature in ways\nthat writers were not intended to be used, which resulted in
      the\ndevelopment of lua filters.\n:::\n\n::: {#filters .section .level2}\n##
      Filters {#filters .anchored anchor-id=\"filters\"}\n\nAn additional benefit
      of a unified document type is that the document\ncan be modified programmatically,
      regardless of which input and output\nformat is chosen. Pandoc provides two
      interfaces for this.\n\n::: {#json-filters .section .level3}\n### JSON Filters
      {#json-filters .anchored anchor-id=\"json-filters\"}\n\nThe first -- very flexible
      -- method is based on JSON. Pandoc can\nserialize the document to JSON; other
      programs [can read and\nmodify](https://pandoc.org/filters.html) the document.
      The resulting\ndocument JSON is passed back to pandoc, thus allowing users to
      use any\nprogramming language capable of parsing JSON to alter the document.
      Many\nlibraries for various languages have been implemented, including\n[Haskell](https://hackage.haskell.org/package/pandoc-types),\n[Python](http://scorreia.com/software/panflute/),\n[Ruby](https://heerdebeer.org/Software/markdown/paru/),
      and\n[JavaScript](https://www.npmjs.com/package/pandoc-filter).\n\nThe flexibility
      of JSON filters can also be a disadvantage, as it\nrequires additional software
      and usually the full installation of a\nscripting language''s ecosystem. Pandoc
      is designed to work on all major\nplatforms and without any dependencies on
      other libraries and binaries.\nDepending on additional software can be problematic,
      especially for\nnon-technical users.\n:::\n\n::: {#lua-filters .section .level3}\n###
      Lua filters {#lua-filters .anchored anchor-id=\"lua-filters\"}\n\nThe [Lua filter](https://pandoc.org/lua-filters.html)
      system added in\npandoc 2.0 not only solves the portability issue of JSON filters,
      but\nalso offers better performance and more functionality. Document elements\ncan
      be selectively serialized to Lua tables, modified using the full\npower of Lua,
      and will then be transferred back, thus replacing the\nprevious values.\n\nLua
      filters operate by calling filter functions on each element of the\nspecified
      name. I.e., if a Lua filter contains a function with the same\nname as an AST
      element, then this function is called for all elements of\nthe respective type.
      The serialized element is passed as input to the\nfilter function, and the function''s
      return value is deserialized and\nused to replace the input element. This method
      is as simple as it is\nflexible, and fits well with the concept of immutability
      which is\nprevalent in Haskell programs: pandoc ignores modifications to the\nserialized
      object itself, it will just use the filter function''s return\nvalue.\n\nThe
      following example filter transforms all text set in small caps into\nemphasized
      text:\n\n::: {#cb3 .sourceCode style=\"background: #f1f3f5;\"}\n``` {.sourceCode
      .lua .code-with-copy}\nfunction SmallCaps (element)\n  return pandoc.Emph(element.content)\nend\n```\n:::\n\nThe
      element constructor functions in module pandoc, like `pandoc.Emph`\nin the above
      example, are also the central step when transforming\nelements from their pandoc-internal
      representation to Lua values. This\nensures consistency in the way element values
      are produced, whether\nduring serialization or through a constructor call in
      the filter script.\nThe current implementation uses only strings, tables, and
      some\nmetatables when constructing element values, with the goal of marking\nthese
      values easy and flexible to use.\n:::\n:::\n\n::: {#lua-filter-example-macro-expander
      .section .level2}\n## Lua filter example: macro expander {#lua-filter-example-macro-expander
      .anchored anchor-id=\"lua-filter-example-macro-expander\"}\n\nBelow is the code
      for a simple macro expander using pandoc''s Lua filter\nfunctionality. The expander
      replaces all macro occurrences in the given\ndocument. Macro definitions are
      hard-coded into the filter, but could as\nwell be read from an external file.\n\n:::
      {#cb4 .sourceCode style=\"background: #f1f3f5;\"}\n``` {.sourceCode .lua .code-with-copy}\n--
      file: macro-expander.lua\n\n-- Macro substitutions: contains macro identifier
      as\n-- keys and the expanded inlines as values.\nlocal macro_substs = {\n  [''{{hello}}'']
      = pandoc.Emph{pandoc.Str \"Hello, World!\"}\n}\n\n-- Replace string with macro
      expansion, if any.\nfunction Str (s)\n  return macro_substs[s.text] or s\nend\n```\n:::\n\nThe
      heart of the macro expander is the function `Str`. It is called on\nall simple
      strings in the document. The return value of this function is\nthen read back
      into pandoc, replacing the original `Str` value.\n\nAssume a Markdown file `greeting.md`:\n\n    Greeting:
      {{hello}}\n\nWe can apply the macro expander by calling\n\n::: {#cb6 .sourceCode
      style=\"background: #f1f3f5;\"}\n``` {.sourceCode .bash .code-with-copy}\npandoc
      --lua-filter macro-expander.lua greeting.md\n```\n:::\n\nresulting in the expected
      expansion:\n\n> Greeting: *Hello, World!*\n\nThe function `Str` could be shortened
      further by dropping the trailing\n`or s`:\n\n::: {#cb7 .sourceCode style=\"background:
      #f1f3f5;\"}\n``` {.sourceCode .lua .code-with-copy}\nfunction Str (s) return
      macro_substs[s.text] end\n```\n:::\n\nThis is a convenience feature of pandoc
      filters: if the function returns\nno value (or `nil`), the original value is
      kept unchanged. This makes\nfilter functions easier to write and speeds up filtering,
      as unchanged\nelements don''t need to be deserialized again.\n:::\n\n::: {#whats-good-and-whats-next
      .section .level2}\n## What''s good, and what''s next {#whats-good-and-whats-next
      .anchored anchor-id=\"whats-good-and-whats-next\"}\n\nUsing pandoc with Lua
      is a fast, flexible, and platform independent way\nof augmenting pandoc with
      additional functionality. For me personally,\nhaving the full power of Lua at
      ones finger tips proved to be a lot of\nfun, while opening unexpected document
      processing possibilities.\n\nPandoc and its Lua subsystem are under constant
      development. E.g., the\nnext versions will feature more utility functions exposed
      via Lua\nmodules. There is constant work to make more and more internal functions\navailable.
      The next big goal is to grant scripting access to all\nformat-output functions.
      However, this requires some changes to pandoc''s\ninternals. It remains a long
      way for pandoc to become a fully\nLua-scriptable publishing platform.\n\nIf
      you want to learn more about Lua filters, the [Lua filter\ndocs](https://pandoc.org/lua-filters.html)
      is a good place to start. It\nincludes up-to-date examples of Lua scripts, as
      well as a reference of\nall modules and functions accessible via Lua. Pandoc''s
      [user\nmanual](https://pandoc.org/MANUAL.html) is a good resource to learn\nabout
      all of pandoc features and its command line options.\n\n[Feedback](https://groups.google.com/forum/#!forum/pandoc-discuss)
      is\nalways welcome!\n:::\n\n::: {#acknowledgements .section .level2}\n## Acknowledgements
      {#acknowledgements .anchored anchor-id=\"acknowledgements\"}\n\nA big thank
      you to Jennifer K\u00f6nig, Birgit Pohl, and John MacFarlane for\ntheir feedback
      on an earlier version of this post, and to all pandoc\ncontributors and users,
      who make working on this project incredibly fun.\n:::\n", "images": [], "updated_at":
      1513987200, "published_at": 1513987200, "image": null, "language": "en", "category":
      "computerAndInformationSciences", "reference": [], "relationships": [], "summary":
      "My first exposure to Lua has been as a pandoc user, and adding new Lua features
      to pandoc turned Lua into one of my favorite languages. In this post I will
      take a look at pandoc, the universal document converter, and explore how one
      can script and extend it with Lua. Pandoc includes a Lua interpreter since 2012,
      but the integration of Lua has been expanded significantly with the latest 2.0
      release.\n", "tags": ["Pandoc", "Lua", "Pandoc-filter"], "title": "Extending
      pandoc with Lua", "url": "https://tarleb.com/posts/extending-pandoc-with-lua",
      "guid": "https://tarleb.com/posts/extending-pandoc-with-lua/index.html", "archive_url":
      "https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/extending-pandoc-with-lua"}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      accept-profile:
      - public
      connection:
      - keep-alive
      content-length:
      - '14095'
      content-profile:
      - public
      content-type:
      - application/json
      host:
      - db.rogue-scholar.org
      prefer:
      - return=representation,resolution=merge-duplicates
      user-agent:
      - python-httpx/0.25.2
      x-client-info:
      - supabase-py/2.3.4
    method: POST
    uri: https://db.rogue-scholar.org/rest/v1/posts?on_conflict=guid
  response:
    content: "[{\"url\":\"https://tarleb.com/posts/extending-pandoc-with-lua\",\"title\":\"Extending
      pandoc with Lua\",\"summary\":\"My first exposure to Lua has been as a pandoc
      user, and adding new Lua features to pandoc turned Lua into one of my favorite
      languages. In this post I will take a look at pandoc, the universal document
      converter, and explore how one can script and extend it with Lua. Pandoc includes
      a Lua interpreter since 2012, but the integration of Lua has been expanded significantly
      with the latest 2.0 release.\\n\",\"image\":null,\"tags\":[\"Pandoc\",\"Lua\",\"Pandoc-filter\"],\"language\":\"en\",\"authors\":[{\"name\":
      \"Albert Krewinkel\"}],\"doi\":\"https://doi.org/10.59350/49r3s-rnr41\",\"id\":\"146e7741-5865-42f3-81cc-d1146bbf38f5\",\"reference\":[],\"updated_at\":1513987200,\"published_at\":1513987200,\"blog_name\":\"tarleb\",\"indexed_at\":1700481930,\"indexed\":true,\"images\":[],\"blog_slug\":\"tarleb\",\"content_text\":\"My
      first exposure to Lua has been as a pandoc user, and adding new Lua\\nfeatures
      to pandoc turned Lua into one of my favorite languages. In this\\npost I will
      take a look at [pandoc](https://pandoc.org/), the universal\\ndocument converter,
      and explore how one can script and extend it with\\nLua. Pandoc includes a Lua
      interpreter since 2012, but the integration\\nof Lua has been expanded significantly
      with the latest 2.0 release. My\\nhope for this article is to highlight the
      beauty of these systems.\\n\\n::: {#the-universal-document-converter .section
      .level2}\\n## The universal document converter {#the-universal-document-converter
      .anchored anchor-id=\\\"the-universal-document-converter\\\"}\\n\\n[Pandoc](https://pandoc.org/)
      -- written and maintained by [John\\nMacFarlane](https://johnmacfarlane.net)
      -- is an relatively old project.\\nIt has grown considerably since the first
      version was published in 2006:\\nat the time of writing, pandoc can read 27
      different document formats\\nand dialects, and can write 49 formats. Besides
      serving as a one-off\\ndocument conversions tool, pandoc also frequently features
      as the\\ncentral part of publishing pipelines. For example, Pandoc is used in\\n[static](https://github.com/mfenner/jekyll-pandoc)
      [site\\ngenerators](https://jaspervdj.be/hakyll/) and is frequently used [by\\nacademic\\nwriters](https://programminghistorian.org/lessons/sustainable-authorship-in-plain-text-using-pandoc-and-markdown),\\ndue
      also to its excellent support for citations.\\n\\nAs a brief example, consider
      the following commands which transform\\nMarkdown input into docx, HTML, or
      PDF:\\n\\n::: {#cb1 .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n``` {.sourceCode
      .bash .code-with-copy}\\n# command to convert a markdown file to docx\\npandoc
      input-file.md --output=output-file.docx\\n\\n# convert to HTML\\npandoc input-file.md
      --standalone --output=output-file.html\\n\\n# convert to PDF (via LaTeX)\\npandoc
      input-file.md --output=output-file.pdf\\n```\\n:::\\n\\nMany conversion tasks
      need to alter the default behavior or require\\nspecial conversion features.
      This highlights the importance of good\\ncustomization support for a conversion
      tool, one of the areas in which\\nLua shines.\\n\\nPandoc is unusual for a Lua-extendable
      program, in that it is written in\\nHaskell. Using Haskell is very productive,
      but is less suitable as an\\nextension language: its concepts are often alien
      to users of other\\nlanguages, and shipping a full Haskell interpreter with
      pandoc would\\nresult in considerable bloat. Lua is an excellent choice here,
      as it is\\nlightweight, simple, and beautiful. It should be noted, however,
      that\\n[bridging Haskell and Lua](https://github.com/hslua) is its own can of\\nworms
      and worth a separate blog post.\\n:::\\n\\n::: {#pandocs-document-ast .section
      .level2}\\n## Pandoc's document AST {#pandocs-document-ast .anchored anchor-id=\\\"pandocs-document-ast\\\"}\\n\\nAn
      important factor in pandoc's immense transformation powers is its use\\nof a
      unifying document representation: Every input is parsed into this\\ndocument
      AST, which is then rendered in the desired output format. While\\na direct conversion
      between any of *n* input and *m* output formats\\nwould require *n* m\\\\* converters,
      using an intermediate representation\\nreduces complexity to *n + m*.\\n\\nThere
      are additional advantages to this: as we'll see, it becomes much\\nsimpler to
      work with a unified document representation than it would be\\nto work with
      any of the input or output formats directly.\\n\\nThere are four main types
      in pandoc's document model: inlines, blocks,\\ndocument metadata, and the full
      document.\\n\\n- Inline elements represent text and text markup. Examples are
      *Space*\\n  for inter-word spaces, *Str* for (usually non-whitespace) text,
      and\\n  *Emph* for emphasized text.\\n\\n- Blocks are elements like paragraphs,
      lists, code listings, and\\n  headers. They are usually rendered in lines or
      blocks of their own;\\n  many block elements contain lists of inline elements.\\n\\n-
      Meta information is a simple mapping from string keys to meta values.\\n  Meta
      values can be thought of as a special JSON or YAML object.\\n\\n- Last but not
      least, the *Pandoc* type represents a full document. A\\n  *Pandoc* element
      consists of a lists of block elements, plus\\n  additional document metadata.\\n\\nPandoc's
      Lua features revolve around modifying or converting these\\nelements. The oldest
      use of Lua in pandoc enables the conversion of AST\\nelements into strings as
      to output any document format.\\n:::\\n\\n::: {#custom-writers .section .level2}\\n##
      Custom writers {#custom-writers .anchored anchor-id=\\\"custom-writers\\\"}\\n\\nUsers
      can define custom writers in Lua to render any document format.\\nEach of the
      aforementioned AST elements is transformed to a string by\\ncalling a Lua function
      of the same name as the element. E.g., this\\nexample demonstrates how emphasized
      text can be rendered as HTML:\\n\\n::: {#cb2 .sourceCode style=\\\"background:
      #f1f3f5;\\\"}\\n``` {.sourceCode .lua .code-with-copy}\\nfunction Emph(content_string)\\n
      \ return '<em>' .. content_string .. '</em>'\\nend\\n```\\n:::\\n\\nA full custom
      writer is defined by specifying functions for all document\\nAST elements. Example
      writers using this method include\\n[2bbcode](https://github.com/lilydjwg/2bbcode)
      by [@lilydjwg (\u4F9D\\n\u4E91)](https://github.com/lilydjwg), as well as pandoc's
      `sample.lua`. The\\nlatter is a well documented starting point for authors of
      new custom\\nwriters. The file can be produced by calling\\n`pandoc --print-default-data-file=sample.lua`.\\n\\nThe
      [pandoc-scholar](https://pandoc-scholar.github.io/) project serves\\nas an example
      for the power offered by custom writers. It is a\\npublishing tool intended
      to [help authors of scholarly\\narticles](https://doi.org/10.7717/peerj-cs.112)
      and was created with\\ncustom Lua writers. The tool leans on the custom writers
      feature in ways\\nthat writers were not intended to be used, which resulted
      in the\\ndevelopment of lua filters.\\n:::\\n\\n::: {#filters .section .level2}\\n##
      Filters {#filters .anchored anchor-id=\\\"filters\\\"}\\n\\nAn additional benefit
      of a unified document type is that the document\\ncan be modified programmatically,
      regardless of which input and output\\nformat is chosen. Pandoc provides two
      interfaces for this.\\n\\n::: {#json-filters .section .level3}\\n### JSON Filters
      {#json-filters .anchored anchor-id=\\\"json-filters\\\"}\\n\\nThe first -- very
      flexible -- method is based on JSON. Pandoc can\\nserialize the document to
      JSON; other programs [can read and\\nmodify](https://pandoc.org/filters.html)
      the document. The resulting\\ndocument JSON is passed back to pandoc, thus allowing
      users to use any\\nprogramming language capable of parsing JSON to alter the
      document. Many\\nlibraries for various languages have been implemented, including\\n[Haskell](https://hackage.haskell.org/package/pandoc-types),\\n[Python](http://scorreia.com/software/panflute/),\\n[Ruby](https://heerdebeer.org/Software/markdown/paru/),
      and\\n[JavaScript](https://www.npmjs.com/package/pandoc-filter).\\n\\nThe flexibility
      of JSON filters can also be a disadvantage, as it\\nrequires additional software
      and usually the full installation of a\\nscripting language's ecosystem. Pandoc
      is designed to work on all major\\nplatforms and without any dependencies on
      other libraries and binaries.\\nDepending on additional software can be problematic,
      especially for\\nnon-technical users.\\n:::\\n\\n::: {#lua-filters .section
      .level3}\\n### Lua filters {#lua-filters .anchored anchor-id=\\\"lua-filters\\\"}\\n\\nThe
      [Lua filter](https://pandoc.org/lua-filters.html) system added in\\npandoc 2.0
      not only solves the portability issue of JSON filters, but\\nalso offers better
      performance and more functionality. Document elements\\ncan be selectively serialized
      to Lua tables, modified using the full\\npower of Lua, and will then be transferred
      back, thus replacing the\\nprevious values.\\n\\nLua filters operate by calling
      filter functions on each element of the\\nspecified name. I.e., if a Lua filter
      contains a function with the same\\nname as an AST element, then this function
      is called for all elements of\\nthe respective type. The serialized element
      is passed as input to the\\nfilter function, and the function's return value
      is deserialized and\\nused to replace the input element. This method is as simple
      as it is\\nflexible, and fits well with the concept of immutability which is\\nprevalent
      in Haskell programs: pandoc ignores modifications to the\\nserialized object
      itself, it will just use the filter function's return\\nvalue.\\n\\nThe following
      example filter transforms all text set in small caps into\\nemphasized text:\\n\\n:::
      {#cb3 .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n``` {.sourceCode .lua
      .code-with-copy}\\nfunction SmallCaps (element)\\n  return pandoc.Emph(element.content)\\nend\\n```\\n:::\\n\\nThe
      element constructor functions in module pandoc, like `pandoc.Emph`\\nin the
      above example, are also the central step when transforming\\nelements from their
      pandoc-internal representation to Lua values. This\\nensures consistency in
      the way element values are produced, whether\\nduring serialization or through
      a constructor call in the filter script.\\nThe current implementation uses only
      strings, tables, and some\\nmetatables when constructing element values, with
      the goal of marking\\nthese values easy and flexible to use.\\n:::\\n:::\\n\\n:::
      {#lua-filter-example-macro-expander .section .level2}\\n## Lua filter example:
      macro expander {#lua-filter-example-macro-expander .anchored anchor-id=\\\"lua-filter-example-macro-expander\\\"}\\n\\nBelow
      is the code for a simple macro expander using pandoc's Lua filter\\nfunctionality.
      The expander replaces all macro occurrences in the given\\ndocument. Macro definitions
      are hard-coded into the filter, but could as\\nwell be read from an external
      file.\\n\\n::: {#cb4 .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n``` {.sourceCode
      .lua .code-with-copy}\\n-- file: macro-expander.lua\\n\\n-- Macro substitutions:
      contains macro identifier as\\n-- keys and the expanded inlines as values.\\nlocal
      macro_substs = {\\n  ['{{hello}}'] = pandoc.Emph{pandoc.Str \\\"Hello, World!\\\"}\\n}\\n\\n--
      Replace string with macro expansion, if any.\\nfunction Str (s)\\n  return macro_substs[s.text]
      or s\\nend\\n```\\n:::\\n\\nThe heart of the macro expander is the function
      `Str`. It is called on\\nall simple strings in the document. The return value
      of this function is\\nthen read back into pandoc, replacing the original `Str`
      value.\\n\\nAssume a Markdown file `greeting.md`:\\n\\n    Greeting: {{hello}}\\n\\nWe
      can apply the macro expander by calling\\n\\n::: {#cb6 .sourceCode style=\\\"background:
      #f1f3f5;\\\"}\\n``` {.sourceCode .bash .code-with-copy}\\npandoc --lua-filter
      macro-expander.lua greeting.md\\n```\\n:::\\n\\nresulting in the expected expansion:\\n\\n>
      Greeting: *Hello, World!*\\n\\nThe function `Str` could be shortened further
      by dropping the trailing\\n`or s`:\\n\\n::: {#cb7 .sourceCode style=\\\"background:
      #f1f3f5;\\\"}\\n``` {.sourceCode .lua .code-with-copy}\\nfunction Str (s) return
      macro_substs[s.text] end\\n```\\n:::\\n\\nThis is a convenience feature of pandoc
      filters: if the function returns\\nno value (or `nil`), the original value is
      kept unchanged. This makes\\nfilter functions easier to write and speeds up
      filtering, as unchanged\\nelements don't need to be deserialized again.\\n:::\\n\\n:::
      {#whats-good-and-whats-next .section .level2}\\n## What's good, and what's next
      {#whats-good-and-whats-next .anchored anchor-id=\\\"whats-good-and-whats-next\\\"}\\n\\nUsing
      pandoc with Lua is a fast, flexible, and platform independent way\\nof augmenting
      pandoc with additional functionality. For me personally,\\nhaving the full power
      of Lua at ones finger tips proved to be a lot of\\nfun, while opening unexpected
      document processing possibilities.\\n\\nPandoc and its Lua subsystem are under
      constant development. E.g., the\\nnext versions will feature more utility functions
      exposed via Lua\\nmodules. There is constant work to make more and more internal
      functions\\navailable. The next big goal is to grant scripting access to all\\nformat-output
      functions. However, this requires some changes to pandoc's\\ninternals. It remains
      a long way for pandoc to become a fully\\nLua-scriptable publishing platform.\\n\\nIf
      you want to learn more about Lua filters, the [Lua filter\\ndocs](https://pandoc.org/lua-filters.html)
      is a good place to start. It\\nincludes up-to-date examples of Lua scripts,
      as well as a reference of\\nall modules and functions accessible via Lua. Pandoc's
      [user\\nmanual](https://pandoc.org/MANUAL.html) is a good resource to learn\\nabout
      all of pandoc features and its command line options.\\n\\n[Feedback](https://groups.google.com/forum/#!forum/pandoc-discuss)
      is\\nalways welcome!\\n:::\\n\\n::: {#acknowledgements .section .level2}\\n##
      Acknowledgements {#acknowledgements .anchored anchor-id=\\\"acknowledgements\\\"}\\n\\nA
      big thank you to Jennifer K\xF6nig, Birgit Pohl, and John MacFarlane for\\ntheir
      feedback on an earlier version of this post, and to all pandoc\\ncontributors
      and users, who make working on this project incredibly fun.\\n:::\\n\",\"relationships\":[],\"archive_url\":\"https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/extending-pandoc-with-lua\",\"guid\":\"https://tarleb.com/posts/extending-pandoc-with-lua/index.html\",\"updated\":false,\"category\":\"computerAndInformationSciences\"}]"
    headers:
      Access-Control-Allow-Origin:
      - '*'
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 8498646f49b81638-DUS
      Connection:
      - keep-alive
      Content-Profile:
      - public
      Content-Range:
      - '*/*'
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Mon, 22 Jan 2024 14:12:31 GMT
      Preference-Applied:
      - resolution=merge-duplicates
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      Via:
      - kong/2.8.1
      X-Kong-Proxy-Latency:
      - '0'
      X-Kong-Upstream-Latency:
      - '4'
      alt-svc:
      - h3=":443"; ma=86400
      sb-gateway-version:
      - '1'
    http_version: HTTP/1.1
    status_code: 201
- request:
    body: '{"indexed": true}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      accept-profile:
      - public
      connection:
      - keep-alive
      content-length:
      - '17'
      content-profile:
      - public
      content-type:
      - application/json
      host:
      - db.rogue-scholar.org
      prefer:
      - return=representation
      user-agent:
      - python-httpx/0.25.2
      x-client-info:
      - supabase-py/2.3.4
    method: PATCH
    uri: https://db.rogue-scholar.org/rest/v1/posts?id=eq.146e7741-5865-42f3-81cc-d1146bbf38f5
  response:
    content: "[{\"url\":\"https://tarleb.com/posts/extending-pandoc-with-lua\",\"title\":\"Extending
      pandoc with Lua\",\"summary\":\"My first exposure to Lua has been as a pandoc
      user, and adding new Lua features to pandoc turned Lua into one of my favorite
      languages. In this post I will take a look at pandoc, the universal document
      converter, and explore how one can script and extend it with Lua. Pandoc includes
      a Lua interpreter since 2012, but the integration of Lua has been expanded significantly
      with the latest 2.0 release.\\n\",\"image\":null,\"tags\":[\"Pandoc\",\"Lua\",\"Pandoc-filter\"],\"language\":\"en\",\"authors\":[{\"name\":
      \"Albert Krewinkel\"}],\"doi\":\"https://doi.org/10.59350/49r3s-rnr41\",\"id\":\"146e7741-5865-42f3-81cc-d1146bbf38f5\",\"reference\":[],\"updated_at\":1513987200,\"published_at\":1513987200,\"blog_name\":\"tarleb\",\"indexed_at\":1700481930,\"indexed\":true,\"images\":[],\"blog_slug\":\"tarleb\",\"content_text\":\"My
      first exposure to Lua has been as a pandoc user, and adding new Lua\\nfeatures
      to pandoc turned Lua into one of my favorite languages. In this\\npost I will
      take a look at [pandoc](https://pandoc.org/), the universal\\ndocument converter,
      and explore how one can script and extend it with\\nLua. Pandoc includes a Lua
      interpreter since 2012, but the integration\\nof Lua has been expanded significantly
      with the latest 2.0 release. My\\nhope for this article is to highlight the
      beauty of these systems.\\n\\n::: {#the-universal-document-converter .section
      .level2}\\n## The universal document converter {#the-universal-document-converter
      .anchored anchor-id=\\\"the-universal-document-converter\\\"}\\n\\n[Pandoc](https://pandoc.org/)
      -- written and maintained by [John\\nMacFarlane](https://johnmacfarlane.net)
      -- is an relatively old project.\\nIt has grown considerably since the first
      version was published in 2006:\\nat the time of writing, pandoc can read 27
      different document formats\\nand dialects, and can write 49 formats. Besides
      serving as a one-off\\ndocument conversions tool, pandoc also frequently features
      as the\\ncentral part of publishing pipelines. For example, Pandoc is used in\\n[static](https://github.com/mfenner/jekyll-pandoc)
      [site\\ngenerators](https://jaspervdj.be/hakyll/) and is frequently used [by\\nacademic\\nwriters](https://programminghistorian.org/lessons/sustainable-authorship-in-plain-text-using-pandoc-and-markdown),\\ndue
      also to its excellent support for citations.\\n\\nAs a brief example, consider
      the following commands which transform\\nMarkdown input into docx, HTML, or
      PDF:\\n\\n::: {#cb1 .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n``` {.sourceCode
      .bash .code-with-copy}\\n# command to convert a markdown file to docx\\npandoc
      input-file.md --output=output-file.docx\\n\\n# convert to HTML\\npandoc input-file.md
      --standalone --output=output-file.html\\n\\n# convert to PDF (via LaTeX)\\npandoc
      input-file.md --output=output-file.pdf\\n```\\n:::\\n\\nMany conversion tasks
      need to alter the default behavior or require\\nspecial conversion features.
      This highlights the importance of good\\ncustomization support for a conversion
      tool, one of the areas in which\\nLua shines.\\n\\nPandoc is unusual for a Lua-extendable
      program, in that it is written in\\nHaskell. Using Haskell is very productive,
      but is less suitable as an\\nextension language: its concepts are often alien
      to users of other\\nlanguages, and shipping a full Haskell interpreter with
      pandoc would\\nresult in considerable bloat. Lua is an excellent choice here,
      as it is\\nlightweight, simple, and beautiful. It should be noted, however,
      that\\n[bridging Haskell and Lua](https://github.com/hslua) is its own can of\\nworms
      and worth a separate blog post.\\n:::\\n\\n::: {#pandocs-document-ast .section
      .level2}\\n## Pandoc's document AST {#pandocs-document-ast .anchored anchor-id=\\\"pandocs-document-ast\\\"}\\n\\nAn
      important factor in pandoc's immense transformation powers is its use\\nof a
      unifying document representation: Every input is parsed into this\\ndocument
      AST, which is then rendered in the desired output format. While\\na direct conversion
      between any of *n* input and *m* output formats\\nwould require *n* m\\\\* converters,
      using an intermediate representation\\nreduces complexity to *n + m*.\\n\\nThere
      are additional advantages to this: as we'll see, it becomes much\\nsimpler to
      work with a unified document representation than it would be\\nto work with
      any of the input or output formats directly.\\n\\nThere are four main types
      in pandoc's document model: inlines, blocks,\\ndocument metadata, and the full
      document.\\n\\n- Inline elements represent text and text markup. Examples are
      *Space*\\n  for inter-word spaces, *Str* for (usually non-whitespace) text,
      and\\n  *Emph* for emphasized text.\\n\\n- Blocks are elements like paragraphs,
      lists, code listings, and\\n  headers. They are usually rendered in lines or
      blocks of their own;\\n  many block elements contain lists of inline elements.\\n\\n-
      Meta information is a simple mapping from string keys to meta values.\\n  Meta
      values can be thought of as a special JSON or YAML object.\\n\\n- Last but not
      least, the *Pandoc* type represents a full document. A\\n  *Pandoc* element
      consists of a lists of block elements, plus\\n  additional document metadata.\\n\\nPandoc's
      Lua features revolve around modifying or converting these\\nelements. The oldest
      use of Lua in pandoc enables the conversion of AST\\nelements into strings as
      to output any document format.\\n:::\\n\\n::: {#custom-writers .section .level2}\\n##
      Custom writers {#custom-writers .anchored anchor-id=\\\"custom-writers\\\"}\\n\\nUsers
      can define custom writers in Lua to render any document format.\\nEach of the
      aforementioned AST elements is transformed to a string by\\ncalling a Lua function
      of the same name as the element. E.g., this\\nexample demonstrates how emphasized
      text can be rendered as HTML:\\n\\n::: {#cb2 .sourceCode style=\\\"background:
      #f1f3f5;\\\"}\\n``` {.sourceCode .lua .code-with-copy}\\nfunction Emph(content_string)\\n
      \ return '<em>' .. content_string .. '</em>'\\nend\\n```\\n:::\\n\\nA full custom
      writer is defined by specifying functions for all document\\nAST elements. Example
      writers using this method include\\n[2bbcode](https://github.com/lilydjwg/2bbcode)
      by [@lilydjwg (\u4F9D\\n\u4E91)](https://github.com/lilydjwg), as well as pandoc's
      `sample.lua`. The\\nlatter is a well documented starting point for authors of
      new custom\\nwriters. The file can be produced by calling\\n`pandoc --print-default-data-file=sample.lua`.\\n\\nThe
      [pandoc-scholar](https://pandoc-scholar.github.io/) project serves\\nas an example
      for the power offered by custom writers. It is a\\npublishing tool intended
      to [help authors of scholarly\\narticles](https://doi.org/10.7717/peerj-cs.112)
      and was created with\\ncustom Lua writers. The tool leans on the custom writers
      feature in ways\\nthat writers were not intended to be used, which resulted
      in the\\ndevelopment of lua filters.\\n:::\\n\\n::: {#filters .section .level2}\\n##
      Filters {#filters .anchored anchor-id=\\\"filters\\\"}\\n\\nAn additional benefit
      of a unified document type is that the document\\ncan be modified programmatically,
      regardless of which input and output\\nformat is chosen. Pandoc provides two
      interfaces for this.\\n\\n::: {#json-filters .section .level3}\\n### JSON Filters
      {#json-filters .anchored anchor-id=\\\"json-filters\\\"}\\n\\nThe first -- very
      flexible -- method is based on JSON. Pandoc can\\nserialize the document to
      JSON; other programs [can read and\\nmodify](https://pandoc.org/filters.html)
      the document. The resulting\\ndocument JSON is passed back to pandoc, thus allowing
      users to use any\\nprogramming language capable of parsing JSON to alter the
      document. Many\\nlibraries for various languages have been implemented, including\\n[Haskell](https://hackage.haskell.org/package/pandoc-types),\\n[Python](http://scorreia.com/software/panflute/),\\n[Ruby](https://heerdebeer.org/Software/markdown/paru/),
      and\\n[JavaScript](https://www.npmjs.com/package/pandoc-filter).\\n\\nThe flexibility
      of JSON filters can also be a disadvantage, as it\\nrequires additional software
      and usually the full installation of a\\nscripting language's ecosystem. Pandoc
      is designed to work on all major\\nplatforms and without any dependencies on
      other libraries and binaries.\\nDepending on additional software can be problematic,
      especially for\\nnon-technical users.\\n:::\\n\\n::: {#lua-filters .section
      .level3}\\n### Lua filters {#lua-filters .anchored anchor-id=\\\"lua-filters\\\"}\\n\\nThe
      [Lua filter](https://pandoc.org/lua-filters.html) system added in\\npandoc 2.0
      not only solves the portability issue of JSON filters, but\\nalso offers better
      performance and more functionality. Document elements\\ncan be selectively serialized
      to Lua tables, modified using the full\\npower of Lua, and will then be transferred
      back, thus replacing the\\nprevious values.\\n\\nLua filters operate by calling
      filter functions on each element of the\\nspecified name. I.e., if a Lua filter
      contains a function with the same\\nname as an AST element, then this function
      is called for all elements of\\nthe respective type. The serialized element
      is passed as input to the\\nfilter function, and the function's return value
      is deserialized and\\nused to replace the input element. This method is as simple
      as it is\\nflexible, and fits well with the concept of immutability which is\\nprevalent
      in Haskell programs: pandoc ignores modifications to the\\nserialized object
      itself, it will just use the filter function's return\\nvalue.\\n\\nThe following
      example filter transforms all text set in small caps into\\nemphasized text:\\n\\n:::
      {#cb3 .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n``` {.sourceCode .lua
      .code-with-copy}\\nfunction SmallCaps (element)\\n  return pandoc.Emph(element.content)\\nend\\n```\\n:::\\n\\nThe
      element constructor functions in module pandoc, like `pandoc.Emph`\\nin the
      above example, are also the central step when transforming\\nelements from their
      pandoc-internal representation to Lua values. This\\nensures consistency in
      the way element values are produced, whether\\nduring serialization or through
      a constructor call in the filter script.\\nThe current implementation uses only
      strings, tables, and some\\nmetatables when constructing element values, with
      the goal of marking\\nthese values easy and flexible to use.\\n:::\\n:::\\n\\n:::
      {#lua-filter-example-macro-expander .section .level2}\\n## Lua filter example:
      macro expander {#lua-filter-example-macro-expander .anchored anchor-id=\\\"lua-filter-example-macro-expander\\\"}\\n\\nBelow
      is the code for a simple macro expander using pandoc's Lua filter\\nfunctionality.
      The expander replaces all macro occurrences in the given\\ndocument. Macro definitions
      are hard-coded into the filter, but could as\\nwell be read from an external
      file.\\n\\n::: {#cb4 .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n``` {.sourceCode
      .lua .code-with-copy}\\n-- file: macro-expander.lua\\n\\n-- Macro substitutions:
      contains macro identifier as\\n-- keys and the expanded inlines as values.\\nlocal
      macro_substs = {\\n  ['{{hello}}'] = pandoc.Emph{pandoc.Str \\\"Hello, World!\\\"}\\n}\\n\\n--
      Replace string with macro expansion, if any.\\nfunction Str (s)\\n  return macro_substs[s.text]
      or s\\nend\\n```\\n:::\\n\\nThe heart of the macro expander is the function
      `Str`. It is called on\\nall simple strings in the document. The return value
      of this function is\\nthen read back into pandoc, replacing the original `Str`
      value.\\n\\nAssume a Markdown file `greeting.md`:\\n\\n    Greeting: {{hello}}\\n\\nWe
      can apply the macro expander by calling\\n\\n::: {#cb6 .sourceCode style=\\\"background:
      #f1f3f5;\\\"}\\n``` {.sourceCode .bash .code-with-copy}\\npandoc --lua-filter
      macro-expander.lua greeting.md\\n```\\n:::\\n\\nresulting in the expected expansion:\\n\\n>
      Greeting: *Hello, World!*\\n\\nThe function `Str` could be shortened further
      by dropping the trailing\\n`or s`:\\n\\n::: {#cb7 .sourceCode style=\\\"background:
      #f1f3f5;\\\"}\\n``` {.sourceCode .lua .code-with-copy}\\nfunction Str (s) return
      macro_substs[s.text] end\\n```\\n:::\\n\\nThis is a convenience feature of pandoc
      filters: if the function returns\\nno value (or `nil`), the original value is
      kept unchanged. This makes\\nfilter functions easier to write and speeds up
      filtering, as unchanged\\nelements don't need to be deserialized again.\\n:::\\n\\n:::
      {#whats-good-and-whats-next .section .level2}\\n## What's good, and what's next
      {#whats-good-and-whats-next .anchored anchor-id=\\\"whats-good-and-whats-next\\\"}\\n\\nUsing
      pandoc with Lua is a fast, flexible, and platform independent way\\nof augmenting
      pandoc with additional functionality. For me personally,\\nhaving the full power
      of Lua at ones finger tips proved to be a lot of\\nfun, while opening unexpected
      document processing possibilities.\\n\\nPandoc and its Lua subsystem are under
      constant development. E.g., the\\nnext versions will feature more utility functions
      exposed via Lua\\nmodules. There is constant work to make more and more internal
      functions\\navailable. The next big goal is to grant scripting access to all\\nformat-output
      functions. However, this requires some changes to pandoc's\\ninternals. It remains
      a long way for pandoc to become a fully\\nLua-scriptable publishing platform.\\n\\nIf
      you want to learn more about Lua filters, the [Lua filter\\ndocs](https://pandoc.org/lua-filters.html)
      is a good place to start. It\\nincludes up-to-date examples of Lua scripts,
      as well as a reference of\\nall modules and functions accessible via Lua. Pandoc's
      [user\\nmanual](https://pandoc.org/MANUAL.html) is a good resource to learn\\nabout
      all of pandoc features and its command line options.\\n\\n[Feedback](https://groups.google.com/forum/#!forum/pandoc-discuss)
      is\\nalways welcome!\\n:::\\n\\n::: {#acknowledgements .section .level2}\\n##
      Acknowledgements {#acknowledgements .anchored anchor-id=\\\"acknowledgements\\\"}\\n\\nA
      big thank you to Jennifer K\xF6nig, Birgit Pohl, and John MacFarlane for\\ntheir
      feedback on an earlier version of this post, and to all pandoc\\ncontributors
      and users, who make working on this project incredibly fun.\\n:::\\n\",\"relationships\":[],\"archive_url\":\"https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/extending-pandoc-with-lua\",\"guid\":\"https://tarleb.com/posts/extending-pandoc-with-lua/index.html\",\"updated\":false,\"category\":\"computerAndInformationSciences\"}]"
    headers:
      Access-Control-Allow-Origin:
      - '*'
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 8498646fca6d1638-DUS
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Profile:
      - public
      Content-Range:
      - 0-0/*
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Mon, 22 Jan 2024 14:12:31 GMT
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      Via:
      - kong/2.8.1
      X-Kong-Proxy-Latency:
      - '1'
      X-Kong-Upstream-Latency:
      - '3'
      alt-svc:
      - h3=":443"; ma=86400
      sb-gateway-version:
      - '1'
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: '{"authors": [{"name": "Albert Krewinkel"}], "blog_name": "tarleb", "blog_slug":
      "tarleb", "content_text": "Last night was the night of this year''s MetaNook.
      It was the fourth time\nthat the local hackers, most notably [MetaMeute](https://metameute.de)\nand
      [Chaotikum](https://chaotikum.org), joined forces to organize a\nnight full
      of beginner-friendly introductions, advanced tech talks, and\nproject presentations.\n\nMy
      [talk contribution](https://github.com/tarleb/shell-talk) this year\nwas a brief
      introduction in the \"magic\" of the command-line. The talk\nslides are adapted
      to the topic in that the presentation must be given\nfrom the command line.
      Each slide is just a function, the whole\npresentation environment is held together
      by scripts and other\nshell-equivalences of duckt-tape. Feedback from the thirty
      or-so\nattendees was mostly positive.\n\nIt was a very fun experience over all,
      as usual.\n", "images": [], "updated_at": 1416614400, "published_at": 1416614400,
      "image": null, "language": "en", "category": "computerAndInformationSciences",
      "reference": [], "relationships": [], "summary": "Last night was the night of
      this year\u2019s MetaNook. It was the fourth time that the local hackers, most
      notably MetaMeute and Chaotikum, joined forces to organize a night full of beginner-friendly
      introductions, advanced tech talks, and project presentations. My talk contribution
      this year was a brief introduction in the \u201cmagic\u201d of the command-line.\n",
      "tags": ["Talk", "Command-line"], "title": "MetaNook2014 \u2013 Command Line
      Talk", "url": "https://tarleb.com/posts/nook-2014", "guid": "https://tarleb.com/posts/nook-2014/index.html",
      "archive_url": "https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/nook-2014"}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      accept-profile:
      - public
      connection:
      - keep-alive
      content-length:
      - '1776'
      content-profile:
      - public
      content-type:
      - application/json
      host:
      - db.rogue-scholar.org
      prefer:
      - return=representation,resolution=merge-duplicates
      user-agent:
      - python-httpx/0.25.2
      x-client-info:
      - supabase-py/2.3.4
    method: POST
    uri: https://db.rogue-scholar.org/rest/v1/posts?on_conflict=guid
  response:
    content: "[{\"url\":\"https://tarleb.com/posts/nook-2014\",\"title\":\"MetaNook2014
      \u2013 Command Line Talk\",\"summary\":\"Last night was the night of this year\u2019s
      MetaNook. It was the fourth time that the local hackers, most notably MetaMeute
      and Chaotikum, joined forces to organize a night full of beginner-friendly introductions,
      advanced tech talks, and project presentations. My talk contribution this year
      was a brief introduction in the \u201Cmagic\u201D of the command-line.\\n\",\"image\":null,\"tags\":[\"Talk\",\"Command-line\"],\"language\":\"en\",\"authors\":[{\"name\":
      \"Albert Krewinkel\"}],\"doi\":\"https://doi.org/10.59350/6gm9g-pzs97\",\"id\":\"3b609a34-a6cd-4dd4-a075-67f9418e7d8f\",\"reference\":[],\"updated_at\":1416614400,\"published_at\":1416614400,\"blog_name\":\"tarleb\",\"indexed_at\":1700482681,\"indexed\":true,\"images\":[],\"blog_slug\":\"tarleb\",\"content_text\":\"Last
      night was the night of this year's MetaNook. It was the fourth time\\nthat the
      local hackers, most notably [MetaMeute](https://metameute.de)\\nand [Chaotikum](https://chaotikum.org),
      joined forces to organize a\\nnight full of beginner-friendly introductions,
      advanced tech talks, and\\nproject presentations.\\n\\nMy [talk contribution](https://github.com/tarleb/shell-talk)
      this year\\nwas a brief introduction in the \\\"magic\\\" of the command-line.
      The talk\\nslides are adapted to the topic in that the presentation must be
      given\\nfrom the command line. Each slide is just a function, the whole\\npresentation
      environment is held together by scripts and other\\nshell-equivalences of duckt-tape.
      Feedback from the thirty or-so\\nattendees was mostly positive.\\n\\nIt was
      a very fun experience over all, as usual.\\n\",\"relationships\":[],\"archive_url\":\"https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/nook-2014\",\"guid\":\"https://tarleb.com/posts/nook-2014/index.html\",\"updated\":false,\"category\":\"computerAndInformationSciences\"}]"
    headers:
      Access-Control-Allow-Origin:
      - '*'
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 849864702ad31638-DUS
      Connection:
      - keep-alive
      Content-Profile:
      - public
      Content-Range:
      - '*/*'
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Mon, 22 Jan 2024 14:12:31 GMT
      Preference-Applied:
      - resolution=merge-duplicates
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      Via:
      - kong/2.8.1
      X-Kong-Proxy-Latency:
      - '0'
      X-Kong-Upstream-Latency:
      - '3'
      alt-svc:
      - h3=":443"; ma=86400
      sb-gateway-version:
      - '1'
    http_version: HTTP/1.1
    status_code: 201
- request:
    body: '{"indexed": true}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      accept-profile:
      - public
      connection:
      - keep-alive
      content-length:
      - '17'
      content-profile:
      - public
      content-type:
      - application/json
      host:
      - db.rogue-scholar.org
      prefer:
      - return=representation
      user-agent:
      - python-httpx/0.25.2
      x-client-info:
      - supabase-py/2.3.4
    method: PATCH
    uri: https://db.rogue-scholar.org/rest/v1/posts?id=eq.3b609a34-a6cd-4dd4-a075-67f9418e7d8f
  response:
    content: "[{\"url\":\"https://tarleb.com/posts/nook-2014\",\"title\":\"MetaNook2014
      \u2013 Command Line Talk\",\"summary\":\"Last night was the night of this year\u2019s
      MetaNook. It was the fourth time that the local hackers, most notably MetaMeute
      and Chaotikum, joined forces to organize a night full of beginner-friendly introductions,
      advanced tech talks, and project presentations. My talk contribution this year
      was a brief introduction in the \u201Cmagic\u201D of the command-line.\\n\",\"image\":null,\"tags\":[\"Talk\",\"Command-line\"],\"language\":\"en\",\"authors\":[{\"name\":
      \"Albert Krewinkel\"}],\"doi\":\"https://doi.org/10.59350/6gm9g-pzs97\",\"id\":\"3b609a34-a6cd-4dd4-a075-67f9418e7d8f\",\"reference\":[],\"updated_at\":1416614400,\"published_at\":1416614400,\"blog_name\":\"tarleb\",\"indexed_at\":1700482681,\"indexed\":true,\"images\":[],\"blog_slug\":\"tarleb\",\"content_text\":\"Last
      night was the night of this year's MetaNook. It was the fourth time\\nthat the
      local hackers, most notably [MetaMeute](https://metameute.de)\\nand [Chaotikum](https://chaotikum.org),
      joined forces to organize a\\nnight full of beginner-friendly introductions,
      advanced tech talks, and\\nproject presentations.\\n\\nMy [talk contribution](https://github.com/tarleb/shell-talk)
      this year\\nwas a brief introduction in the \\\"magic\\\" of the command-line.
      The talk\\nslides are adapted to the topic in that the presentation must be
      given\\nfrom the command line. Each slide is just a function, the whole\\npresentation
      environment is held together by scripts and other\\nshell-equivalences of duckt-tape.
      Feedback from the thirty or-so\\nattendees was mostly positive.\\n\\nIt was
      a very fun experience over all, as usual.\\n\",\"relationships\":[],\"archive_url\":\"https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/nook-2014\",\"guid\":\"https://tarleb.com/posts/nook-2014/index.html\",\"updated\":false,\"category\":\"computerAndInformationSciences\"}]"
    headers:
      Access-Control-Allow-Origin:
      - '*'
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 849864709b711638-DUS
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Profile:
      - public
      Content-Range:
      - 0-0/*
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Mon, 22 Jan 2024 14:12:31 GMT
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      Via:
      - kong/2.8.1
      X-Kong-Proxy-Latency:
      - '1'
      X-Kong-Upstream-Latency:
      - '2'
      alt-svc:
      - h3=":443"; ma=86400
      sb-gateway-version:
      - '1'
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: '{"authors": [{"name": "Albert Krewinkel"}], "blog_name": "tarleb", "blog_slug":
      "tarleb", "content_text": "The zeitkraut server is configured to work with IPv6.
      For quite some\ntime now, I''ve been seeing some strange errors in my log files.
      If\nyou''ve been noticing something similar, here is what''s going on and how\nto
      prevent the messages from appearing.\n\n::: {#the-problem .section .level2}\n##
      The Problem {#the-problem .anchored anchor-id=\"the-problem\"}\n\nEverything
      works as expected, except for some weird messages in the\nlogs:\n\n    rt6_redirect:
      source isn''t a valid nexthop for redirect target\n\nNot even [startpage](https://startpage.com)
      was of much help. Searching\nfor the above line only lists only some\n[unanswered](http://ubuntuforums.org/archive/index.php/t-1947743.html)\n[forum](http://board.gulli.com/thread/1699675-rt6-redirect-source-isn-t-a-valid-nexthop/)\nquestions
      and the kernel source code which is producing the message. Oh,\nand a somewhat
      unhelpful blog entry\n[telling](https://www.kernel-error.de/kernel-error-blog/189-rt6-redirect-source-isn-t-a-valid-nexthop-for-redirect-target)\npeople
      to always use their routers link local address when routing. This\nis useless
      advice in my case, I don''t *have* a link-local address of the\nrouter, only
      it''s global address.\n:::\n\n::: {#the-cause .section .level2}\n## The Cause
      {#the-cause .anchored anchor-id=\"the-cause\"}\n\nI found a way to stop the
      message from appearing in my logs. On the way,\nI learned a bit more about IPv6
      and improved server security on the way.\n\nIPv6 contains functionality to tell
      a computer about better routes to\nthe target destination. A router may send
      ICMPv6 redirect packages (type\n137 to be specific), informing neighboring computers
      about more\neffective ways to reach their targets. This makes the most sense
      when\napplied within an environment heavily relying on auto-configuration --\nlike
      a dynamic internal company or home network. It makes a lot less\nsense for servers
      very stable network topologies.\n\nAttackers may try to exploit the redirect
      functionality by including\nthemselves into the route to the target. The specification
      for those\nredirects includes some security-measures, requiring the attacker
      to\ncorrectly guess the server''s current next hop. If the attackers get it\nwrong,
      the Linux kernel refuses to use the new routing information. This\nis most-likely
      what happens when you see the above log messages.\n:::\n\n::: {#the-solution
      .section .level2}\n## The Solution {#the-solution .anchored anchor-id=\"the-solution\"}\n\nLong
      talk short, the solution is to disable IPv6 redirecting:\n\n    sudo sysctl
      net.ipv6.conf.all.accept_redirects=0\n\nMy server is not a router, so there
      is no need to accept any kind of\nroute changing messages from external sources.
      We can simply disable\nredirects, using above command. The change can be made
      permanent by\nsetting the value in `/etc/sysctl.conf`. In fact, we can disable
      routing\nfor both IPv4 and IPv6. Be careful though, you might happen to be in
      a\nnetwork environment requiring you to accept redirect commands for some\nreason.\n\nIf
      you are on Debian or similar distribution like Ubuntu, change the\nfollowing
      lines in `/etc/sysctl.conf` from\n\n    # Do not accept ICMP redirects (prevent
      MITM attacks)\n    #net.ipv4.conf.all.accept_redirects = 0\n    #net.ipv6.conf.all.accept_redirects
      = 0\n    # _or_\n    # Accept ICMP redirects only for gateways listed in our
      default\n    # gateway list (enabled by default)\n    # net.ipv4.conf.all.secure_redirects
      = 1\n    #\n    # Do not send ICMP redirects (we are not a router)\n    #net.ipv4.conf.all.send_redirects
      = 0\n    #\n    # Do not accept IP source route packets (we are not a router)\n    #net.ipv4.conf.all.accept_source_route
      = 0\n    #net.ipv6.conf.all.accept_source_route = 0\n\nto\n\n    # Do not accept
      ICMP redirects (prevent MITM attacks)\n    net.ipv4.conf.all.accept_redirects
      = 0\n    net.ipv6.conf.all.accept_redirects = 0\n    #\n    # Do not send ICMP
      redirects (we are not a router)\n    net.ipv4.conf.all.send_redirects = 0\n    #\n    #
      Do not accept IP source route packets (we are not a router)\n    net.ipv4.conf.all.accept_source_route
      = 0\n    net.ipv6.conf.all.accept_source_route = 0\n\nRunning `sudo sysctl -p`
      loads the new settings.\n:::\n\n::: {#alternative-solution .section .level2}\n##
      Alternative Solution {#alternative-solution .anchored anchor-id=\"alternative-solution\"}\n\nCompletely
      disabling redirects in the kernel should keep you reasonably\nsecure. However,
      if you need redirects within your internal network, you\ncould also block redirect
      packages reaching you through external\ninterfaces. E.g., to block redirect
      packages coming in on eth1, one\nwould issue\n\n    sudo ip6tables -A -i eth1
      -p icmpv6 --icmpv6-type 137 -j DROP\n\nHowever, firewall configuration is a
      complex topic, so I''m not going to\ngo into details here.\n\nIf you have any
      questions, corrections or comments on the matter, please\ndrop me a line.\n:::\n",
      "images": [], "updated_at": 1406851200, "published_at": 1406851200, "image":
      null, "language": "en", "category": "computerAndInformationSciences", "reference":
      [], "relationships": [], "summary": "The zeitkraut server is configured to work
      with IPv6. For quite some time now, I\u2019ve been seeing some strange errors
      in my log files. If you\u2019ve been noticing something similar, here is what\u2019s
      going on and how to prevent the messages from appearing. The Problem   Everything
      works as expected, except for some weird messages in the logs: rt6_redirect:
      source isn''t a valid nexthop for redirect target  Not even startpage was of
      much help.\n", "tags": ["Security", "Sysadmin"], "title": "rt6_redirect: source
      isn\u2019t a valid nexthop for redirect target", "url": "https://tarleb.com/posts/rt6_redirect",
      "guid": "https://tarleb.com/posts/rt6_redirect/index.html", "archive_url": "https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/rt6_redirect"}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      accept-profile:
      - public
      connection:
      - keep-alive
      content-length:
      - '6022'
      content-profile:
      - public
      content-type:
      - application/json
      host:
      - db.rogue-scholar.org
      prefer:
      - return=representation,resolution=merge-duplicates
      user-agent:
      - python-httpx/0.25.2
      x-client-info:
      - supabase-py/2.3.4
    method: POST
    uri: https://db.rogue-scholar.org/rest/v1/posts?on_conflict=guid
  response:
    content: "[{\"url\":\"https://tarleb.com/posts/rt6_redirect\",\"title\":\"rt6_redirect:
      source isn\u2019t a valid nexthop for redirect target\",\"summary\":\"The zeitkraut
      server is configured to work with IPv6. For quite some time now, I\u2019ve been
      seeing some strange errors in my log files. If you\u2019ve been noticing something
      similar, here is what\u2019s going on and how to prevent the messages from appearing.
      The Problem   Everything works as expected, except for some weird messages in
      the logs: rt6_redirect: source isn't a valid nexthop for redirect target  Not
      even startpage was of much help.\\n\",\"image\":null,\"tags\":[\"Security\",\"Sysadmin\"],\"language\":\"en\",\"authors\":[{\"name\":
      \"Albert Krewinkel\"}],\"doi\":\"https://doi.org/10.59350/eek5z-xdj13\",\"id\":\"e0cd3729-73cd-43b4-a2e7-079bf5618506\",\"reference\":[],\"updated_at\":1406851200,\"published_at\":1406851200,\"blog_name\":\"tarleb\",\"indexed_at\":1700483671,\"indexed\":true,\"images\":[],\"blog_slug\":\"tarleb\",\"content_text\":\"The
      zeitkraut server is configured to work with IPv6. For quite some\\ntime now,
      I've been seeing some strange errors in my log files. If\\nyou've been noticing
      something similar, here is what's going on and how\\nto prevent the messages
      from appearing.\\n\\n::: {#the-problem .section .level2}\\n## The Problem {#the-problem
      .anchored anchor-id=\\\"the-problem\\\"}\\n\\nEverything works as expected,
      except for some weird messages in the\\nlogs:\\n\\n    rt6_redirect: source
      isn't a valid nexthop for redirect target\\n\\nNot even [startpage](https://startpage.com)
      was of much help. Searching\\nfor the above line only lists only some\\n[unanswered](http://ubuntuforums.org/archive/index.php/t-1947743.html)\\n[forum](http://board.gulli.com/thread/1699675-rt6-redirect-source-isn-t-a-valid-nexthop/)\\nquestions
      and the kernel source code which is producing the message. Oh,\\nand a somewhat
      unhelpful blog entry\\n[telling](https://www.kernel-error.de/kernel-error-blog/189-rt6-redirect-source-isn-t-a-valid-nexthop-for-redirect-target)\\npeople
      to always use their routers link local address when routing. This\\nis useless
      advice in my case, I don't *have* a link-local address of the\\nrouter, only
      it's global address.\\n:::\\n\\n::: {#the-cause .section .level2}\\n## The Cause
      {#the-cause .anchored anchor-id=\\\"the-cause\\\"}\\n\\nI found a way to stop
      the message from appearing in my logs. On the way,\\nI learned a bit more about
      IPv6 and improved server security on the way.\\n\\nIPv6 contains functionality
      to tell a computer about better routes to\\nthe target destination. A router
      may send ICMPv6 redirect packages (type\\n137 to be specific), informing neighboring
      computers about more\\neffective ways to reach their targets. This makes the
      most sense when\\napplied within an environment heavily relying on auto-configuration
      --\\nlike a dynamic internal company or home network. It makes a lot less\\nsense
      for servers very stable network topologies.\\n\\nAttackers may try to exploit
      the redirect functionality by including\\nthemselves into the route to the target.
      The specification for those\\nredirects includes some security-measures, requiring
      the attacker to\\ncorrectly guess the server's current next hop. If the attackers
      get it\\nwrong, the Linux kernel refuses to use the new routing information.
      This\\nis most-likely what happens when you see the above log messages.\\n:::\\n\\n:::
      {#the-solution .section .level2}\\n## The Solution {#the-solution .anchored
      anchor-id=\\\"the-solution\\\"}\\n\\nLong talk short, the solution is to disable
      IPv6 redirecting:\\n\\n    sudo sysctl net.ipv6.conf.all.accept_redirects=0\\n\\nMy
      server is not a router, so there is no need to accept any kind of\\nroute changing
      messages from external sources. We can simply disable\\nredirects, using above
      command. The change can be made permanent by\\nsetting the value in `/etc/sysctl.conf`.
      In fact, we can disable routing\\nfor both IPv4 and IPv6. Be careful though,
      you might happen to be in a\\nnetwork environment requiring you to accept redirect
      commands for some\\nreason.\\n\\nIf you are on Debian or similar distribution
      like Ubuntu, change the\\nfollowing lines in `/etc/sysctl.conf` from\\n\\n    #
      Do not accept ICMP redirects (prevent MITM attacks)\\n    #net.ipv4.conf.all.accept_redirects
      = 0\\n    #net.ipv6.conf.all.accept_redirects = 0\\n    # _or_\\n    # Accept
      ICMP redirects only for gateways listed in our default\\n    # gateway list
      (enabled by default)\\n    # net.ipv4.conf.all.secure_redirects = 1\\n    #\\n
      \   # Do not send ICMP redirects (we are not a router)\\n    #net.ipv4.conf.all.send_redirects
      = 0\\n    #\\n    # Do not accept IP source route packets (we are not a router)\\n
      \   #net.ipv4.conf.all.accept_source_route = 0\\n    #net.ipv6.conf.all.accept_source_route
      = 0\\n\\nto\\n\\n    # Do not accept ICMP redirects (prevent MITM attacks)\\n
      \   net.ipv4.conf.all.accept_redirects = 0\\n    net.ipv6.conf.all.accept_redirects
      = 0\\n    #\\n    # Do not send ICMP redirects (we are not a router)\\n    net.ipv4.conf.all.send_redirects
      = 0\\n    #\\n    # Do not accept IP source route packets (we are not a router)\\n
      \   net.ipv4.conf.all.accept_source_route = 0\\n    net.ipv6.conf.all.accept_source_route
      = 0\\n\\nRunning `sudo sysctl -p` loads the new settings.\\n:::\\n\\n::: {#alternative-solution
      .section .level2}\\n## Alternative Solution {#alternative-solution .anchored
      anchor-id=\\\"alternative-solution\\\"}\\n\\nCompletely disabling redirects
      in the kernel should keep you reasonably\\nsecure. However, if you need redirects
      within your internal network, you\\ncould also block redirect packages reaching
      you through external\\ninterfaces. E.g., to block redirect packages coming in
      on eth1, one\\nwould issue\\n\\n    sudo ip6tables -A -i eth1 -p icmpv6 --icmpv6-type
      137 -j DROP\\n\\nHowever, firewall configuration is a complex topic, so I'm
      not going to\\ngo into details here.\\n\\nIf you have any questions, corrections
      or comments on the matter, please\\ndrop me a line.\\n:::\\n\",\"relationships\":[],\"archive_url\":\"https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/rt6_redirect\",\"guid\":\"https://tarleb.com/posts/rt6_redirect/index.html\",\"updated\":false,\"category\":\"computerAndInformationSciences\"}]"
    headers:
      Access-Control-Allow-Origin:
      - '*'
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 849864711c081638-DUS
      Connection:
      - keep-alive
      Content-Profile:
      - public
      Content-Range:
      - '*/*'
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Mon, 22 Jan 2024 14:12:31 GMT
      Preference-Applied:
      - resolution=merge-duplicates
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      Via:
      - kong/2.8.1
      X-Kong-Proxy-Latency:
      - '0'
      X-Kong-Upstream-Latency:
      - '5'
      alt-svc:
      - h3=":443"; ma=86400
      sb-gateway-version:
      - '1'
    http_version: HTTP/1.1
    status_code: 201
- request:
    body: '{"indexed": true}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      accept-profile:
      - public
      connection:
      - keep-alive
      content-length:
      - '17'
      content-profile:
      - public
      content-type:
      - application/json
      host:
      - db.rogue-scholar.org
      prefer:
      - return=representation
      user-agent:
      - python-httpx/0.25.2
      x-client-info:
      - supabase-py/2.3.4
    method: PATCH
    uri: https://db.rogue-scholar.org/rest/v1/posts?id=eq.e0cd3729-73cd-43b4-a2e7-079bf5618506
  response:
    content: "[{\"url\":\"https://tarleb.com/posts/rt6_redirect\",\"title\":\"rt6_redirect:
      source isn\u2019t a valid nexthop for redirect target\",\"summary\":\"The zeitkraut
      server is configured to work with IPv6. For quite some time now, I\u2019ve been
      seeing some strange errors in my log files. If you\u2019ve been noticing something
      similar, here is what\u2019s going on and how to prevent the messages from appearing.
      The Problem   Everything works as expected, except for some weird messages in
      the logs: rt6_redirect: source isn't a valid nexthop for redirect target  Not
      even startpage was of much help.\\n\",\"image\":null,\"tags\":[\"Security\",\"Sysadmin\"],\"language\":\"en\",\"authors\":[{\"name\":
      \"Albert Krewinkel\"}],\"doi\":\"https://doi.org/10.59350/eek5z-xdj13\",\"id\":\"e0cd3729-73cd-43b4-a2e7-079bf5618506\",\"reference\":[],\"updated_at\":1406851200,\"published_at\":1406851200,\"blog_name\":\"tarleb\",\"indexed_at\":1700483671,\"indexed\":true,\"images\":[],\"blog_slug\":\"tarleb\",\"content_text\":\"The
      zeitkraut server is configured to work with IPv6. For quite some\\ntime now,
      I've been seeing some strange errors in my log files. If\\nyou've been noticing
      something similar, here is what's going on and how\\nto prevent the messages
      from appearing.\\n\\n::: {#the-problem .section .level2}\\n## The Problem {#the-problem
      .anchored anchor-id=\\\"the-problem\\\"}\\n\\nEverything works as expected,
      except for some weird messages in the\\nlogs:\\n\\n    rt6_redirect: source
      isn't a valid nexthop for redirect target\\n\\nNot even [startpage](https://startpage.com)
      was of much help. Searching\\nfor the above line only lists only some\\n[unanswered](http://ubuntuforums.org/archive/index.php/t-1947743.html)\\n[forum](http://board.gulli.com/thread/1699675-rt6-redirect-source-isn-t-a-valid-nexthop/)\\nquestions
      and the kernel source code which is producing the message. Oh,\\nand a somewhat
      unhelpful blog entry\\n[telling](https://www.kernel-error.de/kernel-error-blog/189-rt6-redirect-source-isn-t-a-valid-nexthop-for-redirect-target)\\npeople
      to always use their routers link local address when routing. This\\nis useless
      advice in my case, I don't *have* a link-local address of the\\nrouter, only
      it's global address.\\n:::\\n\\n::: {#the-cause .section .level2}\\n## The Cause
      {#the-cause .anchored anchor-id=\\\"the-cause\\\"}\\n\\nI found a way to stop
      the message from appearing in my logs. On the way,\\nI learned a bit more about
      IPv6 and improved server security on the way.\\n\\nIPv6 contains functionality
      to tell a computer about better routes to\\nthe target destination. A router
      may send ICMPv6 redirect packages (type\\n137 to be specific), informing neighboring
      computers about more\\neffective ways to reach their targets. This makes the
      most sense when\\napplied within an environment heavily relying on auto-configuration
      --\\nlike a dynamic internal company or home network. It makes a lot less\\nsense
      for servers very stable network topologies.\\n\\nAttackers may try to exploit
      the redirect functionality by including\\nthemselves into the route to the target.
      The specification for those\\nredirects includes some security-measures, requiring
      the attacker to\\ncorrectly guess the server's current next hop. If the attackers
      get it\\nwrong, the Linux kernel refuses to use the new routing information.
      This\\nis most-likely what happens when you see the above log messages.\\n:::\\n\\n:::
      {#the-solution .section .level2}\\n## The Solution {#the-solution .anchored
      anchor-id=\\\"the-solution\\\"}\\n\\nLong talk short, the solution is to disable
      IPv6 redirecting:\\n\\n    sudo sysctl net.ipv6.conf.all.accept_redirects=0\\n\\nMy
      server is not a router, so there is no need to accept any kind of\\nroute changing
      messages from external sources. We can simply disable\\nredirects, using above
      command. The change can be made permanent by\\nsetting the value in `/etc/sysctl.conf`.
      In fact, we can disable routing\\nfor both IPv4 and IPv6. Be careful though,
      you might happen to be in a\\nnetwork environment requiring you to accept redirect
      commands for some\\nreason.\\n\\nIf you are on Debian or similar distribution
      like Ubuntu, change the\\nfollowing lines in `/etc/sysctl.conf` from\\n\\n    #
      Do not accept ICMP redirects (prevent MITM attacks)\\n    #net.ipv4.conf.all.accept_redirects
      = 0\\n    #net.ipv6.conf.all.accept_redirects = 0\\n    # _or_\\n    # Accept
      ICMP redirects only for gateways listed in our default\\n    # gateway list
      (enabled by default)\\n    # net.ipv4.conf.all.secure_redirects = 1\\n    #\\n
      \   # Do not send ICMP redirects (we are not a router)\\n    #net.ipv4.conf.all.send_redirects
      = 0\\n    #\\n    # Do not accept IP source route packets (we are not a router)\\n
      \   #net.ipv4.conf.all.accept_source_route = 0\\n    #net.ipv6.conf.all.accept_source_route
      = 0\\n\\nto\\n\\n    # Do not accept ICMP redirects (prevent MITM attacks)\\n
      \   net.ipv4.conf.all.accept_redirects = 0\\n    net.ipv6.conf.all.accept_redirects
      = 0\\n    #\\n    # Do not send ICMP redirects (we are not a router)\\n    net.ipv4.conf.all.send_redirects
      = 0\\n    #\\n    # Do not accept IP source route packets (we are not a router)\\n
      \   net.ipv4.conf.all.accept_source_route = 0\\n    net.ipv6.conf.all.accept_source_route
      = 0\\n\\nRunning `sudo sysctl -p` loads the new settings.\\n:::\\n\\n::: {#alternative-solution
      .section .level2}\\n## Alternative Solution {#alternative-solution .anchored
      anchor-id=\\\"alternative-solution\\\"}\\n\\nCompletely disabling redirects
      in the kernel should keep you reasonably\\nsecure. However, if you need redirects
      within your internal network, you\\ncould also block redirect packages reaching
      you through external\\ninterfaces. E.g., to block redirect packages coming in
      on eth1, one\\nwould issue\\n\\n    sudo ip6tables -A -i eth1 -p icmpv6 --icmpv6-type
      137 -j DROP\\n\\nHowever, firewall configuration is a complex topic, so I'm
      not going to\\ngo into details here.\\n\\nIf you have any questions, corrections
      or comments on the matter, please\\ndrop me a line.\\n:::\\n\",\"relationships\":[],\"archive_url\":\"https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/rt6_redirect\",\"guid\":\"https://tarleb.com/posts/rt6_redirect/index.html\",\"updated\":false,\"category\":\"computerAndInformationSciences\"}]"
    headers:
      Access-Control-Allow-Origin:
      - '*'
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 849864718cac1638-DUS
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Profile:
      - public
      Content-Range:
      - 0-0/*
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Mon, 22 Jan 2024 14:12:31 GMT
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      Via:
      - kong/2.8.1
      X-Kong-Proxy-Latency:
      - '0'
      X-Kong-Upstream-Latency:
      - '3'
      alt-svc:
      - h3=":443"; ma=86400
      sb-gateway-version:
      - '1'
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: '{"authors": [{"name": "Albert Krewinkel"}], "blog_name": "tarleb", "blog_slug":
      "tarleb", "content_text": "Having a good working environment is vital for feeling
      comfortable being\nproductive. This extends to computational tools and the [command\nshell](https://en.wikipedia.org/wiki/command%20shell)
      is an integral\npart of the daily work for many of us. It''s a good idea to
      configure the\nshell''s interface to be efficient and pleasant to use. Here
      we see how\n`zsh`{.verbatim}, arguably the best shell around, can be configured
      to\nsuit the needs of people used to vi key bindings (which are arguably\narguably
      superior and more ergonomical than the default emacs-style\nbindings)^1^.\n\n:::
      {#using-vi-bindings-in-the-shell .section .level2}\n## Using vi-bindings in
      the shell {#using-vi-bindings-in-the-shell .anchored anchor-id=\"using-vi-bindings-in-the-shell\"}\n\nThe
      first step towards nice vi key bindings is almost too easy: The red\npill takes
      the form of\n\n::: {#cb1 .sourceCode style=\"background: #f1f3f5;\"}\n``` {.sourceCode
      .bash .code-with-copy}\nbindkey -v\n```\n:::\n\nType it into your prompt (and
      add it to your `.zshrc`{.verbatim} file)\nand emacs bindings are going bye-bye.
      `Escape`{.verbatim} will bring you\nto normal-mode, while `i`, `a`, `o` etc.
      will bring you back to\ninsert-mode, just as with your favorite editor. Use
      `j` and `k` in\nnormal-mode to go through your history and move around within
      the line\nwith `h`, `l`, `w`, `b` and the like.\n\nThis is a good start, let''s
      see how we can bring it from \"this is nice\"\nto \"that''s just awesome\".\n\nFirst,
      we may want to keep some of the default key bindings in\ninsert-mode since we''ve
      grown accustomed to them. No missing out, let''s\nput them back in:\n\n::: {#cb2
      .sourceCode style=\"background: #f1f3f5;\"}\n``` {.sourceCode .bash .code-with-copy}\n#
      Kill input from the current point to the end of line with Ctrl-k\nbindkey ''^k''
      kill-line\n# Search the history incremantally with Ctrl-r\nbindkey ''^r'' history-incremental-search-backward\n#
      Insert and go through the \"last words\" of previous commands with Meta-.\n#
      (or Escape-. for that matter).\nbindkey ''^[.'' insert-last-word\n# Show the
      man-page or other helpful infos with Meta-h\nbindkey ''^[h'' run-help\n```\n:::\n\nYou
      can take a look at the key bindings defined for emacs-mode by typing\n`bindkey
      -M emacs -L` and reuse the bindings you like. See the `zshzle`\nmanpage for
      more pre-defined widgets for which you could define\nbindings.\n:::\n\n::: {#configuring-the-prompt-to-show-the-current-editing-mode
      .section .level2}\n## Configuring the prompt to show the current editing mode
      {#configuring-the-prompt-to-show-the-current-editing-mode .anchored anchor-id=\"configuring-the-prompt-to-show-the-current-editing-mode\"}\n\nSo
      the key bindings are quite usable now, but it''s a bit unfortunate\nthat it
      is impossible to see if the shell is in insert- or normal-mode.\nThere should
      be a mode indicator right in the shell prompt!\n\n::: {#cb3 .sourceCode style=\"background:
      #f1f3f5;\"}\n``` {.sourceCode .bash .code-with-copy}\n# You may already have
      those in your .zshrc somewhere\nautoload -U promptinit && promptinit\nautoload
      -U colors     && colors\n\nsetopt prompt_subst\n\n# Set the colors to your liking\nlocal
      vi_normal_marker=\"[%{$fg[green]%}%BN%b%{$reset_color%}]\"\nlocal vi_insert_marker=\"[%{$fg[cyan]%}%BI%b%{$reset_color%}]\"\nlocal
      vi_unknown_marker=\"[%{$fg[red]%}%BU%b%{$reset_color%}]\"\nlocal vi_mode=\"$vi_insert_marker\"\nvi_mode_indicator
      () {\n  case ${KEYMAP} in\n    (vicmd)      echo $vi_normal_marker ;;\n    (main|viins)
      echo $vi_insert_marker ;;\n    (*)          echo $vi_unknown_marker ;;\n  esac\n}\n\n#
      Reset mode-marker and prompt whenever the keymap changes\nfunction zle-line-init
      zle-keymap-select {\n  vi_mode=\"$(vi_mode_indicator)\"\n  zle reset-prompt\n}\nzle
      -N zle-line-init\nzle -N zle-keymap-select\n\n# Multiline-prompts don''t quite
      work with reset-prompt; we work around this by\n# printing the first line(s)
      via a precmd which is executed before the prompt\n# is printed.  The following
      can be integrated into PROMPT for single-line\n# prompts.\n#\n# Colorize freely\nlocal
      user_host=''%B%n%b@%m''\nlocal current_dir=''%~''\nprecmd () print -rP \"${user_host}
      ${current_dir}\"\n\nlocal return_code=\"%(?..%{$fg[red]%}%? %{$reset_color%})\"\nPROMPT=''${return_code}${vi_mode}
      %# ''\n```\n:::\n\nThis gives a prompt in the style of\n\n    user@host /current/working/path\n    [I]
      %\n\nwhere `[I]` is the insert-mode indicator and is changed to `[N]` when\nnormal-mode
      is activated. Neat, isn''t it?\n:::\n\n::: {#single--and-multi-key-shortcuts
      .section .level2}\n## Single- and multi-key shortcuts {#single--and-multi-key-shortcuts
      .anchored anchor-id=\"single--and-multi-key-shortcuts\"}\n\nThis is all nice
      and dandy, but it''s not quite like vim yet. How about\nthose sweet bindings
      where pressing `jj` in quick succession brings us\nto normal-mode without having
      to press `Esc`? Setting it up is easy as\npie.\n\n::: {#cb5 .sourceCode style=\"background:
      #f1f3f5;\"}\n``` {.sourceCode .bash .code-with-copy}\n# Time in which two keys
      have to be pressed in order to be recognized as a\n# single command (in centiseconds,
      set to 0.4 sec by default -- may be\n# modified as needed).\nexport KEYTIMEOUT=40\nbindkey
      ''jj'' vi-cmd-mode\n```\n:::\n\nWe can also add two-key bindings to jump to
      the start and end of the\nline:\n\n::: {#cb6 .sourceCode style=\"background:
      #f1f3f5;\"}\n``` {.sourceCode .bash .code-with-copy}\n# Bind to both possible
      orders in which the keys could be pressed.\n# Move all the way to the left\nbindkey
      '';l'' end-of-line\nbindkey ''l;'' end-of-line\n# Move all the way to the right\nbindkey
      '';h'' beginning-of-line\nbindkey ''h;'' beginning-of-line\n```\n:::\n\nJumping
      to the beginning of the line is now as easy as pressing `;` and\n`h` at the
      same time. No need to switch to normal-mode and your fingers\ndon''t leave the
      your keyboard''s home-row. Try it, it''s great!\n:::\n\n::: {#more .section
      .level2}\n## More {#more .anchored anchor-id=\"more\"}\n\nCustomizations like
      this can make it much more pleasant to use the\ncommand line and boost your
      productivity. If the above is still not\nenough, here are some more ideas:\n\n-
      Define custom keymaps, e.g.\u00a0to control other programs such as `mpc` or\n  `tmux`.\n-
      Switch to said keymaps via some nice bindings.\n- Show the status of version
      control systems and build environments in\n  the prompt.\n\nIf you don''t feel
      like doing all the work yourself, I can heartly\nreommend you take a look at
      [oh-my-zsh](http://ohmyz.sh). It offers a\ngreat collection of ideas to build
      on and some really cool ready-to-use\nplugins. Have fun!\n:::\n\n::: {#quarto-appendix
      .default}\n::: {#footnotes .section .footnotes .footnotes-end-of-document}\n##
      Footnotes {#footnotes .anchored .quarto-appendix-heading}\n\n1.  ::: {#fn1}\n    Emacs
      is a great program which I''ve been using for years and\n    continue to use
      daily, but vi bindings just make good things better.\n    Thanks to [evil](https://gitorious.org/evil/pages/Home),
      that''s not\n    a problem.\u21a9\ufe0e\n    :::\n:::\n:::\n", "images": [],
      "updated_at": 1404000000, "published_at": 1404000000, "image": null, "language":
      "en", "category": "computerAndInformationSciences", "reference": [], "relationships":
      [], "summary": "Having a good working environment is vital for feeling comfortable
      being productive. This extends to computational tools and the command shell
      is an integral part of the daily work for many of us. It\u2019s a good idea
      to configure the shell\u2019s interface to be efficient and pleasant to use.\n",
      "tags": ["Command-line", "Key Bindings"], "title": "How to configure zsh with
      vi bindings and nice shortcuts", "url": "https://tarleb.com/posts/howto-zsh-vi-style",
      "guid": "https://tarleb.com/posts/howto-zsh-vi-style/index.html", "archive_url":
      "https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/howto-zsh-vi-style"}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      accept-profile:
      - public
      connection:
      - keep-alive
      content-length:
      - '7995'
      content-profile:
      - public
      content-type:
      - application/json
      host:
      - db.rogue-scholar.org
      prefer:
      - return=representation,resolution=merge-duplicates
      user-agent:
      - python-httpx/0.25.2
      x-client-info:
      - supabase-py/2.3.4
    method: POST
    uri: https://db.rogue-scholar.org/rest/v1/posts?on_conflict=guid
  response:
    content: "[{\"url\":\"https://tarleb.com/posts/howto-zsh-vi-style\",\"title\":\"How
      to configure zsh with vi bindings and nice shortcuts\",\"summary\":\"Having
      a good working environment is vital for feeling comfortable being productive.
      This extends to computational tools and the command shell is an integral part
      of the daily work for many of us. It\u2019s a good idea to configure the shell\u2019s
      interface to be efficient and pleasant to use.\\n\",\"image\":null,\"tags\":[\"Command-line\",\"Key
      Bindings\"],\"language\":\"en\",\"authors\":[{\"name\": \"Albert Krewinkel\"}],\"doi\":\"https://doi.org/10.59350/nepmz-sn896\",\"id\":\"ec547272-e118-4dac-926c-96c2667ba699\",\"reference\":[],\"updated_at\":1404000000,\"published_at\":1404000000,\"blog_name\":\"tarleb\",\"indexed_at\":1700484548,\"indexed\":true,\"images\":[],\"blog_slug\":\"tarleb\",\"content_text\":\"Having
      a good working environment is vital for feeling comfortable being\\nproductive.
      This extends to computational tools and the [command\\nshell](https://en.wikipedia.org/wiki/command%20shell)
      is an integral\\npart of the daily work for many of us. It's a good idea to
      configure the\\nshell's interface to be efficient and pleasant to use. Here
      we see how\\n`zsh`{.verbatim}, arguably the best shell around, can be configured
      to\\nsuit the needs of people used to vi key bindings (which are arguably\\narguably
      superior and more ergonomical than the default emacs-style\\nbindings)^1^.\\n\\n:::
      {#using-vi-bindings-in-the-shell .section .level2}\\n## Using vi-bindings in
      the shell {#using-vi-bindings-in-the-shell .anchored anchor-id=\\\"using-vi-bindings-in-the-shell\\\"}\\n\\nThe
      first step towards nice vi key bindings is almost too easy: The red\\npill takes
      the form of\\n\\n::: {#cb1 .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n```
      {.sourceCode .bash .code-with-copy}\\nbindkey -v\\n```\\n:::\\n\\nType it into
      your prompt (and add it to your `.zshrc`{.verbatim} file)\\nand emacs bindings
      are going bye-bye. `Escape`{.verbatim} will bring you\\nto normal-mode, while
      `i`, `a`, `o` etc. will bring you back to\\ninsert-mode, just as with your favorite
      editor. Use `j` and `k` in\\nnormal-mode to go through your history and move
      around within the line\\nwith `h`, `l`, `w`, `b` and the like.\\n\\nThis is
      a good start, let's see how we can bring it from \\\"this is nice\\\"\\nto \\\"that's
      just awesome\\\".\\n\\nFirst, we may want to keep some of the default key bindings
      in\\ninsert-mode since we've grown accustomed to them. No missing out, let's\\nput
      them back in:\\n\\n::: {#cb2 .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n```
      {.sourceCode .bash .code-with-copy}\\n# Kill input from the current point to
      the end of line with Ctrl-k\\nbindkey '^k' kill-line\\n# Search the history
      incremantally with Ctrl-r\\nbindkey '^r' history-incremental-search-backward\\n#
      Insert and go through the \\\"last words\\\" of previous commands with Meta-.\\n#
      (or Escape-. for that matter).\\nbindkey '^[.' insert-last-word\\n# Show the
      man-page or other helpful infos with Meta-h\\nbindkey '^[h' run-help\\n```\\n:::\\n\\nYou
      can take a look at the key bindings defined for emacs-mode by typing\\n`bindkey
      -M emacs -L` and reuse the bindings you like. See the `zshzle`\\nmanpage for
      more pre-defined widgets for which you could define\\nbindings.\\n:::\\n\\n:::
      {#configuring-the-prompt-to-show-the-current-editing-mode .section .level2}\\n##
      Configuring the prompt to show the current editing mode {#configuring-the-prompt-to-show-the-current-editing-mode
      .anchored anchor-id=\\\"configuring-the-prompt-to-show-the-current-editing-mode\\\"}\\n\\nSo
      the key bindings are quite usable now, but it's a bit unfortunate\\nthat it
      is impossible to see if the shell is in insert- or normal-mode.\\nThere should
      be a mode indicator right in the shell prompt!\\n\\n::: {#cb3 .sourceCode style=\\\"background:
      #f1f3f5;\\\"}\\n``` {.sourceCode .bash .code-with-copy}\\n# You may already
      have those in your .zshrc somewhere\\nautoload -U promptinit && promptinit\\nautoload
      -U colors     && colors\\n\\nsetopt prompt_subst\\n\\n# Set the colors to your
      liking\\nlocal vi_normal_marker=\\\"[%{$fg[green]%}%BN%b%{$reset_color%}]\\\"\\nlocal
      vi_insert_marker=\\\"[%{$fg[cyan]%}%BI%b%{$reset_color%}]\\\"\\nlocal vi_unknown_marker=\\\"[%{$fg[red]%}%BU%b%{$reset_color%}]\\\"\\nlocal
      vi_mode=\\\"$vi_insert_marker\\\"\\nvi_mode_indicator () {\\n  case ${KEYMAP}
      in\\n    (vicmd)      echo $vi_normal_marker ;;\\n    (main|viins) echo $vi_insert_marker
      ;;\\n    (*)          echo $vi_unknown_marker ;;\\n  esac\\n}\\n\\n# Reset mode-marker
      and prompt whenever the keymap changes\\nfunction zle-line-init zle-keymap-select
      {\\n  vi_mode=\\\"$(vi_mode_indicator)\\\"\\n  zle reset-prompt\\n}\\nzle -N
      zle-line-init\\nzle -N zle-keymap-select\\n\\n# Multiline-prompts don't quite
      work with reset-prompt; we work around this by\\n# printing the first line(s)
      via a precmd which is executed before the prompt\\n# is printed.  The following
      can be integrated into PROMPT for single-line\\n# prompts.\\n#\\n# Colorize
      freely\\nlocal user_host='%B%n%b@%m'\\nlocal current_dir='%~'\\nprecmd () print
      -rP \\\"${user_host} ${current_dir}\\\"\\n\\nlocal return_code=\\\"%(?..%{$fg[red]%}%?
      %{$reset_color%})\\\"\\nPROMPT='${return_code}${vi_mode} %# '\\n```\\n:::\\n\\nThis
      gives a prompt in the style of\\n\\n    user@host /current/working/path\\n    [I]
      %\\n\\nwhere `[I]` is the insert-mode indicator and is changed to `[N]` when\\nnormal-mode
      is activated. Neat, isn't it?\\n:::\\n\\n::: {#single--and-multi-key-shortcuts
      .section .level2}\\n## Single- and multi-key shortcuts {#single--and-multi-key-shortcuts
      .anchored anchor-id=\\\"single--and-multi-key-shortcuts\\\"}\\n\\nThis is all
      nice and dandy, but it's not quite like vim yet. How about\\nthose sweet bindings
      where pressing `jj` in quick succession brings us\\nto normal-mode without having
      to press `Esc`? Setting it up is easy as\\npie.\\n\\n::: {#cb5 .sourceCode style=\\\"background:
      #f1f3f5;\\\"}\\n``` {.sourceCode .bash .code-with-copy}\\n# Time in which two
      keys have to be pressed in order to be recognized as a\\n# single command (in
      centiseconds, set to 0.4 sec by default -- may be\\n# modified as needed).\\nexport
      KEYTIMEOUT=40\\nbindkey 'jj' vi-cmd-mode\\n```\\n:::\\n\\nWe can also add two-key
      bindings to jump to the start and end of the\\nline:\\n\\n::: {#cb6 .sourceCode
      style=\\\"background: #f1f3f5;\\\"}\\n``` {.sourceCode .bash .code-with-copy}\\n#
      Bind to both possible orders in which the keys could be pressed.\\n# Move all
      the way to the left\\nbindkey ';l' end-of-line\\nbindkey 'l;' end-of-line\\n#
      Move all the way to the right\\nbindkey ';h' beginning-of-line\\nbindkey 'h;'
      beginning-of-line\\n```\\n:::\\n\\nJumping to the beginning of the line is now
      as easy as pressing `;` and\\n`h` at the same time. No need to switch to normal-mode
      and your fingers\\ndon't leave the your keyboard's home-row. Try it, it's great!\\n:::\\n\\n:::
      {#more .section .level2}\\n## More {#more .anchored anchor-id=\\\"more\\\"}\\n\\nCustomizations
      like this can make it much more pleasant to use the\\ncommand line and boost
      your productivity. If the above is still not\\nenough, here are some more ideas:\\n\\n-
      Define custom keymaps, e.g.\_to control other programs such as `mpc` or\\n  `tmux`.\\n-
      Switch to said keymaps via some nice bindings.\\n- Show the status of version
      control systems and build environments in\\n  the prompt.\\n\\nIf you don't
      feel like doing all the work yourself, I can heartly\\nreommend you take a look
      at [oh-my-zsh](http://ohmyz.sh). It offers a\\ngreat collection of ideas to
      build on and some really cool ready-to-use\\nplugins. Have fun!\\n:::\\n\\n:::
      {#quarto-appendix .default}\\n::: {#footnotes .section .footnotes .footnotes-end-of-document}\\n##
      Footnotes {#footnotes .anchored .quarto-appendix-heading}\\n\\n1.  ::: {#fn1}\\n
      \   Emacs is a great program which I've been using for years and\\n    continue
      to use daily, but vi bindings just make good things better.\\n    Thanks to
      [evil](https://gitorious.org/evil/pages/Home), that's not\\n    a problem.\u21A9\uFE0E\\n
      \   :::\\n:::\\n:::\\n\",\"relationships\":[],\"archive_url\":\"https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/howto-zsh-vi-style\",\"guid\":\"https://tarleb.com/posts/howto-zsh-vi-style/index.html\",\"updated\":false,\"category\":\"computerAndInformationSciences\"}]"
    headers:
      Access-Control-Allow-Origin:
      - '*'
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 84986471fd5b1638-DUS
      Connection:
      - keep-alive
      Content-Profile:
      - public
      Content-Range:
      - '*/*'
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Mon, 22 Jan 2024 14:12:31 GMT
      Preference-Applied:
      - resolution=merge-duplicates
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      Via:
      - kong/2.8.1
      X-Kong-Proxy-Latency:
      - '0'
      X-Kong-Upstream-Latency:
      - '4'
      alt-svc:
      - h3=":443"; ma=86400
      sb-gateway-version:
      - '1'
    http_version: HTTP/1.1
    status_code: 201
- request:
    body: '{"indexed": true}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      accept-profile:
      - public
      connection:
      - keep-alive
      content-length:
      - '17'
      content-profile:
      - public
      content-type:
      - application/json
      host:
      - db.rogue-scholar.org
      prefer:
      - return=representation
      user-agent:
      - python-httpx/0.25.2
      x-client-info:
      - supabase-py/2.3.4
    method: PATCH
    uri: https://db.rogue-scholar.org/rest/v1/posts?id=eq.ec547272-e118-4dac-926c-96c2667ba699
  response:
    content: "[{\"url\":\"https://tarleb.com/posts/howto-zsh-vi-style\",\"title\":\"How
      to configure zsh with vi bindings and nice shortcuts\",\"summary\":\"Having
      a good working environment is vital for feeling comfortable being productive.
      This extends to computational tools and the command shell is an integral part
      of the daily work for many of us. It\u2019s a good idea to configure the shell\u2019s
      interface to be efficient and pleasant to use.\\n\",\"image\":null,\"tags\":[\"Command-line\",\"Key
      Bindings\"],\"language\":\"en\",\"authors\":[{\"name\": \"Albert Krewinkel\"}],\"doi\":\"https://doi.org/10.59350/nepmz-sn896\",\"id\":\"ec547272-e118-4dac-926c-96c2667ba699\",\"reference\":[],\"updated_at\":1404000000,\"published_at\":1404000000,\"blog_name\":\"tarleb\",\"indexed_at\":1700484548,\"indexed\":true,\"images\":[],\"blog_slug\":\"tarleb\",\"content_text\":\"Having
      a good working environment is vital for feeling comfortable being\\nproductive.
      This extends to computational tools and the [command\\nshell](https://en.wikipedia.org/wiki/command%20shell)
      is an integral\\npart of the daily work for many of us. It's a good idea to
      configure the\\nshell's interface to be efficient and pleasant to use. Here
      we see how\\n`zsh`{.verbatim}, arguably the best shell around, can be configured
      to\\nsuit the needs of people used to vi key bindings (which are arguably\\narguably
      superior and more ergonomical than the default emacs-style\\nbindings)^1^.\\n\\n:::
      {#using-vi-bindings-in-the-shell .section .level2}\\n## Using vi-bindings in
      the shell {#using-vi-bindings-in-the-shell .anchored anchor-id=\\\"using-vi-bindings-in-the-shell\\\"}\\n\\nThe
      first step towards nice vi key bindings is almost too easy: The red\\npill takes
      the form of\\n\\n::: {#cb1 .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n```
      {.sourceCode .bash .code-with-copy}\\nbindkey -v\\n```\\n:::\\n\\nType it into
      your prompt (and add it to your `.zshrc`{.verbatim} file)\\nand emacs bindings
      are going bye-bye. `Escape`{.verbatim} will bring you\\nto normal-mode, while
      `i`, `a`, `o` etc. will bring you back to\\ninsert-mode, just as with your favorite
      editor. Use `j` and `k` in\\nnormal-mode to go through your history and move
      around within the line\\nwith `h`, `l`, `w`, `b` and the like.\\n\\nThis is
      a good start, let's see how we can bring it from \\\"this is nice\\\"\\nto \\\"that's
      just awesome\\\".\\n\\nFirst, we may want to keep some of the default key bindings
      in\\ninsert-mode since we've grown accustomed to them. No missing out, let's\\nput
      them back in:\\n\\n::: {#cb2 .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n```
      {.sourceCode .bash .code-with-copy}\\n# Kill input from the current point to
      the end of line with Ctrl-k\\nbindkey '^k' kill-line\\n# Search the history
      incremantally with Ctrl-r\\nbindkey '^r' history-incremental-search-backward\\n#
      Insert and go through the \\\"last words\\\" of previous commands with Meta-.\\n#
      (or Escape-. for that matter).\\nbindkey '^[.' insert-last-word\\n# Show the
      man-page or other helpful infos with Meta-h\\nbindkey '^[h' run-help\\n```\\n:::\\n\\nYou
      can take a look at the key bindings defined for emacs-mode by typing\\n`bindkey
      -M emacs -L` and reuse the bindings you like. See the `zshzle`\\nmanpage for
      more pre-defined widgets for which you could define\\nbindings.\\n:::\\n\\n:::
      {#configuring-the-prompt-to-show-the-current-editing-mode .section .level2}\\n##
      Configuring the prompt to show the current editing mode {#configuring-the-prompt-to-show-the-current-editing-mode
      .anchored anchor-id=\\\"configuring-the-prompt-to-show-the-current-editing-mode\\\"}\\n\\nSo
      the key bindings are quite usable now, but it's a bit unfortunate\\nthat it
      is impossible to see if the shell is in insert- or normal-mode.\\nThere should
      be a mode indicator right in the shell prompt!\\n\\n::: {#cb3 .sourceCode style=\\\"background:
      #f1f3f5;\\\"}\\n``` {.sourceCode .bash .code-with-copy}\\n# You may already
      have those in your .zshrc somewhere\\nautoload -U promptinit && promptinit\\nautoload
      -U colors     && colors\\n\\nsetopt prompt_subst\\n\\n# Set the colors to your
      liking\\nlocal vi_normal_marker=\\\"[%{$fg[green]%}%BN%b%{$reset_color%}]\\\"\\nlocal
      vi_insert_marker=\\\"[%{$fg[cyan]%}%BI%b%{$reset_color%}]\\\"\\nlocal vi_unknown_marker=\\\"[%{$fg[red]%}%BU%b%{$reset_color%}]\\\"\\nlocal
      vi_mode=\\\"$vi_insert_marker\\\"\\nvi_mode_indicator () {\\n  case ${KEYMAP}
      in\\n    (vicmd)      echo $vi_normal_marker ;;\\n    (main|viins) echo $vi_insert_marker
      ;;\\n    (*)          echo $vi_unknown_marker ;;\\n  esac\\n}\\n\\n# Reset mode-marker
      and prompt whenever the keymap changes\\nfunction zle-line-init zle-keymap-select
      {\\n  vi_mode=\\\"$(vi_mode_indicator)\\\"\\n  zle reset-prompt\\n}\\nzle -N
      zle-line-init\\nzle -N zle-keymap-select\\n\\n# Multiline-prompts don't quite
      work with reset-prompt; we work around this by\\n# printing the first line(s)
      via a precmd which is executed before the prompt\\n# is printed.  The following
      can be integrated into PROMPT for single-line\\n# prompts.\\n#\\n# Colorize
      freely\\nlocal user_host='%B%n%b@%m'\\nlocal current_dir='%~'\\nprecmd () print
      -rP \\\"${user_host} ${current_dir}\\\"\\n\\nlocal return_code=\\\"%(?..%{$fg[red]%}%?
      %{$reset_color%})\\\"\\nPROMPT='${return_code}${vi_mode} %# '\\n```\\n:::\\n\\nThis
      gives a prompt in the style of\\n\\n    user@host /current/working/path\\n    [I]
      %\\n\\nwhere `[I]` is the insert-mode indicator and is changed to `[N]` when\\nnormal-mode
      is activated. Neat, isn't it?\\n:::\\n\\n::: {#single--and-multi-key-shortcuts
      .section .level2}\\n## Single- and multi-key shortcuts {#single--and-multi-key-shortcuts
      .anchored anchor-id=\\\"single--and-multi-key-shortcuts\\\"}\\n\\nThis is all
      nice and dandy, but it's not quite like vim yet. How about\\nthose sweet bindings
      where pressing `jj` in quick succession brings us\\nto normal-mode without having
      to press `Esc`? Setting it up is easy as\\npie.\\n\\n::: {#cb5 .sourceCode style=\\\"background:
      #f1f3f5;\\\"}\\n``` {.sourceCode .bash .code-with-copy}\\n# Time in which two
      keys have to be pressed in order to be recognized as a\\n# single command (in
      centiseconds, set to 0.4 sec by default -- may be\\n# modified as needed).\\nexport
      KEYTIMEOUT=40\\nbindkey 'jj' vi-cmd-mode\\n```\\n:::\\n\\nWe can also add two-key
      bindings to jump to the start and end of the\\nline:\\n\\n::: {#cb6 .sourceCode
      style=\\\"background: #f1f3f5;\\\"}\\n``` {.sourceCode .bash .code-with-copy}\\n#
      Bind to both possible orders in which the keys could be pressed.\\n# Move all
      the way to the left\\nbindkey ';l' end-of-line\\nbindkey 'l;' end-of-line\\n#
      Move all the way to the right\\nbindkey ';h' beginning-of-line\\nbindkey 'h;'
      beginning-of-line\\n```\\n:::\\n\\nJumping to the beginning of the line is now
      as easy as pressing `;` and\\n`h` at the same time. No need to switch to normal-mode
      and your fingers\\ndon't leave the your keyboard's home-row. Try it, it's great!\\n:::\\n\\n:::
      {#more .section .level2}\\n## More {#more .anchored anchor-id=\\\"more\\\"}\\n\\nCustomizations
      like this can make it much more pleasant to use the\\ncommand line and boost
      your productivity. If the above is still not\\nenough, here are some more ideas:\\n\\n-
      Define custom keymaps, e.g.\_to control other programs such as `mpc` or\\n  `tmux`.\\n-
      Switch to said keymaps via some nice bindings.\\n- Show the status of version
      control systems and build environments in\\n  the prompt.\\n\\nIf you don't
      feel like doing all the work yourself, I can heartly\\nreommend you take a look
      at [oh-my-zsh](http://ohmyz.sh). It offers a\\ngreat collection of ideas to
      build on and some really cool ready-to-use\\nplugins. Have fun!\\n:::\\n\\n:::
      {#quarto-appendix .default}\\n::: {#footnotes .section .footnotes .footnotes-end-of-document}\\n##
      Footnotes {#footnotes .anchored .quarto-appendix-heading}\\n\\n1.  ::: {#fn1}\\n
      \   Emacs is a great program which I've been using for years and\\n    continue
      to use daily, but vi bindings just make good things better.\\n    Thanks to
      [evil](https://gitorious.org/evil/pages/Home), that's not\\n    a problem.\u21A9\uFE0E\\n
      \   :::\\n:::\\n:::\\n\",\"relationships\":[],\"archive_url\":\"https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/howto-zsh-vi-style\",\"guid\":\"https://tarleb.com/posts/howto-zsh-vi-style/index.html\",\"updated\":false,\"category\":\"computerAndInformationSciences\"}]"
    headers:
      Access-Control-Allow-Origin:
      - '*'
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 849864727e2d1638-DUS
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Profile:
      - public
      Content-Range:
      - 0-0/*
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Mon, 22 Jan 2024 14:12:31 GMT
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      Via:
      - kong/2.8.1
      X-Kong-Proxy-Latency:
      - '0'
      X-Kong-Upstream-Latency:
      - '3'
      alt-svc:
      - h3=":443"; ma=86400
      sb-gateway-version:
      - '1'
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: '{"authors": [{"name": "Albert Krewinkel"}], "blog_name": "tarleb", "blog_slug":
      "tarleb", "content_text": "One of the many great things about free and open
      source software and the\nwhole GNU/Linux ecosystem are the simple yet powerful
      tools available.\nThe possibilities enabled by almost trivial programs are incredible.
      A\nvery positive side effect this has on me is that I like to go and\nexplore
      technologies with the tools at my disposal. My latest\nexperiments revolved
      around the HTTP protocol, specifically HTTP\nheaders, and very basic open source
      networking tools.\n\n::: {#the-hypertext-transfer-protocol .section .level2}\n##
      The HyperText Transfer Protocol {#the-hypertext-transfer-protocol .anchored
      anchor-id=\"the-hypertext-transfer-protocol\"}\n\nWebservers on the internet
      sending a website to a browser use the\nHyperText Transfer Protocol (HTTP) to
      do so. Along with the HTML data\nfor the page itself, the server answer includes
      additional information:\nResponse code, cookies, and how the browser or proxy
      server should\nhandle the contents is transfered within the *HTTP header*. The
      ability\nof the headers to control state on the client side is what makes them
      so\ninteresting and the reason why we are going to have a closer look at\nthem.\n:::\n\n:::
      {#communicating-with-netcat .section .level2}\n## Communicating with `netcat`
      {#communicating-with-netcat .anchored anchor-id=\"communicating-with-netcat\"}\n\nInstead
      of building our own HTTP client and server implementations --\nthat would be
      total overkill -- we restrict the goal to a simple\nnetworking tool that can
      be made to receive, send and alter basic HTTP\ncommands: `netcat`, the self-described
      TCP/IP swiss army knife, combined\nwith basic shell scripts.\n\nWe start by
      setting up a basic echoing server which sends everything\nback the same way
      it was received.\n\n``` shell\nnc -l -p 8042 -e ''/bin/cat''\n```\n\nPointing
      the browser at `http://localhost:8042`, then killing the\n`netcat` process manually
      by hitting `Control-C`, we can see the headers\nwe sent within our browser.
      Everything that is send to our simple server\nis put through the `cat` program,
      which just passes it on to STDOUT,\nwhich is then sent back to the connecting
      browser. The process has to be\nterminated manually, as it doesn''t know when
      to stop listening for more\ninput. It''s crude, yet effective.\n:::\n\n::: {#shell-scripting-for-more-advanced-features
      .section .level2}\n## Shell Scripting for more advanced features {#shell-scripting-for-more-advanced-features
      .anchored anchor-id=\"shell-scripting-for-more-advanced-features\"}\n\nThe above
      is neither comfortable to use nor very good to toy with, so we\nreplace `cat`
      with a script of our own, we''ll call it\n`exploring-http.sh`:\n\n``` shell\n#!/bin/sh\n\n#
      Keep reading everything until we hit the first empty line\nread_headers ()\n{\n    read
      i\n    while [ -n \"$i\" ] &&\n          [ \"$(echo -n \"\\r\\n\")\" != \"$i\"
      ] &&\n          [ \"$(echo -n \"\\n\")\" != \"$i\" ]\n    do\n        echo \"$i\"\n        read
      i\n    done\n}\nrequest_headers=\"$(read_headers)\"\n\n# Get some response headers
      ready\nresponse_headers ()\n{\n    printf \"HTTP/1.1 200 OK\\r\\n\"\n    printf
      \"Content-Type: text/plain\\r\\n\"\n    printf \"\\r\\n\"\n}\n\n# Send the response\nrespond
      ()\n{\n    local response_headers=\"$(response_headers)\"\n    echo \"${response_headers}\"\n    echo
      \"Browser Request Headers\"\n    echo \"=======================\"\n    echo
      \"$request_headers\"\n    echo \"\\r\\n\"\n    echo \"Server Response Headers\"\n    echo
      \"=======================\"\n    echo \"${response_headers}\"\n}\n\nrespond\n```\n\nThe
      request send by the browser is read till we reach the first black\nline, signaling
      the end of the request header. This time, we follow the\nprotocol by prefixing
      the content with very simple response headers\nbefore sending it back to the
      browser. We also don''t have to manually\nterminate our `netcat` server, it
      terminates after answering to the\nrequest. Starting it again after each request
      is tedious, so we automate\nit and put it into a loop, restarting the server
      immediately once it\nterminates.\n\n``` shell\nsh -c ''while true; do nc -l
      -p 8042 -e exploring-http.sh; done''\n```\n\nNow we are free to experiment with
      HTTP headers and the way browser and\nserver interact. For example, we can let
      the server add a\n`Last-Modified` header, the content of which should be sent
      back by the\nbrowser in the next request:\n\n``` shell\nresponse_headers ()\n{\n    printf
      \"HTTP/1.1 200 OK\\r\\n\"\n    printf \"Content-Type: text/plain\\r\\n\"\n    printf
      \"Last-Modified: $(date --rfc-2822)\\r\\n\"\n    printf \"\\r\\n\"\n}\n```\n\nReloading
      twice, and the browser request will change to send an\nadditional `If-Modified-Since`
      header.\n:::\n\n::: {#etags .section .level2}\n## ETags {#etags .anchored anchor-id=\"etags\"}\n\nThe
      functionality of ETags, designed to communicate caching of old\nfiles, can be
      used follow users around without the need of cookies.\nLet''s see if we can
      do this with our little server.\n\nThe function generating the response headers
      is modified to extract any\nETag supplied by the browser. If none exists, we
      generate a new one by\nhashing the number of nanoseconds passed since the beginning
      of the UNIX\nepoche. The parsed or newly generated etag is then sent back to
      the\nbrowser. We also add a few header to make sure the conents isn''t cached.\nAs
      a result, we should be able to track a user through his or her\nbrowser cache.\n\n```
      shell\nresponse_headers ()\n{\n    local etag\n    etag=$(echo \"${request_headers}\"
      | sed -ne ''s/^\\(If-None-Match: \"\\([a-f0-9]*\\)\".*\\)/\\2/gp'')\n    printf
      \"HTTP/1.1 200 OK\\r\\n\"\n    printf \"Content-Type: text/plain\\r\\n\"\n    printf
      \"Last-Modified: $(date --rfc-2822)\\r\\n\"\n    printf \"ETag: \\\"${etag:-$(date
      +%s%N | md5sum | cut -d'' '' -f1)}\\\"\\r\\n\"\n    printf \"Expires: Tue, 01
      Jan 2013 00:00:01 GMT\\r\\n\"\n    printf \"Cache-Control: max-age=0\\r\\n\"\n    printf
      \"Connection: keep-alive\\r\\n\"\n    printf \"\\r\\n\"\n}\n```\n\nWe can test
      this by reloading our test page twice and... it works! We\ncan reload as often
      as we want, the ETag header sent by the browser will\nnot change unless we clear
      the browser''s cache. A stealthy kind of user\ntracking can be simulated with
      just a few lines of shell script.\n:::\n\n::: {#conclusion .section .level2}\n##
      Conclusion {#conclusion .anchored anchor-id=\"conclusion\"}\n\nEven though we
      used nothing but simple command line tools and shell\nscripting, we managed
      to build a simple server and to experiment with\nthe ways in which stateless
      servers and stateful browseres can effect\neach other through HTTP headers.
      Standard UNIX tools are very powerful\nby themselves; together with a tool like
      `netcat`, power and fun extend\neven into experiments with networking and default
      protocols.\n:::\n", "images": [], "updated_at": 1383609600, "published_at":
      1383609600, "image": null, "language": "en", "category": "computerAndInformationSciences",
      "reference": [], "relationships": [], "summary": "One of the many great things
      about free and open source software and the whole GNU/Linux ecosystem are the
      simple yet powerful tools available. The possibilities enabled by almost trivial
      programs are incredible. A very positive side effect this has on me is that
      I like to go and explore technologies with the tools at my disposal.\n", "tags":
      ["Command-line", "Network"], "title": "Exploring HTTP Headers with netcat",
      "url": "https://tarleb.com/posts/exploring-http-headers", "guid": "https://tarleb.com/posts/exploring-http-headers/index.html",
      "archive_url": "https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/exploring-http-headers"}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      accept-profile:
      - public
      connection:
      - keep-alive
      content-length:
      - '7783'
      content-profile:
      - public
      content-type:
      - application/json
      host:
      - db.rogue-scholar.org
      prefer:
      - return=representation,resolution=merge-duplicates
      user-agent:
      - python-httpx/0.25.2
      x-client-info:
      - supabase-py/2.3.4
    method: POST
    uri: https://db.rogue-scholar.org/rest/v1/posts?on_conflict=guid
  response:
    content: '[{"url":"https://tarleb.com/posts/exploring-http-headers","title":"Exploring
      HTTP Headers with netcat","summary":"One of the many great things about free
      and open source software and the whole GNU/Linux ecosystem are the simple yet
      powerful tools available. The possibilities enabled by almost trivial programs
      are incredible. A very positive side effect this has on me is that I like to
      go and explore technologies with the tools at my disposal.\n","image":null,"tags":["Command-line","Network"],"language":"en","authors":[{"name":
      "Albert Krewinkel"}],"doi":"https://doi.org/10.59350/wprk0-6nx33","id":"7894f246-b7f8-4114-9e80-f42c9a80d8ae","reference":[],"updated_at":1383609600,"published_at":1383609600,"blog_name":"tarleb","indexed_at":1700485209,"indexed":true,"images":[],"blog_slug":"tarleb","content_text":"One
      of the many great things about free and open source software and the\nwhole
      GNU/Linux ecosystem are the simple yet powerful tools available.\nThe possibilities
      enabled by almost trivial programs are incredible. A\nvery positive side effect
      this has on me is that I like to go and\nexplore technologies with the tools
      at my disposal. My latest\nexperiments revolved around the HTTP protocol, specifically
      HTTP\nheaders, and very basic open source networking tools.\n\n::: {#the-hypertext-transfer-protocol
      .section .level2}\n## The HyperText Transfer Protocol {#the-hypertext-transfer-protocol
      .anchored anchor-id=\"the-hypertext-transfer-protocol\"}\n\nWebservers on the
      internet sending a website to a browser use the\nHyperText Transfer Protocol
      (HTTP) to do so. Along with the HTML data\nfor the page itself, the server answer
      includes additional information:\nResponse code, cookies, and how the browser
      or proxy server should\nhandle the contents is transfered within the *HTTP header*.
      The ability\nof the headers to control state on the client side is what makes
      them so\ninteresting and the reason why we are going to have a closer look at\nthem.\n:::\n\n:::
      {#communicating-with-netcat .section .level2}\n## Communicating with `netcat`
      {#communicating-with-netcat .anchored anchor-id=\"communicating-with-netcat\"}\n\nInstead
      of building our own HTTP client and server implementations --\nthat would be
      total overkill -- we restrict the goal to a simple\nnetworking tool that can
      be made to receive, send and alter basic HTTP\ncommands: `netcat`, the self-described
      TCP/IP swiss army knife, combined\nwith basic shell scripts.\n\nWe start by
      setting up a basic echoing server which sends everything\nback the same way
      it was received.\n\n``` shell\nnc -l -p 8042 -e ''/bin/cat''\n```\n\nPointing
      the browser at `http://localhost:8042`, then killing the\n`netcat` process manually
      by hitting `Control-C`, we can see the headers\nwe sent within our browser.
      Everything that is send to our simple server\nis put through the `cat` program,
      which just passes it on to STDOUT,\nwhich is then sent back to the connecting
      browser. The process has to be\nterminated manually, as it doesn''t know when
      to stop listening for more\ninput. It''s crude, yet effective.\n:::\n\n::: {#shell-scripting-for-more-advanced-features
      .section .level2}\n## Shell Scripting for more advanced features {#shell-scripting-for-more-advanced-features
      .anchored anchor-id=\"shell-scripting-for-more-advanced-features\"}\n\nThe above
      is neither comfortable to use nor very good to toy with, so we\nreplace `cat`
      with a script of our own, we''ll call it\n`exploring-http.sh`:\n\n``` shell\n#!/bin/sh\n\n#
      Keep reading everything until we hit the first empty line\nread_headers ()\n{\n    read
      i\n    while [ -n \"$i\" ] &&\n          [ \"$(echo -n \"\\r\\n\")\" != \"$i\"
      ] &&\n          [ \"$(echo -n \"\\n\")\" != \"$i\" ]\n    do\n        echo \"$i\"\n        read
      i\n    done\n}\nrequest_headers=\"$(read_headers)\"\n\n# Get some response headers
      ready\nresponse_headers ()\n{\n    printf \"HTTP/1.1 200 OK\\r\\n\"\n    printf
      \"Content-Type: text/plain\\r\\n\"\n    printf \"\\r\\n\"\n}\n\n# Send the response\nrespond
      ()\n{\n    local response_headers=\"$(response_headers)\"\n    echo \"${response_headers}\"\n    echo
      \"Browser Request Headers\"\n    echo \"=======================\"\n    echo
      \"$request_headers\"\n    echo \"\\r\\n\"\n    echo \"Server Response Headers\"\n    echo
      \"=======================\"\n    echo \"${response_headers}\"\n}\n\nrespond\n```\n\nThe
      request send by the browser is read till we reach the first black\nline, signaling
      the end of the request header. This time, we follow the\nprotocol by prefixing
      the content with very simple response headers\nbefore sending it back to the
      browser. We also don''t have to manually\nterminate our `netcat` server, it
      terminates after answering to the\nrequest. Starting it again after each request
      is tedious, so we automate\nit and put it into a loop, restarting the server
      immediately once it\nterminates.\n\n``` shell\nsh -c ''while true; do nc -l
      -p 8042 -e exploring-http.sh; done''\n```\n\nNow we are free to experiment with
      HTTP headers and the way browser and\nserver interact. For example, we can let
      the server add a\n`Last-Modified` header, the content of which should be sent
      back by the\nbrowser in the next request:\n\n``` shell\nresponse_headers ()\n{\n    printf
      \"HTTP/1.1 200 OK\\r\\n\"\n    printf \"Content-Type: text/plain\\r\\n\"\n    printf
      \"Last-Modified: $(date --rfc-2822)\\r\\n\"\n    printf \"\\r\\n\"\n}\n```\n\nReloading
      twice, and the browser request will change to send an\nadditional `If-Modified-Since`
      header.\n:::\n\n::: {#etags .section .level2}\n## ETags {#etags .anchored anchor-id=\"etags\"}\n\nThe
      functionality of ETags, designed to communicate caching of old\nfiles, can be
      used follow users around without the need of cookies.\nLet''s see if we can
      do this with our little server.\n\nThe function generating the response headers
      is modified to extract any\nETag supplied by the browser. If none exists, we
      generate a new one by\nhashing the number of nanoseconds passed since the beginning
      of the UNIX\nepoche. The parsed or newly generated etag is then sent back to
      the\nbrowser. We also add a few header to make sure the conents isn''t cached.\nAs
      a result, we should be able to track a user through his or her\nbrowser cache.\n\n```
      shell\nresponse_headers ()\n{\n    local etag\n    etag=$(echo \"${request_headers}\"
      | sed -ne ''s/^\\(If-None-Match: \"\\([a-f0-9]*\\)\".*\\)/\\2/gp'')\n    printf
      \"HTTP/1.1 200 OK\\r\\n\"\n    printf \"Content-Type: text/plain\\r\\n\"\n    printf
      \"Last-Modified: $(date --rfc-2822)\\r\\n\"\n    printf \"ETag: \\\"${etag:-$(date
      +%s%N | md5sum | cut -d'' '' -f1)}\\\"\\r\\n\"\n    printf \"Expires: Tue, 01
      Jan 2013 00:00:01 GMT\\r\\n\"\n    printf \"Cache-Control: max-age=0\\r\\n\"\n    printf
      \"Connection: keep-alive\\r\\n\"\n    printf \"\\r\\n\"\n}\n```\n\nWe can test
      this by reloading our test page twice and... it works! We\ncan reload as often
      as we want, the ETag header sent by the browser will\nnot change unless we clear
      the browser''s cache. A stealthy kind of user\ntracking can be simulated with
      just a few lines of shell script.\n:::\n\n::: {#conclusion .section .level2}\n##
      Conclusion {#conclusion .anchored anchor-id=\"conclusion\"}\n\nEven though we
      used nothing but simple command line tools and shell\nscripting, we managed
      to build a simple server and to experiment with\nthe ways in which stateless
      servers and stateful browseres can effect\neach other through HTTP headers.
      Standard UNIX tools are very powerful\nby themselves; together with a tool like
      `netcat`, power and fun extend\neven into experiments with networking and default
      protocols.\n:::\n","relationships":[],"archive_url":"https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/exploring-http-headers","guid":"https://tarleb.com/posts/exploring-http-headers/index.html","updated":false,"category":"computerAndInformationSciences"}]'
    headers:
      Access-Control-Allow-Origin:
      - '*'
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 84986472debe1638-DUS
      Connection:
      - keep-alive
      Content-Profile:
      - public
      Content-Range:
      - '*/*'
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Mon, 22 Jan 2024 14:12:31 GMT
      Preference-Applied:
      - resolution=merge-duplicates
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      Via:
      - kong/2.8.1
      X-Kong-Proxy-Latency:
      - '0'
      X-Kong-Upstream-Latency:
      - '4'
      alt-svc:
      - h3=":443"; ma=86400
      sb-gateway-version:
      - '1'
    http_version: HTTP/1.1
    status_code: 201
- request:
    body: '{"indexed": true}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      accept-profile:
      - public
      connection:
      - keep-alive
      content-length:
      - '17'
      content-profile:
      - public
      content-type:
      - application/json
      host:
      - db.rogue-scholar.org
      prefer:
      - return=representation
      user-agent:
      - python-httpx/0.25.2
      x-client-info:
      - supabase-py/2.3.4
    method: PATCH
    uri: https://db.rogue-scholar.org/rest/v1/posts?id=eq.7894f246-b7f8-4114-9e80-f42c9a80d8ae
  response:
    content: '[{"url":"https://tarleb.com/posts/exploring-http-headers","title":"Exploring
      HTTP Headers with netcat","summary":"One of the many great things about free
      and open source software and the whole GNU/Linux ecosystem are the simple yet
      powerful tools available. The possibilities enabled by almost trivial programs
      are incredible. A very positive side effect this has on me is that I like to
      go and explore technologies with the tools at my disposal.\n","image":null,"tags":["Command-line","Network"],"language":"en","authors":[{"name":
      "Albert Krewinkel"}],"doi":"https://doi.org/10.59350/wprk0-6nx33","id":"7894f246-b7f8-4114-9e80-f42c9a80d8ae","reference":[],"updated_at":1383609600,"published_at":1383609600,"blog_name":"tarleb","indexed_at":1700485209,"indexed":true,"images":[],"blog_slug":"tarleb","content_text":"One
      of the many great things about free and open source software and the\nwhole
      GNU/Linux ecosystem are the simple yet powerful tools available.\nThe possibilities
      enabled by almost trivial programs are incredible. A\nvery positive side effect
      this has on me is that I like to go and\nexplore technologies with the tools
      at my disposal. My latest\nexperiments revolved around the HTTP protocol, specifically
      HTTP\nheaders, and very basic open source networking tools.\n\n::: {#the-hypertext-transfer-protocol
      .section .level2}\n## The HyperText Transfer Protocol {#the-hypertext-transfer-protocol
      .anchored anchor-id=\"the-hypertext-transfer-protocol\"}\n\nWebservers on the
      internet sending a website to a browser use the\nHyperText Transfer Protocol
      (HTTP) to do so. Along with the HTML data\nfor the page itself, the server answer
      includes additional information:\nResponse code, cookies, and how the browser
      or proxy server should\nhandle the contents is transfered within the *HTTP header*.
      The ability\nof the headers to control state on the client side is what makes
      them so\ninteresting and the reason why we are going to have a closer look at\nthem.\n:::\n\n:::
      {#communicating-with-netcat .section .level2}\n## Communicating with `netcat`
      {#communicating-with-netcat .anchored anchor-id=\"communicating-with-netcat\"}\n\nInstead
      of building our own HTTP client and server implementations --\nthat would be
      total overkill -- we restrict the goal to a simple\nnetworking tool that can
      be made to receive, send and alter basic HTTP\ncommands: `netcat`, the self-described
      TCP/IP swiss army knife, combined\nwith basic shell scripts.\n\nWe start by
      setting up a basic echoing server which sends everything\nback the same way
      it was received.\n\n``` shell\nnc -l -p 8042 -e ''/bin/cat''\n```\n\nPointing
      the browser at `http://localhost:8042`, then killing the\n`netcat` process manually
      by hitting `Control-C`, we can see the headers\nwe sent within our browser.
      Everything that is send to our simple server\nis put through the `cat` program,
      which just passes it on to STDOUT,\nwhich is then sent back to the connecting
      browser. The process has to be\nterminated manually, as it doesn''t know when
      to stop listening for more\ninput. It''s crude, yet effective.\n:::\n\n::: {#shell-scripting-for-more-advanced-features
      .section .level2}\n## Shell Scripting for more advanced features {#shell-scripting-for-more-advanced-features
      .anchored anchor-id=\"shell-scripting-for-more-advanced-features\"}\n\nThe above
      is neither comfortable to use nor very good to toy with, so we\nreplace `cat`
      with a script of our own, we''ll call it\n`exploring-http.sh`:\n\n``` shell\n#!/bin/sh\n\n#
      Keep reading everything until we hit the first empty line\nread_headers ()\n{\n    read
      i\n    while [ -n \"$i\" ] &&\n          [ \"$(echo -n \"\\r\\n\")\" != \"$i\"
      ] &&\n          [ \"$(echo -n \"\\n\")\" != \"$i\" ]\n    do\n        echo \"$i\"\n        read
      i\n    done\n}\nrequest_headers=\"$(read_headers)\"\n\n# Get some response headers
      ready\nresponse_headers ()\n{\n    printf \"HTTP/1.1 200 OK\\r\\n\"\n    printf
      \"Content-Type: text/plain\\r\\n\"\n    printf \"\\r\\n\"\n}\n\n# Send the response\nrespond
      ()\n{\n    local response_headers=\"$(response_headers)\"\n    echo \"${response_headers}\"\n    echo
      \"Browser Request Headers\"\n    echo \"=======================\"\n    echo
      \"$request_headers\"\n    echo \"\\r\\n\"\n    echo \"Server Response Headers\"\n    echo
      \"=======================\"\n    echo \"${response_headers}\"\n}\n\nrespond\n```\n\nThe
      request send by the browser is read till we reach the first black\nline, signaling
      the end of the request header. This time, we follow the\nprotocol by prefixing
      the content with very simple response headers\nbefore sending it back to the
      browser. We also don''t have to manually\nterminate our `netcat` server, it
      terminates after answering to the\nrequest. Starting it again after each request
      is tedious, so we automate\nit and put it into a loop, restarting the server
      immediately once it\nterminates.\n\n``` shell\nsh -c ''while true; do nc -l
      -p 8042 -e exploring-http.sh; done''\n```\n\nNow we are free to experiment with
      HTTP headers and the way browser and\nserver interact. For example, we can let
      the server add a\n`Last-Modified` header, the content of which should be sent
      back by the\nbrowser in the next request:\n\n``` shell\nresponse_headers ()\n{\n    printf
      \"HTTP/1.1 200 OK\\r\\n\"\n    printf \"Content-Type: text/plain\\r\\n\"\n    printf
      \"Last-Modified: $(date --rfc-2822)\\r\\n\"\n    printf \"\\r\\n\"\n}\n```\n\nReloading
      twice, and the browser request will change to send an\nadditional `If-Modified-Since`
      header.\n:::\n\n::: {#etags .section .level2}\n## ETags {#etags .anchored anchor-id=\"etags\"}\n\nThe
      functionality of ETags, designed to communicate caching of old\nfiles, can be
      used follow users around without the need of cookies.\nLet''s see if we can
      do this with our little server.\n\nThe function generating the response headers
      is modified to extract any\nETag supplied by the browser. If none exists, we
      generate a new one by\nhashing the number of nanoseconds passed since the beginning
      of the UNIX\nepoche. The parsed or newly generated etag is then sent back to
      the\nbrowser. We also add a few header to make sure the conents isn''t cached.\nAs
      a result, we should be able to track a user through his or her\nbrowser cache.\n\n```
      shell\nresponse_headers ()\n{\n    local etag\n    etag=$(echo \"${request_headers}\"
      | sed -ne ''s/^\\(If-None-Match: \"\\([a-f0-9]*\\)\".*\\)/\\2/gp'')\n    printf
      \"HTTP/1.1 200 OK\\r\\n\"\n    printf \"Content-Type: text/plain\\r\\n\"\n    printf
      \"Last-Modified: $(date --rfc-2822)\\r\\n\"\n    printf \"ETag: \\\"${etag:-$(date
      +%s%N | md5sum | cut -d'' '' -f1)}\\\"\\r\\n\"\n    printf \"Expires: Tue, 01
      Jan 2013 00:00:01 GMT\\r\\n\"\n    printf \"Cache-Control: max-age=0\\r\\n\"\n    printf
      \"Connection: keep-alive\\r\\n\"\n    printf \"\\r\\n\"\n}\n```\n\nWe can test
      this by reloading our test page twice and... it works! We\ncan reload as often
      as we want, the ETag header sent by the browser will\nnot change unless we clear
      the browser''s cache. A stealthy kind of user\ntracking can be simulated with
      just a few lines of shell script.\n:::\n\n::: {#conclusion .section .level2}\n##
      Conclusion {#conclusion .anchored anchor-id=\"conclusion\"}\n\nEven though we
      used nothing but simple command line tools and shell\nscripting, we managed
      to build a simple server and to experiment with\nthe ways in which stateless
      servers and stateful browseres can effect\neach other through HTTP headers.
      Standard UNIX tools are very powerful\nby themselves; together with a tool like
      `netcat`, power and fun extend\neven into experiments with networking and default
      protocols.\n:::\n","relationships":[],"archive_url":"https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/exploring-http-headers","guid":"https://tarleb.com/posts/exploring-http-headers/index.html","updated":false,"category":"computerAndInformationSciences"}]'
    headers:
      Access-Control-Allow-Origin:
      - '*'
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 849864735f401638-DUS
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Profile:
      - public
      Content-Range:
      - 0-0/*
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Mon, 22 Jan 2024 14:12:31 GMT
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      Via:
      - kong/2.8.1
      X-Kong-Proxy-Latency:
      - '0'
      X-Kong-Upstream-Latency:
      - '3'
      alt-svc:
      - h3=":443"; ma=86400
      sb-gateway-version:
      - '1'
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: '{"authors": [{"name": "Albert Krewinkel"}], "blog_name": "tarleb", "blog_slug":
      "tarleb", "content_text": "A couple of friends and I just discussed the idea
      of Russian Process\nRoulette: Everybody starts a little program which kills
      processes at\nrandom. The winner is the one whose computer remains usable the
      longest.\nIs this crazy? Yes. Immature? Sure. Fun? Definitely. Adviced against
      to\nactually play unless the consequences are fully understood? That too.\n\nPlaying
      the game is as simple as starting a command like the following:\n\n``` shell\nwhile
      sleep 600; do kill -9 $(tr -cd \"[:digit:]\" < /dev/urandom | head -c5); done\n```\n\nThis
      one-liner will wake up every 10 minutes, generate a random 5-digit\nnumber and
      then kill the process with the corresponding process ID. It\nwill run forever,
      until it is either stopped, kills itself or has\nsuccessfully crashed the user''s
      session.\n\nOf course, there are some problems with this code. The time at which
      the\nnext process will be killed is predictable, making it easier to prepare\nfor
      the eventuality of a dying process. Worse, the range of random\nprocess ids
      (0 to 99999) is about three times as large as the actual\nrange of process ids
      on a typical linux system (0 to 32768). This lowers\nthe chance of hitting a
      valid process ID quite a bit. So let''s put our\nscripting-fu to some misguided
      use and \"optimize\" the code.\n\nThe first step is to write a function which
      gives uniformly distributed\nrandom numbers below a threshold.\n\n``` shell\nrandom_number_below
      () {\n  local upperbound=$1\n  local candidate=$(( $1 + 1 ))\n  local maxlen=$(printf
      $upperbound | wc -c)\n  while [ $candidate -gt $upperbound ]\n  do\n      candidate=$(tr
      -cd ''[:digit:]'' < /dev/urandom | head -c \"$maxlen\" )\n  done\n  echo $candidate\n}\n```\n\nOur
      random number generator is very very wasteful in terms of processor\ncycles.
      Even more, if the output of `/dev/urandom` is truly random, the\nfunction were
      not even guaranteed to terminate in any specified time\nframe. But given the
      nature of the application we have in mind, both\ncaveats are completely acceptable
      here. Candidate numbers are generated\nby reading random characters from the
      systems urandom device, throwing\naway every character that isn''t a digit.
      After this, the candidate\nnumber is checked to make sure we haven''t generated
      a number greater\nthan the specified upper bound. If that should be the case,
      we run the\nwhole procedure again. Otherwise, the random number is returned.
      While\nwasteful, this function produces an unbiased uniform distribution on
      the\ninterval \\[0, upperbound\\].\n\nThe second problem, regarding the range
      of possible process identifiers,\nis easier to fix. A little bit of searching
      reveals that the largest\npossible process identifier can be read from the file\n`/proc/sys/kernel/pid_max`.
      With this functionality in our hands, we can\nnow write a \"better\" Russian
      Process Roulette script.\n\n``` shell\nwhile sleep $(random_number_below 999)\ndo\n    local
      maxpid=$(cat /proc/sys/kernel/pid_max)\n    kill -9 $(random_number_below \"$maxpid\")\ndone\n```\n\nWe
      should (*probably not*) run this as `root`, thereby making sure no\nprocess
      is safe from our \"process gun\".\n\nWhile the result of our efforts isn''t
      necessarily useful, it is still a\nnice exercises in shell scripting. Our game
      remains destructive and\nimmature, but the execution is slightly more sophisticated.
      Hope you\nlike it.\n", "images": [], "updated_at": 1380240000, "published_at":
      1380240000, "image": null, "language": "en", "category": "computerAndInformationSciences",
      "reference": [], "relationships": [], "summary": "A couple of friends and I
      just discussed the idea of Russian Process Roulette: Everybody starts a little
      program which kills processes at random. The winner is the one whose computer
      remains usable the longest. Is this crazy? Yes. Immature? Sure. Fun? Definitely.
      Adviced against to actually play unless the consequences are fully understood?
      That too. Playing the game is as simple as starting a command like the following:
      while sleep 600;\n", "tags": ["Command-line", "Nonsense"], "title": "Russian
      Process Roulette", "url": "https://tarleb.com/posts/russian-process-roulette",
      "guid": "https://tarleb.com/posts/russian-process-roulette/index.html", "archive_url":
      "https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/russian-process-roulette"}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      accept-profile:
      - public
      connection:
      - keep-alive
      content-length:
      - '4434'
      content-profile:
      - public
      content-type:
      - application/json
      host:
      - db.rogue-scholar.org
      prefer:
      - return=representation,resolution=merge-duplicates
      user-agent:
      - python-httpx/0.25.2
      x-client-info:
      - supabase-py/2.3.4
    method: POST
    uri: https://db.rogue-scholar.org/rest/v1/posts?on_conflict=guid
  response:
    content: '[{"url":"https://tarleb.com/posts/russian-process-roulette","title":"Russian
      Process Roulette","summary":"A couple of friends and I just discussed the idea
      of Russian Process Roulette: Everybody starts a little program which kills processes
      at random. The winner is the one whose computer remains usable the longest.
      Is this crazy? Yes. Immature? Sure. Fun? Definitely. Adviced against to actually
      play unless the consequences are fully understood? That too. Playing the game
      is as simple as starting a command like the following: while sleep 600;\n","image":null,"tags":["Command-line","Nonsense"],"language":"en","authors":[{"name":
      "Albert Krewinkel"}],"doi":"https://doi.org/10.59350/5md5e-8rr11","id":"4457d532-104c-424c-a9f9-6e63fab4881c","reference":[],"updated_at":1380240000,"published_at":1380240000,"blog_name":"tarleb","indexed_at":1700485858,"indexed":true,"images":[],"blog_slug":"tarleb","content_text":"A
      couple of friends and I just discussed the idea of Russian Process\nRoulette:
      Everybody starts a little program which kills processes at\nrandom. The winner
      is the one whose computer remains usable the longest.\nIs this crazy? Yes. Immature?
      Sure. Fun? Definitely. Adviced against to\nactually play unless the consequences
      are fully understood? That too.\n\nPlaying the game is as simple as starting
      a command like the following:\n\n``` shell\nwhile sleep 600; do kill -9 $(tr
      -cd \"[:digit:]\" < /dev/urandom | head -c5); done\n```\n\nThis one-liner will
      wake up every 10 minutes, generate a random 5-digit\nnumber and then kill the
      process with the corresponding process ID. It\nwill run forever, until it is
      either stopped, kills itself or has\nsuccessfully crashed the user''s session.\n\nOf
      course, there are some problems with this code. The time at which the\nnext
      process will be killed is predictable, making it easier to prepare\nfor the
      eventuality of a dying process. Worse, the range of random\nprocess ids (0 to
      99999) is about three times as large as the actual\nrange of process ids on
      a typical linux system (0 to 32768). This lowers\nthe chance of hitting a valid
      process ID quite a bit. So let''s put our\nscripting-fu to some misguided use
      and \"optimize\" the code.\n\nThe first step is to write a function which gives
      uniformly distributed\nrandom numbers below a threshold.\n\n``` shell\nrandom_number_below
      () {\n  local upperbound=$1\n  local candidate=$(( $1 + 1 ))\n  local maxlen=$(printf
      $upperbound | wc -c)\n  while [ $candidate -gt $upperbound ]\n  do\n      candidate=$(tr
      -cd ''[:digit:]'' < /dev/urandom | head -c \"$maxlen\" )\n  done\n  echo $candidate\n}\n```\n\nOur
      random number generator is very very wasteful in terms of processor\ncycles.
      Even more, if the output of `/dev/urandom` is truly random, the\nfunction were
      not even guaranteed to terminate in any specified time\nframe. But given the
      nature of the application we have in mind, both\ncaveats are completely acceptable
      here. Candidate numbers are generated\nby reading random characters from the
      systems urandom device, throwing\naway every character that isn''t a digit.
      After this, the candidate\nnumber is checked to make sure we haven''t generated
      a number greater\nthan the specified upper bound. If that should be the case,
      we run the\nwhole procedure again. Otherwise, the random number is returned.
      While\nwasteful, this function produces an unbiased uniform distribution on
      the\ninterval \\[0, upperbound\\].\n\nThe second problem, regarding the range
      of possible process identifiers,\nis easier to fix. A little bit of searching
      reveals that the largest\npossible process identifier can be read from the file\n`/proc/sys/kernel/pid_max`.
      With this functionality in our hands, we can\nnow write a \"better\" Russian
      Process Roulette script.\n\n``` shell\nwhile sleep $(random_number_below 999)\ndo\n    local
      maxpid=$(cat /proc/sys/kernel/pid_max)\n    kill -9 $(random_number_below \"$maxpid\")\ndone\n```\n\nWe
      should (*probably not*) run this as `root`, thereby making sure no\nprocess
      is safe from our \"process gun\".\n\nWhile the result of our efforts isn''t
      necessarily useful, it is still a\nnice exercises in shell scripting. Our game
      remains destructive and\nimmature, but the execution is slightly more sophisticated.
      Hope you\nlike it.\n","relationships":[],"archive_url":"https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/russian-process-roulette","guid":"https://tarleb.com/posts/russian-process-roulette/index.html","updated":false,"category":"computerAndInformationSciences"}]'
    headers:
      Access-Control-Allow-Origin:
      - '*'
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 84986473d8281638-DUS
      Connection:
      - keep-alive
      Content-Profile:
      - public
      Content-Range:
      - '*/*'
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Mon, 22 Jan 2024 14:12:32 GMT
      Preference-Applied:
      - resolution=merge-duplicates
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      Via:
      - kong/2.8.1
      X-Kong-Proxy-Latency:
      - '0'
      X-Kong-Upstream-Latency:
      - '5'
      alt-svc:
      - h3=":443"; ma=86400
      sb-gateway-version:
      - '1'
    http_version: HTTP/1.1
    status_code: 201
- request:
    body: '{"indexed": true}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      accept-profile:
      - public
      connection:
      - keep-alive
      content-length:
      - '17'
      content-profile:
      - public
      content-type:
      - application/json
      host:
      - db.rogue-scholar.org
      prefer:
      - return=representation
      user-agent:
      - python-httpx/0.25.2
      x-client-info:
      - supabase-py/2.3.4
    method: PATCH
    uri: https://db.rogue-scholar.org/rest/v1/posts?id=eq.4457d532-104c-424c-a9f9-6e63fab4881c
  response:
    content: '[{"url":"https://tarleb.com/posts/russian-process-roulette","title":"Russian
      Process Roulette","summary":"A couple of friends and I just discussed the idea
      of Russian Process Roulette: Everybody starts a little program which kills processes
      at random. The winner is the one whose computer remains usable the longest.
      Is this crazy? Yes. Immature? Sure. Fun? Definitely. Adviced against to actually
      play unless the consequences are fully understood? That too. Playing the game
      is as simple as starting a command like the following: while sleep 600;\n","image":null,"tags":["Command-line","Nonsense"],"language":"en","authors":[{"name":
      "Albert Krewinkel"}],"doi":"https://doi.org/10.59350/5md5e-8rr11","id":"4457d532-104c-424c-a9f9-6e63fab4881c","reference":[],"updated_at":1380240000,"published_at":1380240000,"blog_name":"tarleb","indexed_at":1700485858,"indexed":true,"images":[],"blog_slug":"tarleb","content_text":"A
      couple of friends and I just discussed the idea of Russian Process\nRoulette:
      Everybody starts a little program which kills processes at\nrandom. The winner
      is the one whose computer remains usable the longest.\nIs this crazy? Yes. Immature?
      Sure. Fun? Definitely. Adviced against to\nactually play unless the consequences
      are fully understood? That too.\n\nPlaying the game is as simple as starting
      a command like the following:\n\n``` shell\nwhile sleep 600; do kill -9 $(tr
      -cd \"[:digit:]\" < /dev/urandom | head -c5); done\n```\n\nThis one-liner will
      wake up every 10 minutes, generate a random 5-digit\nnumber and then kill the
      process with the corresponding process ID. It\nwill run forever, until it is
      either stopped, kills itself or has\nsuccessfully crashed the user''s session.\n\nOf
      course, there are some problems with this code. The time at which the\nnext
      process will be killed is predictable, making it easier to prepare\nfor the
      eventuality of a dying process. Worse, the range of random\nprocess ids (0 to
      99999) is about three times as large as the actual\nrange of process ids on
      a typical linux system (0 to 32768). This lowers\nthe chance of hitting a valid
      process ID quite a bit. So let''s put our\nscripting-fu to some misguided use
      and \"optimize\" the code.\n\nThe first step is to write a function which gives
      uniformly distributed\nrandom numbers below a threshold.\n\n``` shell\nrandom_number_below
      () {\n  local upperbound=$1\n  local candidate=$(( $1 + 1 ))\n  local maxlen=$(printf
      $upperbound | wc -c)\n  while [ $candidate -gt $upperbound ]\n  do\n      candidate=$(tr
      -cd ''[:digit:]'' < /dev/urandom | head -c \"$maxlen\" )\n  done\n  echo $candidate\n}\n```\n\nOur
      random number generator is very very wasteful in terms of processor\ncycles.
      Even more, if the output of `/dev/urandom` is truly random, the\nfunction were
      not even guaranteed to terminate in any specified time\nframe. But given the
      nature of the application we have in mind, both\ncaveats are completely acceptable
      here. Candidate numbers are generated\nby reading random characters from the
      systems urandom device, throwing\naway every character that isn''t a digit.
      After this, the candidate\nnumber is checked to make sure we haven''t generated
      a number greater\nthan the specified upper bound. If that should be the case,
      we run the\nwhole procedure again. Otherwise, the random number is returned.
      While\nwasteful, this function produces an unbiased uniform distribution on
      the\ninterval \\[0, upperbound\\].\n\nThe second problem, regarding the range
      of possible process identifiers,\nis easier to fix. A little bit of searching
      reveals that the largest\npossible process identifier can be read from the file\n`/proc/sys/kernel/pid_max`.
      With this functionality in our hands, we can\nnow write a \"better\" Russian
      Process Roulette script.\n\n``` shell\nwhile sleep $(random_number_below 999)\ndo\n    local
      maxpid=$(cat /proc/sys/kernel/pid_max)\n    kill -9 $(random_number_below \"$maxpid\")\ndone\n```\n\nWe
      should (*probably not*) run this as `root`, thereby making sure no\nprocess
      is safe from our \"process gun\".\n\nWhile the result of our efforts isn''t
      necessarily useful, it is still a\nnice exercises in shell scripting. Our game
      remains destructive and\nimmature, but the execution is slightly more sophisticated.
      Hope you\nlike it.\n","relationships":[],"archive_url":"https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/russian-process-roulette","guid":"https://tarleb.com/posts/russian-process-roulette/index.html","updated":false,"category":"computerAndInformationSciences"}]'
    headers:
      Access-Control-Allow-Origin:
      - '*'
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 8498647458bf1638-DUS
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Profile:
      - public
      Content-Range:
      - 0-0/*
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Mon, 22 Jan 2024 14:12:32 GMT
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      Via:
      - kong/2.8.1
      X-Kong-Proxy-Latency:
      - '1'
      X-Kong-Upstream-Latency:
      - '3'
      alt-svc:
      - h3=":443"; ma=86400
      sb-gateway-version:
      - '1'
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: '{"authors": [{"name": "Albert Krewinkel"}], "blog_name": "tarleb", "blog_slug":
      "tarleb", "content_text": "Spam just doesn''t die. Every major mail provider
      has really good spam\nfilters in place, as do the common mail clients. Nontheless,
      there seem\nto be enough people reading -- and acting on -- spam mail to make
      it a\nprofitable business. No matter how much we hate it, we need to deal with\nspam.\n\nBetter
      than having a good spam filter is not to be spammed in the first\nplace. Since
      nobody can sent me unsolicited bulk mail if they don''t know\nmy mail address,
      keeping the mail address as private as possible is the\nway to go here. But
      what if we *want* our e-mail address to be public\nfor other people to reach
      us? Adding minor obstacles to make it just a\nbit more difficult for spammers
      to get the address can be enough.\n\n::: {#address-munging .section .level2}\n##
      Address Munging {#address-munging .anchored anchor-id=\"address-munging\"}\n\nThe
      usual way for spammers to collect email addresses is to crawl\nwebsites and
      to harvest everything that looks like a valid mail address.\nA common defense
      is [address\nmunging](https://en.wikipedia.org/wiki/Address_munging), i.e.\u00a0resolving\nto
      bogus comments, additional markup, images or javascript to hide mail\naddresses
      from automatic harvesters. I find the use of images or\njavascript problematic
      for various reasons and just dislike unnecessary\ncomments. Luckily, HTML5 and
      CSS3 make it really easy to mangle\naddresses without using either of these
      methods.\n:::\n\n::: {#obfuscating-an-address-with-html5-css3 .section .level2}\n##
      Obfuscating an Address with HTML5 & CSS3 {#obfuscating-an-address-with-html5-css3
      .anchored anchor-id=\"obfuscating-an-address-with-html5-css3\"}\n\nOur approach
      here leverages the HTML5\n[`data-*`](http://www.w3.org/TR/html5/dom.html#embedding-custom-non-visible-data-with-the-data-*-attributes)\nattributes
      as well as the\n[`::before`](https://developer.mozilla.org/en-US/docs/Web/CSS/::before)\nand\n[`::after`](https://developer.mozilla.org/en-US/docs/Web/CSS/::after)\npseudo-elements.
      The mail address is divided and stored in custom data\nattributes and displayed
      as pseudo-elements. The address is kept in the\nmarkup, the presentation is
      handled in the style sheet:\n\nHTML:\n\n::: {#cb1 .sourceCode style=\"background:
      #f1f3f5;\"}\n``` {.sourceCode .html .code-with-copy}\n<span data-user=\"john.doe\"\n      data-domain=\"example.com\"\n      class=\"obfuscated-mail-address\"><!--\n-->@<span>obfuscated
      email address</span></span>\n```\n:::\n\nCSS:\n\n::: {#cb2 .sourceCode style=\"background:
      #f1f3f5;\"}\n``` {.sourceCode .css .code-with-copy}\n.obfuscated-mail-address::before
      {\n  content: attr(data-user);\n}\n.obfuscated-mail-address::after {\n  content:
      attr(data-domain);\n}\n.obfuscated-email-address > * {\n  display: none;\n}\n```\n:::\n\nThe
      result is readable, but can be neither selected nor copied:\n\n[obfuscated email
      address]{.obfuscated-mail-address .dont-touch\nuser=\"john.doe\" domain=\"example.com\"}\n\nThe
      nested `<span>` and its styling could be omitted, without changing\nthe presentation
      in most browsers. We use it to ensures that everything\nfails gracefully in
      browsers with limited CSS support. To see why this\nmatters, have a look at
      this page in a text browser like *w3m* or\n*links*.\n:::\n\n::: {#drawbacks
      .section .level2}\n## Drawbacks {#drawbacks .anchored anchor-id=\"drawbacks\"}\n\nThe
      biggest advantage of this method is also it''s biggest disadvantage:\nThe semantics
      are broken. The classic markup-code\n\n::: {#cb3 .sourceCode style=\"background:
      #f1f3f5;\"}\n``` {.sourceCode .html .code-with-copy}\n<a href=\"mailto:me@example.com\">John
      Doe</a>\n```\n:::\n\nis rendered as [John Doe](mailto:me@example.com) and makes
      it very\nclear, to machines and humans alike, that *John Doe* can be reached
      at\n*me@example.com*. Address munging, like the above, preserves this\nmeaning
      for humans, but takes it away for machines. For better and for\nworse, browsers,
      search engines, and spam bots will not be aware of the\nmeaning of the obfuscated
      address.\n\nThese effects can be alleviated by resolving to additional javascript:\n\n:::
      {#cb4 .sourceCode style=\"background: #f1f3f5;\"}\n``` {.sourceCode .javascript
      .code-with-copy}\n// convert obfuscated mail addresses into clickable \"mailto:\"
      links\njQuery(\"document\").ready(function($) {\n  var mailAddressClass = \"obfuscated-mail-address\";\n  $(\".\"+mailAddressClass).each(function()
      {\n    var address = $(this).attr(\"data-user\") + \"@\" + $(this).attr(\"data-domain\");\n    $(this).html($(\"<a
      href=\\\"mailto:\" + address + \"\\\">\" + address + \"</a>\", {}));\n    $(this).removeClass(mailAddressClass);\n  });\n});\n```\n:::\n\nThe
      webpage is still usable with JavaScript turned off, and even fails\ngracefully
      on text-only browsers. If JavaScript is available, the\nobfuscated links offer
      the same experience as properly coded\n`<a href=\"mailto:...\">...</a>` links:
      [@]{.obfuscated-mail-address\nuser=\"john.doe\" domain=\"example.com\"}. I believe
      this to be a very good\ntrade-off between usability and safety from harvesters.\n:::\n",
      "images": [], "updated_at": 1377388800, "published_at": 1377388800, "image":
      null, "language": "en", "category": "computerAndInformationSciences", "reference":
      [], "relationships": [], "summary": "Spam just doesn\u2019t die. Every major
      mail provider has really good spam filters in place, as do the common mail clients.
      Nontheless, there seem to be enough people reading \u2013 and acting on \u2013
      spam mail to make it a profitable business. No matter how much we hate it, we
      need to deal with spam. Better than having a good spam filter is not to be spammed
      in the first place.\n", "tags": ["Html", "Css", "Javascript"], "title": "Avoid
      Mail Harvesting through Address Munging", "url": "https://tarleb.com/posts/avoiding-spam",
      "guid": "https://tarleb.com/posts/avoiding-spam/index.html", "archive_url":
      "https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/avoiding-spam"}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      accept-profile:
      - public
      connection:
      - keep-alive
      content-length:
      - '6074'
      content-profile:
      - public
      content-type:
      - application/json
      host:
      - db.rogue-scholar.org
      prefer:
      - return=representation,resolution=merge-duplicates
      user-agent:
      - python-httpx/0.25.2
      x-client-info:
      - supabase-py/2.3.4
    method: POST
    uri: https://db.rogue-scholar.org/rest/v1/posts?on_conflict=guid
  response:
    content: "[{\"url\":\"https://tarleb.com/posts/avoiding-spam\",\"title\":\"Avoid
      Mail Harvesting through Address Munging\",\"summary\":\"Spam just doesn\u2019t
      die. Every major mail provider has really good spam filters in place, as do
      the common mail clients. Nontheless, there seem to be enough people reading
      \u2013 and acting on \u2013 spam mail to make it a profitable business. No matter
      how much we hate it, we need to deal with spam. Better than having a good spam
      filter is not to be spammed in the first place.\\n\",\"image\":null,\"tags\":[\"Html\",\"Css\",\"Javascript\"],\"language\":\"en\",\"authors\":[{\"name\":
      \"Albert Krewinkel\"}],\"doi\":\"https://doi.org/10.59350/fk5r0-szd72\",\"id\":\"1855bfd0-e6c3-40c2-86e3-ddcea2ecfce8\",\"reference\":[],\"updated_at\":1377388800,\"published_at\":1377388800,\"blog_name\":\"tarleb\",\"indexed_at\":1700486796,\"indexed\":true,\"images\":[],\"blog_slug\":\"tarleb\",\"content_text\":\"Spam
      just doesn't die. Every major mail provider has really good spam\\nfilters in
      place, as do the common mail clients. Nontheless, there seem\\nto be enough
      people reading -- and acting on -- spam mail to make it a\\nprofitable business.
      No matter how much we hate it, we need to deal with\\nspam.\\n\\nBetter than
      having a good spam filter is not to be spammed in the first\\nplace. Since nobody
      can sent me unsolicited bulk mail if they don't know\\nmy mail address, keeping
      the mail address as private as possible is the\\nway to go here. But what if
      we *want* our e-mail address to be public\\nfor other people to reach us? Adding
      minor obstacles to make it just a\\nbit more difficult for spammers to get the
      address can be enough.\\n\\n::: {#address-munging .section .level2}\\n## Address
      Munging {#address-munging .anchored anchor-id=\\\"address-munging\\\"}\\n\\nThe
      usual way for spammers to collect email addresses is to crawl\\nwebsites and
      to harvest everything that looks like a valid mail address.\\nA common defense
      is [address\\nmunging](https://en.wikipedia.org/wiki/Address_munging), i.e.\_resolving\\nto
      bogus comments, additional markup, images or javascript to hide mail\\naddresses
      from automatic harvesters. I find the use of images or\\njavascript problematic
      for various reasons and just dislike unnecessary\\ncomments. Luckily, HTML5
      and CSS3 make it really easy to mangle\\naddresses without using either of these
      methods.\\n:::\\n\\n::: {#obfuscating-an-address-with-html5-css3 .section .level2}\\n##
      Obfuscating an Address with HTML5 & CSS3 {#obfuscating-an-address-with-html5-css3
      .anchored anchor-id=\\\"obfuscating-an-address-with-html5-css3\\\"}\\n\\nOur
      approach here leverages the HTML5\\n[`data-*`](http://www.w3.org/TR/html5/dom.html#embedding-custom-non-visible-data-with-the-data-*-attributes)\\nattributes
      as well as the\\n[`::before`](https://developer.mozilla.org/en-US/docs/Web/CSS/::before)\\nand\\n[`::after`](https://developer.mozilla.org/en-US/docs/Web/CSS/::after)\\npseudo-elements.
      The mail address is divided and stored in custom data\\nattributes and displayed
      as pseudo-elements. The address is kept in the\\nmarkup, the presentation is
      handled in the style sheet:\\n\\nHTML:\\n\\n::: {#cb1 .sourceCode style=\\\"background:
      #f1f3f5;\\\"}\\n``` {.sourceCode .html .code-with-copy}\\n<span data-user=\\\"john.doe\\\"\\n
      \     data-domain=\\\"example.com\\\"\\n      class=\\\"obfuscated-mail-address\\\"><!--\\n-->@<span>obfuscated
      email address</span></span>\\n```\\n:::\\n\\nCSS:\\n\\n::: {#cb2 .sourceCode
      style=\\\"background: #f1f3f5;\\\"}\\n``` {.sourceCode .css .code-with-copy}\\n.obfuscated-mail-address::before
      {\\n  content: attr(data-user);\\n}\\n.obfuscated-mail-address::after {\\n  content:
      attr(data-domain);\\n}\\n.obfuscated-email-address > * {\\n  display: none;\\n}\\n```\\n:::\\n\\nThe
      result is readable, but can be neither selected nor copied:\\n\\n[obfuscated
      email address]{.obfuscated-mail-address .dont-touch\\nuser=\\\"john.doe\\\"
      domain=\\\"example.com\\\"}\\n\\nThe nested `<span>` and its styling could be
      omitted, without changing\\nthe presentation in most browsers. We use it to
      ensures that everything\\nfails gracefully in browsers with limited CSS support.
      To see why this\\nmatters, have a look at this page in a text browser like *w3m*
      or\\n*links*.\\n:::\\n\\n::: {#drawbacks .section .level2}\\n## Drawbacks {#drawbacks
      .anchored anchor-id=\\\"drawbacks\\\"}\\n\\nThe biggest advantage of this method
      is also it's biggest disadvantage:\\nThe semantics are broken. The classic markup-code\\n\\n:::
      {#cb3 .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n``` {.sourceCode .html
      .code-with-copy}\\n<a href=\\\"mailto:me@example.com\\\">John Doe</a>\\n```\\n:::\\n\\nis
      rendered as [John Doe](mailto:me@example.com) and makes it very\\nclear, to
      machines and humans alike, that *John Doe* can be reached at\\n*me@example.com*.
      Address munging, like the above, preserves this\\nmeaning for humans, but takes
      it away for machines. For better and for\\nworse, browsers, search engines,
      and spam bots will not be aware of the\\nmeaning of the obfuscated address.\\n\\nThese
      effects can be alleviated by resolving to additional javascript:\\n\\n::: {#cb4
      .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n``` {.sourceCode .javascript
      .code-with-copy}\\n// convert obfuscated mail addresses into clickable \\\"mailto:\\\"
      links\\njQuery(\\\"document\\\").ready(function($) {\\n  var mailAddressClass
      = \\\"obfuscated-mail-address\\\";\\n  $(\\\".\\\"+mailAddressClass).each(function()
      {\\n    var address = $(this).attr(\\\"data-user\\\") + \\\"@\\\" + $(this).attr(\\\"data-domain\\\");\\n
      \   $(this).html($(\\\"<a href=\\\\\\\"mailto:\\\" + address + \\\"\\\\\\\">\\\"
      + address + \\\"</a>\\\", {}));\\n    $(this).removeClass(mailAddressClass);\\n
      \ });\\n});\\n```\\n:::\\n\\nThe webpage is still usable with JavaScript turned
      off, and even fails\\ngracefully on text-only browsers. If JavaScript is available,
      the\\nobfuscated links offer the same experience as properly coded\\n`<a href=\\\"mailto:...\\\">...</a>`
      links: [@]{.obfuscated-mail-address\\nuser=\\\"john.doe\\\" domain=\\\"example.com\\\"}.
      I believe this to be a very good\\ntrade-off between usability and safety from
      harvesters.\\n:::\\n\",\"relationships\":[],\"archive_url\":\"https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/avoiding-spam\",\"guid\":\"https://tarleb.com/posts/avoiding-spam/index.html\",\"updated\":false,\"category\":\"computerAndInformationSciences\"}]"
    headers:
      Access-Control-Allow-Origin:
      - '*'
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 84986474e96c1638-DUS
      Connection:
      - keep-alive
      Content-Profile:
      - public
      Content-Range:
      - '*/*'
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Mon, 22 Jan 2024 14:12:32 GMT
      Preference-Applied:
      - resolution=merge-duplicates
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      Via:
      - kong/2.8.1
      X-Kong-Proxy-Latency:
      - '1'
      X-Kong-Upstream-Latency:
      - '5'
      alt-svc:
      - h3=":443"; ma=86400
      sb-gateway-version:
      - '1'
    http_version: HTTP/1.1
    status_code: 201
- request:
    body: '{"indexed": true}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      accept-profile:
      - public
      connection:
      - keep-alive
      content-length:
      - '17'
      content-profile:
      - public
      content-type:
      - application/json
      host:
      - db.rogue-scholar.org
      prefer:
      - return=representation
      user-agent:
      - python-httpx/0.25.2
      x-client-info:
      - supabase-py/2.3.4
    method: PATCH
    uri: https://db.rogue-scholar.org/rest/v1/posts?id=eq.1855bfd0-e6c3-40c2-86e3-ddcea2ecfce8
  response:
    content: "[{\"url\":\"https://tarleb.com/posts/avoiding-spam\",\"title\":\"Avoid
      Mail Harvesting through Address Munging\",\"summary\":\"Spam just doesn\u2019t
      die. Every major mail provider has really good spam filters in place, as do
      the common mail clients. Nontheless, there seem to be enough people reading
      \u2013 and acting on \u2013 spam mail to make it a profitable business. No matter
      how much we hate it, we need to deal with spam. Better than having a good spam
      filter is not to be spammed in the first place.\\n\",\"image\":null,\"tags\":[\"Html\",\"Css\",\"Javascript\"],\"language\":\"en\",\"authors\":[{\"name\":
      \"Albert Krewinkel\"}],\"doi\":\"https://doi.org/10.59350/fk5r0-szd72\",\"id\":\"1855bfd0-e6c3-40c2-86e3-ddcea2ecfce8\",\"reference\":[],\"updated_at\":1377388800,\"published_at\":1377388800,\"blog_name\":\"tarleb\",\"indexed_at\":1700486796,\"indexed\":true,\"images\":[],\"blog_slug\":\"tarleb\",\"content_text\":\"Spam
      just doesn't die. Every major mail provider has really good spam\\nfilters in
      place, as do the common mail clients. Nontheless, there seem\\nto be enough
      people reading -- and acting on -- spam mail to make it a\\nprofitable business.
      No matter how much we hate it, we need to deal with\\nspam.\\n\\nBetter than
      having a good spam filter is not to be spammed in the first\\nplace. Since nobody
      can sent me unsolicited bulk mail if they don't know\\nmy mail address, keeping
      the mail address as private as possible is the\\nway to go here. But what if
      we *want* our e-mail address to be public\\nfor other people to reach us? Adding
      minor obstacles to make it just a\\nbit more difficult for spammers to get the
      address can be enough.\\n\\n::: {#address-munging .section .level2}\\n## Address
      Munging {#address-munging .anchored anchor-id=\\\"address-munging\\\"}\\n\\nThe
      usual way for spammers to collect email addresses is to crawl\\nwebsites and
      to harvest everything that looks like a valid mail address.\\nA common defense
      is [address\\nmunging](https://en.wikipedia.org/wiki/Address_munging), i.e.\_resolving\\nto
      bogus comments, additional markup, images or javascript to hide mail\\naddresses
      from automatic harvesters. I find the use of images or\\njavascript problematic
      for various reasons and just dislike unnecessary\\ncomments. Luckily, HTML5
      and CSS3 make it really easy to mangle\\naddresses without using either of these
      methods.\\n:::\\n\\n::: {#obfuscating-an-address-with-html5-css3 .section .level2}\\n##
      Obfuscating an Address with HTML5 & CSS3 {#obfuscating-an-address-with-html5-css3
      .anchored anchor-id=\\\"obfuscating-an-address-with-html5-css3\\\"}\\n\\nOur
      approach here leverages the HTML5\\n[`data-*`](http://www.w3.org/TR/html5/dom.html#embedding-custom-non-visible-data-with-the-data-*-attributes)\\nattributes
      as well as the\\n[`::before`](https://developer.mozilla.org/en-US/docs/Web/CSS/::before)\\nand\\n[`::after`](https://developer.mozilla.org/en-US/docs/Web/CSS/::after)\\npseudo-elements.
      The mail address is divided and stored in custom data\\nattributes and displayed
      as pseudo-elements. The address is kept in the\\nmarkup, the presentation is
      handled in the style sheet:\\n\\nHTML:\\n\\n::: {#cb1 .sourceCode style=\\\"background:
      #f1f3f5;\\\"}\\n``` {.sourceCode .html .code-with-copy}\\n<span data-user=\\\"john.doe\\\"\\n
      \     data-domain=\\\"example.com\\\"\\n      class=\\\"obfuscated-mail-address\\\"><!--\\n-->@<span>obfuscated
      email address</span></span>\\n```\\n:::\\n\\nCSS:\\n\\n::: {#cb2 .sourceCode
      style=\\\"background: #f1f3f5;\\\"}\\n``` {.sourceCode .css .code-with-copy}\\n.obfuscated-mail-address::before
      {\\n  content: attr(data-user);\\n}\\n.obfuscated-mail-address::after {\\n  content:
      attr(data-domain);\\n}\\n.obfuscated-email-address > * {\\n  display: none;\\n}\\n```\\n:::\\n\\nThe
      result is readable, but can be neither selected nor copied:\\n\\n[obfuscated
      email address]{.obfuscated-mail-address .dont-touch\\nuser=\\\"john.doe\\\"
      domain=\\\"example.com\\\"}\\n\\nThe nested `<span>` and its styling could be
      omitted, without changing\\nthe presentation in most browsers. We use it to
      ensures that everything\\nfails gracefully in browsers with limited CSS support.
      To see why this\\nmatters, have a look at this page in a text browser like *w3m*
      or\\n*links*.\\n:::\\n\\n::: {#drawbacks .section .level2}\\n## Drawbacks {#drawbacks
      .anchored anchor-id=\\\"drawbacks\\\"}\\n\\nThe biggest advantage of this method
      is also it's biggest disadvantage:\\nThe semantics are broken. The classic markup-code\\n\\n:::
      {#cb3 .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n``` {.sourceCode .html
      .code-with-copy}\\n<a href=\\\"mailto:me@example.com\\\">John Doe</a>\\n```\\n:::\\n\\nis
      rendered as [John Doe](mailto:me@example.com) and makes it very\\nclear, to
      machines and humans alike, that *John Doe* can be reached at\\n*me@example.com*.
      Address munging, like the above, preserves this\\nmeaning for humans, but takes
      it away for machines. For better and for\\nworse, browsers, search engines,
      and spam bots will not be aware of the\\nmeaning of the obfuscated address.\\n\\nThese
      effects can be alleviated by resolving to additional javascript:\\n\\n::: {#cb4
      .sourceCode style=\\\"background: #f1f3f5;\\\"}\\n``` {.sourceCode .javascript
      .code-with-copy}\\n// convert obfuscated mail addresses into clickable \\\"mailto:\\\"
      links\\njQuery(\\\"document\\\").ready(function($) {\\n  var mailAddressClass
      = \\\"obfuscated-mail-address\\\";\\n  $(\\\".\\\"+mailAddressClass).each(function()
      {\\n    var address = $(this).attr(\\\"data-user\\\") + \\\"@\\\" + $(this).attr(\\\"data-domain\\\");\\n
      \   $(this).html($(\\\"<a href=\\\\\\\"mailto:\\\" + address + \\\"\\\\\\\">\\\"
      + address + \\\"</a>\\\", {}));\\n    $(this).removeClass(mailAddressClass);\\n
      \ });\\n});\\n```\\n:::\\n\\nThe webpage is still usable with JavaScript turned
      off, and even fails\\ngracefully on text-only browsers. If JavaScript is available,
      the\\nobfuscated links offer the same experience as properly coded\\n`<a href=\\\"mailto:...\\\">...</a>`
      links: [@]{.obfuscated-mail-address\\nuser=\\\"john.doe\\\" domain=\\\"example.com\\\"}.
      I believe this to be a very good\\ntrade-off between usability and safety from
      harvesters.\\n:::\\n\",\"relationships\":[],\"archive_url\":\"https://wayback.archive-it.org/22161/20231101171515/https://tarleb.com/posts/avoiding-spam\",\"guid\":\"https://tarleb.com/posts/avoiding-spam/index.html\",\"updated\":false,\"category\":\"computerAndInformationSciences\"}]"
    headers:
      Access-Control-Allow-Origin:
      - '*'
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 849864758a191638-DUS
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Profile:
      - public
      Content-Range:
      - 0-0/*
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Mon, 22 Jan 2024 14:12:32 GMT
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      Via:
      - kong/2.8.1
      X-Kong-Proxy-Latency:
      - '0'
      X-Kong-Upstream-Latency:
      - '3'
      alt-svc:
      - h3=":443"; ma=86400
      sb-gateway-version:
      - '1'
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: '{}'
    headers:
      accept:
      - application/vnd.pgrst.object+json
      accept-encoding:
      - gzip, deflate
      accept-profile:
      - public
      connection:
      - keep-alive
      content-length:
      - '2'
      content-profile:
      - public
      content-type:
      - application/json
      host:
      - db.rogue-scholar.org
      user-agent:
      - python-httpx/0.25.2
      x-client-info:
      - supabase-py/2.3.4
    method: GET
    uri: https://db.rogue-scholar.org/rest/v1/blogs?select=id%2C%20slug%2C%20feed_url%2C%20current_feed_url%2C%20home_page_url%2C%20archive_prefix%2C%20feed_format%2C%20created_at%2C%20updated_at%2C%20mastodon%2C%20generator%2C%20generator_raw%2C%20language%2C%20category%2C%20favicon%2C%20title%2C%20description%2C%20category%2C%20status%2C%20user_id%2C%20authors%2C%20plan%2C%20use_api%2C%20relative_url%2C%20filter%2C%20secure&slug=eq.tarleb
  response:
    content: '{"id":"c6e3ab7a-a0d9-4ee8-9b16-efa5b5c541b8","slug":"tarleb","feed_url":"https://tarleb.com/index.xml","current_feed_url":null,"home_page_url":"https://tarleb.com/index.html","archive_prefix":"https://wayback.archive-it.org/22161/20231101171515/","feed_format":"application/rss+xml","created_at":1681948800,"updated_at":1679616000,"mastodon":null,"generator":"Quarto","generator_raw":"Quarto
      1.2.475","language":"en","category":"computerAndInformationSciences","favicon":null,"title":"tarleb","description":"tarleb''s
      blog","category":"computerAndInformationSciences","status":"active","user_id":"dead81b3-8a8b-45c9-85fe-f01bb3948c77","authors":null,"plan":"Starter","use_api":null,"relative_url":null,"filter":null,"secure":true}'
    headers:
      Access-Control-Allow-Origin:
      - '*'
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 84c069075da7cb09-DUS
      Connection:
      - keep-alive
      Content-Location:
      - /blogs?select=id%2C%20slug%2C%20feed_url%2C%20current_feed_url%2C%20home_page_url%2C%20archive_prefix%2C%20feed_format%2C%20created_at%2C%20updated_at%2C%20mastodon%2C%20generator%2C%20generator_raw%2C%20language%2C%20category%2C%20favicon%2C%20title%2C%20description%2C%20category%2C%20status%2C%20user_id%2C%20authors%2C%20plan%2C%20use_api%2C%20relative_url%2C%20filter%2C%20secure&slug=eq.tarleb
      Content-Profile:
      - public
      Content-Range:
      - 0-0/*
      Content-Type:
      - application/vnd.pgrst.object+json; charset=utf-8
      Date:
      - Sat, 27 Jan 2024 10:46:09 GMT
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      Via:
      - kong/2.8.1
      X-Kong-Proxy-Latency:
      - '1'
      X-Kong-Upstream-Latency:
      - '5'
      alt-svc:
      - h3=":443"; ma=86400
      sb-gateway-version:
      - '1'
    http_version: HTTP/1.1
    status_code: 200
version: 1
